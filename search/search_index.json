{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome Welcome to Hongnan G.'s website. Here you can follow my learning journey. I write consistently about mathematics, computer science, and programming, with heavy focus on fundamental concepts. I also dabble in computer vision and participate in competitions from time to time.","title":"Home"},{"location":"#welcome","text":"Welcome to Hongnan G.'s website. Here you can follow my learning journey. I write consistently about mathematics, computer science, and programming, with heavy focus on fundamental concepts. I also dabble in computer vision and participate in competitions from time to time.","title":"Welcome"},{"location":"about/","text":"My name is Hongnan Gao, hailing from Singapore. I graduated from the National University of Singapore with a degree in Mathematics in 2019.","title":"About"},{"location":"reighns_ml_journey/data_structures_and_algorithms/BigO%20Notation/","text":"\\[ \\newcommand{\\O}{\\mathcal{O}} \\] Most times if your for loop loops \\(n\\) times and each the for loop block, each statement takes \\(\\O(1)\\) time, then we conveniently deduce that \\[ n \\cdot \\O(1) = \\O(n \\cdot 1) = \\O(n) \\] but the confusion may lie in whether this is mathematically correct. One can find out more here 1 . https://cs.stackexchange.com/questions/366/what-goes-wrong-with-sums-of-landau-terms \u21a9","title":"BigO Notation"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Duplicates/","text":"\\[ \\newcommand{\\O}{\\mathcal{O}} \\] Contains Duplicates Insert Problem Statement. Assumptions Each given input will have exactly one solution Same element cannot be used twice Order of indices does not matter Test Cases Intuition Code Walkthrough Consider writing pseudo code. from typing import * def containsDuplicate ( nums : List [ int ]) -> bool : \"\"\"Check if a list contains duplicate elements. Args: nums (List[int]): List of integers. Returns: bool: Boolean value to indicate if the list contains duplicate elements. Examples: >>> containsDuplicate(nums=[1,2,3,2,11]) \"\"\" dup_dict = {} for _ , num in enumerate ( nums ): if num not in dup_dict : dup_dict [ num ] = 0 else : return True return False >>> nums = [ 15 , 2 , 3 , 7 ] >>> target = 9 >>> twoSum ( nums , target ) [1, 3] Time Complexity Time complexity: Space Complexity Space complexity:","title":"Duplicates"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Duplicates/#contains-duplicates","text":"Insert Problem Statement.","title":"Contains Duplicates"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Duplicates/#assumptions","text":"Each given input will have exactly one solution Same element cannot be used twice Order of indices does not matter","title":"Assumptions"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Duplicates/#test-cases","text":"","title":"Test Cases"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Duplicates/#intuition","text":"","title":"Intuition"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Duplicates/#code-walkthrough","text":"Consider writing pseudo code. from typing import * def containsDuplicate ( nums : List [ int ]) -> bool : \"\"\"Check if a list contains duplicate elements. Args: nums (List[int]): List of integers. Returns: bool: Boolean value to indicate if the list contains duplicate elements. Examples: >>> containsDuplicate(nums=[1,2,3,2,11]) \"\"\" dup_dict = {} for _ , num in enumerate ( nums ): if num not in dup_dict : dup_dict [ num ] = 0 else : return True return False >>> nums = [ 15 , 2 , 3 , 7 ] >>> target = 9 >>> twoSum ( nums , target ) [1, 3]","title":"Code Walkthrough"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Duplicates/#time-complexity","text":"Time complexity:","title":"Time Complexity"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Duplicates/#space-complexity","text":"Space complexity:","title":"Space Complexity"},{"location":"reighns_ml_journey/data_structures_and_algorithms/HashMap/","text":"\\[ \\newcommand{\\O}{\\mathcal{O}} \\] Time Complexity Time complexity: \\(\\O(n)\\) . We traverse the list containing \\(n\\) elements only once. Each lookup in the table costs only \\(\\O(1)\\) time. Loosely speaking, this means in each for loop from line 22 to 26, each line takes \\(\\O(1)\\) time, so in a typical single iteration, we use around \\(\\O(3)\\) time, and looping it \\(n\\) times takes \\[W n \\cdot \\O(3) \\approx \\O(3n) \\approx \\O(n) \\] Space Complexity Space complexity: \\(\\O(n)\\) . The extra space required depends on the number of items stored in the dictionary seen , which stores at most \\(n\\) elements.","title":"HashMap"},{"location":"reighns_ml_journey/data_structures_and_algorithms/HashMap/#time-complexity","text":"Time complexity: \\(\\O(n)\\) . We traverse the list containing \\(n\\) elements only once. Each lookup in the table costs only \\(\\O(1)\\) time. Loosely speaking, this means in each for loop from line 22 to 26, each line takes \\(\\O(1)\\) time, so in a typical single iteration, we use around \\(\\O(3)\\) time, and looping it \\(n\\) times takes \\[W n \\cdot \\O(3) \\approx \\O(3n) \\approx \\O(n) \\]","title":"Time Complexity"},{"location":"reighns_ml_journey/data_structures_and_algorithms/HashMap/#space-complexity","text":"Space complexity: \\(\\O(n)\\) . The extra space required depends on the number of items stored in the dictionary seen , which stores at most \\(n\\) elements.","title":"Space Complexity"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Least%20Recently%20Used%20%28LRU%29%20cache/","text":"Tags Linked List Hash Maps Linked List + Hash Maps = OrderedDict from typing import * from collections import OrderedDict class LRUCache ( OrderedDict ): def __init__ ( self , capacity ): \"\"\" :type capacity: int \"\"\" self . capacity = capacity def get ( self , key ): \"\"\" :type key: int :rtype: int \"\"\" print ( self ) if key not in self : return - 1 self . move_to_end ( key , last = True ) print ( \"self[key]\" , self [ key ]) return self [ key ] def put ( self , key , value ): \"\"\" :type key: int :type value: int :rtype: void \"\"\" if key in self : self . move_to_end ( key , last = True ) self [ key ] = value if len ( self ) > self . capacity : self . popitem ( last = False ) # Your LRUCache object will be instantiated and called as such: # obj = LRUCache(capacity) # param_1 = obj.get(key) # obj.put(key,value) od = OrderedDict ({ 1 : 2 , 2 : 3 , 3 : 4 }) print ( od ) od . move_to_end ( 2 , last = True ) print ( od ) OrderedDict([(1, 2), (2, 3), (3, 4)]) OrderedDict([(1, 2), (3, 4), (2, 3)]) od . popitem ( last = False ) (1, 2) capacity = 2 obj = LRUCache ( capacity ) # self refers to obj obj . get ( 1 ) LRUCache() -1 obj [ 1 ] = 10 obj LRUCache([(2, 10), (1, 10)]) obj . put ( 2 , 10 ) obj [ 2 ] 10","title":"Least Recently Used (LRU) cache"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Least%20Recently%20Used%20%28LRU%29%20cache/#tags","text":"Linked List Hash Maps Linked List + Hash Maps = OrderedDict from typing import * from collections import OrderedDict class LRUCache ( OrderedDict ): def __init__ ( self , capacity ): \"\"\" :type capacity: int \"\"\" self . capacity = capacity def get ( self , key ): \"\"\" :type key: int :rtype: int \"\"\" print ( self ) if key not in self : return - 1 self . move_to_end ( key , last = True ) print ( \"self[key]\" , self [ key ]) return self [ key ] def put ( self , key , value ): \"\"\" :type key: int :type value: int :rtype: void \"\"\" if key in self : self . move_to_end ( key , last = True ) self [ key ] = value if len ( self ) > self . capacity : self . popitem ( last = False ) # Your LRUCache object will be instantiated and called as such: # obj = LRUCache(capacity) # param_1 = obj.get(key) # obj.put(key,value) od = OrderedDict ({ 1 : 2 , 2 : 3 , 3 : 4 }) print ( od ) od . move_to_end ( 2 , last = True ) print ( od ) OrderedDict([(1, 2), (2, 3), (3, 4)]) OrderedDict([(1, 2), (3, 4), (2, 3)]) od . popitem ( last = False ) (1, 2) capacity = 2 obj = LRUCache ( capacity ) # self refers to obj obj . get ( 1 ) LRUCache() -1 obj [ 1 ] = 10 obj LRUCache([(2, 10), (1, 10)]) obj . put ( 2 , 10 ) obj [ 2 ] 10","title":"Tags"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Linked%20List/","text":"from typing import * Node Object We create the Node object below. This object is currently going to be used for Singly Linked List. class Node : \"\"\" The Node object is initialized with a value and can be linked to the next node by setting the next_node attribute to a Node object. This node is Singular associated with Singly Linked List. Attributes: curr_node_value (Any): The value associated with the created node. next_node (Node): The next node in the linked list. Note the distinction between curr_node_value and next_node, the former is the value of the node, the latter is the pointer to the next node. Examples: >>> node = Node(1) >>> print(node.curr_node_value) 1 >>> print(node.next_node) None >>> node.next_node = Node(2) >>> print(node.next_node.curr_node_value) 2 >>> print(node.next_node.next_node) None \"\"\" curr_node_value : Any next_node : Optional [ \"Node\" ] def __init__ ( self , curr_node_value : Any = None ) -> None : self . curr_node_value = curr_node_value self . next_node = None One thing for me to visualize is the Node object is not just a single object. If we are talking about one node, then our node object should hold a curr_node_value and the next_node attribute should point to None . If the Node object holds more than one node, then we can imagine the whole Node object as a series of nodes. We can only access the nodes sequentially, starting from the first node. Nodes >>> node = Node ( 1 ) >>> print ( node . curr_node_value ) >>> print ( node . next_node ) >>> node . next_node = Node ( 2 ) >>> print ( node . next_node . curr_node_value ) >>> print ( node . next_node . next_node ) 1 None 2 None Linked List Object Base Class The head node (the first node) of a Linked List is of a Node object. The head entirely determines the entirety of the whole Linked List . Why? Because knowing the head node of the Linked List , we will be able to know every single node that comes after it sequentially (if exists). class LinkedList : \"\"\" The LinkedList object is initialized with a head node. The `head` node (the first node) of a **Linked List** is of a `Node` object. The `head` **entirely determines** the entirety of the whole **Linked List**. Because knowing the head node of the **Linked List**, we will be able to know every single node that comes after it sequentially (if exists). Attributes: head (Node): The head node of the linked list. \"\"\" head : Node = None def __init__ ( self ) -> None : self . head = None Let us walk through how to create a Linked List . Start with an empty linked list object. The head of the linked list is None. llist = LinkedList () We create 3 Node objects as of now, these 3 node object holds value of 1, 2 and 3 respectively. They are not linked, which can be verified by printing .next which returns None . first_node = Node ( 1 ) second_node = Node ( 2 ) third_node = Node ( 3 ) Now we assign the first node object first_node = Node(1) to the head attribute of the llist object. We further note that both first_node and llist.head now point to the same object and both are of type Node and each of them holds a value of \\(1\\) . We also have to be clear that we did not link the head (first) node to the next (second) node yet. \\[ \\textbf{first_node} \\to \\textbf{None} \\] llist . head = first_node assert id ( llist . head ) == id ( first_node ) assert isinstance ( llist . head , Node ) == isinstance ( first_node , Node ) assert llist . head . curr_node_value == first_node . curr_node_value == 1 We now link the first node with the second by populating the next_node attribute of the head of the linked list llist (i.e. llist.head.next_node = second_node ). We further note that both llist.head.next_node and second_node now point to the same object and both are of type Node and each of them holds a curr_node_value of \\(2\\) . Now the linked list llist has connected the first node and the second node in a linear fashion: \\[ \\textbf{first_node} \\to \\textbf{second_node} \\to \\textbf{None} \\] So to reiterate, our linked list llist at this stage is akin to a list [1, 2] . To access the first value of the linked list we can do llist.head.curr_node_value and to get the next value we can call llist.head.next_node.curr_node_value . We now link the second node with the third by populating the next_node attribute of the second node of the linked list llist , but to do so, we must actually reach the second node. (i.e. llist.head.next_node.next_node = third_node ). We further note that both llist.head.next_node.next_node and third_node now point to the same object and both are of type Node and each of them holds a curr_node_value of \\(3\\) . Now the linked list llist has connected the second node and the third node in a linear fashion: \\[ \\textbf{first_node} \\to \\textbf{second_node} \\to \\textbf{third_node} \\to \\textbf{None} \\] So to reiterate, our linked list llist at this stage is akin to a list [1, 2, 3] . To access the first value of the linked list we can do llist.head.curr_node_value and to get the next value we can call llist.head.next_node.curr_node_value and to get the third value, llist.head.next_node.next_node.value . There should be no confusion why we can chain attribute next_node here, since llist.head.next_node and llist.head.next_node.next_node are two different Node objects, so there won't be any overwriting of the next_node attribute. # 1 llist = LinkedList () # 2 first_node = Node ( 1 ) second_node = Node ( 2 ) third_node = Node ( 3 ) # 3 llist . head = first_node assert id ( llist . head ) == id ( first_node ) assert isinstance ( llist . head , Node ) == isinstance ( first_node , Node ) assert llist . head . curr_node_value == first_node . curr_node_value == 1 # 4 llist . head . next_node = second_node ; # Link first node with second assert id ( llist . head . next_node ) == id ( second_node ) assert isinstance ( llist . head . next_node , Node ) == isinstance ( second_node , Node ) assert llist . head . next_node . curr_node_value == second_node . curr_node_value == 2 # 5 llist . head . next_node . next_node = third_node ; # Link second node with the third node assert id ( llist . head . next_node . next_node ) == id ( third_node ) assert isinstance ( llist . head . next_node . next_node , Node ) == isinstance ( third_node , Node ) assert llist . head . next_node . next_node . curr_node_value == third_node . curr_node_value == 3 Traversing a Linked List A Wrong Attempt We first show a wrong attempt. The logic in traverse is as follows: We want to terminate the printing when we reach the last node, that is to say, when the last node is reached, the .next_node attribute should return None . We start off with the head node self.head and print self.head.curr_node_value in the first while loop to get the first node value. Subsequently, we overwrite self.head to be self.head.next_node after printing, so when the next while loop happens, printing self.head.curr_node_value actually points to self.head.next_node.curr_node_value . The logic continues until we reach the last node. class LinkedList : \"\"\" The LinkedList object is initialized with a head node. The `head` node (the first node) of a **Linked List** is of a `Node` object. The `head` **entirely determines** the entirety of the whole **Linked List**. Because knowing the head node of the **Linked List**, we will be able to know every single node that comes after it sequentially (if exists). Attributes: head (Node): The head node of the linked list. \"\"\" head : Node = None def __init__ ( self ) -> None : self . head = None def traverse ( self ) -> None : \"\"\"Traverse the linked list and print the values of each node. Examples: >>> first = Node(1) >>> second = Node(2) >>> third = Node(3) >>> ll = LinkedList() >>> ll.head = first >>> ll.head.next_node = second >>> ll.head.next_node.next_node = third >>> ll.traverse(ll.head) \"\"\" while self . head is not None : print ( self . head . curr_node_value ) self . head = self . head . next_node if self . head is None : print ( \"None\" ) >>> first = Node ( 1 ) >>> second = Node ( 2 ) >>> third = Node ( 3 ) >>> ll = LinkedList () >>> ll . head = first >>> ll . head . next_node = second >>> ll . head . next_node . next_node = third >>> ll . traverse () 1 2 3 None The code above works fine, but is not ideal since if we want to access llist.head.curr_node_value after calling llist.traverse() , there will be AttributeError: 'NoneType' object has no attribute 'value' since we already set self.head to None in our last loop. Thus, we should change the code a bit where we assign a temp variable to self.head . temp_node = self . head while temp_node is not None : print ( temp_node . curr_node_value ) temp_node = temp_node . next_node if temp_node is None : print ( \"None\" ) isinstance ( ll . head , type ( None )) # print(ll.head.curr_node_value) True Static Method Since I am just starting out on this topic, I want to keep the traverse method as a standalone function. This is easier for me to debug. class LinkedList : \"\"\" The LinkedList object is initialized with a head node. The `head` node (the first node) of a **Linked List** is of a `Node` object. The `head` **entirely determines** the entirety of the whole **Linked List**. Because knowing the head node of the **Linked List**, we will be able to know every single node that comes after it sequentially (if exists). Attributes: head (Node): The head node of the linked list. \"\"\" head : Node = None def __init__ ( self ) -> None : self . head = None @staticmethod def traverse ( head_node : Node ) -> None : \"\"\"Traverse the linked list and print the values of each node. Args: head_node (Node): The head node of a linked list. Examples: >>> first = Node(1) >>> second = Node(2) >>> third = Node(3) >>> ll = LinkedList() >>> ll.head = first >>> ll.head.next_node = second >>> ll.head.next_node.next_node = third >>> ll.traverse(ll.head) \"\"\" temp_node = head_node while temp_node is not None : print ( temp_node . curr_node_value ) temp_node = temp_node . next_node if temp_node is None : print ( \"None\" ) >>> first = Node ( 1 ) >>> second = Node ( 2 ) >>> third = Node ( 3 ) >>> ll = LinkedList () >>> ll . head = first >>> ll . head . next_node = second >>> ll . head . next_node . next_node = third >>> ll . traverse ( ll . head ) 1 2 3 None Linked List Walkthrough from typing import * class Node : curr_node_value : Any # next_node: self def __init__ ( self , curr_node_value : Any = None ): # a node can hold a current value and by default its next node is None # however we can assign values to the next of a node, but the next must be of object node as denoted # note the distinction between curr node value and next node, they are diff self . curr_node_value = curr_node_value self . next_node = None class LinkedList : def __init__ ( self ): # key point is that end of every llist, it points to None always self . head = None @staticmethod def add_node_before_head ( head_node : Node , node_value : Any ): # if you set head_node to self.head # first = Node(1) # second = Node(2) # third = Node(3) # ll = LinkedList() # ll.head = first # ll.head.next_node = second # ll.head.next_node.next_node = third # ll.add_node_before_head(0) # if you do these above, it won't get you 0123None, it gives 0None # because we are referring to self.head in this code block and self.head is None # therefore for clarity of my learning, I will do all staticmethods first then internalize one day. print ( \"Before inserting in the beginning\" ) LinkedList . traverse ( head_node ) new_node = Node ( node_value ) new_node . next_node = head_node head_node = new_node print ( \"After inserting in the beginning\" ) LinkedList . traverse ( head_node ) return head_node @staticmethod def add_node_after_node ( prev_node : Node , node_value : Any ): assert prev_node is not None , \"There should be a previous node in the given LinkedList!\" next_node = Node ( node_value ) next_node . next_node = prev_node . next_node prev_node . next_node = next_node LinkedList . traverse ( prev_node ) return prev_node # def add_single_node(self, node_value: Any) -> Node: # if self.head is None: # self.head = Node(node_value) # else: # self.head.next_node = Node(node_value) def add_multiple_nodes ( self , list_of_node_values : List [ Any ]): for node_value in list_of_node_values : self . head . next_node = node_value @staticmethod def traverse ( head_node : Node ): # stay true to the idea of having None as the \"last last Node\" temp = head_node while temp is not None : print ( temp . curr_node_value ) temp = temp . next_node if temp is None : print ( \"None\" ) @classmethod def reverse ( cls , head_node : Node ): print ( \"Traverse current head node:\" ) cls . traverse ( head_node ) prev_node = None curr_node = head_node while curr_node is not None : temp = curr_node curr_node = curr_node . next_node temp . next_node = prev_node prev_node = temp reversed_head_node = prev_node print ( \"Traverse reversed head node:\" ) cls . traverse ( reversed_head_node ) return reversed_head_node # to be more clear we isolate the reverse linked list fn def reverse ( head ): prev_node = None curr_node = head while curr_node is not None : temp = curr_node curr_node = curr_node . next_node temp . next_node = prev_node prev_node = temp reversed_head_node = prev_node return reversed_head_node if __name__ == \"__main__\" : # a = dummy_convert_to_redcap() first = Node ( 1 ) second = Node ( 2 ) third = Node ( 3 ) ll = LinkedList () ll . head = first ll . head . next_node = second ll . head . next_node . next_node = third # ll.add_node_before_head(ll.head, 0) ll . reverse ( ll . head ) Traverse current head node: 1 2 3 None Traverse reversed head node: 3 2 1 None References Linked List | Set 1 (Introduction) (GeeksforGeeks) Amazon Coding Interview Question: Reverse a Linked List (Leetcode 206 in Python) How to Implement a Linked List in Python","title":"Linked Lists"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Linked%20List/#node-object","text":"We create the Node object below. This object is currently going to be used for Singly Linked List. class Node : \"\"\" The Node object is initialized with a value and can be linked to the next node by setting the next_node attribute to a Node object. This node is Singular associated with Singly Linked List. Attributes: curr_node_value (Any): The value associated with the created node. next_node (Node): The next node in the linked list. Note the distinction between curr_node_value and next_node, the former is the value of the node, the latter is the pointer to the next node. Examples: >>> node = Node(1) >>> print(node.curr_node_value) 1 >>> print(node.next_node) None >>> node.next_node = Node(2) >>> print(node.next_node.curr_node_value) 2 >>> print(node.next_node.next_node) None \"\"\" curr_node_value : Any next_node : Optional [ \"Node\" ] def __init__ ( self , curr_node_value : Any = None ) -> None : self . curr_node_value = curr_node_value self . next_node = None One thing for me to visualize is the Node object is not just a single object. If we are talking about one node, then our node object should hold a curr_node_value and the next_node attribute should point to None . If the Node object holds more than one node, then we can imagine the whole Node object as a series of nodes. We can only access the nodes sequentially, starting from the first node. Nodes >>> node = Node ( 1 ) >>> print ( node . curr_node_value ) >>> print ( node . next_node ) >>> node . next_node = Node ( 2 ) >>> print ( node . next_node . curr_node_value ) >>> print ( node . next_node . next_node ) 1 None 2 None","title":"Node Object"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Linked%20List/#linked-list-object","text":"","title":"Linked List Object"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Linked%20List/#base-class","text":"The head node (the first node) of a Linked List is of a Node object. The head entirely determines the entirety of the whole Linked List . Why? Because knowing the head node of the Linked List , we will be able to know every single node that comes after it sequentially (if exists). class LinkedList : \"\"\" The LinkedList object is initialized with a head node. The `head` node (the first node) of a **Linked List** is of a `Node` object. The `head` **entirely determines** the entirety of the whole **Linked List**. Because knowing the head node of the **Linked List**, we will be able to know every single node that comes after it sequentially (if exists). Attributes: head (Node): The head node of the linked list. \"\"\" head : Node = None def __init__ ( self ) -> None : self . head = None Let us walk through how to create a Linked List . Start with an empty linked list object. The head of the linked list is None. llist = LinkedList () We create 3 Node objects as of now, these 3 node object holds value of 1, 2 and 3 respectively. They are not linked, which can be verified by printing .next which returns None . first_node = Node ( 1 ) second_node = Node ( 2 ) third_node = Node ( 3 ) Now we assign the first node object first_node = Node(1) to the head attribute of the llist object. We further note that both first_node and llist.head now point to the same object and both are of type Node and each of them holds a value of \\(1\\) . We also have to be clear that we did not link the head (first) node to the next (second) node yet. \\[ \\textbf{first_node} \\to \\textbf{None} \\] llist . head = first_node assert id ( llist . head ) == id ( first_node ) assert isinstance ( llist . head , Node ) == isinstance ( first_node , Node ) assert llist . head . curr_node_value == first_node . curr_node_value == 1 We now link the first node with the second by populating the next_node attribute of the head of the linked list llist (i.e. llist.head.next_node = second_node ). We further note that both llist.head.next_node and second_node now point to the same object and both are of type Node and each of them holds a curr_node_value of \\(2\\) . Now the linked list llist has connected the first node and the second node in a linear fashion: \\[ \\textbf{first_node} \\to \\textbf{second_node} \\to \\textbf{None} \\] So to reiterate, our linked list llist at this stage is akin to a list [1, 2] . To access the first value of the linked list we can do llist.head.curr_node_value and to get the next value we can call llist.head.next_node.curr_node_value . We now link the second node with the third by populating the next_node attribute of the second node of the linked list llist , but to do so, we must actually reach the second node. (i.e. llist.head.next_node.next_node = third_node ). We further note that both llist.head.next_node.next_node and third_node now point to the same object and both are of type Node and each of them holds a curr_node_value of \\(3\\) . Now the linked list llist has connected the second node and the third node in a linear fashion: \\[ \\textbf{first_node} \\to \\textbf{second_node} \\to \\textbf{third_node} \\to \\textbf{None} \\] So to reiterate, our linked list llist at this stage is akin to a list [1, 2, 3] . To access the first value of the linked list we can do llist.head.curr_node_value and to get the next value we can call llist.head.next_node.curr_node_value and to get the third value, llist.head.next_node.next_node.value . There should be no confusion why we can chain attribute next_node here, since llist.head.next_node and llist.head.next_node.next_node are two different Node objects, so there won't be any overwriting of the next_node attribute. # 1 llist = LinkedList () # 2 first_node = Node ( 1 ) second_node = Node ( 2 ) third_node = Node ( 3 ) # 3 llist . head = first_node assert id ( llist . head ) == id ( first_node ) assert isinstance ( llist . head , Node ) == isinstance ( first_node , Node ) assert llist . head . curr_node_value == first_node . curr_node_value == 1 # 4 llist . head . next_node = second_node ; # Link first node with second assert id ( llist . head . next_node ) == id ( second_node ) assert isinstance ( llist . head . next_node , Node ) == isinstance ( second_node , Node ) assert llist . head . next_node . curr_node_value == second_node . curr_node_value == 2 # 5 llist . head . next_node . next_node = third_node ; # Link second node with the third node assert id ( llist . head . next_node . next_node ) == id ( third_node ) assert isinstance ( llist . head . next_node . next_node , Node ) == isinstance ( third_node , Node ) assert llist . head . next_node . next_node . curr_node_value == third_node . curr_node_value == 3","title":"Base Class"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Linked%20List/#traversing-a-linked-list","text":"","title":"Traversing a Linked List"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Linked%20List/#a-wrong-attempt","text":"We first show a wrong attempt. The logic in traverse is as follows: We want to terminate the printing when we reach the last node, that is to say, when the last node is reached, the .next_node attribute should return None . We start off with the head node self.head and print self.head.curr_node_value in the first while loop to get the first node value. Subsequently, we overwrite self.head to be self.head.next_node after printing, so when the next while loop happens, printing self.head.curr_node_value actually points to self.head.next_node.curr_node_value . The logic continues until we reach the last node. class LinkedList : \"\"\" The LinkedList object is initialized with a head node. The `head` node (the first node) of a **Linked List** is of a `Node` object. The `head` **entirely determines** the entirety of the whole **Linked List**. Because knowing the head node of the **Linked List**, we will be able to know every single node that comes after it sequentially (if exists). Attributes: head (Node): The head node of the linked list. \"\"\" head : Node = None def __init__ ( self ) -> None : self . head = None def traverse ( self ) -> None : \"\"\"Traverse the linked list and print the values of each node. Examples: >>> first = Node(1) >>> second = Node(2) >>> third = Node(3) >>> ll = LinkedList() >>> ll.head = first >>> ll.head.next_node = second >>> ll.head.next_node.next_node = third >>> ll.traverse(ll.head) \"\"\" while self . head is not None : print ( self . head . curr_node_value ) self . head = self . head . next_node if self . head is None : print ( \"None\" ) >>> first = Node ( 1 ) >>> second = Node ( 2 ) >>> third = Node ( 3 ) >>> ll = LinkedList () >>> ll . head = first >>> ll . head . next_node = second >>> ll . head . next_node . next_node = third >>> ll . traverse () 1 2 3 None The code above works fine, but is not ideal since if we want to access llist.head.curr_node_value after calling llist.traverse() , there will be AttributeError: 'NoneType' object has no attribute 'value' since we already set self.head to None in our last loop. Thus, we should change the code a bit where we assign a temp variable to self.head . temp_node = self . head while temp_node is not None : print ( temp_node . curr_node_value ) temp_node = temp_node . next_node if temp_node is None : print ( \"None\" ) isinstance ( ll . head , type ( None )) # print(ll.head.curr_node_value) True","title":"A Wrong Attempt"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Linked%20List/#static-method","text":"Since I am just starting out on this topic, I want to keep the traverse method as a standalone function. This is easier for me to debug. class LinkedList : \"\"\" The LinkedList object is initialized with a head node. The `head` node (the first node) of a **Linked List** is of a `Node` object. The `head` **entirely determines** the entirety of the whole **Linked List**. Because knowing the head node of the **Linked List**, we will be able to know every single node that comes after it sequentially (if exists). Attributes: head (Node): The head node of the linked list. \"\"\" head : Node = None def __init__ ( self ) -> None : self . head = None @staticmethod def traverse ( head_node : Node ) -> None : \"\"\"Traverse the linked list and print the values of each node. Args: head_node (Node): The head node of a linked list. Examples: >>> first = Node(1) >>> second = Node(2) >>> third = Node(3) >>> ll = LinkedList() >>> ll.head = first >>> ll.head.next_node = second >>> ll.head.next_node.next_node = third >>> ll.traverse(ll.head) \"\"\" temp_node = head_node while temp_node is not None : print ( temp_node . curr_node_value ) temp_node = temp_node . next_node if temp_node is None : print ( \"None\" ) >>> first = Node ( 1 ) >>> second = Node ( 2 ) >>> third = Node ( 3 ) >>> ll = LinkedList () >>> ll . head = first >>> ll . head . next_node = second >>> ll . head . next_node . next_node = third >>> ll . traverse ( ll . head ) 1 2 3 None","title":"Static Method"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Linked%20List/#linked-list-walkthrough","text":"from typing import * class Node : curr_node_value : Any # next_node: self def __init__ ( self , curr_node_value : Any = None ): # a node can hold a current value and by default its next node is None # however we can assign values to the next of a node, but the next must be of object node as denoted # note the distinction between curr node value and next node, they are diff self . curr_node_value = curr_node_value self . next_node = None class LinkedList : def __init__ ( self ): # key point is that end of every llist, it points to None always self . head = None @staticmethod def add_node_before_head ( head_node : Node , node_value : Any ): # if you set head_node to self.head # first = Node(1) # second = Node(2) # third = Node(3) # ll = LinkedList() # ll.head = first # ll.head.next_node = second # ll.head.next_node.next_node = third # ll.add_node_before_head(0) # if you do these above, it won't get you 0123None, it gives 0None # because we are referring to self.head in this code block and self.head is None # therefore for clarity of my learning, I will do all staticmethods first then internalize one day. print ( \"Before inserting in the beginning\" ) LinkedList . traverse ( head_node ) new_node = Node ( node_value ) new_node . next_node = head_node head_node = new_node print ( \"After inserting in the beginning\" ) LinkedList . traverse ( head_node ) return head_node @staticmethod def add_node_after_node ( prev_node : Node , node_value : Any ): assert prev_node is not None , \"There should be a previous node in the given LinkedList!\" next_node = Node ( node_value ) next_node . next_node = prev_node . next_node prev_node . next_node = next_node LinkedList . traverse ( prev_node ) return prev_node # def add_single_node(self, node_value: Any) -> Node: # if self.head is None: # self.head = Node(node_value) # else: # self.head.next_node = Node(node_value) def add_multiple_nodes ( self , list_of_node_values : List [ Any ]): for node_value in list_of_node_values : self . head . next_node = node_value @staticmethod def traverse ( head_node : Node ): # stay true to the idea of having None as the \"last last Node\" temp = head_node while temp is not None : print ( temp . curr_node_value ) temp = temp . next_node if temp is None : print ( \"None\" ) @classmethod def reverse ( cls , head_node : Node ): print ( \"Traverse current head node:\" ) cls . traverse ( head_node ) prev_node = None curr_node = head_node while curr_node is not None : temp = curr_node curr_node = curr_node . next_node temp . next_node = prev_node prev_node = temp reversed_head_node = prev_node print ( \"Traverse reversed head node:\" ) cls . traverse ( reversed_head_node ) return reversed_head_node # to be more clear we isolate the reverse linked list fn def reverse ( head ): prev_node = None curr_node = head while curr_node is not None : temp = curr_node curr_node = curr_node . next_node temp . next_node = prev_node prev_node = temp reversed_head_node = prev_node return reversed_head_node if __name__ == \"__main__\" : # a = dummy_convert_to_redcap() first = Node ( 1 ) second = Node ( 2 ) third = Node ( 3 ) ll = LinkedList () ll . head = first ll . head . next_node = second ll . head . next_node . next_node = third # ll.add_node_before_head(ll.head, 0) ll . reverse ( ll . head ) Traverse current head node: 1 2 3 None Traverse reversed head node: 3 2 1 None","title":"Linked List Walkthrough"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Linked%20List/#references","text":"Linked List | Set 1 (Introduction) (GeeksforGeeks) Amazon Coding Interview Question: Reverse a Linked List (Leetcode 206 in Python) How to Implement a Linked List in Python","title":"References"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Merge%20Two%20Sorted%20%28Linked%29%20Lists/","text":"\\[ \\newcommand{\\O}{\\mathcal{O}} \\] Merge Two Sorted (Linked) Lists https://www.geeksforgeeks.org/merge-two-sorted-linked-lists/ Explain problem first, I got confused at first. Assumptions Each given input will have exactly one solution Same element cannot be used twice Order of indices does not matter Test Cases Intuition Code Walkthrough from typing import * class Node : curr_node_value : Any # next_node: Node def __init__ ( self , curr_node_value : Any = None ): # a node can hold a current value and by default its next node is None # however we can assign values to the next of a node, but the next must be of object node as denoted # note the distinction between curr node value and next node, they are diff self . curr_node_value = curr_node_value self . next_node = None class LinkedList : def __init__ ( self ): # key point is that end of every llist, it points to None always self . head = None @staticmethod def traverse ( head_node : Node ): # stay true to the idea of having None as the \"last last Node\" temp = head_node while temp is not None : print ( temp . curr_node_value ) temp = temp . next_node if temp is None : print ( \"None\" ) ll1_first = Node ( 1 ) ll1_second = Node ( 2 ) ll1_third = Node ( 3 ) ll2_first = Node ( 4 ) ll2_second = Node ( 5 ) ll2_third = Node ( 6 ) # create llist 1 ll1 = LinkedList () ll1 . head = ll1_first ll1 . head . next_node = ll1_second ll1 . head . next_node . next_node = ll1_third # create llist 2 ll2 = LinkedList () ll2 . head = ll2_first ll2 . head . next_node = ll2_second ll2 . head . next_node . next_node = ll2_third merged_sorted_llist = LinkedList () merged_sorted_llist . head = Node ( - 100 ) prehead_node = Node ( - 100 ) temp_node = prehead_node ll1_head = ll1 . head ll2_head = ll2 . head while ll1_head is not None and ll2_head is not None : # start with list 1 if ll1_head . curr_node_value <= ll2_head . curr_node_value : temp_node . next_node = ll1_head ll1_head = ll1_head . next_node else : temp_node . next_node = ll2_head ll2_head = ll2_head . next_node temp_node = temp_node . next_node temp_node . next_node = ll1_head or ll2_head merged_sorted_llist . traverse ( prehead_node . next_node ) 1 2 3 4 5 6 None https://leetcode.com/problems/merge-two-sorted-lists/discuss/759870/Python3-Solution-with-a-Detailed-Explanation-dummy-explained Time Complexity Time complexity: \\(\\O(n)\\) . We traverse the list containing \\(n\\) elements only once. Each lookup in the table costs only \\(\\O(1)\\) time. Loosely speaking, this means in each for loop from line 22 to 26, each line takes \\(\\O(1)\\) time, so in a typical single iteration, we use around \\(\\O(3)\\) time, and looping it \\(n\\) times takes \\[ n \\cdot \\O(3) \\approx \\O(3n) \\approx \\O(n) \\] Space Complexity Space complexity: \\(\\O(n)\\) . The extra space required depends on the number of items stored in the dictionary seen , which stores at most \\(n\\) elements.","title":"Merge Two Sorted (Linked) Lists"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Merge%20Two%20Sorted%20%28Linked%29%20Lists/#merge-two-sorted-linked-lists","text":"https://www.geeksforgeeks.org/merge-two-sorted-linked-lists/ Explain problem first, I got confused at first.","title":"Merge Two Sorted (Linked) Lists"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Merge%20Two%20Sorted%20%28Linked%29%20Lists/#assumptions","text":"Each given input will have exactly one solution Same element cannot be used twice Order of indices does not matter","title":"Assumptions"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Merge%20Two%20Sorted%20%28Linked%29%20Lists/#test-cases","text":"","title":"Test Cases"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Merge%20Two%20Sorted%20%28Linked%29%20Lists/#intuition","text":"","title":"Intuition"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Merge%20Two%20Sorted%20%28Linked%29%20Lists/#code-walkthrough","text":"from typing import * class Node : curr_node_value : Any # next_node: Node def __init__ ( self , curr_node_value : Any = None ): # a node can hold a current value and by default its next node is None # however we can assign values to the next of a node, but the next must be of object node as denoted # note the distinction between curr node value and next node, they are diff self . curr_node_value = curr_node_value self . next_node = None class LinkedList : def __init__ ( self ): # key point is that end of every llist, it points to None always self . head = None @staticmethod def traverse ( head_node : Node ): # stay true to the idea of having None as the \"last last Node\" temp = head_node while temp is not None : print ( temp . curr_node_value ) temp = temp . next_node if temp is None : print ( \"None\" ) ll1_first = Node ( 1 ) ll1_second = Node ( 2 ) ll1_third = Node ( 3 ) ll2_first = Node ( 4 ) ll2_second = Node ( 5 ) ll2_third = Node ( 6 ) # create llist 1 ll1 = LinkedList () ll1 . head = ll1_first ll1 . head . next_node = ll1_second ll1 . head . next_node . next_node = ll1_third # create llist 2 ll2 = LinkedList () ll2 . head = ll2_first ll2 . head . next_node = ll2_second ll2 . head . next_node . next_node = ll2_third merged_sorted_llist = LinkedList () merged_sorted_llist . head = Node ( - 100 ) prehead_node = Node ( - 100 ) temp_node = prehead_node ll1_head = ll1 . head ll2_head = ll2 . head while ll1_head is not None and ll2_head is not None : # start with list 1 if ll1_head . curr_node_value <= ll2_head . curr_node_value : temp_node . next_node = ll1_head ll1_head = ll1_head . next_node else : temp_node . next_node = ll2_head ll2_head = ll2_head . next_node temp_node = temp_node . next_node temp_node . next_node = ll1_head or ll2_head merged_sorted_llist . traverse ( prehead_node . next_node ) 1 2 3 4 5 6 None https://leetcode.com/problems/merge-two-sorted-lists/discuss/759870/Python3-Solution-with-a-Detailed-Explanation-dummy-explained","title":"Code Walkthrough"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Merge%20Two%20Sorted%20%28Linked%29%20Lists/#time-complexity","text":"Time complexity: \\(\\O(n)\\) . We traverse the list containing \\(n\\) elements only once. Each lookup in the table costs only \\(\\O(1)\\) time. Loosely speaking, this means in each for loop from line 22 to 26, each line takes \\(\\O(1)\\) time, so in a typical single iteration, we use around \\(\\O(3)\\) time, and looping it \\(n\\) times takes \\[ n \\cdot \\O(3) \\approx \\O(3n) \\approx \\O(n) \\]","title":"Time Complexity"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Merge%20Two%20Sorted%20%28Linked%29%20Lists/#space-complexity","text":"Space complexity: \\(\\O(n)\\) . The extra space required depends on the number of items stored in the dictionary seen , which stores at most \\(n\\) elements.","title":"Space Complexity"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Object%20Reference%20Confusion/","text":"Primer Consider the class dummy below. class dummy : def __init__ ( self , name ): self . name = name We start off with assigning two variables a and b to two dummy objects with their attribute name to be \\(1\\) and \\(2\\) respectively. Then we set a new variable c to be equals to a , we call c a reference to a and they are of the same object referenced to dummy(name=1) as the assertion holds. Now at line 9 , we re-assign c to b , and we assert that both a and c are different objects now. Main point is that the variable a is untouched, remaining \\(1\\) the whole time. We say that c is merely a reference to a and if we assign a new value (variable) to c , you don't change a . a = dummy ( name = 1 ) b = dummy ( name = 2 ) print ( f \"a= { a . name } , b= { b . name } \" ) c = a print ( f \"a= { a . name } , c= { c . name } \" ) assert id ( a ) == id ( c ) c = b print ( f \"a= { a . name } , c= { c . name } \" ) assert id ( a ) != id ( c ) a=1, b=2 a=1, c=1 a=1, c=2 The setup is exactly the same as previous up till line 7 . Instead of assigning c to another variable directly, we first change the attribute (property) of the object c to become \\(3\\) by c.name = 3 . Now if we print a.name and c.name again, we magically find that a.name is changed from \\(1\\) to \\(3\\) , moreover, both a and c are still referencing to the same object. We conclude that if you access a member (attribute) of the reference variable c , you're actually accessing a member (attribute) of a . So, if you assign a new value to the member (attribute) of c , you're assigning the same value to that member (attribute) of a . a = dummy ( name = 1 ) b = dummy ( name = 2 ) print ( f \"a= { a . name } , b= { b . name } \" ) c = a print ( f \"a= { a . name } , c= { c . name } \" ) assert id ( a ) == id ( c ) c . name = 3 print ( f \"a= { a . name } , c= { c . name } \" ) assert id ( a ) == id ( c ) a=1, b=2 a=1, c=1 a=3, c=3 Confusion 1 from typing import * class Node : curr_node_value : Any # next_node: Node def __init__ ( self , curr_node_value : Any = None ): self . curr_node_value = curr_node_value self . next_node = None class LinkedList : def __init__ ( self ): self . head = None ll1_first = Node ( 1 ) ll1_second = Node ( 2 ) ll1_third = Node ( 3 ) ll2_first = Node ( 4 ) ll2_second = Node ( 5 ) ll2_third = Node ( 6 ) # create llist 1 ll1 = LinkedList () ll1 . head = ll1_first ll1 . head . next_node = ll1_second ll1 . head . next_node . next_node = ll1_third # create llist 2 ll2 = LinkedList () ll2 . head = ll2_first ll2 . head . next_node = ll2_second ll2 . head . next_node . next_node = ll2_third merged_sorted_llist = LinkedList () ll1_temp_curr_node = ll1 . head ll2_temp_curr_node = ll2 . head while ll1_temp_curr_node is not None and ll2_temp_curr_node is not None : print ( ll1_temp_curr_node . curr_node_value ) ll1_curr_node = ll1_temp_curr_node ll2_curr_node = ll2_temp_curr_node if ll1_curr_node . curr_node_value <= ll2_curr_node . curr_node_value : merged_sorted_llist . head = ll1_curr_node merged_sorted_llist . head . next_node = ll2_curr_node ll1_temp_curr_node = ll1_temp_curr_node . next_node ll2_temp_curr_node = ll2_temp_curr_node . next_node 1 4 5 Scenario 1 If you comment out line 48 , then line 42 's print statement print(ll1_temp_curr_node.curr_node_value) will give you the following output: print ( ll1_temp_curr_node . curr_node_value ) print ( ll1_temp_curr_node . curr_node_value ) 1 2 3 Intuitively, this should be the case since our ll1_temp_curr_node starts off with ll1.head , and at line 51 , we re-assign ll1_temp_curr_node to its next node ll1_temp_curr_node.next_node so that in our next iteration it prints out the node value \\(2\\) , and so on. The scenario gets out of hand soon if you uncomment line 42 . Scenario 2 If you uncomment out line 48 , then line 42 's print statement print(ll1_temp_curr_node.curr_node_value) will give you the following output: print ( ll1_temp_curr_node . curr_node_value ) print ( ll1_temp_curr_node . curr_node_value ) 1 4 5 This gets confusing since I did not explicitly made any changes besides adding a harmless looking line . Why then did in the second iteration, ll1_temp_curr_node.curr_node_value gives us \\(4\\) instead of \\(2\\) ? This has to originate from the logic we laid out in the section Primer . The logic goes: ll1_temp_curr_node = ll1 . head # ll1_temp_curr_node is a reference to ll1.head ll1_curr_node = ll1_temp_curr_node # ll1_curr_node is a reference to ll1_temp_curr_node merged_sorted_llist . head = ll1_curr_node # this part is ok but main thing is to remember that merged_sorted_llist.head is a reference to ll1_curr_node merged_sorted_llist . head . next_node = ll2_curr_node # this part is where things go tricky, we explain more below. ll1_temp_curr_node = ll1_temp_curr_node . next_node # we explain more below The second last line is problematic, we made a change to the attribute next_node of merged_sorted_llist.head and so our merged_sorted_llist.head.next_node holds a value of \\(4\\) (the current value of ll2_curr_node ), and by our logic in Primer , this changes the attribute next_node in ll1_curr_node , so now ll1_curr_node 's next_node holds a value of \\(4\\) ; and recall that ll1_curr_node is also a reference to ll1_temp_curr_node , so changing the attribute of ll1_curr_node changes the attribute of ll1_temp_curr_node , so that ll1_temp_curr_node has a next_node of \\(4\\) . To recap, a small change in line 48 changes the next node of ll1_temp_curr_node and that is why when you call line 51 , our poor ll1_temp_curr_node did go to the next node, but the next node is no longer \\(2\\) and is now \\(4\\) . Confusion 2 So the name of the game is that: Using Primer as an example: in most cases in Python, when you perform an assignment on a variable, c in this case, the value of c changes, but the object a that it was originally referring to does not. This is because Python variables are simply references/pointers to objects. However, when you perform an assignment such that the reference variable changes its properties (attribute), then the original referenced object will change! However, when calling the reverse() method in a Linked List, one would think that line 43 changing temp 's attribute will affect the value of curr_node . The original logic was that: We assigned temp as a reference to curr_node in line 36 . We changed the attribute of the reference variable temp by setting its next_node to prev_node . Thus, curr_node 's next_node should also be prev_node (which is None ). This is not the case, why? The reason is simple, at line 40 , we overwrite curr_node to be something else, at this point in time, temp will lose its connection to curr_node , and is no longer a reference to it. Thus, when we did something to its attribute in line 43 , curr_node is unchanged. from typing import * class Node : curr_node_value : Any # next_node: Node def __init__ ( self , curr_node_value : Any = None ): self . curr_node_value = curr_node_value self . next_node = None class LinkedList : def __init__ ( self ): self . head = None @staticmethod def traverse ( head_node : Node ): # stay true to the idea of having None as the \"last last Node\" temp = head_node while temp is not None : print ( temp . curr_node_value ) temp = temp . next_node if temp is None : print ( \"None\" ) @classmethod def reverse ( cls , head_node : Node ): print ( \"Traverse current head node:\" ) cls . traverse ( head_node ) prev_node = None curr_node = head_node # print(id(head_node), id(curr_node)) counter = 1 while curr_node is not None : temp = curr_node # print(id(temp), id(curr_node)) print ( f \"loop { counter } : curr_node= { curr_node . curr_node_value } \" ) curr_node = curr_node . next_node # print(id(temp), id(curr_node)) temp . next_node = prev_node # print(id(temp), id(curr_node)) print ( f \"loop { counter } : curr_node= { curr_node . curr_node_value } \" ) prev_node = temp counter += 1 reversed_head_node = prev_node print ( \"Traverse reversed head node:\" ) cls . traverse ( reversed_head_node ) return reversed_head_node ll1_first = Node ( 1 ) ll1_second = Node ( 2 ) ll1_third = Node ( 3 ) # create llist 1 ll1 = LinkedList () ll1 . head = ll1_first ll1 . head . next_node = ll1_second ll1 . head . next_node . next_node = ll1_third _ = ll1 . reverse ( ll1 . head ) Traverse current head node: 1 2 3 None loop 1: curr_node=1 loop 1: curr_node=2 loop 2: curr_node=2 loop 2: curr_node=3 loop 3: curr_node=3 --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) ~\\AppData\\Local\\Temp/ipykernel_27492/346498127.py in <module> 66 67 ---> 68 _ = ll1.reverse(ll1.head) ~\\AppData\\Local\\Temp/ipykernel_27492/346498127.py in reverse(cls, head_node) 43 temp.next_node = prev_node 44 # print(id(temp), id(curr_node)) ---> 45 print(f\"loop {counter}: curr_node={curr_node.curr_node_value}\") 46 47 prev_node = temp AttributeError: 'NoneType' object has no attribute 'curr_node_value' Reference https://stackoverflow.com/questions/58759348/when-does-a-pointer-to-a-linked-list-change-the-actual-list","title":"Object Reference Confusion"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Object%20Reference%20Confusion/#primer","text":"Consider the class dummy below. class dummy : def __init__ ( self , name ): self . name = name We start off with assigning two variables a and b to two dummy objects with their attribute name to be \\(1\\) and \\(2\\) respectively. Then we set a new variable c to be equals to a , we call c a reference to a and they are of the same object referenced to dummy(name=1) as the assertion holds. Now at line 9 , we re-assign c to b , and we assert that both a and c are different objects now. Main point is that the variable a is untouched, remaining \\(1\\) the whole time. We say that c is merely a reference to a and if we assign a new value (variable) to c , you don't change a . a = dummy ( name = 1 ) b = dummy ( name = 2 ) print ( f \"a= { a . name } , b= { b . name } \" ) c = a print ( f \"a= { a . name } , c= { c . name } \" ) assert id ( a ) == id ( c ) c = b print ( f \"a= { a . name } , c= { c . name } \" ) assert id ( a ) != id ( c ) a=1, b=2 a=1, c=1 a=1, c=2 The setup is exactly the same as previous up till line 7 . Instead of assigning c to another variable directly, we first change the attribute (property) of the object c to become \\(3\\) by c.name = 3 . Now if we print a.name and c.name again, we magically find that a.name is changed from \\(1\\) to \\(3\\) , moreover, both a and c are still referencing to the same object. We conclude that if you access a member (attribute) of the reference variable c , you're actually accessing a member (attribute) of a . So, if you assign a new value to the member (attribute) of c , you're assigning the same value to that member (attribute) of a . a = dummy ( name = 1 ) b = dummy ( name = 2 ) print ( f \"a= { a . name } , b= { b . name } \" ) c = a print ( f \"a= { a . name } , c= { c . name } \" ) assert id ( a ) == id ( c ) c . name = 3 print ( f \"a= { a . name } , c= { c . name } \" ) assert id ( a ) == id ( c ) a=1, b=2 a=1, c=1 a=3, c=3","title":"Primer"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Object%20Reference%20Confusion/#confusion-1","text":"from typing import * class Node : curr_node_value : Any # next_node: Node def __init__ ( self , curr_node_value : Any = None ): self . curr_node_value = curr_node_value self . next_node = None class LinkedList : def __init__ ( self ): self . head = None ll1_first = Node ( 1 ) ll1_second = Node ( 2 ) ll1_third = Node ( 3 ) ll2_first = Node ( 4 ) ll2_second = Node ( 5 ) ll2_third = Node ( 6 ) # create llist 1 ll1 = LinkedList () ll1 . head = ll1_first ll1 . head . next_node = ll1_second ll1 . head . next_node . next_node = ll1_third # create llist 2 ll2 = LinkedList () ll2 . head = ll2_first ll2 . head . next_node = ll2_second ll2 . head . next_node . next_node = ll2_third merged_sorted_llist = LinkedList () ll1_temp_curr_node = ll1 . head ll2_temp_curr_node = ll2 . head while ll1_temp_curr_node is not None and ll2_temp_curr_node is not None : print ( ll1_temp_curr_node . curr_node_value ) ll1_curr_node = ll1_temp_curr_node ll2_curr_node = ll2_temp_curr_node if ll1_curr_node . curr_node_value <= ll2_curr_node . curr_node_value : merged_sorted_llist . head = ll1_curr_node merged_sorted_llist . head . next_node = ll2_curr_node ll1_temp_curr_node = ll1_temp_curr_node . next_node ll2_temp_curr_node = ll2_temp_curr_node . next_node 1 4 5","title":"Confusion 1"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Object%20Reference%20Confusion/#scenario-1","text":"If you comment out line 48 , then line 42 's print statement print(ll1_temp_curr_node.curr_node_value) will give you the following output: print ( ll1_temp_curr_node . curr_node_value ) print ( ll1_temp_curr_node . curr_node_value ) 1 2 3 Intuitively, this should be the case since our ll1_temp_curr_node starts off with ll1.head , and at line 51 , we re-assign ll1_temp_curr_node to its next node ll1_temp_curr_node.next_node so that in our next iteration it prints out the node value \\(2\\) , and so on. The scenario gets out of hand soon if you uncomment line 42 .","title":"Scenario 1"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Object%20Reference%20Confusion/#scenario-2","text":"If you uncomment out line 48 , then line 42 's print statement print(ll1_temp_curr_node.curr_node_value) will give you the following output: print ( ll1_temp_curr_node . curr_node_value ) print ( ll1_temp_curr_node . curr_node_value ) 1 4 5 This gets confusing since I did not explicitly made any changes besides adding a harmless looking line . Why then did in the second iteration, ll1_temp_curr_node.curr_node_value gives us \\(4\\) instead of \\(2\\) ? This has to originate from the logic we laid out in the section Primer . The logic goes: ll1_temp_curr_node = ll1 . head # ll1_temp_curr_node is a reference to ll1.head ll1_curr_node = ll1_temp_curr_node # ll1_curr_node is a reference to ll1_temp_curr_node merged_sorted_llist . head = ll1_curr_node # this part is ok but main thing is to remember that merged_sorted_llist.head is a reference to ll1_curr_node merged_sorted_llist . head . next_node = ll2_curr_node # this part is where things go tricky, we explain more below. ll1_temp_curr_node = ll1_temp_curr_node . next_node # we explain more below The second last line is problematic, we made a change to the attribute next_node of merged_sorted_llist.head and so our merged_sorted_llist.head.next_node holds a value of \\(4\\) (the current value of ll2_curr_node ), and by our logic in Primer , this changes the attribute next_node in ll1_curr_node , so now ll1_curr_node 's next_node holds a value of \\(4\\) ; and recall that ll1_curr_node is also a reference to ll1_temp_curr_node , so changing the attribute of ll1_curr_node changes the attribute of ll1_temp_curr_node , so that ll1_temp_curr_node has a next_node of \\(4\\) . To recap, a small change in line 48 changes the next node of ll1_temp_curr_node and that is why when you call line 51 , our poor ll1_temp_curr_node did go to the next node, but the next node is no longer \\(2\\) and is now \\(4\\) .","title":"Scenario 2"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Object%20Reference%20Confusion/#confusion-2","text":"So the name of the game is that: Using Primer as an example: in most cases in Python, when you perform an assignment on a variable, c in this case, the value of c changes, but the object a that it was originally referring to does not. This is because Python variables are simply references/pointers to objects. However, when you perform an assignment such that the reference variable changes its properties (attribute), then the original referenced object will change! However, when calling the reverse() method in a Linked List, one would think that line 43 changing temp 's attribute will affect the value of curr_node . The original logic was that: We assigned temp as a reference to curr_node in line 36 . We changed the attribute of the reference variable temp by setting its next_node to prev_node . Thus, curr_node 's next_node should also be prev_node (which is None ). This is not the case, why? The reason is simple, at line 40 , we overwrite curr_node to be something else, at this point in time, temp will lose its connection to curr_node , and is no longer a reference to it. Thus, when we did something to its attribute in line 43 , curr_node is unchanged. from typing import * class Node : curr_node_value : Any # next_node: Node def __init__ ( self , curr_node_value : Any = None ): self . curr_node_value = curr_node_value self . next_node = None class LinkedList : def __init__ ( self ): self . head = None @staticmethod def traverse ( head_node : Node ): # stay true to the idea of having None as the \"last last Node\" temp = head_node while temp is not None : print ( temp . curr_node_value ) temp = temp . next_node if temp is None : print ( \"None\" ) @classmethod def reverse ( cls , head_node : Node ): print ( \"Traverse current head node:\" ) cls . traverse ( head_node ) prev_node = None curr_node = head_node # print(id(head_node), id(curr_node)) counter = 1 while curr_node is not None : temp = curr_node # print(id(temp), id(curr_node)) print ( f \"loop { counter } : curr_node= { curr_node . curr_node_value } \" ) curr_node = curr_node . next_node # print(id(temp), id(curr_node)) temp . next_node = prev_node # print(id(temp), id(curr_node)) print ( f \"loop { counter } : curr_node= { curr_node . curr_node_value } \" ) prev_node = temp counter += 1 reversed_head_node = prev_node print ( \"Traverse reversed head node:\" ) cls . traverse ( reversed_head_node ) return reversed_head_node ll1_first = Node ( 1 ) ll1_second = Node ( 2 ) ll1_third = Node ( 3 ) # create llist 1 ll1 = LinkedList () ll1 . head = ll1_first ll1 . head . next_node = ll1_second ll1 . head . next_node . next_node = ll1_third _ = ll1 . reverse ( ll1 . head ) Traverse current head node: 1 2 3 None loop 1: curr_node=1 loop 1: curr_node=2 loop 2: curr_node=2 loop 2: curr_node=3 loop 3: curr_node=3 --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) ~\\AppData\\Local\\Temp/ipykernel_27492/346498127.py in <module> 66 67 ---> 68 _ = ll1.reverse(ll1.head) ~\\AppData\\Local\\Temp/ipykernel_27492/346498127.py in reverse(cls, head_node) 43 temp.next_node = prev_node 44 # print(id(temp), id(curr_node)) ---> 45 print(f\"loop {counter}: curr_node={curr_node.curr_node_value}\") 46 47 prev_node = temp AttributeError: 'NoneType' object has no attribute 'curr_node_value'","title":"Confusion 2"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Object%20Reference%20Confusion/#reference","text":"https://stackoverflow.com/questions/58759348/when-does-a-pointer-to-a-linked-list-change-the-actual-list","title":"Reference"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/","text":"from typing import * Primer Some solutions using pythons in-built function is not recommended to do in front of interviewer. Greatest Sum Divisible by Three 1 def maxSumDivThree ( nums : List [ int ]) -> int : \"\"\" https://leetcode.com/problems/greatest-sum-divisible-by-three/discuss/431077/JavaC%2B%2BPython-One-Pass-O(1)-space Args: nums (List[int]): The input list of integers. Returns: int: The maximum sum of the integers that can be divided by three. Examples: >>> nums = [3,6,5,1,8] >>> maxSumDivThree(nums) 18 \"\"\" dp = [ 0 , 0 , 0 ] for num in nums : for i in dp [:]: dp [( i + num ) % 3 ] = max ( dp [( i + num ) % 3 ], i + num ) return dp [ 0 ] https://leetcode.com/problems/greatest-sum-divisible-by-three/discuss/431077/JavaC%2B%2BPython-One-Pass-O(1)-space https://leetcode.com/problems/greatest-sum-divisible-by-three/discuss/559999/Come-here-if-you-can't-seem-to-get-it-(Full-Explanation-%2B-uncondensed-code) Palindrome Pairs 2 def palindromePairs ( words : List [ str ]) -> List [ List [ int ]]: \"\"\"https://leetcode.com/problems/palindrome-pairs/discuss/79219/Python-solution~ Args: words (List[str]): _description_ Returns: List[List[int]]: _description_ \"\"\" d = {} for i , w in enumerate ( words ): d [ w [:: - 1 ]] = i indices = set () for i , w in enumerate ( words ): for j in range ( len ( w ) + 1 ): prefix = w [: j ] postfix = w [ j :] if prefix in d and i != d [ prefix ] and postfix == postfix [:: - 1 ]: indices . add (( i , d [ prefix ])) if postfix in d and i != d [ postfix ] and prefix == prefix [:: - 1 ]: indices . add (( d [ postfix ], i )) return [ list ( p ) for p in indices ] Construct Binary Tree from Inorder and Postorder Traversal 3 # Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right def buildTree ( inorder : List [ int ], postorder : List [ int ]) -> TreeNode : \"\"\"https://leetcode.com/problems/construct-binary-tree-from-inorder-and-postorder-traversal/discuss/221681/A-better-Python-solution See henrygas solution. Args: inorder (List[int]): _description_ postorder (List[int]): _description_ Returns: TreeNode: _description_ \"\"\" value_to_idx = dict () for idx , value in enumerate ( inorder ): value_to_idx [ value ] = idx def build ( inorder , postorder , in_start , in_end , post_start , post_end ): if in_start <= in_end : root = TreeNode ( postorder [ post_end ]) in_idx = value_to_idx [ root . val ] in_idx_delta = in_idx - in_start root . left = build ( inorder , postorder , in_start , in_idx - 1 , post_start , post_start + in_idx_delta - 1 ) root . right = build ( inorder , postorder , in_idx + 1 , in_end , post_start + in_idx_delta , post_end - 1 ) return root else : return None return build ( inorder , postorder , 0 , len ( inorder ) - 1 , 0 , len ( postorder ) - 1 ) inorder = [ 4 , 8 , 2 , 5 , 1 , 6 , 3 , 7 ] postorder = [ 8 , 4 , 5 , 2 , 6 , 7 , 3 , 1 ] tree = buildTree ( inorder , postorder ) tree . val tree . left . val tree . left . right . val 1 https://www.geeksforgeeks.org/construct-a-binary-tree-from-postorder-and-inorder/ Minimum Cost For Tickets 4 def mincostTickets ( days : List [ int ], costs : List [ int ]) -> int : \"\"\"https://leetcode.com/problems/minimum-cost-for-tickets/discuss/228421/Python-solution Args: days (List[int]): _description_ costs (List[int]): _description_ Returns: int: _description_ \"\"\" # Logic 1: Solving with Dynamic Programming # This logic as inreference to the discuss thread - https://leetcode.com/problems/minimum-cost-for-tickets/discuss/228421/Python-solution # Create dictionary for faster lookup of days import collections days_dict = collections . Counter ( days ) # Create a table of all the day cost # * Instead of creating a 365 days table, we create until the last day on the days list table = [ 0 for i in range ( 0 , days [ - 1 ] + 1 )] for i in range ( 0 , days [ - 1 ] + 1 ): # If the current day is not present in the travel days dictionary, it takes the previous value if i not in days_dict : table [ i ] = table [ i - 1 ] else : # Used max to identify if the index exists table [ i ] = min ( table [ max ( 0 , i - 1 )] + costs [ 0 ], # per days value table [ max ( 0 , i - 7 )] + costs [ 1 ], # per week value table [ max ( 0 , i - 30 )] + costs [ 2 ], # per year value ) return table [ - 1 ] days = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 30 , 31 ] costs = [ 2 , 7 , 15 ] mincostTickets ( days , costs ) 17 LRU Cache 5 Good to know solution using OrderedDict but need to know underlying is using Hashmap + DoubleLinkedList. from collections import OrderedDict class LRUCache ( OrderedDict ): # def __init__ ( self , capacity ): \"\"\" :type capacity: int \"\"\" self . capacity = capacity def get ( self , key ): \"\"\" :type key: int :rtype: int \"\"\" if key not in self : return - 1 self . move_to_end ( key ) return self [ key ] def put ( self , key , value ): \"\"\" :type key: int :type value: int :rtype: void \"\"\" if key in self : self . move_to_end ( key ) self [ key ] = value if len ( self ) > self . capacity : self . popitem ( last = False ) # Your LRUCache object will be instantiated and called as such: # obj = LRUCache(capacity) # param_1 = obj.get(key) # obj.put(key,value) Merge Intervals 6 Discussion says don't bother with first solution using graphs. def merge ( intervals : List [ List [ int ]]) -> List [ List [ int ]]: # https://leetcode.com/problems/merge-intervals/solution/ intervals . sort ( key = lambda x : x [ 0 ]) print ( intervals ) merged = [] for interval in intervals : # if the list of merged intervals is empty or if the current # interval does not overlap with the previous, simply append it. if len ( merged ) == 0 or merged [ - 1 ][ 1 ] < interval [ 0 ]: merged . append ( interval ) else : # otherwise, there is overlap, so we merge the current and previous # intervals. merged [ - 1 ][ 1 ] = max ( merged [ - 1 ][ 1 ], interval [ 1 ]) return merged intervals = [[ 1 , 3 ],[ 8 , 10 ],[ 2 , 6 ],[ 15 , 18 ]] merge ( intervals ) [[1, 3], [2, 6], [8, 10], [15, 18]] [[1, 6], [8, 10], [15, 18]] Merge Sorted Array 7 def merge_naive ( nums1 : List [ int ], m : int , nums2 : List [ int ], n : int ) -> None : \"\"\" https://leetcode.com/problems/merge-sorted-array/solution/ Approach 1: Merge and sort Do not return anything, modify nums1 in-place instead. \"\"\" # Write the elements of num2 into the end of nums1. for i in range ( n ): nums1 [ i + m ] = nums2 [ i ] # Sort nums1 list in-place. nums1 . sort () nums1 = [ 1 , 2 , 3 , 0 , 0 , 0 ] m = 3 nums2 = [ 2 , 5 , 6 ] n = 3 merge_naive ( nums1 , m , nums2 , n ) print ( nums1 ) [1, 2, 2, 3, 5, 6] Number of Islands 8 def numIslands ( grid : List [ List [ str ]]) -> int : # https://leetcode.com/problems/number-of-islands/discuss/56340/Python-Simple-DFS-Solution if not grid : return 0 count = 0 for i in range ( len ( grid )): for j in range ( len ( grid [ 0 ])): if grid [ i ][ j ] == '1' : self . dfs ( grid , i , j ) count += 1 return count def dfs ( self , grid , i , j ): if i < 0 or j < 0 or i >= len ( grid ) or j >= len ( grid [ 0 ]) or grid [ i ][ j ] != '1' : return grid [ i ][ j ] = '#' self . dfs ( grid , i + 1 , j ) self . dfs ( grid , i - 1 , j ) self . dfs ( grid , i , j + 1 ) self . dfs ( grid , i , j - 1 ) Maximum Subarray 9 def maxSubArray_kadane ( nums : List [ int ]) -> int : # Approach 2: Dynamic Programming, Kadane's Algorithm # https://leetcode.com/problems/maximum-subarray/solution/ # THE LOGIC in the gif in leetcode soln is quite intuitive. # Initialize our variables using the first element. current_subarray = max_subarray = nums [ 0 ] # Start with the 2nd element since we already used the first one. for num in nums [ 1 :]: # If current_subarray is negative, throw it away. Otherwise, keep adding to it. current_subarray = max ( num , current_subarray + num ) max_subarray = max ( max_subarray , current_subarray ) return max_subarray nums = [ - 2 , 1 , - 3 , 4 , - 1 , 2 , 1 , - 5 , 4 ] maxSubArray_kadane ( nums ) 6 Top K Frequent Elements 10 class Solution : def topKFrequent ( self , nums , k ): bucket = [[] for _ in range ( len ( nums ) + 1 )] Count = Counter ( nums ) . items () for num , freq in Count : bucket [ freq ] . append ( num ) flat_list = list ( chain ( * bucket )) return flat_list [:: - 1 ][: k ] Merge k Sorted Lists 11 from Queue import PriorityQueue class Solution ( object ): def mergeKLists ( self , lists ): dummy = ListNode ( None ) curr = dummy q = PriorityQueue () for node in lists : if node : q . put (( node . val , node )) while q . qsize () > 0 : curr . next = q . get ()[ 1 ] curr = curr . next if curr . next : q . put (( curr . next . val , curr . next )) return dummy . next Merge Two Sorted Lists [^21. Merge Two Sorted Lists] class Solution : # shud see my own soln def mergeTwoLists ( self , l1 , l2 ): # maintain an unchanging reference to node ahead of the return node. prehead = ListNode ( - 1 ) prev = prehead while l1 and l2 : if l1 . val <= l2 . val : prev . next = l1 l1 = l1 . next else : prev . next = l2 l2 = l2 . next prev = prev . next # At least one of l1 and l2 can still have nodes at this point, so connect # the non-null list to the end of the merged list. prev . next = l1 if l1 is not None else l2 return prehead . next Kth Largest Element in an Array 13 # O(nlgn) time # https://leetcode.com/problems/kth-largest-element-in-an-array/discuss/60306/Python-different-solutions-with-comments-(bubble-sort-selection-sort-heap-sort-and-quick-sort). def findKthLargest1 ( self , nums , k ): return sorted ( nums , reverse = True )[ k - 1 ] Design HashMap 14 class Bucket : def __init__ ( self ): self . bucket = [] def get ( self , key ): for ( k , v ) in self . bucket : if k == key : return v return - 1 def update ( self , key , value ): found = False for i , kv in enumerate ( self . bucket ): if key == kv [ 0 ]: self . bucket [ i ] = ( key , value ) found = True break if not found : self . bucket . append (( key , value )) def remove ( self , key ): for i , kv in enumerate ( self . bucket ): if key == kv [ 0 ]: del self . bucket [ i ] Design HashSet [^706. Design HashSet] class MyHashSet ( object ): def __init__ ( self ): \"\"\" Initialize your data structure here. \"\"\" self . keyRange = 769 self . bucketArray = [ Bucket () for i in range ( self . keyRange )] def _hash ( self , key ): return key % self . keyRange def add ( self , key ): \"\"\" :type key: int :rtype: None \"\"\" bucketIndex = self . _hash ( key ) self . bucketArray [ bucketIndex ] . insert ( key ) def remove ( self , key ): \"\"\" :type key: int :rtype: None \"\"\" bucketIndex = self . _hash ( key ) self . bucketArray [ bucketIndex ] . delete ( key ) def contains ( self , key ): \"\"\" Returns true if this set contains the specified element :type key: int :rtype: bool \"\"\" bucketIndex = self . _hash ( key ) return self . bucketArray [ bucketIndex ] . exists ( key ) class Node : def __init__ ( self , value , nextNode = None ): self . value = value self . next = nextNode class Bucket : def __init__ ( self ): # a pseudo head self . head = Node ( 0 ) def insert ( self , newValue ): # if not existed, add the new element to the head. if not self . exists ( newValue ): newNode = Node ( newValue , self . head . next ) # set the new head. self . head . next = newNode def delete ( self , value ): prev = self . head curr = self . head . next while curr is not None : if curr . value == value : # remove the current node prev . next = curr . next return prev = curr curr = curr . next def exists ( self , value ): curr = self . head . next while curr is not None : if curr . value == value : # value existed already, do nothing return True curr = curr . next return False # Your MyHashSet object will be instantiated and called as such: # obj = MyHashSet() # obj.add(key) # obj.remove(key) # param_3 = obj.contains(key) Design Circular Deque 16 class MyCircularDeque : # https://leetcode.com/problems/design-circular-deque/discuss/154055/python3-using-list-easy-to-understand def __init__ ( self , k ): \"\"\" Initialize your data structure here. Set the size of the deque to be k. :type k: int \"\"\" self . _size = 0 self . _front , self . _rear = 0 , 0 self . _capacity = k self . _data = [ - 1 ] * k def insertFront ( self , value ): \"\"\" Adds an item at the front of Deque. Return true if the operation is successful. :type value: int :rtype: bool \"\"\" if self . isFull (): return False if self . isEmpty (): self . _data [ self . _front ] = value else : self . _front = ( self . _front - 1 ) % self . _capacity self . _data [ self . _front ] = value self . _size += 1 return True def insertLast ( self , value ): \"\"\" Adds an item at the rear of Deque. Return true if the operation is successful. :type value: int :rtype: bool \"\"\" if self . isFull (): return False if self . isEmpty (): self . _data [ self . _rear ] = value else : self . _rear = ( self . _rear + 1 ) % self . _capacity self . _data [ self . _rear ] = value self . _size += 1 return True def deleteFront ( self ): \"\"\" Deletes an item from the front of Deque. Return true if the operation is successful. :rtype: bool \"\"\" if self . isEmpty (): return False self . _data [ self . _front ] = - 1 self . _front = ( self . _front + 1 ) % self . _capacity self . _size -= 1 if self . isEmpty (): self . _rear = self . _front return True def deleteLast ( self ): \"\"\" Deletes an item from the rear of Deque. Return true if the operation is successful. :rtype: bool \"\"\" if self . isEmpty (): return False self . _data [ self . _rear ] = - 1 self . _rear = ( self . _rear - 1 ) % self . _capacity self . _size -= 1 if self . isEmpty (): self . _front = self . _rear return True def getFront ( self ): \"\"\" Get the front item from the deque. :rtype: int \"\"\" return self . _data [ self . _front ] def getRear ( self ): \"\"\" Get the last item from the deque. :rtype: int \"\"\" return self . _data [ self . _rear ] def isEmpty ( self ): \"\"\" Checks whether the circular deque is empty or not. :rtype: bool \"\"\" return self . _size == 0 def isFull ( self ): \"\"\" Checks whether the circular deque is full or not. :rtype: bool \"\"\" return self . _size == self . _capacity Spiral Matrix 17 class Solution : def spiralOrder ( self , matrix : List [ List [ int ]]) -> List [ int ]: result = [] rows , columns = len ( matrix ), len ( matrix [ 0 ]) up = left = 0 right = columns - 1 down = rows - 1 while len ( result ) < rows * columns : # Traverse from left to right. for col in range ( left , right + 1 ): result . append ( matrix [ up ][ col ]) # Traverse downwards. for row in range ( up + 1 , down + 1 ): result . append ( matrix [ row ][ right ]) # Make sure we are now on a different row. if up != down : # Traverse from right to left. for col in range ( right - 1 , left - 1 , - 1 ): result . append ( matrix [ down ][ col ]) # Make sure we are now on a different column. if left != right : # Traverse upwards. for row in range ( down - 1 , up , - 1 ): result . append ( matrix [ row ][ left ]) left += 1 right -= 1 up += 1 down -= 1 return result 19. Remove Nth Node From End of List https://leetcode.com/problems/remove-nth-node-from-end-of-list/ class Solution : def removeNthFromEnd ( self , head , n ): fast = slow = head for _ in range ( n ): fast = fast . next if not fast : return head . next while fast . next : fast = fast . next slow = slow . next slow . next = slow . next . next return head 143. Reorder List https://leetcode.com/problems/reorder-list/ class Solution : # https://leetcode.com/problems/reorder-list/discuss/801883/Python-3-steps-to-success-explained def reorderList ( self , head ): #step 1: find middle if not head : return [] slow , fast = head , head while fast . next and fast . next . next : slow = slow . next fast = fast . next . next #step 2: reverse second half prev , curr = None , slow . next while curr : nextt = curr . next curr . next = prev prev = curr curr = nextt slow . next = None #step 3: merge lists head1 , head2 = head , prev while head2 : nextt = head1 . next head1 . next = head2 head1 = head2 head2 = nextt Greatest Sum Divisible by Three \u21a9 Palindrome Pairs \u21a9 Construct Binary Tree from Inorder and Postorder Traversal \u21a9 Minimum Cost For Tickets \u21a9 LRU Cache \u21a9 Merge Intervals \u21a9 Merge Sorted Array \u21a9 Number of Islands \u21a9 Maximum Subarray \u21a9 Top K Frequent Elements \u21a9 Merge k Sorted Lists \u21a9 Merge Two Sorted Lists \u21a9 Kth Largest Element in an Array \u21a9 Design HashMap \u21a9 Design HashSet \u21a9 Design Circular Deque \u21a9 Spiral Matrix \u21a9","title":"Question Bank"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#primer","text":"Some solutions using pythons in-built function is not recommended to do in front of interviewer.","title":"Primer"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#greatest-sum-divisible-by-three-1","text":"def maxSumDivThree ( nums : List [ int ]) -> int : \"\"\" https://leetcode.com/problems/greatest-sum-divisible-by-three/discuss/431077/JavaC%2B%2BPython-One-Pass-O(1)-space Args: nums (List[int]): The input list of integers. Returns: int: The maximum sum of the integers that can be divided by three. Examples: >>> nums = [3,6,5,1,8] >>> maxSumDivThree(nums) 18 \"\"\" dp = [ 0 , 0 , 0 ] for num in nums : for i in dp [:]: dp [( i + num ) % 3 ] = max ( dp [( i + num ) % 3 ], i + num ) return dp [ 0 ] https://leetcode.com/problems/greatest-sum-divisible-by-three/discuss/431077/JavaC%2B%2BPython-One-Pass-O(1)-space https://leetcode.com/problems/greatest-sum-divisible-by-three/discuss/559999/Come-here-if-you-can't-seem-to-get-it-(Full-Explanation-%2B-uncondensed-code)","title":"Greatest Sum Divisible by Three 1"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#palindrome-pairs-2","text":"def palindromePairs ( words : List [ str ]) -> List [ List [ int ]]: \"\"\"https://leetcode.com/problems/palindrome-pairs/discuss/79219/Python-solution~ Args: words (List[str]): _description_ Returns: List[List[int]]: _description_ \"\"\" d = {} for i , w in enumerate ( words ): d [ w [:: - 1 ]] = i indices = set () for i , w in enumerate ( words ): for j in range ( len ( w ) + 1 ): prefix = w [: j ] postfix = w [ j :] if prefix in d and i != d [ prefix ] and postfix == postfix [:: - 1 ]: indices . add (( i , d [ prefix ])) if postfix in d and i != d [ postfix ] and prefix == prefix [:: - 1 ]: indices . add (( d [ postfix ], i )) return [ list ( p ) for p in indices ]","title":"Palindrome Pairs 2"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#construct-binary-tree-from-inorder-and-postorder-traversal-3","text":"# Definition for a binary tree node. class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right def buildTree ( inorder : List [ int ], postorder : List [ int ]) -> TreeNode : \"\"\"https://leetcode.com/problems/construct-binary-tree-from-inorder-and-postorder-traversal/discuss/221681/A-better-Python-solution See henrygas solution. Args: inorder (List[int]): _description_ postorder (List[int]): _description_ Returns: TreeNode: _description_ \"\"\" value_to_idx = dict () for idx , value in enumerate ( inorder ): value_to_idx [ value ] = idx def build ( inorder , postorder , in_start , in_end , post_start , post_end ): if in_start <= in_end : root = TreeNode ( postorder [ post_end ]) in_idx = value_to_idx [ root . val ] in_idx_delta = in_idx - in_start root . left = build ( inorder , postorder , in_start , in_idx - 1 , post_start , post_start + in_idx_delta - 1 ) root . right = build ( inorder , postorder , in_idx + 1 , in_end , post_start + in_idx_delta , post_end - 1 ) return root else : return None return build ( inorder , postorder , 0 , len ( inorder ) - 1 , 0 , len ( postorder ) - 1 ) inorder = [ 4 , 8 , 2 , 5 , 1 , 6 , 3 , 7 ] postorder = [ 8 , 4 , 5 , 2 , 6 , 7 , 3 , 1 ] tree = buildTree ( inorder , postorder ) tree . val tree . left . val tree . left . right . val 1 https://www.geeksforgeeks.org/construct-a-binary-tree-from-postorder-and-inorder/","title":"Construct Binary Tree from Inorder and Postorder Traversal 3"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#minimum-cost-for-tickets-4","text":"def mincostTickets ( days : List [ int ], costs : List [ int ]) -> int : \"\"\"https://leetcode.com/problems/minimum-cost-for-tickets/discuss/228421/Python-solution Args: days (List[int]): _description_ costs (List[int]): _description_ Returns: int: _description_ \"\"\" # Logic 1: Solving with Dynamic Programming # This logic as inreference to the discuss thread - https://leetcode.com/problems/minimum-cost-for-tickets/discuss/228421/Python-solution # Create dictionary for faster lookup of days import collections days_dict = collections . Counter ( days ) # Create a table of all the day cost # * Instead of creating a 365 days table, we create until the last day on the days list table = [ 0 for i in range ( 0 , days [ - 1 ] + 1 )] for i in range ( 0 , days [ - 1 ] + 1 ): # If the current day is not present in the travel days dictionary, it takes the previous value if i not in days_dict : table [ i ] = table [ i - 1 ] else : # Used max to identify if the index exists table [ i ] = min ( table [ max ( 0 , i - 1 )] + costs [ 0 ], # per days value table [ max ( 0 , i - 7 )] + costs [ 1 ], # per week value table [ max ( 0 , i - 30 )] + costs [ 2 ], # per year value ) return table [ - 1 ] days = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 30 , 31 ] costs = [ 2 , 7 , 15 ] mincostTickets ( days , costs ) 17","title":"Minimum Cost For Tickets 4"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#lru-cache-5","text":"Good to know solution using OrderedDict but need to know underlying is using Hashmap + DoubleLinkedList. from collections import OrderedDict class LRUCache ( OrderedDict ): # def __init__ ( self , capacity ): \"\"\" :type capacity: int \"\"\" self . capacity = capacity def get ( self , key ): \"\"\" :type key: int :rtype: int \"\"\" if key not in self : return - 1 self . move_to_end ( key ) return self [ key ] def put ( self , key , value ): \"\"\" :type key: int :type value: int :rtype: void \"\"\" if key in self : self . move_to_end ( key ) self [ key ] = value if len ( self ) > self . capacity : self . popitem ( last = False ) # Your LRUCache object will be instantiated and called as such: # obj = LRUCache(capacity) # param_1 = obj.get(key) # obj.put(key,value)","title":"LRU Cache 5"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#merge-intervals-6","text":"Discussion says don't bother with first solution using graphs. def merge ( intervals : List [ List [ int ]]) -> List [ List [ int ]]: # https://leetcode.com/problems/merge-intervals/solution/ intervals . sort ( key = lambda x : x [ 0 ]) print ( intervals ) merged = [] for interval in intervals : # if the list of merged intervals is empty or if the current # interval does not overlap with the previous, simply append it. if len ( merged ) == 0 or merged [ - 1 ][ 1 ] < interval [ 0 ]: merged . append ( interval ) else : # otherwise, there is overlap, so we merge the current and previous # intervals. merged [ - 1 ][ 1 ] = max ( merged [ - 1 ][ 1 ], interval [ 1 ]) return merged intervals = [[ 1 , 3 ],[ 8 , 10 ],[ 2 , 6 ],[ 15 , 18 ]] merge ( intervals ) [[1, 3], [2, 6], [8, 10], [15, 18]] [[1, 6], [8, 10], [15, 18]]","title":"Merge Intervals 6"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#merge-sorted-array-7","text":"def merge_naive ( nums1 : List [ int ], m : int , nums2 : List [ int ], n : int ) -> None : \"\"\" https://leetcode.com/problems/merge-sorted-array/solution/ Approach 1: Merge and sort Do not return anything, modify nums1 in-place instead. \"\"\" # Write the elements of num2 into the end of nums1. for i in range ( n ): nums1 [ i + m ] = nums2 [ i ] # Sort nums1 list in-place. nums1 . sort () nums1 = [ 1 , 2 , 3 , 0 , 0 , 0 ] m = 3 nums2 = [ 2 , 5 , 6 ] n = 3 merge_naive ( nums1 , m , nums2 , n ) print ( nums1 ) [1, 2, 2, 3, 5, 6]","title":"Merge Sorted Array 7"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#number-of-islands-8","text":"def numIslands ( grid : List [ List [ str ]]) -> int : # https://leetcode.com/problems/number-of-islands/discuss/56340/Python-Simple-DFS-Solution if not grid : return 0 count = 0 for i in range ( len ( grid )): for j in range ( len ( grid [ 0 ])): if grid [ i ][ j ] == '1' : self . dfs ( grid , i , j ) count += 1 return count def dfs ( self , grid , i , j ): if i < 0 or j < 0 or i >= len ( grid ) or j >= len ( grid [ 0 ]) or grid [ i ][ j ] != '1' : return grid [ i ][ j ] = '#' self . dfs ( grid , i + 1 , j ) self . dfs ( grid , i - 1 , j ) self . dfs ( grid , i , j + 1 ) self . dfs ( grid , i , j - 1 )","title":"Number of Islands 8"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#maximum-subarray-9","text":"def maxSubArray_kadane ( nums : List [ int ]) -> int : # Approach 2: Dynamic Programming, Kadane's Algorithm # https://leetcode.com/problems/maximum-subarray/solution/ # THE LOGIC in the gif in leetcode soln is quite intuitive. # Initialize our variables using the first element. current_subarray = max_subarray = nums [ 0 ] # Start with the 2nd element since we already used the first one. for num in nums [ 1 :]: # If current_subarray is negative, throw it away. Otherwise, keep adding to it. current_subarray = max ( num , current_subarray + num ) max_subarray = max ( max_subarray , current_subarray ) return max_subarray nums = [ - 2 , 1 , - 3 , 4 , - 1 , 2 , 1 , - 5 , 4 ] maxSubArray_kadane ( nums ) 6","title":"Maximum Subarray 9"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#top-k-frequent-elements-10","text":"class Solution : def topKFrequent ( self , nums , k ): bucket = [[] for _ in range ( len ( nums ) + 1 )] Count = Counter ( nums ) . items () for num , freq in Count : bucket [ freq ] . append ( num ) flat_list = list ( chain ( * bucket )) return flat_list [:: - 1 ][: k ]","title":"Top K Frequent Elements 10"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#merge-k-sorted-lists-11","text":"from Queue import PriorityQueue class Solution ( object ): def mergeKLists ( self , lists ): dummy = ListNode ( None ) curr = dummy q = PriorityQueue () for node in lists : if node : q . put (( node . val , node )) while q . qsize () > 0 : curr . next = q . get ()[ 1 ] curr = curr . next if curr . next : q . put (( curr . next . val , curr . next )) return dummy . next","title":"Merge k Sorted Lists 11"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#merge-two-sorted-lists-21-merge-two-sorted-lists","text":"class Solution : # shud see my own soln def mergeTwoLists ( self , l1 , l2 ): # maintain an unchanging reference to node ahead of the return node. prehead = ListNode ( - 1 ) prev = prehead while l1 and l2 : if l1 . val <= l2 . val : prev . next = l1 l1 = l1 . next else : prev . next = l2 l2 = l2 . next prev = prev . next # At least one of l1 and l2 can still have nodes at this point, so connect # the non-null list to the end of the merged list. prev . next = l1 if l1 is not None else l2 return prehead . next","title":"Merge Two Sorted Lists [^21. Merge Two Sorted Lists]"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#kth-largest-element-in-an-array-13","text":"# O(nlgn) time # https://leetcode.com/problems/kth-largest-element-in-an-array/discuss/60306/Python-different-solutions-with-comments-(bubble-sort-selection-sort-heap-sort-and-quick-sort). def findKthLargest1 ( self , nums , k ): return sorted ( nums , reverse = True )[ k - 1 ]","title":"Kth Largest Element in an Array 13"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#design-hashmap-14","text":"class Bucket : def __init__ ( self ): self . bucket = [] def get ( self , key ): for ( k , v ) in self . bucket : if k == key : return v return - 1 def update ( self , key , value ): found = False for i , kv in enumerate ( self . bucket ): if key == kv [ 0 ]: self . bucket [ i ] = ( key , value ) found = True break if not found : self . bucket . append (( key , value )) def remove ( self , key ): for i , kv in enumerate ( self . bucket ): if key == kv [ 0 ]: del self . bucket [ i ]","title":"Design HashMap 14"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#design-hashset-706-design-hashset","text":"class MyHashSet ( object ): def __init__ ( self ): \"\"\" Initialize your data structure here. \"\"\" self . keyRange = 769 self . bucketArray = [ Bucket () for i in range ( self . keyRange )] def _hash ( self , key ): return key % self . keyRange def add ( self , key ): \"\"\" :type key: int :rtype: None \"\"\" bucketIndex = self . _hash ( key ) self . bucketArray [ bucketIndex ] . insert ( key ) def remove ( self , key ): \"\"\" :type key: int :rtype: None \"\"\" bucketIndex = self . _hash ( key ) self . bucketArray [ bucketIndex ] . delete ( key ) def contains ( self , key ): \"\"\" Returns true if this set contains the specified element :type key: int :rtype: bool \"\"\" bucketIndex = self . _hash ( key ) return self . bucketArray [ bucketIndex ] . exists ( key ) class Node : def __init__ ( self , value , nextNode = None ): self . value = value self . next = nextNode class Bucket : def __init__ ( self ): # a pseudo head self . head = Node ( 0 ) def insert ( self , newValue ): # if not existed, add the new element to the head. if not self . exists ( newValue ): newNode = Node ( newValue , self . head . next ) # set the new head. self . head . next = newNode def delete ( self , value ): prev = self . head curr = self . head . next while curr is not None : if curr . value == value : # remove the current node prev . next = curr . next return prev = curr curr = curr . next def exists ( self , value ): curr = self . head . next while curr is not None : if curr . value == value : # value existed already, do nothing return True curr = curr . next return False # Your MyHashSet object will be instantiated and called as such: # obj = MyHashSet() # obj.add(key) # obj.remove(key) # param_3 = obj.contains(key)","title":"Design HashSet [^706. Design HashSet]"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#design-circular-deque-16","text":"class MyCircularDeque : # https://leetcode.com/problems/design-circular-deque/discuss/154055/python3-using-list-easy-to-understand def __init__ ( self , k ): \"\"\" Initialize your data structure here. Set the size of the deque to be k. :type k: int \"\"\" self . _size = 0 self . _front , self . _rear = 0 , 0 self . _capacity = k self . _data = [ - 1 ] * k def insertFront ( self , value ): \"\"\" Adds an item at the front of Deque. Return true if the operation is successful. :type value: int :rtype: bool \"\"\" if self . isFull (): return False if self . isEmpty (): self . _data [ self . _front ] = value else : self . _front = ( self . _front - 1 ) % self . _capacity self . _data [ self . _front ] = value self . _size += 1 return True def insertLast ( self , value ): \"\"\" Adds an item at the rear of Deque. Return true if the operation is successful. :type value: int :rtype: bool \"\"\" if self . isFull (): return False if self . isEmpty (): self . _data [ self . _rear ] = value else : self . _rear = ( self . _rear + 1 ) % self . _capacity self . _data [ self . _rear ] = value self . _size += 1 return True def deleteFront ( self ): \"\"\" Deletes an item from the front of Deque. Return true if the operation is successful. :rtype: bool \"\"\" if self . isEmpty (): return False self . _data [ self . _front ] = - 1 self . _front = ( self . _front + 1 ) % self . _capacity self . _size -= 1 if self . isEmpty (): self . _rear = self . _front return True def deleteLast ( self ): \"\"\" Deletes an item from the rear of Deque. Return true if the operation is successful. :rtype: bool \"\"\" if self . isEmpty (): return False self . _data [ self . _rear ] = - 1 self . _rear = ( self . _rear - 1 ) % self . _capacity self . _size -= 1 if self . isEmpty (): self . _front = self . _rear return True def getFront ( self ): \"\"\" Get the front item from the deque. :rtype: int \"\"\" return self . _data [ self . _front ] def getRear ( self ): \"\"\" Get the last item from the deque. :rtype: int \"\"\" return self . _data [ self . _rear ] def isEmpty ( self ): \"\"\" Checks whether the circular deque is empty or not. :rtype: bool \"\"\" return self . _size == 0 def isFull ( self ): \"\"\" Checks whether the circular deque is full or not. :rtype: bool \"\"\" return self . _size == self . _capacity","title":"Design Circular Deque 16"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#spiral-matrix-17","text":"class Solution : def spiralOrder ( self , matrix : List [ List [ int ]]) -> List [ int ]: result = [] rows , columns = len ( matrix ), len ( matrix [ 0 ]) up = left = 0 right = columns - 1 down = rows - 1 while len ( result ) < rows * columns : # Traverse from left to right. for col in range ( left , right + 1 ): result . append ( matrix [ up ][ col ]) # Traverse downwards. for row in range ( up + 1 , down + 1 ): result . append ( matrix [ row ][ right ]) # Make sure we are now on a different row. if up != down : # Traverse from right to left. for col in range ( right - 1 , left - 1 , - 1 ): result . append ( matrix [ down ][ col ]) # Make sure we are now on a different column. if left != right : # Traverse upwards. for row in range ( down - 1 , up , - 1 ): result . append ( matrix [ row ][ left ]) left += 1 right -= 1 up += 1 down -= 1 return result","title":"Spiral Matrix 17"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#19-remove-nth-node-from-end-of-list","text":"https://leetcode.com/problems/remove-nth-node-from-end-of-list/ class Solution : def removeNthFromEnd ( self , head , n ): fast = slow = head for _ in range ( n ): fast = fast . next if not fast : return head . next while fast . next : fast = fast . next slow = slow . next slow . next = slow . next . next return head","title":"19. Remove Nth Node From End of List"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Question%20Bank/#143-reorder-list","text":"https://leetcode.com/problems/reorder-list/ class Solution : # https://leetcode.com/problems/reorder-list/discuss/801883/Python-3-steps-to-success-explained def reorderList ( self , head ): #step 1: find middle if not head : return [] slow , fast = head , head while fast . next and fast . next . next : slow = slow . next fast = fast . next . next #step 2: reverse second half prev , curr = None , slow . next while curr : nextt = curr . next curr . next = prev prev = curr curr = nextt slow . next = None #step 3: merge lists head1 , head2 = head , prev while head2 : nextt = head1 . next head1 . next = head2 head1 = head2 head2 = nextt Greatest Sum Divisible by Three \u21a9 Palindrome Pairs \u21a9 Construct Binary Tree from Inorder and Postorder Traversal \u21a9 Minimum Cost For Tickets \u21a9 LRU Cache \u21a9 Merge Intervals \u21a9 Merge Sorted Array \u21a9 Number of Islands \u21a9 Maximum Subarray \u21a9 Top K Frequent Elements \u21a9 Merge k Sorted Lists \u21a9 Merge Two Sorted Lists \u21a9 Kth Largest Element in an Array \u21a9 Design HashMap \u21a9 Design HashSet \u21a9 Design Circular Deque \u21a9 Spiral Matrix \u21a9","title":"143. Reorder List"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Reverse%20Linked%20List/","text":"\\[ \\newcommand{\\O}{\\mathcal{O}} \\] Reverse Linked List # # from leetcode # class LinkedList: # \"\"\"Function to initialize the Linked List object.\"\"\" # head: Node = None # def __init__(self): # self.head = None # def traverse(self) -> None: # \"\"\"Traverse through a linked list by printing all the nodes.\"\"\" # temp = self.head # while temp is not None: # print(temp.value) # temp = temp.next # def reverseList(self, head): # \"\"\" # :type head: ListNode # :rtype: ListNode # \"\"\" # prev_node = None # curr_node = head # while curr_node: # next_node = curr_node.next # Remember next node # curr_node.next = prev_node # REVERSE! None, first time round. # prev_node = curr_node # Used in the next iteration. # curr_node = next_node # Move to next node. # head = prev_node # return head from typing import * class Node : \"\"\" The Node object is initialized with a value and can be linked to the next node by setting the next_node attribute to a Node object. This node is Singular associated with Singly Linked List. Attributes: curr_node_value (Any): The value associated with the created node. next_node (Node): The next node in the linked list. Note the distinction between curr_node_value and next_node, the former is the value of the node, the latter is the pointer to the next node. Examples: >>> node = Node(1) >>> print(node.curr_node_value) 1 >>> print(node.next_node) None >>> node.next_node = Node(2) >>> print(node.next_node.curr_node_value) 2 >>> print(node.next_node.next_node) None \"\"\" curr_node_value : Any next_node : Optional [ \"Node\" ] def __init__ ( self , curr_node_value : Any = None ) -> None : self . curr_node_value = curr_node_value self . next_node = None class LinkedList : \"\"\" The LinkedList object is initialized with a head node. The `head` node (the first node) of a **Linked List** is of a `Node` object. The `head` **entirely determines** the entirety of the whole **Linked List**. Because knowing the head node of the **Linked List**, we will be able to know every single node that comes after it sequentially (if exists). Attributes: head (Node): The head node of the linked list. \"\"\" head : Node = None def __init__ ( self ) -> None : self . head = None @staticmethod def traverse ( head_node : Node ) -> None : \"\"\"Traverse the linked list and print the values of each node. Args: head_node (Node): The head node of a linked list. Examples: >>> first = Node(1) >>> second = Node(2) >>> third = Node(3) >>> ll = LinkedList() >>> ll.head = first >>> ll.head.next_node = second >>> ll.head.next_node.next_node = third >>> ll.traverse(ll.head) \"\"\" temp_node = head_node while temp_node is not None : print ( temp_node . curr_node_value ) temp_node = temp_node . next_node if temp_node is None : print ( \"None\" ) @classmethod def reverse ( cls , head_node : Node ) -> None : \"\"\"Reverse the linked list. Args: head_node (Node): The head node of a linked list. Examples: >>> first = Node(1) >>> second = Node(2) >>> third = Node(3) >>> ll = LinkedList() >>> ll.head = first >>> ll.head.next_node = second >>> ll.head.next_node.next_node = third >>> ll.traverse(ll.head) >>> _ = ll.reverse(ll.head) \"\"\" # at this stage we must have a mental model # 1 -> 2 -> 3 -> None is the original linked list # 3 -> 2 -> 1 -> None is the reversed linked list # we can do so by: # 1. Start off with current node as the head node which is 1. # 2. Set the next node of current node as None (note we set our prev_node as None). At this stage we are envisioning (1 -> None) and we should have prev_node as (1 -> None) now, it may not be obvious now but it will be clear later. # 3. Now if we can have a node that holds the value of 2 (which is the next node of 1), we can set this node's next node as the prev_node (which is 1 -> None). Now we have (2 -> 1 -> None) and we should have prev_node as (2 -> 1 -> None) now. # 4. By now, the rough algorithm is clear, as we go through the original linked list sequentially, we can get the current node and set its next node as the prev_node where prev_node is the nodes pointing backwards. prev_node = None curr_node = head_node while curr_node is not None : temp_node = curr_node curr_node = curr_node . next_node temp_node . next_node = prev_node prev_node = temp_node reversed_head_node = prev_node print ( \"Traverse reversed head node:\" ) cls . traverse ( reversed_head_node ) return reversed_head_node Note the pointer references can be confusing, permuting curr_node = curr_node . next_node temp_node . next_node = prev_node will cause errors! Do you know why? >>> first = Node ( 1 ) >>> second = Node ( 2 ) >>> third = Node ( 3 ) >>> ll = LinkedList () >>> ll . head = first >>> ll . head . next_node = second >>> ll . head . next_node . next_node = third >>> ll . traverse ( ll . head ) >>> _ = ll . reverse ( ll . head ) 1 2 3 None Traverse reversed head node: 3 2 1 None Time Complexity Time complexity: \\(\\O(n)\\) . We traverse the list containing \\(n\\) elements only once. Each lookup in the table costs only \\(\\O(1)\\) time. Loosely speaking, this means in each for loop from line 22 to 26, each line takes \\(\\O(1)\\) time, so in a typical single iteration, we use around \\(\\O(3)\\) time, and looping it \\(n\\) times takes \\[ n \\cdot \\O(3) \\approx \\O(3n) \\approx \\O(n) \\] Space Complexity Space complexity: \\(\\O(n)\\) . The extra space required depends on the number of items stored in the dictionary seen , which stores at most \\(n\\) elements. References https://www.youtube.com/watch?v=XDO6I8jxHtA","title":"Reverse Linked List"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Reverse%20Linked%20List/#reverse-linked-list","text":"# # from leetcode # class LinkedList: # \"\"\"Function to initialize the Linked List object.\"\"\" # head: Node = None # def __init__(self): # self.head = None # def traverse(self) -> None: # \"\"\"Traverse through a linked list by printing all the nodes.\"\"\" # temp = self.head # while temp is not None: # print(temp.value) # temp = temp.next # def reverseList(self, head): # \"\"\" # :type head: ListNode # :rtype: ListNode # \"\"\" # prev_node = None # curr_node = head # while curr_node: # next_node = curr_node.next # Remember next node # curr_node.next = prev_node # REVERSE! None, first time round. # prev_node = curr_node # Used in the next iteration. # curr_node = next_node # Move to next node. # head = prev_node # return head from typing import * class Node : \"\"\" The Node object is initialized with a value and can be linked to the next node by setting the next_node attribute to a Node object. This node is Singular associated with Singly Linked List. Attributes: curr_node_value (Any): The value associated with the created node. next_node (Node): The next node in the linked list. Note the distinction between curr_node_value and next_node, the former is the value of the node, the latter is the pointer to the next node. Examples: >>> node = Node(1) >>> print(node.curr_node_value) 1 >>> print(node.next_node) None >>> node.next_node = Node(2) >>> print(node.next_node.curr_node_value) 2 >>> print(node.next_node.next_node) None \"\"\" curr_node_value : Any next_node : Optional [ \"Node\" ] def __init__ ( self , curr_node_value : Any = None ) -> None : self . curr_node_value = curr_node_value self . next_node = None class LinkedList : \"\"\" The LinkedList object is initialized with a head node. The `head` node (the first node) of a **Linked List** is of a `Node` object. The `head` **entirely determines** the entirety of the whole **Linked List**. Because knowing the head node of the **Linked List**, we will be able to know every single node that comes after it sequentially (if exists). Attributes: head (Node): The head node of the linked list. \"\"\" head : Node = None def __init__ ( self ) -> None : self . head = None @staticmethod def traverse ( head_node : Node ) -> None : \"\"\"Traverse the linked list and print the values of each node. Args: head_node (Node): The head node of a linked list. Examples: >>> first = Node(1) >>> second = Node(2) >>> third = Node(3) >>> ll = LinkedList() >>> ll.head = first >>> ll.head.next_node = second >>> ll.head.next_node.next_node = third >>> ll.traverse(ll.head) \"\"\" temp_node = head_node while temp_node is not None : print ( temp_node . curr_node_value ) temp_node = temp_node . next_node if temp_node is None : print ( \"None\" ) @classmethod def reverse ( cls , head_node : Node ) -> None : \"\"\"Reverse the linked list. Args: head_node (Node): The head node of a linked list. Examples: >>> first = Node(1) >>> second = Node(2) >>> third = Node(3) >>> ll = LinkedList() >>> ll.head = first >>> ll.head.next_node = second >>> ll.head.next_node.next_node = third >>> ll.traverse(ll.head) >>> _ = ll.reverse(ll.head) \"\"\" # at this stage we must have a mental model # 1 -> 2 -> 3 -> None is the original linked list # 3 -> 2 -> 1 -> None is the reversed linked list # we can do so by: # 1. Start off with current node as the head node which is 1. # 2. Set the next node of current node as None (note we set our prev_node as None). At this stage we are envisioning (1 -> None) and we should have prev_node as (1 -> None) now, it may not be obvious now but it will be clear later. # 3. Now if we can have a node that holds the value of 2 (which is the next node of 1), we can set this node's next node as the prev_node (which is 1 -> None). Now we have (2 -> 1 -> None) and we should have prev_node as (2 -> 1 -> None) now. # 4. By now, the rough algorithm is clear, as we go through the original linked list sequentially, we can get the current node and set its next node as the prev_node where prev_node is the nodes pointing backwards. prev_node = None curr_node = head_node while curr_node is not None : temp_node = curr_node curr_node = curr_node . next_node temp_node . next_node = prev_node prev_node = temp_node reversed_head_node = prev_node print ( \"Traverse reversed head node:\" ) cls . traverse ( reversed_head_node ) return reversed_head_node Note the pointer references can be confusing, permuting curr_node = curr_node . next_node temp_node . next_node = prev_node will cause errors! Do you know why? >>> first = Node ( 1 ) >>> second = Node ( 2 ) >>> third = Node ( 3 ) >>> ll = LinkedList () >>> ll . head = first >>> ll . head . next_node = second >>> ll . head . next_node . next_node = third >>> ll . traverse ( ll . head ) >>> _ = ll . reverse ( ll . head ) 1 2 3 None Traverse reversed head node: 3 2 1 None","title":"Reverse Linked List"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Reverse%20Linked%20List/#time-complexity","text":"Time complexity: \\(\\O(n)\\) . We traverse the list containing \\(n\\) elements only once. Each lookup in the table costs only \\(\\O(1)\\) time. Loosely speaking, this means in each for loop from line 22 to 26, each line takes \\(\\O(1)\\) time, so in a typical single iteration, we use around \\(\\O(3)\\) time, and looping it \\(n\\) times takes \\[ n \\cdot \\O(3) \\approx \\O(3n) \\approx \\O(n) \\]","title":"Time Complexity"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Reverse%20Linked%20List/#space-complexity","text":"Space complexity: \\(\\O(n)\\) . The extra space required depends on the number of items stored in the dictionary seen , which stores at most \\(n\\) elements.","title":"Space Complexity"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Reverse%20Linked%20List/#references","text":"https://www.youtube.com/watch?v=XDO6I8jxHtA","title":"References"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Two%20Sum/","text":"\\[ \\newcommand{\\O}{\\mathcal{O}} \\] Two Sum Insert Problem Statement. Assumptions Each given input will have exactly one solution Same element cannot be used twice Order of indices does not matter Test Cases Intuition Code Walkthrough Consider writing pseudo code. from typing import * def twoSum ( nums : List [ int ], target : int ) -> List [ int ]: \"\"\"https://leetcode.com/problems/two-sum/ Args: nums (List[int]): The list of numbers. target (int): The target number. Returns: List[int, int]: The indices of the two numbers that sum to the target. Examples: >>> nums = [15, 2, 3, 7] >>> target = 9 >>> twoSum(nums, target) [1, 3] \"\"\" seen : Dict = {} for index , num in enumerate ( nums ): complement = target - num if complement not in seen : seen [ num ] = index else : return [ seen [ complement ], index ] >>> nums = [ 15 , 2 , 3 , 7 ] >>> target = 9 >>> twoSum ( nums , target ) [1, 3] Time Complexity Time complexity: \\(\\O(n)\\) . We traverse the list containing \\(n\\) elements only once. Each lookup in the table costs only \\(\\O(1)\\) time. Loosely speaking, this means in each for loop from line 22 to 26, each line takes \\(\\O(1)\\) time, so in a typical single iteration, we use around \\(\\O(3)\\) time, and looping it \\(n\\) times takes \\[ n \\cdot \\O(3) \\approx \\O(3n) \\approx \\O(n) \\] Space Complexity Space complexity: \\(\\O(n)\\) . The extra space required depends on the number of items stored in the dictionary seen , which stores at most \\(n\\) elements.","title":"Two Sum"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Two%20Sum/#two-sum","text":"Insert Problem Statement.","title":"Two Sum"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Two%20Sum/#assumptions","text":"Each given input will have exactly one solution Same element cannot be used twice Order of indices does not matter","title":"Assumptions"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Two%20Sum/#test-cases","text":"","title":"Test Cases"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Two%20Sum/#intuition","text":"","title":"Intuition"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Two%20Sum/#code-walkthrough","text":"Consider writing pseudo code. from typing import * def twoSum ( nums : List [ int ], target : int ) -> List [ int ]: \"\"\"https://leetcode.com/problems/two-sum/ Args: nums (List[int]): The list of numbers. target (int): The target number. Returns: List[int, int]: The indices of the two numbers that sum to the target. Examples: >>> nums = [15, 2, 3, 7] >>> target = 9 >>> twoSum(nums, target) [1, 3] \"\"\" seen : Dict = {} for index , num in enumerate ( nums ): complement = target - num if complement not in seen : seen [ num ] = index else : return [ seen [ complement ], index ] >>> nums = [ 15 , 2 , 3 , 7 ] >>> target = 9 >>> twoSum ( nums , target ) [1, 3]","title":"Code Walkthrough"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Two%20Sum/#time-complexity","text":"Time complexity: \\(\\O(n)\\) . We traverse the list containing \\(n\\) elements only once. Each lookup in the table costs only \\(\\O(1)\\) time. Loosely speaking, this means in each for loop from line 22 to 26, each line takes \\(\\O(1)\\) time, so in a typical single iteration, we use around \\(\\O(3)\\) time, and looping it \\(n\\) times takes \\[ n \\cdot \\O(3) \\approx \\O(3n) \\approx \\O(n) \\]","title":"Time Complexity"},{"location":"reighns_ml_journey/data_structures_and_algorithms/Two%20Sum/#space-complexity","text":"Space complexity: \\(\\O(n)\\) . The extra space required depends on the number of items stored in the dictionary seen , which stores at most \\(n\\) elements.","title":"Space Complexity"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/PyTorch%20Utilities/","text":"Imports, Config and Seeding import timm import torch import torchvision from typing import Dict , Union , Callable , OrderedDict , Tuple import os , random import numpy as np import torch.nn as nn def seed_all ( seed : int = 1992 ) -> None : \"\"\"Seed all random number generators.\"\"\" print ( f \"Using Seed Number { seed } \" ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator # set fixed value for python built-in pseudo-random generator random . seed ( seed ) torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = True torch . backends . cudnn . enabled = True def seed_worker ( _worker_id ) -> None : \"\"\"Seed a worker with the given ID.\"\"\" worker_seed = torch . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) seed_all ( seed = 1992 ) Using Seed Number 1992 DEVICE = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) Convolutional Neural Networks Terminologies Kernel Filter Receptive Field X = torch . tensor ([[ 0.0 , 1.0 , 2.0 ], [ 3.0 , 4.0 , 5.0 ], [ 6.0 , 7.0 , 8.0 ]]) K = torch . tensor ([[ 0.0 , 1.0 ], [ 2.0 , 3.0 ]]) def my_conv2d ( x : torch . Tensor , kernel : torch . Tensor ) -> torch . Tensor : kernel_height , kernel_width = kernel . shape input_height , input_width = x . shape feature_map_height , feature_map_width = ( input_height - kernel_height + 1 , input_width - kernel_width + 1 , ) feature_map = torch . zeros ( size = ( feature_map_height , feature_map_width )) for height_index in range ( feature_map_height ): for width_index in range ( feature_map_width ): # 1st iter: height_index = 0, width_index = 0 # 2nd iter: height_index = 0, width_index = 1 receptive_field = x [ height_index : height_index + kernel_height , width_index : width_index + kernel_width , ] feature_map [ height_index , width_index ] = ( receptive_field * kernel ) . sum () return feature_map my_conv2d ( X , K ) tensor([[19., 25.], [37., 43.]]) class MyConv2D ( nn . Module ): def __init__ ( self , kernel_size : Tuple [ int , int ]): super () . __init__ () self . kernel = nn . Parameter ( torch . rand ( size = ( kernel_size [ 0 ], kernel_size [ 1 ])) ) self . bias = nn . Parameter ( torch . zeros ( 1 )) def forward ( self , x ): return my_conv2d ( x , self . kernel ) + self . bias conv2d = MyConv2D (( 2 , 2 )) conv2d ( X ) tensor([[ 7.3671, 10.2563], [16.0346, 18.9238]], grad_fn=<AddBackward0>) CNN Conv2d Layer Output Dimensions Calculation Given: n: Input image's height/width f: Filter/Kernel Size p: Padding Size s: Stride Given an image of size \\(n \\times n\\) and a kernel of \\(f \\times f\\) , our output shape is \\[ o = n - f + 1 \\] and if we pad the image with 1 extra layer outside, that means our input image is of size \\((n + 2*1) \\times (n + 2*1)\\) , if you see an image you will be clear why adding one layer around means input width and height add 2 times the padding \\(p\\) . hence our new output shape is: \\[ o = (n+2) - f + 1 \\] and a generic formula for padding equals \\(p\\) will yield \\[ o = (n + 2p) - f + 1 \\] Note that: If \\(p=0\\) , then this is valid padding where the output shape is \\(n - f + 1\\) ; If \\(p=\\frac{f-1}{2}\\) , then this is same padding where the output shape is equals to the original input shape \\(n\\) . Same padding can be deduced by setting \\[ (n+2p) - f + 1 = n \\implies p = \\frac{f-1}{2} \\] where by construction \\(f\\) must be odd in order to get a whole number for the padding \\(p\\) , and that's why most kernels/filters are of odd shape. With stride into action our final shape is: \\[ o = \\dfrac{n - f + 2p}{s} + 1 \\] where sometimes \\(o\\) is applied by \\(\\text{floor}(o)\\) if the \\(o\\) is non-integer. CNN Pooling Layer Output Dimensions Calculation For general pooling operations: Given: n: Input image's height/width f: Filter/Kernel Size s: Stride Given an image of size \\(n \\times n\\) and a kernel of \\(f \\times f\\) , our output shape after pooling is: \\[ o = \\text{floor}\\left(\\dfrac{n - f}{s} + 1\\right) \\] with floor applied to \\(o\\) . LeNet import torch from torch import nn lenet = nn . Sequential ( nn . Conv2d ( in_channels = 1 , out_channels = 6 , kernel_size = 5 , padding = 2 , stride = 1 ), nn . Sigmoid (), nn . AvgPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 6 , out_channels = 16 , kernel_size = 5 , padding = 0 , stride = 1 ), nn . Sigmoid (), nn . AvgPool2d ( kernel_size = 2 , stride = 2 ), nn . Flatten (), nn . Linear ( 16 * 5 * 5 , 120 ), nn . Sigmoid (), nn . Linear ( 120 , 84 ), nn . Sigmoid (), nn . Linear ( 84 , 10 ), ) X: (1, 1, 28, 28) 1st conv2d layer: a conv2d layer that applies a filter containing 6 kernels, where each kernel is of size \\(5 \\times 5\\) with a padding of 2 and stride of 1 n = 28 f = 5 p = 2 ; Note in particular the padding of 2 is derived from the formula \\(p = (f-1)/2 = 4/2=2\\) to get same padding! s = 1 shape: \\(o = \\frac{28-5+4}{1} + 1 = 28\\) The final output shape is (1, 6, 28, 28) where 1 is the batch size 6 is the number of kernels applied, for each kernel our output shape is 28 by 28 28, 28 is the output shape by the kernels 1st avgpool2d layer: n = 28 f = 2 s = 2 o = 14 The final output shape is (1, 6, 14, 14) where the kernels are halved in size. 2nd conv2d layer: n = 14 f = 5 p = 0 s = 1 o = 10 The final output shape is (1, 16, 10, 10) X = torch . rand ( size = ( 1 , 1 , 28 , 28 ), dtype = torch . float32 ) for layer in lenet : X = layer ( X ) print ( layer . __class__ . __name__ , \"output shape: \\t \" , X . shape ) Conv2d output shape: torch.Size([1, 6, 28, 28]) Sigmoid output shape: torch.Size([1, 6, 28, 28]) AvgPool2d output shape: torch.Size([1, 6, 14, 14]) Conv2d output shape: torch.Size([1, 16, 10, 10]) Sigmoid output shape: torch.Size([1, 16, 10, 10]) AvgPool2d output shape: torch.Size([1, 16, 5, 5]) Flatten output shape: torch.Size([1, 400]) Linear output shape: torch.Size([1, 120]) Sigmoid output shape: torch.Size([1, 120]) Linear output shape: torch.Size([1, 84]) Sigmoid output shape: torch.Size([1, 84]) Linear output shape: torch.Size([1, 10]) X = torch . rand ( size = ( 1 , 1 , 28 , 28 ), dtype = torch . float32 ) for layer in lenet : X = layer ( X ) if hasattr ( layer , \"weight\" ): print ( layer , \"layer weight shape: \\t \" , layer . weight . shape ) Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)) layer weight shape: torch.Size([6, 1, 5, 5]) Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) layer weight shape: torch.Size([16, 6, 5, 5]) Linear(in_features=400, out_features=120, bias=True) layer weight shape: torch.Size([120, 400]) Linear(in_features=120, out_features=84, bias=True) layer weight shape: torch.Size([84, 120]) Linear(in_features=84, out_features=10, bias=True) layer weight shape: torch.Size([10, 84]) Toy Models I created two versions of the same model. The Sequential method has a more compact form, but often is more difficult to extract layers. class ToyModel ( torch . nn . Module ): def __init__ ( self ): super () . __init__ () self . cl1 = torch . nn . Linear ( 25 , 60 ) self . cl2 = torch . nn . Linear ( 60 , 16 ) self . fc1 = torch . nn . Linear ( 16 , 120 ) self . fc2 = torch . nn . Linear ( 120 , 84 ) self . fc3 = torch . nn . Linear ( 84 , 10 ) def forward ( self , x ): \"\"\"Forward pass of the model. Args: x ([type]): [description] Returns: [type]: [description] \"\"\" x = torch . nn . ReLU ()( self . cl1 ( x )) x = torch . nn . ReLU ()( self . cl2 ( x )) x = torch . nn . ReLU ()( self . fc1 ( x )) x = torch . nn . ReLU ()( self . fc2 ( x )) x = torch . nn . LogSoftmax ( dim = 1 )( self . fc3 ( x )) return x class ToySequentialModel ( torch . nn . Module ): # Create a sequential model pytorch same as ToyModel. def __init__ ( self ) -> None : super () . __init__ () self . backbone = torch . nn . Sequential ( OrderedDict ( [ ( \"cl1\" , torch . nn . Linear ( 25 , 60 )), ( \"cl_relu1\" , torch . nn . ReLU ()), ( \"cl2\" , torch . nn . Linear ( 60 , 16 )), ( \"cl_relu2\" , torch . nn . ReLU ()), ] ) ) self . head = torch . nn . Sequential ( OrderedDict ( [ ( \"fc1\" , torch . nn . Linear ( 16 , 120 )), ( \"fc_relu_1\" , torch . nn . ReLU ()), ( \"fc2\" , torch . nn . Linear ( 120 , 84 )), ( \"fc_relu_2\" , torch . nn . ReLU ()), ( \"fc3\" , torch . nn . Linear ( 84 , 10 )), ( \"fc_log_softmax\" , torch . nn . LogSoftmax ( dim = 1 )), ] ) ) def forward ( self , x ): \"\"\"Forward pass of the model. Args: x ([type]): [description] Returns: [type]: [description] \"\"\" x = self . backbone ( x ) x = self . head ( x ) return x Named Modules Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself. for name , layer in ToySequentialModel () . named_modules (): print ( name ) backbone backbone.cl1 backbone.cl_relu1 backbone.cl2 backbone.cl_relu2 head head.fc1 head.fc_relu_1 head.fc2 head.fc_relu_2 head.fc3 head.fc_log_softmax Get Convolutional Layers def get_conv_layers ( model : Callable , layer_type : str = \"Conv2d\" ) -> Dict [ str , str ]: \"\"\"Create a function that give me the convolutional layers of PyTorch model. This function is created to be used in conjunction with Visualization of Feature Maps. Args: model (Union[torchvision.models, timm.models]): A PyTorch model. layer_type (str): The type of layer to be extracted. Returns: conv_layers (Dict[str, str]): {\"layer1.0.conv1\": layer1.0.conv1, ...} Example: >>> resnet18_pretrained_true = timm.create_model(model_name = \"resnet34\", pretrained=True, num_classes=10).to(DEVICE) >>> conv_layers = get_conv_layers(resnet18_pretrained_true, layer_type=\"Conv2d\") \"\"\" if layer_type == \"Conv2d\" : _layer_type = torch . nn . Conv2d elif layer_type == \"Conv1d\" : _layer_type = torch . nn . Conv1d conv_layers = {} for name , layer in model . named_modules (): if isinstance ( layer , _layer_type ): conv_layers [ name ] = name return conv_layers resnet18_pretrained_true = timm . create_model ( model_name = \"resnet34\" , pretrained = True , num_classes = 10 ) . to ( DEVICE ) >>> resnet18_pretrained_true = timm . create_model ( model_name = \"resnet34\" , pretrained = True , num_classes = 10 ) . to ( DEVICE ) >>> conv_layers = get_conv_layers ( resnet18_pretrained_true , layer_type = \"Conv2d\" ) >>> print ( conv_layers ) {'conv1': 'conv1', 'layer1.0.conv1': 'layer1.0.conv1', 'layer1.0.conv2': 'layer1.0.conv2', 'layer1.1.conv1': 'layer1.1.conv1', 'layer1.1.conv2': 'layer1.1.conv2', 'layer1.2.conv1': 'layer1.2.conv1', 'layer1.2.conv2': 'layer1.2.conv2', 'layer2.0.conv1': 'layer2.0.conv1', 'layer2.0.conv2': 'layer2.0.conv2', 'layer2.0.downsample.0': 'layer2.0.downsample.0', 'layer2.1.conv1': 'layer2.1.conv1', 'layer2.1.conv2': 'layer2.1.conv2', 'layer2.2.conv1': 'layer2.2.conv1', 'layer2.2.conv2': 'layer2.2.conv2', 'layer2.3.conv1': 'layer2.3.conv1', 'layer2.3.conv2': 'layer2.3.conv2', 'layer3.0.conv1': 'layer3.0.conv1', 'layer3.0.conv2': 'layer3.0.conv2', 'layer3.0.downsample.0': 'layer3.0.downsample.0', 'layer3.1.conv1': 'layer3.1.conv1', 'layer3.1.conv2': 'layer3.1.conv2', 'layer3.2.conv1': 'layer3.2.conv1', 'layer3.2.conv2': 'layer3.2.conv2', 'layer3.3.conv1': 'layer3.3.conv1', 'layer3.3.conv2': 'layer3.3.conv2', 'layer3.4.conv1': 'layer3.4.conv1', 'layer3.4.conv2': 'layer3.4.conv2', 'layer3.5.conv1': 'layer3.5.conv1', 'layer3.5.conv2': 'layer3.5.conv2', 'layer4.0.conv1': 'layer4.0.conv1', 'layer4.0.conv2': 'layer4.0.conv2', 'layer4.0.downsample.0': 'layer4.0.downsample.0', 'layer4.1.conv1': 'layer4.1.conv1', 'layer4.1.conv2': 'layer4.1.conv2', 'layer4.2.conv1': 'layer4.2.conv1', 'layer4.2.conv2': 'layer4.2.conv2'} activation = {} def get_intermediate_features ( name : str ) -> Callable : \"\"\"Get the intermediate features of a model. Forward Hook. This is using forward hook with reference https://discuss.pytorch.org/t/how-can-l-load-my-best-model-as-a-feature-extractor-evaluator/17254/5 Args: name (str): name of the layer. Returns: Callable: [description] \"\"\" def hook ( model , input , output ): activation [ name ] = output . detach () return hook # The below is testing the forward hook functionalities, especially getting intermediate features. # Note that both models are same organically but created differently. # Due to seeding issues, you can check whether they are the same output or not by running them separately. # We also used assertion to check that the output from model(x) is same as torch.nn.LogSoftmax(dim=1)(fc3_output) use_sequential_model = True x = torch . randn ( 1 , 25 ) if not use_sequential_model : model = ToyModel () model . fc2 . register_forward_hook ( get_intermediate_features ( \"fc2\" )) model . fc3 . register_forward_hook ( get_intermediate_features ( \"fc3\" )) output = model ( x ) print ( activation ) fc2_output = activation [ \"fc2\" ] fc3_output = activation [ \"fc3\" ] # assert output and logsoftmax fc3_output are the same assert torch . allclose ( output , torch . nn . LogSoftmax ( dim = 1 )( fc3_output )) else : sequential_model = ToySequentialModel () # Do this if you want all, if not you can see below. # for name, layer in sequential_model.named_modules(): # layer.register_forward_hook(get_intermediate_features(name)) sequential_model . head . fc2 . register_forward_hook ( get_intermediate_features ( \"head.fc2\" ) ) sequential_model . head . fc3 . register_forward_hook ( get_intermediate_features ( \"head.fc3\" ) ) sequential_model_output = sequential_model ( x ) print ( activation ) fc2_output = activation [ \"head.fc2\" ] fc3_output = activation [ \"head.fc3\" ] assert torch . allclose ( sequential_model_output , torch . nn . LogSoftmax ( dim = 1 )( fc3_output ) ) {'head.fc2': tensor([[ 0.0697, 0.0544, -0.0157, -0.1059, -0.0464, -0.0090, 0.0532, -0.1273, -0.0286, -0.0151, 0.0963, 0.2205, 0.0745, -0.0110, -0.1127, -0.0367, -0.0681, 0.0463, -0.0833, 0.1288, 0.1058, 0.0976, -0.0251, 0.0980, -0.0110, 0.1170, -0.0650, 0.2091, -0.1773, 0.0363, -0.1452, 0.0036, 0.0112, -0.0304, -0.0620, -0.0658, -0.0543, 0.0072, 0.0436, 0.0703, 0.0254, -0.0614, 0.0164, -0.1003, -0.0396, 0.0349, 0.0089, -0.1243, -0.1037, -0.0491, 0.0627, -0.1347, 0.0010, -0.1290, -0.0280, -0.0344, 0.1487, -0.1764, -0.0233, 0.0082, 0.1270, 0.0368, 0.0103, -0.0929, 0.0038, 0.1346, -0.0688, -0.0437, -0.1205, -0.1596, -0.0240, -0.1001, -0.0300, -0.1119, 0.0344, -0.1587, 0.0329, -0.0424, 0.0999, 0.0732, 0.1116, 0.0220, -0.0570, 0.0232]]), 'head.fc3': tensor([[ 0.0256, -0.0924, 0.0456, 0.0972, 0.0107, 0.0527, 0.0208, 0.0373, 0.0451, 0.0712]])} How to freeze layers # resnet18_pretrained_true = timm.create_model(model_name = \"resnet34\", pretrained=True, num_classes=10).to(DEVICE) norm = torch . nn . InstanceNorm2d ( num_features = 3 , track_running_stats = True ) print ( norm . running_mean , norm . running_var ) tensor([0., 0., 0.]) tensor([1., 1., 1.]) x = torch . randn ( 2 , 3 , 24 , 24 ) out = norm ( x ) print ( norm . running_mean , norm . running_var ) out = norm ( x ) print ( norm . running_mean , norm . running_var ) out = norm ( x ) print ( norm . running_mean , norm . running_var ) tensor([-1.3414e-03, -4.7338e-05, 1.1239e-03]) tensor([1.0010, 0.9984, 0.9989]) tensor([-2.5486e-03, -8.9943e-05, 2.1355e-03]) tensor([1.0018, 0.9969, 0.9979]) tensor([-0.0036, -0.0001, 0.0030]) tensor([1.0026, 0.9956, 0.9970]) norm . eval () out = norm ( x ) print ( norm . running_mean , norm . running_var ) tensor([-0.0160, -0.0018, 0.0068]) tensor([1.0002, 1.0082, 0.9904]) def freeze_batchnorm_layers ( model : Callable ) -> None : \"\"\"Freeze the batchnorm layers of a PyTorch model. Args: model (CustomNeuralNet): model to be frozen. Example: >>> model = timm.create_model(\"efficientnet_b0\", pretrained=True) >>> model.apply(freeze_batchnorm_layers) # to freeze during training \"\"\" # https://discuss.pytorch.org/t/how-to-freeze-bn-layers-while-training-the-rest-of-network-mean-and-var-wont-freeze/89736/19 # https://discuss.pytorch.org/t/should-i-use-model-eval-when-i-freeze-batchnorm-layers-to-finetune/39495/3 classname = model . __class__ . __name__ for module in model . modules (): if isinstance ( module , torch . nn . InstanceNorm2d ): module . eval () if isinstance ( module , torch . nn . BatchNorm2d ): if hasattr ( module , \"weight\" ): module . weight . requires_grad_ ( False ) if hasattr ( module , \"bias\" ): module . bias . requires_grad_ ( False ) module . eval () norm . apply ( freeze_batchnorm_layers ) InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True) out = norm ( x ) norm . running_mean , norm . running_var (tensor([-0.0036, -0.0001, 0.0030]), tensor([1.0026, 0.9956, 0.9970]))","title":"PyTorch Utilities"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/PyTorch%20Utilities/#imports-config-and-seeding","text":"import timm import torch import torchvision from typing import Dict , Union , Callable , OrderedDict , Tuple import os , random import numpy as np import torch.nn as nn def seed_all ( seed : int = 1992 ) -> None : \"\"\"Seed all random number generators.\"\"\" print ( f \"Using Seed Number { seed } \" ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator # set fixed value for python built-in pseudo-random generator random . seed ( seed ) torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = True torch . backends . cudnn . enabled = True def seed_worker ( _worker_id ) -> None : \"\"\"Seed a worker with the given ID.\"\"\" worker_seed = torch . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) seed_all ( seed = 1992 ) Using Seed Number 1992 DEVICE = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" )","title":"Imports, Config and Seeding"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/PyTorch%20Utilities/#convolutional-neural-networks","text":"","title":"Convolutional Neural Networks"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/PyTorch%20Utilities/#terminologies","text":"Kernel Filter Receptive Field X = torch . tensor ([[ 0.0 , 1.0 , 2.0 ], [ 3.0 , 4.0 , 5.0 ], [ 6.0 , 7.0 , 8.0 ]]) K = torch . tensor ([[ 0.0 , 1.0 ], [ 2.0 , 3.0 ]]) def my_conv2d ( x : torch . Tensor , kernel : torch . Tensor ) -> torch . Tensor : kernel_height , kernel_width = kernel . shape input_height , input_width = x . shape feature_map_height , feature_map_width = ( input_height - kernel_height + 1 , input_width - kernel_width + 1 , ) feature_map = torch . zeros ( size = ( feature_map_height , feature_map_width )) for height_index in range ( feature_map_height ): for width_index in range ( feature_map_width ): # 1st iter: height_index = 0, width_index = 0 # 2nd iter: height_index = 0, width_index = 1 receptive_field = x [ height_index : height_index + kernel_height , width_index : width_index + kernel_width , ] feature_map [ height_index , width_index ] = ( receptive_field * kernel ) . sum () return feature_map my_conv2d ( X , K ) tensor([[19., 25.], [37., 43.]]) class MyConv2D ( nn . Module ): def __init__ ( self , kernel_size : Tuple [ int , int ]): super () . __init__ () self . kernel = nn . Parameter ( torch . rand ( size = ( kernel_size [ 0 ], kernel_size [ 1 ])) ) self . bias = nn . Parameter ( torch . zeros ( 1 )) def forward ( self , x ): return my_conv2d ( x , self . kernel ) + self . bias conv2d = MyConv2D (( 2 , 2 )) conv2d ( X ) tensor([[ 7.3671, 10.2563], [16.0346, 18.9238]], grad_fn=<AddBackward0>)","title":"Terminologies"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/PyTorch%20Utilities/#cnn-conv2d-layer-output-dimensions-calculation","text":"Given: n: Input image's height/width f: Filter/Kernel Size p: Padding Size s: Stride Given an image of size \\(n \\times n\\) and a kernel of \\(f \\times f\\) , our output shape is \\[ o = n - f + 1 \\] and if we pad the image with 1 extra layer outside, that means our input image is of size \\((n + 2*1) \\times (n + 2*1)\\) , if you see an image you will be clear why adding one layer around means input width and height add 2 times the padding \\(p\\) . hence our new output shape is: \\[ o = (n+2) - f + 1 \\] and a generic formula for padding equals \\(p\\) will yield \\[ o = (n + 2p) - f + 1 \\] Note that: If \\(p=0\\) , then this is valid padding where the output shape is \\(n - f + 1\\) ; If \\(p=\\frac{f-1}{2}\\) , then this is same padding where the output shape is equals to the original input shape \\(n\\) . Same padding can be deduced by setting \\[ (n+2p) - f + 1 = n \\implies p = \\frac{f-1}{2} \\] where by construction \\(f\\) must be odd in order to get a whole number for the padding \\(p\\) , and that's why most kernels/filters are of odd shape. With stride into action our final shape is: \\[ o = \\dfrac{n - f + 2p}{s} + 1 \\] where sometimes \\(o\\) is applied by \\(\\text{floor}(o)\\) if the \\(o\\) is non-integer.","title":"CNN Conv2d Layer Output Dimensions Calculation"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/PyTorch%20Utilities/#cnn-pooling-layer-output-dimensions-calculation","text":"For general pooling operations: Given: n: Input image's height/width f: Filter/Kernel Size s: Stride Given an image of size \\(n \\times n\\) and a kernel of \\(f \\times f\\) , our output shape after pooling is: \\[ o = \\text{floor}\\left(\\dfrac{n - f}{s} + 1\\right) \\] with floor applied to \\(o\\) .","title":"CNN Pooling Layer Output Dimensions Calculation"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/PyTorch%20Utilities/#lenet","text":"import torch from torch import nn lenet = nn . Sequential ( nn . Conv2d ( in_channels = 1 , out_channels = 6 , kernel_size = 5 , padding = 2 , stride = 1 ), nn . Sigmoid (), nn . AvgPool2d ( kernel_size = 2 , stride = 2 ), nn . Conv2d ( in_channels = 6 , out_channels = 16 , kernel_size = 5 , padding = 0 , stride = 1 ), nn . Sigmoid (), nn . AvgPool2d ( kernel_size = 2 , stride = 2 ), nn . Flatten (), nn . Linear ( 16 * 5 * 5 , 120 ), nn . Sigmoid (), nn . Linear ( 120 , 84 ), nn . Sigmoid (), nn . Linear ( 84 , 10 ), ) X: (1, 1, 28, 28) 1st conv2d layer: a conv2d layer that applies a filter containing 6 kernels, where each kernel is of size \\(5 \\times 5\\) with a padding of 2 and stride of 1 n = 28 f = 5 p = 2 ; Note in particular the padding of 2 is derived from the formula \\(p = (f-1)/2 = 4/2=2\\) to get same padding! s = 1 shape: \\(o = \\frac{28-5+4}{1} + 1 = 28\\) The final output shape is (1, 6, 28, 28) where 1 is the batch size 6 is the number of kernels applied, for each kernel our output shape is 28 by 28 28, 28 is the output shape by the kernels 1st avgpool2d layer: n = 28 f = 2 s = 2 o = 14 The final output shape is (1, 6, 14, 14) where the kernels are halved in size. 2nd conv2d layer: n = 14 f = 5 p = 0 s = 1 o = 10 The final output shape is (1, 16, 10, 10) X = torch . rand ( size = ( 1 , 1 , 28 , 28 ), dtype = torch . float32 ) for layer in lenet : X = layer ( X ) print ( layer . __class__ . __name__ , \"output shape: \\t \" , X . shape ) Conv2d output shape: torch.Size([1, 6, 28, 28]) Sigmoid output shape: torch.Size([1, 6, 28, 28]) AvgPool2d output shape: torch.Size([1, 6, 14, 14]) Conv2d output shape: torch.Size([1, 16, 10, 10]) Sigmoid output shape: torch.Size([1, 16, 10, 10]) AvgPool2d output shape: torch.Size([1, 16, 5, 5]) Flatten output shape: torch.Size([1, 400]) Linear output shape: torch.Size([1, 120]) Sigmoid output shape: torch.Size([1, 120]) Linear output shape: torch.Size([1, 84]) Sigmoid output shape: torch.Size([1, 84]) Linear output shape: torch.Size([1, 10]) X = torch . rand ( size = ( 1 , 1 , 28 , 28 ), dtype = torch . float32 ) for layer in lenet : X = layer ( X ) if hasattr ( layer , \"weight\" ): print ( layer , \"layer weight shape: \\t \" , layer . weight . shape ) Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)) layer weight shape: torch.Size([6, 1, 5, 5]) Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) layer weight shape: torch.Size([16, 6, 5, 5]) Linear(in_features=400, out_features=120, bias=True) layer weight shape: torch.Size([120, 400]) Linear(in_features=120, out_features=84, bias=True) layer weight shape: torch.Size([84, 120]) Linear(in_features=84, out_features=10, bias=True) layer weight shape: torch.Size([10, 84])","title":"LeNet"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/PyTorch%20Utilities/#toy-models","text":"I created two versions of the same model. The Sequential method has a more compact form, but often is more difficult to extract layers. class ToyModel ( torch . nn . Module ): def __init__ ( self ): super () . __init__ () self . cl1 = torch . nn . Linear ( 25 , 60 ) self . cl2 = torch . nn . Linear ( 60 , 16 ) self . fc1 = torch . nn . Linear ( 16 , 120 ) self . fc2 = torch . nn . Linear ( 120 , 84 ) self . fc3 = torch . nn . Linear ( 84 , 10 ) def forward ( self , x ): \"\"\"Forward pass of the model. Args: x ([type]): [description] Returns: [type]: [description] \"\"\" x = torch . nn . ReLU ()( self . cl1 ( x )) x = torch . nn . ReLU ()( self . cl2 ( x )) x = torch . nn . ReLU ()( self . fc1 ( x )) x = torch . nn . ReLU ()( self . fc2 ( x )) x = torch . nn . LogSoftmax ( dim = 1 )( self . fc3 ( x )) return x class ToySequentialModel ( torch . nn . Module ): # Create a sequential model pytorch same as ToyModel. def __init__ ( self ) -> None : super () . __init__ () self . backbone = torch . nn . Sequential ( OrderedDict ( [ ( \"cl1\" , torch . nn . Linear ( 25 , 60 )), ( \"cl_relu1\" , torch . nn . ReLU ()), ( \"cl2\" , torch . nn . Linear ( 60 , 16 )), ( \"cl_relu2\" , torch . nn . ReLU ()), ] ) ) self . head = torch . nn . Sequential ( OrderedDict ( [ ( \"fc1\" , torch . nn . Linear ( 16 , 120 )), ( \"fc_relu_1\" , torch . nn . ReLU ()), ( \"fc2\" , torch . nn . Linear ( 120 , 84 )), ( \"fc_relu_2\" , torch . nn . ReLU ()), ( \"fc3\" , torch . nn . Linear ( 84 , 10 )), ( \"fc_log_softmax\" , torch . nn . LogSoftmax ( dim = 1 )), ] ) ) def forward ( self , x ): \"\"\"Forward pass of the model. Args: x ([type]): [description] Returns: [type]: [description] \"\"\" x = self . backbone ( x ) x = self . head ( x ) return x","title":"Toy Models"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/PyTorch%20Utilities/#named-modules","text":"Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself. for name , layer in ToySequentialModel () . named_modules (): print ( name ) backbone backbone.cl1 backbone.cl_relu1 backbone.cl2 backbone.cl_relu2 head head.fc1 head.fc_relu_1 head.fc2 head.fc_relu_2 head.fc3 head.fc_log_softmax","title":"Named Modules"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/PyTorch%20Utilities/#get-convolutional-layers","text":"def get_conv_layers ( model : Callable , layer_type : str = \"Conv2d\" ) -> Dict [ str , str ]: \"\"\"Create a function that give me the convolutional layers of PyTorch model. This function is created to be used in conjunction with Visualization of Feature Maps. Args: model (Union[torchvision.models, timm.models]): A PyTorch model. layer_type (str): The type of layer to be extracted. Returns: conv_layers (Dict[str, str]): {\"layer1.0.conv1\": layer1.0.conv1, ...} Example: >>> resnet18_pretrained_true = timm.create_model(model_name = \"resnet34\", pretrained=True, num_classes=10).to(DEVICE) >>> conv_layers = get_conv_layers(resnet18_pretrained_true, layer_type=\"Conv2d\") \"\"\" if layer_type == \"Conv2d\" : _layer_type = torch . nn . Conv2d elif layer_type == \"Conv1d\" : _layer_type = torch . nn . Conv1d conv_layers = {} for name , layer in model . named_modules (): if isinstance ( layer , _layer_type ): conv_layers [ name ] = name return conv_layers resnet18_pretrained_true = timm . create_model ( model_name = \"resnet34\" , pretrained = True , num_classes = 10 ) . to ( DEVICE ) >>> resnet18_pretrained_true = timm . create_model ( model_name = \"resnet34\" , pretrained = True , num_classes = 10 ) . to ( DEVICE ) >>> conv_layers = get_conv_layers ( resnet18_pretrained_true , layer_type = \"Conv2d\" ) >>> print ( conv_layers ) {'conv1': 'conv1', 'layer1.0.conv1': 'layer1.0.conv1', 'layer1.0.conv2': 'layer1.0.conv2', 'layer1.1.conv1': 'layer1.1.conv1', 'layer1.1.conv2': 'layer1.1.conv2', 'layer1.2.conv1': 'layer1.2.conv1', 'layer1.2.conv2': 'layer1.2.conv2', 'layer2.0.conv1': 'layer2.0.conv1', 'layer2.0.conv2': 'layer2.0.conv2', 'layer2.0.downsample.0': 'layer2.0.downsample.0', 'layer2.1.conv1': 'layer2.1.conv1', 'layer2.1.conv2': 'layer2.1.conv2', 'layer2.2.conv1': 'layer2.2.conv1', 'layer2.2.conv2': 'layer2.2.conv2', 'layer2.3.conv1': 'layer2.3.conv1', 'layer2.3.conv2': 'layer2.3.conv2', 'layer3.0.conv1': 'layer3.0.conv1', 'layer3.0.conv2': 'layer3.0.conv2', 'layer3.0.downsample.0': 'layer3.0.downsample.0', 'layer3.1.conv1': 'layer3.1.conv1', 'layer3.1.conv2': 'layer3.1.conv2', 'layer3.2.conv1': 'layer3.2.conv1', 'layer3.2.conv2': 'layer3.2.conv2', 'layer3.3.conv1': 'layer3.3.conv1', 'layer3.3.conv2': 'layer3.3.conv2', 'layer3.4.conv1': 'layer3.4.conv1', 'layer3.4.conv2': 'layer3.4.conv2', 'layer3.5.conv1': 'layer3.5.conv1', 'layer3.5.conv2': 'layer3.5.conv2', 'layer4.0.conv1': 'layer4.0.conv1', 'layer4.0.conv2': 'layer4.0.conv2', 'layer4.0.downsample.0': 'layer4.0.downsample.0', 'layer4.1.conv1': 'layer4.1.conv1', 'layer4.1.conv2': 'layer4.1.conv2', 'layer4.2.conv1': 'layer4.2.conv1', 'layer4.2.conv2': 'layer4.2.conv2'} activation = {} def get_intermediate_features ( name : str ) -> Callable : \"\"\"Get the intermediate features of a model. Forward Hook. This is using forward hook with reference https://discuss.pytorch.org/t/how-can-l-load-my-best-model-as-a-feature-extractor-evaluator/17254/5 Args: name (str): name of the layer. Returns: Callable: [description] \"\"\" def hook ( model , input , output ): activation [ name ] = output . detach () return hook # The below is testing the forward hook functionalities, especially getting intermediate features. # Note that both models are same organically but created differently. # Due to seeding issues, you can check whether they are the same output or not by running them separately. # We also used assertion to check that the output from model(x) is same as torch.nn.LogSoftmax(dim=1)(fc3_output) use_sequential_model = True x = torch . randn ( 1 , 25 ) if not use_sequential_model : model = ToyModel () model . fc2 . register_forward_hook ( get_intermediate_features ( \"fc2\" )) model . fc3 . register_forward_hook ( get_intermediate_features ( \"fc3\" )) output = model ( x ) print ( activation ) fc2_output = activation [ \"fc2\" ] fc3_output = activation [ \"fc3\" ] # assert output and logsoftmax fc3_output are the same assert torch . allclose ( output , torch . nn . LogSoftmax ( dim = 1 )( fc3_output )) else : sequential_model = ToySequentialModel () # Do this if you want all, if not you can see below. # for name, layer in sequential_model.named_modules(): # layer.register_forward_hook(get_intermediate_features(name)) sequential_model . head . fc2 . register_forward_hook ( get_intermediate_features ( \"head.fc2\" ) ) sequential_model . head . fc3 . register_forward_hook ( get_intermediate_features ( \"head.fc3\" ) ) sequential_model_output = sequential_model ( x ) print ( activation ) fc2_output = activation [ \"head.fc2\" ] fc3_output = activation [ \"head.fc3\" ] assert torch . allclose ( sequential_model_output , torch . nn . LogSoftmax ( dim = 1 )( fc3_output ) ) {'head.fc2': tensor([[ 0.0697, 0.0544, -0.0157, -0.1059, -0.0464, -0.0090, 0.0532, -0.1273, -0.0286, -0.0151, 0.0963, 0.2205, 0.0745, -0.0110, -0.1127, -0.0367, -0.0681, 0.0463, -0.0833, 0.1288, 0.1058, 0.0976, -0.0251, 0.0980, -0.0110, 0.1170, -0.0650, 0.2091, -0.1773, 0.0363, -0.1452, 0.0036, 0.0112, -0.0304, -0.0620, -0.0658, -0.0543, 0.0072, 0.0436, 0.0703, 0.0254, -0.0614, 0.0164, -0.1003, -0.0396, 0.0349, 0.0089, -0.1243, -0.1037, -0.0491, 0.0627, -0.1347, 0.0010, -0.1290, -0.0280, -0.0344, 0.1487, -0.1764, -0.0233, 0.0082, 0.1270, 0.0368, 0.0103, -0.0929, 0.0038, 0.1346, -0.0688, -0.0437, -0.1205, -0.1596, -0.0240, -0.1001, -0.0300, -0.1119, 0.0344, -0.1587, 0.0329, -0.0424, 0.0999, 0.0732, 0.1116, 0.0220, -0.0570, 0.0232]]), 'head.fc3': tensor([[ 0.0256, -0.0924, 0.0456, 0.0972, 0.0107, 0.0527, 0.0208, 0.0373, 0.0451, 0.0712]])}","title":"Get Convolutional Layers"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/PyTorch%20Utilities/#how-to-freeze-layers","text":"# resnet18_pretrained_true = timm.create_model(model_name = \"resnet34\", pretrained=True, num_classes=10).to(DEVICE) norm = torch . nn . InstanceNorm2d ( num_features = 3 , track_running_stats = True ) print ( norm . running_mean , norm . running_var ) tensor([0., 0., 0.]) tensor([1., 1., 1.]) x = torch . randn ( 2 , 3 , 24 , 24 ) out = norm ( x ) print ( norm . running_mean , norm . running_var ) out = norm ( x ) print ( norm . running_mean , norm . running_var ) out = norm ( x ) print ( norm . running_mean , norm . running_var ) tensor([-1.3414e-03, -4.7338e-05, 1.1239e-03]) tensor([1.0010, 0.9984, 0.9989]) tensor([-2.5486e-03, -8.9943e-05, 2.1355e-03]) tensor([1.0018, 0.9969, 0.9979]) tensor([-0.0036, -0.0001, 0.0030]) tensor([1.0026, 0.9956, 0.9970]) norm . eval () out = norm ( x ) print ( norm . running_mean , norm . running_var ) tensor([-0.0160, -0.0018, 0.0068]) tensor([1.0002, 1.0082, 0.9904]) def freeze_batchnorm_layers ( model : Callable ) -> None : \"\"\"Freeze the batchnorm layers of a PyTorch model. Args: model (CustomNeuralNet): model to be frozen. Example: >>> model = timm.create_model(\"efficientnet_b0\", pretrained=True) >>> model.apply(freeze_batchnorm_layers) # to freeze during training \"\"\" # https://discuss.pytorch.org/t/how-to-freeze-bn-layers-while-training-the-rest-of-network-mean-and-var-wont-freeze/89736/19 # https://discuss.pytorch.org/t/should-i-use-model-eval-when-i-freeze-batchnorm-layers-to-finetune/39495/3 classname = model . __class__ . __name__ for module in model . modules (): if isinstance ( module , torch . nn . InstanceNorm2d ): module . eval () if isinstance ( module , torch . nn . BatchNorm2d ): if hasattr ( module , \"weight\" ): module . weight . requires_grad_ ( False ) if hasattr ( module , \"bias\" ): module . bias . requires_grad_ ( False ) module . eval () norm . apply ( freeze_batchnorm_layers ) InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True) out = norm ( x ) norm . running_mean , norm . running_var (tensor([-0.0036, -0.0001, 0.0030]), tensor([1.0026, 0.9956, 0.9970]))","title":"How to freeze layers"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/","text":"Object Detection https://everitt257.github.io/post/2018/08/10/object_detection.html https://towardsdatascience.com/deep-learning-for-object-detection-a-comprehensive-review-73930816d8d9 https://viso.ai/deep-learning/yolov3-overview/#:~:text=YOLOv3%20(You%20Only%20Look%20Once%2C%20Version%203)%20is%20a,network%20to%20detect%20an%20object. https://sheng-fang.github.io/2020-04-25-review_yolo/ https://deep-learning-study-note.readthedocs.io/en/latest/Part%202%20(Modern%20Practical%20Deep%20Networks)/12%20Applications/Computer%20Vision%20External/YOLO.html Bounding Boxes https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/ Anchor Boxes https://towardsdatascience.com/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9 Yolo Insanely well written article by Oracle detailing with examples of Yolo v1-v3 https://datascience.stackexchange.com/questions/85306/yolov1-algorithm-how-to-determine-predictor-responsibility Quick walkthrough of Yolo v1-v5 https://www.harrysprojects.com/articles/yolov1.html#:~:text=The%20architecture%20of%20YOLO%20v1,of%20those%20fully%20connected%20layers. https://chowdera.com/2022/02/202202130021493704.html In Depth: https://www.codetd.com/en/article/11916630 https://towardsdatascience.com/yolov1-you-only-look-once-object-detection-e1f3ffec8a89 https://jonathan-hui.medium.com/real-time-object-detection-with-yolo-yolov2-28b1b93e2088 https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/ Yolo Implementations https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/amp/ There is a distinct difference in how anchor boxes are decided in YOLOv1 versus the later versions. https://stackoverflow.com/questions/52710248/anchor-boxes-in-yolo-how-are-they-decided https://leimao.github.io/blog/YOLOs/ https://stats.stackexchange.com/questions/287486/yolo-loss-function-explanation/287497 https://dkharazi.github.io/notes/ml/cnn/yolo How to use Yolo Library https://www.kaggle.com/code/andradaolteanu/greatbarrierreef-yolo-full-guide-train-infer#Step-4.-YOLOv5-Training Train Custom Data provides a solid introduction. There are other detailed tutorials in their documentation page. Weights & Biases Logging also provides how to log metrics to Weights & Biases. Training Colab Notebook can also be found inside the tutorials. Be sure to look out for them as they are scattered around. YOLOv5 Inference Documentation https://colab.research.google.com/github/bala-codes/Yolo-v5_Object_Detection_Blood_Cell_Count_and_Detection/blob/master/codes/1.%20Yolo-V5%20BCC%20Training%20%26%20Testing.ipynb#scrollTo=k3Tc61Qzd4lY https://www.kaggle.com/code/andradaolteanu/greatbarrierreef-yolo-full-guide-train-infer/notebook#Step-3.-YOLO-Configuration https://github.com/awsaf49/bbox/blob/main/bbox/utils.py https://www.kaggle.com/code/andradaolteanu/whales-dolphins-effnet-embedding-cos-distance#6.-Get-Image-Embeddings https://www.kaggle.com/code/awsaf49/happywhale-boundingbox-yolov5/notebook#%F0%9F%9B%A0-Install-Libraries https://www.kaggle.com/code/awsaf49/happywhale-cropped-dataset-yolov5/notebook#Crop-Utility https://towardsai.net/p/computer-vision/yolo-v5-object-detection-on-a-custom-dataset https://docs.ultralytics.com/tutorials/train-custom-datasets/ https://www.kaggle.com/code/vbookshelf/basics-of-yolo-v5-balloon-detection/notebook#Create-the-yaml-file https://towardsdatascience.com/the-practical-guide-for-object-detection-with-yolov5-algorithm-74c04aac4843 https://docs.ultralytics.com/tutorials/train-custom-datasets/#5-train https://docs.ultralytics.com/tutorials/pytorch-hub/ https://github.com/ultralytics/yolov5/issues/36 RCNN Follow This for basic implementation Simple RCNN Implementation https://towardsdatascience.com/deep-learning-for-object-detection-a-comprehensive-review-73930816d8d9 https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection https://tryolabs.com/blog/2017/08/30/object-detection-an-overview-in-the-age-of-deep-learning#deep-learning-approach https://blog.paperspace.com/faster-r-cnn-explained-object-detection/","title":"README"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/#object-detection","text":"https://everitt257.github.io/post/2018/08/10/object_detection.html https://towardsdatascience.com/deep-learning-for-object-detection-a-comprehensive-review-73930816d8d9 https://viso.ai/deep-learning/yolov3-overview/#:~:text=YOLOv3%20(You%20Only%20Look%20Once%2C%20Version%203)%20is%20a,network%20to%20detect%20an%20object. https://sheng-fang.github.io/2020-04-25-review_yolo/ https://deep-learning-study-note.readthedocs.io/en/latest/Part%202%20(Modern%20Practical%20Deep%20Networks)/12%20Applications/Computer%20Vision%20External/YOLO.html","title":"Object Detection"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/#bounding-boxes","text":"https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/","title":"Bounding Boxes"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/#anchor-boxes","text":"https://towardsdatascience.com/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9","title":"Anchor Boxes"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/#yolo","text":"Insanely well written article by Oracle detailing with examples of Yolo v1-v3 https://datascience.stackexchange.com/questions/85306/yolov1-algorithm-how-to-determine-predictor-responsibility Quick walkthrough of Yolo v1-v5 https://www.harrysprojects.com/articles/yolov1.html#:~:text=The%20architecture%20of%20YOLO%20v1,of%20those%20fully%20connected%20layers. https://chowdera.com/2022/02/202202130021493704.html In Depth: https://www.codetd.com/en/article/11916630 https://towardsdatascience.com/yolov1-you-only-look-once-object-detection-e1f3ffec8a89 https://jonathan-hui.medium.com/real-time-object-detection-with-yolo-yolov2-28b1b93e2088 https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/ Yolo Implementations https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/amp/ There is a distinct difference in how anchor boxes are decided in YOLOv1 versus the later versions. https://stackoverflow.com/questions/52710248/anchor-boxes-in-yolo-how-are-they-decided https://leimao.github.io/blog/YOLOs/ https://stats.stackexchange.com/questions/287486/yolo-loss-function-explanation/287497 https://dkharazi.github.io/notes/ml/cnn/yolo How to use Yolo Library https://www.kaggle.com/code/andradaolteanu/greatbarrierreef-yolo-full-guide-train-infer#Step-4.-YOLOv5-Training Train Custom Data provides a solid introduction. There are other detailed tutorials in their documentation page. Weights & Biases Logging also provides how to log metrics to Weights & Biases. Training Colab Notebook can also be found inside the tutorials. Be sure to look out for them as they are scattered around. YOLOv5 Inference Documentation https://colab.research.google.com/github/bala-codes/Yolo-v5_Object_Detection_Blood_Cell_Count_and_Detection/blob/master/codes/1.%20Yolo-V5%20BCC%20Training%20%26%20Testing.ipynb#scrollTo=k3Tc61Qzd4lY https://www.kaggle.com/code/andradaolteanu/greatbarrierreef-yolo-full-guide-train-infer/notebook#Step-3.-YOLO-Configuration https://github.com/awsaf49/bbox/blob/main/bbox/utils.py https://www.kaggle.com/code/andradaolteanu/whales-dolphins-effnet-embedding-cos-distance#6.-Get-Image-Embeddings https://www.kaggle.com/code/awsaf49/happywhale-boundingbox-yolov5/notebook#%F0%9F%9B%A0-Install-Libraries https://www.kaggle.com/code/awsaf49/happywhale-cropped-dataset-yolov5/notebook#Crop-Utility https://towardsai.net/p/computer-vision/yolo-v5-object-detection-on-a-custom-dataset https://docs.ultralytics.com/tutorials/train-custom-datasets/ https://www.kaggle.com/code/vbookshelf/basics-of-yolo-v5-balloon-detection/notebook#Create-the-yaml-file https://towardsdatascience.com/the-practical-guide-for-object-detection-with-yolov5-algorithm-74c04aac4843 https://docs.ultralytics.com/tutorials/train-custom-datasets/#5-train https://docs.ultralytics.com/tutorials/pytorch-hub/ https://github.com/ultralytics/yolov5/issues/36","title":"Yolo"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/#rcnn","text":"Follow This for basic implementation Simple RCNN Implementation https://towardsdatascience.com/deep-learning-for-object-detection-a-comprehensive-review-73930816d8d9 https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection https://tryolabs.com/blog/2017/08/30/object-detection-an-overview-in-the-age-of-deep-learning#deep-learning-approach https://blog.paperspace.com/faster-r-cnn-explained-object-detection/","title":"RCNN"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/image_normalization/Image_Normalization_and_Standardization/","text":"Imports and Utils import os import random from typing import Dict , Tuple import cv2 import numpy as np import pandas as pd import torch import torchvision.datasets as datasets from PIL import Image , ImageFile from torchvision import transforms from tqdm import tqdm def seed_all ( seed : int = 1930 ): \"\"\"Seed all random number generators.\"\"\" print ( \"Using Seed Number {} \" . format ( seed )) # set PYTHONHASHSEED env var at fixed value os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator random . seed ( seed ) # set fixed value for python built-in pseudo-random generator torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False torch . backends . cudnn . enabled = False seed_all () Using Seed Number 1930 Disclaimer Note that the following method is not the most efficient way , but it is good for learning as the steps in the codes are laid out sequentially so that it is easy to follow. Info There are a few pre-preprocessing techniques for image data. Here we discuss the most common one that I encounter, Normalization across channels. [1^]: Extracted from CS231n Warning Data leakage will occur if you apply this pre-processing step prior to your train-valid-test split. We should apply normalization on the training step, obtaining the mean and std metrics for \\(X_{\\text{train}}\\) and apply them to validation set during model selection, and to test set during model evaluation. In our examples below, I apply mean and std calculation on the training set (which includes the validation set), in reality, we should further split the training set into training and validation sets. General Steps to Normalize Important Warning Important: Most of the times we resize the images, so different image size may result in different mean and std. So remember to resize first then calcuate. RGB image with 3 channels. We assume it is channels first, if not convert from channels last to channels first. As I am using PyTorch primarily, this is more natural to me. See CIFAR-10 for such example. Load the data into disk using either cv2 or PIL . Divide by 255 across all images first to normalize it. Then find the image's mean and std per channel. For example, if we want to find the mean of the red channel of a batch of images, and assume we have 10 images of size \\((100, 100, 3)\\) each. Then each image has 3 channels, each channel has \\(100 \\times 100\\) pixels, and therefore 10 such images will have \\(10 \\times 100 \\times 100 = 100000\\) pixels. We flatten() all these 10 images' red channel and take the average (i.e. sum all \\(100000\\) red pixels, and divide by \\(1000000\\) ). We do the same for all the other channels. Grayscale image with 1 channel. This is just average the values in one channel. Audio/Spectrograms like SETI etc. CIFAR-10 (RGB) We first see an example of calculating the mean and standard deviation of cifar10, which is of RGB channels. Mean : { \"R\" : 0.49139968 \"G\" : 0.48215827 \"B\" : 0.44653124 } Standard Deviation : { \"R\" : 0.24703233 \"G\" : 0.24348505 \"B\" : 0.26158768 } We will code a function to calculate the mean and standard deviation of a batch of images. TRANSFORMS = transforms . Compose ([ transforms . ToTensor ()]) trainset_cifar10 = datasets . CIFAR10 ( root = \"./data\" , train = True , download = True , transform = TRANSFORMS ) testset_cifar10 = datasets . CIFAR10 ( root = \"./data\" , train = False , download = True , transform = TRANSFORMS ) train_images_cifar10 = np . asarray ( trainset_cifar10 . data ) # (50000, 32, 32, 3) test_images_cifar10 = np . asarray ( testset_cifar10 . data ) # (10000, 32, 32, 3) Files already downloaded and verified Files already downloaded and verified def calcMeanStd ( images : np . ndarray ) -> Dict [ str , Tuple [ float ]]: \"\"\"Take in an numpy array of images and returns mean and std per channel. This function assumes for a start, your array is loaded into disk. Args: images (np.ndarray): [num_images, channel, height, width] or [num_images, height, width, channel] Returns: Dict[str, Tuple[float]]: {\"mean\": (mean_r, mean_g, mean_b), \"std\": (std_r, std_g, std_b)} \"\"\" images = np . asarray ( images ) # good way to test if images is passed in the correct dtype images = images / 255. # min-max and divide by 255 if images . ndim == 4 : # RGB if images . shape [ 1 ] != 3 : # if channel is not first, make it so, assume channels last images = images . transpose ( 0 , 3 , 1 , 2 ) # if tensor use permute instead # permutation applies the following mapping # axis0 -> axis0 # axis1 -> axis3 # axis2 -> axis1 # axis3 -> axis2 b , c , w , h = images . shape r_channel , g_channel , b_channel = images [:, 0 , :, :], images [:, 1 , :, :], images [:, 2 , :, :] # get rgb channels individually r_channel , g_channel , b_channel = r_channel . flatten (), g_channel . flatten (), b_channel . flatten () # flatten each channel into one array mean_r = r_channel . mean ( axis = None ) # since we are averaging per channel, we get the first channel's mean by r_channel.mean mean_g = g_channel . mean ( axis = None ) # same as above mean_b = b_channel . mean ( axis = None ) # same as above # calculate std over each channel (r,g,b) std_r = r_channel . std ( axis = None ) std_g = g_channel . std ( axis = None ) std_b = b_channel . std ( axis = None ) return { 'mean' : ( mean_r , mean_g , mean_b ), 'std' : ( std_r , std_g , std_b )} elif images . ndim == 3 : # grayscale gray_channel = images . flatten () # flatten directly since only 1 channel mean = gray_channel . mean ( axis = None ) std = gray_channel . std ( axis = None ) return { \"mean\" : ( mean ,), \"std\" : ( std , )} else : raise ValueError ( \"passed error is not of the right shape!\" ) mean_std_cifar = calcMeanStd ( train_images_cifar10 ) print ( mean_std_cifar ) {'mean': (0.49139967861519745, 0.4821584083946076, 0.44653091444546616), 'std': (0.2470322324632823, 0.24348512800005553, 0.2615878417279641)} # alternate way to do this. print ( trainset_cifar10 . data . shape ) print ( trainset_cifar10 . data . mean ( axis = ( 0 , 1 , 2 )) / 255 ) print ( trainset_cifar10 . data . std ( axis = ( 0 , 1 , 2 )) / 255 ) (50000, 32, 32, 3) [0.49139968 0.48215841 0.44653091] [0.24703223 0.24348513 0.26158784] Depending on your use case, we can normalize the test/validation set with the parameters found on the train set, though in practice, for image recognition problems, we use the same normalization parameters on both the train and validation set, and apply it to test set. The steps are: Calculate the mean and std using the method above. Divide the training/validation/test set by 255. Normalize it using the values found. Note step 2 can be skipped if the normalization method in the library does a division of 255 internally. TRANSFORMS_with_normalization = transforms . Compose ( [ transforms . Normalize ( mean = mean_std_cifar [ \"mean\" ], std = mean_std_cifar [ \"std\" ] ), transforms . ToTensor (), ] ) trainset_cifar10 = datasets . CIFAR10 ( root = \"./data\" , train = True , download = True , transform = TRANSFORMS_with_normalization ) testset_cifar10 = datasets . CIFAR10 ( root = \"./data\" , train = False , download = True , transform = TRANSFORMS_with_normalization ) train_images_cifar10 = np . asarray ( trainset_cifar10 . data ) # (50000, 32, 32, 3) test_images_cifar10 = np . asarray ( testset_cifar10 . data ) # (10000, 32, 32, 3) Files already downloaded and verified Files already downloaded and verified MNIST (Grayscale) We next see an example of calculating the mean and standard deviation of MNIST, which is of one channel (grayscale). Mean : 0.1307 Standard Deviation : 0.3081 We will code a function to calculate the mean and standard deviation of a batch of images. # mnist trainset_mnist = datasets . MNIST ( root = \"./data/\" , train = True , download = True , transform = TRANSFORMS ) testset_mnist = datasets . MNIST ( root = \"./data\" , train = False , download = True , transform = TRANSFORMS ) train_images_mnist = np . asarray ( trainset_mnist . data ) # (60000, 28, 28) test_images_mnist = np . asarray ( testset_mnist . data ) # (10000, 28, 28) mean_std_mnist = calcMeanStd ( train_images_mnist ) print ( mean_std_mnist ) {'mean': (0.1306604762738429,), 'std': (0.3081078038564622,)} print ( trainset_mnist . data . float () . mean () / 255 ) print ( trainset_mnist . data . float () . std () / 255 ) tensor(0.1307) tensor(0.3081) References To read up more on how others do it efficiently , please have a read below. https://www.kaggle.com/kozodoi/seti-mean-and-std-of-new-data/notebook https://www.kaggle.com/kozodoi/computing-dataset-mean-and-std https://forums.fast.ai/t/calculating-our-own-image-stats-imagenet-stats-cifar-stats-etc/40355/3 https://github.com/JoshVarty/CancerDetection/blob/master/01_ImageStats.ipynb https://forums.fast.ai/t/calculating-new-stats/31214 https://forums.fast.ai/t/calcuating-the-mean-and-standard-deviation-for-normalize/62883/13 https://www.kaggle.com/c/ranzcr-clip-catheter-line-classification/discussion/211039 https://stackoverflow.com/questions/58151507/why-pytorch-officially-use-mean-0-485-0-456-0-406-and-std-0-229-0-224-0-2 https://stackoverflow.com/questions/65699020/calculate-standard-deviation-for-grayscale-imagenet-pixel-values-with-rotation-m/65717887#65717887 https://stackoverflow.com/questions/66678052/how-to-calculate-the-mean-and-the-std-of-cifar10-data https://drive.google.com/drive/u/1/folders/1Gum3vsRsKKRSFZ1hyKaPTiVs1AUAmdKD https://stackoverflow.com/questions/50710493/cifar-10-meaningless-normalization-values https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/6 https://github.com/kuangliu/pytorch-cifar/issues/19 https://github.com/Armour/pytorch-nn-practice/blob/master/utils/meanstd.py","title":"Image Normalization"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/image_normalization/Image_Normalization_and_Standardization/#imports-and-utils","text":"import os import random from typing import Dict , Tuple import cv2 import numpy as np import pandas as pd import torch import torchvision.datasets as datasets from PIL import Image , ImageFile from torchvision import transforms from tqdm import tqdm def seed_all ( seed : int = 1930 ): \"\"\"Seed all random number generators.\"\"\" print ( \"Using Seed Number {} \" . format ( seed )) # set PYTHONHASHSEED env var at fixed value os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator random . seed ( seed ) # set fixed value for python built-in pseudo-random generator torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False torch . backends . cudnn . enabled = False seed_all () Using Seed Number 1930","title":"Imports and Utils"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/image_normalization/Image_Normalization_and_Standardization/#disclaimer","text":"Note that the following method is not the most efficient way , but it is good for learning as the steps in the codes are laid out sequentially so that it is easy to follow. Info There are a few pre-preprocessing techniques for image data. Here we discuss the most common one that I encounter, Normalization across channels. [1^]: Extracted from CS231n Warning Data leakage will occur if you apply this pre-processing step prior to your train-valid-test split. We should apply normalization on the training step, obtaining the mean and std metrics for \\(X_{\\text{train}}\\) and apply them to validation set during model selection, and to test set during model evaluation. In our examples below, I apply mean and std calculation on the training set (which includes the validation set), in reality, we should further split the training set into training and validation sets.","title":"Disclaimer"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/image_normalization/Image_Normalization_and_Standardization/#general-steps-to-normalize","text":"Important Warning Important: Most of the times we resize the images, so different image size may result in different mean and std. So remember to resize first then calcuate. RGB image with 3 channels. We assume it is channels first, if not convert from channels last to channels first. As I am using PyTorch primarily, this is more natural to me. See CIFAR-10 for such example. Load the data into disk using either cv2 or PIL . Divide by 255 across all images first to normalize it. Then find the image's mean and std per channel. For example, if we want to find the mean of the red channel of a batch of images, and assume we have 10 images of size \\((100, 100, 3)\\) each. Then each image has 3 channels, each channel has \\(100 \\times 100\\) pixels, and therefore 10 such images will have \\(10 \\times 100 \\times 100 = 100000\\) pixels. We flatten() all these 10 images' red channel and take the average (i.e. sum all \\(100000\\) red pixels, and divide by \\(1000000\\) ). We do the same for all the other channels. Grayscale image with 1 channel. This is just average the values in one channel. Audio/Spectrograms like SETI etc.","title":"General Steps to Normalize"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/image_normalization/Image_Normalization_and_Standardization/#cifar-10-rgb","text":"We first see an example of calculating the mean and standard deviation of cifar10, which is of RGB channels. Mean : { \"R\" : 0.49139968 \"G\" : 0.48215827 \"B\" : 0.44653124 } Standard Deviation : { \"R\" : 0.24703233 \"G\" : 0.24348505 \"B\" : 0.26158768 } We will code a function to calculate the mean and standard deviation of a batch of images. TRANSFORMS = transforms . Compose ([ transforms . ToTensor ()]) trainset_cifar10 = datasets . CIFAR10 ( root = \"./data\" , train = True , download = True , transform = TRANSFORMS ) testset_cifar10 = datasets . CIFAR10 ( root = \"./data\" , train = False , download = True , transform = TRANSFORMS ) train_images_cifar10 = np . asarray ( trainset_cifar10 . data ) # (50000, 32, 32, 3) test_images_cifar10 = np . asarray ( testset_cifar10 . data ) # (10000, 32, 32, 3) Files already downloaded and verified Files already downloaded and verified def calcMeanStd ( images : np . ndarray ) -> Dict [ str , Tuple [ float ]]: \"\"\"Take in an numpy array of images and returns mean and std per channel. This function assumes for a start, your array is loaded into disk. Args: images (np.ndarray): [num_images, channel, height, width] or [num_images, height, width, channel] Returns: Dict[str, Tuple[float]]: {\"mean\": (mean_r, mean_g, mean_b), \"std\": (std_r, std_g, std_b)} \"\"\" images = np . asarray ( images ) # good way to test if images is passed in the correct dtype images = images / 255. # min-max and divide by 255 if images . ndim == 4 : # RGB if images . shape [ 1 ] != 3 : # if channel is not first, make it so, assume channels last images = images . transpose ( 0 , 3 , 1 , 2 ) # if tensor use permute instead # permutation applies the following mapping # axis0 -> axis0 # axis1 -> axis3 # axis2 -> axis1 # axis3 -> axis2 b , c , w , h = images . shape r_channel , g_channel , b_channel = images [:, 0 , :, :], images [:, 1 , :, :], images [:, 2 , :, :] # get rgb channels individually r_channel , g_channel , b_channel = r_channel . flatten (), g_channel . flatten (), b_channel . flatten () # flatten each channel into one array mean_r = r_channel . mean ( axis = None ) # since we are averaging per channel, we get the first channel's mean by r_channel.mean mean_g = g_channel . mean ( axis = None ) # same as above mean_b = b_channel . mean ( axis = None ) # same as above # calculate std over each channel (r,g,b) std_r = r_channel . std ( axis = None ) std_g = g_channel . std ( axis = None ) std_b = b_channel . std ( axis = None ) return { 'mean' : ( mean_r , mean_g , mean_b ), 'std' : ( std_r , std_g , std_b )} elif images . ndim == 3 : # grayscale gray_channel = images . flatten () # flatten directly since only 1 channel mean = gray_channel . mean ( axis = None ) std = gray_channel . std ( axis = None ) return { \"mean\" : ( mean ,), \"std\" : ( std , )} else : raise ValueError ( \"passed error is not of the right shape!\" ) mean_std_cifar = calcMeanStd ( train_images_cifar10 ) print ( mean_std_cifar ) {'mean': (0.49139967861519745, 0.4821584083946076, 0.44653091444546616), 'std': (0.2470322324632823, 0.24348512800005553, 0.2615878417279641)} # alternate way to do this. print ( trainset_cifar10 . data . shape ) print ( trainset_cifar10 . data . mean ( axis = ( 0 , 1 , 2 )) / 255 ) print ( trainset_cifar10 . data . std ( axis = ( 0 , 1 , 2 )) / 255 ) (50000, 32, 32, 3) [0.49139968 0.48215841 0.44653091] [0.24703223 0.24348513 0.26158784] Depending on your use case, we can normalize the test/validation set with the parameters found on the train set, though in practice, for image recognition problems, we use the same normalization parameters on both the train and validation set, and apply it to test set. The steps are: Calculate the mean and std using the method above. Divide the training/validation/test set by 255. Normalize it using the values found. Note step 2 can be skipped if the normalization method in the library does a division of 255 internally. TRANSFORMS_with_normalization = transforms . Compose ( [ transforms . Normalize ( mean = mean_std_cifar [ \"mean\" ], std = mean_std_cifar [ \"std\" ] ), transforms . ToTensor (), ] ) trainset_cifar10 = datasets . CIFAR10 ( root = \"./data\" , train = True , download = True , transform = TRANSFORMS_with_normalization ) testset_cifar10 = datasets . CIFAR10 ( root = \"./data\" , train = False , download = True , transform = TRANSFORMS_with_normalization ) train_images_cifar10 = np . asarray ( trainset_cifar10 . data ) # (50000, 32, 32, 3) test_images_cifar10 = np . asarray ( testset_cifar10 . data ) # (10000, 32, 32, 3) Files already downloaded and verified Files already downloaded and verified","title":"CIFAR-10 (RGB)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/image_normalization/Image_Normalization_and_Standardization/#mnist-grayscale","text":"We next see an example of calculating the mean and standard deviation of MNIST, which is of one channel (grayscale). Mean : 0.1307 Standard Deviation : 0.3081 We will code a function to calculate the mean and standard deviation of a batch of images. # mnist trainset_mnist = datasets . MNIST ( root = \"./data/\" , train = True , download = True , transform = TRANSFORMS ) testset_mnist = datasets . MNIST ( root = \"./data\" , train = False , download = True , transform = TRANSFORMS ) train_images_mnist = np . asarray ( trainset_mnist . data ) # (60000, 28, 28) test_images_mnist = np . asarray ( testset_mnist . data ) # (10000, 28, 28) mean_std_mnist = calcMeanStd ( train_images_mnist ) print ( mean_std_mnist ) {'mean': (0.1306604762738429,), 'std': (0.3081078038564622,)} print ( trainset_mnist . data . float () . mean () / 255 ) print ( trainset_mnist . data . float () . std () / 255 ) tensor(0.1307) tensor(0.3081)","title":"MNIST (Grayscale)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/image_normalization/Image_Normalization_and_Standardization/#references","text":"To read up more on how others do it efficiently , please have a read below. https://www.kaggle.com/kozodoi/seti-mean-and-std-of-new-data/notebook https://www.kaggle.com/kozodoi/computing-dataset-mean-and-std https://forums.fast.ai/t/calculating-our-own-image-stats-imagenet-stats-cifar-stats-etc/40355/3 https://github.com/JoshVarty/CancerDetection/blob/master/01_ImageStats.ipynb https://forums.fast.ai/t/calculating-new-stats/31214 https://forums.fast.ai/t/calcuating-the-mean-and-standard-deviation-for-normalize/62883/13 https://www.kaggle.com/c/ranzcr-clip-catheter-line-classification/discussion/211039 https://stackoverflow.com/questions/58151507/why-pytorch-officially-use-mean-0-485-0-456-0-406-and-std-0-229-0-224-0-2 https://stackoverflow.com/questions/65699020/calculate-standard-deviation-for-grayscale-imagenet-pixel-values-with-rotation-m/65717887#65717887 https://stackoverflow.com/questions/66678052/how-to-calculate-the-mean-and-the-std-of-cifar10-data https://drive.google.com/drive/u/1/folders/1Gum3vsRsKKRSFZ1hyKaPTiVs1AUAmdKD https://stackoverflow.com/questions/50710493/cifar-10-meaningless-normalization-values https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/6 https://github.com/kuangliu/pytorch-cifar/issues/19 https://github.com/Armour/pytorch-nn-practice/blob/master/utils/meanstd.py","title":"References"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/importance_of_model_calibration_and_interpretability_in_healthcare/","text":"Model Calibration Model Interpretation","title":"Importance of model calibration and interpretability in healthcare"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/model_interpretation/","text":"Interpretating what Convolutional Neural Networks Learn On the Importance of Model Interpretability in Healthcare When we started out on our Machine Learning Journey, most of us have seen authors describe the conundrum of the trade off between prediction performance and a model (hypothesis)'s interpretability 1 . The general consensus, though not always correct, is that more complex models will have high performance measures but low interpretability and less complex models, the opposite. One might ask, when should one consider the usage of a complex or a simpler one? Here is a rule of thumb for you to follow. If the only interest is in prediction , for example, one company seeks to develop an algorithm that predicts the crypto price , then it is likely that the performance measure should be maximized over interpretability. On the other hand, if our interest is in inference 2 , for example in a healthcare setting where our medical use case is to predict whether a patient has melanoma (skin cancer) , then interpretability is more important that high performance . This is because the models are really not the only one making the decision, healthcare practitioners will need to understand the cause of the decision made by the model. In short, doctors wanted to know and agree on which particular area of the skin cell propels the model to make the decision that it is cancerous or not. One more point, can help to do error analysis on where the model did wrong. For example, a beginner trained a model to classify red and white blood cells, started from MNIST, he naturally greyed out the blood cells and received poor results. Doing some error analysis to interpret what went wrong easily tells us that by greying out the cells, the model get confused because they looked very similar, one important feature (i.e. color) is missing. For more understanding in this section, the book 3 Interpretable Machine Learning by Christoph Molnar is a good read. Computer Vision and Convolutional Neural Networks The computer vision has seen a bloom in the recent decade, empowering many use cases, including but not limited to the healthcare, automobile and facial recoginition industry . Most computer vision problems uses a type of neural networks Convolutional Neural Networks (CNN) , though recent breakthroughs show more promising results in vision transformers 4 . We will however, focus more on CNN in this section. For the longest time, CNNs are regarded as black box model simply because it is very complex and hence difficult to interpret . However, in recent times, as the need to interpret models grows, there are quite some methods to give a glimpse of what your CNN is looking at. CNN is a black box? Neural Networks are well defined mathematically, so why we cannot use the same way we do to say Logistic Regression to interpret the model? Well ... the feature importance is not so easy to decode as neural networks in computer vision are interpreted pixel level and it is not logical to derive feature importance at a pixel level. We need something at a spatial level. For example, we plot a grayscale image of a number 3 taken from MNIST by pixel level (i.e. \\(28 \\times 28\\) ), then it is not immediately obvious how we should recover the \"importance\" of any single pixel. MNIST pixel level plot; By Hongnan G. High level understanding of CNN The below is referenced from the Interpretable Machine Learning . We start off with the question, why cannot we use a normal model say, SVM or Logistic Regression to predict a cat image? Can't we just flatten the pixels and feed it as input to the models? Flattened pixels lose spatial level information , it only encodes information sequentially and high level features are not captured. Intuition is that a cat is a cat because of its eyes and ears (example) but when flattened these features may not be clustered together. We may need insane Feature Engineering to make classical ML models work (i.e. if you can re-construct the features of a cat's eyes using the flattened pixels then you may be successful). The power of CNN is that it learns high-level spatial features such as colors, edges and patterns that is unique to the image. This is enabled by the number of hidden layers that did many transformations to the inputs. So in a sense, the hidden layers of CNN are implicitly performing feature engineering . Let us detail a high level outline of a \"life cycle of a CNN\". The input (image) is usually of size \\((C, H, W)\\) is fed into the CNN. Note we do not flatten the image . In these CNN layers , the network first learns simple features such as the cat's edges and shapes, then as it progress to later layers, it learns highly abstract features such as more complex textures and patterns . After propagating to the last layer of the Convolutional Layer , we will then use a type of pooling and flatten the learned features and connect it to fully connected layers and predict the classes. Cat and CNN; By Hongnan G. CNN Interpretation Feature Visualization Through Convolutional Layers As mentioned in the previous section on the high level overview of CNN, an immediate solution is to ask if we can visualize what each layer's output is showing. This method is useful for understanding: How successive CNN layers transform their inputs. What each combination of filters does, good for having an intuition of whether the filter detects edges, shapes or more. Visualizing these filters can give us an understanding of the visual pattern that the CNN is capturing. Visualization Here is a visual of the conv layers' outputs. VGG16 Conv layers on a Cat; By Hongnan G. Takeaways Our takeaways are: The first few layers act as a collection of various edge and shape detectors and the activations retain almost all of the information from the original input image. As you go deeper, the layers begin to encode high and abstract features, the features become less \"informative and obvious\" and more \"generic\" (more on this intuition later). The sparsity of the activations increases with the depth of the layer: in the first layer, almost all filters are activated by the input image, but in the following layers, more and more filters are blank. This means the pattern encoded by the filter isn't found in the input image. Intuition As Francis Chollet mentioned, a deep CNN acts as an information distillation pipeline , but what is it? Why is it that as you go deeper, the image of a cat looks less precise and less like a real cat ? The analogy I use (similar to hise) gives you intuition: Imagine you were tasked to recognize a cat, you will do so instantly. Now you are also tasked to draw a cat, surely you can do so if you can recognize it? You started to draw a cat and compare it with a real cat. You realize that we cannot really remember the specific details of a cat but we can draw the abstract (generic) cat. The neural networks is like our brain, where we manage to recognize an image by filtering out the irrelevant details and transform it to high-level abstract features . This is what happens to a CNN and this is ideal! We do not want the model to remember too specific details of an image in fear of it not being able to generalize. A cat image from me A cat image from Unsplash Readings Readings over this section: Fran\u00e7ois Chollet: Deep Learning With Python pp.262-267 Christoph Molnar: Interpretable Machine Learning section. 10.1 Gradcam Interpret decision by determining which feature in our inputs had the highest contribution. If model predicted a cat, is it the eyes, ears or body shape that defined the class? Gradients can be very useful in this. Intuition is that gradients measure the effect on the outputs caused by some inputs. i.e. \\(y = f(x) = 2x\\) , then every change of 1 unit of change in \\(x\\) causes \\(2\\) units of change in our output \\(y\\) . The gradient is 2 here and measures the rate of change of \\(y\\) with respect to \\(x\\) . The same analogy applies here, can we find the pixels \\(x\\) in the image that contributes to the target \\(y\\) ? In practice however, we often denote a loss function \\(\\mathcal{L}(\\hat{f(\\mathbf{x})}, \\mathbf{y})\\) to minimize it and we can compute the gradient of this loss function with respect to the inputs. That is to say, if our loss \\(\\mathcal{L}\\) is low, then our model is doing something right and we can examine the gradients of the loss with respect to \\(x\\) to find out more. If we are interested in the cat class, we focus only on the \\(y_{cat}\\) . Feature maps of a cat: \\(A_1, A_2, ..., A_k\\) , each contributes in making the final decision in what \\(\\hat{y}\\) is. Computing gradient of \\(y_{cat}\\) with respect to \\(A_k\\) will give us the rate of change of the feature maps with respect to the target. For each feature map, we compute the gradients. For example if we have 8 32 by 32 feature maps, we compute gradients for all \\(8 x 32 x 32\\) pixels and average them channel wise. Now we have a single 32 by 32 feature map with all the gradient info, we then apply ReLU to it, where we set negative values to 0 because we are only interested in the class cat. i.e. negative values in gradient does not mean non-importance, it only pulls the prediction to the other classes. Now we have a 32 by 32 feature map with only positive values at certain areas, we need to map it back to the original image. For example if the original image of the cat is 320 x 320, then we need to scale it back to overlay back to the original image. The overlayed image will show a heatmap on where the gradients are non-negative, highlighting areas of focus. Gradcam 1 Gradcam 2 References https://christophm.github.io/interpretable-ml-book/ https://distill.pub/2017/feature-visualization/ Deep Learning with Python by Francois Chollet An Introduction to Statistical Learning, James, G., Witten, D., Hastie, T., & Tibshirani, R. pp.24-25 \u21a9 Note that the difference between inference and prediction is that inference can be thought of as one step beyond prediction, where we are not only concerned with the outputs of our model but also want to be able to extract a meaningful relationship between our input features and our predictions. Inference may be understood as prediction in the ML community, but not in the statistics community. \u21a9 https://christophm.github.io/interpretable-ml-book/ \u21a9 https://en.wikipedia.org/wiki/Vision_transformer \u21a9","title":"Model interpretation"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/model_interpretation/#interpretating-what-convolutional-neural-networks-learn","text":"","title":"Interpretating what Convolutional Neural Networks Learn"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/model_interpretation/#on-the-importance-of-model-interpretability-in-healthcare","text":"When we started out on our Machine Learning Journey, most of us have seen authors describe the conundrum of the trade off between prediction performance and a model (hypothesis)'s interpretability 1 . The general consensus, though not always correct, is that more complex models will have high performance measures but low interpretability and less complex models, the opposite. One might ask, when should one consider the usage of a complex or a simpler one? Here is a rule of thumb for you to follow. If the only interest is in prediction , for example, one company seeks to develop an algorithm that predicts the crypto price , then it is likely that the performance measure should be maximized over interpretability. On the other hand, if our interest is in inference 2 , for example in a healthcare setting where our medical use case is to predict whether a patient has melanoma (skin cancer) , then interpretability is more important that high performance . This is because the models are really not the only one making the decision, healthcare practitioners will need to understand the cause of the decision made by the model. In short, doctors wanted to know and agree on which particular area of the skin cell propels the model to make the decision that it is cancerous or not. One more point, can help to do error analysis on where the model did wrong. For example, a beginner trained a model to classify red and white blood cells, started from MNIST, he naturally greyed out the blood cells and received poor results. Doing some error analysis to interpret what went wrong easily tells us that by greying out the cells, the model get confused because they looked very similar, one important feature (i.e. color) is missing. For more understanding in this section, the book 3 Interpretable Machine Learning by Christoph Molnar is a good read.","title":"On the Importance of Model Interpretability in Healthcare"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/model_interpretation/#computer-vision-and-convolutional-neural-networks","text":"The computer vision has seen a bloom in the recent decade, empowering many use cases, including but not limited to the healthcare, automobile and facial recoginition industry . Most computer vision problems uses a type of neural networks Convolutional Neural Networks (CNN) , though recent breakthroughs show more promising results in vision transformers 4 . We will however, focus more on CNN in this section. For the longest time, CNNs are regarded as black box model simply because it is very complex and hence difficult to interpret . However, in recent times, as the need to interpret models grows, there are quite some methods to give a glimpse of what your CNN is looking at.","title":"Computer Vision and Convolutional Neural Networks"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/model_interpretation/#cnn-is-a-black-box","text":"Neural Networks are well defined mathematically, so why we cannot use the same way we do to say Logistic Regression to interpret the model? Well ... the feature importance is not so easy to decode as neural networks in computer vision are interpreted pixel level and it is not logical to derive feature importance at a pixel level. We need something at a spatial level. For example, we plot a grayscale image of a number 3 taken from MNIST by pixel level (i.e. \\(28 \\times 28\\) ), then it is not immediately obvious how we should recover the \"importance\" of any single pixel. MNIST pixel level plot; By Hongnan G.","title":"CNN is a black box?"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/model_interpretation/#high-level-understanding-of-cnn","text":"The below is referenced from the Interpretable Machine Learning . We start off with the question, why cannot we use a normal model say, SVM or Logistic Regression to predict a cat image? Can't we just flatten the pixels and feed it as input to the models? Flattened pixels lose spatial level information , it only encodes information sequentially and high level features are not captured. Intuition is that a cat is a cat because of its eyes and ears (example) but when flattened these features may not be clustered together. We may need insane Feature Engineering to make classical ML models work (i.e. if you can re-construct the features of a cat's eyes using the flattened pixels then you may be successful). The power of CNN is that it learns high-level spatial features such as colors, edges and patterns that is unique to the image. This is enabled by the number of hidden layers that did many transformations to the inputs. So in a sense, the hidden layers of CNN are implicitly performing feature engineering . Let us detail a high level outline of a \"life cycle of a CNN\". The input (image) is usually of size \\((C, H, W)\\) is fed into the CNN. Note we do not flatten the image . In these CNN layers , the network first learns simple features such as the cat's edges and shapes, then as it progress to later layers, it learns highly abstract features such as more complex textures and patterns . After propagating to the last layer of the Convolutional Layer , we will then use a type of pooling and flatten the learned features and connect it to fully connected layers and predict the classes. Cat and CNN; By Hongnan G.","title":"High level understanding of CNN"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/model_interpretation/#cnn-interpretation","text":"","title":"CNN Interpretation"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/model_interpretation/#feature-visualization-through-convolutional-layers","text":"As mentioned in the previous section on the high level overview of CNN, an immediate solution is to ask if we can visualize what each layer's output is showing. This method is useful for understanding: How successive CNN layers transform their inputs. What each combination of filters does, good for having an intuition of whether the filter detects edges, shapes or more. Visualizing these filters can give us an understanding of the visual pattern that the CNN is capturing.","title":"Feature Visualization Through Convolutional Layers"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/model_interpretation/#visualization","text":"Here is a visual of the conv layers' outputs. VGG16 Conv layers on a Cat; By Hongnan G.","title":"Visualization"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/model_interpretation/#takeaways","text":"Our takeaways are: The first few layers act as a collection of various edge and shape detectors and the activations retain almost all of the information from the original input image. As you go deeper, the layers begin to encode high and abstract features, the features become less \"informative and obvious\" and more \"generic\" (more on this intuition later). The sparsity of the activations increases with the depth of the layer: in the first layer, almost all filters are activated by the input image, but in the following layers, more and more filters are blank. This means the pattern encoded by the filter isn't found in the input image.","title":"Takeaways"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/model_interpretation/#intuition","text":"As Francis Chollet mentioned, a deep CNN acts as an information distillation pipeline , but what is it? Why is it that as you go deeper, the image of a cat looks less precise and less like a real cat ? The analogy I use (similar to hise) gives you intuition: Imagine you were tasked to recognize a cat, you will do so instantly. Now you are also tasked to draw a cat, surely you can do so if you can recognize it? You started to draw a cat and compare it with a real cat. You realize that we cannot really remember the specific details of a cat but we can draw the abstract (generic) cat. The neural networks is like our brain, where we manage to recognize an image by filtering out the irrelevant details and transform it to high-level abstract features . This is what happens to a CNN and this is ideal! We do not want the model to remember too specific details of an image in fear of it not being able to generalize. A cat image from me A cat image from Unsplash","title":"Intuition"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/model_interpretation/#readings","text":"Readings over this section: Fran\u00e7ois Chollet: Deep Learning With Python pp.262-267 Christoph Molnar: Interpretable Machine Learning section. 10.1","title":"Readings"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/model_interpretation/#gradcam","text":"Interpret decision by determining which feature in our inputs had the highest contribution. If model predicted a cat, is it the eyes, ears or body shape that defined the class? Gradients can be very useful in this. Intuition is that gradients measure the effect on the outputs caused by some inputs. i.e. \\(y = f(x) = 2x\\) , then every change of 1 unit of change in \\(x\\) causes \\(2\\) units of change in our output \\(y\\) . The gradient is 2 here and measures the rate of change of \\(y\\) with respect to \\(x\\) . The same analogy applies here, can we find the pixels \\(x\\) in the image that contributes to the target \\(y\\) ? In practice however, we often denote a loss function \\(\\mathcal{L}(\\hat{f(\\mathbf{x})}, \\mathbf{y})\\) to minimize it and we can compute the gradient of this loss function with respect to the inputs. That is to say, if our loss \\(\\mathcal{L}\\) is low, then our model is doing something right and we can examine the gradients of the loss with respect to \\(x\\) to find out more. If we are interested in the cat class, we focus only on the \\(y_{cat}\\) . Feature maps of a cat: \\(A_1, A_2, ..., A_k\\) , each contributes in making the final decision in what \\(\\hat{y}\\) is. Computing gradient of \\(y_{cat}\\) with respect to \\(A_k\\) will give us the rate of change of the feature maps with respect to the target. For each feature map, we compute the gradients. For example if we have 8 32 by 32 feature maps, we compute gradients for all \\(8 x 32 x 32\\) pixels and average them channel wise. Now we have a single 32 by 32 feature map with all the gradient info, we then apply ReLU to it, where we set negative values to 0 because we are only interested in the class cat. i.e. negative values in gradient does not mean non-importance, it only pulls the prediction to the other classes. Now we have a 32 by 32 feature map with only positive values at certain areas, we need to map it back to the original image. For example if the original image of the cat is 320 x 320, then we need to scale it back to overlay back to the original image. The overlayed image will show a heatmap on where the gradients are non-negative, highlighting areas of focus. Gradcam 1 Gradcam 2","title":"Gradcam"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/model_interpretation/#references","text":"https://christophm.github.io/interpretable-ml-book/ https://distill.pub/2017/feature-visualization/ Deep Learning with Python by Francois Chollet An Introduction to Statistical Learning, James, G., Witten, D., Hastie, T., & Tibshirani, R. pp.24-25 \u21a9 Note that the difference between inference and prediction is that inference can be thought of as one step beyond prediction, where we are not only concerned with the outputs of our model but also want to be able to extract a meaningful relationship between our input features and our predictions. Inference may be understood as prediction in the ML community, but not in the statistics community. \u21a9 https://christophm.github.io/interpretable-ml-book/ \u21a9 https://en.wikipedia.org/wiki/Vision_transformer \u21a9","title":"References"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/","text":"EDA Visualizations for Image Recognition (Feature Map Activation) Dependencies and Imports from typing import Dict import matplotlib.pyplot as plt import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import timm import torch import torchvision from torchvision.models.feature_extraction import ( create_feature_extractor , get_graph_node_names ) % matplotlib inline import glob import os import random from math import ceil from PIL import Image plt . rcParams [ \"figure.figsize\" ] = 16 , 8 import glob from torchvision.models import * import cv2 import matplotlib.pyplot as plt import numpy as np import PIL from IPython.core.interactiveshell import InteractiveShell from PIL import Image InteractiveShell . ast_node_interactivity = \"all\" # importing modules import urllib.request from typing import * from PIL import Image Import Custom Utils Import utils function as script. % cd .. import utils C:\\Users\\reighns\\reighns_ml\\reighns_ml_blog\\docs\\reighns_ml_journey\\deep_learning\\computer_vision\\general\\neural_network_interpretation Call Config from Utils device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) logger = utils . init_logger () utils . seed_all () Using Seed Number 1992 Load Images We load the images and plot the original image. image_paths = glob . glob ( \"./images/animals/*.*\" ) # elephant has RGBA idk why so need convert images = list ( map ( lambda x : Image . open ( x ) . convert ( \"RGB\" ), image_paths )) utils . subplot ( images , title = \"inputs\" , rows_titles = [ \"cat\" , \"dog_and_cat\" , \"african_elephant\" ], nrows = 1 , ncols = 3 , ) Transforms Params (ImageNet) class NormalizeInverse ( torchvision . transforms . Normalize ): \"\"\" Undoes the normalization and returns the reconstructed images in the input domain. https://github.com/FrancescoSaverioZuppichini/A-journey-into-Convolutional-Neural-Network-visualization- \"\"\" def __init__ ( self , mean , std ): mean = torch . Tensor ( mean ) std = torch . Tensor ( std ) std_inv = 1 / ( std + 1e-7 ) mean_inv = - mean * std_inv super () . __init__ ( mean = mean_inv , std = std_inv ) def __call__ ( self , tensor ): return super () . __call__ ( tensor . clone ()) imagenet_mean : List [ float ] = [ 0.485 , 0.456 , 0.406 ] imagenet_std : List [ float ] = [ 0.229 , 0.224 , 0.225 ] image_size : int = 224 normalized_transform = torchvision . transforms . Compose ( [ torchvision . transforms . Resize (( image_size , image_size )), torchvision . transforms . ToTensor (), torchvision . transforms . Normalize ( mean = imagenet_mean , std = imagenet_std ), ] ) inverse_normalized_transform = torchvision . transforms . Compose ( [ torchvision . transforms . Resize (( image_size , image_size )), torchvision . transforms . ToTensor (), NormalizeInverse ( mean = imagenet_mean , std = imagenet_std ), ] ) # We use torchvision's transform to transform the cat image with resize and normalization. # Conveniently, also making it channel first! cat_tensor = normalized_transform ( images [ 0 ]) cat_and_dog_tensor = normalized_transform ( images [ 1 ]) elephant_tensor = normalized_transform ( images [ 2 ]) # assert cat_tensor.shape[0] == cat_and_dog_tensor.shape[0] == 3, \"PyTorch expects Channel First!\" # Now feature_extractor expects batch_size x C x H x W, so we expand one dimension in the 0th dim # and put them on device cat_tensor = cat_tensor . unsqueeze ( dim = 0 ) . to ( device ) cat_and_dog_tensor = cat_and_dog_tensor . unsqueeze ( dim = 0 ) . to ( device ) elephant_tensor = elephant_tensor . unsqueeze ( dim = 0 ) . to ( device ) # logger.info(f\"\\n\\ncat_tensor's shape:\\n{cat_tensor.shape}\\n\\ndog_tensor's shape:\\n{cat_and_dog_tensor.shape}\") images_dict : Dict [ str , torch . Tensor ] = { \"cat\" : cat_tensor , \"cat_and_dog\" : cat_and_dog_tensor , \"elephant\" : elephant_tensor } Working with Torch Models Load the Models alexnet_ = alexnet ( pretrained = True ) . to ( device ) vgg16_ = vgg16 ( pretrained = True ) . to ( device ) Torch Summary import torchsummary def torchsummary_wrapper ( model , image_size : Tuple [ int , int , int ] ) -> torchsummary . model_statistics . ModelStatistics : \"\"\"A torch wrapper to print out layers of a Model. Args: model (CustomNeuralNet): Model. image_size (Tuple[int, int, int]): Image size as a tuple of (channels, height, width). Returns: model_summary (torchsummary.model_statistics.ModelStatistics): Model summary. \"\"\" model_summary = torchsummary . summary ( model , image_size ) return model_summary alexnet_model_summary = torchsummary_wrapper ( alexnet_ , image_size = ( 3 , 224 , 224 )) ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== \u251c\u2500Sequential: 1-1 [-1, 256, 6, 6] -- | \u2514\u2500Conv2d: 2-1 [-1, 64, 55, 55] 23,296 | \u2514\u2500ReLU: 2-2 [-1, 64, 55, 55] -- | \u2514\u2500MaxPool2d: 2-3 [-1, 64, 27, 27] -- | \u2514\u2500Conv2d: 2-4 [-1, 192, 27, 27] 307,392 | \u2514\u2500ReLU: 2-5 [-1, 192, 27, 27] -- | \u2514\u2500MaxPool2d: 2-6 [-1, 192, 13, 13] -- | \u2514\u2500Conv2d: 2-7 [-1, 384, 13, 13] 663,936 | \u2514\u2500ReLU: 2-8 [-1, 384, 13, 13] -- | \u2514\u2500Conv2d: 2-9 [-1, 256, 13, 13] 884,992 | \u2514\u2500ReLU: 2-10 [-1, 256, 13, 13] -- | \u2514\u2500Conv2d: 2-11 [-1, 256, 13, 13] 590,080 | \u2514\u2500ReLU: 2-12 [-1, 256, 13, 13] -- | \u2514\u2500MaxPool2d: 2-13 [-1, 256, 6, 6] -- \u251c\u2500AdaptiveAvgPool2d: 1-2 [-1, 256, 6, 6] -- \u251c\u2500Sequential: 1-3 [-1, 1000] -- | \u2514\u2500Dropout: 2-14 [-1, 9216] -- | \u2514\u2500Linear: 2-15 [-1, 4096] 37,752,832 | \u2514\u2500ReLU: 2-16 [-1, 4096] -- | \u2514\u2500Dropout: 2-17 [-1, 4096] -- | \u2514\u2500Linear: 2-18 [-1, 4096] 16,781,312 | \u2514\u2500ReLU: 2-19 [-1, 4096] -- | \u2514\u2500Linear: 2-20 [-1, 1000] 4,097,000 ========================================================================================== Total params: 61,100,840 Trainable params: 61,100,840 Non-trainable params: 0 Total mult-adds (M): 775.28 ========================================================================================== Input size (MB): 0.57 Forward/backward pass size (MB): 3.77 Params size (MB): 233.08 Estimated Total Size (MB): 237.43 ========================================================================================== vgg16_model_summary = torchsummary_wrapper ( vgg16_ , image_size = ( 3 , 224 , 224 )) ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== \u251c\u2500Sequential: 1-1 [-1, 512, 7, 7] -- | \u2514\u2500Conv2d: 2-1 [-1, 64, 224, 224] 1,792 | \u2514\u2500ReLU: 2-2 [-1, 64, 224, 224] -- | \u2514\u2500Conv2d: 2-3 [-1, 64, 224, 224] 36,928 | \u2514\u2500ReLU: 2-4 [-1, 64, 224, 224] -- | \u2514\u2500MaxPool2d: 2-5 [-1, 64, 112, 112] -- | \u2514\u2500Conv2d: 2-6 [-1, 128, 112, 112] 73,856 | \u2514\u2500ReLU: 2-7 [-1, 128, 112, 112] -- | \u2514\u2500Conv2d: 2-8 [-1, 128, 112, 112] 147,584 | \u2514\u2500ReLU: 2-9 [-1, 128, 112, 112] -- | \u2514\u2500MaxPool2d: 2-10 [-1, 128, 56, 56] -- | \u2514\u2500Conv2d: 2-11 [-1, 256, 56, 56] 295,168 | \u2514\u2500ReLU: 2-12 [-1, 256, 56, 56] -- | \u2514\u2500Conv2d: 2-13 [-1, 256, 56, 56] 590,080 | \u2514\u2500ReLU: 2-14 [-1, 256, 56, 56] -- | \u2514\u2500Conv2d: 2-15 [-1, 256, 56, 56] 590,080 | \u2514\u2500ReLU: 2-16 [-1, 256, 56, 56] -- | \u2514\u2500MaxPool2d: 2-17 [-1, 256, 28, 28] -- | \u2514\u2500Conv2d: 2-18 [-1, 512, 28, 28] 1,180,160 | \u2514\u2500ReLU: 2-19 [-1, 512, 28, 28] -- | \u2514\u2500Conv2d: 2-20 [-1, 512, 28, 28] 2,359,808 | \u2514\u2500ReLU: 2-21 [-1, 512, 28, 28] -- | \u2514\u2500Conv2d: 2-22 [-1, 512, 28, 28] 2,359,808 | \u2514\u2500ReLU: 2-23 [-1, 512, 28, 28] -- | \u2514\u2500MaxPool2d: 2-24 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-25 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-26 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-27 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-28 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-29 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-30 [-1, 512, 14, 14] -- | \u2514\u2500MaxPool2d: 2-31 [-1, 512, 7, 7] -- \u251c\u2500AdaptiveAvgPool2d: 1-2 [-1, 512, 7, 7] -- \u251c\u2500Sequential: 1-3 [-1, 1000] -- | \u2514\u2500Linear: 2-32 [-1, 4096] 102,764,544 | \u2514\u2500ReLU: 2-33 [-1, 4096] -- | \u2514\u2500Dropout: 2-34 [-1, 4096] -- | \u2514\u2500Linear: 2-35 [-1, 4096] 16,781,312 | \u2514\u2500ReLU: 2-36 [-1, 4096] -- | \u2514\u2500Dropout: 2-37 [-1, 4096] -- | \u2514\u2500Linear: 2-38 [-1, 1000] 4,097,000 ========================================================================================== Total params: 138,357,544 Trainable params: 138,357,544 Non-trainable params: 0 Total mult-adds (G): 15.61 ========================================================================================== Input size (MB): 0.57 Forward/backward pass size (MB): 103.43 Params size (MB): 527.79 Estimated Total Size (MB): 631.80 ========================================================================================== Forward Backward Hooks def forward_hook ( module_name : str , forward_activations : Dict [ str , torch . Tensor ] ) -> Callable : \"\"\"In-place forward hook to save activations of a layer. Args: module_name (str): The name of the layer to hook. forward_activations (Dict[str, torch.Tensor]): The dictionary to save the activations. Returns: forward_hook_: The forward hook function. \"\"\" def forward_hook_ ( module , input , output ): # Save forward feature map activations forward_activations [ module_name ] = output . detach () return forward_hook_ def backward_hook ( module_name : str , backward_gradients : Dict [ str , torch . Tensor ] ) -> Callable : \"\"\"In-place backward hook to save gradients of a layer. Args: module_name (str): The name of the layer to hook. backward_gradients (Dict[str, torch.Tensor]): The dictionary to save the gradients. Returns: Callable: The backward hook function. \"\"\" def backward_hook_ ( module , grad_input , grad_output ): # Save the gradients correspond to the feature maps # This will only be saved when backwards is called. backward_gradients [ module_name ] = grad_output [ 0 ] . detach () return backward_hook_ We define a function to get feature map activations. def get_feature_maps_activations ( model : Callable , image : torch . Tensor ) -> Union [ List [ Callable ], Dict [ str , torch . Tensor ]]: \"\"\"Get feature maps and activations from a model. Args: model (Callable): A model. image (torch.Tensor): The input image. Returns: handlers List[Callable]: A list of handlers. forward_activations Dict[str, torch.Tensor]: A dictionary of forward activations. \"\"\" forward_activations = OrderedDict () handlers = [] for name , module in model . named_modules (): module_name = name + \"_\" + str ( module ) handlers . append ( module . register_forward_hook ( forward_hook ( module_name , forward_activations ) ) ) model = model . eval () y_logits = model ( image ) return handlers , forward_activations _ , alexnet_f = get_feature_maps_activations ( alexnet_ , image = images_dict [ \"cat\" ]) _ , vgg16_f = get_feature_maps_activations ( vgg16_ , image = images_dict [ \"cat\" ]) First Conv Layer Output Alexnet We will get the first convolutional layer's output as follows. We note the following stats: There are 64 kernels. Each kernel is of size 11 by 11. You can assume that each kernel is a 2d-image in grayscale. Therefore, the first conv layer output is also a stack of 64 2d-image, output by the 64 kernels respectively. We traditionally call them feature maps . Each 2d output is of 55 by 55 shape. You can assume that this is a 2d-image with dimensions 55 by 55. Note you can calculate by hand that 55 by 55 is correct. We can squeeze the first dimension as this is not needed since we are dealing with 1 image. first_conv_layer_output = alexnet_f [ \"features.0_Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\" ] print ( first_conv_layer_output . shape ) first_conv_layer_output = first_conv_layer_output . squeeze ( dim = 0 ) print ( first_conv_layer_output . shape ) torch.Size([1, 64, 55, 55]) torch.Size([64, 55, 55]) For plotting, we will use the repo 's code verbatim. Note we set number of columns and rows to be 8 by 8 to see all 64 feature maps. plt . rcParams [ \"figure.figsize\" ] = 32 , 24 utils . subplot ( first_conv_layer_output , utils . tensor2img , title = \"features.0_Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\" , ncols = 8 , nrows = 8 ) # plt.rcParams[\"figure.figsize\"]= 32, 24 # utils.subplot(f[\"features.2_MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\"][0], utils.tensor2img, title=\"eatures.2_MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\", ncols=8, nrows=8) First Conv Layer Output VGG16 first_conv_layer_output = vgg16_f [ \"features.0_Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\" ] print ( first_conv_layer_output . shape ) first_conv_layer_output = first_conv_layer_output . squeeze ( dim = 0 ) print ( first_conv_layer_output . shape ) torch.Size([1, 64, 224, 224]) torch.Size([64, 224, 224]) plt . rcParams [ \"figure.figsize\" ] = 32 , 24 utils . subplot ( first_conv_layer_output , utils . tensor2img , title = \"features.0_Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\" , ncols = 8 , nrows = 8 ) Mean and Sum Reduce of the Feature Maps In the above section, if there are 64 feature maps after a conv layer, we will plot all 64 feauture maps. In the next section, we can either sum or average all 64 feature maps to reduce them to 1 single feature map.","title":"Feature Map Activations (Part I)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/#eda-visualizations-for-image-recognition-feature-map-activation","text":"","title":"EDA Visualizations for Image Recognition (Feature Map Activation)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/#dependencies-and-imports","text":"from typing import Dict import matplotlib.pyplot as plt import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import timm import torch import torchvision from torchvision.models.feature_extraction import ( create_feature_extractor , get_graph_node_names ) % matplotlib inline import glob import os import random from math import ceil from PIL import Image plt . rcParams [ \"figure.figsize\" ] = 16 , 8 import glob from torchvision.models import * import cv2 import matplotlib.pyplot as plt import numpy as np import PIL from IPython.core.interactiveshell import InteractiveShell from PIL import Image InteractiveShell . ast_node_interactivity = \"all\" # importing modules import urllib.request from typing import * from PIL import Image","title":"Dependencies and Imports"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/#import-custom-utils","text":"Import utils function as script. % cd .. import utils C:\\Users\\reighns\\reighns_ml\\reighns_ml_blog\\docs\\reighns_ml_journey\\deep_learning\\computer_vision\\general\\neural_network_interpretation","title":"Import Custom Utils"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/#call-config-from-utils","text":"device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) logger = utils . init_logger () utils . seed_all () Using Seed Number 1992","title":"Call Config from Utils"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/#load-images","text":"We load the images and plot the original image. image_paths = glob . glob ( \"./images/animals/*.*\" ) # elephant has RGBA idk why so need convert images = list ( map ( lambda x : Image . open ( x ) . convert ( \"RGB\" ), image_paths )) utils . subplot ( images , title = \"inputs\" , rows_titles = [ \"cat\" , \"dog_and_cat\" , \"african_elephant\" ], nrows = 1 , ncols = 3 , )","title":"Load Images"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/#transforms-params-imagenet","text":"class NormalizeInverse ( torchvision . transforms . Normalize ): \"\"\" Undoes the normalization and returns the reconstructed images in the input domain. https://github.com/FrancescoSaverioZuppichini/A-journey-into-Convolutional-Neural-Network-visualization- \"\"\" def __init__ ( self , mean , std ): mean = torch . Tensor ( mean ) std = torch . Tensor ( std ) std_inv = 1 / ( std + 1e-7 ) mean_inv = - mean * std_inv super () . __init__ ( mean = mean_inv , std = std_inv ) def __call__ ( self , tensor ): return super () . __call__ ( tensor . clone ()) imagenet_mean : List [ float ] = [ 0.485 , 0.456 , 0.406 ] imagenet_std : List [ float ] = [ 0.229 , 0.224 , 0.225 ] image_size : int = 224 normalized_transform = torchvision . transforms . Compose ( [ torchvision . transforms . Resize (( image_size , image_size )), torchvision . transforms . ToTensor (), torchvision . transforms . Normalize ( mean = imagenet_mean , std = imagenet_std ), ] ) inverse_normalized_transform = torchvision . transforms . Compose ( [ torchvision . transforms . Resize (( image_size , image_size )), torchvision . transforms . ToTensor (), NormalizeInverse ( mean = imagenet_mean , std = imagenet_std ), ] ) # We use torchvision's transform to transform the cat image with resize and normalization. # Conveniently, also making it channel first! cat_tensor = normalized_transform ( images [ 0 ]) cat_and_dog_tensor = normalized_transform ( images [ 1 ]) elephant_tensor = normalized_transform ( images [ 2 ]) # assert cat_tensor.shape[0] == cat_and_dog_tensor.shape[0] == 3, \"PyTorch expects Channel First!\" # Now feature_extractor expects batch_size x C x H x W, so we expand one dimension in the 0th dim # and put them on device cat_tensor = cat_tensor . unsqueeze ( dim = 0 ) . to ( device ) cat_and_dog_tensor = cat_and_dog_tensor . unsqueeze ( dim = 0 ) . to ( device ) elephant_tensor = elephant_tensor . unsqueeze ( dim = 0 ) . to ( device ) # logger.info(f\"\\n\\ncat_tensor's shape:\\n{cat_tensor.shape}\\n\\ndog_tensor's shape:\\n{cat_and_dog_tensor.shape}\") images_dict : Dict [ str , torch . Tensor ] = { \"cat\" : cat_tensor , \"cat_and_dog\" : cat_and_dog_tensor , \"elephant\" : elephant_tensor }","title":"Transforms Params (ImageNet)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/#working-with-torch-models","text":"","title":"Working with Torch Models"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/#load-the-models","text":"alexnet_ = alexnet ( pretrained = True ) . to ( device ) vgg16_ = vgg16 ( pretrained = True ) . to ( device )","title":"Load the Models"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/#torch-summary","text":"import torchsummary def torchsummary_wrapper ( model , image_size : Tuple [ int , int , int ] ) -> torchsummary . model_statistics . ModelStatistics : \"\"\"A torch wrapper to print out layers of a Model. Args: model (CustomNeuralNet): Model. image_size (Tuple[int, int, int]): Image size as a tuple of (channels, height, width). Returns: model_summary (torchsummary.model_statistics.ModelStatistics): Model summary. \"\"\" model_summary = torchsummary . summary ( model , image_size ) return model_summary alexnet_model_summary = torchsummary_wrapper ( alexnet_ , image_size = ( 3 , 224 , 224 )) ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== \u251c\u2500Sequential: 1-1 [-1, 256, 6, 6] -- | \u2514\u2500Conv2d: 2-1 [-1, 64, 55, 55] 23,296 | \u2514\u2500ReLU: 2-2 [-1, 64, 55, 55] -- | \u2514\u2500MaxPool2d: 2-3 [-1, 64, 27, 27] -- | \u2514\u2500Conv2d: 2-4 [-1, 192, 27, 27] 307,392 | \u2514\u2500ReLU: 2-5 [-1, 192, 27, 27] -- | \u2514\u2500MaxPool2d: 2-6 [-1, 192, 13, 13] -- | \u2514\u2500Conv2d: 2-7 [-1, 384, 13, 13] 663,936 | \u2514\u2500ReLU: 2-8 [-1, 384, 13, 13] -- | \u2514\u2500Conv2d: 2-9 [-1, 256, 13, 13] 884,992 | \u2514\u2500ReLU: 2-10 [-1, 256, 13, 13] -- | \u2514\u2500Conv2d: 2-11 [-1, 256, 13, 13] 590,080 | \u2514\u2500ReLU: 2-12 [-1, 256, 13, 13] -- | \u2514\u2500MaxPool2d: 2-13 [-1, 256, 6, 6] -- \u251c\u2500AdaptiveAvgPool2d: 1-2 [-1, 256, 6, 6] -- \u251c\u2500Sequential: 1-3 [-1, 1000] -- | \u2514\u2500Dropout: 2-14 [-1, 9216] -- | \u2514\u2500Linear: 2-15 [-1, 4096] 37,752,832 | \u2514\u2500ReLU: 2-16 [-1, 4096] -- | \u2514\u2500Dropout: 2-17 [-1, 4096] -- | \u2514\u2500Linear: 2-18 [-1, 4096] 16,781,312 | \u2514\u2500ReLU: 2-19 [-1, 4096] -- | \u2514\u2500Linear: 2-20 [-1, 1000] 4,097,000 ========================================================================================== Total params: 61,100,840 Trainable params: 61,100,840 Non-trainable params: 0 Total mult-adds (M): 775.28 ========================================================================================== Input size (MB): 0.57 Forward/backward pass size (MB): 3.77 Params size (MB): 233.08 Estimated Total Size (MB): 237.43 ========================================================================================== vgg16_model_summary = torchsummary_wrapper ( vgg16_ , image_size = ( 3 , 224 , 224 )) ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== \u251c\u2500Sequential: 1-1 [-1, 512, 7, 7] -- | \u2514\u2500Conv2d: 2-1 [-1, 64, 224, 224] 1,792 | \u2514\u2500ReLU: 2-2 [-1, 64, 224, 224] -- | \u2514\u2500Conv2d: 2-3 [-1, 64, 224, 224] 36,928 | \u2514\u2500ReLU: 2-4 [-1, 64, 224, 224] -- | \u2514\u2500MaxPool2d: 2-5 [-1, 64, 112, 112] -- | \u2514\u2500Conv2d: 2-6 [-1, 128, 112, 112] 73,856 | \u2514\u2500ReLU: 2-7 [-1, 128, 112, 112] -- | \u2514\u2500Conv2d: 2-8 [-1, 128, 112, 112] 147,584 | \u2514\u2500ReLU: 2-9 [-1, 128, 112, 112] -- | \u2514\u2500MaxPool2d: 2-10 [-1, 128, 56, 56] -- | \u2514\u2500Conv2d: 2-11 [-1, 256, 56, 56] 295,168 | \u2514\u2500ReLU: 2-12 [-1, 256, 56, 56] -- | \u2514\u2500Conv2d: 2-13 [-1, 256, 56, 56] 590,080 | \u2514\u2500ReLU: 2-14 [-1, 256, 56, 56] -- | \u2514\u2500Conv2d: 2-15 [-1, 256, 56, 56] 590,080 | \u2514\u2500ReLU: 2-16 [-1, 256, 56, 56] -- | \u2514\u2500MaxPool2d: 2-17 [-1, 256, 28, 28] -- | \u2514\u2500Conv2d: 2-18 [-1, 512, 28, 28] 1,180,160 | \u2514\u2500ReLU: 2-19 [-1, 512, 28, 28] -- | \u2514\u2500Conv2d: 2-20 [-1, 512, 28, 28] 2,359,808 | \u2514\u2500ReLU: 2-21 [-1, 512, 28, 28] -- | \u2514\u2500Conv2d: 2-22 [-1, 512, 28, 28] 2,359,808 | \u2514\u2500ReLU: 2-23 [-1, 512, 28, 28] -- | \u2514\u2500MaxPool2d: 2-24 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-25 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-26 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-27 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-28 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-29 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-30 [-1, 512, 14, 14] -- | \u2514\u2500MaxPool2d: 2-31 [-1, 512, 7, 7] -- \u251c\u2500AdaptiveAvgPool2d: 1-2 [-1, 512, 7, 7] -- \u251c\u2500Sequential: 1-3 [-1, 1000] -- | \u2514\u2500Linear: 2-32 [-1, 4096] 102,764,544 | \u2514\u2500ReLU: 2-33 [-1, 4096] -- | \u2514\u2500Dropout: 2-34 [-1, 4096] -- | \u2514\u2500Linear: 2-35 [-1, 4096] 16,781,312 | \u2514\u2500ReLU: 2-36 [-1, 4096] -- | \u2514\u2500Dropout: 2-37 [-1, 4096] -- | \u2514\u2500Linear: 2-38 [-1, 1000] 4,097,000 ========================================================================================== Total params: 138,357,544 Trainable params: 138,357,544 Non-trainable params: 0 Total mult-adds (G): 15.61 ========================================================================================== Input size (MB): 0.57 Forward/backward pass size (MB): 103.43 Params size (MB): 527.79 Estimated Total Size (MB): 631.80 ==========================================================================================","title":"Torch Summary"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/#forward-backward-hooks","text":"def forward_hook ( module_name : str , forward_activations : Dict [ str , torch . Tensor ] ) -> Callable : \"\"\"In-place forward hook to save activations of a layer. Args: module_name (str): The name of the layer to hook. forward_activations (Dict[str, torch.Tensor]): The dictionary to save the activations. Returns: forward_hook_: The forward hook function. \"\"\" def forward_hook_ ( module , input , output ): # Save forward feature map activations forward_activations [ module_name ] = output . detach () return forward_hook_ def backward_hook ( module_name : str , backward_gradients : Dict [ str , torch . Tensor ] ) -> Callable : \"\"\"In-place backward hook to save gradients of a layer. Args: module_name (str): The name of the layer to hook. backward_gradients (Dict[str, torch.Tensor]): The dictionary to save the gradients. Returns: Callable: The backward hook function. \"\"\" def backward_hook_ ( module , grad_input , grad_output ): # Save the gradients correspond to the feature maps # This will only be saved when backwards is called. backward_gradients [ module_name ] = grad_output [ 0 ] . detach () return backward_hook_ We define a function to get feature map activations. def get_feature_maps_activations ( model : Callable , image : torch . Tensor ) -> Union [ List [ Callable ], Dict [ str , torch . Tensor ]]: \"\"\"Get feature maps and activations from a model. Args: model (Callable): A model. image (torch.Tensor): The input image. Returns: handlers List[Callable]: A list of handlers. forward_activations Dict[str, torch.Tensor]: A dictionary of forward activations. \"\"\" forward_activations = OrderedDict () handlers = [] for name , module in model . named_modules (): module_name = name + \"_\" + str ( module ) handlers . append ( module . register_forward_hook ( forward_hook ( module_name , forward_activations ) ) ) model = model . eval () y_logits = model ( image ) return handlers , forward_activations _ , alexnet_f = get_feature_maps_activations ( alexnet_ , image = images_dict [ \"cat\" ]) _ , vgg16_f = get_feature_maps_activations ( vgg16_ , image = images_dict [ \"cat\" ])","title":"Forward Backward Hooks"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/#first-conv-layer-output-alexnet","text":"We will get the first convolutional layer's output as follows. We note the following stats: There are 64 kernels. Each kernel is of size 11 by 11. You can assume that each kernel is a 2d-image in grayscale. Therefore, the first conv layer output is also a stack of 64 2d-image, output by the 64 kernels respectively. We traditionally call them feature maps . Each 2d output is of 55 by 55 shape. You can assume that this is a 2d-image with dimensions 55 by 55. Note you can calculate by hand that 55 by 55 is correct. We can squeeze the first dimension as this is not needed since we are dealing with 1 image. first_conv_layer_output = alexnet_f [ \"features.0_Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\" ] print ( first_conv_layer_output . shape ) first_conv_layer_output = first_conv_layer_output . squeeze ( dim = 0 ) print ( first_conv_layer_output . shape ) torch.Size([1, 64, 55, 55]) torch.Size([64, 55, 55]) For plotting, we will use the repo 's code verbatim. Note we set number of columns and rows to be 8 by 8 to see all 64 feature maps. plt . rcParams [ \"figure.figsize\" ] = 32 , 24 utils . subplot ( first_conv_layer_output , utils . tensor2img , title = \"features.0_Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\" , ncols = 8 , nrows = 8 ) # plt.rcParams[\"figure.figsize\"]= 32, 24 # utils.subplot(f[\"features.2_MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\"][0], utils.tensor2img, title=\"eatures.2_MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\", ncols=8, nrows=8)","title":"First Conv Layer Output Alexnet"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/#first-conv-layer-output-vgg16","text":"first_conv_layer_output = vgg16_f [ \"features.0_Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\" ] print ( first_conv_layer_output . shape ) first_conv_layer_output = first_conv_layer_output . squeeze ( dim = 0 ) print ( first_conv_layer_output . shape ) torch.Size([1, 64, 224, 224]) torch.Size([64, 224, 224]) plt . rcParams [ \"figure.figsize\" ] = 32 , 24 utils . subplot ( first_conv_layer_output , utils . tensor2img , title = \"features.0_Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\" , ncols = 8 , nrows = 8 )","title":"First Conv Layer Output VGG16"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/#mean-and-sum-reduce-of-the-feature-maps","text":"In the above section, if there are 64 feature maps after a conv layer, we will plot all 64 feauture maps. In the next section, we can either sum or average all 64 feature maps to reduce them to 1 single feature map.","title":"Mean and Sum Reduce of the Feature Maps"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/","text":"EDA Visualizations for Image Recognition (Conv Filter Edition) Dependencies and Imports ! pip install - q timm from typing import Dict import matplotlib.pyplot as plt import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import timm import torch import torchvision from torchvision.models.feature_extraction import ( create_feature_extractor , get_graph_node_names ) % matplotlib inline import glob import os from math import ceil import random import cv2 import PIL from IPython.core.interactiveshell import InteractiveShell InteractiveShell . ast_node_interactivity = \"all\" from typing import * # importing modules import urllib.request from PIL import Image Config and Logging import logging from logging import INFO , FileHandler , Formatter , StreamHandler , getLogger def init_logger ( log_file : str = \"info.log\" ) -> logging . Logger : \"\"\"Initialize logger and save to file. Consider having more log_file paths to save, eg: debug.log, error.log, etc. Args: log_file (str, optional): [description]. Defaults to Path(LOGS_DIR, \"info.log\"). Returns: logging.Logger: [description] \"\"\" logger = getLogger ( __name__ ) logger . setLevel ( INFO ) stream_handler = StreamHandler () stream_handler . setFormatter ( Formatter ( \" %(asctime)s : %(message)s \" , \"%Y-%m- %d %H:%M:%S\" ) ) file_handler = FileHandler ( filename = log_file ) file_handler . setFormatter ( Formatter ( \" %(asctime)s : %(message)s \" , \"%Y-%m- %d %H:%M:%S\" ) ) logger . addHandler ( stream_handler ) logger . addHandler ( file_handler ) return logger logger = init_logger () Utils def plot_multiple_img ( img_matrix_list , title_list , ncols , main_title = \"\" ): fig , myaxes = plt . subplots ( figsize = ( 20 , 15 ), nrows = ceil ( len ( img_matrix_list ) / ncols ), ncols = ncols , squeeze = False , ) fig . suptitle ( main_title , fontsize = 30 ) fig . subplots_adjust ( wspace = 0.3 ) fig . subplots_adjust ( hspace = 0.3 ) for i , ( img , title ) in enumerate ( zip ( img_matrix_list , title_list )): myaxes [ i // ncols ][ i % ncols ] . imshow ( img ) myaxes [ i // ncols ][ i % ncols ] . set_title ( title , fontsize = 15 ) plt . show () Seeding def seed_all ( seed : int = 1992 ) -> None : \"\"\"Seed all random number generators.\"\"\" print ( f \"Using Seed Number { seed } \" ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator # set fixed value for python built-in pseudo-random generator random . seed ( seed ) torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = True torch . backends . cudnn . enabled = True def seed_worker ( _worker_id ) -> None : \"\"\"Seed a worker with the given ID.\"\"\" worker_seed = torch . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) seed_all () Using Seed Number 1992 Transforms Params mean : List [ float ] = [ 0.485 , 0.456 , 0.406 ] std : List [ float ] = [ 0.229 , 0.224 , 0.225 ] image_size : int = 224 transform = torchvision . transforms . Compose ( [ torchvision . transforms . Resize (( image_size , image_size )), torchvision . transforms . ToTensor (), torchvision . transforms . Normalize ( mean = mean , std = std ), ] ) pre_normalize_transform = torchvision . transforms . Compose ( [ torchvision . transforms . Resize (( image_size , image_size )), torchvision . transforms . ToTensor (), ] ) Visualizations cat_p = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/deep_learning/computer_vision/data/misc/cat.jpg\" dog_p = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/deep_learning/computer_vision/data/misc/dog.jpg\" from urllib.request import urlopen # plot cat and dog with title using PIL plt . figure ( figsize = ( 10 , 10 )) plt . subplot ( 1 , 2 , 1 ) cat = PIL . Image . open ( urlopen ( cat_p )) plt . imshow ( cat . resize (( 1024 , 1024 ))) plt . title ( \"Cat\" ) plt . subplot ( 1 , 2 , 2 ) dog = PIL . Image . open ( urlopen ( dog_p )) plt . imshow ( dog . resize (( 1024 , 1024 ))) plt . title ( \"Dog\" ) plt . show (); Convolution Layers The image and content are referenced with courtesy from [Tarun's notebook](https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models](https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models). Convolution is a rather simple algorithm which involves a kernel (a 2D matrix) which moves over the entire image, calculating dot products with each window along the way. The GIF below demonstrates convolution in action. The above process can be summarized with an equation, where f is the image and h is the kernel. The dimensions of f are (m, n) and the kernel is a square matrix with dimensions smaller than f : \\( \\(\\text{conv}(f, h) = \\sum_{j}\\sum_{k}h_{jk} \\cdot f_{(m-j)(n-k)}\\) \\) In the above equation, the kernel h is moving across the length and breadth of the image. The dot product of h with a sub-matrix or window of matrix f is taken at each step, hence the double summation (rows and columns). I have always remembered from the revered Andrew Ng about how he taught us about what convolutional layers do. In the beginning, the conv layers are of low level abstraction, detailing a image's features such as shapes and sizes. In particular, he described to us the horizontal and vertical conv filters. As the conv layers go later, it will pick up on many abstract features, which is not really easily distinguished by human eyes. Below, we see an example of horizontal and vertical filters. def conv_horizontal ( image : np . ndarray ) -> None : \"\"\"Plot the horizontal convolution of the image. Args: image (torch.Tensor): [description] \"\"\" fig , ax = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 20 , 20 )) kernel = np . ones (( 3 , 3 ), np . float32 ) kernel [ 1 ] = np . array ([ 0 , 0 , 0 ], np . float32 ) kernel [ 2 ] = np . array ([ - 1 , - 1 , - 1 ], np . float32 ) conv = cv2 . filter2D ( image , - 1 , kernel ) ax [ 0 ] . imshow ( image ) ax [ 0 ] . set_title ( \"Original Image\" , fontsize = 24 ) ax [ 1 ] . imshow ( conv ) ax [ 1 ] . set_title ( \"Convolved Image with horizontal edges\" , fontsize = 24 ) plt . show () def conv_vertical ( image : np . ndarray ) -> None : \"\"\"Plot the vertical convolution of the image. Args: image (torch.Tensor): [description] \"\"\" fig , ax = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 20 , 20 )) kernel = np . ones (( 3 , 3 ), np . float32 ) kernel [ 0 ] = np . array ([ 1 , 0 , - 1 ]) kernel [ 1 ] = np . array ([ 1 , 0 , - 1 ]) kernel [ 2 ] = np . array ([ 1 , 0 , - 1 ]) conv = cv2 . filter2D ( image , - 1 , kernel ) ax [ 0 ] . imshow ( image ) ax [ 0 ] . set_title ( \"Original Image\" , fontsize = 24 ) ax [ 1 ] . imshow ( conv ) ax [ 1 ] . set_title ( \"Convolved Image with vertical edges\" , fontsize = 24 ) plt . show () Well, I can easily make out the horizontal and vertical edges from the dog image! Actually, not so obvious if you don't look closely! conv_horizontal ( np . asarray ( dog )) conv_vertical ( np . asarray ( dog )) The issue is, I want to visualize what our models' conv layers are seeing, like for example, the first conv layer usually has 64 filters, that is a whooping 64 different combinations of filters, each doing a slightly different thing. A mental model that I have for the first conv layer looks something like the following. conv_1_filters = [ \"vertical edge detector\" , \"horizontal edge detector\" , \"slanted 45 degrees detector\" , \"slanted 180 degrees detector\" , ... ] Feature Extractor using PyTorch's native Feature Extraction Module In order to visualize properly, I made use of PyTorch's newest feature_extraction module to do so. Note that the new feature is still in development, but it does make my life easier and reduces overhead. I no longer need use hooks or what not to plot layer information! We just need to import from torchvision.models.feature_extraction import ( create_feature_extractor , get_graph_node_names ) def get_conv_layers ( model : torchvision . models ) -> Dict [ str , str ]: \"\"\"Create a function that give me the conv layers of PyTorch model. Args: model (Union[torchvision.models, timm.models]): A PyTorch model. Returns: conv_layers (Dict[str, str]): {\"layer1.0.conv1\": layer1.0.conv1, ...} \"\"\" conv_layers = {} for name , layer in model . named_modules (): if isinstance ( layer , torch . nn . Conv2d ): conv_layers [ name ] = name return conv_layers def get_feature_maps ( model_name : str , image : torch . Tensor , reduction : str = \"mean\" , pretrained : bool = True ) -> Union [ Dict [ str , torch . Tensor ], List [ torch . Tensor ], List [ str ]]: \"\"\"Function to plot feature maps from PyTorch models. Args: model_name (str): Name of the model to use. image (torch.Tensor): image should be a tensor of shape (1, 3, H, W) reduction (str, optional): Defaults to \"mean\". One of [\"mean\", \"max\", \"sum\"] pretrained (bool): whether the model is pretrained or not Raises: ValueError: Must use Torchvision models. Returns: model_feature_maps (Dict[str, torch.Tensor]): {\"conv_1\": conv_1_feature_map, ...} processed_feature_maps (List[torch.Tensor]): [conv_1_feature_map, ...] processed using a reduction method. feature_map_names (List[str]): [conv_1, ...] Example: >>> from torchvision.models.vgg import vgg16 >>> model = vgg16(pretrained=True) >>> image = torch.rand(1, 3, 224, 224) >>> feature_maps = get_feature_maps(model, image, reduction=\"mean\") Reduction: If a feature map has 4 filters, in the shape of (4, H, W) = (4, 32, 32), then the reduction can be done as follows: >>> reduction = \"mean\": There are 4 filters in this feature map, you can imagine it as 4 32x32 images. We sum up all 4 filters channel wise and get a single 32x32 image. i.e filter 1-4's (0, 0) coordinate has pixel say 1,2,3,4, respectively, then sum up channel wise means 1+2+3+4 = 10 and Then we take the mean of all 32x32 images by dividing by num of kernels to get a single 32x32 image, which is reduction=\"mean\" which means 10 / 4 = 2.5 for that pixel at (0, 0) \"\"\" try : model = getattr ( torchvision . models , model_name )( pretrained = pretrained ) except AttributeError : raise ValueError ( f \"Model { model_name } not found.\" ) train_nodes , eval_nodes = get_graph_node_names ( model ) logger . info ( f \"The train nodes of the model graph is: \\n\\n { train_nodes } \" ) return_conv_nodes = get_conv_layers ( model ) feature_extractor = create_feature_extractor ( model , return_nodes = return_conv_nodes ) # `model_feature_maps` will be a dict of Tensors, each representing a feature map model_feature_maps = feature_extractor ( image ) processed_feature_maps = [] feature_map_names = [] for conv_name , conv_feature_map in model_feature_maps . items (): conv_feature_map = conv_feature_map . squeeze ( dim = 0 ) num_filters = conv_feature_map . shape [ 0 ] if reduction == \"mean\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) / num_filters elif reduction == \"max\" : gray_scale = torch . max ( conv_feature_map , dim = 0 ) elif reduction == \"sum\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) processed_feature_maps . append ( gray_scale . data . cpu () . numpy ()) feature_map_names . append ( conv_name ) return model_feature_maps , processed_feature_maps , feature_map_names Visualizing VGG16 and ResNet18 Step 1: Initialize the models. As of now, I recommend using torchvision 's models. Ideally, I will want to use timm library for a more detailed list, but there are some bugs that is not easily integrated with the module. device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) import torchvision.models as models vgg16_pretrained_true = models . vgg16 ( pretrained = True ) vgg16_pretrained_true = vgg16_pretrained_true . to ( device ) resnet18_pretrained_true = models . resnet18 ( pretrained = True ) resnet18_pretrained_true = resnet18_pretrained_true . to ( device ) # Get node names train_nodes , eval_nodes = get_graph_node_names ( vgg16_pretrained_true ) logger . info ( f \"Train nodes of VGG16: \\n\\n { train_nodes } \" ) train_nodes , eval_nodes = get_graph_node_names ( resnet18_pretrained_true ) logger . info ( f \"Train nodes of ResNet18: \\n\\n { train_nodes } \" ) 2021-12-29 19:06:08: Train nodes of VGG16: ['x', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'features.13', 'features.14', 'features.15', 'features.16', 'features.17', 'features.18', 'features.19', 'features.20', 'features.21', 'features.22', 'features.23', 'features.24', 'features.25', 'features.26', 'features.27', 'features.28', 'features.29', 'features.30', 'avgpool', 'flatten', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6'] 2021-12-29 19:06:08: Train nodes of ResNet18: ['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avgpool', 'flatten', 'fc'] Good God! When I saw the layer names from vgg16 , I nearly fainted, I see no easy way to know which layer belongs to a Conv layer. I understand that get_graph_node_names will get all the nodes on the model's graph, but it is difficult to map the node names to a layer if it is named as such, seeing resnet18 's node names is much easier for one to identify which is conv layer or not. train_nodes , eval_nodes = get_graph_node_names ( model ) logger . info ( f \"The train nodes of the model graph is: \\n\\n { train_nodes } \" ) Thus I wrote a small function get_conv_layers to get the conv layer names. It is not perfect, as downsample layers (1x1 conv layers) are tagged under Conv2d but we may not really need to use them to visualize our feature maps. One can tweak a bit if need be, but for now, I will get all layers that use the Conv2d blocks. If the feature names in vgg16 are named with conv, then we can simply use a small loop below to find the conv layer names. conv_layers = [] for node in nodes : if \"conv\" in node : conv_layers . append ( node ) I actually thought ResNet18 has 18 conv layers, but even minusing to 3 downsample layers, it's 17 conv layers, wonder why? Step 2: Transform the Tensors The PyTorch feature_extraction expects the image input to be of shape [B,C,H,W] . # We use torchvision's transform to transform the cat image to channels first. cat_tensor = transform ( cat ) # Now feature_extractor expects batch_size x C x H x W, so we expand one dimension in the 0th dim cat_tensor = cat_tensor . unsqueeze ( dim = 0 ) . to ( device ) # We use torchvision's transform to transform the cat image with resize and normalization. # Conveniently, also making it channel first! cat_tensor = transform ( cat ) dog_tensor = transform ( dog ) assert cat_tensor . shape [ 0 ] == dog_tensor . shape [ 0 ] == 3 , \"PyTorch expects Channel First!\" # Now feature_extractor expects batch_size x C x H x W, so we expand one dimension in the 0th dim cat_tensor = cat_tensor . unsqueeze ( dim = 0 ) . to ( device ) dog_tensor = dog_tensor . unsqueeze ( dim = 0 ) . to ( device ) logger . info ( f \" \\n\\n cat_tensor's shape: \\n { cat_tensor . shape } \\n\\n dog_tensor's shape: \\n { dog_tensor . shape } \" ) 2021-12-29 19:06:10: cat_tensor's shape: torch.Size([1, 3, 224, 224]) dog_tensor's shape: torch.Size([1, 3, 224, 224]) Step 3: Plotting the Feature Maps We first walk through get_feature_maps and see what my function is doing. # Get node names train_nodes , eval_nodes = get_graph_node_names ( model ) # Since get node names do not indicate properly which is a conv layer or not, # we use get_conv_layer instead to do the job, which returns a dict {\"conv_layer_name\": \"conv_layer_name\"} return_conv_nodes = get_conv_layers ( model ) # call create_feature_extractor on the model and its corresponding conv layer names. feature_extractor = create_feature_extractor ( model , return_nodes = return_conv_nodes ) # `model_feature_maps` will be a dict of Tensors, each representing a feature map # {\"conv_layer_1\": output filter map,...} model_feature_maps = feature_extractor ( image ) # we need to further process the feature maps processed_feature_maps , feature_map_names = [], [] for conv_name , conv_feature_map in model_feature_maps . items (): # Squeeze the dimension from [1, 64, 32, 32] to [64, 32, 32] # This means we have 64 filters of 32x32 \"images\" or kernels conv_feature_map = conv_feature_map . squeeze ( dim = 0 ) # get number of feature/kernels in this layer num_filters = conv_feature_map . shape [ 0 ] # If a feature map has 4 filters, in the shape of (4, H, W) = (4, 32, 32), then the reduction mean can be done as follows: There are 4 filters in this feature map, you can imagine it as 4 32x32 images. # Step 1: We sum up all 4 filters element-wise and get a single 32x32 image. # Step 2: Then we take the mean of all 32x32 images to get a single 32x32 image, which is reduction=\"mean\". if reduction == \"mean\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) / num_filters elif reduction == \"max\" : gray_scale = torch . max ( conv_feature_map , dim = 0 ) elif reduction == \"sum\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) processed_feature_maps . append ( gray_scale . data . cpu () . numpy ()) feature_map_names . append ( conv_name ) _ , vgg16_processed_feature_maps , vgg16_feature_map_names = get_feature_maps ( model_name = \"vgg16\" , image = cat_tensor , reduction = \"mean\" , pretrained = True ) _ , resnet18_processed_feature_maps , resnet18_feature_map_names = get_feature_maps ( model_name = \"resnet18\" , image = cat_tensor , reduction = \"mean\" , pretrained = True ) 2021-12-29 19:06:12: The train nodes of the model graph is: ['x', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'features.13', 'features.14', 'features.15', 'features.16', 'features.17', 'features.18', 'features.19', 'features.20', 'features.21', 'features.22', 'features.23', 'features.24', 'features.25', 'features.26', 'features.27', 'features.28', 'features.29', 'features.30', 'avgpool', 'flatten', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6'] 2021-12-29 19:06:12: The train nodes of the model graph is: ['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avgpool', 'flatten', 'fc'] Then we create a simple plot_feature_maps that take in the processed_feature_maps and feature_map_names to plot them. def plot_feature_maps ( processed_feature_maps : List [ torch . Tensor ], feature_map_names : List [ str ], nrows : int , title : str = None ) -> None : \"\"\"Plot the feature maps. Args: processed_feature_maps (List[torch.Tensor]): [description] feature_map_names (List[str]): [description] nrows (int): [description] \"\"\" fig = plt . figure ( figsize = ( 30 , 50 )) ncols = len ( processed_feature_maps ) // nrows + 1 for i in range ( len ( processed_feature_maps )): a = fig . add_subplot ( nrows , ncols , i + 1 ) imgplot = plt . imshow ( processed_feature_maps [ i ]) a . axis ( \"off\" ) a . set_title ( feature_map_names [ i ] . split ( \"(\" )[ 0 ], fontsize = 30 ) fig . suptitle ( title , fontsize = 50 ) fig . tight_layout () fig . subplots_adjust ( top = 0.95 ) plt . savefig ( title , bbox_inches = 'tight' ) plt . show (); plot_feature_maps ( vgg16_processed_feature_maps , vgg16_feature_map_names , nrows = 5 , title = \"VGG16 Pretrained Feature Maps\" , ) plot_feature_maps ( resnet18_processed_feature_maps , resnet18_feature_map_names , nrows = 5 , title = \"ResNet18 Pretrained Feature Maps\" , ) Comparison with Randomly Initialized Weights We know that if the model is not pretrained, it will initialize with random weights using weight initialization methods such as Kaimin or Xavier. I expect the edges to be not so \"smooth\" as the ones that are pretrained! This is logical, as the filters in the conv layers are mostly random, and we have not trained any epochs yet, so let's see what it gives us. _ , vgg16_processed_feature_maps , vgg16_feature_map_names = get_feature_maps ( model_name = \"vgg16\" , image = cat_tensor , reduction = \"mean\" , pretrained = False ) _ , resnet18_processed_feature_maps , resnet18_feature_map_names = get_feature_maps ( model_name = \"resnet18\" , image = cat_tensor , reduction = \"mean\" , pretrained = False ) 2021-12-29 19:06:21: The train nodes of the model graph is: ['x', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'features.13', 'features.14', 'features.15', 'features.16', 'features.17', 'features.18', 'features.19', 'features.20', 'features.21', 'features.22', 'features.23', 'features.24', 'features.25', 'features.26', 'features.27', 'features.28', 'features.29', 'features.30', 'avgpool', 'flatten', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6'] 2021-12-29 19:06:21: The train nodes of the model graph is: ['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avgpool', 'flatten', 'fc'] plot_feature_maps ( vgg16_processed_feature_maps , vgg16_feature_map_names , nrows = 5 , title = \"VGG16 NOT Pretrained Feature Maps\" , ) plot_feature_maps ( resnet18_processed_feature_maps , resnet18_feature_map_names , nrows = 5 , title = \"ResNet18 NOT Pretrained Feature Maps\" , ) References: https://pytorch.org/vision/stable/feature_extraction.html https://ravivaishnav20.medium.com/visualizing-feature-maps-using-pytorch https://pytorch.org/blog/FX-feature-extraction-torchvision/ https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models","title":"Feature Map Activations (Part II)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/#eda-visualizations-for-image-recognition-conv-filter-edition","text":"","title":"EDA Visualizations for Image Recognition (Conv Filter Edition)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/#dependencies-and-imports","text":"! pip install - q timm from typing import Dict import matplotlib.pyplot as plt import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import timm import torch import torchvision from torchvision.models.feature_extraction import ( create_feature_extractor , get_graph_node_names ) % matplotlib inline import glob import os from math import ceil import random import cv2 import PIL from IPython.core.interactiveshell import InteractiveShell InteractiveShell . ast_node_interactivity = \"all\" from typing import * # importing modules import urllib.request from PIL import Image","title":"Dependencies and Imports"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/#config-and-logging","text":"import logging from logging import INFO , FileHandler , Formatter , StreamHandler , getLogger def init_logger ( log_file : str = \"info.log\" ) -> logging . Logger : \"\"\"Initialize logger and save to file. Consider having more log_file paths to save, eg: debug.log, error.log, etc. Args: log_file (str, optional): [description]. Defaults to Path(LOGS_DIR, \"info.log\"). Returns: logging.Logger: [description] \"\"\" logger = getLogger ( __name__ ) logger . setLevel ( INFO ) stream_handler = StreamHandler () stream_handler . setFormatter ( Formatter ( \" %(asctime)s : %(message)s \" , \"%Y-%m- %d %H:%M:%S\" ) ) file_handler = FileHandler ( filename = log_file ) file_handler . setFormatter ( Formatter ( \" %(asctime)s : %(message)s \" , \"%Y-%m- %d %H:%M:%S\" ) ) logger . addHandler ( stream_handler ) logger . addHandler ( file_handler ) return logger logger = init_logger ()","title":"Config and Logging"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/#utils","text":"def plot_multiple_img ( img_matrix_list , title_list , ncols , main_title = \"\" ): fig , myaxes = plt . subplots ( figsize = ( 20 , 15 ), nrows = ceil ( len ( img_matrix_list ) / ncols ), ncols = ncols , squeeze = False , ) fig . suptitle ( main_title , fontsize = 30 ) fig . subplots_adjust ( wspace = 0.3 ) fig . subplots_adjust ( hspace = 0.3 ) for i , ( img , title ) in enumerate ( zip ( img_matrix_list , title_list )): myaxes [ i // ncols ][ i % ncols ] . imshow ( img ) myaxes [ i // ncols ][ i % ncols ] . set_title ( title , fontsize = 15 ) plt . show ()","title":"Utils"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/#seeding","text":"def seed_all ( seed : int = 1992 ) -> None : \"\"\"Seed all random number generators.\"\"\" print ( f \"Using Seed Number { seed } \" ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator # set fixed value for python built-in pseudo-random generator random . seed ( seed ) torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = True torch . backends . cudnn . enabled = True def seed_worker ( _worker_id ) -> None : \"\"\"Seed a worker with the given ID.\"\"\" worker_seed = torch . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) seed_all () Using Seed Number 1992","title":"Seeding"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/#transforms-params","text":"mean : List [ float ] = [ 0.485 , 0.456 , 0.406 ] std : List [ float ] = [ 0.229 , 0.224 , 0.225 ] image_size : int = 224 transform = torchvision . transforms . Compose ( [ torchvision . transforms . Resize (( image_size , image_size )), torchvision . transforms . ToTensor (), torchvision . transforms . Normalize ( mean = mean , std = std ), ] ) pre_normalize_transform = torchvision . transforms . Compose ( [ torchvision . transforms . Resize (( image_size , image_size )), torchvision . transforms . ToTensor (), ] )","title":"Transforms Params"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/#visualizations","text":"cat_p = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/deep_learning/computer_vision/data/misc/cat.jpg\" dog_p = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/deep_learning/computer_vision/data/misc/dog.jpg\" from urllib.request import urlopen # plot cat and dog with title using PIL plt . figure ( figsize = ( 10 , 10 )) plt . subplot ( 1 , 2 , 1 ) cat = PIL . Image . open ( urlopen ( cat_p )) plt . imshow ( cat . resize (( 1024 , 1024 ))) plt . title ( \"Cat\" ) plt . subplot ( 1 , 2 , 2 ) dog = PIL . Image . open ( urlopen ( dog_p )) plt . imshow ( dog . resize (( 1024 , 1024 ))) plt . title ( \"Dog\" ) plt . show ();","title":"Visualizations"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/#convolution-layers","text":"The image and content are referenced with courtesy from [Tarun's notebook](https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models](https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models). Convolution is a rather simple algorithm which involves a kernel (a 2D matrix) which moves over the entire image, calculating dot products with each window along the way. The GIF below demonstrates convolution in action. The above process can be summarized with an equation, where f is the image and h is the kernel. The dimensions of f are (m, n) and the kernel is a square matrix with dimensions smaller than f : \\( \\(\\text{conv}(f, h) = \\sum_{j}\\sum_{k}h_{jk} \\cdot f_{(m-j)(n-k)}\\) \\) In the above equation, the kernel h is moving across the length and breadth of the image. The dot product of h with a sub-matrix or window of matrix f is taken at each step, hence the double summation (rows and columns). I have always remembered from the revered Andrew Ng about how he taught us about what convolutional layers do. In the beginning, the conv layers are of low level abstraction, detailing a image's features such as shapes and sizes. In particular, he described to us the horizontal and vertical conv filters. As the conv layers go later, it will pick up on many abstract features, which is not really easily distinguished by human eyes. Below, we see an example of horizontal and vertical filters. def conv_horizontal ( image : np . ndarray ) -> None : \"\"\"Plot the horizontal convolution of the image. Args: image (torch.Tensor): [description] \"\"\" fig , ax = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 20 , 20 )) kernel = np . ones (( 3 , 3 ), np . float32 ) kernel [ 1 ] = np . array ([ 0 , 0 , 0 ], np . float32 ) kernel [ 2 ] = np . array ([ - 1 , - 1 , - 1 ], np . float32 ) conv = cv2 . filter2D ( image , - 1 , kernel ) ax [ 0 ] . imshow ( image ) ax [ 0 ] . set_title ( \"Original Image\" , fontsize = 24 ) ax [ 1 ] . imshow ( conv ) ax [ 1 ] . set_title ( \"Convolved Image with horizontal edges\" , fontsize = 24 ) plt . show () def conv_vertical ( image : np . ndarray ) -> None : \"\"\"Plot the vertical convolution of the image. Args: image (torch.Tensor): [description] \"\"\" fig , ax = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 20 , 20 )) kernel = np . ones (( 3 , 3 ), np . float32 ) kernel [ 0 ] = np . array ([ 1 , 0 , - 1 ]) kernel [ 1 ] = np . array ([ 1 , 0 , - 1 ]) kernel [ 2 ] = np . array ([ 1 , 0 , - 1 ]) conv = cv2 . filter2D ( image , - 1 , kernel ) ax [ 0 ] . imshow ( image ) ax [ 0 ] . set_title ( \"Original Image\" , fontsize = 24 ) ax [ 1 ] . imshow ( conv ) ax [ 1 ] . set_title ( \"Convolved Image with vertical edges\" , fontsize = 24 ) plt . show () Well, I can easily make out the horizontal and vertical edges from the dog image! Actually, not so obvious if you don't look closely! conv_horizontal ( np . asarray ( dog )) conv_vertical ( np . asarray ( dog )) The issue is, I want to visualize what our models' conv layers are seeing, like for example, the first conv layer usually has 64 filters, that is a whooping 64 different combinations of filters, each doing a slightly different thing. A mental model that I have for the first conv layer looks something like the following. conv_1_filters = [ \"vertical edge detector\" , \"horizontal edge detector\" , \"slanted 45 degrees detector\" , \"slanted 180 degrees detector\" , ... ]","title":"Convolution Layers "},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/#feature-extractor-using-pytorchs-native-feature-extraction-module","text":"In order to visualize properly, I made use of PyTorch's newest feature_extraction module to do so. Note that the new feature is still in development, but it does make my life easier and reduces overhead. I no longer need use hooks or what not to plot layer information! We just need to import from torchvision.models.feature_extraction import ( create_feature_extractor , get_graph_node_names ) def get_conv_layers ( model : torchvision . models ) -> Dict [ str , str ]: \"\"\"Create a function that give me the conv layers of PyTorch model. Args: model (Union[torchvision.models, timm.models]): A PyTorch model. Returns: conv_layers (Dict[str, str]): {\"layer1.0.conv1\": layer1.0.conv1, ...} \"\"\" conv_layers = {} for name , layer in model . named_modules (): if isinstance ( layer , torch . nn . Conv2d ): conv_layers [ name ] = name return conv_layers def get_feature_maps ( model_name : str , image : torch . Tensor , reduction : str = \"mean\" , pretrained : bool = True ) -> Union [ Dict [ str , torch . Tensor ], List [ torch . Tensor ], List [ str ]]: \"\"\"Function to plot feature maps from PyTorch models. Args: model_name (str): Name of the model to use. image (torch.Tensor): image should be a tensor of shape (1, 3, H, W) reduction (str, optional): Defaults to \"mean\". One of [\"mean\", \"max\", \"sum\"] pretrained (bool): whether the model is pretrained or not Raises: ValueError: Must use Torchvision models. Returns: model_feature_maps (Dict[str, torch.Tensor]): {\"conv_1\": conv_1_feature_map, ...} processed_feature_maps (List[torch.Tensor]): [conv_1_feature_map, ...] processed using a reduction method. feature_map_names (List[str]): [conv_1, ...] Example: >>> from torchvision.models.vgg import vgg16 >>> model = vgg16(pretrained=True) >>> image = torch.rand(1, 3, 224, 224) >>> feature_maps = get_feature_maps(model, image, reduction=\"mean\") Reduction: If a feature map has 4 filters, in the shape of (4, H, W) = (4, 32, 32), then the reduction can be done as follows: >>> reduction = \"mean\": There are 4 filters in this feature map, you can imagine it as 4 32x32 images. We sum up all 4 filters channel wise and get a single 32x32 image. i.e filter 1-4's (0, 0) coordinate has pixel say 1,2,3,4, respectively, then sum up channel wise means 1+2+3+4 = 10 and Then we take the mean of all 32x32 images by dividing by num of kernels to get a single 32x32 image, which is reduction=\"mean\" which means 10 / 4 = 2.5 for that pixel at (0, 0) \"\"\" try : model = getattr ( torchvision . models , model_name )( pretrained = pretrained ) except AttributeError : raise ValueError ( f \"Model { model_name } not found.\" ) train_nodes , eval_nodes = get_graph_node_names ( model ) logger . info ( f \"The train nodes of the model graph is: \\n\\n { train_nodes } \" ) return_conv_nodes = get_conv_layers ( model ) feature_extractor = create_feature_extractor ( model , return_nodes = return_conv_nodes ) # `model_feature_maps` will be a dict of Tensors, each representing a feature map model_feature_maps = feature_extractor ( image ) processed_feature_maps = [] feature_map_names = [] for conv_name , conv_feature_map in model_feature_maps . items (): conv_feature_map = conv_feature_map . squeeze ( dim = 0 ) num_filters = conv_feature_map . shape [ 0 ] if reduction == \"mean\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) / num_filters elif reduction == \"max\" : gray_scale = torch . max ( conv_feature_map , dim = 0 ) elif reduction == \"sum\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) processed_feature_maps . append ( gray_scale . data . cpu () . numpy ()) feature_map_names . append ( conv_name ) return model_feature_maps , processed_feature_maps , feature_map_names","title":"Feature Extractor using PyTorch's native Feature Extraction Module"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/#visualizing-vgg16-and-resnet18","text":"","title":"Visualizing VGG16 and ResNet18"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/#step-1-initialize-the-models","text":"As of now, I recommend using torchvision 's models. Ideally, I will want to use timm library for a more detailed list, but there are some bugs that is not easily integrated with the module. device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) import torchvision.models as models vgg16_pretrained_true = models . vgg16 ( pretrained = True ) vgg16_pretrained_true = vgg16_pretrained_true . to ( device ) resnet18_pretrained_true = models . resnet18 ( pretrained = True ) resnet18_pretrained_true = resnet18_pretrained_true . to ( device ) # Get node names train_nodes , eval_nodes = get_graph_node_names ( vgg16_pretrained_true ) logger . info ( f \"Train nodes of VGG16: \\n\\n { train_nodes } \" ) train_nodes , eval_nodes = get_graph_node_names ( resnet18_pretrained_true ) logger . info ( f \"Train nodes of ResNet18: \\n\\n { train_nodes } \" ) 2021-12-29 19:06:08: Train nodes of VGG16: ['x', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'features.13', 'features.14', 'features.15', 'features.16', 'features.17', 'features.18', 'features.19', 'features.20', 'features.21', 'features.22', 'features.23', 'features.24', 'features.25', 'features.26', 'features.27', 'features.28', 'features.29', 'features.30', 'avgpool', 'flatten', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6'] 2021-12-29 19:06:08: Train nodes of ResNet18: ['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avgpool', 'flatten', 'fc'] Good God! When I saw the layer names from vgg16 , I nearly fainted, I see no easy way to know which layer belongs to a Conv layer. I understand that get_graph_node_names will get all the nodes on the model's graph, but it is difficult to map the node names to a layer if it is named as such, seeing resnet18 's node names is much easier for one to identify which is conv layer or not. train_nodes , eval_nodes = get_graph_node_names ( model ) logger . info ( f \"The train nodes of the model graph is: \\n\\n { train_nodes } \" ) Thus I wrote a small function get_conv_layers to get the conv layer names. It is not perfect, as downsample layers (1x1 conv layers) are tagged under Conv2d but we may not really need to use them to visualize our feature maps. One can tweak a bit if need be, but for now, I will get all layers that use the Conv2d blocks. If the feature names in vgg16 are named with conv, then we can simply use a small loop below to find the conv layer names. conv_layers = [] for node in nodes : if \"conv\" in node : conv_layers . append ( node ) I actually thought ResNet18 has 18 conv layers, but even minusing to 3 downsample layers, it's 17 conv layers, wonder why?","title":"Step 1: Initialize the models."},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/#step-2-transform-the-tensors","text":"The PyTorch feature_extraction expects the image input to be of shape [B,C,H,W] . # We use torchvision's transform to transform the cat image to channels first. cat_tensor = transform ( cat ) # Now feature_extractor expects batch_size x C x H x W, so we expand one dimension in the 0th dim cat_tensor = cat_tensor . unsqueeze ( dim = 0 ) . to ( device ) # We use torchvision's transform to transform the cat image with resize and normalization. # Conveniently, also making it channel first! cat_tensor = transform ( cat ) dog_tensor = transform ( dog ) assert cat_tensor . shape [ 0 ] == dog_tensor . shape [ 0 ] == 3 , \"PyTorch expects Channel First!\" # Now feature_extractor expects batch_size x C x H x W, so we expand one dimension in the 0th dim cat_tensor = cat_tensor . unsqueeze ( dim = 0 ) . to ( device ) dog_tensor = dog_tensor . unsqueeze ( dim = 0 ) . to ( device ) logger . info ( f \" \\n\\n cat_tensor's shape: \\n { cat_tensor . shape } \\n\\n dog_tensor's shape: \\n { dog_tensor . shape } \" ) 2021-12-29 19:06:10: cat_tensor's shape: torch.Size([1, 3, 224, 224]) dog_tensor's shape: torch.Size([1, 3, 224, 224])","title":"Step 2: Transform the Tensors"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/#step-3-plotting-the-feature-maps","text":"We first walk through get_feature_maps and see what my function is doing. # Get node names train_nodes , eval_nodes = get_graph_node_names ( model ) # Since get node names do not indicate properly which is a conv layer or not, # we use get_conv_layer instead to do the job, which returns a dict {\"conv_layer_name\": \"conv_layer_name\"} return_conv_nodes = get_conv_layers ( model ) # call create_feature_extractor on the model and its corresponding conv layer names. feature_extractor = create_feature_extractor ( model , return_nodes = return_conv_nodes ) # `model_feature_maps` will be a dict of Tensors, each representing a feature map # {\"conv_layer_1\": output filter map,...} model_feature_maps = feature_extractor ( image ) # we need to further process the feature maps processed_feature_maps , feature_map_names = [], [] for conv_name , conv_feature_map in model_feature_maps . items (): # Squeeze the dimension from [1, 64, 32, 32] to [64, 32, 32] # This means we have 64 filters of 32x32 \"images\" or kernels conv_feature_map = conv_feature_map . squeeze ( dim = 0 ) # get number of feature/kernels in this layer num_filters = conv_feature_map . shape [ 0 ] # If a feature map has 4 filters, in the shape of (4, H, W) = (4, 32, 32), then the reduction mean can be done as follows: There are 4 filters in this feature map, you can imagine it as 4 32x32 images. # Step 1: We sum up all 4 filters element-wise and get a single 32x32 image. # Step 2: Then we take the mean of all 32x32 images to get a single 32x32 image, which is reduction=\"mean\". if reduction == \"mean\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) / num_filters elif reduction == \"max\" : gray_scale = torch . max ( conv_feature_map , dim = 0 ) elif reduction == \"sum\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) processed_feature_maps . append ( gray_scale . data . cpu () . numpy ()) feature_map_names . append ( conv_name ) _ , vgg16_processed_feature_maps , vgg16_feature_map_names = get_feature_maps ( model_name = \"vgg16\" , image = cat_tensor , reduction = \"mean\" , pretrained = True ) _ , resnet18_processed_feature_maps , resnet18_feature_map_names = get_feature_maps ( model_name = \"resnet18\" , image = cat_tensor , reduction = \"mean\" , pretrained = True ) 2021-12-29 19:06:12: The train nodes of the model graph is: ['x', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'features.13', 'features.14', 'features.15', 'features.16', 'features.17', 'features.18', 'features.19', 'features.20', 'features.21', 'features.22', 'features.23', 'features.24', 'features.25', 'features.26', 'features.27', 'features.28', 'features.29', 'features.30', 'avgpool', 'flatten', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6'] 2021-12-29 19:06:12: The train nodes of the model graph is: ['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avgpool', 'flatten', 'fc'] Then we create a simple plot_feature_maps that take in the processed_feature_maps and feature_map_names to plot them. def plot_feature_maps ( processed_feature_maps : List [ torch . Tensor ], feature_map_names : List [ str ], nrows : int , title : str = None ) -> None : \"\"\"Plot the feature maps. Args: processed_feature_maps (List[torch.Tensor]): [description] feature_map_names (List[str]): [description] nrows (int): [description] \"\"\" fig = plt . figure ( figsize = ( 30 , 50 )) ncols = len ( processed_feature_maps ) // nrows + 1 for i in range ( len ( processed_feature_maps )): a = fig . add_subplot ( nrows , ncols , i + 1 ) imgplot = plt . imshow ( processed_feature_maps [ i ]) a . axis ( \"off\" ) a . set_title ( feature_map_names [ i ] . split ( \"(\" )[ 0 ], fontsize = 30 ) fig . suptitle ( title , fontsize = 50 ) fig . tight_layout () fig . subplots_adjust ( top = 0.95 ) plt . savefig ( title , bbox_inches = 'tight' ) plt . show (); plot_feature_maps ( vgg16_processed_feature_maps , vgg16_feature_map_names , nrows = 5 , title = \"VGG16 Pretrained Feature Maps\" , ) plot_feature_maps ( resnet18_processed_feature_maps , resnet18_feature_map_names , nrows = 5 , title = \"ResNet18 Pretrained Feature Maps\" , )","title":"Step 3: Plotting the Feature Maps"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/#comparison-with-randomly-initialized-weights","text":"We know that if the model is not pretrained, it will initialize with random weights using weight initialization methods such as Kaimin or Xavier. I expect the edges to be not so \"smooth\" as the ones that are pretrained! This is logical, as the filters in the conv layers are mostly random, and we have not trained any epochs yet, so let's see what it gives us. _ , vgg16_processed_feature_maps , vgg16_feature_map_names = get_feature_maps ( model_name = \"vgg16\" , image = cat_tensor , reduction = \"mean\" , pretrained = False ) _ , resnet18_processed_feature_maps , resnet18_feature_map_names = get_feature_maps ( model_name = \"resnet18\" , image = cat_tensor , reduction = \"mean\" , pretrained = False ) 2021-12-29 19:06:21: The train nodes of the model graph is: ['x', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'features.13', 'features.14', 'features.15', 'features.16', 'features.17', 'features.18', 'features.19', 'features.20', 'features.21', 'features.22', 'features.23', 'features.24', 'features.25', 'features.26', 'features.27', 'features.28', 'features.29', 'features.30', 'avgpool', 'flatten', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6'] 2021-12-29 19:06:21: The train nodes of the model graph is: ['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avgpool', 'flatten', 'fc'] plot_feature_maps ( vgg16_processed_feature_maps , vgg16_feature_map_names , nrows = 5 , title = \"VGG16 NOT Pretrained Feature Maps\" , ) plot_feature_maps ( resnet18_processed_feature_maps , resnet18_feature_map_names , nrows = 5 , title = \"ResNet18 NOT Pretrained Feature Maps\" , ) References: https://pytorch.org/vision/stable/feature_extraction.html https://ravivaishnav20.medium.com/visualizing-feature-maps-using-pytorch https://pytorch.org/blog/FX-feature-extraction-torchvision/ https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models","title":"Comparison with Randomly Initialized Weights"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/","text":"EDA Visualizations for Image Recognition (Conv Filter Edition) Dependencies and Imports ! pip install - q timm from typing import Dict import matplotlib.pyplot as plt import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import timm import torch import torchvision from torchvision.models.feature_extraction import ( create_feature_extractor , get_graph_node_names ) % matplotlib inline import glob import os from math import ceil import random import cv2 import PIL from IPython.core.interactiveshell import InteractiveShell InteractiveShell . ast_node_interactivity = \"all\" from typing import * # importing modules import urllib.request from PIL import Image Config and Logging import logging from logging import INFO , FileHandler , Formatter , StreamHandler , getLogger def init_logger ( log_file : str = \"info.log\" ) -> logging . Logger : \"\"\"Initialize logger and save to file. Consider having more log_file paths to save, eg: debug.log, error.log, etc. Args: log_file (str, optional): [description]. Defaults to Path(LOGS_DIR, \"info.log\"). Returns: logging.Logger: [description] \"\"\" logger = getLogger ( __name__ ) logger . setLevel ( INFO ) stream_handler = StreamHandler () stream_handler . setFormatter ( Formatter ( \" %(asctime)s : %(message)s \" , \"%Y-%m- %d %H:%M:%S\" ) ) file_handler = FileHandler ( filename = log_file ) file_handler . setFormatter ( Formatter ( \" %(asctime)s : %(message)s \" , \"%Y-%m- %d %H:%M:%S\" ) ) logger . addHandler ( stream_handler ) logger . addHandler ( file_handler ) return logger logger = init_logger () Utils def plot_multiple_img ( img_matrix_list , title_list , ncols , main_title = \"\" ): fig , myaxes = plt . subplots ( figsize = ( 20 , 15 ), nrows = ceil ( len ( img_matrix_list ) / ncols ), ncols = ncols , squeeze = False , ) fig . suptitle ( main_title , fontsize = 30 ) fig . subplots_adjust ( wspace = 0.3 ) fig . subplots_adjust ( hspace = 0.3 ) for i , ( img , title ) in enumerate ( zip ( img_matrix_list , title_list )): myaxes [ i // ncols ][ i % ncols ] . imshow ( img ) myaxes [ i // ncols ][ i % ncols ] . set_title ( title , fontsize = 15 ) plt . show () Seeding def seed_all ( seed : int = 1992 ) -> None : \"\"\"Seed all random number generators.\"\"\" print ( f \"Using Seed Number { seed } \" ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator # set fixed value for python built-in pseudo-random generator random . seed ( seed ) torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = True torch . backends . cudnn . enabled = True def seed_worker ( _worker_id ) -> None : \"\"\"Seed a worker with the given ID.\"\"\" worker_seed = torch . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) seed_all () Using Seed Number 1992 Transforms Params mean : List [ float ] = [ 0.485 , 0.456 , 0.406 ] std : List [ float ] = [ 0.229 , 0.224 , 0.225 ] image_size : int = 224 transform = torchvision . transforms . Compose ( [ torchvision . transforms . Resize (( image_size , image_size )), torchvision . transforms . ToTensor (), torchvision . transforms . Normalize ( mean = mean , std = std ), ] ) pre_normalize_transform = torchvision . transforms . Compose ( [ torchvision . transforms . Resize (( image_size , image_size )), torchvision . transforms . ToTensor (), ] ) Visualizations cat_p = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/deep_learning/computer_vision/data/misc/cat.jpg\" dog_p = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/deep_learning/computer_vision/data/misc/dog.jpg\" from urllib.request import urlopen # plot cat and dog with title using PIL plt . figure ( figsize = ( 10 , 10 )) plt . subplot ( 1 , 2 , 1 ) cat = PIL . Image . open ( urlopen ( cat_p )) plt . imshow ( cat . resize (( 1024 , 1024 ))) plt . title ( \"Cat\" ) plt . subplot ( 1 , 2 , 2 ) dog = PIL . Image . open ( urlopen ( dog_p )) plt . imshow ( dog . resize (( 1024 , 1024 ))) plt . title ( \"Dog\" ) plt . show (); Convolution Layers The image and content are referenced with courtesy from [Tarun's notebook](https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models](https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models). Convolution is a rather simple algorithm which involves a kernel (a 2D matrix) which moves over the entire image, calculating dot products with each window along the way. The GIF below demonstrates convolution in action. The above process can be summarized with an equation, where f is the image and h is the kernel. The dimensions of f are (m, n) and the kernel is a square matrix with dimensions smaller than f : \\( \\(\\text{conv}(f, h) = \\sum_{j}\\sum_{k}h_{jk} \\cdot f_{(m-j)(n-k)}\\) \\) In the above equation, the kernel h is moving across the length and breadth of the image. The dot product of h with a sub-matrix or window of matrix f is taken at each step, hence the double summation (rows and columns). I have always remembered from the revered Andrew Ng about how he taught us about what convolutional layers do. In the beginning, the conv layers are of low level abstraction, detailing a image's features such as shapes and sizes. In particular, he described to us the horizontal and vertical conv filters. As the conv layers go later, it will pick up on many abstract features, which is not really easily distinguished by human eyes. Below, we see an example of horizontal and vertical filters. def conv_horizontal ( image : np . ndarray ) -> None : \"\"\"Plot the horizontal convolution of the image. Args: image (torch.Tensor): [description] \"\"\" fig , ax = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 20 , 20 )) kernel = np . ones (( 3 , 3 ), np . float32 ) kernel [ 1 ] = np . array ([ 0 , 0 , 0 ], np . float32 ) kernel [ 2 ] = np . array ([ - 1 , - 1 , - 1 ], np . float32 ) conv = cv2 . filter2D ( image , - 1 , kernel ) ax [ 0 ] . imshow ( image ) ax [ 0 ] . set_title ( \"Original Image\" , fontsize = 24 ) ax [ 1 ] . imshow ( conv ) ax [ 1 ] . set_title ( \"Convolved Image with horizontal edges\" , fontsize = 24 ) plt . show () def conv_vertical ( image : np . ndarray ) -> None : \"\"\"Plot the vertical convolution of the image. Args: image (torch.Tensor): [description] \"\"\" fig , ax = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 20 , 20 )) kernel = np . ones (( 3 , 3 ), np . float32 ) kernel [ 0 ] = np . array ([ 1 , 0 , - 1 ]) kernel [ 1 ] = np . array ([ 1 , 0 , - 1 ]) kernel [ 2 ] = np . array ([ 1 , 0 , - 1 ]) conv = cv2 . filter2D ( image , - 1 , kernel ) ax [ 0 ] . imshow ( image ) ax [ 0 ] . set_title ( \"Original Image\" , fontsize = 24 ) ax [ 1 ] . imshow ( conv ) ax [ 1 ] . set_title ( \"Convolved Image with vertical edges\" , fontsize = 24 ) plt . show () Well, I can easily make out the horizontal and vertical edges from the dog image! Actually, not so obvious if you don't look closely! conv_horizontal ( np . asarray ( dog )) conv_vertical ( np . asarray ( dog )) The issue is, I want to visualize what our models' conv layers are seeing, like for example, the first conv layer usually has 64 filters, that is a whooping 64 different combinations of filters, each doing a slightly different thing. A mental model that I have for the first conv layer looks something like the following. conv_1_filters = [ \"vertical edge detector\" , \"horizontal edge detector\" , \"slanted 45 degrees detector\" , \"slanted 180 degrees detector\" , ... ] Feature Extractor using PyTorch's native Feature Extraction Module In order to visualize properly, I made use of PyTorch's newest feature_extraction module to do so. Note that the new feature is still in development, but it does make my life easier and reduces overhead. I no longer need use hooks or what not to plot layer information! We just need to import from torchvision.models.feature_extraction import ( create_feature_extractor , get_graph_node_names ) def get_conv_layers ( model : torchvision . models ) -> Dict [ str , str ]: \"\"\"Create a function that give me the conv layers of PyTorch model. Args: model (Union[torchvision.models, timm.models]): A PyTorch model. Returns: conv_layers (Dict[str, str]): {\"layer1.0.conv1\": layer1.0.conv1, ...} \"\"\" conv_layers = {} for name , layer in model . named_modules (): if isinstance ( layer , torch . nn . Conv2d ): conv_layers [ name ] = name return conv_layers def get_feature_maps ( model_name : str , image : torch . Tensor , reduction : str = \"mean\" , pretrained : bool = True ) -> Union [ Dict [ str , torch . Tensor ], List [ torch . Tensor ], List [ str ]]: \"\"\"Function to plot feature maps from PyTorch models. Args: model_name (str): Name of the model to use. image (torch.Tensor): image should be a tensor of shape (1, 3, H, W) reduction (str, optional): Defaults to \"mean\". One of [\"mean\", \"max\", \"sum\"] pretrained (bool): whether the model is pretrained or not Raises: ValueError: Must use Torchvision models. Returns: model_feature_maps (Dict[str, torch.Tensor]): {\"conv_1\": conv_1_feature_map, ...} processed_feature_maps (List[torch.Tensor]): [conv_1_feature_map, ...] processed using a reduction method. feature_map_names (List[str]): [conv_1, ...] Example: >>> from torchvision.models.vgg import vgg16 >>> model = vgg16(pretrained=True) >>> image = torch.rand(1, 3, 224, 224) >>> feature_maps = get_feature_maps(model, image, reduction=\"mean\") Reduction: If a feature map has 4 filters, in the shape of (4, H, W) = (4, 32, 32), then the reduction can be done as follows: >>> reduction = \"mean\": There are 4 filters in this feature map, you can imagine it as 4 32x32 images. We sum up all 4 filters element-wise and get a single 32x32 image. Then we take the mean of all 32x32 images by dividing by num of kernels to get a single 32x32 image, which is reduction=\"mean\". \"\"\" try : model = getattr ( torchvision . models , model_name )( pretrained = pretrained ) except AttributeError : raise ValueError ( f \"Model { model_name } not found.\" ) train_nodes , eval_nodes = get_graph_node_names ( model ) logger . info ( f \"The train nodes of the model graph is: \\n\\n { train_nodes } \" ) return_conv_nodes = get_conv_layers ( model ) feature_extractor = create_feature_extractor ( model , return_nodes = return_conv_nodes ) # `model_feature_maps` will be a dict of Tensors, each representing a feature map model_feature_maps = feature_extractor ( image ) processed_feature_maps = [] feature_map_names = [] for conv_name , conv_feature_map in model_feature_maps . items (): conv_feature_map = conv_feature_map . squeeze ( dim = 0 ) num_filters = conv_feature_map . shape [ 0 ] if reduction == \"mean\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) / num_filters elif reduction == \"max\" : gray_scale = torch . max ( conv_feature_map , dim = 0 ) elif reduction == \"sum\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) processed_feature_maps . append ( gray_scale . data . cpu () . numpy ()) feature_map_names . append ( conv_name ) return model_feature_maps , processed_feature_maps , feature_map_names Visualizing VGG16 and ResNet18 Step 1: Initialize the models. As of now, I recommend using torchvision 's models. Ideally, I will want to use timm library for a more detailed list, but there are some bugs that is not easily integrated with the module. device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) import torchvision.models as models vgg16_pretrained_true = models . vgg16 ( pretrained = True ) vgg16_pretrained_true = vgg16_pretrained_true . to ( device ) resnet18_pretrained_true = models . resnet18 ( pretrained = True ) resnet18_pretrained_true = resnet18_pretrained_true . to ( device ) # Get node names train_nodes , eval_nodes = get_graph_node_names ( vgg16_pretrained_true ) logger . info ( f \"Train nodes of VGG16: \\n\\n { train_nodes } \" ) train_nodes , eval_nodes = get_graph_node_names ( resnet18_pretrained_true ) logger . info ( f \"Train nodes of ResNet18: \\n\\n { train_nodes } \" ) 2021-12-29 19:06:08: Train nodes of VGG16: ['x', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'features.13', 'features.14', 'features.15', 'features.16', 'features.17', 'features.18', 'features.19', 'features.20', 'features.21', 'features.22', 'features.23', 'features.24', 'features.25', 'features.26', 'features.27', 'features.28', 'features.29', 'features.30', 'avgpool', 'flatten', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6'] 2021-12-29 19:06:08: Train nodes of ResNet18: ['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avgpool', 'flatten', 'fc'] Good God! When I saw the layer names from vgg16 , I nearly fainted, I see no easy way to know which layer belongs to a Conv layer. I understand that get_graph_node_names will get all the nodes on the model's graph, but it is difficult to map the node names to a layer if it is named as such, seeing resnet18 's node names is much easier for one to identify which is conv layer or not. train_nodes , eval_nodes = get_graph_node_names ( model ) logger . info ( f \"The train nodes of the model graph is: \\n\\n { train_nodes } \" ) Thus I wrote a small function get_conv_layers to get the conv layer names. It is not perfect, as downsample layers (1x1 conv layers) are tagged under Conv2d but we may not really need to use them to visualize our feature maps. One can tweak a bit if need be, but for now, I will get all layers that use the Conv2d blocks. If the feature names in vgg16 are named with conv, then we can simply use a small loop below to find the conv layer names. conv_layers = [] for node in nodes : if \"conv\" in node : conv_layers . append ( node ) I actually thought ResNet18 has 18 conv layers, but even minusing to 3 downsample layers, it's 17 conv layers, wonder why? Step 2: Transform the Tensors The PyTorch feature_extraction expects the image input to be of shape [B,C,H,W] . # We use torchvision's transform to transform the cat image to channels first. cat_tensor = transform ( cat ) # Now feature_extractor expects batch_size x C x H x W, so we expand one dimension in the 0th dim cat_tensor = cat_tensor . unsqueeze ( dim = 0 ) . to ( device ) # We use torchvision's transform to transform the cat image with resize and normalization. # Conveniently, also making it channel first! cat_tensor = transform ( cat ) dog_tensor = transform ( dog ) assert cat_tensor . shape [ 0 ] == dog_tensor . shape [ 0 ] == 3 , \"PyTorch expects Channel First!\" # Now feature_extractor expects batch_size x C x H x W, so we expand one dimension in the 0th dim cat_tensor = cat_tensor . unsqueeze ( dim = 0 ) . to ( device ) dog_tensor = dog_tensor . unsqueeze ( dim = 0 ) . to ( device ) logger . info ( f \" \\n\\n cat_tensor's shape: \\n { cat_tensor . shape } \\n\\n dog_tensor's shape: \\n { dog_tensor . shape } \" ) 2021-12-29 19:06:10: cat_tensor's shape: torch.Size([1, 3, 224, 224]) dog_tensor's shape: torch.Size([1, 3, 224, 224]) Step 3: Plotting the Feature Maps We first walk through get_feature_maps and see what my function is doing. # Get node names train_nodes , eval_nodes = get_graph_node_names ( model ) # Since get node names do not indicate properly which is a conv layer or not, # we use get_conv_layer instead to do the job, which returns a dict {\"conv_layer_name\": \"conv_layer_name\"} return_conv_nodes = get_conv_layers ( model ) # call create_feature_extractor on the model and its corresponding conv layer names. feature_extractor = create_feature_extractor ( model , return_nodes = return_conv_nodes ) # `model_feature_maps` will be a dict of Tensors, each representing a feature map # {\"conv_layer_1\": output filter map,...} model_feature_maps = feature_extractor ( image ) # we need to further process the feature maps processed_feature_maps , feature_map_names = [], [] for conv_name , conv_feature_map in model_feature_maps . items (): # Squeeze the dimension from [1, 64, 32, 32] to [64, 32, 32] # This means we have 64 filters of 32x32 \"images\" or kernels conv_feature_map = conv_feature_map . squeeze ( dim = 0 ) # get number of feature/kernels in this layer num_filters = conv_feature_map . shape [ 0 ] # If a feature map has 4 filters, in the shape of (4, H, W) = (4, 32, 32), then the reduction mean can be done as follows: There are 4 filters in this feature map, you can imagine it as 4 32x32 images. # Step 1: We sum up all 4 filters element-wise and get a single 32x32 image. # Step 2: Then we take the mean of all 32x32 images to get a single 32x32 image, which is reduction=\"mean\". if reduction == \"mean\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) / num_filters elif reduction == \"max\" : gray_scale = torch . max ( conv_feature_map , dim = 0 ) elif reduction == \"sum\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) processed_feature_maps . append ( gray_scale . data . cpu () . numpy ()) feature_map_names . append ( conv_name ) _ , vgg16_processed_feature_maps , vgg16_feature_map_names = get_feature_maps ( model_name = \"vgg16\" , image = cat_tensor , reduction = \"mean\" , pretrained = True ) _ , resnet18_processed_feature_maps , resnet18_feature_map_names = get_feature_maps ( model_name = \"resnet18\" , image = cat_tensor , reduction = \"mean\" , pretrained = True ) 2021-12-29 19:06:12: The train nodes of the model graph is: ['x', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'features.13', 'features.14', 'features.15', 'features.16', 'features.17', 'features.18', 'features.19', 'features.20', 'features.21', 'features.22', 'features.23', 'features.24', 'features.25', 'features.26', 'features.27', 'features.28', 'features.29', 'features.30', 'avgpool', 'flatten', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6'] 2021-12-29 19:06:12: The train nodes of the model graph is: ['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avgpool', 'flatten', 'fc'] Then we create a simple plot_feature_maps that take in the processed_feature_maps and feature_map_names to plot them. def plot_feature_maps ( processed_feature_maps : List [ torch . Tensor ], feature_map_names : List [ str ], nrows : int , title : str = None ) -> None : \"\"\"Plot the feature maps. Args: processed_feature_maps (List[torch.Tensor]): [description] feature_map_names (List[str]): [description] nrows (int): [description] \"\"\" fig = plt . figure ( figsize = ( 30 , 50 )) ncols = len ( processed_feature_maps ) // nrows + 1 for i in range ( len ( processed_feature_maps )): a = fig . add_subplot ( nrows , ncols , i + 1 ) imgplot = plt . imshow ( processed_feature_maps [ i ]) a . axis ( \"off\" ) a . set_title ( feature_map_names [ i ] . split ( \"(\" )[ 0 ], fontsize = 30 ) fig . suptitle ( title , fontsize = 50 ) fig . tight_layout () fig . subplots_adjust ( top = 0.95 ) plt . savefig ( title , bbox_inches = 'tight' ) plt . show (); plot_feature_maps ( vgg16_processed_feature_maps , vgg16_feature_map_names , nrows = 5 , title = \"VGG16 Pretrained Feature Maps\" , ) plot_feature_maps ( resnet18_processed_feature_maps , resnet18_feature_map_names , nrows = 5 , title = \"ResNet18 Pretrained Feature Maps\" , ) Comparison with Randomly Initialized Weights We know that if the model is not pretrained, it will initialize with random weights using weight initialization methods such as Kaimin or Xavier. I expect the edges to be not so \"smooth\" as the ones that are pretrained! This is logical, as the filters in the conv layers are mostly random, and we have not trained any epochs yet, so let's see what it gives us. _ , vgg16_processed_feature_maps , vgg16_feature_map_names = get_feature_maps ( model_name = \"vgg16\" , image = cat_tensor , reduction = \"mean\" , pretrained = False ) _ , resnet18_processed_feature_maps , resnet18_feature_map_names = get_feature_maps ( model_name = \"resnet18\" , image = cat_tensor , reduction = \"mean\" , pretrained = False ) 2021-12-29 19:06:21: The train nodes of the model graph is: ['x', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'features.13', 'features.14', 'features.15', 'features.16', 'features.17', 'features.18', 'features.19', 'features.20', 'features.21', 'features.22', 'features.23', 'features.24', 'features.25', 'features.26', 'features.27', 'features.28', 'features.29', 'features.30', 'avgpool', 'flatten', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6'] 2021-12-29 19:06:21: The train nodes of the model graph is: ['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avgpool', 'flatten', 'fc'] plot_feature_maps ( vgg16_processed_feature_maps , vgg16_feature_map_names , nrows = 5 , title = \"VGG16 NOT Pretrained Feature Maps\" , ) plot_feature_maps ( resnet18_processed_feature_maps , resnet18_feature_map_names , nrows = 5 , title = \"ResNet18 NOT Pretrained Feature Maps\" , ) References: https://pytorch.org/vision/stable/feature_extraction.html https://ravivaishnav20.medium.com/visualizing-feature-maps-using-pytorch https://pytorch.org/blog/FX-feature-extraction-torchvision/ https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models","title":"EDA Visualizations for Image Recognition (Conv Filter Edition)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/#eda-visualizations-for-image-recognition-conv-filter-edition","text":"","title":"EDA Visualizations for Image Recognition (Conv Filter Edition)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/#dependencies-and-imports","text":"! pip install - q timm from typing import Dict import matplotlib.pyplot as plt import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import timm import torch import torchvision from torchvision.models.feature_extraction import ( create_feature_extractor , get_graph_node_names ) % matplotlib inline import glob import os from math import ceil import random import cv2 import PIL from IPython.core.interactiveshell import InteractiveShell InteractiveShell . ast_node_interactivity = \"all\" from typing import * # importing modules import urllib.request from PIL import Image","title":"Dependencies and Imports"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/#config-and-logging","text":"import logging from logging import INFO , FileHandler , Formatter , StreamHandler , getLogger def init_logger ( log_file : str = \"info.log\" ) -> logging . Logger : \"\"\"Initialize logger and save to file. Consider having more log_file paths to save, eg: debug.log, error.log, etc. Args: log_file (str, optional): [description]. Defaults to Path(LOGS_DIR, \"info.log\"). Returns: logging.Logger: [description] \"\"\" logger = getLogger ( __name__ ) logger . setLevel ( INFO ) stream_handler = StreamHandler () stream_handler . setFormatter ( Formatter ( \" %(asctime)s : %(message)s \" , \"%Y-%m- %d %H:%M:%S\" ) ) file_handler = FileHandler ( filename = log_file ) file_handler . setFormatter ( Formatter ( \" %(asctime)s : %(message)s \" , \"%Y-%m- %d %H:%M:%S\" ) ) logger . addHandler ( stream_handler ) logger . addHandler ( file_handler ) return logger logger = init_logger ()","title":"Config and Logging"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/#utils","text":"def plot_multiple_img ( img_matrix_list , title_list , ncols , main_title = \"\" ): fig , myaxes = plt . subplots ( figsize = ( 20 , 15 ), nrows = ceil ( len ( img_matrix_list ) / ncols ), ncols = ncols , squeeze = False , ) fig . suptitle ( main_title , fontsize = 30 ) fig . subplots_adjust ( wspace = 0.3 ) fig . subplots_adjust ( hspace = 0.3 ) for i , ( img , title ) in enumerate ( zip ( img_matrix_list , title_list )): myaxes [ i // ncols ][ i % ncols ] . imshow ( img ) myaxes [ i // ncols ][ i % ncols ] . set_title ( title , fontsize = 15 ) plt . show ()","title":"Utils"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/#seeding","text":"def seed_all ( seed : int = 1992 ) -> None : \"\"\"Seed all random number generators.\"\"\" print ( f \"Using Seed Number { seed } \" ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator # set fixed value for python built-in pseudo-random generator random . seed ( seed ) torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = True torch . backends . cudnn . enabled = True def seed_worker ( _worker_id ) -> None : \"\"\"Seed a worker with the given ID.\"\"\" worker_seed = torch . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) seed_all () Using Seed Number 1992","title":"Seeding"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/#transforms-params","text":"mean : List [ float ] = [ 0.485 , 0.456 , 0.406 ] std : List [ float ] = [ 0.229 , 0.224 , 0.225 ] image_size : int = 224 transform = torchvision . transforms . Compose ( [ torchvision . transforms . Resize (( image_size , image_size )), torchvision . transforms . ToTensor (), torchvision . transforms . Normalize ( mean = mean , std = std ), ] ) pre_normalize_transform = torchvision . transforms . Compose ( [ torchvision . transforms . Resize (( image_size , image_size )), torchvision . transforms . ToTensor (), ] )","title":"Transforms Params"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/#visualizations","text":"cat_p = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/deep_learning/computer_vision/data/misc/cat.jpg\" dog_p = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/deep_learning/computer_vision/data/misc/dog.jpg\" from urllib.request import urlopen # plot cat and dog with title using PIL plt . figure ( figsize = ( 10 , 10 )) plt . subplot ( 1 , 2 , 1 ) cat = PIL . Image . open ( urlopen ( cat_p )) plt . imshow ( cat . resize (( 1024 , 1024 ))) plt . title ( \"Cat\" ) plt . subplot ( 1 , 2 , 2 ) dog = PIL . Image . open ( urlopen ( dog_p )) plt . imshow ( dog . resize (( 1024 , 1024 ))) plt . title ( \"Dog\" ) plt . show ();","title":"Visualizations"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/#convolution-layers","text":"The image and content are referenced with courtesy from [Tarun's notebook](https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models](https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models). Convolution is a rather simple algorithm which involves a kernel (a 2D matrix) which moves over the entire image, calculating dot products with each window along the way. The GIF below demonstrates convolution in action. The above process can be summarized with an equation, where f is the image and h is the kernel. The dimensions of f are (m, n) and the kernel is a square matrix with dimensions smaller than f : \\( \\(\\text{conv}(f, h) = \\sum_{j}\\sum_{k}h_{jk} \\cdot f_{(m-j)(n-k)}\\) \\) In the above equation, the kernel h is moving across the length and breadth of the image. The dot product of h with a sub-matrix or window of matrix f is taken at each step, hence the double summation (rows and columns). I have always remembered from the revered Andrew Ng about how he taught us about what convolutional layers do. In the beginning, the conv layers are of low level abstraction, detailing a image's features such as shapes and sizes. In particular, he described to us the horizontal and vertical conv filters. As the conv layers go later, it will pick up on many abstract features, which is not really easily distinguished by human eyes. Below, we see an example of horizontal and vertical filters. def conv_horizontal ( image : np . ndarray ) -> None : \"\"\"Plot the horizontal convolution of the image. Args: image (torch.Tensor): [description] \"\"\" fig , ax = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 20 , 20 )) kernel = np . ones (( 3 , 3 ), np . float32 ) kernel [ 1 ] = np . array ([ 0 , 0 , 0 ], np . float32 ) kernel [ 2 ] = np . array ([ - 1 , - 1 , - 1 ], np . float32 ) conv = cv2 . filter2D ( image , - 1 , kernel ) ax [ 0 ] . imshow ( image ) ax [ 0 ] . set_title ( \"Original Image\" , fontsize = 24 ) ax [ 1 ] . imshow ( conv ) ax [ 1 ] . set_title ( \"Convolved Image with horizontal edges\" , fontsize = 24 ) plt . show () def conv_vertical ( image : np . ndarray ) -> None : \"\"\"Plot the vertical convolution of the image. Args: image (torch.Tensor): [description] \"\"\" fig , ax = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 20 , 20 )) kernel = np . ones (( 3 , 3 ), np . float32 ) kernel [ 0 ] = np . array ([ 1 , 0 , - 1 ]) kernel [ 1 ] = np . array ([ 1 , 0 , - 1 ]) kernel [ 2 ] = np . array ([ 1 , 0 , - 1 ]) conv = cv2 . filter2D ( image , - 1 , kernel ) ax [ 0 ] . imshow ( image ) ax [ 0 ] . set_title ( \"Original Image\" , fontsize = 24 ) ax [ 1 ] . imshow ( conv ) ax [ 1 ] . set_title ( \"Convolved Image with vertical edges\" , fontsize = 24 ) plt . show () Well, I can easily make out the horizontal and vertical edges from the dog image! Actually, not so obvious if you don't look closely! conv_horizontal ( np . asarray ( dog )) conv_vertical ( np . asarray ( dog )) The issue is, I want to visualize what our models' conv layers are seeing, like for example, the first conv layer usually has 64 filters, that is a whooping 64 different combinations of filters, each doing a slightly different thing. A mental model that I have for the first conv layer looks something like the following. conv_1_filters = [ \"vertical edge detector\" , \"horizontal edge detector\" , \"slanted 45 degrees detector\" , \"slanted 180 degrees detector\" , ... ]","title":"Convolution Layers "},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/#feature-extractor-using-pytorchs-native-feature-extraction-module","text":"In order to visualize properly, I made use of PyTorch's newest feature_extraction module to do so. Note that the new feature is still in development, but it does make my life easier and reduces overhead. I no longer need use hooks or what not to plot layer information! We just need to import from torchvision.models.feature_extraction import ( create_feature_extractor , get_graph_node_names ) def get_conv_layers ( model : torchvision . models ) -> Dict [ str , str ]: \"\"\"Create a function that give me the conv layers of PyTorch model. Args: model (Union[torchvision.models, timm.models]): A PyTorch model. Returns: conv_layers (Dict[str, str]): {\"layer1.0.conv1\": layer1.0.conv1, ...} \"\"\" conv_layers = {} for name , layer in model . named_modules (): if isinstance ( layer , torch . nn . Conv2d ): conv_layers [ name ] = name return conv_layers def get_feature_maps ( model_name : str , image : torch . Tensor , reduction : str = \"mean\" , pretrained : bool = True ) -> Union [ Dict [ str , torch . Tensor ], List [ torch . Tensor ], List [ str ]]: \"\"\"Function to plot feature maps from PyTorch models. Args: model_name (str): Name of the model to use. image (torch.Tensor): image should be a tensor of shape (1, 3, H, W) reduction (str, optional): Defaults to \"mean\". One of [\"mean\", \"max\", \"sum\"] pretrained (bool): whether the model is pretrained or not Raises: ValueError: Must use Torchvision models. Returns: model_feature_maps (Dict[str, torch.Tensor]): {\"conv_1\": conv_1_feature_map, ...} processed_feature_maps (List[torch.Tensor]): [conv_1_feature_map, ...] processed using a reduction method. feature_map_names (List[str]): [conv_1, ...] Example: >>> from torchvision.models.vgg import vgg16 >>> model = vgg16(pretrained=True) >>> image = torch.rand(1, 3, 224, 224) >>> feature_maps = get_feature_maps(model, image, reduction=\"mean\") Reduction: If a feature map has 4 filters, in the shape of (4, H, W) = (4, 32, 32), then the reduction can be done as follows: >>> reduction = \"mean\": There are 4 filters in this feature map, you can imagine it as 4 32x32 images. We sum up all 4 filters element-wise and get a single 32x32 image. Then we take the mean of all 32x32 images by dividing by num of kernels to get a single 32x32 image, which is reduction=\"mean\". \"\"\" try : model = getattr ( torchvision . models , model_name )( pretrained = pretrained ) except AttributeError : raise ValueError ( f \"Model { model_name } not found.\" ) train_nodes , eval_nodes = get_graph_node_names ( model ) logger . info ( f \"The train nodes of the model graph is: \\n\\n { train_nodes } \" ) return_conv_nodes = get_conv_layers ( model ) feature_extractor = create_feature_extractor ( model , return_nodes = return_conv_nodes ) # `model_feature_maps` will be a dict of Tensors, each representing a feature map model_feature_maps = feature_extractor ( image ) processed_feature_maps = [] feature_map_names = [] for conv_name , conv_feature_map in model_feature_maps . items (): conv_feature_map = conv_feature_map . squeeze ( dim = 0 ) num_filters = conv_feature_map . shape [ 0 ] if reduction == \"mean\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) / num_filters elif reduction == \"max\" : gray_scale = torch . max ( conv_feature_map , dim = 0 ) elif reduction == \"sum\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) processed_feature_maps . append ( gray_scale . data . cpu () . numpy ()) feature_map_names . append ( conv_name ) return model_feature_maps , processed_feature_maps , feature_map_names","title":"Feature Extractor using PyTorch's native Feature Extraction Module"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/#visualizing-vgg16-and-resnet18","text":"","title":"Visualizing VGG16 and ResNet18"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/#step-1-initialize-the-models","text":"As of now, I recommend using torchvision 's models. Ideally, I will want to use timm library for a more detailed list, but there are some bugs that is not easily integrated with the module. device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) import torchvision.models as models vgg16_pretrained_true = models . vgg16 ( pretrained = True ) vgg16_pretrained_true = vgg16_pretrained_true . to ( device ) resnet18_pretrained_true = models . resnet18 ( pretrained = True ) resnet18_pretrained_true = resnet18_pretrained_true . to ( device ) # Get node names train_nodes , eval_nodes = get_graph_node_names ( vgg16_pretrained_true ) logger . info ( f \"Train nodes of VGG16: \\n\\n { train_nodes } \" ) train_nodes , eval_nodes = get_graph_node_names ( resnet18_pretrained_true ) logger . info ( f \"Train nodes of ResNet18: \\n\\n { train_nodes } \" ) 2021-12-29 19:06:08: Train nodes of VGG16: ['x', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'features.13', 'features.14', 'features.15', 'features.16', 'features.17', 'features.18', 'features.19', 'features.20', 'features.21', 'features.22', 'features.23', 'features.24', 'features.25', 'features.26', 'features.27', 'features.28', 'features.29', 'features.30', 'avgpool', 'flatten', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6'] 2021-12-29 19:06:08: Train nodes of ResNet18: ['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avgpool', 'flatten', 'fc'] Good God! When I saw the layer names from vgg16 , I nearly fainted, I see no easy way to know which layer belongs to a Conv layer. I understand that get_graph_node_names will get all the nodes on the model's graph, but it is difficult to map the node names to a layer if it is named as such, seeing resnet18 's node names is much easier for one to identify which is conv layer or not. train_nodes , eval_nodes = get_graph_node_names ( model ) logger . info ( f \"The train nodes of the model graph is: \\n\\n { train_nodes } \" ) Thus I wrote a small function get_conv_layers to get the conv layer names. It is not perfect, as downsample layers (1x1 conv layers) are tagged under Conv2d but we may not really need to use them to visualize our feature maps. One can tweak a bit if need be, but for now, I will get all layers that use the Conv2d blocks. If the feature names in vgg16 are named with conv, then we can simply use a small loop below to find the conv layer names. conv_layers = [] for node in nodes : if \"conv\" in node : conv_layers . append ( node ) I actually thought ResNet18 has 18 conv layers, but even minusing to 3 downsample layers, it's 17 conv layers, wonder why?","title":"Step 1: Initialize the models."},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/#step-2-transform-the-tensors","text":"The PyTorch feature_extraction expects the image input to be of shape [B,C,H,W] . # We use torchvision's transform to transform the cat image to channels first. cat_tensor = transform ( cat ) # Now feature_extractor expects batch_size x C x H x W, so we expand one dimension in the 0th dim cat_tensor = cat_tensor . unsqueeze ( dim = 0 ) . to ( device ) # We use torchvision's transform to transform the cat image with resize and normalization. # Conveniently, also making it channel first! cat_tensor = transform ( cat ) dog_tensor = transform ( dog ) assert cat_tensor . shape [ 0 ] == dog_tensor . shape [ 0 ] == 3 , \"PyTorch expects Channel First!\" # Now feature_extractor expects batch_size x C x H x W, so we expand one dimension in the 0th dim cat_tensor = cat_tensor . unsqueeze ( dim = 0 ) . to ( device ) dog_tensor = dog_tensor . unsqueeze ( dim = 0 ) . to ( device ) logger . info ( f \" \\n\\n cat_tensor's shape: \\n { cat_tensor . shape } \\n\\n dog_tensor's shape: \\n { dog_tensor . shape } \" ) 2021-12-29 19:06:10: cat_tensor's shape: torch.Size([1, 3, 224, 224]) dog_tensor's shape: torch.Size([1, 3, 224, 224])","title":"Step 2: Transform the Tensors"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/#step-3-plotting-the-feature-maps","text":"We first walk through get_feature_maps and see what my function is doing. # Get node names train_nodes , eval_nodes = get_graph_node_names ( model ) # Since get node names do not indicate properly which is a conv layer or not, # we use get_conv_layer instead to do the job, which returns a dict {\"conv_layer_name\": \"conv_layer_name\"} return_conv_nodes = get_conv_layers ( model ) # call create_feature_extractor on the model and its corresponding conv layer names. feature_extractor = create_feature_extractor ( model , return_nodes = return_conv_nodes ) # `model_feature_maps` will be a dict of Tensors, each representing a feature map # {\"conv_layer_1\": output filter map,...} model_feature_maps = feature_extractor ( image ) # we need to further process the feature maps processed_feature_maps , feature_map_names = [], [] for conv_name , conv_feature_map in model_feature_maps . items (): # Squeeze the dimension from [1, 64, 32, 32] to [64, 32, 32] # This means we have 64 filters of 32x32 \"images\" or kernels conv_feature_map = conv_feature_map . squeeze ( dim = 0 ) # get number of feature/kernels in this layer num_filters = conv_feature_map . shape [ 0 ] # If a feature map has 4 filters, in the shape of (4, H, W) = (4, 32, 32), then the reduction mean can be done as follows: There are 4 filters in this feature map, you can imagine it as 4 32x32 images. # Step 1: We sum up all 4 filters element-wise and get a single 32x32 image. # Step 2: Then we take the mean of all 32x32 images to get a single 32x32 image, which is reduction=\"mean\". if reduction == \"mean\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) / num_filters elif reduction == \"max\" : gray_scale = torch . max ( conv_feature_map , dim = 0 ) elif reduction == \"sum\" : gray_scale = torch . sum ( conv_feature_map , dim = 0 ) processed_feature_maps . append ( gray_scale . data . cpu () . numpy ()) feature_map_names . append ( conv_name ) _ , vgg16_processed_feature_maps , vgg16_feature_map_names = get_feature_maps ( model_name = \"vgg16\" , image = cat_tensor , reduction = \"mean\" , pretrained = True ) _ , resnet18_processed_feature_maps , resnet18_feature_map_names = get_feature_maps ( model_name = \"resnet18\" , image = cat_tensor , reduction = \"mean\" , pretrained = True ) 2021-12-29 19:06:12: The train nodes of the model graph is: ['x', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'features.13', 'features.14', 'features.15', 'features.16', 'features.17', 'features.18', 'features.19', 'features.20', 'features.21', 'features.22', 'features.23', 'features.24', 'features.25', 'features.26', 'features.27', 'features.28', 'features.29', 'features.30', 'avgpool', 'flatten', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6'] 2021-12-29 19:06:12: The train nodes of the model graph is: ['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avgpool', 'flatten', 'fc'] Then we create a simple plot_feature_maps that take in the processed_feature_maps and feature_map_names to plot them. def plot_feature_maps ( processed_feature_maps : List [ torch . Tensor ], feature_map_names : List [ str ], nrows : int , title : str = None ) -> None : \"\"\"Plot the feature maps. Args: processed_feature_maps (List[torch.Tensor]): [description] feature_map_names (List[str]): [description] nrows (int): [description] \"\"\" fig = plt . figure ( figsize = ( 30 , 50 )) ncols = len ( processed_feature_maps ) // nrows + 1 for i in range ( len ( processed_feature_maps )): a = fig . add_subplot ( nrows , ncols , i + 1 ) imgplot = plt . imshow ( processed_feature_maps [ i ]) a . axis ( \"off\" ) a . set_title ( feature_map_names [ i ] . split ( \"(\" )[ 0 ], fontsize = 30 ) fig . suptitle ( title , fontsize = 50 ) fig . tight_layout () fig . subplots_adjust ( top = 0.95 ) plt . savefig ( title , bbox_inches = 'tight' ) plt . show (); plot_feature_maps ( vgg16_processed_feature_maps , vgg16_feature_map_names , nrows = 5 , title = \"VGG16 Pretrained Feature Maps\" , ) plot_feature_maps ( resnet18_processed_feature_maps , resnet18_feature_map_names , nrows = 5 , title = \"ResNet18 Pretrained Feature Maps\" , )","title":"Step 3: Plotting the Feature Maps"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/02_conv_filters/Visualizing%20Convolutional%20Filters/#comparison-with-randomly-initialized-weights","text":"We know that if the model is not pretrained, it will initialize with random weights using weight initialization methods such as Kaimin or Xavier. I expect the edges to be not so \"smooth\" as the ones that are pretrained! This is logical, as the filters in the conv layers are mostly random, and we have not trained any epochs yet, so let's see what it gives us. _ , vgg16_processed_feature_maps , vgg16_feature_map_names = get_feature_maps ( model_name = \"vgg16\" , image = cat_tensor , reduction = \"mean\" , pretrained = False ) _ , resnet18_processed_feature_maps , resnet18_feature_map_names = get_feature_maps ( model_name = \"resnet18\" , image = cat_tensor , reduction = \"mean\" , pretrained = False ) 2021-12-29 19:06:21: The train nodes of the model graph is: ['x', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'features.13', 'features.14', 'features.15', 'features.16', 'features.17', 'features.18', 'features.19', 'features.20', 'features.21', 'features.22', 'features.23', 'features.24', 'features.25', 'features.26', 'features.27', 'features.28', 'features.29', 'features.30', 'avgpool', 'flatten', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6'] 2021-12-29 19:06:21: The train nodes of the model graph is: ['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'avgpool', 'flatten', 'fc'] plot_feature_maps ( vgg16_processed_feature_maps , vgg16_feature_map_names , nrows = 5 , title = \"VGG16 NOT Pretrained Feature Maps\" , ) plot_feature_maps ( resnet18_processed_feature_maps , resnet18_feature_map_names , nrows = 5 , title = \"ResNet18 NOT Pretrained Feature Maps\" , ) References: https://pytorch.org/vision/stable/feature_extraction.html https://ravivaishnav20.medium.com/visualizing-feature-maps-using-pytorch https://pytorch.org/blog/FX-feature-extraction-torchvision/ https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models","title":"Comparison with Randomly Initialized Weights"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/%28archived%29%20gradcam_from_scratch/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\L}{\\mathbf{L}} \\newcommand{\\X}{\\mathbf{X}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\] Dependencies and Config from typing import * import cv2 import matplotlib.pyplot as plt import numpy as np import torch import torch.nn as nn import torchsummary import torchvision from torch.utils import data from torchvision import datasets , transforms from torchvision.models import vgg19 , resnet34 import os import random # Display from IPython.display import Image , display from pytorch_grad_cam import GradCAM from pytorch_grad_cam.utils.image import show_cam_on_image % cd .. import utils device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) utils . seed_all () We will be using three sample images from ImageNet dataset. elephant_path = \"../images/animals/elephant.png\" single_cat_path = \"../images/animals/cat.jpg\" dog_and_cat_path = \"../images/animals/dog_and_cat.jpg\" Dataset and Dataloader We create a simple PyTorch Dataset that reads and return one single image, this is to illustrate our example easily. from torch.utils.data import Dataset class CustomDataset ( Dataset ): def __init__ ( self , image_path , target = None , transform = None ): \"\"\"This Dataset reads 1 image at a time. Args: image_path (_type_): The path to the image target (_type_): The target class of the image transform (_type_, optional): The transform to apply to the image \"\"\" self . image_path = image_path self . target = target self . transform = transform def __len__ ( self ): \"\"\"This loader only returns 1 image at a time Returns: The length of the dataset \"\"\" return 1 def __getitem__ ( self , x ): # read 1 image only so no need subset idx image_path = self . image_path image = cv2 . imread ( image_path ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) if self . target is None : # force assign 0 tensor to be compatible with loader self . target = torch . zeros ( 0 ) if self . transform is not None : image = self . transform ( image ) return image , self . target Transforms We use some default transforms of image size 224 with ImageNet mean and standard deviation. # use the ImageNet transformation transform = transforms . Compose ( [ transforms . ToPILImage (), transforms . Resize (( 224 , 224 )), transforms . ToTensor (), transforms . Normalize ( mean = [ 0.485 , 0.456 , 0.406 ], std = [ 0.229 , 0.224 , 0.225 ] ), ] ) Create the DataLoaders We create the three datasets and dataloaders below. # define a 1 image dataset elephant_dataset = CustomDataset ( image_path = elephant_path , transform = transform ) cat_dataset = CustomDataset ( image_path = single_cat_path , transform = transform ) dog_and_cat_dataset = CustomDataset ( image_path = dog_and_cat_path , transform = transform ) # define the dataloader to load that single image elephant_dataloader = torch . utils . data . DataLoader ( dataset = elephant_dataset , shuffle = False , batch_size = 1 ) cat_dataloader = torch . utils . data . DataLoader ( dataset = cat_dataset , shuffle = False , batch_size = 1 ) dog_and_cat_dataloader = torch . utils . data . DataLoader ( dataset = dog_and_cat_dataset , shuffle = False , batch_size = 1 ) Sanity Check We get a feel if our dataloader is working by plotting the image in the loader. # get some random training images dataiter = iter ( dog_and_cat_dataloader ) images , targets = dataiter . next () # show images plt . imshow ( np . transpose ( torchvision . utils . make_grid ( images ), ( 1 , 2 , 0 ))) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). <matplotlib.image.AxesImage at 0x17f73646640> Models Checking the Layers We use a library to output the layer information like Keras's model.summary() . We need to identify the last convolutional layer. def torchsummary_wrapper ( model , image_size : Tuple [ int , int , int ] ) -> torchsummary . model_statistics . ModelStatistics : \"\"\"A torch wrapper to print out layers of a Model. Args: model (CustomNeuralNet): Model. image_size (Tuple[int, int, int]): Image size as a tuple of (channels, height, width). Returns: model_summary (torchsummary.model_statistics.ModelStatistics): Model summary. \"\"\" model_summary = torchsummary . summary ( model , image_size ) return model_summary vgg19_ = vgg19 ( pretrained = True ) resnet34_ = resnet34 ( pretrained = True ) Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to C:\\Users\\reighns/.cache\\torch\\hub\\checkpoints\\resnet34-b627a593.pth 0%| | 0.00/83.3M [00:00<?, ?B/s] vgg19_model_summary = torchsummary_wrapper ( vgg19_ , image_size = ( 3 , 224 , 224 )) ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== \u251c\u2500Sequential: 1-1 [-1, 512, 7, 7] -- | \u2514\u2500Conv2d: 2-1 [-1, 64, 224, 224] 1,792 | \u2514\u2500ReLU: 2-2 [-1, 64, 224, 224] -- | \u2514\u2500Conv2d: 2-3 [-1, 64, 224, 224] 36,928 | \u2514\u2500ReLU: 2-4 [-1, 64, 224, 224] -- | \u2514\u2500MaxPool2d: 2-5 [-1, 64, 112, 112] -- | \u2514\u2500Conv2d: 2-6 [-1, 128, 112, 112] 73,856 | \u2514\u2500ReLU: 2-7 [-1, 128, 112, 112] -- | \u2514\u2500Conv2d: 2-8 [-1, 128, 112, 112] 147,584 | \u2514\u2500ReLU: 2-9 [-1, 128, 112, 112] -- | \u2514\u2500MaxPool2d: 2-10 [-1, 128, 56, 56] -- | \u2514\u2500Conv2d: 2-11 [-1, 256, 56, 56] 295,168 | \u2514\u2500ReLU: 2-12 [-1, 256, 56, 56] -- | \u2514\u2500Conv2d: 2-13 [-1, 256, 56, 56] 590,080 | \u2514\u2500ReLU: 2-14 [-1, 256, 56, 56] -- | \u2514\u2500Conv2d: 2-15 [-1, 256, 56, 56] 590,080 | \u2514\u2500ReLU: 2-16 [-1, 256, 56, 56] -- | \u2514\u2500Conv2d: 2-17 [-1, 256, 56, 56] 590,080 | \u2514\u2500ReLU: 2-18 [-1, 256, 56, 56] -- | \u2514\u2500MaxPool2d: 2-19 [-1, 256, 28, 28] -- | \u2514\u2500Conv2d: 2-20 [-1, 512, 28, 28] 1,180,160 | \u2514\u2500ReLU: 2-21 [-1, 512, 28, 28] -- | \u2514\u2500Conv2d: 2-22 [-1, 512, 28, 28] 2,359,808 | \u2514\u2500ReLU: 2-23 [-1, 512, 28, 28] -- | \u2514\u2500Conv2d: 2-24 [-1, 512, 28, 28] 2,359,808 | \u2514\u2500ReLU: 2-25 [-1, 512, 28, 28] -- | \u2514\u2500Conv2d: 2-26 [-1, 512, 28, 28] 2,359,808 | \u2514\u2500ReLU: 2-27 [-1, 512, 28, 28] -- | \u2514\u2500MaxPool2d: 2-28 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-29 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-30 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-31 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-32 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-33 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-34 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-35 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-36 [-1, 512, 14, 14] -- | \u2514\u2500MaxPool2d: 2-37 [-1, 512, 7, 7] -- \u251c\u2500AdaptiveAvgPool2d: 1-2 [-1, 512, 7, 7] -- \u251c\u2500Sequential: 1-3 [-1, 1000] -- | \u2514\u2500Linear: 2-38 [-1, 4096] 102,764,544 | \u2514\u2500ReLU: 2-39 [-1, 4096] -- | \u2514\u2500Dropout: 2-40 [-1, 4096] -- | \u2514\u2500Linear: 2-41 [-1, 4096] 16,781,312 | \u2514\u2500ReLU: 2-42 [-1, 4096] -- | \u2514\u2500Dropout: 2-43 [-1, 4096] -- | \u2514\u2500Linear: 2-44 [-1, 1000] 4,097,000 ========================================================================================== Total params: 143,667,240 Trainable params: 143,667,240 Non-trainable params: 0 Total mult-adds (G): 19.78 ========================================================================================== Input size (MB): 0.57 Forward/backward pass size (MB): 113.38 Params size (MB): 548.05 Estimated Total Size (MB): 662.00 ========================================================================================== # resnet34_model_summary = torchsummary_wrapper(resnet34_, image_size = (3, 224, 224)) Define our Target Layers We define what our target layers would be for the respective models. # this is the last conv layer layer 35 from Francis's book right after conv2d + relu, but https://github.com/jacobgil/pytorch-grad-cam suggests [-1] where it is max pooled. Can try both. vgg19_last_conv_layer = vgg19_ . features [ - 2 ] print ( vgg19_last_conv_layer ) resnet34_last_conv_layer = resnet34_ . layer4 [ - 1 ] print ( resnet34_last_conv_layer ) ReLU(inplace=True) BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) Store Forward and Backward Hooks These function help us to get forward activations and backward gradients. forward_activations = OrderedDict () backward_gradients = OrderedDict () def get_forward_hook ( name : str ) -> Callable : \"\"\"Get the intermediate features of a model. Forward Hook. This is using forward hook with reference https://discuss.pytorch.org/t/how-can-l-load-my-best-model-as-a-feature-extractor-evaluator/17254/5 Args: name (str): name of the layer. Returns: Callable: [description] \"\"\" def forward_hook ( model , input , output ): forward_activations [ name ] = output . detach () return forward_hook def get_backward_hook ( name : str ) -> Callable : \"\"\"Get the intermediate features of a model. Backward Hook. This is using backward hook with reference https://discuss.pytorch.org/t/how-can-l-load-my-best-model-as-a-feature-extractor-evaluator/17254/5 Args: name (str): name of the layer. Returns: Callable: [description] \"\"\" def backward_hook ( model , grad_input , grad_output ): backward_gradients [ name ] = grad_output [ 0 ] . detach () return backward_hook Step by Step Walkthrough Skip to the next section if you are familiar with the Grad-CAM process. vgg19_last_conv_layer . register_forward_hook ( get_forward_hook ( \"features.35\" )) vgg19_last_conv_layer . register_backward_hook ( get_backward_hook ( \"features.35\" )) # register_backward_hook deprecated but for now we use it <torch.utils.hooks.RemovableHandle at 0x1a39f0623a0> # set the evaluation mode vgg19_ . eval () # get the image from the dataloader image , _ = next ( iter ( elephant_dataloader )) # the y_logits before softmax y_logits = vgg19_ ( image ) target_category = None if target_category is None : # get the most likely prediction of the model target_category = vgg19_ ( image ) . argmax ( dim = 1 ) target_category = target_category . item () # convert to scalar # get the activations of the last convolutional layer forward_conv_activations = forward_activations [ \"features.35\" ] y_logits [:, target_category ] . backward () dyc_dA = backward_gradients [ \"features.35\" ] # average pool the gradients across the channels global_average_pooled_gradients = torch . mean ( dyc_dA , dim = [ 0 , 2 , 3 ]) num_feature_maps = 512 weighted_localization_map = torch . clone ( forward_conv_activations ) # weight the channels by corresponding gradients for i in range ( num_feature_maps ): weighted_localization_map [:, i , :, :] *= global_average_pooled_gradients [ i ] # sum the channels of the activations weighted_localization_map = torch . sum ( weighted_localization_map , dim = 1 ) . squeeze () assert weighted_localization_map . shape == ( 14 , 14 ) # relu on top of the heatmap expression (2) in https://arxiv.org/pdf/1610.02391.pdf relu_weighted_localization_map = torch . nn . ReLU ( inplace = False )( weighted_localization_map ) # normalize the heatmap, scale features to between 0 and 1 to plot heatmap = relu_weighted_localization_map / torch . max ( relu_weighted_localization_map ) # draw the heatmap plt . matshow ( heatmap . squeeze ()) tensor([[0.1695, 0.1367, 0.1292, 0.1435, 0.1037, 0.0376, 0.0048, 0.0520, 0.1114, 0.1495, 0.1856, 0.1638, 0.0733, 0.2405], [0.1262, 0.0933, 0.1134, 0.1632, 0.0805, 0.0000, 0.0000, 0.0254, 0.1456, 0.2702, 0.2565, 0.1883, 0.0819, 0.1331], [0.1508, 0.1267, 0.1541, 0.2010, 0.0570, 0.0000, 0.0000, 0.0973, 0.5866, 0.8733, 0.8954, 0.7577, 0.2693, 0.2221], [0.1884, 0.1376, 0.0959, 0.0888, 0.0000, 0.0000, 0.0715, 0.3818, 0.8004, 1.0000, 0.9425, 0.7478, 0.2823, 0.1800], [0.1931, 0.1158, 0.0351, 0.1330, 0.1786, 0.1146, 0.1243, 0.3891, 0.6943, 0.7773, 0.6895, 0.5610, 0.2427, 0.1264], [0.1552, 0.1056, 0.0473, 0.2595, 0.4205, 0.4517, 0.3047, 0.2987, 0.3538, 0.3354, 0.3093, 0.3014, 0.2003, 0.1028], [0.1290, 0.0747, 0.0794, 0.2144, 0.3984, 0.4928, 0.3979, 0.2380, 0.1140, 0.0156, 0.0354, 0.1017, 0.0838, 0.0565], [0.1351, 0.0931, 0.0892, 0.2174, 0.2635, 0.2547, 0.2120, 0.0853, 0.0532, 0.0892, 0.0746, 0.0637, 0.0590, 0.0669], [0.1265, 0.1018, 0.1014, 0.1031, 0.0350, 0.0000, 0.0000, 0.0000, 0.0760, 0.1283, 0.0963, 0.0719, 0.0648, 0.1028], [0.1022, 0.0842, 0.0833, 0.0784, 0.0661, 0.0453, 0.0620, 0.0855, 0.0810, 0.0651, 0.0514, 0.0575, 0.0807, 0.0874], [0.0744, 0.0565, 0.0446, 0.0513, 0.0579, 0.0656, 0.0686, 0.0619, 0.0518, 0.0432, 0.0352, 0.0422, 0.0603, 0.0671], [0.0691, 0.0449, 0.0282, 0.0311, 0.0371, 0.0427, 0.0493, 0.0538, 0.0555, 0.0554, 0.0536, 0.0601, 0.0876, 0.1001], [0.0985, 0.0838, 0.0768, 0.0767, 0.0800, 0.0848, 0.0896, 0.0934, 0.0930, 0.0902, 0.0896, 0.0985, 0.1177, 0.1245], [0.1639, 0.1344, 0.1271, 0.1290, 0.1266, 0.1226, 0.1187, 0.1174, 0.1148, 0.1075, 0.1006, 0.0996, 0.1054, 0.1203]]) <matplotlib.image.AxesImage at 0x1a39f0dc0d0> img = cv2 . imread ( elephant_path ) heatmap = cv2 . resize ( heatmap . cpu () . detach () . numpy (), ( img . shape [ 1 ], img . shape [ 0 ])) heatmap = np . uint8 ( 255 * heatmap ) heatmap = cv2 . applyColorMap ( heatmap , cv2 . COLORMAP_JET ) superimposed_img = heatmap * 0.4 + img cv2 . imwrite ( './elephant_gradcam.jpg' , superimposed_img ) True Function for Grad-CAM Heatmap def make_gradcam_heatmap ( target_layer : torch . nn . Module , target_layer_name : str , model : torch . nn . Module , image : torch . Tensor , target_category : Optional [ int ] = None , ): \"\"\"_summary_ Args: target_layer (str): _description_ model (torch.nn.Module): _description_ image (torch.Tensor): _description_ target_category (Optional[int], optional): _description_. Defaults to None. \"\"\" target_layer . register_forward_hook ( get_forward_hook ( target_layer_name ) ) target_layer . register_backward_hook ( get_backward_hook ( target_layer_name ) ) # register_backward_hook deprecated but for now we use it model . eval () # the y_logits before softmax y_logits = model ( image ) if target_category is None : # get the most likely prediction of the model target_category = model ( image ) . argmax ( dim = 1 ) target_category = target_category . item () # convert to scalar # get the activations of the last convolutional layer forward_conv_activations = forward_activations [ target_layer_name ] y_logits [:, target_category ] . backward () dyc_dA = backward_gradients [ target_layer_name ] # average pool the gradients across the channels global_average_pooled_gradients = torch . mean ( dyc_dA , dim = [ 0 , 2 , 3 ]) num_feature_maps = forward_conv_activations . squeeze () . shape [ 0 ] weighted_localization_map = torch . clone ( forward_conv_activations ) # weight the channels by corresponding gradients for i in range ( num_feature_maps ): weighted_localization_map [ :, i , :, : ] *= global_average_pooled_gradients [ i ] # sum the channels of the activations weighted_localization_map = torch . sum ( weighted_localization_map , dim = 1 ) . squeeze () # relu on top of the heatmap expression (2) in https://arxiv.org/pdf/1610.02391.pdf relu_weighted_localization_map = torch . nn . ReLU ( inplace = False )( weighted_localization_map ) # normalize the heatmap, scale features to between 0 and 1 to plot heatmap = relu_weighted_localization_map / torch . max ( relu_weighted_localization_map ) # draw the heatmap plt . matshow ( heatmap . squeeze ()) return heatmap cat_image , _ = next ( iter ( cat_dataloader )) dog_and_cat_image , _ = next ( iter ( dog_and_cat_dataloader )) elephant_image , _ = next ( iter ( elephant_dataloader )) dog_and_cat_heatmap = make_gradcam_heatmap ( target_layer = vgg19_last_conv_layer , target_layer_name = \"vgg19.feature.35\" , model = vgg19_ , image = dog_and_cat_image , target_category = None ) dog_and_cat_heatmap_resnet34 = make_gradcam_heatmap ( target_layer = resnet34_last_conv_layer , target_layer_name = \"resnet34.layer4[-1]\" , model = resnet34_ , image = dog_and_cat_image , target_category = None ) dog_and_cat_heatmap_resnet34_target_dog = make_gradcam_heatmap ( target_layer = resnet34_last_conv_layer , target_layer_name = \"resnet34.layer4[-1]\" , model = resnet34_ , image = dog_and_cat_image , target_category = 260 ) dog_and_cat_heatmap_resnet34_target_cat = make_gradcam_heatmap ( target_layer = resnet34_last_conv_layer , target_layer_name = \"resnet34.layer4[-1]\" , model = resnet34_ , image = dog_and_cat_image , target_category = 285 ) cat_heatmap = make_gradcam_heatmap ( target_layer = vgg19_last_conv_layer , target_layer_name = \"vgg19.feature.35\" , model = vgg19_ , image = cat_image , target_category = None ) cat_heatmap_resnet34 = make_gradcam_heatmap ( target_layer = resnet34_last_conv_layer , target_layer_name = \"resnet34.layer4[-1]\" , model = resnet34_ , image = cat_image , target_category = None ) elephant_heatmap = make_gradcam_heatmap ( target_layer = vgg19_last_conv_layer , target_layer_name = \"vgg19.features.35\" , model = vgg19_ , image = elephant_image , target_category = None ) elephant_heatmap_resnet34 = make_gradcam_heatmap ( target_layer = resnet34_last_conv_layer , target_layer_name = \"resnet34.layer4[-1]\" , model = resnet34_ , image = elephant_image , target_category = None ) # def save_and_display_gradcam( # image_path, heatmap, image_size=None, cam_path=\"./cat_gradcam.jpg\", alpha=0.4 # ): # # cv2 imread auto reads as BGR # image = cv2.imread(image_path) # if image_size is not None: # image = cv2.resize(image, (image_size, image_size)) # if not isinstance(heatmap, np.ndarray): # heatmap = heatmap.cpu().detach().numpy() # heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0])) # heatmap = np.uint8(255 * heatmap) # heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET) # superimposed_image = heatmap * alpha + image # cv2.imwrite(cam_path, superimposed_image) # return np.uint8(superimposed_image) def save_and_display_gradcam ( image_path , heatmap , image_size = None , cam_path = \"./cat_gradcam.jpg\" , alpha = 0.4 , use_rgb = False , ): \"\"\"_summary_ Args: image_path (_type_): _description_ heatmap (_type_): _description_ image_size (_type_, optional): _description_. Defaults to None. cam_path (str, optional): _description_. Defaults to \"./cat_gradcam.jpg\". alpha (float, optional): _description_. Defaults to 0.4. Returns: _type_: _description_ \"\"\" # Load original image, cv2 imread auto reads as BGR image = cv2 . imread ( image_path ) if image_size is not None : image = cv2 . resize ( image , ( image_size , image_size )) if isinstance ( heatmap , torch . Tensor ): heatmap = heatmap . cpu () . detach () . numpy () # Rescale heatmap to a range 0-255 heatmap = np . uint8 ( 255 * heatmap ) # Use Jet colormap to colorize heatmap heatmap = cv2 . applyColorMap ( heatmap , cv2 . COLORMAP_JET ) if use_rgb : image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) heatmap = cv2 . cvtColor ( heatmap , cv2 . COLOR_BGR2RGB ) # resize heatmap to original image size heatmap = cv2 . resize ( heatmap , ( image . shape [ 1 ], image . shape [ 0 ])) superimposed_image = heatmap * alpha + image cv2 . imwrite ( cam_path , superimposed_image ) # Display Grad CAM display ( Image ( cam_path )) return np . uint8 ( superimposed_image ) # def save_and_display_gradcam( # image_path, heatmap, cam_path=\"./cat_gradcam.jpg\", alpha=0.4 # ): # image = cv2.imread(image_path) # heatmap = cv2.resize( # heatmap.cpu().detach().numpy(), (image.shape[1], image.shape[0]) # ) # heatmap = np.uint8(255 * heatmap) # heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET) # superimposed_image = heatmap * alpha + image # cv2.imwrite(cam_path, superimposed_image) # return superimposed_image elephant_gradcam_vgg19 = save_and_display_gradcam ( image_path = elephant_path , heatmap = elephant_heatmap , image_size = 224 , cam_path = \"./elephant_gradcam.jpg\" , alpha = 0.4 , use_rgb = False ) cat_gradcam_vgg19 = save_and_display_gradcam ( image_path = single_cat_path , heatmap = cat_heatmap , image_size = 224 , cam_path = \"./cat_gradcam.jpg\" , alpha = 0.4 , use_rgb = False ) cat_gradcam_resnet34 = save_and_display_gradcam ( image_path = single_cat_path , heatmap = cat_heatmap_resnet34 , image_size = 224 , cam_path = \"./cat_gradcam_resnet34.jpg\" , alpha = 0.4 ) elephant_gradcam_resnet34 = save_and_display_gradcam ( image_path = elephant_path , heatmap = elephant_heatmap_resnet34 , image_size = 224 , cam_path = \"./elephant_gradcam_resnet34.jpg\" , alpha = 0.4 ) dog_and_cat_gradcam_resnet34 = save_and_display_gradcam ( image_path = dog_and_cat_path , heatmap = dog_and_cat_heatmap_resnet34 , image_size = 224 , cam_path = \"./dog_and_cat_gradcam_resnet34.jpg\" , alpha = 0.4 ) dog_and_cat_gradcam_resnet34_target_dog = save_and_display_gradcam ( image_path = dog_and_cat_path , heatmap = dog_and_cat_heatmap_resnet34_target_dog , image_size = 224 , cam_path = \"./dog_and_cat_gradcam_target_dog_resnet34.jpg\" , alpha = 0.4 ) dog_and_cat_gradcam_resnet34_target_dog = save_and_display_gradcam ( image_path = dog_and_cat_path , heatmap = dog_and_cat_heatmap_resnet34_target_cat , image_size = 224 , cam_path = \"./dog_and_cat_gradcam_target_cat_resnet34.jpg\" , alpha = 0.4 ) save_and_display_gradcam ( image_path = dog_and_cat_path , heatmap = dog_and_cat_heatmap , cam_path = \"./dog_and_cat_gradcam.jpg\" , alpha = 0.4 ) image = cv2 . imread ( single_cat_path ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) # needed for gradcam. original_image = cv2 . resize ( image , ( 224 , 224 )) from pytorch_grad_cam import GradCAM , ScoreCAM , GradCAMPlusPlus , AblationCAM , XGradCAM , EigenCAM , FullGrad # from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget from pytorch_grad_cam.utils.image import show_cam_on_image from torchvision.models import resnet50 , vgg19 , resnet34 model = resnet34 ( pretrained = True ) target_layers = [ model . layer4 [ - 1 ]] input_tensor = cat_image # Create an input tensor image for your model.. # Note: input_tensor can be a batch tensor with several images! # Construct the CAM object once, and then re-use it on many images: cam = GradCAM ( model = model , target_layers = target_layers , use_cuda = False ) # You can also use it within a with statement, to make sure it is freed, # In case you need to re-create it inside an outer loop: # with GradCAM(model=model, target_layers=target_layers, use_cuda=args.use_cuda) as cam: # ... # We have to specify the target we want to generate # the Class Activation Maps for. # If targets is None, the highest scoring category # will be used for every image in the batch. # Here we use ClassifierOutputTarget, but you can define your own custom targets # That are, for example, combinations of categories, or specific outputs in a non standard model. target_category = None # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing. grayscale_cam = cam ( input_tensor = input_tensor , target_category = target_category ) # In this example grayscale_cam has only one image in the batch: grayscale_cam = grayscale_cam [ 0 , :] cat_image_normalized = original_image / 255. cat_image_normalized . shape (224, 224, 3) visualization = show_cam_on_image ( cat_image_normalized , grayscale_cam , use_rgb = True ) _fig , axes = plt . subplots ( figsize = ( 8 , 8 ), ncols = 2 ) axes [ 0 ] . imshow ( cat_image_normalized ) axes [ 1 ] . imshow ( visualization ) plt . show () torch . cuda . empty_cache ()","title":"(archived) gradcam from scratch"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/%28archived%29%20gradcam_from_scratch/#dependencies-and-config","text":"from typing import * import cv2 import matplotlib.pyplot as plt import numpy as np import torch import torch.nn as nn import torchsummary import torchvision from torch.utils import data from torchvision import datasets , transforms from torchvision.models import vgg19 , resnet34 import os import random # Display from IPython.display import Image , display from pytorch_grad_cam import GradCAM from pytorch_grad_cam.utils.image import show_cam_on_image % cd .. import utils device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) utils . seed_all () We will be using three sample images from ImageNet dataset. elephant_path = \"../images/animals/elephant.png\" single_cat_path = \"../images/animals/cat.jpg\" dog_and_cat_path = \"../images/animals/dog_and_cat.jpg\"","title":"Dependencies and Config"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/%28archived%29%20gradcam_from_scratch/#dataset-and-dataloader","text":"We create a simple PyTorch Dataset that reads and return one single image, this is to illustrate our example easily. from torch.utils.data import Dataset class CustomDataset ( Dataset ): def __init__ ( self , image_path , target = None , transform = None ): \"\"\"This Dataset reads 1 image at a time. Args: image_path (_type_): The path to the image target (_type_): The target class of the image transform (_type_, optional): The transform to apply to the image \"\"\" self . image_path = image_path self . target = target self . transform = transform def __len__ ( self ): \"\"\"This loader only returns 1 image at a time Returns: The length of the dataset \"\"\" return 1 def __getitem__ ( self , x ): # read 1 image only so no need subset idx image_path = self . image_path image = cv2 . imread ( image_path ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) if self . target is None : # force assign 0 tensor to be compatible with loader self . target = torch . zeros ( 0 ) if self . transform is not None : image = self . transform ( image ) return image , self . target","title":"Dataset and Dataloader"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/%28archived%29%20gradcam_from_scratch/#transforms","text":"We use some default transforms of image size 224 with ImageNet mean and standard deviation. # use the ImageNet transformation transform = transforms . Compose ( [ transforms . ToPILImage (), transforms . Resize (( 224 , 224 )), transforms . ToTensor (), transforms . Normalize ( mean = [ 0.485 , 0.456 , 0.406 ], std = [ 0.229 , 0.224 , 0.225 ] ), ] )","title":"Transforms"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/%28archived%29%20gradcam_from_scratch/#create-the-dataloaders","text":"We create the three datasets and dataloaders below. # define a 1 image dataset elephant_dataset = CustomDataset ( image_path = elephant_path , transform = transform ) cat_dataset = CustomDataset ( image_path = single_cat_path , transform = transform ) dog_and_cat_dataset = CustomDataset ( image_path = dog_and_cat_path , transform = transform ) # define the dataloader to load that single image elephant_dataloader = torch . utils . data . DataLoader ( dataset = elephant_dataset , shuffle = False , batch_size = 1 ) cat_dataloader = torch . utils . data . DataLoader ( dataset = cat_dataset , shuffle = False , batch_size = 1 ) dog_and_cat_dataloader = torch . utils . data . DataLoader ( dataset = dog_and_cat_dataset , shuffle = False , batch_size = 1 )","title":"Create the DataLoaders"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/%28archived%29%20gradcam_from_scratch/#sanity-check","text":"We get a feel if our dataloader is working by plotting the image in the loader. # get some random training images dataiter = iter ( dog_and_cat_dataloader ) images , targets = dataiter . next () # show images plt . imshow ( np . transpose ( torchvision . utils . make_grid ( images ), ( 1 , 2 , 0 ))) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). <matplotlib.image.AxesImage at 0x17f73646640>","title":"Sanity Check"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/%28archived%29%20gradcam_from_scratch/#models","text":"","title":"Models"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/%28archived%29%20gradcam_from_scratch/#checking-the-layers","text":"We use a library to output the layer information like Keras's model.summary() . We need to identify the last convolutional layer. def torchsummary_wrapper ( model , image_size : Tuple [ int , int , int ] ) -> torchsummary . model_statistics . ModelStatistics : \"\"\"A torch wrapper to print out layers of a Model. Args: model (CustomNeuralNet): Model. image_size (Tuple[int, int, int]): Image size as a tuple of (channels, height, width). Returns: model_summary (torchsummary.model_statistics.ModelStatistics): Model summary. \"\"\" model_summary = torchsummary . summary ( model , image_size ) return model_summary vgg19_ = vgg19 ( pretrained = True ) resnet34_ = resnet34 ( pretrained = True ) Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to C:\\Users\\reighns/.cache\\torch\\hub\\checkpoints\\resnet34-b627a593.pth 0%| | 0.00/83.3M [00:00<?, ?B/s] vgg19_model_summary = torchsummary_wrapper ( vgg19_ , image_size = ( 3 , 224 , 224 )) ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== \u251c\u2500Sequential: 1-1 [-1, 512, 7, 7] -- | \u2514\u2500Conv2d: 2-1 [-1, 64, 224, 224] 1,792 | \u2514\u2500ReLU: 2-2 [-1, 64, 224, 224] -- | \u2514\u2500Conv2d: 2-3 [-1, 64, 224, 224] 36,928 | \u2514\u2500ReLU: 2-4 [-1, 64, 224, 224] -- | \u2514\u2500MaxPool2d: 2-5 [-1, 64, 112, 112] -- | \u2514\u2500Conv2d: 2-6 [-1, 128, 112, 112] 73,856 | \u2514\u2500ReLU: 2-7 [-1, 128, 112, 112] -- | \u2514\u2500Conv2d: 2-8 [-1, 128, 112, 112] 147,584 | \u2514\u2500ReLU: 2-9 [-1, 128, 112, 112] -- | \u2514\u2500MaxPool2d: 2-10 [-1, 128, 56, 56] -- | \u2514\u2500Conv2d: 2-11 [-1, 256, 56, 56] 295,168 | \u2514\u2500ReLU: 2-12 [-1, 256, 56, 56] -- | \u2514\u2500Conv2d: 2-13 [-1, 256, 56, 56] 590,080 | \u2514\u2500ReLU: 2-14 [-1, 256, 56, 56] -- | \u2514\u2500Conv2d: 2-15 [-1, 256, 56, 56] 590,080 | \u2514\u2500ReLU: 2-16 [-1, 256, 56, 56] -- | \u2514\u2500Conv2d: 2-17 [-1, 256, 56, 56] 590,080 | \u2514\u2500ReLU: 2-18 [-1, 256, 56, 56] -- | \u2514\u2500MaxPool2d: 2-19 [-1, 256, 28, 28] -- | \u2514\u2500Conv2d: 2-20 [-1, 512, 28, 28] 1,180,160 | \u2514\u2500ReLU: 2-21 [-1, 512, 28, 28] -- | \u2514\u2500Conv2d: 2-22 [-1, 512, 28, 28] 2,359,808 | \u2514\u2500ReLU: 2-23 [-1, 512, 28, 28] -- | \u2514\u2500Conv2d: 2-24 [-1, 512, 28, 28] 2,359,808 | \u2514\u2500ReLU: 2-25 [-1, 512, 28, 28] -- | \u2514\u2500Conv2d: 2-26 [-1, 512, 28, 28] 2,359,808 | \u2514\u2500ReLU: 2-27 [-1, 512, 28, 28] -- | \u2514\u2500MaxPool2d: 2-28 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-29 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-30 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-31 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-32 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-33 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-34 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-35 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-36 [-1, 512, 14, 14] -- | \u2514\u2500MaxPool2d: 2-37 [-1, 512, 7, 7] -- \u251c\u2500AdaptiveAvgPool2d: 1-2 [-1, 512, 7, 7] -- \u251c\u2500Sequential: 1-3 [-1, 1000] -- | \u2514\u2500Linear: 2-38 [-1, 4096] 102,764,544 | \u2514\u2500ReLU: 2-39 [-1, 4096] -- | \u2514\u2500Dropout: 2-40 [-1, 4096] -- | \u2514\u2500Linear: 2-41 [-1, 4096] 16,781,312 | \u2514\u2500ReLU: 2-42 [-1, 4096] -- | \u2514\u2500Dropout: 2-43 [-1, 4096] -- | \u2514\u2500Linear: 2-44 [-1, 1000] 4,097,000 ========================================================================================== Total params: 143,667,240 Trainable params: 143,667,240 Non-trainable params: 0 Total mult-adds (G): 19.78 ========================================================================================== Input size (MB): 0.57 Forward/backward pass size (MB): 113.38 Params size (MB): 548.05 Estimated Total Size (MB): 662.00 ========================================================================================== # resnet34_model_summary = torchsummary_wrapper(resnet34_, image_size = (3, 224, 224))","title":"Checking the Layers"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/%28archived%29%20gradcam_from_scratch/#define-our-target-layers","text":"We define what our target layers would be for the respective models. # this is the last conv layer layer 35 from Francis's book right after conv2d + relu, but https://github.com/jacobgil/pytorch-grad-cam suggests [-1] where it is max pooled. Can try both. vgg19_last_conv_layer = vgg19_ . features [ - 2 ] print ( vgg19_last_conv_layer ) resnet34_last_conv_layer = resnet34_ . layer4 [ - 1 ] print ( resnet34_last_conv_layer ) ReLU(inplace=True) BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) )","title":"Define our Target Layers"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/%28archived%29%20gradcam_from_scratch/#store-forward-and-backward-hooks","text":"These function help us to get forward activations and backward gradients. forward_activations = OrderedDict () backward_gradients = OrderedDict () def get_forward_hook ( name : str ) -> Callable : \"\"\"Get the intermediate features of a model. Forward Hook. This is using forward hook with reference https://discuss.pytorch.org/t/how-can-l-load-my-best-model-as-a-feature-extractor-evaluator/17254/5 Args: name (str): name of the layer. Returns: Callable: [description] \"\"\" def forward_hook ( model , input , output ): forward_activations [ name ] = output . detach () return forward_hook def get_backward_hook ( name : str ) -> Callable : \"\"\"Get the intermediate features of a model. Backward Hook. This is using backward hook with reference https://discuss.pytorch.org/t/how-can-l-load-my-best-model-as-a-feature-extractor-evaluator/17254/5 Args: name (str): name of the layer. Returns: Callable: [description] \"\"\" def backward_hook ( model , grad_input , grad_output ): backward_gradients [ name ] = grad_output [ 0 ] . detach () return backward_hook","title":"Store Forward and Backward Hooks"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/%28archived%29%20gradcam_from_scratch/#step-by-step-walkthrough","text":"Skip to the next section if you are familiar with the Grad-CAM process. vgg19_last_conv_layer . register_forward_hook ( get_forward_hook ( \"features.35\" )) vgg19_last_conv_layer . register_backward_hook ( get_backward_hook ( \"features.35\" )) # register_backward_hook deprecated but for now we use it <torch.utils.hooks.RemovableHandle at 0x1a39f0623a0> # set the evaluation mode vgg19_ . eval () # get the image from the dataloader image , _ = next ( iter ( elephant_dataloader )) # the y_logits before softmax y_logits = vgg19_ ( image ) target_category = None if target_category is None : # get the most likely prediction of the model target_category = vgg19_ ( image ) . argmax ( dim = 1 ) target_category = target_category . item () # convert to scalar # get the activations of the last convolutional layer forward_conv_activations = forward_activations [ \"features.35\" ] y_logits [:, target_category ] . backward () dyc_dA = backward_gradients [ \"features.35\" ] # average pool the gradients across the channels global_average_pooled_gradients = torch . mean ( dyc_dA , dim = [ 0 , 2 , 3 ]) num_feature_maps = 512 weighted_localization_map = torch . clone ( forward_conv_activations ) # weight the channels by corresponding gradients for i in range ( num_feature_maps ): weighted_localization_map [:, i , :, :] *= global_average_pooled_gradients [ i ] # sum the channels of the activations weighted_localization_map = torch . sum ( weighted_localization_map , dim = 1 ) . squeeze () assert weighted_localization_map . shape == ( 14 , 14 ) # relu on top of the heatmap expression (2) in https://arxiv.org/pdf/1610.02391.pdf relu_weighted_localization_map = torch . nn . ReLU ( inplace = False )( weighted_localization_map ) # normalize the heatmap, scale features to between 0 and 1 to plot heatmap = relu_weighted_localization_map / torch . max ( relu_weighted_localization_map ) # draw the heatmap plt . matshow ( heatmap . squeeze ()) tensor([[0.1695, 0.1367, 0.1292, 0.1435, 0.1037, 0.0376, 0.0048, 0.0520, 0.1114, 0.1495, 0.1856, 0.1638, 0.0733, 0.2405], [0.1262, 0.0933, 0.1134, 0.1632, 0.0805, 0.0000, 0.0000, 0.0254, 0.1456, 0.2702, 0.2565, 0.1883, 0.0819, 0.1331], [0.1508, 0.1267, 0.1541, 0.2010, 0.0570, 0.0000, 0.0000, 0.0973, 0.5866, 0.8733, 0.8954, 0.7577, 0.2693, 0.2221], [0.1884, 0.1376, 0.0959, 0.0888, 0.0000, 0.0000, 0.0715, 0.3818, 0.8004, 1.0000, 0.9425, 0.7478, 0.2823, 0.1800], [0.1931, 0.1158, 0.0351, 0.1330, 0.1786, 0.1146, 0.1243, 0.3891, 0.6943, 0.7773, 0.6895, 0.5610, 0.2427, 0.1264], [0.1552, 0.1056, 0.0473, 0.2595, 0.4205, 0.4517, 0.3047, 0.2987, 0.3538, 0.3354, 0.3093, 0.3014, 0.2003, 0.1028], [0.1290, 0.0747, 0.0794, 0.2144, 0.3984, 0.4928, 0.3979, 0.2380, 0.1140, 0.0156, 0.0354, 0.1017, 0.0838, 0.0565], [0.1351, 0.0931, 0.0892, 0.2174, 0.2635, 0.2547, 0.2120, 0.0853, 0.0532, 0.0892, 0.0746, 0.0637, 0.0590, 0.0669], [0.1265, 0.1018, 0.1014, 0.1031, 0.0350, 0.0000, 0.0000, 0.0000, 0.0760, 0.1283, 0.0963, 0.0719, 0.0648, 0.1028], [0.1022, 0.0842, 0.0833, 0.0784, 0.0661, 0.0453, 0.0620, 0.0855, 0.0810, 0.0651, 0.0514, 0.0575, 0.0807, 0.0874], [0.0744, 0.0565, 0.0446, 0.0513, 0.0579, 0.0656, 0.0686, 0.0619, 0.0518, 0.0432, 0.0352, 0.0422, 0.0603, 0.0671], [0.0691, 0.0449, 0.0282, 0.0311, 0.0371, 0.0427, 0.0493, 0.0538, 0.0555, 0.0554, 0.0536, 0.0601, 0.0876, 0.1001], [0.0985, 0.0838, 0.0768, 0.0767, 0.0800, 0.0848, 0.0896, 0.0934, 0.0930, 0.0902, 0.0896, 0.0985, 0.1177, 0.1245], [0.1639, 0.1344, 0.1271, 0.1290, 0.1266, 0.1226, 0.1187, 0.1174, 0.1148, 0.1075, 0.1006, 0.0996, 0.1054, 0.1203]]) <matplotlib.image.AxesImage at 0x1a39f0dc0d0> img = cv2 . imread ( elephant_path ) heatmap = cv2 . resize ( heatmap . cpu () . detach () . numpy (), ( img . shape [ 1 ], img . shape [ 0 ])) heatmap = np . uint8 ( 255 * heatmap ) heatmap = cv2 . applyColorMap ( heatmap , cv2 . COLORMAP_JET ) superimposed_img = heatmap * 0.4 + img cv2 . imwrite ( './elephant_gradcam.jpg' , superimposed_img ) True","title":"Step by Step Walkthrough"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/%28archived%29%20gradcam_from_scratch/#function-for-grad-cam-heatmap","text":"def make_gradcam_heatmap ( target_layer : torch . nn . Module , target_layer_name : str , model : torch . nn . Module , image : torch . Tensor , target_category : Optional [ int ] = None , ): \"\"\"_summary_ Args: target_layer (str): _description_ model (torch.nn.Module): _description_ image (torch.Tensor): _description_ target_category (Optional[int], optional): _description_. Defaults to None. \"\"\" target_layer . register_forward_hook ( get_forward_hook ( target_layer_name ) ) target_layer . register_backward_hook ( get_backward_hook ( target_layer_name ) ) # register_backward_hook deprecated but for now we use it model . eval () # the y_logits before softmax y_logits = model ( image ) if target_category is None : # get the most likely prediction of the model target_category = model ( image ) . argmax ( dim = 1 ) target_category = target_category . item () # convert to scalar # get the activations of the last convolutional layer forward_conv_activations = forward_activations [ target_layer_name ] y_logits [:, target_category ] . backward () dyc_dA = backward_gradients [ target_layer_name ] # average pool the gradients across the channels global_average_pooled_gradients = torch . mean ( dyc_dA , dim = [ 0 , 2 , 3 ]) num_feature_maps = forward_conv_activations . squeeze () . shape [ 0 ] weighted_localization_map = torch . clone ( forward_conv_activations ) # weight the channels by corresponding gradients for i in range ( num_feature_maps ): weighted_localization_map [ :, i , :, : ] *= global_average_pooled_gradients [ i ] # sum the channels of the activations weighted_localization_map = torch . sum ( weighted_localization_map , dim = 1 ) . squeeze () # relu on top of the heatmap expression (2) in https://arxiv.org/pdf/1610.02391.pdf relu_weighted_localization_map = torch . nn . ReLU ( inplace = False )( weighted_localization_map ) # normalize the heatmap, scale features to between 0 and 1 to plot heatmap = relu_weighted_localization_map / torch . max ( relu_weighted_localization_map ) # draw the heatmap plt . matshow ( heatmap . squeeze ()) return heatmap cat_image , _ = next ( iter ( cat_dataloader )) dog_and_cat_image , _ = next ( iter ( dog_and_cat_dataloader )) elephant_image , _ = next ( iter ( elephant_dataloader )) dog_and_cat_heatmap = make_gradcam_heatmap ( target_layer = vgg19_last_conv_layer , target_layer_name = \"vgg19.feature.35\" , model = vgg19_ , image = dog_and_cat_image , target_category = None ) dog_and_cat_heatmap_resnet34 = make_gradcam_heatmap ( target_layer = resnet34_last_conv_layer , target_layer_name = \"resnet34.layer4[-1]\" , model = resnet34_ , image = dog_and_cat_image , target_category = None ) dog_and_cat_heatmap_resnet34_target_dog = make_gradcam_heatmap ( target_layer = resnet34_last_conv_layer , target_layer_name = \"resnet34.layer4[-1]\" , model = resnet34_ , image = dog_and_cat_image , target_category = 260 ) dog_and_cat_heatmap_resnet34_target_cat = make_gradcam_heatmap ( target_layer = resnet34_last_conv_layer , target_layer_name = \"resnet34.layer4[-1]\" , model = resnet34_ , image = dog_and_cat_image , target_category = 285 ) cat_heatmap = make_gradcam_heatmap ( target_layer = vgg19_last_conv_layer , target_layer_name = \"vgg19.feature.35\" , model = vgg19_ , image = cat_image , target_category = None ) cat_heatmap_resnet34 = make_gradcam_heatmap ( target_layer = resnet34_last_conv_layer , target_layer_name = \"resnet34.layer4[-1]\" , model = resnet34_ , image = cat_image , target_category = None ) elephant_heatmap = make_gradcam_heatmap ( target_layer = vgg19_last_conv_layer , target_layer_name = \"vgg19.features.35\" , model = vgg19_ , image = elephant_image , target_category = None ) elephant_heatmap_resnet34 = make_gradcam_heatmap ( target_layer = resnet34_last_conv_layer , target_layer_name = \"resnet34.layer4[-1]\" , model = resnet34_ , image = elephant_image , target_category = None ) # def save_and_display_gradcam( # image_path, heatmap, image_size=None, cam_path=\"./cat_gradcam.jpg\", alpha=0.4 # ): # # cv2 imread auto reads as BGR # image = cv2.imread(image_path) # if image_size is not None: # image = cv2.resize(image, (image_size, image_size)) # if not isinstance(heatmap, np.ndarray): # heatmap = heatmap.cpu().detach().numpy() # heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0])) # heatmap = np.uint8(255 * heatmap) # heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET) # superimposed_image = heatmap * alpha + image # cv2.imwrite(cam_path, superimposed_image) # return np.uint8(superimposed_image) def save_and_display_gradcam ( image_path , heatmap , image_size = None , cam_path = \"./cat_gradcam.jpg\" , alpha = 0.4 , use_rgb = False , ): \"\"\"_summary_ Args: image_path (_type_): _description_ heatmap (_type_): _description_ image_size (_type_, optional): _description_. Defaults to None. cam_path (str, optional): _description_. Defaults to \"./cat_gradcam.jpg\". alpha (float, optional): _description_. Defaults to 0.4. Returns: _type_: _description_ \"\"\" # Load original image, cv2 imread auto reads as BGR image = cv2 . imread ( image_path ) if image_size is not None : image = cv2 . resize ( image , ( image_size , image_size )) if isinstance ( heatmap , torch . Tensor ): heatmap = heatmap . cpu () . detach () . numpy () # Rescale heatmap to a range 0-255 heatmap = np . uint8 ( 255 * heatmap ) # Use Jet colormap to colorize heatmap heatmap = cv2 . applyColorMap ( heatmap , cv2 . COLORMAP_JET ) if use_rgb : image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) heatmap = cv2 . cvtColor ( heatmap , cv2 . COLOR_BGR2RGB ) # resize heatmap to original image size heatmap = cv2 . resize ( heatmap , ( image . shape [ 1 ], image . shape [ 0 ])) superimposed_image = heatmap * alpha + image cv2 . imwrite ( cam_path , superimposed_image ) # Display Grad CAM display ( Image ( cam_path )) return np . uint8 ( superimposed_image ) # def save_and_display_gradcam( # image_path, heatmap, cam_path=\"./cat_gradcam.jpg\", alpha=0.4 # ): # image = cv2.imread(image_path) # heatmap = cv2.resize( # heatmap.cpu().detach().numpy(), (image.shape[1], image.shape[0]) # ) # heatmap = np.uint8(255 * heatmap) # heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET) # superimposed_image = heatmap * alpha + image # cv2.imwrite(cam_path, superimposed_image) # return superimposed_image elephant_gradcam_vgg19 = save_and_display_gradcam ( image_path = elephant_path , heatmap = elephant_heatmap , image_size = 224 , cam_path = \"./elephant_gradcam.jpg\" , alpha = 0.4 , use_rgb = False ) cat_gradcam_vgg19 = save_and_display_gradcam ( image_path = single_cat_path , heatmap = cat_heatmap , image_size = 224 , cam_path = \"./cat_gradcam.jpg\" , alpha = 0.4 , use_rgb = False ) cat_gradcam_resnet34 = save_and_display_gradcam ( image_path = single_cat_path , heatmap = cat_heatmap_resnet34 , image_size = 224 , cam_path = \"./cat_gradcam_resnet34.jpg\" , alpha = 0.4 ) elephant_gradcam_resnet34 = save_and_display_gradcam ( image_path = elephant_path , heatmap = elephant_heatmap_resnet34 , image_size = 224 , cam_path = \"./elephant_gradcam_resnet34.jpg\" , alpha = 0.4 ) dog_and_cat_gradcam_resnet34 = save_and_display_gradcam ( image_path = dog_and_cat_path , heatmap = dog_and_cat_heatmap_resnet34 , image_size = 224 , cam_path = \"./dog_and_cat_gradcam_resnet34.jpg\" , alpha = 0.4 ) dog_and_cat_gradcam_resnet34_target_dog = save_and_display_gradcam ( image_path = dog_and_cat_path , heatmap = dog_and_cat_heatmap_resnet34_target_dog , image_size = 224 , cam_path = \"./dog_and_cat_gradcam_target_dog_resnet34.jpg\" , alpha = 0.4 ) dog_and_cat_gradcam_resnet34_target_dog = save_and_display_gradcam ( image_path = dog_and_cat_path , heatmap = dog_and_cat_heatmap_resnet34_target_cat , image_size = 224 , cam_path = \"./dog_and_cat_gradcam_target_cat_resnet34.jpg\" , alpha = 0.4 ) save_and_display_gradcam ( image_path = dog_and_cat_path , heatmap = dog_and_cat_heatmap , cam_path = \"./dog_and_cat_gradcam.jpg\" , alpha = 0.4 ) image = cv2 . imread ( single_cat_path ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) # needed for gradcam. original_image = cv2 . resize ( image , ( 224 , 224 )) from pytorch_grad_cam import GradCAM , ScoreCAM , GradCAMPlusPlus , AblationCAM , XGradCAM , EigenCAM , FullGrad # from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget from pytorch_grad_cam.utils.image import show_cam_on_image from torchvision.models import resnet50 , vgg19 , resnet34 model = resnet34 ( pretrained = True ) target_layers = [ model . layer4 [ - 1 ]] input_tensor = cat_image # Create an input tensor image for your model.. # Note: input_tensor can be a batch tensor with several images! # Construct the CAM object once, and then re-use it on many images: cam = GradCAM ( model = model , target_layers = target_layers , use_cuda = False ) # You can also use it within a with statement, to make sure it is freed, # In case you need to re-create it inside an outer loop: # with GradCAM(model=model, target_layers=target_layers, use_cuda=args.use_cuda) as cam: # ... # We have to specify the target we want to generate # the Class Activation Maps for. # If targets is None, the highest scoring category # will be used for every image in the batch. # Here we use ClassifierOutputTarget, but you can define your own custom targets # That are, for example, combinations of categories, or specific outputs in a non standard model. target_category = None # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing. grayscale_cam = cam ( input_tensor = input_tensor , target_category = target_category ) # In this example grayscale_cam has only one image in the batch: grayscale_cam = grayscale_cam [ 0 , :] cat_image_normalized = original_image / 255. cat_image_normalized . shape (224, 224, 3) visualization = show_cam_on_image ( cat_image_normalized , grayscale_cam , use_rgb = True ) _fig , axes = plt . subplots ( figsize = ( 8 , 8 ), ncols = 2 ) axes [ 0 ] . imshow ( cat_image_normalized ) axes [ 1 ] . imshow ( visualization ) plt . show () torch . cuda . empty_cache ()","title":"Function for Grad-CAM Heatmap"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\L}{\\mathbf{L}} \\newcommand{\\X}{\\mathbf{X}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\] Grad-CAM, an Introduction We will be discussing the paper written by R.R Selvaraju et al on Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization on how we can interpret large scale Deep Neural Networks (CNN). Terminologies Feature Maps Feature Maps has an intuitive interpretation , understanding it intuitively should be prioritized than knowing the underlying mathematical structure. Imagine a 32 by 32 image, consider that a convolutional layer applied on the input and we assume only 2 kernels are applied, then only 2 feature maps are obtained: The first feature map is a color filter that is responsible to detect color contrast of an image; The second feature map is a sobel's filter where it detects edges. Then assume kernel has size 5 by 5, when convolved on the 32 by 32 image, yields a feature map output of size 28 by 28, although \"downsampled\", this feature map should still capture valueble spatial information of the 32 by 32 image, and in this case, all edges of the input image (say a cat) will be shown in the feature map 1, we call it \\(\\A^1\\) , and the color contrast is displayed on feature map 2, \\(\\A^2\\) . So the full settings is: An input image \\(\\mathcal{X}\\) of size \\((3, 32, 32)\\) . A CNN but we will only look at its very first layer, a conv layer that has: 2 kernels of size 5 by 5 and default paddings and stride such that the output feature map is 28 by 28. Original Cat Image Feature Map A1 and A2; By Hongnan G. Notice in the 2 feature maps above, after we pass in the RGB cat image of 3 channels to the first conv layer, we will receive two outputs, called feature maps , each of them will describe the image in one way or another. One thing to note is that earlier conv layers will retain a lot detailed information of the image such as the edges, color contrast, but as we go on later, the feature maps become more abstract as they capture high level and abstract details that we human cannot comprehend easily. Global Average Pooling (GAP) The GAP is usually applied after the last conv layer. But for the sake of explanation, we will assume that our \"last conv layer\" is our first conv layer. Instead of down sampling patches of the input feature map, global pooling down samples the entire feature map to a single value. In the last few years, experts have turned to global average pooling (GAP) layers to minimize overfitting by reducing the total number of parameters in the model. Similar to max pooling layers, GAP layers are used to reduce the spatial dimensions of a three-dimensional tensor. However, GAP layers perform a more extreme type of dimensionality reduction, where a tensor with dimensions h\u00d7w\u00d7d is reduced in size to have dimensions 1\u00d71\u00d7d. GAP layers reduce each h\u00d7w feature map to a single number by simply taking the average of all hw values. Visualize GAP; Courtesy of Alexis Cook Eventually our task is to classify whether the image is a cat or something else. We are unable to succinctly pass these 2 feature maps directly to a linear classifier to classify the cats (i.e. passing in two 28 by 28 kernels to a linear layer does not work but we need linear layer to give us an output). Therefore, we need to flatten these feature maps generated by the conv layers. One way to do this is Global Average Pooling . A wrong example First, I show you a source of confusion on what some perceive GAP as: For example: \\[ \\A^1 = \\begin{bmatrix} 2 & 3 \\\\ 1 & 5 \\end{bmatrix} \\quad \\A^2 = \\begin{bmatrix} 3 & 1 \\\\ 2 & 8 \\end{bmatrix} \\] Assume for a moment \\(\\A^1\\) and \\(\\A^2\\) are our feature maps (although I mentioned it was 28 by 28 but this illustrates the idea). Then to retain the spatial information, we can perform an averaging across depths/channels of each kernel as such: \\[ \\A_{\\text{average feature maps across depth}} = \\dfrac{\\A^1 + \\A^2}{\\textbf{num_feature_maps}} = \\dfrac{\\A^1 + \\A^2}{2} = \\begin{bmatrix} 2.5 & 2 \\\\ 1.5 & 6.5 \\end{bmatrix} \\] Then we flatten the \\(\\A_{gap}\\) to a single vector and pass it to linear layer. Feature Map A1 and A2 but Averaged over Channels; By Hongnan G. A correct example \\[ \\A^1 = \\begin{bmatrix} 2 & 3 \\\\ 1 & 5 \\end{bmatrix} \\quad \\A^2 = \\begin{bmatrix} 3 & 1 \\\\ 2 & 8 \\end{bmatrix} \\] Assume for a moment \\(\\A^1\\) and \\(\\A^2\\) are our feature maps (although I mentioned it was 28 by 28 but this illustrates the idea). Then to retain the spatial information, we can perform an averaging across each kernel as such: \\[ \\text{mean}\\left(\\A^1\\right) = \\dfrac{2+3+1+5}{2 \\times 2} = 2.75 \\quad \\text{mean}\\left(\\A^2\\right) = \\dfrac{3+1+2+8}{2 \\times 2} = 3.5 \\] where by \\(2 \\times 2\\) means the number of pixels in the feature map; and thus the \\[ \\A_{\\text{gap}} = \\begin{bmatrix}2.75 \\\\ 3.5 \\end{bmatrix} \\] The Grad-CAM paper also applied the GAP idea over each feature map \\(\\A_k\\) . One can refer to here to understand the intuition here. Basically each unique feature map will be reduced to a single value, for eg, \\(2.75\\) , which summarizes the entire feature map. The Intuition This part is referenced from Interpretable Machine Learning by Christoph Molnar . He started off with an intuitive description of Grad-CAM. High level idea: Grad-CAM is to understand at which parts of an image a convolutional layer \"looks\" for a certain classification. As a reminder, the first convolutional layer of a CNN takes as input the images and outputs feature maps that encode learned features (see the chapter on Learned Features ). The higher-level convolutional layers do the same, but take as input the feature maps of the previous convolutional layers. To understand how the CNN makes decisions, Grad-CAM analyzes which regions are activated in the feature maps of the last convolutional layers. There are \\(k\\) feature maps in the last convolutional layer, and I will call them \\(\\A^1, \\A^2, \\ldots, \\A^k\\) . How can we \"see\" from the feature maps how the convolutional neural network has made a certain classification? In the first approach, we could simply visualize the raw values of each feature map, average over the feature maps and overlay this over our image. This is the method of visualization feature map activations. This would not be helpful since the feature maps encode information for all classes , but we are interested in a particular class. Grad-CAM has to decide how important each of the k feature map was to our class c that we are interested in. We have to weight each pixel of each feature map with the gradient before we average over the feature maps. This gives us a heatmap which highlights regions that positively or negatively affect the class of interest. This heatmap is send through the ReLU function, which is a fancy way of saying that we set all negative values to zero. Grad-CAM removes all negative values by using a ReLU function, with the argument that we are only interested in the parts that contribute to the selected class c and not to other classes. The word pixel might be misleading here as the feature map is smaller than the image (because of the pooling units) but is mapped back to the original image. We then scale the Grad-CAM map to the interval [0,1] for visualization purposes and overlay it over the original image. The Big Picture This part can be best understood alongside my drawings. The big picture is when you \"reduce\" the 3 feature maps into 1 single new \"feature map\" (localization map) by way of a linear sum where each feature map \\(\\A^k\\) is multiplied by the global average pooled gradients \\(\\alpha_k^c\\) . In the example on my drawings, it can be seen that feature maps \\(\\A^1\\) and \\(\\A^2\\) are more important for the model to distinguish the elephant class than that of \\(\\A^3\\) . By design, I made \\(\\A^3\\) in itself already look different in terms of values from \\(\\A^1\\) and \\(\\A^2\\) on the get go. But at this point in time, even though we know the values in feature map \\(\\A^3\\) are vastly different, we cannot say for sure whether \\(\\A^3\\) in itself contributed to the prediction of our class elephant or not. It could also be the case that \\(\\A^1\\) and \\(\\A^2\\) are bonkers. Thus, the concept of taking the gradient of the class \\(\\y^c\\) with respect to each of these feature maps \\(\\A^k\\) becomes increasingly important as now we have a mathematical way to assign some importance to each of these feature maps. Now to even further bring out the intuition, imagine the 3 feature maps for the input image elephant as follows: Feature map \\(\\A^1\\) corresponds to Sobel Filter where it detect edges in particular their trunk of the elephants . Feature map \\(\\A^2\\) corresponds to Another Filter where it detects the ear of the elephants . Feature map \\(\\A^3\\) corresponds to a Background Filter where it detect the background and in particular the grass patch under the elephants . Now this is apparent why \\(\\A^3\\) is vastly different in terms of values since it is actually representing the background and grass. We know that grass is a non-factor in determining an elephant since the african grass field can hold many other animals as well. We really do not want the model to assign important to the grass, if any at all. We can then compute the gradient of \\(\\y^c\\) wrt each feature map and we can intuitively understand it as (see my diagrams): Gradient map \\(\\frac{d\\y^{386}}{d\\A^1}\\) has values \\(\\begin{bmatrix} 2 & 3 \\\\ 4 & 2 \\end{bmatrix}\\) These values are the gradients of feature map \\(\\A^1\\) at a pixel level. We may find it difficult to comprehend these gradients and we want a quick summary of how feature map \\(\\A^1\\) changes our model's decision for \\(\\y^{386}\\) . Thus we use GAP. and when we perform GAP on them, we have \\(\\alpha_{1}^{386} = 2.75\\) . This value roughly translates to a pertubation of \\(2.75\\) in feature map \\(\\A^1\\) will result in a unit change in our class \\(\\y^{386}\\) . Gradient map \\(\\frac{d\\y^{386}}{d\\A^2}\\) has values \\(\\begin{bmatrix} 3 & 5 \\\\ 6 & 3 \\end{bmatrix}\\) and when we perform GAP on them, we have \\(4.25\\) . The same logic applies. Gradient map \\(\\frac{d\\y^{386}}{d\\A^3}\\) has values \\(\\begin{bmatrix} 0.1 & -0.1 \\\\ 0.2 & 0.2 \\end{bmatrix}\\) and when we perform GAP on them, we have \\(0.1\\) . The same logic applies and we see that the gradient is small here and hence we can deduce that this feature map is not very important. Ultimately however, we want to know how the change in all feature maps \\(\\A^k\\) affects our final decision. This is where we perform a linear sum of \\(\\left(\\sum_{k} \\alpha_k^c A^k\\right)\\) of all feature maps with the weight coefficient being their global average pooled gradient map. Just like our good old linear regression model, the intuition is the same as in \\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ...\\) . The coefficients (the gradient values of \\(2.75, 4.25, 0.1\\) decides which feature map are important and gets \"activated and highlighted\"). We get the weighted sum heatmap to be the shape \\((2, 2)\\) of values \\([8.925, -2.025, 16.125, 2.6]\\) . Now this is a very small map and is likely not going to happen in real life. More often the map at this stage is of size \\((10, 10)\\) and beyond. Imagine once more how \\(\\A^3\\) played almost no role. Lastly, an elementwise ReLU operation is applied to the heatmap to get \\([8,925, 0, 16.125, 2.6]\\) and from the paper: We apply a ReLU to the linear combination of maps because we are only interested in the features that have a positive influence on the class of interest, i.e. pixels whose intensity should be increased in order to increase \\(y^{c}\\) . Intuitively, the idea is that negative values contribute to other classes and we should not really care about it. We can scale back the heatmap to overlay on the original image. From here , author said: Another potential question that can arise is why wouldn\u2019t we just compute the gradient of the class logit with respect to the input image. Remember that a convolutional neural network works as a feature extractor and deeper layers of the network operate in increasingly abstract spaces. We want to see which of the features actually influenced the model\u2019s choice of the class rather than just individual image pixels. That is why it is crucial to take the activation maps of deeper convolutional layers. The Algorithm With reference to Interpretable Machine Learning by Christoph Molnar . Notation Input image: \\(\\X\\) Feature Maps of the last convolutional layer in a CNN is denoted as: \\[\\A_1, \\A_2, \\ldots, \\A_k\\] The \\(k\\) is an arbitrary number for the number of feature maps. The Feature Logits of a particular class \\(c\\) is denoted as: \\[\\y^{c}\\] In other words, in ImageNet , the elephant class is indexed \\(386\\) , and is denoted \\(\\y^{386}\\) . This is also the raw feature logits output before the softmax layer. The gradient of the fully-connected logits for class \\(c\\) , \\(\\y^{c}\\) (before the softmax), with respect to feature map activations \\(\\A_k\\) of a convolutional layer : \\[\\dfrac{d\\y^{c}}{d\\A^{k}}\\] It follows that the gradient of the fully-connected for each class \\(c\\) , \\(\\y^{c}\\) , with respect to each pixel on the feature map activations \\(\\A_k\\) is denoted as : \\[\\dfrac{d\\y^{c}}{d\\A^{k}_{ij}}\\] Let us define the gradient of \\(\\y^c\\) with respect to the GAP of each feature map \\(\\A^k\\) to be: \\[\\alpha_k^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^k}}_{\\text{gradients via backprop}}\\] Denote the ReLU function as: \\[\\textbf{ReLU}\\] The final heatmap, also called the localization map of Grad-CAM is denoted as: \\[\\L^{c}_{Grad-CAM} \\in \\R^{w \\times h}\\] where \\(w\\) and \\(h\\) is the width and height of the final output localization map. and is equals to \\[\\L^{c}_{Grad-CAM} \\in \\R^{w \\times h} = \\underbrace{ReLU}_{\\text{Pick positive values}}\\left(\\sum_{k} \\alpha_k^c A^k\\right)\\] The Algorithm We will only assume our input is 1 single image. Let us look at the recipe for Grad-CAM. Our goal is to find the localization map, which is defined as: \\[L^c_{Grad-CAM} \\in \\mathbb{R}^{u\\times v} = \\underbrace{ReLU}_{\\text{Pick positive values}}\\left(\\sum_{k} \\alpha_k^c A^k\\right)\\] Here, u is the width, v the height of the explanation and c the class of interest. Forward-propagate the input image through the convolutional neural network. Obtain the raw score for the class of interest, meaning the activation of the neuron before the softmax layer. Set all other class activations to zero. Back-propagate the gradient of the class of interest to the last convolutional layer before the fully connected layers: \\(\\frac{\\delta{}y^c}{\\delta{}A^k}\\) . Weight each feature map \"pixel\" by the gradient for the class. Indices i and j refer to the width and height dimensions: \\( \\(\\alpha_k^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^k}}_{\\text{gradients via backprop}}\\) \\) This means that the gradients are globally pooled. Calculate an average of the feature maps, weighted per pixel by the gradient. Apply ReLU to the averaged feature map. For visualization: Scale values to the interval between 0 and 1. Upscale the image and overlay it over the original image. Additional step for Guided Grad-CAM: Multiply heatmap with guided backpropagation. Step 1: Forward-propagate This step just takes in one single image \\(\\mathcal{X}\\) and perform a forward pass the input image through the convolutional neural network and save all the forward pass feature map activations . # the y_logits before softmax; forward pass to populate the forward_activations y_logits = model ( image ) # this dict will be populated with the feature map outputs forward_activations = { \"features.11_ReLU(inplace=True)\" : feature_map_logits } We now have the feature maps stored and we can get our target conv layer. \\[ \\begin{bmatrix} \\A^1 & \\A^2 & \\A^3 & \\cdots & \\A^k \\end{bmatrix} \\] where each \\(\\A^i \\in \\R^{f \\times f}\\) . Step 2: Backward-propagate In Grad-CAM, we need the gradients of the target category with respect to the target convolutional layer . That is to say, when we call backwards, we are only interested in the particular class's gradients wrt feature maps. if target_category is None : # get the most likely prediction of the model target_category = model ( image ) . argmax ( dim = 1 ) # convert to scalar target_category = target_category . item () # call backward on the model to populate backward_gradients y_logits [:, target_category ] . backward () # this dict will be populated with the gradients backward_gradients = { \"features.11_ReLU(inplace=True)\" : gradients_yc_wrt_features .11 } The above code just says, if we did not choose a target category , the model will choose the one with the highest logit activation. We then call y_logits[: target_category] backwards to store the gradients in backward_gradients . We now have the gradients of the class of interest with respect to the target conv layer (usually last conv layer). \\[ \\begin{bmatrix} \\dfrac{d\\y^{c}}{d\\A^{1}} & \\dfrac{d\\y^{c}}{d\\A^{2}} & \\dfrac{d\\y^{c}}{d\\A^{3}} & \\cdots & \\dfrac{d\\y^{c}}{d\\A^{k}} \\end{bmatrix} \\] where each \\(\\dfrac{d\\y^{c}}{d\\A^{i}} \\in \\R^{f \\times f}\\) . Step 3: Global Average Pool Gradients The intuition we explained earlier tells us that we need to assign an importance score to each feature map \\(\\A^i\\) . How to do that? In my naive thought, since \\(\\dfrac{d\\y^{c}}{d\\A^{i}}\\) is the same shape as the feature map \\(f \\times f\\) , I would have thought we can just multiply them elementwise. More concretely, If \\[ \\A^1 = \\begin{bmatrix} 2 & 3 \\\\ 1 & 5 \\end{bmatrix} \\quad \\A^2 = \\begin{bmatrix} 3 & 1 \\\\ 2 & 8 \\end{bmatrix} \\] and \\[ \\dfrac{d\\y^{c}}{d\\A^{1}} = \\begin{bmatrix} 0.1 & 0.2 \\\\ 0.3 & 0.5 \\end{bmatrix} \\quad \\dfrac{d\\y^{c}}{d\\A^{2}} = \\begin{bmatrix} 0.3 & 0.1 \\\\ 0.2 & 0.3 \\end{bmatrix} \\] Then we can weigh each feature map on a pixel level: \\[ \\A^1 * \\dfrac{d\\y^{c}}{d\\A^{1}} = \\begin{bmatrix} 0.2 & 0.6 \\\\ 0.3 & 0.25 \\end{bmatrix} \\quad \\A^2 * \\dfrac{d\\y^{c}}{d\\A^{2}} = \\begin{bmatrix} 0.9 & 0.1 \\\\ 0.4 & 0.24 \\end{bmatrix} \\] However, the paper suggested that we can perform a Global Average Pooling on the gradient maps first, the idea is the same, we assume that the average of each gradient map should be representative of the rate of change of \\(y^c\\) with respect to each feature map. \\[\\alpha_k^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^k}}_{\\text{gradients via backprop}}\\] where \\(Z\\) is the total number of pixels in this gradient map. Applying this to our example: \\[ \\alpha_1^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^1}}_{\\text{gradients via backprop}} = \\frac{1}{4}\\left(0.2+0.6+0.3+0.25\\right) = 0.3375 \\] \\[ \\alpha_2^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^2}}_{\\text{gradients via backprop}} = \\frac{1}{4}\\left(0.9+0.1+0.4+0.24\\right) = 0.41 \\] These \\(\\alpha_k^c\\) will be the importance score of each feature map \\(\\A^k\\) . We will stack them into vectors: \\[ \\begin{bmatrix} \\alpha_1^c & \\alpha_2^c & \\alpha_3^c & \\cdots & \\alpha_k^c \\end{bmatrix} \\] and \\(\\alpha_k^c \\in \\R\\) is a scalar. In code it is of the form: dyc_dA = backward_gradients [ target_layer_name ] # average pool the gradients across the channels global_average_pooled_gradients = torch . mean ( dyc_dA , dim = [ 0 , 2 , 3 ]) Step 4: Weighted Global Sum: Localized Feature Maps Recall that good old linear regression has the form \\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_k x_k\\) . Now we do the same here and treat \\(\\alpha_k^c\\) as the beta weight coefficients, and feature maps \\(\\A^k\\) as our features to get: \\[\\textbf{Localized_Feature_Map} = \\left(\\sum_{k} \\alpha_k^c A^k\\right)\\] which has a shape of \\(\\R^{f \\times f}\\) . The intuition is that some unimportant feature maps will go down to \\(0\\) or near \\(0\\) , and the important feature maps are magnified! The code has this structure: weighted_localization_map = torch . clone ( forward_conv_activations ) # weight the channels by corresponding gradients for i in range ( num_feature_maps ): weighted_localization_map [ :, i , :, : ] *= global_average_pooled_gradients [ i ] # sum the channels of the activations weighted_localization_map = torch . sum ( weighted_localization_map , dim = 1 ) . squeeze () Step 5: Grad-CAM Localization Map with ReLU The last step is to apply ReLU to the \\(\\textbf{Localized_Feature_Map}\\) above. This is really to zero out all negative entries. Why? Well, for one, in typical logistic regression, negative weights are associated with the model placing importance in the \"other class of interest\", and we do not want that. The same analogy can be applied here though I believe mine is hand-wavy at best. \\[L^c_{Grad-CAM} \\in \\mathbb{R}^{f \\times f} = \\underbrace{ReLU}_{\\text{Pick positive values}}\\left(\\sum_{k} \\alpha_k^c A^k\\right)\\] The code has structure like: # relu on top of the heatmap expression (2) in https://arxiv.org/pdf/1610.02391.pdf relu_weighted_localization_map = torch . nn . ReLU ( inplace = False )( weighted_localization_map ) # normalize the heatmap, scale features to between 0 and 1 to plot gradcam_heatmap = relu_weighted_localization_map / torch . max ( relu_weighted_localization_map ) Step 6: Superimpose the Grad-CAM Heatmap to Original Image This step is just doing some resizing from the \\(f \\times f\\) to say \\(224 \\times 224\\) to overlay on the original image. Dissecting KERAS's code https://keras.io/examples/vision/grad_cam/ has sample code but I converted to PyTorch, before converting, I annotated each of the variable inside. (See my KERAS notebook as I changed some variables name). last_conv_layer_output Shape: \\(2 \\times 2 \\times 3\\) with 3 filters of 2 by 2 shape. Note this is just \\(\\A^1, \\A^2, \\A^3\\) where each \\(\\A^k \\in \\R^{2 \\times 2}\\) . y_logits Shape: \\(1 \\times 1000\\) since there are 1000 classes in ImageNet. Note that this is our \\(\\y\\) . If we are interested in the elephant class at index 386, then we denote it as \\(\\y^{c} = \\y^{386}\\) . Thus, \\(\\y \\in \\R^{1 \\times 1000}\\) but \\(\\y^{c} \\in \\R^{1 \\times 1}\\) . Note carefully this is the logits output of all the layers of the CNN, and is just right before the softmax where we transform the logits to probabilities. We can imagine that among these 1000 logits, the highest number means the model thinks that this index is the most probable class. Theoretically speaking, there is no difference in differentiation of the logits wrt to the feature maps versus the softmax probs wrt to the feature maps. This is because softmax is monotonic , and the pre-softmax logits output will tell us already which class is most probable, and so will the softmax. So there should not be any confusion here on why we did not differentiate softmax probs wrt to the feature maps instead since the ranking is preserved in the sense that values in logits the highest is the most probable when transformed by softmax. target_category This is an optional argument in the function. If None , we will automatically assign it to the highest logit's index. In this example, the highest logit in \\(\\y\\) is at index 386 with a value of \\(23.632\\) , corresponding to the target class of elephant. If specified, then the \\(\\y^{c}\\) will change. target_category_logits Once our target_category is defined, we will just slice y_logits[:, target_category] to get the logit value of that particular class. This variable is just \\(\\y^{c}\\) if you look carefully. grads = tape.gradient(target_category_logits, last_conv_layer_output) This is the gradient of the output neuron (top predicted or chosen) with regard to the output feature map of the last conv layer. This has shape \\(2 \\times 2 \\times 3\\) in our simple example. In the python example, the shape at this moment has an additional axis like \\(1 \\times 2 \\times 2 \\times 3\\) which we will eventually squeeze it anyways. Notice it has the same shape as last_conv_layer_output aka the feature maps. In other words, this variable has 3 feature maps stacked together and can be visualized as: \\[\\begin{bmatrix} \\dfrac{d\\y^{c}}{d\\A^{1}} & \\dfrac{d\\y^{c}}{d\\A^{2}} & \\dfrac{d\\y^{c}}{d\\A^{3}} \\end{bmatrix}\\] pooled_grads Shape: \\(3 \\times 1\\) This is a vector where each entry is the mean intensity of the gradient over a specific feature map channel. In other words, in grads[0] we have \\(\\frac{d\\y^c}{d\\A^1}\\) which is of shape \\(2 \\times 2\\) . What we do not is Global Average Pooling on these gradients where we just take the average of all available pixels in this \\(2 \\times 2\\) gradient map for feature map 1. You can find more intuition of GAP above, but in general this is similar logic to how you perform GAP on the output of the feature logits from the last conv layer. \\[\\alpha_k^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^k}}_{\\text{gradients via backprop}}\\] where \\(Z\\) is the total number of pixels in this gradient map. heatmap Shape: \\(2 \\times 2\\) which is also the filter size and also the feature map size. This is the weighted sum of all feature maps \\(\\A^1, \\A^2, \\A^3\\) and is \\[\\textbf{Localized_Map} = \\left(\\sum_{k} \\alpha_k^c A^k\\right)\\]","title":"Grad-CAM Explained"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#grad-cam-an-introduction","text":"We will be discussing the paper written by R.R Selvaraju et al on Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization on how we can interpret large scale Deep Neural Networks (CNN).","title":"Grad-CAM, an Introduction"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#terminologies","text":"","title":"Terminologies"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#feature-maps","text":"Feature Maps has an intuitive interpretation , understanding it intuitively should be prioritized than knowing the underlying mathematical structure. Imagine a 32 by 32 image, consider that a convolutional layer applied on the input and we assume only 2 kernels are applied, then only 2 feature maps are obtained: The first feature map is a color filter that is responsible to detect color contrast of an image; The second feature map is a sobel's filter where it detects edges. Then assume kernel has size 5 by 5, when convolved on the 32 by 32 image, yields a feature map output of size 28 by 28, although \"downsampled\", this feature map should still capture valueble spatial information of the 32 by 32 image, and in this case, all edges of the input image (say a cat) will be shown in the feature map 1, we call it \\(\\A^1\\) , and the color contrast is displayed on feature map 2, \\(\\A^2\\) . So the full settings is: An input image \\(\\mathcal{X}\\) of size \\((3, 32, 32)\\) . A CNN but we will only look at its very first layer, a conv layer that has: 2 kernels of size 5 by 5 and default paddings and stride such that the output feature map is 28 by 28. Original Cat Image Feature Map A1 and A2; By Hongnan G. Notice in the 2 feature maps above, after we pass in the RGB cat image of 3 channels to the first conv layer, we will receive two outputs, called feature maps , each of them will describe the image in one way or another. One thing to note is that earlier conv layers will retain a lot detailed information of the image such as the edges, color contrast, but as we go on later, the feature maps become more abstract as they capture high level and abstract details that we human cannot comprehend easily.","title":"Feature Maps"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#global-average-pooling-gap","text":"The GAP is usually applied after the last conv layer. But for the sake of explanation, we will assume that our \"last conv layer\" is our first conv layer. Instead of down sampling patches of the input feature map, global pooling down samples the entire feature map to a single value. In the last few years, experts have turned to global average pooling (GAP) layers to minimize overfitting by reducing the total number of parameters in the model. Similar to max pooling layers, GAP layers are used to reduce the spatial dimensions of a three-dimensional tensor. However, GAP layers perform a more extreme type of dimensionality reduction, where a tensor with dimensions h\u00d7w\u00d7d is reduced in size to have dimensions 1\u00d71\u00d7d. GAP layers reduce each h\u00d7w feature map to a single number by simply taking the average of all hw values. Visualize GAP; Courtesy of Alexis Cook Eventually our task is to classify whether the image is a cat or something else. We are unable to succinctly pass these 2 feature maps directly to a linear classifier to classify the cats (i.e. passing in two 28 by 28 kernels to a linear layer does not work but we need linear layer to give us an output). Therefore, we need to flatten these feature maps generated by the conv layers. One way to do this is Global Average Pooling . A wrong example First, I show you a source of confusion on what some perceive GAP as: For example: \\[ \\A^1 = \\begin{bmatrix} 2 & 3 \\\\ 1 & 5 \\end{bmatrix} \\quad \\A^2 = \\begin{bmatrix} 3 & 1 \\\\ 2 & 8 \\end{bmatrix} \\] Assume for a moment \\(\\A^1\\) and \\(\\A^2\\) are our feature maps (although I mentioned it was 28 by 28 but this illustrates the idea). Then to retain the spatial information, we can perform an averaging across depths/channels of each kernel as such: \\[ \\A_{\\text{average feature maps across depth}} = \\dfrac{\\A^1 + \\A^2}{\\textbf{num_feature_maps}} = \\dfrac{\\A^1 + \\A^2}{2} = \\begin{bmatrix} 2.5 & 2 \\\\ 1.5 & 6.5 \\end{bmatrix} \\] Then we flatten the \\(\\A_{gap}\\) to a single vector and pass it to linear layer. Feature Map A1 and A2 but Averaged over Channels; By Hongnan G. A correct example \\[ \\A^1 = \\begin{bmatrix} 2 & 3 \\\\ 1 & 5 \\end{bmatrix} \\quad \\A^2 = \\begin{bmatrix} 3 & 1 \\\\ 2 & 8 \\end{bmatrix} \\] Assume for a moment \\(\\A^1\\) and \\(\\A^2\\) are our feature maps (although I mentioned it was 28 by 28 but this illustrates the idea). Then to retain the spatial information, we can perform an averaging across each kernel as such: \\[ \\text{mean}\\left(\\A^1\\right) = \\dfrac{2+3+1+5}{2 \\times 2} = 2.75 \\quad \\text{mean}\\left(\\A^2\\right) = \\dfrac{3+1+2+8}{2 \\times 2} = 3.5 \\] where by \\(2 \\times 2\\) means the number of pixels in the feature map; and thus the \\[ \\A_{\\text{gap}} = \\begin{bmatrix}2.75 \\\\ 3.5 \\end{bmatrix} \\] The Grad-CAM paper also applied the GAP idea over each feature map \\(\\A_k\\) . One can refer to here to understand the intuition here. Basically each unique feature map will be reduced to a single value, for eg, \\(2.75\\) , which summarizes the entire feature map.","title":"Global Average Pooling (GAP)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#the-intuition","text":"This part is referenced from Interpretable Machine Learning by Christoph Molnar . He started off with an intuitive description of Grad-CAM. High level idea: Grad-CAM is to understand at which parts of an image a convolutional layer \"looks\" for a certain classification. As a reminder, the first convolutional layer of a CNN takes as input the images and outputs feature maps that encode learned features (see the chapter on Learned Features ). The higher-level convolutional layers do the same, but take as input the feature maps of the previous convolutional layers. To understand how the CNN makes decisions, Grad-CAM analyzes which regions are activated in the feature maps of the last convolutional layers. There are \\(k\\) feature maps in the last convolutional layer, and I will call them \\(\\A^1, \\A^2, \\ldots, \\A^k\\) . How can we \"see\" from the feature maps how the convolutional neural network has made a certain classification? In the first approach, we could simply visualize the raw values of each feature map, average over the feature maps and overlay this over our image. This is the method of visualization feature map activations. This would not be helpful since the feature maps encode information for all classes , but we are interested in a particular class. Grad-CAM has to decide how important each of the k feature map was to our class c that we are interested in. We have to weight each pixel of each feature map with the gradient before we average over the feature maps. This gives us a heatmap which highlights regions that positively or negatively affect the class of interest. This heatmap is send through the ReLU function, which is a fancy way of saying that we set all negative values to zero. Grad-CAM removes all negative values by using a ReLU function, with the argument that we are only interested in the parts that contribute to the selected class c and not to other classes. The word pixel might be misleading here as the feature map is smaller than the image (because of the pooling units) but is mapped back to the original image. We then scale the Grad-CAM map to the interval [0,1] for visualization purposes and overlay it over the original image.","title":"The Intuition"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#the-big-picture","text":"This part can be best understood alongside my drawings. The big picture is when you \"reduce\" the 3 feature maps into 1 single new \"feature map\" (localization map) by way of a linear sum where each feature map \\(\\A^k\\) is multiplied by the global average pooled gradients \\(\\alpha_k^c\\) . In the example on my drawings, it can be seen that feature maps \\(\\A^1\\) and \\(\\A^2\\) are more important for the model to distinguish the elephant class than that of \\(\\A^3\\) . By design, I made \\(\\A^3\\) in itself already look different in terms of values from \\(\\A^1\\) and \\(\\A^2\\) on the get go. But at this point in time, even though we know the values in feature map \\(\\A^3\\) are vastly different, we cannot say for sure whether \\(\\A^3\\) in itself contributed to the prediction of our class elephant or not. It could also be the case that \\(\\A^1\\) and \\(\\A^2\\) are bonkers. Thus, the concept of taking the gradient of the class \\(\\y^c\\) with respect to each of these feature maps \\(\\A^k\\) becomes increasingly important as now we have a mathematical way to assign some importance to each of these feature maps. Now to even further bring out the intuition, imagine the 3 feature maps for the input image elephant as follows: Feature map \\(\\A^1\\) corresponds to Sobel Filter where it detect edges in particular their trunk of the elephants . Feature map \\(\\A^2\\) corresponds to Another Filter where it detects the ear of the elephants . Feature map \\(\\A^3\\) corresponds to a Background Filter where it detect the background and in particular the grass patch under the elephants . Now this is apparent why \\(\\A^3\\) is vastly different in terms of values since it is actually representing the background and grass. We know that grass is a non-factor in determining an elephant since the african grass field can hold many other animals as well. We really do not want the model to assign important to the grass, if any at all. We can then compute the gradient of \\(\\y^c\\) wrt each feature map and we can intuitively understand it as (see my diagrams): Gradient map \\(\\frac{d\\y^{386}}{d\\A^1}\\) has values \\(\\begin{bmatrix} 2 & 3 \\\\ 4 & 2 \\end{bmatrix}\\) These values are the gradients of feature map \\(\\A^1\\) at a pixel level. We may find it difficult to comprehend these gradients and we want a quick summary of how feature map \\(\\A^1\\) changes our model's decision for \\(\\y^{386}\\) . Thus we use GAP. and when we perform GAP on them, we have \\(\\alpha_{1}^{386} = 2.75\\) . This value roughly translates to a pertubation of \\(2.75\\) in feature map \\(\\A^1\\) will result in a unit change in our class \\(\\y^{386}\\) . Gradient map \\(\\frac{d\\y^{386}}{d\\A^2}\\) has values \\(\\begin{bmatrix} 3 & 5 \\\\ 6 & 3 \\end{bmatrix}\\) and when we perform GAP on them, we have \\(4.25\\) . The same logic applies. Gradient map \\(\\frac{d\\y^{386}}{d\\A^3}\\) has values \\(\\begin{bmatrix} 0.1 & -0.1 \\\\ 0.2 & 0.2 \\end{bmatrix}\\) and when we perform GAP on them, we have \\(0.1\\) . The same logic applies and we see that the gradient is small here and hence we can deduce that this feature map is not very important. Ultimately however, we want to know how the change in all feature maps \\(\\A^k\\) affects our final decision. This is where we perform a linear sum of \\(\\left(\\sum_{k} \\alpha_k^c A^k\\right)\\) of all feature maps with the weight coefficient being their global average pooled gradient map. Just like our good old linear regression model, the intuition is the same as in \\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ...\\) . The coefficients (the gradient values of \\(2.75, 4.25, 0.1\\) decides which feature map are important and gets \"activated and highlighted\"). We get the weighted sum heatmap to be the shape \\((2, 2)\\) of values \\([8.925, -2.025, 16.125, 2.6]\\) . Now this is a very small map and is likely not going to happen in real life. More often the map at this stage is of size \\((10, 10)\\) and beyond. Imagine once more how \\(\\A^3\\) played almost no role. Lastly, an elementwise ReLU operation is applied to the heatmap to get \\([8,925, 0, 16.125, 2.6]\\) and from the paper: We apply a ReLU to the linear combination of maps because we are only interested in the features that have a positive influence on the class of interest, i.e. pixels whose intensity should be increased in order to increase \\(y^{c}\\) . Intuitively, the idea is that negative values contribute to other classes and we should not really care about it. We can scale back the heatmap to overlay on the original image. From here , author said: Another potential question that can arise is why wouldn\u2019t we just compute the gradient of the class logit with respect to the input image. Remember that a convolutional neural network works as a feature extractor and deeper layers of the network operate in increasingly abstract spaces. We want to see which of the features actually influenced the model\u2019s choice of the class rather than just individual image pixels. That is why it is crucial to take the activation maps of deeper convolutional layers.","title":"The Big Picture"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#the-algorithm","text":"With reference to Interpretable Machine Learning by Christoph Molnar .","title":"The Algorithm"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#notation","text":"Input image: \\(\\X\\) Feature Maps of the last convolutional layer in a CNN is denoted as: \\[\\A_1, \\A_2, \\ldots, \\A_k\\] The \\(k\\) is an arbitrary number for the number of feature maps. The Feature Logits of a particular class \\(c\\) is denoted as: \\[\\y^{c}\\] In other words, in ImageNet , the elephant class is indexed \\(386\\) , and is denoted \\(\\y^{386}\\) . This is also the raw feature logits output before the softmax layer. The gradient of the fully-connected logits for class \\(c\\) , \\(\\y^{c}\\) (before the softmax), with respect to feature map activations \\(\\A_k\\) of a convolutional layer : \\[\\dfrac{d\\y^{c}}{d\\A^{k}}\\] It follows that the gradient of the fully-connected for each class \\(c\\) , \\(\\y^{c}\\) , with respect to each pixel on the feature map activations \\(\\A_k\\) is denoted as : \\[\\dfrac{d\\y^{c}}{d\\A^{k}_{ij}}\\] Let us define the gradient of \\(\\y^c\\) with respect to the GAP of each feature map \\(\\A^k\\) to be: \\[\\alpha_k^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^k}}_{\\text{gradients via backprop}}\\] Denote the ReLU function as: \\[\\textbf{ReLU}\\] The final heatmap, also called the localization map of Grad-CAM is denoted as: \\[\\L^{c}_{Grad-CAM} \\in \\R^{w \\times h}\\] where \\(w\\) and \\(h\\) is the width and height of the final output localization map. and is equals to \\[\\L^{c}_{Grad-CAM} \\in \\R^{w \\times h} = \\underbrace{ReLU}_{\\text{Pick positive values}}\\left(\\sum_{k} \\alpha_k^c A^k\\right)\\]","title":"Notation"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#the-algorithm_1","text":"We will only assume our input is 1 single image. Let us look at the recipe for Grad-CAM. Our goal is to find the localization map, which is defined as: \\[L^c_{Grad-CAM} \\in \\mathbb{R}^{u\\times v} = \\underbrace{ReLU}_{\\text{Pick positive values}}\\left(\\sum_{k} \\alpha_k^c A^k\\right)\\] Here, u is the width, v the height of the explanation and c the class of interest. Forward-propagate the input image through the convolutional neural network. Obtain the raw score for the class of interest, meaning the activation of the neuron before the softmax layer. Set all other class activations to zero. Back-propagate the gradient of the class of interest to the last convolutional layer before the fully connected layers: \\(\\frac{\\delta{}y^c}{\\delta{}A^k}\\) . Weight each feature map \"pixel\" by the gradient for the class. Indices i and j refer to the width and height dimensions: \\( \\(\\alpha_k^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^k}}_{\\text{gradients via backprop}}\\) \\) This means that the gradients are globally pooled. Calculate an average of the feature maps, weighted per pixel by the gradient. Apply ReLU to the averaged feature map. For visualization: Scale values to the interval between 0 and 1. Upscale the image and overlay it over the original image. Additional step for Guided Grad-CAM: Multiply heatmap with guided backpropagation.","title":"The Algorithm"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#step-1-forward-propagate","text":"This step just takes in one single image \\(\\mathcal{X}\\) and perform a forward pass the input image through the convolutional neural network and save all the forward pass feature map activations . # the y_logits before softmax; forward pass to populate the forward_activations y_logits = model ( image ) # this dict will be populated with the feature map outputs forward_activations = { \"features.11_ReLU(inplace=True)\" : feature_map_logits } We now have the feature maps stored and we can get our target conv layer. \\[ \\begin{bmatrix} \\A^1 & \\A^2 & \\A^3 & \\cdots & \\A^k \\end{bmatrix} \\] where each \\(\\A^i \\in \\R^{f \\times f}\\) .","title":"Step 1: Forward-propagate"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#step-2-backward-propagate","text":"In Grad-CAM, we need the gradients of the target category with respect to the target convolutional layer . That is to say, when we call backwards, we are only interested in the particular class's gradients wrt feature maps. if target_category is None : # get the most likely prediction of the model target_category = model ( image ) . argmax ( dim = 1 ) # convert to scalar target_category = target_category . item () # call backward on the model to populate backward_gradients y_logits [:, target_category ] . backward () # this dict will be populated with the gradients backward_gradients = { \"features.11_ReLU(inplace=True)\" : gradients_yc_wrt_features .11 } The above code just says, if we did not choose a target category , the model will choose the one with the highest logit activation. We then call y_logits[: target_category] backwards to store the gradients in backward_gradients . We now have the gradients of the class of interest with respect to the target conv layer (usually last conv layer). \\[ \\begin{bmatrix} \\dfrac{d\\y^{c}}{d\\A^{1}} & \\dfrac{d\\y^{c}}{d\\A^{2}} & \\dfrac{d\\y^{c}}{d\\A^{3}} & \\cdots & \\dfrac{d\\y^{c}}{d\\A^{k}} \\end{bmatrix} \\] where each \\(\\dfrac{d\\y^{c}}{d\\A^{i}} \\in \\R^{f \\times f}\\) .","title":"Step 2: Backward-propagate"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#step-3-global-average-pool-gradients","text":"The intuition we explained earlier tells us that we need to assign an importance score to each feature map \\(\\A^i\\) . How to do that? In my naive thought, since \\(\\dfrac{d\\y^{c}}{d\\A^{i}}\\) is the same shape as the feature map \\(f \\times f\\) , I would have thought we can just multiply them elementwise. More concretely, If \\[ \\A^1 = \\begin{bmatrix} 2 & 3 \\\\ 1 & 5 \\end{bmatrix} \\quad \\A^2 = \\begin{bmatrix} 3 & 1 \\\\ 2 & 8 \\end{bmatrix} \\] and \\[ \\dfrac{d\\y^{c}}{d\\A^{1}} = \\begin{bmatrix} 0.1 & 0.2 \\\\ 0.3 & 0.5 \\end{bmatrix} \\quad \\dfrac{d\\y^{c}}{d\\A^{2}} = \\begin{bmatrix} 0.3 & 0.1 \\\\ 0.2 & 0.3 \\end{bmatrix} \\] Then we can weigh each feature map on a pixel level: \\[ \\A^1 * \\dfrac{d\\y^{c}}{d\\A^{1}} = \\begin{bmatrix} 0.2 & 0.6 \\\\ 0.3 & 0.25 \\end{bmatrix} \\quad \\A^2 * \\dfrac{d\\y^{c}}{d\\A^{2}} = \\begin{bmatrix} 0.9 & 0.1 \\\\ 0.4 & 0.24 \\end{bmatrix} \\] However, the paper suggested that we can perform a Global Average Pooling on the gradient maps first, the idea is the same, we assume that the average of each gradient map should be representative of the rate of change of \\(y^c\\) with respect to each feature map. \\[\\alpha_k^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^k}}_{\\text{gradients via backprop}}\\] where \\(Z\\) is the total number of pixels in this gradient map. Applying this to our example: \\[ \\alpha_1^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^1}}_{\\text{gradients via backprop}} = \\frac{1}{4}\\left(0.2+0.6+0.3+0.25\\right) = 0.3375 \\] \\[ \\alpha_2^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^2}}_{\\text{gradients via backprop}} = \\frac{1}{4}\\left(0.9+0.1+0.4+0.24\\right) = 0.41 \\] These \\(\\alpha_k^c\\) will be the importance score of each feature map \\(\\A^k\\) . We will stack them into vectors: \\[ \\begin{bmatrix} \\alpha_1^c & \\alpha_2^c & \\alpha_3^c & \\cdots & \\alpha_k^c \\end{bmatrix} \\] and \\(\\alpha_k^c \\in \\R\\) is a scalar. In code it is of the form: dyc_dA = backward_gradients [ target_layer_name ] # average pool the gradients across the channels global_average_pooled_gradients = torch . mean ( dyc_dA , dim = [ 0 , 2 , 3 ])","title":"Step 3: Global Average Pool Gradients"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#step-4-weighted-global-sum-localized-feature-maps","text":"Recall that good old linear regression has the form \\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_k x_k\\) . Now we do the same here and treat \\(\\alpha_k^c\\) as the beta weight coefficients, and feature maps \\(\\A^k\\) as our features to get: \\[\\textbf{Localized_Feature_Map} = \\left(\\sum_{k} \\alpha_k^c A^k\\right)\\] which has a shape of \\(\\R^{f \\times f}\\) . The intuition is that some unimportant feature maps will go down to \\(0\\) or near \\(0\\) , and the important feature maps are magnified! The code has this structure: weighted_localization_map = torch . clone ( forward_conv_activations ) # weight the channels by corresponding gradients for i in range ( num_feature_maps ): weighted_localization_map [ :, i , :, : ] *= global_average_pooled_gradients [ i ] # sum the channels of the activations weighted_localization_map = torch . sum ( weighted_localization_map , dim = 1 ) . squeeze ()","title":"Step 4: Weighted Global Sum: Localized Feature Maps"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#step-5-grad-cam-localization-map-with-relu","text":"The last step is to apply ReLU to the \\(\\textbf{Localized_Feature_Map}\\) above. This is really to zero out all negative entries. Why? Well, for one, in typical logistic regression, negative weights are associated with the model placing importance in the \"other class of interest\", and we do not want that. The same analogy can be applied here though I believe mine is hand-wavy at best. \\[L^c_{Grad-CAM} \\in \\mathbb{R}^{f \\times f} = \\underbrace{ReLU}_{\\text{Pick positive values}}\\left(\\sum_{k} \\alpha_k^c A^k\\right)\\] The code has structure like: # relu on top of the heatmap expression (2) in https://arxiv.org/pdf/1610.02391.pdf relu_weighted_localization_map = torch . nn . ReLU ( inplace = False )( weighted_localization_map ) # normalize the heatmap, scale features to between 0 and 1 to plot gradcam_heatmap = relu_weighted_localization_map / torch . max ( relu_weighted_localization_map )","title":"Step 5: Grad-CAM Localization Map with ReLU"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#step-6-superimpose-the-grad-cam-heatmap-to-original-image","text":"This step is just doing some resizing from the \\(f \\times f\\) to say \\(224 \\times 224\\) to overlay on the original image.","title":"Step 6: Superimpose the Grad-CAM Heatmap to Original Image"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/#dissecting-kerass-code","text":"https://keras.io/examples/vision/grad_cam/ has sample code but I converted to PyTorch, before converting, I annotated each of the variable inside. (See my KERAS notebook as I changed some variables name). last_conv_layer_output Shape: \\(2 \\times 2 \\times 3\\) with 3 filters of 2 by 2 shape. Note this is just \\(\\A^1, \\A^2, \\A^3\\) where each \\(\\A^k \\in \\R^{2 \\times 2}\\) . y_logits Shape: \\(1 \\times 1000\\) since there are 1000 classes in ImageNet. Note that this is our \\(\\y\\) . If we are interested in the elephant class at index 386, then we denote it as \\(\\y^{c} = \\y^{386}\\) . Thus, \\(\\y \\in \\R^{1 \\times 1000}\\) but \\(\\y^{c} \\in \\R^{1 \\times 1}\\) . Note carefully this is the logits output of all the layers of the CNN, and is just right before the softmax where we transform the logits to probabilities. We can imagine that among these 1000 logits, the highest number means the model thinks that this index is the most probable class. Theoretically speaking, there is no difference in differentiation of the logits wrt to the feature maps versus the softmax probs wrt to the feature maps. This is because softmax is monotonic , and the pre-softmax logits output will tell us already which class is most probable, and so will the softmax. So there should not be any confusion here on why we did not differentiate softmax probs wrt to the feature maps instead since the ranking is preserved in the sense that values in logits the highest is the most probable when transformed by softmax. target_category This is an optional argument in the function. If None , we will automatically assign it to the highest logit's index. In this example, the highest logit in \\(\\y\\) is at index 386 with a value of \\(23.632\\) , corresponding to the target class of elephant. If specified, then the \\(\\y^{c}\\) will change. target_category_logits Once our target_category is defined, we will just slice y_logits[:, target_category] to get the logit value of that particular class. This variable is just \\(\\y^{c}\\) if you look carefully. grads = tape.gradient(target_category_logits, last_conv_layer_output) This is the gradient of the output neuron (top predicted or chosen) with regard to the output feature map of the last conv layer. This has shape \\(2 \\times 2 \\times 3\\) in our simple example. In the python example, the shape at this moment has an additional axis like \\(1 \\times 2 \\times 2 \\times 3\\) which we will eventually squeeze it anyways. Notice it has the same shape as last_conv_layer_output aka the feature maps. In other words, this variable has 3 feature maps stacked together and can be visualized as: \\[\\begin{bmatrix} \\dfrac{d\\y^{c}}{d\\A^{1}} & \\dfrac{d\\y^{c}}{d\\A^{2}} & \\dfrac{d\\y^{c}}{d\\A^{3}} \\end{bmatrix}\\] pooled_grads Shape: \\(3 \\times 1\\) This is a vector where each entry is the mean intensity of the gradient over a specific feature map channel. In other words, in grads[0] we have \\(\\frac{d\\y^c}{d\\A^1}\\) which is of shape \\(2 \\times 2\\) . What we do not is Global Average Pooling on these gradients where we just take the average of all available pixels in this \\(2 \\times 2\\) gradient map for feature map 1. You can find more intuition of GAP above, but in general this is similar logic to how you perform GAP on the output of the feature logits from the last conv layer. \\[\\alpha_k^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^k}}_{\\text{gradients via backprop}}\\] where \\(Z\\) is the total number of pixels in this gradient map. heatmap Shape: \\(2 \\times 2\\) which is also the filter size and also the feature map size. This is the weighted sum of all feature maps \\(\\A^1, \\A^2, \\A^3\\) and is \\[\\textbf{Localized_Map} = \\left(\\sum_{k} \\alpha_k^c A^k\\right)\\]","title":"Dissecting KERAS's code"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\L}{\\mathbf{L}} \\newcommand{\\X}{\\mathbf{X}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\] Dependencies and Config from typing import * import cv2 import matplotlib.pyplot as plt import numpy as np import torch import torch.nn as nn import torchsummary import torchvision from torch.utils import data from torchvision import datasets , transforms from torchvision.models import * import glob import os import random # Display from IPython.display import Image , display from pytorch_grad_cam import GradCAM from pytorch_grad_cam.utils.image import show_cam_on_image import PIL % cd .. import utils C:\\Users\\reighns\\reighns_ml\\reighns_ml_blog\\docs\\reighns_ml_journey\\deep_learning\\computer_vision\\general\\neural_network_interpretation device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) utils . seed_all () Using Seed Number 1992 Load Images We load the images and plot the original image. We use the subplot function from the repo here. image_paths = glob . glob ( \"./images/animals/*.*\" ) # elephant has RGBA idk why so need convert images = list ( map ( lambda x : PIL . Image . open ( x ) . convert ( \"RGB\" ), image_paths )) plt . rcParams [ \"figure.figsize\" ] = 16 , 8 utils . subplot ( images , title = \"inputs\" , rows_titles = [ \"cat\" , \"dog_and_cat\" , \"african_elephant\" ], nrows = 1 , ncols = 3 , ) Transforms Params (ImageNet) imagenet_mean : List [ float ] = [ 0.485 , 0.456 , 0.406 ] imagenet_std : List [ float ] = [ 0.229 , 0.224 , 0.225 ] image_size : int = 224 normalized_transform = torchvision . transforms . Compose ( [ torchvision . transforms . Resize (( image_size , image_size )), torchvision . transforms . ToTensor (), torchvision . transforms . Normalize ( mean = imagenet_mean , std = imagenet_std ), ] ) inverse_normalized_transform = torchvision . transforms . Compose ( [ utils . NormalizeInverse ( mean = imagenet_mean , std = imagenet_std )] ) # We use torchvision's transform to transform the cat image with resize and normalization. # Note the tensors below should all be channels first! cat_tensor = normalized_transform ( images [ 0 ]) cat_and_dog_tensor = normalized_transform ( images [ 1 ]) elephant_tensor = normalized_transform ( images [ 2 ]) # Now feature_extractor expects batch_size x C x H x W, so we expand one dimension in the 0th dim and put them on device cat_tensor = cat_tensor . unsqueeze ( dim = 0 ) . to ( device ) cat_and_dog_tensor = cat_and_dog_tensor . unsqueeze ( dim = 0 ) . to ( device ) elephant_tensor = elephant_tensor . unsqueeze ( dim = 0 ) . to ( device ) # Construct an images_dict to store these tensors images_dict : Dict [ str , torch . Tensor ] = { \"cat\" : cat_tensor , \"cat_and_dog\" : cat_and_dog_tensor , \"elephant\" : elephant_tensor } Working with Torch Models Load the Models alexnet_ = alexnet ( pretrained = True ) . to ( device ) vgg16_ = vgg16 ( pretrained = True ) . to ( device ) resnet34_ = resnet34 ( pretrained = True ) . to ( device ) Torch Summary We use a library to output the layer information like Keras's model.summary() . We need to identify the last convolutional layer. import torchsummary def torchsummary_wrapper ( model , image_size : Tuple [ int , int , int ] ) -> torchsummary . model_statistics . ModelStatistics : \"\"\"A torch wrapper to print out layers of a Model. Args: model (CustomNeuralNet): Model. image_size (Tuple[int, int, int]): Image size as a tuple of (channels, height, width). Returns: model_summary (torchsummary.model_statistics.ModelStatistics): Model summary. \"\"\" model_summary = torchsummary . summary ( model , image_size ) return model_summary alexnet_model_summary = torchsummary_wrapper ( alexnet_ , image_size = ( 3 , 224 , 224 )) ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== \u251c\u2500Sequential: 1-1 [-1, 256, 6, 6] -- | \u2514\u2500Conv2d: 2-1 [-1, 64, 55, 55] 23,296 | \u2514\u2500ReLU: 2-2 [-1, 64, 55, 55] -- | \u2514\u2500MaxPool2d: 2-3 [-1, 64, 27, 27] -- | \u2514\u2500Conv2d: 2-4 [-1, 192, 27, 27] 307,392 | \u2514\u2500ReLU: 2-5 [-1, 192, 27, 27] -- | \u2514\u2500MaxPool2d: 2-6 [-1, 192, 13, 13] -- | \u2514\u2500Conv2d: 2-7 [-1, 384, 13, 13] 663,936 | \u2514\u2500ReLU: 2-8 [-1, 384, 13, 13] -- | \u2514\u2500Conv2d: 2-9 [-1, 256, 13, 13] 884,992 | \u2514\u2500ReLU: 2-10 [-1, 256, 13, 13] -- | \u2514\u2500Conv2d: 2-11 [-1, 256, 13, 13] 590,080 | \u2514\u2500ReLU: 2-12 [-1, 256, 13, 13] -- | \u2514\u2500MaxPool2d: 2-13 [-1, 256, 6, 6] -- \u251c\u2500AdaptiveAvgPool2d: 1-2 [-1, 256, 6, 6] -- \u251c\u2500Sequential: 1-3 [-1, 1000] -- | \u2514\u2500Dropout: 2-14 [-1, 9216] -- | \u2514\u2500Linear: 2-15 [-1, 4096] 37,752,832 | \u2514\u2500ReLU: 2-16 [-1, 4096] -- | \u2514\u2500Dropout: 2-17 [-1, 4096] -- | \u2514\u2500Linear: 2-18 [-1, 4096] 16,781,312 | \u2514\u2500ReLU: 2-19 [-1, 4096] -- | \u2514\u2500Linear: 2-20 [-1, 1000] 4,097,000 ========================================================================================== Total params: 61,100,840 Trainable params: 61,100,840 Non-trainable params: 0 Total mult-adds (M): 775.28 ========================================================================================== Input size (MB): 0.57 Forward/backward pass size (MB): 3.77 Params size (MB): 233.08 Estimated Total Size (MB): 237.43 ========================================================================================== vgg16_model_summary = torchsummary_wrapper ( vgg16_ , image_size = ( 3 , 224 , 224 )) ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== \u251c\u2500Sequential: 1-1 [-1, 512, 7, 7] -- | \u2514\u2500Conv2d: 2-1 [-1, 64, 224, 224] 1,792 | \u2514\u2500ReLU: 2-2 [-1, 64, 224, 224] -- | \u2514\u2500Conv2d: 2-3 [-1, 64, 224, 224] 36,928 | \u2514\u2500ReLU: 2-4 [-1, 64, 224, 224] -- | \u2514\u2500MaxPool2d: 2-5 [-1, 64, 112, 112] -- | \u2514\u2500Conv2d: 2-6 [-1, 128, 112, 112] 73,856 | \u2514\u2500ReLU: 2-7 [-1, 128, 112, 112] -- | \u2514\u2500Conv2d: 2-8 [-1, 128, 112, 112] 147,584 | \u2514\u2500ReLU: 2-9 [-1, 128, 112, 112] -- | \u2514\u2500MaxPool2d: 2-10 [-1, 128, 56, 56] -- | \u2514\u2500Conv2d: 2-11 [-1, 256, 56, 56] 295,168 | \u2514\u2500ReLU: 2-12 [-1, 256, 56, 56] -- | \u2514\u2500Conv2d: 2-13 [-1, 256, 56, 56] 590,080 | \u2514\u2500ReLU: 2-14 [-1, 256, 56, 56] -- | \u2514\u2500Conv2d: 2-15 [-1, 256, 56, 56] 590,080 | \u2514\u2500ReLU: 2-16 [-1, 256, 56, 56] -- | \u2514\u2500MaxPool2d: 2-17 [-1, 256, 28, 28] -- | \u2514\u2500Conv2d: 2-18 [-1, 512, 28, 28] 1,180,160 | \u2514\u2500ReLU: 2-19 [-1, 512, 28, 28] -- | \u2514\u2500Conv2d: 2-20 [-1, 512, 28, 28] 2,359,808 | \u2514\u2500ReLU: 2-21 [-1, 512, 28, 28] -- | \u2514\u2500Conv2d: 2-22 [-1, 512, 28, 28] 2,359,808 | \u2514\u2500ReLU: 2-23 [-1, 512, 28, 28] -- | \u2514\u2500MaxPool2d: 2-24 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-25 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-26 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-27 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-28 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-29 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-30 [-1, 512, 14, 14] -- | \u2514\u2500MaxPool2d: 2-31 [-1, 512, 7, 7] -- \u251c\u2500AdaptiveAvgPool2d: 1-2 [-1, 512, 7, 7] -- \u251c\u2500Sequential: 1-3 [-1, 1000] -- | \u2514\u2500Linear: 2-32 [-1, 4096] 102,764,544 | \u2514\u2500ReLU: 2-33 [-1, 4096] -- | \u2514\u2500Dropout: 2-34 [-1, 4096] -- | \u2514\u2500Linear: 2-35 [-1, 4096] 16,781,312 | \u2514\u2500ReLU: 2-36 [-1, 4096] -- | \u2514\u2500Dropout: 2-37 [-1, 4096] -- | \u2514\u2500Linear: 2-38 [-1, 1000] 4,097,000 ========================================================================================== Total params: 138,357,544 Trainable params: 138,357,544 Non-trainable params: 0 Total mult-adds (G): 15.61 ========================================================================================== Input size (MB): 0.57 Forward/backward pass size (MB): 103.43 Params size (MB): 527.79 Estimated Total Size (MB): 631.80 ========================================================================================== resnet34_model_summary = torchsummary_wrapper ( resnet34_ , image_size = ( 3 , 224 , 224 )) ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== \u251c\u2500Conv2d: 1-1 [-1, 64, 112, 112] 9,408 \u251c\u2500BatchNorm2d: 1-2 [-1, 64, 112, 112] 128 \u251c\u2500ReLU: 1-3 [-1, 64, 112, 112] -- \u251c\u2500MaxPool2d: 1-4 [-1, 64, 56, 56] -- \u251c\u2500Sequential: 1-5 [-1, 64, 56, 56] -- | \u2514\u2500BasicBlock: 2-1 [-1, 64, 56, 56] -- | | \u2514\u2500Conv2d: 3-1 [-1, 64, 56, 56] 36,864 | | \u2514\u2500BatchNorm2d: 3-2 [-1, 64, 56, 56] 128 | | \u2514\u2500ReLU: 3-3 [-1, 64, 56, 56] -- | | \u2514\u2500Conv2d: 3-4 [-1, 64, 56, 56] 36,864 | | \u2514\u2500BatchNorm2d: 3-5 [-1, 64, 56, 56] 128 | | \u2514\u2500ReLU: 3-6 [-1, 64, 56, 56] -- | \u2514\u2500BasicBlock: 2-2 [-1, 64, 56, 56] -- | | \u2514\u2500Conv2d: 3-7 [-1, 64, 56, 56] 36,864 | | \u2514\u2500BatchNorm2d: 3-8 [-1, 64, 56, 56] 128 | | \u2514\u2500ReLU: 3-9 [-1, 64, 56, 56] -- | | \u2514\u2500Conv2d: 3-10 [-1, 64, 56, 56] 36,864 | | \u2514\u2500BatchNorm2d: 3-11 [-1, 64, 56, 56] 128 | | \u2514\u2500ReLU: 3-12 [-1, 64, 56, 56] -- | \u2514\u2500BasicBlock: 2-3 [-1, 64, 56, 56] -- | | \u2514\u2500Conv2d: 3-13 [-1, 64, 56, 56] 36,864 | | \u2514\u2500BatchNorm2d: 3-14 [-1, 64, 56, 56] 128 | | \u2514\u2500ReLU: 3-15 [-1, 64, 56, 56] -- | | \u2514\u2500Conv2d: 3-16 [-1, 64, 56, 56] 36,864 | | \u2514\u2500BatchNorm2d: 3-17 [-1, 64, 56, 56] 128 | | \u2514\u2500ReLU: 3-18 [-1, 64, 56, 56] -- \u251c\u2500Sequential: 1-6 [-1, 128, 28, 28] -- | \u2514\u2500BasicBlock: 2-4 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-19 [-1, 128, 28, 28] 73,728 | | \u2514\u2500BatchNorm2d: 3-20 [-1, 128, 28, 28] 256 | | \u2514\u2500ReLU: 3-21 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-22 [-1, 128, 28, 28] 147,456 | | \u2514\u2500BatchNorm2d: 3-23 [-1, 128, 28, 28] 256 | | \u2514\u2500Sequential: 3-24 [-1, 128, 28, 28] 8,448 | | \u2514\u2500ReLU: 3-25 [-1, 128, 28, 28] -- | \u2514\u2500BasicBlock: 2-5 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-26 [-1, 128, 28, 28] 147,456 | | \u2514\u2500BatchNorm2d: 3-27 [-1, 128, 28, 28] 256 | | \u2514\u2500ReLU: 3-28 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-29 [-1, 128, 28, 28] 147,456 | | \u2514\u2500BatchNorm2d: 3-30 [-1, 128, 28, 28] 256 | | \u2514\u2500ReLU: 3-31 [-1, 128, 28, 28] -- | \u2514\u2500BasicBlock: 2-6 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-32 [-1, 128, 28, 28] 147,456 | | \u2514\u2500BatchNorm2d: 3-33 [-1, 128, 28, 28] 256 | | \u2514\u2500ReLU: 3-34 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-35 [-1, 128, 28, 28] 147,456 | | \u2514\u2500BatchNorm2d: 3-36 [-1, 128, 28, 28] 256 | | \u2514\u2500ReLU: 3-37 [-1, 128, 28, 28] -- | \u2514\u2500BasicBlock: 2-7 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-38 [-1, 128, 28, 28] 147,456 | | \u2514\u2500BatchNorm2d: 3-39 [-1, 128, 28, 28] 256 | | \u2514\u2500ReLU: 3-40 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-41 [-1, 128, 28, 28] 147,456 | | \u2514\u2500BatchNorm2d: 3-42 [-1, 128, 28, 28] 256 | | \u2514\u2500ReLU: 3-43 [-1, 128, 28, 28] -- \u251c\u2500Sequential: 1-7 [-1, 256, 14, 14] -- | \u2514\u2500BasicBlock: 2-8 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-44 [-1, 256, 14, 14] 294,912 | | \u2514\u2500BatchNorm2d: 3-45 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-46 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-47 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-48 [-1, 256, 14, 14] 512 | | \u2514\u2500Sequential: 3-49 [-1, 256, 14, 14] 33,280 | | \u2514\u2500ReLU: 3-50 [-1, 256, 14, 14] -- | \u2514\u2500BasicBlock: 2-9 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-51 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-52 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-53 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-54 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-55 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-56 [-1, 256, 14, 14] -- | \u2514\u2500BasicBlock: 2-10 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-57 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-58 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-59 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-60 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-61 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-62 [-1, 256, 14, 14] -- | \u2514\u2500BasicBlock: 2-11 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-63 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-64 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-65 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-66 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-67 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-68 [-1, 256, 14, 14] -- | \u2514\u2500BasicBlock: 2-12 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-69 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-70 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-71 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-72 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-73 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-74 [-1, 256, 14, 14] -- | \u2514\u2500BasicBlock: 2-13 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-75 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-76 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-77 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-78 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-79 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-80 [-1, 256, 14, 14] -- \u251c\u2500Sequential: 1-8 [-1, 512, 7, 7] -- | \u2514\u2500BasicBlock: 2-14 [-1, 512, 7, 7] -- | | \u2514\u2500Conv2d: 3-81 [-1, 512, 7, 7] 1,179,648 | | \u2514\u2500BatchNorm2d: 3-82 [-1, 512, 7, 7] 1,024 | | \u2514\u2500ReLU: 3-83 [-1, 512, 7, 7] -- | | \u2514\u2500Conv2d: 3-84 [-1, 512, 7, 7] 2,359,296 | | \u2514\u2500BatchNorm2d: 3-85 [-1, 512, 7, 7] 1,024 | | \u2514\u2500Sequential: 3-86 [-1, 512, 7, 7] 132,096 | | \u2514\u2500ReLU: 3-87 [-1, 512, 7, 7] -- | \u2514\u2500BasicBlock: 2-15 [-1, 512, 7, 7] -- | | \u2514\u2500Conv2d: 3-88 [-1, 512, 7, 7] 2,359,296 | | \u2514\u2500BatchNorm2d: 3-89 [-1, 512, 7, 7] 1,024 | | \u2514\u2500ReLU: 3-90 [-1, 512, 7, 7] -- | | \u2514\u2500Conv2d: 3-91 [-1, 512, 7, 7] 2,359,296 | | \u2514\u2500BatchNorm2d: 3-92 [-1, 512, 7, 7] 1,024 | | \u2514\u2500ReLU: 3-93 [-1, 512, 7, 7] -- | \u2514\u2500BasicBlock: 2-16 [-1, 512, 7, 7] -- | | \u2514\u2500Conv2d: 3-94 [-1, 512, 7, 7] 2,359,296 | | \u2514\u2500BatchNorm2d: 3-95 [-1, 512, 7, 7] 1,024 | | \u2514\u2500ReLU: 3-96 [-1, 512, 7, 7] -- | | \u2514\u2500Conv2d: 3-97 [-1, 512, 7, 7] 2,359,296 | | \u2514\u2500BatchNorm2d: 3-98 [-1, 512, 7, 7] 1,024 | | \u2514\u2500ReLU: 3-99 [-1, 512, 7, 7] -- \u251c\u2500AdaptiveAvgPool2d: 1-9 [-1, 512, 1, 1] -- \u251c\u2500Linear: 1-10 [-1, 1000] 513,000 ========================================================================================== Total params: 21,797,672 Trainable params: 21,797,672 Non-trainable params: 0 Total mult-adds (G): 3.71 ========================================================================================== Input size (MB): 0.57 Forward/backward pass size (MB): 57.05 Params size (MB): 83.15 Estimated Total Size (MB): 140.77 ========================================================================================== Forward Backward Hooks def forward_hook ( module_name : str , forward_activations : Dict [ str , torch . Tensor ] ) -> Callable : \"\"\"In-place forward hook to save activations of a layer. Args: module_name (str): The name of the layer to hook. forward_activations (Dict[str, torch.Tensor]): The dictionary to save the activations. Returns: forward_hook_: The forward hook function. \"\"\" def forward_hook_ ( module , input , output ): # Save forward feature map activations forward_activations [ module_name ] = output . detach () return forward_hook_ def backward_hook ( module_name : str , backward_gradients : Dict [ str , torch . Tensor ] ) -> Callable : \"\"\"In-place backward hook to save gradients of a layer. Args: module_name (str): The name of the layer to hook. backward_gradients (Dict[str, torch.Tensor]): The dictionary to save the gradients. Returns: Callable: The backward hook function. \"\"\" def backward_hook_ ( module , grad_input , grad_output ): # Save the gradients correspond to the feature maps # This will only be saved when backwards is called. backward_gradients [ module_name ] = grad_output [ 0 ] . detach () return backward_hook_ Saving Forward Activations and Backward Gradients We define a function to get feature map activations and the model's backwards gradients. def get_forward_activations_and_backward_gradients ( model : Callable , image : torch . Tensor , target_category : Optional [ int ] = None , ) -> Union [ List [ Callable ], Dict [ str , torch . Tensor ]]: \"\"\"Get feature maps and gradients from a model. Args: model (Callable): A model. image (torch.Tensor): The input image. target_category (Optional[int], optional): The target category for the model to focus on. Defaults to None. Returns: handlers List[Callable]: A list of handlers. forward_activations Dict[str, torch.Tensor]: A dictionary of forward activations. \"\"\" forward_activations = OrderedDict () backward_gradients = OrderedDict () handlers = [] for name , module in model . named_modules (): module_name = name + \"_\" + str ( module ) handlers . append ( module . register_forward_hook ( forward_hook ( module_name , forward_activations ) ) ) handlers . append ( module . register_backward_hook ( backward_hook ( module_name , backward_gradients ) ) ) model = model . eval () # the y_logits before softmax # forward pass to populate the forward_activations y_logits = model ( image ) if target_category is None : # get the most likely prediction of the model target_category = model ( image ) . argmax ( dim = 1 ) # convert to scalar target_category = target_category . item () # call backward on the model to populate backward_gradients y_logits [:, target_category ] . backward () return handlers , forward_activations , backward_gradients Grad-CAM Storing Forward Activations and Backward Gradients This part is the same as Saving Forward Activations and Backward Gradients. def get_forward_activations_and_backward_gradients ( model : Callable , image : torch . Tensor , target_category : Optional [ int ] = None , ) -> Union [ List [ Callable ], Dict [ str , torch . Tensor ]]: \"\"\"Get feature maps and gradients from a model. Args: model (Callable): A model. image (torch.Tensor): The input image. target_category (Optional[int], optional): The target category for the model to focus on. Defaults to None. Returns: handlers List[Callable]: A list of handlers. forward_activations Dict[str, torch.Tensor]: A dictionary of forward activations. \"\"\" forward_activations = OrderedDict () backward_gradients = OrderedDict () handlers = [] for name , module in model . named_modules (): module_name = name + \"_\" + str ( module ) handlers . append ( module . register_forward_hook ( forward_hook ( module_name , forward_activations ) ) ) handlers . append ( module . register_backward_hook ( backward_hook ( module_name , backward_gradients ) ) ) model = model . eval () # the y_logits before softmax # forward pass to populate the forward_activations y_logits = model ( image ) if target_category is None : # get the most likely prediction of the model target_category = model ( image ) . argmax ( dim = 1 ) # convert to scalar target_category = target_category . item () # call backward on the model to populate backward_gradients y_logits [:, target_category ] . backward () return handlers , forward_activations , backward_gradients Grad-CAM Heatmap Function def compute_gradcam_localization_heatmap ( target_layer_name : str , forward_activations : Dict [ str , torch . Tensor ], backward_gradients : Dict [ str , torch . Tensor ], ) -> torch . Tensor : \"\"\"Compute GradCAM for a specific target layer. Args: target_layer_name (str): The name of the target layer. Usually the last convolutional layer. forward_activations (Dict[str, torch.Tensor]): The forward activations of the model. A dictionary of activations. backward_gradients (Dict[str, torch.Tensor]): The backward gradients of the model. A dictionary of gradients. Returns: gradcam_heatmap (torch.Tensor): The heatmap of the GradCAM. \"\"\" # get the activations of the last convolutional layer forward_conv_activations = forward_activations [ target_layer_name ] dyc_dA = backward_gradients [ target_layer_name ] # average pool the gradients across the channels global_average_pooled_gradients = torch . mean ( dyc_dA , dim = [ 0 , 2 , 3 ]) num_feature_maps = forward_conv_activations . squeeze () . shape [ 0 ] weighted_localization_map = torch . clone ( forward_conv_activations ) # weight the channels by corresponding gradients for i in range ( num_feature_maps ): weighted_localization_map [ :, i , :, : ] *= global_average_pooled_gradients [ i ] # sum the channels of the activations weighted_localization_map = torch . sum ( weighted_localization_map , dim = 1 ) . squeeze () # relu on top of the heatmap expression (2) in https://arxiv.org/pdf/1610.02391.pdf relu_weighted_localization_map = torch . nn . ReLU ( inplace = False )( weighted_localization_map ) # normalize the heatmap, scale features to between 0 and 1 to plot gradcam_heatmap = relu_weighted_localization_map / torch . max ( relu_weighted_localization_map ) # draw the heatmap plt . rcParams [ \"figure.figsize\" ] = 16 , 8 plt . matshow ( gradcam_heatmap . squeeze ()) return gradcam_heatmap SuperImpose Image Superimpose heatmap to original image. def display_gradcam ( image : torch . Tensor , gradcam_heatmap : torch . Tensor , alpha = 1.0 , ): \"\"\"Display the GradCAM heatmap. Args: image (torch.Tensor): _description_ gradcam_heatmap (torch.Tensor): _description_ alpha (float, optional): _description_. Defaults to 0.8. \"\"\" # step 1: Unnormalize the input image to be between 0 and 1, and multiply to become within 255 # squeeze dimensions when there is 1. because [1, 3, 224, 224] is [3, 224, 224] # shape = (3, 224, 224) original_image_unnormalized = inverse_normalized_transform ( image . squeeze () . cpu () ) original_image_unnormalized = original_image_unnormalized * 255 # step 2: make CxHxW to HxWxC and convert to numpy original_image_unnormalized = original_image_unnormalized . permute ( 1 , 2 , 0 ) . numpy () # step 3: Normalize the heatmap to between 0 and 1 and resize it to the image size we want, then multiply to within 255 # first make it into numpy gradcam_heatmap = gradcam_heatmap . detach () . cpu () . numpy () h , w , c = original_image_unnormalized . shape # normalize and resize gradcam_heatmap -= np . min ( gradcam_heatmap ) gradcam_heatmap /= np . max ( gradcam_heatmap ) # Normalize between 0-1 gradcam_heatmap = cv2 . resize ( gradcam_heatmap , ( w , h )) gradcam_heatmap = np . uint8 ( gradcam_heatmap * 255.0 ) # step 4: Apply color maps and overlay the heatmap on the original image to get superimposed image gradcam_heatmap = cv2 . applyColorMap ( gradcam_heatmap , cv2 . COLORMAP_JET ) gradcam_heatmap = cv2 . cvtColor ( gradcam_heatmap , cv2 . COLOR_BGR2RGB ) superimposed_image = gradcam_heatmap * alpha + original_image_unnormalized superimposed_image /= np . max ( superimposed_image ) # step 5: Display the image plt . rcParams [ \"figure.figsize\" ] = 16 , 8 plt . imshow ( superimposed_image ) return superimposed_image Alexnet Gradcam _ , f_alexnet , b_alexnet = get_forward_activations_and_backward_gradients ( alexnet_ , image = images_dict [ \"cat\" ], target_category = None ) C:\\Users\\reighns\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior. warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \" For this model, the last layer can be alexnet_.features.11 . In our case it is features.11_ReLU(inplace=True) . target_layer_name = \"features.11_ReLU(inplace=True)\" alexnet_gradcam_heatmap = compute_gradcam_localization_heatmap ( target_layer_name , f_alexnet , b_alexnet ) _ = display_gradcam ( image = images_dict [ \"cat\" ], gradcam_heatmap = alexnet_gradcam_heatmap , alpha = 1.0 ) VGG16 Gradcam _ , f_vgg16 , b_vgg16 = get_forward_activations_and_backward_gradients ( vgg16_ , image = images_dict [ \"cat\" ], target_category = None ) For this model, the last layer can be alexnet_.features.12 . In our case it is features.12_MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) . target_layer_name = \"features.29_ReLU(inplace=True)\" vgg16_gradcam_heatmap = compute_gradcam_localization_heatmap ( target_layer_name , f_vgg16 , b_vgg16 ) _ = display_gradcam ( image = images_dict [ \"cat\" ], gradcam_heatmap = vgg16_gradcam_heatmap , alpha = 1.0 ) VGG16 Grad-CAM with Target Category If we specifically pass into a target category, where 285 is cat and 260 is dog, we see the model sees different things! _ , f_vgg16 , b_vgg16 = get_forward_activations_and_backward_gradients ( vgg16_ , image = images_dict [ \"cat_and_dog\" ], target_category = 285 ) target_layer_name = \"features.29_ReLU(inplace=True)\" vgg16_gradcam_heatmap = compute_gradcam_localization_heatmap ( target_layer_name , f_vgg16 , b_vgg16 ) _ = display_gradcam ( image = images_dict [ \"cat_and_dog\" ], gradcam_heatmap = vgg16_gradcam_heatmap , alpha = 1.0 ) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). _ , f_vgg16 , b_vgg16 = get_forward_activations_and_backward_gradients ( vgg16_ , image = images_dict [ \"cat_and_dog\" ], target_category = 260 ) target_layer_name = \"features.29_ReLU(inplace=True)\" vgg16_gradcam_heatmap = compute_gradcam_localization_heatmap ( target_layer_name , f_vgg16 , b_vgg16 ) _ = display_gradcam ( image = images_dict [ \"cat_and_dog\" ], gradcam_heatmap = vgg16_gradcam_heatmap , alpha = 1.0 ) Out of the Box Library from pytorch_grad_cam import GradCAM , ScoreCAM , GradCAMPlusPlus , AblationCAM , XGradCAM , EigenCAM , FullGrad # from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget from pytorch_grad_cam.utils.image import show_cam_on_image from torchvision.models import resnet50 , vgg19 , resnet34 dog_and_cat_path = \"./images/animals/dog_and_cat.jpg\" image = cv2 . imread ( dog_and_cat_path ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) # needed for gradcam. original_image = cv2 . resize ( image , ( 224 , 224 )) model = vgg16 ( pretrained = True ) target_layers = [ model . features [ - 1 ]] input_tensor = images_dict [ \"cat_and_dog\" ] # Create an input tensor image for your model.. # Note: input_tensor can be a batch tensor with several images! # Construct the CAM object once, and then re-use it on many images: cam = GradCAM ( model = model , target_layers = target_layers , use_cuda = False ) # You can also use it within a with statement, to make sure it is freed, # In case you need to re-create it inside an outer loop: # with GradCAM(model=model, target_layers=target_layers, use_cuda=args.use_cuda) as cam: # ... # We have to specify the target we want to generate # the Class Activation Maps for. # If targets is None, the highest scoring category # will be used for every image in the batch. # Here we use ClassifierOutputTarget, but you can define your own custom targets # That are, for example, combinations of categories, or specific outputs in a non standard model. target_category = 285 # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing. grayscale_cam = cam ( input_tensor = input_tensor , target_category = target_category ) # In this example grayscale_cam has only one image in the batch: grayscale_cam = grayscale_cam [ 0 , :] image_normalized = original_image / 255. visualization = show_cam_on_image ( image_normalized , grayscale_cam , use_rgb = True ) _fig , axes = plt . subplots ( figsize = ( 8 , 8 ), ncols = 2 ) axes [ 0 ] . imshow ( image_normalized ) axes [ 1 ] . imshow ( visualization ) plt . show () torch . cuda . empty_cache () dog_and_cat_path = \"./images/animals/dog_and_cat.jpg\" image = cv2 . imread ( dog_and_cat_path ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) # needed for gradcam. original_image = cv2 . resize ( image , ( 224 , 224 )) model = vgg16 ( pretrained = True ) target_layers = [ model . features [ - 1 ]] input_tensor = images_dict [ \"cat_and_dog\" ] # Create an input tensor image for your model.. # Note: input_tensor can be a batch tensor with several images! # Construct the CAM object once, and then re-use it on many images: cam = GradCAM ( model = model , target_layers = target_layers , use_cuda = False ) # You can also use it within a with statement, to make sure it is freed, # In case you need to re-create it inside an outer loop: # with GradCAM(model=model, target_layers=target_layers, use_cuda=args.use_cuda) as cam: # ... # We have to specify the target we want to generate # the Class Activation Maps for. # If targets is None, the highest scoring category # will be used for every image in the batch. # Here we use ClassifierOutputTarget, but you can define your own custom targets # That are, for example, combinations of categories, or specific outputs in a non standard model. target_category = 260 # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing. grayscale_cam = cam ( input_tensor = input_tensor , target_category = target_category ) # In this example grayscale_cam has only one image in the batch: grayscale_cam = grayscale_cam [ 0 , :] image_normalized = original_image / 255. visualization = show_cam_on_image ( image_normalized , grayscale_cam , use_rgb = True ) _fig , axes = plt . subplots ( figsize = ( 8 , 8 ), ncols = 2 ) axes [ 0 ] . imshow ( image_normalized ) axes [ 1 ] . imshow ( visualization ) plt . show () torch . cuda . empty_cache ()","title":"Grad-CAM from Scratch"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#dependencies-and-config","text":"from typing import * import cv2 import matplotlib.pyplot as plt import numpy as np import torch import torch.nn as nn import torchsummary import torchvision from torch.utils import data from torchvision import datasets , transforms from torchvision.models import * import glob import os import random # Display from IPython.display import Image , display from pytorch_grad_cam import GradCAM from pytorch_grad_cam.utils.image import show_cam_on_image import PIL % cd .. import utils C:\\Users\\reighns\\reighns_ml\\reighns_ml_blog\\docs\\reighns_ml_journey\\deep_learning\\computer_vision\\general\\neural_network_interpretation device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) utils . seed_all () Using Seed Number 1992","title":"Dependencies and Config"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#load-images","text":"We load the images and plot the original image. We use the subplot function from the repo here. image_paths = glob . glob ( \"./images/animals/*.*\" ) # elephant has RGBA idk why so need convert images = list ( map ( lambda x : PIL . Image . open ( x ) . convert ( \"RGB\" ), image_paths )) plt . rcParams [ \"figure.figsize\" ] = 16 , 8 utils . subplot ( images , title = \"inputs\" , rows_titles = [ \"cat\" , \"dog_and_cat\" , \"african_elephant\" ], nrows = 1 , ncols = 3 , )","title":"Load Images"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#transforms-params-imagenet","text":"imagenet_mean : List [ float ] = [ 0.485 , 0.456 , 0.406 ] imagenet_std : List [ float ] = [ 0.229 , 0.224 , 0.225 ] image_size : int = 224 normalized_transform = torchvision . transforms . Compose ( [ torchvision . transforms . Resize (( image_size , image_size )), torchvision . transforms . ToTensor (), torchvision . transforms . Normalize ( mean = imagenet_mean , std = imagenet_std ), ] ) inverse_normalized_transform = torchvision . transforms . Compose ( [ utils . NormalizeInverse ( mean = imagenet_mean , std = imagenet_std )] ) # We use torchvision's transform to transform the cat image with resize and normalization. # Note the tensors below should all be channels first! cat_tensor = normalized_transform ( images [ 0 ]) cat_and_dog_tensor = normalized_transform ( images [ 1 ]) elephant_tensor = normalized_transform ( images [ 2 ]) # Now feature_extractor expects batch_size x C x H x W, so we expand one dimension in the 0th dim and put them on device cat_tensor = cat_tensor . unsqueeze ( dim = 0 ) . to ( device ) cat_and_dog_tensor = cat_and_dog_tensor . unsqueeze ( dim = 0 ) . to ( device ) elephant_tensor = elephant_tensor . unsqueeze ( dim = 0 ) . to ( device ) # Construct an images_dict to store these tensors images_dict : Dict [ str , torch . Tensor ] = { \"cat\" : cat_tensor , \"cat_and_dog\" : cat_and_dog_tensor , \"elephant\" : elephant_tensor }","title":"Transforms Params (ImageNet)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#working-with-torch-models","text":"","title":"Working with Torch Models"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#load-the-models","text":"alexnet_ = alexnet ( pretrained = True ) . to ( device ) vgg16_ = vgg16 ( pretrained = True ) . to ( device ) resnet34_ = resnet34 ( pretrained = True ) . to ( device )","title":"Load the Models"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#torch-summary","text":"We use a library to output the layer information like Keras's model.summary() . We need to identify the last convolutional layer. import torchsummary def torchsummary_wrapper ( model , image_size : Tuple [ int , int , int ] ) -> torchsummary . model_statistics . ModelStatistics : \"\"\"A torch wrapper to print out layers of a Model. Args: model (CustomNeuralNet): Model. image_size (Tuple[int, int, int]): Image size as a tuple of (channels, height, width). Returns: model_summary (torchsummary.model_statistics.ModelStatistics): Model summary. \"\"\" model_summary = torchsummary . summary ( model , image_size ) return model_summary alexnet_model_summary = torchsummary_wrapper ( alexnet_ , image_size = ( 3 , 224 , 224 )) ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== \u251c\u2500Sequential: 1-1 [-1, 256, 6, 6] -- | \u2514\u2500Conv2d: 2-1 [-1, 64, 55, 55] 23,296 | \u2514\u2500ReLU: 2-2 [-1, 64, 55, 55] -- | \u2514\u2500MaxPool2d: 2-3 [-1, 64, 27, 27] -- | \u2514\u2500Conv2d: 2-4 [-1, 192, 27, 27] 307,392 | \u2514\u2500ReLU: 2-5 [-1, 192, 27, 27] -- | \u2514\u2500MaxPool2d: 2-6 [-1, 192, 13, 13] -- | \u2514\u2500Conv2d: 2-7 [-1, 384, 13, 13] 663,936 | \u2514\u2500ReLU: 2-8 [-1, 384, 13, 13] -- | \u2514\u2500Conv2d: 2-9 [-1, 256, 13, 13] 884,992 | \u2514\u2500ReLU: 2-10 [-1, 256, 13, 13] -- | \u2514\u2500Conv2d: 2-11 [-1, 256, 13, 13] 590,080 | \u2514\u2500ReLU: 2-12 [-1, 256, 13, 13] -- | \u2514\u2500MaxPool2d: 2-13 [-1, 256, 6, 6] -- \u251c\u2500AdaptiveAvgPool2d: 1-2 [-1, 256, 6, 6] -- \u251c\u2500Sequential: 1-3 [-1, 1000] -- | \u2514\u2500Dropout: 2-14 [-1, 9216] -- | \u2514\u2500Linear: 2-15 [-1, 4096] 37,752,832 | \u2514\u2500ReLU: 2-16 [-1, 4096] -- | \u2514\u2500Dropout: 2-17 [-1, 4096] -- | \u2514\u2500Linear: 2-18 [-1, 4096] 16,781,312 | \u2514\u2500ReLU: 2-19 [-1, 4096] -- | \u2514\u2500Linear: 2-20 [-1, 1000] 4,097,000 ========================================================================================== Total params: 61,100,840 Trainable params: 61,100,840 Non-trainable params: 0 Total mult-adds (M): 775.28 ========================================================================================== Input size (MB): 0.57 Forward/backward pass size (MB): 3.77 Params size (MB): 233.08 Estimated Total Size (MB): 237.43 ========================================================================================== vgg16_model_summary = torchsummary_wrapper ( vgg16_ , image_size = ( 3 , 224 , 224 )) ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== \u251c\u2500Sequential: 1-1 [-1, 512, 7, 7] -- | \u2514\u2500Conv2d: 2-1 [-1, 64, 224, 224] 1,792 | \u2514\u2500ReLU: 2-2 [-1, 64, 224, 224] -- | \u2514\u2500Conv2d: 2-3 [-1, 64, 224, 224] 36,928 | \u2514\u2500ReLU: 2-4 [-1, 64, 224, 224] -- | \u2514\u2500MaxPool2d: 2-5 [-1, 64, 112, 112] -- | \u2514\u2500Conv2d: 2-6 [-1, 128, 112, 112] 73,856 | \u2514\u2500ReLU: 2-7 [-1, 128, 112, 112] -- | \u2514\u2500Conv2d: 2-8 [-1, 128, 112, 112] 147,584 | \u2514\u2500ReLU: 2-9 [-1, 128, 112, 112] -- | \u2514\u2500MaxPool2d: 2-10 [-1, 128, 56, 56] -- | \u2514\u2500Conv2d: 2-11 [-1, 256, 56, 56] 295,168 | \u2514\u2500ReLU: 2-12 [-1, 256, 56, 56] -- | \u2514\u2500Conv2d: 2-13 [-1, 256, 56, 56] 590,080 | \u2514\u2500ReLU: 2-14 [-1, 256, 56, 56] -- | \u2514\u2500Conv2d: 2-15 [-1, 256, 56, 56] 590,080 | \u2514\u2500ReLU: 2-16 [-1, 256, 56, 56] -- | \u2514\u2500MaxPool2d: 2-17 [-1, 256, 28, 28] -- | \u2514\u2500Conv2d: 2-18 [-1, 512, 28, 28] 1,180,160 | \u2514\u2500ReLU: 2-19 [-1, 512, 28, 28] -- | \u2514\u2500Conv2d: 2-20 [-1, 512, 28, 28] 2,359,808 | \u2514\u2500ReLU: 2-21 [-1, 512, 28, 28] -- | \u2514\u2500Conv2d: 2-22 [-1, 512, 28, 28] 2,359,808 | \u2514\u2500ReLU: 2-23 [-1, 512, 28, 28] -- | \u2514\u2500MaxPool2d: 2-24 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-25 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-26 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-27 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-28 [-1, 512, 14, 14] -- | \u2514\u2500Conv2d: 2-29 [-1, 512, 14, 14] 2,359,808 | \u2514\u2500ReLU: 2-30 [-1, 512, 14, 14] -- | \u2514\u2500MaxPool2d: 2-31 [-1, 512, 7, 7] -- \u251c\u2500AdaptiveAvgPool2d: 1-2 [-1, 512, 7, 7] -- \u251c\u2500Sequential: 1-3 [-1, 1000] -- | \u2514\u2500Linear: 2-32 [-1, 4096] 102,764,544 | \u2514\u2500ReLU: 2-33 [-1, 4096] -- | \u2514\u2500Dropout: 2-34 [-1, 4096] -- | \u2514\u2500Linear: 2-35 [-1, 4096] 16,781,312 | \u2514\u2500ReLU: 2-36 [-1, 4096] -- | \u2514\u2500Dropout: 2-37 [-1, 4096] -- | \u2514\u2500Linear: 2-38 [-1, 1000] 4,097,000 ========================================================================================== Total params: 138,357,544 Trainable params: 138,357,544 Non-trainable params: 0 Total mult-adds (G): 15.61 ========================================================================================== Input size (MB): 0.57 Forward/backward pass size (MB): 103.43 Params size (MB): 527.79 Estimated Total Size (MB): 631.80 ========================================================================================== resnet34_model_summary = torchsummary_wrapper ( resnet34_ , image_size = ( 3 , 224 , 224 )) ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== \u251c\u2500Conv2d: 1-1 [-1, 64, 112, 112] 9,408 \u251c\u2500BatchNorm2d: 1-2 [-1, 64, 112, 112] 128 \u251c\u2500ReLU: 1-3 [-1, 64, 112, 112] -- \u251c\u2500MaxPool2d: 1-4 [-1, 64, 56, 56] -- \u251c\u2500Sequential: 1-5 [-1, 64, 56, 56] -- | \u2514\u2500BasicBlock: 2-1 [-1, 64, 56, 56] -- | | \u2514\u2500Conv2d: 3-1 [-1, 64, 56, 56] 36,864 | | \u2514\u2500BatchNorm2d: 3-2 [-1, 64, 56, 56] 128 | | \u2514\u2500ReLU: 3-3 [-1, 64, 56, 56] -- | | \u2514\u2500Conv2d: 3-4 [-1, 64, 56, 56] 36,864 | | \u2514\u2500BatchNorm2d: 3-5 [-1, 64, 56, 56] 128 | | \u2514\u2500ReLU: 3-6 [-1, 64, 56, 56] -- | \u2514\u2500BasicBlock: 2-2 [-1, 64, 56, 56] -- | | \u2514\u2500Conv2d: 3-7 [-1, 64, 56, 56] 36,864 | | \u2514\u2500BatchNorm2d: 3-8 [-1, 64, 56, 56] 128 | | \u2514\u2500ReLU: 3-9 [-1, 64, 56, 56] -- | | \u2514\u2500Conv2d: 3-10 [-1, 64, 56, 56] 36,864 | | \u2514\u2500BatchNorm2d: 3-11 [-1, 64, 56, 56] 128 | | \u2514\u2500ReLU: 3-12 [-1, 64, 56, 56] -- | \u2514\u2500BasicBlock: 2-3 [-1, 64, 56, 56] -- | | \u2514\u2500Conv2d: 3-13 [-1, 64, 56, 56] 36,864 | | \u2514\u2500BatchNorm2d: 3-14 [-1, 64, 56, 56] 128 | | \u2514\u2500ReLU: 3-15 [-1, 64, 56, 56] -- | | \u2514\u2500Conv2d: 3-16 [-1, 64, 56, 56] 36,864 | | \u2514\u2500BatchNorm2d: 3-17 [-1, 64, 56, 56] 128 | | \u2514\u2500ReLU: 3-18 [-1, 64, 56, 56] -- \u251c\u2500Sequential: 1-6 [-1, 128, 28, 28] -- | \u2514\u2500BasicBlock: 2-4 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-19 [-1, 128, 28, 28] 73,728 | | \u2514\u2500BatchNorm2d: 3-20 [-1, 128, 28, 28] 256 | | \u2514\u2500ReLU: 3-21 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-22 [-1, 128, 28, 28] 147,456 | | \u2514\u2500BatchNorm2d: 3-23 [-1, 128, 28, 28] 256 | | \u2514\u2500Sequential: 3-24 [-1, 128, 28, 28] 8,448 | | \u2514\u2500ReLU: 3-25 [-1, 128, 28, 28] -- | \u2514\u2500BasicBlock: 2-5 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-26 [-1, 128, 28, 28] 147,456 | | \u2514\u2500BatchNorm2d: 3-27 [-1, 128, 28, 28] 256 | | \u2514\u2500ReLU: 3-28 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-29 [-1, 128, 28, 28] 147,456 | | \u2514\u2500BatchNorm2d: 3-30 [-1, 128, 28, 28] 256 | | \u2514\u2500ReLU: 3-31 [-1, 128, 28, 28] -- | \u2514\u2500BasicBlock: 2-6 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-32 [-1, 128, 28, 28] 147,456 | | \u2514\u2500BatchNorm2d: 3-33 [-1, 128, 28, 28] 256 | | \u2514\u2500ReLU: 3-34 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-35 [-1, 128, 28, 28] 147,456 | | \u2514\u2500BatchNorm2d: 3-36 [-1, 128, 28, 28] 256 | | \u2514\u2500ReLU: 3-37 [-1, 128, 28, 28] -- | \u2514\u2500BasicBlock: 2-7 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-38 [-1, 128, 28, 28] 147,456 | | \u2514\u2500BatchNorm2d: 3-39 [-1, 128, 28, 28] 256 | | \u2514\u2500ReLU: 3-40 [-1, 128, 28, 28] -- | | \u2514\u2500Conv2d: 3-41 [-1, 128, 28, 28] 147,456 | | \u2514\u2500BatchNorm2d: 3-42 [-1, 128, 28, 28] 256 | | \u2514\u2500ReLU: 3-43 [-1, 128, 28, 28] -- \u251c\u2500Sequential: 1-7 [-1, 256, 14, 14] -- | \u2514\u2500BasicBlock: 2-8 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-44 [-1, 256, 14, 14] 294,912 | | \u2514\u2500BatchNorm2d: 3-45 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-46 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-47 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-48 [-1, 256, 14, 14] 512 | | \u2514\u2500Sequential: 3-49 [-1, 256, 14, 14] 33,280 | | \u2514\u2500ReLU: 3-50 [-1, 256, 14, 14] -- | \u2514\u2500BasicBlock: 2-9 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-51 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-52 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-53 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-54 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-55 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-56 [-1, 256, 14, 14] -- | \u2514\u2500BasicBlock: 2-10 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-57 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-58 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-59 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-60 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-61 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-62 [-1, 256, 14, 14] -- | \u2514\u2500BasicBlock: 2-11 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-63 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-64 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-65 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-66 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-67 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-68 [-1, 256, 14, 14] -- | \u2514\u2500BasicBlock: 2-12 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-69 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-70 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-71 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-72 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-73 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-74 [-1, 256, 14, 14] -- | \u2514\u2500BasicBlock: 2-13 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-75 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-76 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-77 [-1, 256, 14, 14] -- | | \u2514\u2500Conv2d: 3-78 [-1, 256, 14, 14] 589,824 | | \u2514\u2500BatchNorm2d: 3-79 [-1, 256, 14, 14] 512 | | \u2514\u2500ReLU: 3-80 [-1, 256, 14, 14] -- \u251c\u2500Sequential: 1-8 [-1, 512, 7, 7] -- | \u2514\u2500BasicBlock: 2-14 [-1, 512, 7, 7] -- | | \u2514\u2500Conv2d: 3-81 [-1, 512, 7, 7] 1,179,648 | | \u2514\u2500BatchNorm2d: 3-82 [-1, 512, 7, 7] 1,024 | | \u2514\u2500ReLU: 3-83 [-1, 512, 7, 7] -- | | \u2514\u2500Conv2d: 3-84 [-1, 512, 7, 7] 2,359,296 | | \u2514\u2500BatchNorm2d: 3-85 [-1, 512, 7, 7] 1,024 | | \u2514\u2500Sequential: 3-86 [-1, 512, 7, 7] 132,096 | | \u2514\u2500ReLU: 3-87 [-1, 512, 7, 7] -- | \u2514\u2500BasicBlock: 2-15 [-1, 512, 7, 7] -- | | \u2514\u2500Conv2d: 3-88 [-1, 512, 7, 7] 2,359,296 | | \u2514\u2500BatchNorm2d: 3-89 [-1, 512, 7, 7] 1,024 | | \u2514\u2500ReLU: 3-90 [-1, 512, 7, 7] -- | | \u2514\u2500Conv2d: 3-91 [-1, 512, 7, 7] 2,359,296 | | \u2514\u2500BatchNorm2d: 3-92 [-1, 512, 7, 7] 1,024 | | \u2514\u2500ReLU: 3-93 [-1, 512, 7, 7] -- | \u2514\u2500BasicBlock: 2-16 [-1, 512, 7, 7] -- | | \u2514\u2500Conv2d: 3-94 [-1, 512, 7, 7] 2,359,296 | | \u2514\u2500BatchNorm2d: 3-95 [-1, 512, 7, 7] 1,024 | | \u2514\u2500ReLU: 3-96 [-1, 512, 7, 7] -- | | \u2514\u2500Conv2d: 3-97 [-1, 512, 7, 7] 2,359,296 | | \u2514\u2500BatchNorm2d: 3-98 [-1, 512, 7, 7] 1,024 | | \u2514\u2500ReLU: 3-99 [-1, 512, 7, 7] -- \u251c\u2500AdaptiveAvgPool2d: 1-9 [-1, 512, 1, 1] -- \u251c\u2500Linear: 1-10 [-1, 1000] 513,000 ========================================================================================== Total params: 21,797,672 Trainable params: 21,797,672 Non-trainable params: 0 Total mult-adds (G): 3.71 ========================================================================================== Input size (MB): 0.57 Forward/backward pass size (MB): 57.05 Params size (MB): 83.15 Estimated Total Size (MB): 140.77 ==========================================================================================","title":"Torch Summary"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#forward-backward-hooks","text":"def forward_hook ( module_name : str , forward_activations : Dict [ str , torch . Tensor ] ) -> Callable : \"\"\"In-place forward hook to save activations of a layer. Args: module_name (str): The name of the layer to hook. forward_activations (Dict[str, torch.Tensor]): The dictionary to save the activations. Returns: forward_hook_: The forward hook function. \"\"\" def forward_hook_ ( module , input , output ): # Save forward feature map activations forward_activations [ module_name ] = output . detach () return forward_hook_ def backward_hook ( module_name : str , backward_gradients : Dict [ str , torch . Tensor ] ) -> Callable : \"\"\"In-place backward hook to save gradients of a layer. Args: module_name (str): The name of the layer to hook. backward_gradients (Dict[str, torch.Tensor]): The dictionary to save the gradients. Returns: Callable: The backward hook function. \"\"\" def backward_hook_ ( module , grad_input , grad_output ): # Save the gradients correspond to the feature maps # This will only be saved when backwards is called. backward_gradients [ module_name ] = grad_output [ 0 ] . detach () return backward_hook_","title":"Forward Backward Hooks"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#saving-forward-activations-and-backward-gradients","text":"We define a function to get feature map activations and the model's backwards gradients. def get_forward_activations_and_backward_gradients ( model : Callable , image : torch . Tensor , target_category : Optional [ int ] = None , ) -> Union [ List [ Callable ], Dict [ str , torch . Tensor ]]: \"\"\"Get feature maps and gradients from a model. Args: model (Callable): A model. image (torch.Tensor): The input image. target_category (Optional[int], optional): The target category for the model to focus on. Defaults to None. Returns: handlers List[Callable]: A list of handlers. forward_activations Dict[str, torch.Tensor]: A dictionary of forward activations. \"\"\" forward_activations = OrderedDict () backward_gradients = OrderedDict () handlers = [] for name , module in model . named_modules (): module_name = name + \"_\" + str ( module ) handlers . append ( module . register_forward_hook ( forward_hook ( module_name , forward_activations ) ) ) handlers . append ( module . register_backward_hook ( backward_hook ( module_name , backward_gradients ) ) ) model = model . eval () # the y_logits before softmax # forward pass to populate the forward_activations y_logits = model ( image ) if target_category is None : # get the most likely prediction of the model target_category = model ( image ) . argmax ( dim = 1 ) # convert to scalar target_category = target_category . item () # call backward on the model to populate backward_gradients y_logits [:, target_category ] . backward () return handlers , forward_activations , backward_gradients","title":"Saving Forward Activations and Backward Gradients"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#grad-cam","text":"","title":"Grad-CAM"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#storing-forward-activations-and-backward-gradients","text":"This part is the same as Saving Forward Activations and Backward Gradients. def get_forward_activations_and_backward_gradients ( model : Callable , image : torch . Tensor , target_category : Optional [ int ] = None , ) -> Union [ List [ Callable ], Dict [ str , torch . Tensor ]]: \"\"\"Get feature maps and gradients from a model. Args: model (Callable): A model. image (torch.Tensor): The input image. target_category (Optional[int], optional): The target category for the model to focus on. Defaults to None. Returns: handlers List[Callable]: A list of handlers. forward_activations Dict[str, torch.Tensor]: A dictionary of forward activations. \"\"\" forward_activations = OrderedDict () backward_gradients = OrderedDict () handlers = [] for name , module in model . named_modules (): module_name = name + \"_\" + str ( module ) handlers . append ( module . register_forward_hook ( forward_hook ( module_name , forward_activations ) ) ) handlers . append ( module . register_backward_hook ( backward_hook ( module_name , backward_gradients ) ) ) model = model . eval () # the y_logits before softmax # forward pass to populate the forward_activations y_logits = model ( image ) if target_category is None : # get the most likely prediction of the model target_category = model ( image ) . argmax ( dim = 1 ) # convert to scalar target_category = target_category . item () # call backward on the model to populate backward_gradients y_logits [:, target_category ] . backward () return handlers , forward_activations , backward_gradients","title":"Storing Forward Activations and Backward Gradients"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#grad-cam-heatmap-function","text":"def compute_gradcam_localization_heatmap ( target_layer_name : str , forward_activations : Dict [ str , torch . Tensor ], backward_gradients : Dict [ str , torch . Tensor ], ) -> torch . Tensor : \"\"\"Compute GradCAM for a specific target layer. Args: target_layer_name (str): The name of the target layer. Usually the last convolutional layer. forward_activations (Dict[str, torch.Tensor]): The forward activations of the model. A dictionary of activations. backward_gradients (Dict[str, torch.Tensor]): The backward gradients of the model. A dictionary of gradients. Returns: gradcam_heatmap (torch.Tensor): The heatmap of the GradCAM. \"\"\" # get the activations of the last convolutional layer forward_conv_activations = forward_activations [ target_layer_name ] dyc_dA = backward_gradients [ target_layer_name ] # average pool the gradients across the channels global_average_pooled_gradients = torch . mean ( dyc_dA , dim = [ 0 , 2 , 3 ]) num_feature_maps = forward_conv_activations . squeeze () . shape [ 0 ] weighted_localization_map = torch . clone ( forward_conv_activations ) # weight the channels by corresponding gradients for i in range ( num_feature_maps ): weighted_localization_map [ :, i , :, : ] *= global_average_pooled_gradients [ i ] # sum the channels of the activations weighted_localization_map = torch . sum ( weighted_localization_map , dim = 1 ) . squeeze () # relu on top of the heatmap expression (2) in https://arxiv.org/pdf/1610.02391.pdf relu_weighted_localization_map = torch . nn . ReLU ( inplace = False )( weighted_localization_map ) # normalize the heatmap, scale features to between 0 and 1 to plot gradcam_heatmap = relu_weighted_localization_map / torch . max ( relu_weighted_localization_map ) # draw the heatmap plt . rcParams [ \"figure.figsize\" ] = 16 , 8 plt . matshow ( gradcam_heatmap . squeeze ()) return gradcam_heatmap","title":"Grad-CAM Heatmap Function"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#superimpose-image","text":"Superimpose heatmap to original image. def display_gradcam ( image : torch . Tensor , gradcam_heatmap : torch . Tensor , alpha = 1.0 , ): \"\"\"Display the GradCAM heatmap. Args: image (torch.Tensor): _description_ gradcam_heatmap (torch.Tensor): _description_ alpha (float, optional): _description_. Defaults to 0.8. \"\"\" # step 1: Unnormalize the input image to be between 0 and 1, and multiply to become within 255 # squeeze dimensions when there is 1. because [1, 3, 224, 224] is [3, 224, 224] # shape = (3, 224, 224) original_image_unnormalized = inverse_normalized_transform ( image . squeeze () . cpu () ) original_image_unnormalized = original_image_unnormalized * 255 # step 2: make CxHxW to HxWxC and convert to numpy original_image_unnormalized = original_image_unnormalized . permute ( 1 , 2 , 0 ) . numpy () # step 3: Normalize the heatmap to between 0 and 1 and resize it to the image size we want, then multiply to within 255 # first make it into numpy gradcam_heatmap = gradcam_heatmap . detach () . cpu () . numpy () h , w , c = original_image_unnormalized . shape # normalize and resize gradcam_heatmap -= np . min ( gradcam_heatmap ) gradcam_heatmap /= np . max ( gradcam_heatmap ) # Normalize between 0-1 gradcam_heatmap = cv2 . resize ( gradcam_heatmap , ( w , h )) gradcam_heatmap = np . uint8 ( gradcam_heatmap * 255.0 ) # step 4: Apply color maps and overlay the heatmap on the original image to get superimposed image gradcam_heatmap = cv2 . applyColorMap ( gradcam_heatmap , cv2 . COLORMAP_JET ) gradcam_heatmap = cv2 . cvtColor ( gradcam_heatmap , cv2 . COLOR_BGR2RGB ) superimposed_image = gradcam_heatmap * alpha + original_image_unnormalized superimposed_image /= np . max ( superimposed_image ) # step 5: Display the image plt . rcParams [ \"figure.figsize\" ] = 16 , 8 plt . imshow ( superimposed_image ) return superimposed_image","title":"SuperImpose Image"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#alexnet-gradcam","text":"_ , f_alexnet , b_alexnet = get_forward_activations_and_backward_gradients ( alexnet_ , image = images_dict [ \"cat\" ], target_category = None ) C:\\Users\\reighns\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior. warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \" For this model, the last layer can be alexnet_.features.11 . In our case it is features.11_ReLU(inplace=True) . target_layer_name = \"features.11_ReLU(inplace=True)\" alexnet_gradcam_heatmap = compute_gradcam_localization_heatmap ( target_layer_name , f_alexnet , b_alexnet ) _ = display_gradcam ( image = images_dict [ \"cat\" ], gradcam_heatmap = alexnet_gradcam_heatmap , alpha = 1.0 )","title":"Alexnet Gradcam"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#vgg16-gradcam","text":"_ , f_vgg16 , b_vgg16 = get_forward_activations_and_backward_gradients ( vgg16_ , image = images_dict [ \"cat\" ], target_category = None ) For this model, the last layer can be alexnet_.features.12 . In our case it is features.12_MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) . target_layer_name = \"features.29_ReLU(inplace=True)\" vgg16_gradcam_heatmap = compute_gradcam_localization_heatmap ( target_layer_name , f_vgg16 , b_vgg16 ) _ = display_gradcam ( image = images_dict [ \"cat\" ], gradcam_heatmap = vgg16_gradcam_heatmap , alpha = 1.0 )","title":"VGG16 Gradcam"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#vgg16-grad-cam-with-target-category","text":"If we specifically pass into a target category, where 285 is cat and 260 is dog, we see the model sees different things! _ , f_vgg16 , b_vgg16 = get_forward_activations_and_backward_gradients ( vgg16_ , image = images_dict [ \"cat_and_dog\" ], target_category = 285 ) target_layer_name = \"features.29_ReLU(inplace=True)\" vgg16_gradcam_heatmap = compute_gradcam_localization_heatmap ( target_layer_name , f_vgg16 , b_vgg16 ) _ = display_gradcam ( image = images_dict [ \"cat_and_dog\" ], gradcam_heatmap = vgg16_gradcam_heatmap , alpha = 1.0 ) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). _ , f_vgg16 , b_vgg16 = get_forward_activations_and_backward_gradients ( vgg16_ , image = images_dict [ \"cat_and_dog\" ], target_category = 260 ) target_layer_name = \"features.29_ReLU(inplace=True)\" vgg16_gradcam_heatmap = compute_gradcam_localization_heatmap ( target_layer_name , f_vgg16 , b_vgg16 ) _ = display_gradcam ( image = images_dict [ \"cat_and_dog\" ], gradcam_heatmap = vgg16_gradcam_heatmap , alpha = 1.0 )","title":"VGG16 Grad-CAM with Target Category"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/#out-of-the-box-library","text":"from pytorch_grad_cam import GradCAM , ScoreCAM , GradCAMPlusPlus , AblationCAM , XGradCAM , EigenCAM , FullGrad # from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget from pytorch_grad_cam.utils.image import show_cam_on_image from torchvision.models import resnet50 , vgg19 , resnet34 dog_and_cat_path = \"./images/animals/dog_and_cat.jpg\" image = cv2 . imread ( dog_and_cat_path ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) # needed for gradcam. original_image = cv2 . resize ( image , ( 224 , 224 )) model = vgg16 ( pretrained = True ) target_layers = [ model . features [ - 1 ]] input_tensor = images_dict [ \"cat_and_dog\" ] # Create an input tensor image for your model.. # Note: input_tensor can be a batch tensor with several images! # Construct the CAM object once, and then re-use it on many images: cam = GradCAM ( model = model , target_layers = target_layers , use_cuda = False ) # You can also use it within a with statement, to make sure it is freed, # In case you need to re-create it inside an outer loop: # with GradCAM(model=model, target_layers=target_layers, use_cuda=args.use_cuda) as cam: # ... # We have to specify the target we want to generate # the Class Activation Maps for. # If targets is None, the highest scoring category # will be used for every image in the batch. # Here we use ClassifierOutputTarget, but you can define your own custom targets # That are, for example, combinations of categories, or specific outputs in a non standard model. target_category = 285 # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing. grayscale_cam = cam ( input_tensor = input_tensor , target_category = target_category ) # In this example grayscale_cam has only one image in the batch: grayscale_cam = grayscale_cam [ 0 , :] image_normalized = original_image / 255. visualization = show_cam_on_image ( image_normalized , grayscale_cam , use_rgb = True ) _fig , axes = plt . subplots ( figsize = ( 8 , 8 ), ncols = 2 ) axes [ 0 ] . imshow ( image_normalized ) axes [ 1 ] . imshow ( visualization ) plt . show () torch . cuda . empty_cache () dog_and_cat_path = \"./images/animals/dog_and_cat.jpg\" image = cv2 . imread ( dog_and_cat_path ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) # needed for gradcam. original_image = cv2 . resize ( image , ( 224 , 224 )) model = vgg16 ( pretrained = True ) target_layers = [ model . features [ - 1 ]] input_tensor = images_dict [ \"cat_and_dog\" ] # Create an input tensor image for your model.. # Note: input_tensor can be a batch tensor with several images! # Construct the CAM object once, and then re-use it on many images: cam = GradCAM ( model = model , target_layers = target_layers , use_cuda = False ) # You can also use it within a with statement, to make sure it is freed, # In case you need to re-create it inside an outer loop: # with GradCAM(model=model, target_layers=target_layers, use_cuda=args.use_cuda) as cam: # ... # We have to specify the target we want to generate # the Class Activation Maps for. # If targets is None, the highest scoring category # will be used for every image in the batch. # Here we use ClassifierOutputTarget, but you can define your own custom targets # That are, for example, combinations of categories, or specific outputs in a non standard model. target_category = 260 # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing. grayscale_cam = cam ( input_tensor = input_tensor , target_category = target_category ) # In this example grayscale_cam has only one image in the batch: grayscale_cam = grayscale_cam [ 0 , :] image_normalized = original_image / 255. visualization = show_cam_on_image ( image_normalized , grayscale_cam , use_rgb = True ) _fig , axes = plt . subplots ( figsize = ( 8 , 8 ), ncols = 2 ) axes [ 0 ] . imshow ( image_normalized ) axes [ 1 ] . imshow ( visualization ) plt . show () torch . cuda . empty_cache ()","title":"Out of the Box Library"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/FrancescoSaverioZuppichin_A-journey-into-Convolutional-Neural-Network-visualization/","text":"A journey into Convolutional Neural Network visualization Francesco Saverio Zuppichini There is one famous urban legend about computer vision. Around the 80s, the US military wanted to use neural networks to automatically detect camouflaged enemy tanks. They took a number of pictures of trees without tanks and then pictures with the same trees with tanks behind them. The results were impressive. So impressive that the army wanted to be sure the net had correctly generalized. They took new pictures of woods with and without tanks and they showed them again to the network. This time, the model performed terribly, it was not able to discriminate between pictures with tanks behind woods and just trees.It turned out that all the pictures without tanks were taken on a cloudy day while the ones with tanks on a sunny day! In reality, the network learn to recognize the weather, not the enemy tanks. Nosce te ipsum With this article, we are going to see different techniques to understand what it is going on inside a Convolutional Neural Network to avoid making the same US' army mistake. We are going to use Pytorch . All the code can be found here . Most of the visualizations were developed from scratch, however, some inspiration and parts were taken from here . We will first introduce each technique by briefly explain it and making some example and comparison between different classic computer vision models, alexnet , vgg16 and resnet . Then we will try to better understand a model used in robotics to predict the local distance sensor using only the frontal camera's images. Our goal is not to explain in detail how each technique works since this is already done extremely well by each paper, but to use them to help the reader visualize different model with different inputs to better understand and highlight what and how different models react to a given input. Later on, we show a workflow in which we utilize some of the techniques you will learn in this journey to test the robustness of a model, this is extremely useful to understand and fix its limitations. The curios reader could further improve is understand by looking and the source code for each visulisation and by reading the references. Preambula Disclaimer I am not a fan of jupyter. So apologize in advance if there are some warnings in the outputs and some figures are not well made Let's start our journey by selecting a network. Our first model will be the old school alexnet . It is already available in the torchvision.models package from Pytorch % load_ext autoreload % autoreload 2 from torchvision.models import * from visualisation.core.utils import device model = alexnet ( pretrained = True ) . to ( device ) print ( model ) AlexNet( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2)) (1): ReLU(inplace) (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)) (4): ReLU(inplace) (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (7): ReLU(inplace) (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (9): ReLU(inplace) (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace) (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) ) (classifier): Sequential( (0): Dropout(p=0.5) (1): Linear(in_features=9216, out_features=4096, bias=True) (2): ReLU(inplace) (3): Dropout(p=0.5) (4): Linear(in_features=4096, out_features=4096, bias=True) (5): ReLU(inplace) (6): Linear(in_features=4096, out_features=1000, bias=True) ) ) Now we need some inputs # %matplotlib notebook Now we need some inputs images. We are going to use three pictures, a cat, the beautiful Basilica di San Pietro and an image with a dog and a cat. import glob import matplotlib.pyplot as plt import numpy as np import torch from utils import * from PIL import Image plt . rcParams [ \"figure.figsize\" ] = 16 , 8 We loaded a few packages. In utils there are several utility function to creates the plots. import glob import matplotlib.pyplot as plt import numpy as np from visualisation.core.utils import device from PIL import Image image_paths = glob . glob ( './images/*.*' ) images = list ( map ( lambda x : Image . open ( x ), image_paths )) subplot ( images , title = 'inputs' , rows_titles = [ 'cat' , 'san pietro' , 'dog_cat' ], nrows = 1 , ncols = 3 ) Since all of our models were trained on imagenet , a huge dataset with 1000 different classes, we need to parse and normalize them. In Pytorch, we have to manually send the data to a device. In this case the device if the fist gpu if you have one, otherwise cpu is selected. Be aware that jupyter have not a garbage collected so we will need to manually free the gpu memory. from torchvision.transforms import ToTensor , Resize , Compose , ToPILImage from visualisation.core import * from visualisation.core.utils import image_net_preprocessing inputs = [ Compose ([ Resize (( 224 , 224 )), ToTensor (), image_net_preprocessing ])( x ) . unsqueeze ( 0 ) for x in images ] # add 1 dim for batch inputs = [ i . to ( device ) for i in inputs ] We also define an utility function to clean the gpu cache def free ( modules ): for m in modules : del m torch . cuda . empty_cache () As we said, imagenet is a huge dataset with 1000 classes, represented by an integer not very human interpetable. We can associate each class id to its label by loading the imaganet2human.txt and create a python dictionary. imagenet2human = {} with open ( 'imaganet2human.txt' ) as f : for line in f . readlines (): key , value = line . split ( ':' ) key = key . replace ( '{' , '' ) . replace ( '}' , '' ) # I forget how regex works :) value = value . replace ( \"'\" , '' ) . replace ( \",\" , '' ) imagenet2human [ int ( key . strip ())] = str ( value . strip ()) list ( imagenet2human . items ())[: 2 ] [(0, 'tench Tinca tinca'), (1, 'goldfish Carassius auratus')] Weights Visualization The first straightforward visualization is to just plot the weights of a target Layer. Obviously, the deeper we go the smaller each image becomes while the channels number increases. We are going to show each channel as a grey array image. Unfortunately, each Pytorch module can be nested and nested, so to make our code as general as possible we first need to trace each sub-module that the input traverse and then store each layer in order. We first need to trace our model to get a list of all the layers so we can select a target layer without following the nested structure of a model. In PyTorch models can be infinitely nested. In other words, we are flattering the model's layers, this is implemented in the module2traced function. model_traced = module2traced ( model , inputs [ 0 ]) model_traced [Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2)), ReLU(inplace), MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)), ReLU(inplace), MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False), Dropout(p=0.5), Linear(in_features=9216, out_features=4096, bias=True), ReLU(inplace), Dropout(p=0.5), Linear(in_features=4096, out_features=4096, bias=True), ReLU(inplace), Linear(in_features=4096, out_features=1000, bias=True)] Let's plot the first layer's weight. We also print the shape of the weight to give a correct idea to the reader of the dimensional reduction. vis = Weights ( model , device ) first_layer = model_traced [ 0 ] plt . rcParams [ \"figure.figsize\" ] = 16 , 16 run_vis_plot ( vis , inputs [ 0 ], first_layer , ncols = 4 , nrows = 4 ) torch.Size([1, 55, 55]) Let's stop for a minute to explain what those images represent. We traced the input through the computational graph in order to find out all the layers of our models, in this case, alexnet . Then we instantiate the Weights class implemented in visualisation.core and we call it by passing the current input, the cat image and a target layer . As outputs, we get all the current layer's weights as grey images. Then, we plot 16 of them. We can notice that they, in some way, makes sense; for example, some pixels are brighter in the edges of the images. Let's plot the first MaxPool layer to better see this effect, dimensional reduction and higher brightness pixels in some interesting areas. If you are wondering what the maxpolling operations is doing, check this awesome repo first_maxpool_layer = model_traced [ 2 ] run_vis_plot ( vis , inputs [ 0 ], first_maxpool_layer , ncols = 4 , nrows = 4 ) torch.Size([1, 27, 27]) Let's try with an other input, the San Pietro Basilica run_vis_plot ( vis , inputs [ 1 ], first_maxpool_layer , ncols = 4 , nrows = 4 ) torch.Size([1, 27, 27]) By looking at them, these images make somehow sense; they highlight the basilica layout but it is hard to understand what the model is actually doing. We got the idea that is computing something correctly but we could ask some questions, for example: is it looking at the cupola? Which are the most important features of the Basilica? Moreover, the deeper we go the harder it becomes to even recognize the input. deeper_layer = model_traced [ 6 ] run_vis_plot ( vis , inputs [ 1 ], deeper_layer , ncols = 4 , nrows = 4 ) torch.Size([1, 13, 13]) In this case, we have no idea of what is going on. It can be argued that weights visualization does not carry any useful information about the model, even if this is almost true, there is one nice reason of plotting the weights especially at the first layer. When a model is poorly trained or not trained at all, the first weights have lots of noise, since they are just randomly initialized, and they are a lot more similar to the inputs images than the trained ones. This feature can be useful to understand on the fly is a model is trained or not. However, except for this, weights visualization is not the way to go to understand what your black box is thinking. Below we plot the first layer's weight first for the untraind version of alexnet and the for the trained one. alexnet_not_pretrained = alexnet ( pretrained = False ) . to ( device ) run_vis_plot ( Weights ( alexnet_not_pretrained , device ), inputs [ 0 ], module2traced ( alexnet_not_pretrained , inputs [ 0 ])[ 0 ], ncols = 4 , nrows = 4 ) alexnet_pretrained = alexnet ( pretrained = True ) . to ( device ) run_vis_plot ( Weights ( alexnet_pretrained , device ), inputs [ 0 ], module2traced ( alexnet_pretrained , inputs [ 0 ])[ 0 ], ncols = 4 , nrows = 4 ) del alexnet_not_pretrained torch.Size([1, 55, 55]) torch.Size([1, 55, 55]) You can notice that in the first image is simpler to see the input image. Hoewer, this is not a general rule, but in some cases it can help. Similarities with other models We have seen alexnet 's weights, but are they similar across models? Below we plot the first 4 channel of each first layer's weight for alexnet , vgg and resnet modules_instances = [ alexnet , vgg16 , resnet34 ] modules = ( m ( pretrained = True ) . to ( device ) for m in modules_instances ) # make a generator, we don't want to store in memory all of them at once run_vis_plot_across_models ( modules , inputs [ 0 ], 0 , Weights , 'weights' , device , ncols = 4 ) free ( modules ) The resnet and vgg weights looks more similar to the input images than alexnet . But, again, what does it mean? Remember that at least resnet is initialized in a different way than the other two models. Saliency Visualisation One idea proposed by Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps is to back-prop the output of the network with respect to a target class until the input and plot the computed gradient. This will highligh the part of the image responsible for that class. Let's start with alexnet. Let's first print the prediction of the network (this could change if you re-run the cell) model . eval () pred = model ( inputs [ 0 ]) _ , id = torch . max ( pred , 1 ) print ( 'predicted class {} ' . format ( imagenet2human [ id . item ()])) predicted class tiger cat Each visualisation is implemented in its own class. You can find the code here . It will backproprop the output with respect to the one hot encoding representation of the number corresponding to class tiger cat from visualisation.core.utils import image_net_postprocessing model . eval () model = model . to ( device ) vis = SaliencyMap ( model , device ) out , info = vis ( inputs [ 0 ], first_layer ) subplot ([ image_net_postprocessing ( inputs [ 0 ] . squeeze () . cpu ()), out ], rows_titles = [ 'original' , 'saliency map' ], parse = tensor2img , nrows = 1 , ncols = 2 ) We can see that alexnet gets exited on the cat. We can even do better! We can set to 0 each negative relu gradient when backprop. This is techinique is called guided . out , info = vis ( inputs [ 0 ], first_layer , guide = True ) subplot ([ image_net_postprocessing ( inputs [ 0 ] . squeeze () . cpu ()), out ], rows_titles = [ 'original' , 'guided saliency map' ], parse = tensor2img , nrows = 1 , ncols = 2 ) Now we can clearly see that the network is looking at the eyes and the nose of the cat. We can try to compare different models modules = ( m ( pretrained = True ) . to ( device ) for m in modules_instances ) # make a generator, we don't want to store in memory all of them at once run_vis_plot_across_models ( modules , inputs [ 0 ], 0 , SaliencyMap , 'Saliency' , device , nrows = 1 , ncols = 3 , target_class = 231 , guide = True ) free ( modules ) Alextnet seems more interested to the eyes, while VGG looks at the ears and resnet is similar to alexnet . Now we can clearly understand which part of the inputs help the network gives that prediction. While guiding yields a better human interpretable image, the vanilla implementation can be used for localizing an object of interest. In other words, we can find object of interest for free by cropping out of the input image the region corresponding to the gradient. Let's plot each input image for each model. modules_instances = [ alexnet , vgg16 , resnet34 , resnet152 ] modules = ( m ( pretrained = True ) for m in modules_instances ) # make a generator, we don't want to store in memory all of them at once run_vis_plot_across_models ( modules , inputs [ 0 ], None , SaliencyMap , 'SaliencyMap' , device , nrows = 4 , ncols = 3 , inputs = inputs , idx2label = imagenet2human , annotations = [ 'alexnet' , 'vgg16' , 'resnet34' , 'resnet152' ], guide = True ) free ( modules ) The Basilica is very interesting, all four networks correctly classify it as a dome but only resnet152 is more interested in the sky than on the cupola. In the last column, we have an image with two classes, dog and cat . All the networks highlighted booths, like the eyes of the dog and the ears of the cat in vgg16 . What if we would like to discover only the region of the inputs that are related to a specific class? With this technique is impossible. Class Activation Mapping Class Activation Mapping is a techniques presented in Learning Deep Features for Discriminative Localization . The idea is to use the last convolutional layer output and the neurons in the linear layer of the model responsable for a target class, the map is generated by taking the dot product of those. However, to make this work the model has to have some constrains. First of all, the output from the convolution must first go trought an global average polling and it requires feature maps to directly precede softmax layers. To make it works with other architecture, such as alexnet and vgg we have to change some layers in the model and retrain it. This is a major drawback that will be solved with the next section. For now, we can use it for free with resnet! Since its architecture is perfect. The implementation can be found here . We can pass to the visualisation a target_class parameter to get the relative weights from the fc layer. Notice that by changing the target class, we can see different part of the image highlighted. The first image uses the prediction class, while the second an other type of cat and the last one bookcase , just to see what the model will do with a wrong class. from visualisation.core.utils import imshow # we are using resnet 34 since the model has only one fc layer before the softmax and it is preceded by av avg pool # as required from the paper module = resnet34 ( True ) . to ( device ) module . eval () vis = ClassActivationMapping ( module , device ) classes = [ None , 285 , 453 ] def vis_outs2images_classes ( outs ): images = [ x [ 0 ] for x in outs ] classes = [ imagenet2human [ int ( x [ 1 ][ 'prediction' ])] for x in outs ] return images , classes outs = [ vis ( inputs [ 0 ], None , postprocessing = image_net_postprocessing , target_class = c , guide = True ) for c in classes ] images , classes = vis_outs2images_classes ( outs ) subplot ( images , rows_titles = classes , nrows = 1 , ncols = 3 , parse = tensor2img ) It makes sense, the only thing is that in the last row we still have some part of the cat highlighted for bookcase Let's plot the CAM on the cat images for different resnet architecture. For resnet > 34 the Bottleneck module is used modules_instances = [ resnet18 , resnet34 , resnet101 , resnet152 ] cat = inputs [ 2 ] modules = ( m ( pretrained = True ) . to ( device ) for m in modules_instances ) # make a generator, we don't want to store in memory all of them at once run_vis_plot_across_models ( modules , cat , None , ClassActivationMapping , 'ClassActivationMapping' , device , nrows = len ( modules_instances ), ncols = 1 , postprocessing = image_net_postprocessing , rows_name = [ 'resnet18' , 'resnet34' , 'resnet101' , 'resnet152' ], target_class = None ) free ( modules ) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). They are all very similar as expected. One big drawback of this technique is that force you to use a network with a specific architecture, global polling before the decoder part. The next technique generalize this approach by taking advantage of the gradient at one specific layer. Remember that with the class activation we are using the weights of the feature map as a scaling factor for the channels of the last layer. The features map must be before a softmax layer and right after the average pooling. The next technique propose a more general approach. Grad Cam Grad Cam was introduced by Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization . The idea is actually simple, we backprop the output with respect to a target class while storing the gradient and the output at a given layer, in our case the last convolution. Then we perform a global average of the saved gradient keeping the channel dimension in order to get a 1-d tensor, this will represent the importance of each channel in the target convolutional layer. We then multiply each element of the convolutional layer outputs by the averaged gradients to create the grad cam. This whole procedure is fast and it is architecture independent. Interesting, the authors show that is a generalization of the previous technique. The code is here We can use it to higlight what different models are looking at. modules_instances = [ alexnet , vgg16 , resnet34 , resnet152 ] modules = ( m ( pretrained = True ) . to ( device ) for m in modules_instances ) # make a generator, we don't want to store in memory all of them at once run_vis_plot_across_models ( modules , inputs [ 0 ], None , GradCam , 'Gradcam' , device , nrows = 1 , ncols = 4 , target_class = None , postprocessing = image_net_postprocessing ) free ( modules ) It is really interesting to see how alexnet looks at the nose, while vgg at the ears and resnet at the whole cat. It is interesting to see that the two resnet version looks at different part of the cat. Below we plot the same input for resnet34 but we change the target class in each column to show the reader how the grad cam change accordingly. from visualisation.core.utils import imshow module = module . to ( device ) vis = GradCam ( module , device ) classes = [ None , 285 , 453 ] outs = [ vis ( inputs [ 0 ], None , postprocessing = image_net_postprocessing , target_class = c ) for c in classes ] images , classes = vis_outs2images_classes ( outs ) subplot ( images , title = 'resnet34' , rows_titles = classes , nrows = 1 , ncols = len ( outs ), parse = tensor2img ) Notice how similar to the CAM output they are. To better compore our three models, below we plot the grad cam for each input with respect to each model modules = ( m ( pretrained = True ) . to ( device ) for m in modules_instances ) # make a generator, we don't want to store in memory all of them at once run_vis_plot_across_models ( modules , inputs [ 0 ], None , GradCam , 'Gradcam' , device , nrows = 4 , ncols = 3 , target_class = None , inputs = inputs , idx2label = imagenet2human , annotations = [ 'alexnet' , 'vgg16' , 'resnet34' , 'resnet152' ], postprocessing = image_net_postprocessing ) free ( modules ) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). The reader can immediately notice the difference across the models. Interesting region We talk before about interesting region localizations. Grad-cam can be also used to extract the class object out of the image. Easily, once the have the grad-cam image we can used it as mask to crop out form the input image what we want. The reader can play with the TR parameter to see different effects. TR = 0.3 alexnet_pretrained . eval () vis = GradCam ( alexnet_pretrained , device ) _ = vis ( inputs [ 0 ], None , postprocessing = image_net_postprocessing ) import cv2 def gradcam2crop ( cam , original_img ): b , c , w , h = inputs [ 0 ] . shape cam = cam . numpy () cam -= np . min ( cam ) cam /= np . max ( cam ) cam = cv2 . resize ( cam , ( w , h )) mask = cam > TR original_img = tensor2img ( image_net_postprocessing ( original_img [ 0 ] . squeeze ())) crop = original_img . copy () crop [ mask == 0 ] = 0 return crop crop = gradcam2crop ( vis . cam . cpu (), inputs [ 0 ] . cpu ()) fig = plt . figure () plt . imshow ( crop ) <matplotlib.image.AxesImage at 0x7f79debee048> et voil\u00e0 ! We can also change again class, and crop the interest region for that class. _ = vis ( inputs [ 0 ], None , target_class = 231 , postprocessing = image_net_postprocessing ) crop = gradcam2crop ( vis . cam . cpu (), inputs [ 0 ] . cpu ()) fig = plt . figure () plt . imshow ( crop ) <matplotlib.image.AxesImage at 0x7f79f40c4c18> Different models We have seen all these techniques used with classic classicification models trained on imagenet . What about use them on a different domain? I have ported this paper to Pytorch and retrain it. The model learn from the frontal camera's image of a robot to predict the local distance sensors in order to avoid obstacles. Let's see what if, by using those techniques, we can understand better what is going on inside the model. Learning Long-range Perception using Self-Supervision from Short-Range Sensors and Odometry The idea is to predict the future outputs of a short-range sensor (such as a proximity sensor) given the current outputs of a long-range sensor (such as a camera). They trained a very simple CNN from the robot's camera images to predict the proximity sensor values. If you are interested in their work, you can read the full paper here I have made a PyTorch implementation and retrain the model from scratch. Be awere that I did not fine-tune or try different sets of hyper-parameters so probably my model is not performing as well as the author's one. Let's import it from os import path LONG_RANGE_PERCEPTION_PATH = path . abspath ( './models/long_range_perception/model.pt' ) from models.long_range_perception.model import SimpleCNN from models.long_range_perception.utils import get_dl , H5_PATH , imshow , post_processing , pre_processing , MODEL_PATH free ([ module ]) module = torch . load ( LONG_RANGE_PERCEPTION_PATH , map_location = lambda storage , loc : storage ) module = module . to ( device ) module /home/francesco/Documents/A-journey-into-Convolutional-Neural-Network-visualization-/model.pt SimpleCNN( (encoder): Sequential( (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU() (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (3): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (4): ReLU() (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (6): Conv2d(10, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (7): ReLU() (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (decoder): Sequential( (0): Dropout(p=0.2) (1): Linear(in_features=640, out_features=256, bias=True) (2): ReLU() (3): Linear(in_features=256, out_features=325, bias=True) (4): Sigmoid() ) ) We know need some inputs to test the model, they are taken directly from the test set import os def make_and_show_inputs ( path , transform ): image_paths = glob . glob ( path ) image_paths = filter ( lambda x : os . path . isfile ( x ), image_paths ) images = list ( map ( lambda x : Image . open ( x ) . convert ( 'RGB' ), image_paths )) subplot ( images , title = 'inputs' , rows_titles = [ '1' , '2' , '3' , '4' ], nrows = 1 , ncols = 4 ) plt . show () inputs = [ pre_processing ( x ) . unsqueeze ( 0 ) . to ( device ) for x in images ] # add 1 dim for batch subplot ( inputs , parse = tensor2img , title = 'inputs' , rows_titles = [ '1' , '2' , '3' , '4' ], nrows = 1 , ncols = 4 ) return images , inputs images , inputs = make_and_show_inputs ( 'images/long_range_perception/*' , pre_processing ) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Then author normalize each image, this is done by callind pre_processing . For some reason the inpupts images are different on mac and ubuntu, they should not be like these if you run the notebook on mac the result is different. This is probably due to the warning message. We are going to use the SaliencyMap and the GradCam since those are the best from torch.autograd import Variable module . eval () def run_long_range_vis (): grad = GradCam ( module , device ) all_true = torch . ones ( 1 , 65 * 5 ) . float () . to ( device ) outs_grad = [ grad ( input , None , target_class = all_true , postprocessing = post_processing , regression = True )[ 0 ] for input in inputs ] sal = SaliencyMap ( module , device ) outs_saliency = [ sal ( input , None , guide = True , target_class = all_true , regression = True )[ 0 ] for input in inputs ] subplot ([ * outs_grad , * outs_saliency ], title = 'long_range' , cols_titles = [ '1' , '2' , '3' , '4' ], nrows = 2 , ncols = 4 , parse = tensor2img ) run_long_range_vis () We can clearly see that the model looks at the objects. In the GradCam row, on the second picture, the plan is basically segmented by the heatmap. There is one problem, if you look at the third picture, the white box in front of the camera is not clearly highlighted. This is probably due to the white color of the floor that is very similar to the box's color. Let's investigate this problem. In the second row, the SaliencyMaps highlights all the objects, including the white box. The reader can notice that the reflection in the first picture on the left seems to excite the network in that region. We should also investigate this case but due to time limitations, we will leave it as an exercise for the curious reader. For completeness, let's also print the predicted sensor output. The model tries to predict five frontal distance sensors give the image camera. import seaborn as sns module . eval () preds = module ( torch . stack ( inputs ) . squeeze ( 1 )) fig = plt . figure () sns . heatmap ( preds [ 2 ] . view ( - 1 , 5 ) . detach () . cpu () . numpy ()) <matplotlib.axes._subplots.AxesSubplot at 0x7f79d26dc240> If you compare with the authors pictures, my prediction are worse. This is due to the fact that to speed up everything I did not used all the training set and I did not perform any hyper paramater optimisation. All the code con be found here . Let's now investigate the first problem, object with a similar color to the ground. Similar colors To test if the model has a problem with obstacles with a the same color of the ground, we created in blender four different scenarios with an obstacle. They are showed in the picture below. image_paths = [ * sorted ( glob . glob ( 'images/long_range_perception/equal_color/*' )), * sorted ( glob . glob ( 'images/long_range_perception/different_color/*' ))] image_paths = filter ( lambda x : os . path . isfile ( x ), image_paths ) images = list ( map ( lambda x : Image . open ( x ) . convert ( 'RGB' ), image_paths )) subplot ( images , title = 'inputs' , nrows = 2 , ncols = 4 ) plt . show () There are four different lights configuration and two differents cube colors, one equal to the ground and the second different. The first column represents a realistic situation, while the second has a really strong light from behind that generates a shadow in front of the camera. The third column has a shadow on the left and the last one has a little shadow on the left. This is a perfect scenario to use gradcam to see what the model is looking in each image. In the picture below we plotted the gradcam results. inputs = [ pre_processing ( x ) . unsqueeze ( 0 ) . to ( device ) for x in images ] # add 1 dim for batch run_long_range_vis () The big black shadow in the second column definitly confuses the model. In the first and last column, the grad cam highlights better the corners of the red cube, especially in the first picture. We can definitely say that this model has some hard time with the object of the same colour as the ground. Thanks to this consideration, we could improve the number equal object/ground in the dataset, perform a better preprocessing, change the model structure etc and hopefully increase the robustness of the network. Conclusion In this article, we present different convolutional neural network visualization techniques. In the first section, we introduced each one by applying to a set of famous classification networks. We compared different networks on different inputs and highlight the similarities and difference between them. Then we apply them to a model adopted in robotics to test its robustness and we were able to successfully reveal a problem in the network. Moreover, as a side project, I developed an interactive convolutional neural network visualization application called mirro that receives in just a few days more than a hundred stars on GitHub reflecting the interest of the deep learning community on this topic. All these visualizations are implemented using a common interface and there are available as python module so they can be used in any other module. Thank for reading Francesco Saverio Zuppichini","title":"A journey into Convolutional Neural Network visualization"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/FrancescoSaverioZuppichin_A-journey-into-Convolutional-Neural-Network-visualization/#a-journey-into-convolutional-neural-network-visualization","text":"Francesco Saverio Zuppichini There is one famous urban legend about computer vision. Around the 80s, the US military wanted to use neural networks to automatically detect camouflaged enemy tanks. They took a number of pictures of trees without tanks and then pictures with the same trees with tanks behind them. The results were impressive. So impressive that the army wanted to be sure the net had correctly generalized. They took new pictures of woods with and without tanks and they showed them again to the network. This time, the model performed terribly, it was not able to discriminate between pictures with tanks behind woods and just trees.It turned out that all the pictures without tanks were taken on a cloudy day while the ones with tanks on a sunny day! In reality, the network learn to recognize the weather, not the enemy tanks.","title":"A journey into Convolutional Neural Network visualization"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/FrancescoSaverioZuppichin_A-journey-into-Convolutional-Neural-Network-visualization/#nosce-te-ipsum","text":"With this article, we are going to see different techniques to understand what it is going on inside a Convolutional Neural Network to avoid making the same US' army mistake. We are going to use Pytorch . All the code can be found here . Most of the visualizations were developed from scratch, however, some inspiration and parts were taken from here . We will first introduce each technique by briefly explain it and making some example and comparison between different classic computer vision models, alexnet , vgg16 and resnet . Then we will try to better understand a model used in robotics to predict the local distance sensor using only the frontal camera's images. Our goal is not to explain in detail how each technique works since this is already done extremely well by each paper, but to use them to help the reader visualize different model with different inputs to better understand and highlight what and how different models react to a given input. Later on, we show a workflow in which we utilize some of the techniques you will learn in this journey to test the robustness of a model, this is extremely useful to understand and fix its limitations. The curios reader could further improve is understand by looking and the source code for each visulisation and by reading the references.","title":"Nosce te ipsum"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/FrancescoSaverioZuppichin_A-journey-into-Convolutional-Neural-Network-visualization/#preambula","text":"Disclaimer I am not a fan of jupyter. So apologize in advance if there are some warnings in the outputs and some figures are not well made Let's start our journey by selecting a network. Our first model will be the old school alexnet . It is already available in the torchvision.models package from Pytorch % load_ext autoreload % autoreload 2 from torchvision.models import * from visualisation.core.utils import device model = alexnet ( pretrained = True ) . to ( device ) print ( model ) AlexNet( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2)) (1): ReLU(inplace) (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)) (4): ReLU(inplace) (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (7): ReLU(inplace) (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (9): ReLU(inplace) (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace) (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) ) (classifier): Sequential( (0): Dropout(p=0.5) (1): Linear(in_features=9216, out_features=4096, bias=True) (2): ReLU(inplace) (3): Dropout(p=0.5) (4): Linear(in_features=4096, out_features=4096, bias=True) (5): ReLU(inplace) (6): Linear(in_features=4096, out_features=1000, bias=True) ) ) Now we need some inputs # %matplotlib notebook Now we need some inputs images. We are going to use three pictures, a cat, the beautiful Basilica di San Pietro and an image with a dog and a cat. import glob import matplotlib.pyplot as plt import numpy as np import torch from utils import * from PIL import Image plt . rcParams [ \"figure.figsize\" ] = 16 , 8 We loaded a few packages. In utils there are several utility function to creates the plots. import glob import matplotlib.pyplot as plt import numpy as np from visualisation.core.utils import device from PIL import Image image_paths = glob . glob ( './images/*.*' ) images = list ( map ( lambda x : Image . open ( x ), image_paths )) subplot ( images , title = 'inputs' , rows_titles = [ 'cat' , 'san pietro' , 'dog_cat' ], nrows = 1 , ncols = 3 ) Since all of our models were trained on imagenet , a huge dataset with 1000 different classes, we need to parse and normalize them. In Pytorch, we have to manually send the data to a device. In this case the device if the fist gpu if you have one, otherwise cpu is selected. Be aware that jupyter have not a garbage collected so we will need to manually free the gpu memory. from torchvision.transforms import ToTensor , Resize , Compose , ToPILImage from visualisation.core import * from visualisation.core.utils import image_net_preprocessing inputs = [ Compose ([ Resize (( 224 , 224 )), ToTensor (), image_net_preprocessing ])( x ) . unsqueeze ( 0 ) for x in images ] # add 1 dim for batch inputs = [ i . to ( device ) for i in inputs ] We also define an utility function to clean the gpu cache def free ( modules ): for m in modules : del m torch . cuda . empty_cache () As we said, imagenet is a huge dataset with 1000 classes, represented by an integer not very human interpetable. We can associate each class id to its label by loading the imaganet2human.txt and create a python dictionary. imagenet2human = {} with open ( 'imaganet2human.txt' ) as f : for line in f . readlines (): key , value = line . split ( ':' ) key = key . replace ( '{' , '' ) . replace ( '}' , '' ) # I forget how regex works :) value = value . replace ( \"'\" , '' ) . replace ( \",\" , '' ) imagenet2human [ int ( key . strip ())] = str ( value . strip ()) list ( imagenet2human . items ())[: 2 ] [(0, 'tench Tinca tinca'), (1, 'goldfish Carassius auratus')]","title":"Preambula"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/FrancescoSaverioZuppichin_A-journey-into-Convolutional-Neural-Network-visualization/#weights-visualization","text":"The first straightforward visualization is to just plot the weights of a target Layer. Obviously, the deeper we go the smaller each image becomes while the channels number increases. We are going to show each channel as a grey array image. Unfortunately, each Pytorch module can be nested and nested, so to make our code as general as possible we first need to trace each sub-module that the input traverse and then store each layer in order. We first need to trace our model to get a list of all the layers so we can select a target layer without following the nested structure of a model. In PyTorch models can be infinitely nested. In other words, we are flattering the model's layers, this is implemented in the module2traced function. model_traced = module2traced ( model , inputs [ 0 ]) model_traced [Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2)), ReLU(inplace), MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)), ReLU(inplace), MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False), Dropout(p=0.5), Linear(in_features=9216, out_features=4096, bias=True), ReLU(inplace), Dropout(p=0.5), Linear(in_features=4096, out_features=4096, bias=True), ReLU(inplace), Linear(in_features=4096, out_features=1000, bias=True)] Let's plot the first layer's weight. We also print the shape of the weight to give a correct idea to the reader of the dimensional reduction. vis = Weights ( model , device ) first_layer = model_traced [ 0 ] plt . rcParams [ \"figure.figsize\" ] = 16 , 16 run_vis_plot ( vis , inputs [ 0 ], first_layer , ncols = 4 , nrows = 4 ) torch.Size([1, 55, 55]) Let's stop for a minute to explain what those images represent. We traced the input through the computational graph in order to find out all the layers of our models, in this case, alexnet . Then we instantiate the Weights class implemented in visualisation.core and we call it by passing the current input, the cat image and a target layer . As outputs, we get all the current layer's weights as grey images. Then, we plot 16 of them. We can notice that they, in some way, makes sense; for example, some pixels are brighter in the edges of the images. Let's plot the first MaxPool layer to better see this effect, dimensional reduction and higher brightness pixels in some interesting areas. If you are wondering what the maxpolling operations is doing, check this awesome repo first_maxpool_layer = model_traced [ 2 ] run_vis_plot ( vis , inputs [ 0 ], first_maxpool_layer , ncols = 4 , nrows = 4 ) torch.Size([1, 27, 27]) Let's try with an other input, the San Pietro Basilica run_vis_plot ( vis , inputs [ 1 ], first_maxpool_layer , ncols = 4 , nrows = 4 ) torch.Size([1, 27, 27]) By looking at them, these images make somehow sense; they highlight the basilica layout but it is hard to understand what the model is actually doing. We got the idea that is computing something correctly but we could ask some questions, for example: is it looking at the cupola? Which are the most important features of the Basilica? Moreover, the deeper we go the harder it becomes to even recognize the input. deeper_layer = model_traced [ 6 ] run_vis_plot ( vis , inputs [ 1 ], deeper_layer , ncols = 4 , nrows = 4 ) torch.Size([1, 13, 13]) In this case, we have no idea of what is going on. It can be argued that weights visualization does not carry any useful information about the model, even if this is almost true, there is one nice reason of plotting the weights especially at the first layer. When a model is poorly trained or not trained at all, the first weights have lots of noise, since they are just randomly initialized, and they are a lot more similar to the inputs images than the trained ones. This feature can be useful to understand on the fly is a model is trained or not. However, except for this, weights visualization is not the way to go to understand what your black box is thinking. Below we plot the first layer's weight first for the untraind version of alexnet and the for the trained one. alexnet_not_pretrained = alexnet ( pretrained = False ) . to ( device ) run_vis_plot ( Weights ( alexnet_not_pretrained , device ), inputs [ 0 ], module2traced ( alexnet_not_pretrained , inputs [ 0 ])[ 0 ], ncols = 4 , nrows = 4 ) alexnet_pretrained = alexnet ( pretrained = True ) . to ( device ) run_vis_plot ( Weights ( alexnet_pretrained , device ), inputs [ 0 ], module2traced ( alexnet_pretrained , inputs [ 0 ])[ 0 ], ncols = 4 , nrows = 4 ) del alexnet_not_pretrained torch.Size([1, 55, 55]) torch.Size([1, 55, 55]) You can notice that in the first image is simpler to see the input image. Hoewer, this is not a general rule, but in some cases it can help.","title":"Weights Visualization"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/FrancescoSaverioZuppichin_A-journey-into-Convolutional-Neural-Network-visualization/#similarities-with-other-models","text":"We have seen alexnet 's weights, but are they similar across models? Below we plot the first 4 channel of each first layer's weight for alexnet , vgg and resnet modules_instances = [ alexnet , vgg16 , resnet34 ] modules = ( m ( pretrained = True ) . to ( device ) for m in modules_instances ) # make a generator, we don't want to store in memory all of them at once run_vis_plot_across_models ( modules , inputs [ 0 ], 0 , Weights , 'weights' , device , ncols = 4 ) free ( modules ) The resnet and vgg weights looks more similar to the input images than alexnet . But, again, what does it mean? Remember that at least resnet is initialized in a different way than the other two models.","title":"Similarities with other models"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/FrancescoSaverioZuppichin_A-journey-into-Convolutional-Neural-Network-visualization/#saliency-visualisation","text":"One idea proposed by Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps is to back-prop the output of the network with respect to a target class until the input and plot the computed gradient. This will highligh the part of the image responsible for that class. Let's start with alexnet. Let's first print the prediction of the network (this could change if you re-run the cell) model . eval () pred = model ( inputs [ 0 ]) _ , id = torch . max ( pred , 1 ) print ( 'predicted class {} ' . format ( imagenet2human [ id . item ()])) predicted class tiger cat Each visualisation is implemented in its own class. You can find the code here . It will backproprop the output with respect to the one hot encoding representation of the number corresponding to class tiger cat from visualisation.core.utils import image_net_postprocessing model . eval () model = model . to ( device ) vis = SaliencyMap ( model , device ) out , info = vis ( inputs [ 0 ], first_layer ) subplot ([ image_net_postprocessing ( inputs [ 0 ] . squeeze () . cpu ()), out ], rows_titles = [ 'original' , 'saliency map' ], parse = tensor2img , nrows = 1 , ncols = 2 ) We can see that alexnet gets exited on the cat. We can even do better! We can set to 0 each negative relu gradient when backprop. This is techinique is called guided . out , info = vis ( inputs [ 0 ], first_layer , guide = True ) subplot ([ image_net_postprocessing ( inputs [ 0 ] . squeeze () . cpu ()), out ], rows_titles = [ 'original' , 'guided saliency map' ], parse = tensor2img , nrows = 1 , ncols = 2 ) Now we can clearly see that the network is looking at the eyes and the nose of the cat. We can try to compare different models modules = ( m ( pretrained = True ) . to ( device ) for m in modules_instances ) # make a generator, we don't want to store in memory all of them at once run_vis_plot_across_models ( modules , inputs [ 0 ], 0 , SaliencyMap , 'Saliency' , device , nrows = 1 , ncols = 3 , target_class = 231 , guide = True ) free ( modules ) Alextnet seems more interested to the eyes, while VGG looks at the ears and resnet is similar to alexnet . Now we can clearly understand which part of the inputs help the network gives that prediction. While guiding yields a better human interpretable image, the vanilla implementation can be used for localizing an object of interest. In other words, we can find object of interest for free by cropping out of the input image the region corresponding to the gradient. Let's plot each input image for each model. modules_instances = [ alexnet , vgg16 , resnet34 , resnet152 ] modules = ( m ( pretrained = True ) for m in modules_instances ) # make a generator, we don't want to store in memory all of them at once run_vis_plot_across_models ( modules , inputs [ 0 ], None , SaliencyMap , 'SaliencyMap' , device , nrows = 4 , ncols = 3 , inputs = inputs , idx2label = imagenet2human , annotations = [ 'alexnet' , 'vgg16' , 'resnet34' , 'resnet152' ], guide = True ) free ( modules ) The Basilica is very interesting, all four networks correctly classify it as a dome but only resnet152 is more interested in the sky than on the cupola. In the last column, we have an image with two classes, dog and cat . All the networks highlighted booths, like the eyes of the dog and the ears of the cat in vgg16 . What if we would like to discover only the region of the inputs that are related to a specific class? With this technique is impossible.","title":"Saliency Visualisation"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/FrancescoSaverioZuppichin_A-journey-into-Convolutional-Neural-Network-visualization/#class-activation-mapping","text":"Class Activation Mapping is a techniques presented in Learning Deep Features for Discriminative Localization . The idea is to use the last convolutional layer output and the neurons in the linear layer of the model responsable for a target class, the map is generated by taking the dot product of those. However, to make this work the model has to have some constrains. First of all, the output from the convolution must first go trought an global average polling and it requires feature maps to directly precede softmax layers. To make it works with other architecture, such as alexnet and vgg we have to change some layers in the model and retrain it. This is a major drawback that will be solved with the next section. For now, we can use it for free with resnet! Since its architecture is perfect. The implementation can be found here . We can pass to the visualisation a target_class parameter to get the relative weights from the fc layer. Notice that by changing the target class, we can see different part of the image highlighted. The first image uses the prediction class, while the second an other type of cat and the last one bookcase , just to see what the model will do with a wrong class. from visualisation.core.utils import imshow # we are using resnet 34 since the model has only one fc layer before the softmax and it is preceded by av avg pool # as required from the paper module = resnet34 ( True ) . to ( device ) module . eval () vis = ClassActivationMapping ( module , device ) classes = [ None , 285 , 453 ] def vis_outs2images_classes ( outs ): images = [ x [ 0 ] for x in outs ] classes = [ imagenet2human [ int ( x [ 1 ][ 'prediction' ])] for x in outs ] return images , classes outs = [ vis ( inputs [ 0 ], None , postprocessing = image_net_postprocessing , target_class = c , guide = True ) for c in classes ] images , classes = vis_outs2images_classes ( outs ) subplot ( images , rows_titles = classes , nrows = 1 , ncols = 3 , parse = tensor2img ) It makes sense, the only thing is that in the last row we still have some part of the cat highlighted for bookcase Let's plot the CAM on the cat images for different resnet architecture. For resnet > 34 the Bottleneck module is used modules_instances = [ resnet18 , resnet34 , resnet101 , resnet152 ] cat = inputs [ 2 ] modules = ( m ( pretrained = True ) . to ( device ) for m in modules_instances ) # make a generator, we don't want to store in memory all of them at once run_vis_plot_across_models ( modules , cat , None , ClassActivationMapping , 'ClassActivationMapping' , device , nrows = len ( modules_instances ), ncols = 1 , postprocessing = image_net_postprocessing , rows_name = [ 'resnet18' , 'resnet34' , 'resnet101' , 'resnet152' ], target_class = None ) free ( modules ) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). They are all very similar as expected. One big drawback of this technique is that force you to use a network with a specific architecture, global polling before the decoder part. The next technique generalize this approach by taking advantage of the gradient at one specific layer. Remember that with the class activation we are using the weights of the feature map as a scaling factor for the channels of the last layer. The features map must be before a softmax layer and right after the average pooling. The next technique propose a more general approach.","title":"Class Activation Mapping"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/FrancescoSaverioZuppichin_A-journey-into-Convolutional-Neural-Network-visualization/#grad-cam","text":"Grad Cam was introduced by Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization . The idea is actually simple, we backprop the output with respect to a target class while storing the gradient and the output at a given layer, in our case the last convolution. Then we perform a global average of the saved gradient keeping the channel dimension in order to get a 1-d tensor, this will represent the importance of each channel in the target convolutional layer. We then multiply each element of the convolutional layer outputs by the averaged gradients to create the grad cam. This whole procedure is fast and it is architecture independent. Interesting, the authors show that is a generalization of the previous technique. The code is here We can use it to higlight what different models are looking at. modules_instances = [ alexnet , vgg16 , resnet34 , resnet152 ] modules = ( m ( pretrained = True ) . to ( device ) for m in modules_instances ) # make a generator, we don't want to store in memory all of them at once run_vis_plot_across_models ( modules , inputs [ 0 ], None , GradCam , 'Gradcam' , device , nrows = 1 , ncols = 4 , target_class = None , postprocessing = image_net_postprocessing ) free ( modules ) It is really interesting to see how alexnet looks at the nose, while vgg at the ears and resnet at the whole cat. It is interesting to see that the two resnet version looks at different part of the cat. Below we plot the same input for resnet34 but we change the target class in each column to show the reader how the grad cam change accordingly. from visualisation.core.utils import imshow module = module . to ( device ) vis = GradCam ( module , device ) classes = [ None , 285 , 453 ] outs = [ vis ( inputs [ 0 ], None , postprocessing = image_net_postprocessing , target_class = c ) for c in classes ] images , classes = vis_outs2images_classes ( outs ) subplot ( images , title = 'resnet34' , rows_titles = classes , nrows = 1 , ncols = len ( outs ), parse = tensor2img ) Notice how similar to the CAM output they are. To better compore our three models, below we plot the grad cam for each input with respect to each model modules = ( m ( pretrained = True ) . to ( device ) for m in modules_instances ) # make a generator, we don't want to store in memory all of them at once run_vis_plot_across_models ( modules , inputs [ 0 ], None , GradCam , 'Gradcam' , device , nrows = 4 , ncols = 3 , target_class = None , inputs = inputs , idx2label = imagenet2human , annotations = [ 'alexnet' , 'vgg16' , 'resnet34' , 'resnet152' ], postprocessing = image_net_postprocessing ) free ( modules ) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). The reader can immediately notice the difference across the models.","title":"Grad Cam"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/FrancescoSaverioZuppichin_A-journey-into-Convolutional-Neural-Network-visualization/#interesting-region","text":"We talk before about interesting region localizations. Grad-cam can be also used to extract the class object out of the image. Easily, once the have the grad-cam image we can used it as mask to crop out form the input image what we want. The reader can play with the TR parameter to see different effects. TR = 0.3 alexnet_pretrained . eval () vis = GradCam ( alexnet_pretrained , device ) _ = vis ( inputs [ 0 ], None , postprocessing = image_net_postprocessing ) import cv2 def gradcam2crop ( cam , original_img ): b , c , w , h = inputs [ 0 ] . shape cam = cam . numpy () cam -= np . min ( cam ) cam /= np . max ( cam ) cam = cv2 . resize ( cam , ( w , h )) mask = cam > TR original_img = tensor2img ( image_net_postprocessing ( original_img [ 0 ] . squeeze ())) crop = original_img . copy () crop [ mask == 0 ] = 0 return crop crop = gradcam2crop ( vis . cam . cpu (), inputs [ 0 ] . cpu ()) fig = plt . figure () plt . imshow ( crop ) <matplotlib.image.AxesImage at 0x7f79debee048> et voil\u00e0 ! We can also change again class, and crop the interest region for that class. _ = vis ( inputs [ 0 ], None , target_class = 231 , postprocessing = image_net_postprocessing ) crop = gradcam2crop ( vis . cam . cpu (), inputs [ 0 ] . cpu ()) fig = plt . figure () plt . imshow ( crop ) <matplotlib.image.AxesImage at 0x7f79f40c4c18>","title":"Interesting region"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/FrancescoSaverioZuppichin_A-journey-into-Convolutional-Neural-Network-visualization/#different-models","text":"We have seen all these techniques used with classic classicification models trained on imagenet . What about use them on a different domain? I have ported this paper to Pytorch and retrain it. The model learn from the frontal camera's image of a robot to predict the local distance sensors in order to avoid obstacles. Let's see what if, by using those techniques, we can understand better what is going on inside the model.","title":"Different models"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/FrancescoSaverioZuppichin_A-journey-into-Convolutional-Neural-Network-visualization/#learning-long-range-perception-using-self-supervision-from-short-range-sensors-and-odometry","text":"The idea is to predict the future outputs of a short-range sensor (such as a proximity sensor) given the current outputs of a long-range sensor (such as a camera). They trained a very simple CNN from the robot's camera images to predict the proximity sensor values. If you are interested in their work, you can read the full paper here I have made a PyTorch implementation and retrain the model from scratch. Be awere that I did not fine-tune or try different sets of hyper-parameters so probably my model is not performing as well as the author's one. Let's import it from os import path LONG_RANGE_PERCEPTION_PATH = path . abspath ( './models/long_range_perception/model.pt' ) from models.long_range_perception.model import SimpleCNN from models.long_range_perception.utils import get_dl , H5_PATH , imshow , post_processing , pre_processing , MODEL_PATH free ([ module ]) module = torch . load ( LONG_RANGE_PERCEPTION_PATH , map_location = lambda storage , loc : storage ) module = module . to ( device ) module /home/francesco/Documents/A-journey-into-Convolutional-Neural-Network-visualization-/model.pt SimpleCNN( (encoder): Sequential( (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU() (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (3): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (4): ReLU() (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (6): Conv2d(10, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (7): ReLU() (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (decoder): Sequential( (0): Dropout(p=0.2) (1): Linear(in_features=640, out_features=256, bias=True) (2): ReLU() (3): Linear(in_features=256, out_features=325, bias=True) (4): Sigmoid() ) ) We know need some inputs to test the model, they are taken directly from the test set import os def make_and_show_inputs ( path , transform ): image_paths = glob . glob ( path ) image_paths = filter ( lambda x : os . path . isfile ( x ), image_paths ) images = list ( map ( lambda x : Image . open ( x ) . convert ( 'RGB' ), image_paths )) subplot ( images , title = 'inputs' , rows_titles = [ '1' , '2' , '3' , '4' ], nrows = 1 , ncols = 4 ) plt . show () inputs = [ pre_processing ( x ) . unsqueeze ( 0 ) . to ( device ) for x in images ] # add 1 dim for batch subplot ( inputs , parse = tensor2img , title = 'inputs' , rows_titles = [ '1' , '2' , '3' , '4' ], nrows = 1 , ncols = 4 ) return images , inputs images , inputs = make_and_show_inputs ( 'images/long_range_perception/*' , pre_processing ) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Then author normalize each image, this is done by callind pre_processing . For some reason the inpupts images are different on mac and ubuntu, they should not be like these if you run the notebook on mac the result is different. This is probably due to the warning message. We are going to use the SaliencyMap and the GradCam since those are the best from torch.autograd import Variable module . eval () def run_long_range_vis (): grad = GradCam ( module , device ) all_true = torch . ones ( 1 , 65 * 5 ) . float () . to ( device ) outs_grad = [ grad ( input , None , target_class = all_true , postprocessing = post_processing , regression = True )[ 0 ] for input in inputs ] sal = SaliencyMap ( module , device ) outs_saliency = [ sal ( input , None , guide = True , target_class = all_true , regression = True )[ 0 ] for input in inputs ] subplot ([ * outs_grad , * outs_saliency ], title = 'long_range' , cols_titles = [ '1' , '2' , '3' , '4' ], nrows = 2 , ncols = 4 , parse = tensor2img ) run_long_range_vis () We can clearly see that the model looks at the objects. In the GradCam row, on the second picture, the plan is basically segmented by the heatmap. There is one problem, if you look at the third picture, the white box in front of the camera is not clearly highlighted. This is probably due to the white color of the floor that is very similar to the box's color. Let's investigate this problem. In the second row, the SaliencyMaps highlights all the objects, including the white box. The reader can notice that the reflection in the first picture on the left seems to excite the network in that region. We should also investigate this case but due to time limitations, we will leave it as an exercise for the curious reader. For completeness, let's also print the predicted sensor output. The model tries to predict five frontal distance sensors give the image camera. import seaborn as sns module . eval () preds = module ( torch . stack ( inputs ) . squeeze ( 1 )) fig = plt . figure () sns . heatmap ( preds [ 2 ] . view ( - 1 , 5 ) . detach () . cpu () . numpy ()) <matplotlib.axes._subplots.AxesSubplot at 0x7f79d26dc240> If you compare with the authors pictures, my prediction are worse. This is due to the fact that to speed up everything I did not used all the training set and I did not perform any hyper paramater optimisation. All the code con be found here . Let's now investigate the first problem, object with a similar color to the ground.","title":"Learning Long-range Perception using Self-Supervision from Short-Range Sensors and Odometry"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/FrancescoSaverioZuppichin_A-journey-into-Convolutional-Neural-Network-visualization/#similar-colors","text":"To test if the model has a problem with obstacles with a the same color of the ground, we created in blender four different scenarios with an obstacle. They are showed in the picture below. image_paths = [ * sorted ( glob . glob ( 'images/long_range_perception/equal_color/*' )), * sorted ( glob . glob ( 'images/long_range_perception/different_color/*' ))] image_paths = filter ( lambda x : os . path . isfile ( x ), image_paths ) images = list ( map ( lambda x : Image . open ( x ) . convert ( 'RGB' ), image_paths )) subplot ( images , title = 'inputs' , nrows = 2 , ncols = 4 ) plt . show () There are four different lights configuration and two differents cube colors, one equal to the ground and the second different. The first column represents a realistic situation, while the second has a really strong light from behind that generates a shadow in front of the camera. The third column has a shadow on the left and the last one has a little shadow on the left. This is a perfect scenario to use gradcam to see what the model is looking in each image. In the picture below we plotted the gradcam results. inputs = [ pre_processing ( x ) . unsqueeze ( 0 ) . to ( device ) for x in images ] # add 1 dim for batch run_long_range_vis () The big black shadow in the second column definitly confuses the model. In the first and last column, the grad cam highlights better the corners of the red cube, especially in the first picture. We can definitely say that this model has some hard time with the object of the same colour as the ground. Thanks to this consideration, we could improve the number equal object/ground in the dataset, perform a better preprocessing, change the model structure etc and hopefully increase the robustness of the network.","title":"Similar colors"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/FrancescoSaverioZuppichin_A-journey-into-Convolutional-Neural-Network-visualization/#conclusion","text":"In this article, we present different convolutional neural network visualization techniques. In the first section, we introduced each one by applying to a set of famous classification networks. We compared different networks on different inputs and highlight the similarities and difference between them. Then we apply them to a model adopted in robotics to test its robustness and we were able to successfully reveal a problem in the network. Moreover, as a side project, I developed an interactive convolutional neural network visualization application called mirro that receives in just a few days more than a hundred stars on GitHub reflecting the interest of the deep learning community on this topic. All these visualizations are implemented using a common interface and there are available as python module so they can be used in any other module. Thank for reading Francesco Saverio Zuppichini","title":"Conclusion"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/","text":"Skin Cancer Classification - An Educational Guide In this tutorial we aim to provide a simple step-by-step guide to anyone who wants to work on the problem of skin lesion classification regardless of their level or expertise; from medical doctors, to master students and more experienced researchers. Using this guide you will learn: How to load the data, visualise it and uncover more about the class distribution and meta-data. How to utilise architectures with varying complexity from a few convolutional layers to hundreds of them. How to train a model with appropriate optimisers and loss functions. How to rigorously test your trained model, providing not only metrics such as accuracy but also visualisations like confusion matrix and Grad \u2014 Cam. How to analyse and understand your results. To conclude with, we will provide a few more tips that are usually utilised by the participants of the ISIC Challenges, that will help you increase your model\u2019s performance even more so that you can beat our performance and explore more advanced training schemes. https://github.com/IFL-CAMP/SLClassificationAnEducationalCode-MEC2019 # !pip install imageio # !pip install scikit-image import torch from torch import nn import torch.nn.functional as F import torchvision import torchvision.transforms as transforms import numpy as np import os import numpy as np import pandas as pd from sklearn.model_selection import train_test_split from sklearn.metrics import confusion_matrix , precision_recall_fscore_support import scipy.ndimage from scipy import misc from glob import glob from scipy import stats from sklearn.preprocessing import LabelEncoder , StandardScaler import skimage import imageio import seaborn as sns from PIL import Image import glob import matplotlib.pyplot as plt import matplotlib % matplotlib inline device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) device --------------------------------------------------------------------------- ModuleNotFoundError Traceback (most recent call last) <ipython-input-3-5b38befe3f1d> in <module> 18 import skimage 19 import imageio ---> 20 import seaborn as sns 21 from PIL import Image 22 import glob ModuleNotFoundError: No module named 'seaborn' What about data? The HAM10000 (\"Human Against Machine with 10000 training images\") dataset which contains 10,015 dermatoscopic images was made publically available by the Harvard database on June 2018 in the hopes to provide training data for automating the process of skin cancer lesion classifications. The motivation behind this act was to provide the public with an abundance and variability of data source for machine learning training purposes such that the results may be compared with that of human experts. If successful, the appplications would bring cost and time saving regimes to hospitals and medical professions alike. Apart from the 10,015 images, a metadata file with demographic information of each lesion is provided as well. More than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal) You can download the dataset here: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T The 7 classes of skin cancer lesions included in this dataset are: Melanocytic nevi Melanoma Benign keratosis-like lesions Basal cell carcinoma Actinic keratoses Vascular lesions Dermatofibroma Let's analyze the metadata of the dataset # importing metadata and checking for its shape data_dir = \"/data/HAM10000\" metadata = pd . read_csv ( data_dir + '/HAM10000_metadata.csv' ) print ( metadata . shape ) # label encoding the seven classes for skin cancers le = LabelEncoder () le . fit ( metadata [ 'dx' ]) LabelEncoder () print ( \"Classes:\" , list ( le . classes_ )) metadata [ 'label' ] = le . transform ( metadata [ \"dx\" ]) metadata . sample ( 10 ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-2-3d00b7e51bd3> in <module> 2 data_dir = \"/data/HAM10000\" 3 ----> 4 metadata = pd.read_csv(data_dir + '/HAM10000_metadata.csv') 5 print(metadata.shape) 6 NameError: name 'pd' is not defined # Getting a sense of what the distribution of each column looks like fig = plt . figure ( figsize = ( 40 , 25 )) ax1 = fig . add_subplot ( 221 ) metadata [ 'dx' ] . value_counts () . plot ( kind = 'bar' , ax = ax1 ) ax1 . set_ylabel ( 'Count' , size = 50 ) ax1 . set_title ( 'Cell Type' , size = 50 ) ax2 = fig . add_subplot ( 222 ) metadata [ 'sex' ] . value_counts () . plot ( kind = 'bar' , ax = ax2 ) ax2 . set_ylabel ( 'Count' , size = 50 ) ax2 . set_title ( 'Sex' , size = 50 ); ax3 = fig . add_subplot ( 223 ) metadata [ 'localization' ] . value_counts () . plot ( kind = 'bar' ) ax3 . set_ylabel ( 'Count' , size = 50 ) ax3 . set_title ( 'Localization' , size = 50 ) ax4 = fig . add_subplot ( 224 ) sample_age = metadata [ pd . notnull ( metadata [ 'age' ])] sns . distplot ( sample_age [ 'age' ], fit = stats . norm , color = 'red' ); ax4 . set_title ( 'Age' , size = 50 ) ax4 . set_xlabel ( 'Year' , size = 50 ) plt . tight_layout () plt . show () As you can see there is imbalance in the number of images per class. There are much more images for the lesion type \"Melanocytic Nevi\" compared to other types. This is an usual occurence for medical datasets and so it is very important to analyze the data from beforehand. Let's visualize some examples #Visualizing the images label = [ 'akiec' , 'bcc' , 'bkl' , 'df' , 'mel' , 'nv' , 'vasc' ] label_images = [] classes = [ 'actinic keratoses' , 'basal cell carcinoma' , 'benign keratosis-like lesions' , 'dermatofibroma' , 'melanoma' , 'melanocytic nevi' , 'vascular lesions' ] fig = plt . figure ( figsize = ( 55 , 55 )) k = range ( 7 ) for i in label : sample = metadata [ metadata [ 'dx' ] == i ][ 'image_id' ][: 5 ] label_images . extend ( sample ) for position , ID in enumerate ( label_images ): labl = metadata [ metadata [ 'image_id' ] == ID ][ 'dx' ] im_sample = data_dir + \"/\" + labl . values [ 0 ] + f '/ { ID } .jpg' im_sample = imageio . imread ( im_sample ) plt . subplot ( 7 , 5 , position + 1 ) plt . imshow ( im_sample ) plt . axis ( 'off' ) if position % 5 == 0 : title = int ( position / 5 ) plt . title ( classes [ title ], loc = 'left' , size = 50 , weight = \"bold\" ) plt . tight_layout () plt . show () Median Frequency Balancing As we saw above that there is class imbalance in our dataset. To solve that we use this method. #print(metadata['dx'].value_counts()) #print(metadata[metadata['dx']=='nv']['dx'].value_counts()) label = [ 'akiec' , 'bcc' , 'bkl' , 'df' , 'mel' , 'nv' , 'vasc' ] def estimate_weights_mfb ( label ): class_weights = np . zeros_like ( label , dtype = np . float ) counts = np . zeros_like ( label ) for i , l in enumerate ( label ): counts [ i ] = metadata [ metadata [ 'dx' ] == str ( l )][ 'dx' ] . value_counts ()[ 0 ] counts = counts . astype ( np . float ) #print(counts) median_freq = np . median ( counts ) #print(median_freq) #print(weights.shape) for i , label in enumerate ( label ): #print(label) class_weights [ i ] = median_freq / counts [ i ] return class_weights classweight = estimate_weights_mfb ( label ) for i in range ( len ( label )): print ( label [ i ], \":\" , classweight [ i ]) akiec : 1.5718654434250765 bcc : 1.0 bkl : 0.467697907188353 df : 4.469565217391304 mel : 0.4618149146451033 nv : 0.07665920954511558 vasc : 3.619718309859155 Pre-processing the dataset Before we load the data we need to alter the dataset structure. When you download the dataset, all the images are together in a folder. To use Pytorch dataloader we need to seggregrate the images into folders of their respetive labels. You can use the following script to automate the process. # import os # import shutil # data_dir = os.getcwd() + \"/HAM10000/\" # dest_dir = data_dir + \"test/\" # metadata = pd.read_csv(data_dir + '/HAM10000_metadata.csv') # label = ['bkl', 'nv', 'df', 'mel', 'vasc', 'bcc', 'akiec'] # label_images = [] # for i in label: # os.mkdir(dest_dir + str(i) + \"/\") # sample = metadata[metadata['dx'] == i]['image_id'][:5] # label_images.extend(sample) # for id in label_images: # shutil.copyfile((data_dir + i + \"/\"+ id +\".jpg\"), (dest_dir + i + \"/\"+id+\".jpg\")) # label_images=[] Data Augmentation It is a common fact that medical data is scarce. But to learn a very good model, the network needs a lot of data. So to tackle the problem we perform data augmentation. First we normalize the images. Data normalization is an important step which ensures that each input parameter (pixel, in this case) has a similar data distribution. This makes convergence faster while training the network. Data normalization is done by subtracting the mean from each pixel and then dividing the result by the standard deviation. The distribution of such data would resemble a Gaussian curve centered at zero. Since, skin lesion images are natural images, we use the normalization values (mean and standard deviation) of Imagenet dataset. We also perform data augmentation: - Flipping the image horizontally: RandomHorizontalFlip() - Rotating image 60 degrees: RandomRotation() . 60 degrees is chosen as best practice. You can experiment with other angles. The augmentation is applied using the transform.Compose() function of Pytorch. Take note, we only augment the training set. This is because, augmentation is done to aid the training process. So there is no point in augmenting the test set. data_dir = \"/data/HAM10000\" # normalization values for pretrained resnet on Imagenet norm_mean = ( 0.4914 , 0.4822 , 0.4465 ) norm_std = ( 0.2023 , 0.1994 , 0.2010 ) batch_size = 50 validation_batch_size = 10 test_batch_size = 10 # We compute the weights of individual classes and convert them to tensors class_weights = estimate_weights_mfb ( label ) class_weights = torch . FloatTensor ( class_weights ) transform_train = transforms . Compose ([ transforms . Resize (( 224 , 224 )), transforms . RandomHorizontalFlip (), transforms . RandomRotation ( degrees = 60 ), transforms . ToTensor (), transforms . Normalize ( norm_mean , norm_std ), ]) transform_test = transforms . Compose ([ transforms . Resize (( 224 , 224 )), transforms . ToTensor (), transforms . Normalize (( 0.4914 , 0.4822 , 0.4465 ), ( 0.2023 , 0.1994 , 0.2010 )), ]) Train, Test and Validation Split We split the entire dataset into 3 parts: - Train: 80% - Test: 20% - Validation: 16% The splitting is done class wise so that we have equal representation of all classes in each subset of the data. import torch as th import math test_size = 0.2 val_size = 0.2 class Sampler ( object ): \"\"\"Base class for all Samplers. \"\"\" def __init__ ( self , data_source ): pass def __iter__ ( self ): raise NotImplementedError def __len__ ( self ): raise NotImplementedError class StratifiedSampler ( Sampler ): \"\"\"Stratified Sampling Provides equal representation of target classes \"\"\" def __init__ ( self , class_vector ): \"\"\" Arguments --------- class_vector : torch tensor a vector of class labels batch_size : integer batch_size \"\"\" self . n_splits = 1 self . class_vector = class_vector self . test_size = test_size def gen_sample_array ( self ): try : from sklearn.model_selection import StratifiedShuffleSplit except : print ( 'Need scikit-learn for this functionality' ) import numpy as np s = StratifiedShuffleSplit ( n_splits = self . n_splits , test_size = self . test_size ) X = th . randn ( self . class_vector . size ( 0 ), 2 ) . numpy () y = self . class_vector . numpy () s . get_n_splits ( X , y ) train_index , test_index = next ( s . split ( X , y )) return train_index , test_index def __iter__ ( self ): return iter ( self . gen_sample_array ()) def __len__ ( self ): return len ( self . class_vector ) dataset = torchvision . datasets . ImageFolder ( root = data_dir ) data_label = [ s [ 1 ] for s in dataset . samples ] ss = StratifiedSampler ( torch . FloatTensor ( data_label ), test_size ) pre_train_indices , test_indices = ss . gen_sample_array () # The \"pre\" is necessary to use array to identify train/ val indices with indices generated by second sampler train_label = np . delete ( data_label , test_indices , None ) ss = StratifiedSampler ( torch . FloatTensor ( train_label ), test_size ) train_indices , val_indices = ss . gen_sample_array () indices = { 'train' : pre_train_indices [ train_indices ], # Indices of second sampler are used on pre_train_indices 'val' : pre_train_indices [ val_indices ], # Indices of second sampler are used on pre_train_indices 'test' : test_indices } train_indices = indices [ 'train' ] val_indices = indices [ 'val' ] test_indices = indices [ 'test' ] print ( \"Train Data Size:\" , len ( train_indices )) print ( \"Test Data Size:\" , len ( test_indices )) print ( \"Validation Data Size:\" , len ( val_indices )) Train Data Size: 6409 Test Data Size: 2003 Validation Data Size: 1603 Now we use Pytorch data loader to load the dataset into the memory. SubsetRandomSampler = torch . utils . data . sampler . SubsetRandomSampler dataset = torchvision . datasets . ImageFolder ( root = data_dir , transform = transform_train ) train_samples = SubsetRandomSampler ( train_indices ) val_samples = SubsetRandomSampler ( val_indices ) test_samples = SubsetRandomSampler ( test_indices ) train_data_loader = torch . utils . data . DataLoader ( dataset , batch_size = batch_size , shuffle = False , num_workers = 1 , sampler = train_samples ) validation_data_loader = torch . utils . data . DataLoader ( dataset , batch_size = validation_batch_size , shuffle = False , sampler = val_samples ) dataset = torchvision . datasets . ImageFolder ( root = data_dir , transform = transform_test ) test_data_loader = torch . utils . data . DataLoader ( dataset , batch_size = test_batch_size , shuffle = False , sampler = test_samples ) Let us see some of the training images. # functions to show an image fig = plt . figure ( figsize = ( 10 , 15 )) def imshow ( img ): img = img / 2 + 0.5 # denormalize change this npimg = img . numpy () plt . imshow ( np . transpose ( npimg , ( 1 , 2 , 0 ))) # get some random training images dataiter = iter ( train_data_loader ) images , labels = dataiter . next () # show images imshow ( torchvision . utils . make_grid ( images )) # print labels print ( ' ' . join ( ' %5s , ' % classes [ labels [ j ]] for j in range ( len ( labels )))) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). melanocytic nevi, actinic keratoses, benign keratosis-like lesions, benign keratosis-like lesions, melanocytic nevi, melanocytic nevi, basal cell carcinoma, melanocytic nevi, melanocytic nevi, benign keratosis-like lesions, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, benign keratosis-like lesions, melanocytic nevi, melanoma, melanocytic nevi, melanocytic nevi, melanoma, melanoma, melanocytic nevi, actinic keratoses, melanocytic nevi, actinic keratoses, melanocytic nevi, melanocytic nevi, melanoma, melanocytic nevi, melanoma, melanoma, melanocytic nevi, melanoma, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanoma, melanocytic nevi, melanocytic nevi, melanocytic nevi, dermatofibroma, basal cell carcinoma, basal cell carcinoma, Define a Convolutional Neural Network Pytorch makes it very easy to define a neural network. We have layers like Convolutions, ReLU non-linearity, Maxpooling etc. directly from torch library. In this tutorial, we use The LeNet architecture introduced by LeCun et al. in their 1998 paper, Gradient-Based Learning Applied to Document Recognition . As the name of the paper suggests, the authors\u2019 implementation of LeNet was used primarily for OCR and character recognition in documents. The LeNet architecture is straightforward and small, (in terms of memory footprint), making it perfect for teaching the basics of CNNs. num_classes = len ( classes ) class LeNet ( nn . Module ): def __init__ ( self ): super ( LeNet , self ) . __init__ () self . conv1 = nn . Conv2d ( 3 , 6 , ( 5 , 5 ), padding = 2 ) self . conv2 = nn . Conv2d ( 6 , 16 , ( 5 , 5 )) self . fc1 = nn . Linear ( 16 * 54 * 54 , 120 ) self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , num_classes ) def forward ( self , x ): x = F . max_pool2d ( F . relu ( self . conv1 ( x )), ( 2 , 2 )) x = F . max_pool2d ( F . relu ( self . conv2 ( x )), ( 2 , 2 )) x = x . view ( - 1 , self . num_flat_features ( x )) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x def num_flat_features ( self , x ): size = x . size ()[ 1 :] num_features = 1 for s in size : num_features *= s return num_features net = LeNet () net = net . to ( device ) Define a Loss function and Optimizer Let's use a Classification Cross-Entropy loss. \\(H_{y'} (y) := - \\sum_{i} y_{i}' \\log (y_i)\\) The most common and effective Optimizer currently used is Adam: Adaptive Moments . You can look here for more information. import torch.optim as optim class_weights = class_weights . to ( device ) criterion = nn . CrossEntropyLoss ( weight = class_weights ) optimizer = optim . Adam ( net . parameters (), lr = 1e-5 ) print ( net ) LeNet( (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=46656, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=7, bias=True) ) These are some helper functions to evaluate the training process. from sklearn.metrics import accuracy_score def get_accuracy ( predicted , labels ): batch_len , correct = 0 , 0 batch_len = labels . size ( 0 ) correct = ( predicted == labels ) . sum () . item () return batch_len , correct def evaluate ( model , val_loader ): losses = 0 num_samples_total = 0 correct_total = 0 model . eval () for inputs , labels in val_loader : inputs , labels = inputs . to ( device ), labels . to ( device ) out = model ( inputs ) _ , predicted = torch . max ( out , 1 ) loss = criterion ( out , labels ) losses += loss . item () b_len , corr = get_accuracy ( predicted , labels ) num_samples_total += b_len correct_total += corr accuracy = correct_total / num_samples_total losses = losses / len ( val_loader ) return losses , accuracy Train the network This is when things start to get interesting. We simply loop over the training data iterator, and feed the inputs to the network and optimize. # number of loops over the dataset num_epochs = 50 accuracy = [] val_accuracy = [] losses = [] val_losses = [] for epoch in range ( num_epochs ): running_loss = 0.0 correct_total = 0.0 num_samples_total = 0.0 for i , data in enumerate ( train_data_loader ): # get the inputs inputs , labels = data inputs , labels = inputs . to ( device ), labels . to ( device ) # set the parameter gradients to zero optimizer . zero_grad () # forward + backward + optimize outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () #compute accuracy _ , predicted = torch . max ( outputs , 1 ) b_len , corr = get_accuracy ( predicted , labels ) num_samples_total += b_len correct_total += corr running_loss += loss . item () running_loss /= len ( train_data_loader ) train_accuracy = correct_total / num_samples_total val_loss , val_acc = evaluate ( net , validation_data_loader ) print ( 'Epoch: %d ' % ( epoch + 1 )) print ( 'Loss: %.3f Accuracy: %.3f ' % ( running_loss , train_accuracy )) print ( 'Validation Loss: %.3f Val Accuracy: %.3f ' % ( val_loss , val_acc )) losses . append ( running_loss ) val_losses . append ( val_loss ) accuracy . append ( train_accuracy ) val_accuracy . append ( val_acc ) print ( 'Finished Training' ) Epoch: 1 Loss: 1.806 Accuracy:0.314 Validation Loss: 1.727 Val Accuracy: 0.403 Epoch: 2 Loss: 1.663 Accuracy:0.371 Validation Loss: 1.631 Val Accuracy: 0.419 Epoch: 3 Loss: 1.589 Accuracy:0.459 Validation Loss: 1.565 Val Accuracy: 0.451 Epoch: 4 Loss: 1.542 Accuracy:0.486 Validation Loss: 1.558 Val Accuracy: 0.431 Epoch: 5 Loss: 1.499 Accuracy:0.494 Validation Loss: 1.483 Val Accuracy: 0.500 Epoch: 6 Loss: 1.472 Accuracy:0.500 Validation Loss: 1.457 Val Accuracy: 0.525 Epoch: 7 Loss: 1.447 Accuracy:0.509 Validation Loss: 1.454 Val Accuracy: 0.498 Epoch: 9 Loss: 1.421 Accuracy:0.503 Validation Loss: 1.406 Val Accuracy: 0.527 Epoch: 10 Loss: 1.399 Accuracy:0.516 Validation Loss: 1.413 Val Accuracy: 0.530 Epoch: 11 Loss: 1.390 Accuracy:0.519 Validation Loss: 1.436 Val Accuracy: 0.496 Epoch: 12 Loss: 1.384 Accuracy:0.519 Validation Loss: 1.396 Val Accuracy: 0.505 Epoch: 13 Loss: 1.373 Accuracy:0.529 Validation Loss: 1.391 Val Accuracy: 0.525 Epoch: 14 Loss: 1.363 Accuracy:0.534 Validation Loss: 1.376 Val Accuracy: 0.518 Epoch: 15 Loss: 1.364 Accuracy:0.531 Validation Loss: 1.365 Val Accuracy: 0.536 Epoch: 16 Loss: 1.352 Accuracy:0.534 Validation Loss: 1.363 Val Accuracy: 0.548 Epoch: 17 Loss: 1.337 Accuracy:0.536 Validation Loss: 1.365 Val Accuracy: 0.532 Epoch: 18 Loss: 1.333 Accuracy:0.540 Validation Loss: 1.340 Val Accuracy: 0.527 Epoch: 19 Loss: 1.327 Accuracy:0.542 Validation Loss: 1.333 Val Accuracy: 0.530 Epoch: 20 Loss: 1.320 Accuracy:0.537 Validation Loss: 1.304 Val Accuracy: 0.558 Epoch: 21 Loss: 1.303 Accuracy:0.555 Validation Loss: 1.373 Val Accuracy: 0.490 Epoch: 23 Loss: 1.293 Accuracy:0.550 Validation Loss: 1.348 Val Accuracy: 0.530 Epoch: 24 Loss: 1.308 Accuracy:0.554 Validation Loss: 1.344 Val Accuracy: 0.558 Epoch: 25 Loss: 1.288 Accuracy:0.559 Validation Loss: 1.329 Val Accuracy: 0.552 Epoch: 26 Loss: 1.288 Accuracy:0.558 Validation Loss: 1.321 Val Accuracy: 0.533 Epoch: 27 Loss: 1.295 Accuracy:0.560 Validation Loss: 1.310 Val Accuracy: 0.558 Epoch: 28 Loss: 1.290 Accuracy:0.562 Validation Loss: 1.303 Val Accuracy: 0.534 Epoch: 29 Loss: 1.278 Accuracy:0.560 Validation Loss: 1.315 Val Accuracy: 0.522 Epoch: 30 Loss: 1.280 Accuracy:0.559 Validation Loss: 1.318 Val Accuracy: 0.540 Epoch: 31 Loss: 1.266 Accuracy:0.561 Validation Loss: 1.284 Val Accuracy: 0.540 Epoch: 32 Loss: 1.275 Accuracy:0.565 Validation Loss: 1.289 Val Accuracy: 0.562 Epoch: 33 Loss: 1.259 Accuracy:0.575 Validation Loss: 1.284 Val Accuracy: 0.585 Epoch: 34 Loss: 1.268 Accuracy:0.561 Validation Loss: 1.313 Val Accuracy: 0.530 Epoch: 35 Loss: 1.257 Accuracy:0.574 Validation Loss: 1.328 Val Accuracy: 0.520 Epoch: 36 Loss: 1.254 Accuracy:0.569 Validation Loss: 1.288 Val Accuracy: 0.555 Epoch: 37 Loss: 1.259 Accuracy:0.574 Validation Loss: 1.289 Val Accuracy: 0.566 Epoch: 38 Loss: 1.251 Accuracy:0.576 Validation Loss: 1.319 Val Accuracy: 0.513 Epoch: 39 Loss: 1.248 Accuracy:0.572 Validation Loss: 1.276 Val Accuracy: 0.571 Epoch: 40 Loss: 1.253 Accuracy:0.582 Validation Loss: 1.300 Val Accuracy: 0.533 Epoch: 41 Loss: 1.236 Accuracy:0.570 Validation Loss: 1.288 Val Accuracy: 0.563 Epoch: 42 Loss: 1.246 Accuracy:0.572 Validation Loss: 1.263 Val Accuracy: 0.564 Epoch: 43 Loss: 1.240 Accuracy:0.581 Validation Loss: 1.332 Val Accuracy: 0.520 Epoch: 44 Loss: 1.253 Accuracy:0.573 Validation Loss: 1.311 Val Accuracy: 0.528 Epoch: 45 Loss: 1.229 Accuracy:0.579 Validation Loss: 1.266 Val Accuracy: 0.558 Epoch: 46 Loss: 1.221 Accuracy:0.585 Validation Loss: 1.264 Val Accuracy: 0.553 Epoch: 47 Loss: 1.232 Accuracy:0.586 Validation Loss: 1.258 Val Accuracy: 0.561 Epoch: 48 Loss: 1.236 Accuracy:0.582 Validation Loss: 1.255 Val Accuracy: 0.588 Epoch: 49 Loss: 1.224 Accuracy:0.583 Validation Loss: 1.258 Val Accuracy: 0.581 Epoch: 50 Loss: 1.234 Accuracy:0.582 Validation Loss: 1.261 Val Accuracy: 0.560 Finished Training Plot the training and validation loss curves. # plt.plot(losses) # plt.show() epoch = range ( 1 , num_epochs + 1 ) fig = plt . figure ( figsize = ( 10 , 15 )) plt . subplot ( 2 , 1 , 2 ) plt . plot ( epoch , losses , label = 'Training loss' ) plt . plot ( epoch , val_losses , label = 'Validation loss' ) plt . title ( 'Training and Validation Loss' ) plt . xlabel ( 'Epochs' ) plt . legend () plt . figure () plt . show () fig = plt . figure ( figsize = ( 10 , 15 )) plt . subplot ( 2 , 1 , 2 ) plt . plot ( epoch , accuracy , label = 'Training accuracy' ) plt . plot ( epoch , val_accuracy , label = 'Validation accuracy' ) plt . title ( 'Training and Validation Accuracy' ) plt . xlabel ( 'Epochs' ) plt . legend () plt . figure () plt . show () <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes> Test the network on the test data We have trained the network over the training dataset. But we need to check if the network has learnt anything at all. We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions. Okay, first step. Let us display an image from the test set to get familiar. fig = plt . figure ( figsize = ( 10 , 15 )) dataiter = iter ( test_data_loader ) images , labels = dataiter . next () # print images imshow ( torchvision . utils . make_grid ( images )) print ( 'GroundTruth: ' , ' ' . join ( ' %5s , ' % classes [ labels [ j ]] for j in range ( len ( labels )))) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). GroundTruth: melanocytic nevi, benign keratosis-like lesions, melanocytic nevi, melanoma, melanocytic nevi, benign keratosis-like lesions, melanocytic nevi, melanoma, benign keratosis-like lesions, melanocytic nevi, Okay, now let us check the performance on the test network: correct = 0 total = 0 net . eval () with torch . no_grad (): for data in test_data_loader : images , labels = data images , labels = images . to ( device ), labels . to ( device ) outputs = net ( images ) _ , predicted = torch . max ( outputs . data , 1 ) total += labels . size ( 0 ) correct += ( predicted == labels ) . sum () . item () print ( 'Accuracy of the network on the test images: %d %% ' % ( 100 * correct / total )) Accuracy of the network on the test images: 52 % That looks better than chance, which is about 14% accuracy (randomly picking a class out of 7 classes). Seems like the network learnt something. But maybe it doesn't learn all the classes equally. Let's check which classes that performed well, and which did not. class_correct = list ( 0. for i in range ( len ( classes ))) class_total = list ( 1e-7 for i in range ( len ( classes ))) with torch . no_grad (): for data in test_data_loader : images , labels = data images , labels = images . to ( device ), labels . to ( device ) outputs = net ( images ) _ , predicted = torch . max ( outputs , 1 ) c = ( predicted == labels ) . squeeze () for i in range ( 3 ): label = labels [ i ] class_correct [ label ] += c [ i ] . item () class_total [ label ] += 1 for i in range ( len ( classes )): print ( 'Accuracy of %5s : %2d %% ' % ( classes [ i ], 100 * class_correct [ i ] / class_total [ i ])) Accuracy of actinic keratoses : 27 % Accuracy of basal cell carcinoma : 76 % Accuracy of benign keratosis-like lesions : 4 % Accuracy of dermatofibroma : 39 % Accuracy of melanoma : 73 % Accuracy of melanocytic nevi : 58 % Accuracy of vascular lesions : 0 % Confusion Matrix confusion_matrix = torch . zeros ( len ( classes ), len ( classes )) with torch . no_grad (): for data in test_data_loader : images , labels = data images , labels = images . to ( device ), labels . to ( device ) outputs = net ( images ) _ , predicted = torch . max ( outputs , 1 ) for t , p in zip ( labels . view ( - 1 ), predicted . view ( - 1 )): confusion_matrix [ t . long (), p . long ()] += 1 cm = confusion_matrix . numpy () fig , ax = plt . subplots ( figsize = ( 7 , 7 )) sns . heatmap ( cm / ( cm . astype ( np . float ) . sum ( axis = 1 ) + 1e-9 ), annot = False , ax = ax ) # labels, title and ticks ax . set_xlabel ( 'Predicted' , size = 25 ); ax . set_ylabel ( 'True' , size = 25 ); ax . set_title ( 'Confusion Matrix' , size = 25 ); ax . xaxis . set_ticklabels ([ 'akiec' , 'bcc' , 'bkl' , 'df' , 'mel' , 'nv' , 'vasc' ], size = 15 ); \\ ax . yaxis . set_ticklabels ([ 'akiec' , 'bcc' , 'bkl' , 'df' , 'mel' , 'nv' , 'vasc' ], size = 15 ); Grad cam from collections import OrderedDict , Sequence class _BaseWrapper ( object ): \"\"\" Please modify forward() and backward() according to your task. \"\"\" def __init__ ( self , model ): super ( _BaseWrapper , self ) . __init__ () self . device = next ( model . parameters ()) . device self . model = model self . handlers = [] # a set of hook function handlers def _encode_one_hot ( self , ids ): one_hot = torch . zeros_like ( self . logits ) . to ( self . device ) one_hot . scatter_ ( 1 , ids , 1.0 ) return one_hot def forward ( self , image ): \"\"\" Simple classification \"\"\" self . model . zero_grad () self . logits = self . model ( image ) self . probs = F . softmax ( self . logits , dim = 1 ) return self . probs . sort ( dim = 1 , descending = True ) def backward ( self , ids ): \"\"\" Class-specific backpropagation Either way works: 1. self.logits.backward(gradient=one_hot, retain_graph=True) 2. (self.logits * one_hot).sum().backward(retain_graph=True) \"\"\" one_hot = self . _encode_one_hot ( ids ) self . logits . backward ( gradient = one_hot , retain_graph = True ) def generate ( self ): raise NotImplementedError def remove_hook ( self ): \"\"\" Remove all the forward/backward hook functions \"\"\" for handle in self . handlers : handle . remove () class GradCAM ( _BaseWrapper ): \"\"\" \"Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization\" https://arxiv.org/pdf/1610.02391.pdf Look at Figure 2 on page 4 \"\"\" def __init__ ( self , model , candidate_layers = None ): super ( GradCAM , self ) . __init__ ( model ) self . fmap_pool = OrderedDict () self . grad_pool = OrderedDict () self . candidate_layers = candidate_layers # list def forward_hook ( key ): def forward_hook_ ( module , input , output ): # Save featuremaps self . fmap_pool [ key ] = output . detach () return forward_hook_ def backward_hook ( key ): def backward_hook_ ( module , grad_in , grad_out ): # Save the gradients correspond to the featuremaps self . grad_pool [ key ] = grad_out [ 0 ] . detach () return backward_hook_ # If any candidates are not specified, the hook is registered to all the layers. for name , module in self . model . named_modules (): if self . candidate_layers is None or name in self . candidate_layers : self . handlers . append ( module . register_forward_hook ( forward_hook ( name ))) self . handlers . append ( module . register_backward_hook ( backward_hook ( name ))) def _find ( self , pool , target_layer ): if target_layer in pool . keys (): return pool [ target_layer ] else : raise ValueError ( \"Invalid layer name: {} \" . format ( target_layer )) def _compute_grad_weights ( self , grads ): return F . adaptive_avg_pool2d ( grads , 1 ) def forward ( self , image ): self . image_shape = image . shape [ 2 :] return super ( GradCAM , self ) . forward ( image ) def generate ( self , target_layer ): fmaps = self . _find ( self . fmap_pool , target_layer ) grads = self . _find ( self . grad_pool , target_layer ) weights = self . _compute_grad_weights ( grads ) gcam = torch . mul ( fmaps , weights ) . sum ( dim = 1 , keepdim = True ) gcam = F . relu ( gcam ) gcam = F . interpolate ( gcam , self . image_shape , mode = \"bilinear\" , align_corners = False ) B , C , H , W = gcam . shape gcam = gcam . view ( B , - 1 ) gcam -= gcam . min ( dim = 1 , keepdim = True )[ 0 ] gcam /= gcam . max ( dim = 1 , keepdim = True )[ 0 ] gcam = gcam . view ( B , C , H , W ) return gcam def demo2 ( image , label , model ): \"\"\" Generate Grad-CAM \"\"\" # Model model = model model . to ( device ) model . eval () # The layers target_layers = [ \"conv2\" ] target_class = label # Images images = image . unsqueeze ( 0 ) gcam = GradCAM ( model = model ) probs , ids = gcam . forward ( images ) ids_ = torch . LongTensor ([[ target_class ]] * len ( images )) . to ( device ) gcam . backward ( ids = ids_ ) for target_layer in target_layers : print ( \"Generating Grad-CAM @ {} \" . format ( target_layer )) # Grad-CAM regions = gcam . generate ( target_layer = target_layer ) for j in range ( len ( images )): print ( \" \\t # {} : {} ( {:.5f} )\" . format ( j , classes [ target_class ], float ( probs [ ids == target_class ]) ) ) gcam = regions [ j , 0 ] plt . imshow ( gcam . cpu ()) plt . show () image , label = next ( iter ( test_data_loader )) # Load the model model = net # Grad cam demo2 ( image [ 0 ] . to ( device ), label [ 0 ] . to ( device ), model ) image = np . transpose ( image [ 0 ], ( 1 , 2 , 0 )) image2 = np . add ( np . multiply ( image . numpy (), np . array ( norm_std )) , np . array ( norm_mean )) print ( \"True Class: \" , classes [ label [ 0 ] . cpu ()]) plt . imshow ( image ) plt . show () plt . imshow ( image2 ) plt . show () Generating Grad-CAM @conv2 #0: melanocytic nevi (0.12183) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). True Class: melanocytic nevi Analysis of the results As we can see from the results of the LeNet model, our system is not capable of processing the complexity of the given input images. Our final accuracy on the test data was 61%. About 39% of the images are missclassified, which is a terrible performance for any clinical use case. These results could be substantially improved if we opt for a deeper, more complex network architecture than LeNet, which will allow for a richer learning of the corresponding image features. Switching to superior network architecture:Resnet18 from torch import nn num_classes = len ( classes ) net = torchvision . models . resnet18 ( pretrained = True ) # We replace last layer of resnet to match our number of classes which is 7 net . fc = nn . Linear ( 512 , num_classes ) net = net . to ( device ) Define a Loss function and Optimizer Let's use a Classification Cross-Entropy loss. \\(H_{y'} (y) := - \\sum_{i} y_{i}' \\log (y_i)\\) The most common and effective Optimizer currently used is Adam: Adaptive Moments . You can look here for more information. import torch.optim as optim class_weights = class_weights . to ( device ) criterion = nn . CrossEntropyLoss ( weight = class_weights ) optimizer = optim . Adam ( net . parameters (), lr = 1e-5 ) print ( net ) ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (1): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer2): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer3): Sequential( (0): BasicBlock( (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer4): Sequential( (0): BasicBlock( (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (fc): Linear(in_features=512, out_features=7, bias=True) ) These are some helper functions to evaluate the training process. from sklearn.metrics import accuracy_score def get_accuracy ( predicted , labels ): batch_len , correct = 0 , 0 batch_len = labels . size ( 0 ) correct = ( predicted == labels ) . sum () . item () return batch_len , correct def evaluate ( model , val_loader ): losses = 0 num_samples_total = 0 correct_total = 0 model . eval () for inputs , labels in val_loader : inputs , labels = inputs . to ( device ), labels . to ( device ) out = model ( inputs ) _ , predicted = torch . max ( out , 1 ) loss = criterion ( out , labels ) losses += loss . item () b_len , corr = get_accuracy ( predicted , labels ) num_samples_total += b_len correct_total += corr accuracy = correct_total / num_samples_total losses = losses / len ( val_loader ) return losses , accuracy Train the network This is when things start to get interesting. We simply loop over the training data iterator, and feed the inputs to the network and optimize. # number of loops over the dataset num_epochs = 70 accuracy = [] val_accuracy = [] losses = [] val_losses = [] for epoch in range ( num_epochs ): running_loss = 0.0 correct_total = 0.0 num_samples_total = 0.0 for i , data in enumerate ( train_data_loader ): # get the inputs inputs , labels = data inputs , labels = inputs . to ( device ), labels . to ( device ) # set the parameter gradients to zero optimizer . zero_grad () # forward + backward + optimize outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () #compute accuracy _ , predicted = torch . max ( outputs , 1 ) b_len , corr = get_accuracy ( predicted , labels ) num_samples_total += b_len correct_total += corr running_loss += loss . item () running_loss /= len ( train_data_loader ) train_accuracy = correct_total / num_samples_total val_loss , val_acc = evaluate ( net , validation_data_loader ) print ( 'Epoch: %d ' % ( epoch + 1 )) print ( 'Loss: %.3f Accuracy: %.3f ' % ( running_loss , train_accuracy )) print ( 'Validation Loss: %.3f Val Accuracy: %.3f ' % ( val_loss , val_acc )) losses . append ( running_loss ) val_losses . append ( val_loss ) accuracy . append ( train_accuracy ) val_accuracy . append ( val_acc ) print ( 'Finished Training' ) Epoch: 1 Loss: 1.918 Accuracy:0.098 Validation Loss: 1.588 Val Accuracy: 0.243 Epoch: 2 Loss: 1.125 Accuracy:0.621 Validation Loss: 1.040 Val Accuracy: 0.648 Epoch: 3 Loss: 0.937 Accuracy:0.678 Validation Loss: 0.892 Val Accuracy: 0.674 Epoch: 5 Loss: 0.759 Accuracy:0.724 Validation Loss: 0.929 Val Accuracy: 0.651 Epoch: 6 Loss: 0.690 Accuracy:0.730 Validation Loss: 0.838 Val Accuracy: 0.718 Epoch: 7 Loss: 0.662 Accuracy:0.737 Validation Loss: 0.816 Val Accuracy: 0.709 Epoch: 8 Loss: 0.590 Accuracy:0.763 Validation Loss: 0.819 Val Accuracy: 0.705 Epoch: 9 Loss: 0.564 Accuracy:0.767 Validation Loss: 0.848 Val Accuracy: 0.726 Epoch: 10 Loss: 0.546 Accuracy:0.770 Validation Loss: 0.851 Val Accuracy: 0.719 Epoch: 11 Loss: 0.499 Accuracy:0.778 Validation Loss: 0.766 Val Accuracy: 0.749 Epoch: 12 Loss: 0.499 Accuracy:0.784 Validation Loss: 0.734 Val Accuracy: 0.751 Epoch: 13 Loss: 0.462 Accuracy:0.801 Validation Loss: 0.802 Val Accuracy: 0.757 Epoch: 14 Loss: 0.454 Accuracy:0.805 Validation Loss: 0.757 Val Accuracy: 0.744 Epoch: 15 Loss: 0.414 Accuracy:0.808 Validation Loss: 0.722 Val Accuracy: 0.769 Epoch: 16 Loss: 0.433 Accuracy:0.802 Validation Loss: 0.829 Val Accuracy: 0.787 Epoch: 17 Loss: 0.399 Accuracy:0.813 Validation Loss: 0.791 Val Accuracy: 0.768 Epoch: 18 Loss: 0.372 Accuracy:0.825 Validation Loss: 0.660 Val Accuracy: 0.791 Epoch: 19 Loss: 0.354 Accuracy:0.822 Validation Loss: 0.794 Val Accuracy: 0.784 Epoch: 20 Loss: 0.355 Accuracy:0.829 Validation Loss: 0.789 Val Accuracy: 0.750 Epoch: 21 Loss: 0.318 Accuracy:0.841 Validation Loss: 0.765 Val Accuracy: 0.800 Epoch: 22 Loss: 0.284 Accuracy:0.855 Validation Loss: 0.801 Val Accuracy: 0.777 Epoch: 23 Loss: 0.311 Accuracy:0.839 Validation Loss: 0.849 Val Accuracy: 0.815 Epoch: 24 Loss: 0.277 Accuracy:0.851 Validation Loss: 0.839 Val Accuracy: 0.792 Epoch: 25 Loss: 0.284 Accuracy:0.852 Validation Loss: 0.772 Val Accuracy: 0.770 Epoch: 26 Loss: 0.261 Accuracy:0.863 Validation Loss: 0.770 Val Accuracy: 0.802 Epoch: 27 Loss: 0.244 Accuracy:0.863 Validation Loss: 0.782 Val Accuracy: 0.782 Epoch: 28 Loss: 0.239 Accuracy:0.862 Validation Loss: 0.731 Val Accuracy: 0.805 Epoch: 29 Loss: 0.234 Accuracy:0.870 Validation Loss: 0.786 Val Accuracy: 0.816 Epoch: 30 Loss: 0.248 Accuracy:0.860 Validation Loss: 0.739 Val Accuracy: 0.803 Epoch: 31 Loss: 0.239 Accuracy:0.868 Validation Loss: 0.908 Val Accuracy: 0.779 Epoch: 33 Loss: 0.188 Accuracy:0.884 Validation Loss: 0.771 Val Accuracy: 0.780 Epoch: 34 Loss: 0.180 Accuracy:0.893 Validation Loss: 0.868 Val Accuracy: 0.803 Epoch: 35 Loss: 0.174 Accuracy:0.895 Validation Loss: 0.825 Val Accuracy: 0.800 Epoch: 36 Loss: 0.172 Accuracy:0.893 Validation Loss: 0.893 Val Accuracy: 0.823 Epoch: 37 Loss: 0.180 Accuracy:0.895 Validation Loss: 0.774 Val Accuracy: 0.778 Epoch: 38 Loss: 0.164 Accuracy:0.903 Validation Loss: 0.768 Val Accuracy: 0.776 Epoch: 39 Loss: 0.175 Accuracy:0.897 Validation Loss: 1.080 Val Accuracy: 0.784 Epoch: 40 Loss: 0.150 Accuracy:0.906 Validation Loss: 0.905 Val Accuracy: 0.826 Epoch: 41 Loss: 0.128 Accuracy:0.917 Validation Loss: 0.973 Val Accuracy: 0.809 Epoch: 42 Loss: 0.142 Accuracy:0.912 Validation Loss: 0.944 Val Accuracy: 0.834 Epoch: 43 Loss: 0.127 Accuracy:0.912 Validation Loss: 0.825 Val Accuracy: 0.819 Epoch: 44 Loss: 0.138 Accuracy:0.911 Validation Loss: 0.752 Val Accuracy: 0.810 Plot the training and validation loss curves. # plt.plot(losses) # plt.show() epoch = range ( 1 , num_epochs + 1 ) fig = plt . figure ( figsize = ( 10 , 15 )) plt . subplot ( 2 , 1 , 2 ) plt . plot ( epoch , losses , label = 'Training loss' ) plt . plot ( epoch , val_losses , label = 'Validation loss' ) plt . title ( 'Training and Validation Loss' ) plt . xlabel ( 'Epochs' ) plt . legend () plt . figure () plt . show () fig = plt . figure ( figsize = ( 10 , 15 )) plt . subplot ( 2 , 1 , 2 ) plt . plot ( epoch , accuracy , label = 'Training accuracy' ) plt . plot ( epoch , val_accuracy , label = 'Validation accuracy' ) plt . title ( 'Training and Validation Accuracy' ) plt . xlabel ( 'Epochs' ) plt . legend () plt . figure () plt . show () <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes> Test the network on the test data We have trained the network over the training dataset. But we need to check if the network has learnt anything at all. We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions. Okay, first step. Let us display an image from the test set to get familiar. fig = plt . figure ( figsize = ( 10 , 15 )) dataiter = iter ( test_data_loader ) images , labels = dataiter . next () # print images imshow ( torchvision . utils . make_grid ( images )) print ( 'GroundTruth: ' , ' ' . join ( ' %5s , ' % classes [ labels [ j ]] for j in range ( len ( labels )))) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). GroundTruth: melanocytic nevi, melanoma, melanocytic nevi, melanoma, melanoma, melanocytic nevi, melanocytic nevi, benign keratosis-like lesions, basal cell carcinoma, melanocytic nevi, Okay, now let us check the performance on the test network: correct = 0 total = 0 net . eval () with torch . no_grad (): for data in test_data_loader : images , labels = data images , labels = images . to ( device ), labels . to ( device ) outputs = net ( images ) _ , predicted = torch . max ( outputs . data , 1 ) total += labels . size ( 0 ) correct += ( predicted == labels ) . sum () . item () print ( 'Accuracy of the network on the test images: %d %% ' % ( 100 * correct / total )) Accuracy of the network on the test images: 85 % class_correct = list ( 0. for i in range ( len ( classes ))) class_total = list ( 1e-7 for i in range ( len ( classes ))) with torch . no_grad (): for data in test_data_loader : images , labels = data images , labels = images . to ( device ), labels . to ( device ) outputs = net ( images ) _ , predicted = torch . max ( outputs , 1 ) c = ( predicted == labels ) . squeeze () for i in range ( 3 ): label = labels [ i ] class_correct [ label ] += c [ i ] . item () class_total [ label ] += 1 for i in range ( len ( classes )): print ( 'Accuracy of %5s : %2d %% ' % ( classes [ i ], 100 * class_correct [ i ] / class_total [ i ])) Accuracy of actinic keratoses : 92 % Accuracy of basal cell carcinoma : 96 % Accuracy of benign keratosis-like lesions : 92 % Accuracy of dermatofibroma : 79 % Accuracy of melanoma : 97 % Accuracy of melanocytic nevi : 85 % Accuracy of vascular lesions : 0 % class_correct = list ( 0. for i in range ( len ( classes ))) class_total = list ( 1e-7 for i in range ( len ( classes ))) net . eval () with torch . no_grad (): for data in validation_data_loader : images , labels = data images , labels = images . to ( device ), labels . to ( device ) outputs = net ( images ) _ , predicted = torch . max ( outputs , 1 ) c = ( predicted == labels ) . squeeze () for i in range ( 3 ): label = labels [ i ] class_correct [ label ] += c [ i ] . item () class_total [ label ] += 1 for i in range ( len ( classes )): print ( 'Accuracy of %5s : %2d %% ' % ( classes [ i ], 100 * class_correct [ i ] / class_total [ i ])) Accuracy of actinic keratoses : 66 % Accuracy of basal cell carcinoma : 77 % Accuracy of benign keratosis-like lesions : 77 % Accuracy of dermatofibroma : 69 % Accuracy of melanoma : 79 % Accuracy of melanocytic nevi : 88 % Accuracy of vascular lesions : 0 % Confusion Matrix confusion_matrix = torch . zeros ( len ( classes ), len ( classes )) with torch . no_grad (): for data in test_data_loader : images , labels = data images , labels = images . to ( device ), labels . to ( device ) outputs = net ( images ) _ , predicted = torch . max ( outputs , 1 ) for t , p in zip ( labels . view ( - 1 ), predicted . view ( - 1 )): confusion_matrix [ t . long (), p . long ()] += 1 print ( confusion_matrix ) cm = confusion_matrix . numpy () tensor([[6.0000e+01, 2.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00], [0.0000e+00, 1.0200e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00], [2.0000e+00, 0.0000e+00, 2.0700e+02, 0.0000e+00, 5.0000e+00, 6.0000e+00, 0.0000e+00], [1.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+01, 1.0000e+00, 1.0000e+00, 0.0000e+00], [0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 2.1400e+02, 7.0000e+00, 0.0000e+00], [3.0000e+00, 5.0000e+00, 3.8000e+01, 1.0000e+00, 1.7500e+02, 1.1190e+03, 0.0000e+00], [0.0000e+00, 9.0000e+00, 1.0000e+00, 0.0000e+00, 8.0000e+00, 1.0000e+01, 0.0000e+00]]) fig , ax = plt . subplots ( figsize = ( 7 , 7 )) sns . heatmap ( cm / ( cm . astype ( np . float ) . sum ( axis = 1 ) + 1e-9 ), annot = False , ax = ax ) # labels, title and ticks ax . set_xlabel ( 'Predicted' , size = 25 ); ax . set_ylabel ( 'True' , size = 25 ); ax . set_title ( 'Confusion Matrix' , size = 25 ); ax . xaxis . set_ticklabels ([ 'akiec' , 'bcc' , 'bkl' , 'df' , 'mel' , 'nv' , 'vasc' ], size = 15 ); \\ ax . yaxis . set_ticklabels ([ 'akiec' , 'bcc' , 'bkl' , 'df' , 'mel' , 'nv' , 'vasc' ], size = 15 ); Grad cam from collections import OrderedDict , Sequence class _BaseWrapper ( object ): \"\"\" Please modify forward() and backward() according to your task. \"\"\" def __init__ ( self , model ): super ( _BaseWrapper , self ) . __init__ () self . device = next ( model . parameters ()) . device self . model = model self . handlers = [] # a set of hook function handlers def _encode_one_hot ( self , ids ): one_hot = torch . zeros_like ( self . logits ) . to ( self . device ) one_hot . scatter_ ( 1 , ids , 1.0 ) return one_hot def forward ( self , image ): \"\"\" Simple classification \"\"\" self . model . zero_grad () self . logits = self . model ( image ) self . probs = F . softmax ( self . logits , dim = 1 ) return self . probs . sort ( dim = 1 , descending = True ) def backward ( self , ids ): \"\"\" Class-specific backpropagation Either way works: 1. self.logits.backward(gradient=one_hot, retain_graph=True) 2. (self.logits * one_hot).sum().backward(retain_graph=True) \"\"\" one_hot = self . _encode_one_hot ( ids ) self . logits . backward ( gradient = one_hot , retain_graph = True ) def generate ( self ): raise NotImplementedError def remove_hook ( self ): \"\"\" Remove all the forward/backward hook functions \"\"\" for handle in self . handlers : handle . remove () class GradCAM ( _BaseWrapper ): \"\"\" \"Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization\" https://arxiv.org/pdf/1610.02391.pdf Look at Figure 2 on page 4 \"\"\" def __init__ ( self , model , candidate_layers = None ): super ( GradCAM , self ) . __init__ ( model ) self . fmap_pool = OrderedDict () self . grad_pool = OrderedDict () self . candidate_layers = candidate_layers # list def forward_hook ( key ): def forward_hook_ ( module , input , output ): # Save featuremaps self . fmap_pool [ key ] = output . detach () return forward_hook_ def backward_hook ( key ): def backward_hook_ ( module , grad_in , grad_out ): # Save the gradients correspond to the featuremaps self . grad_pool [ key ] = grad_out [ 0 ] . detach () return backward_hook_ # If any candidates are not specified, the hook is registered to all the layers. for name , module in self . model . named_modules (): if self . candidate_layers is None or name in self . candidate_layers : self . handlers . append ( module . register_forward_hook ( forward_hook ( name ))) self . handlers . append ( module . register_backward_hook ( backward_hook ( name ))) def _find ( self , pool , target_layer ): if target_layer in pool . keys (): return pool [ target_layer ] else : raise ValueError ( \"Invalid layer name: {} \" . format ( target_layer )) def _compute_grad_weights ( self , grads ): return F . adaptive_avg_pool2d ( grads , 1 ) def forward ( self , image ): self . image_shape = image . shape [ 2 :] return super ( GradCAM , self ) . forward ( image ) def generate ( self , target_layer ): fmaps = self . _find ( self . fmap_pool , target_layer ) grads = self . _find ( self . grad_pool , target_layer ) weights = self . _compute_grad_weights ( grads ) gcam = torch . mul ( fmaps , weights ) . sum ( dim = 1 , keepdim = True ) gcam = F . relu ( gcam ) gcam = F . interpolate ( gcam , self . image_shape , mode = \"bilinear\" , align_corners = False ) B , C , H , W = gcam . shape gcam = gcam . view ( B , - 1 ) gcam -= gcam . min ( dim = 1 , keepdim = True )[ 0 ] gcam /= gcam . max ( dim = 1 , keepdim = True )[ 0 ] gcam = gcam . view ( B , C , H , W ) return gcam def demo2 ( image , label , model ): \"\"\" Generate Grad-CAM \"\"\" # Model model = model model . to ( device ) model . eval () # The layers target_layers = [ \"layer4\" ] target_class = label # Images images = image . unsqueeze ( 0 ) gcam = GradCAM ( model = model ) probs , ids = gcam . forward ( images ) ids_ = torch . LongTensor ([[ target_class ]] * len ( images )) . to ( device ) gcam . backward ( ids = ids_ ) for target_layer in target_layers : print ( \"Generating Grad-CAM @ {} \" . format ( target_layer )) # Grad-CAM regions = gcam . generate ( target_layer = target_layer ) for j in range ( len ( images )): print ( \" \\t # {} : {} ( {:.5f} )\" . format ( j , classes [ target_class ], float ( probs [ ids == target_class ]) ) ) gcam = regions [ j , 0 ] plt . imshow ( gcam . cpu ()) plt . show () image , label = next ( iter ( test_data_loader )) # Load the model model = net # Grad cam demo2 ( image [ 0 ] . to ( device ), label [ 0 ] . to ( device ), model ) image = np . transpose ( image [ 0 ], ( 1 , 2 , 0 )) image2 = np . add ( np . multiply ( image . numpy (), np . array ( norm_std )) , np . array ( norm_mean )) print ( \"True Class: \" , classes [ label [ 0 ] . cpu ()]) plt . imshow ( image ) plt . show () plt . imshow ( image2 ) plt . show () Generating Grad-CAM @layer4 #0: melanocytic nevi (0.76489) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). True Class: melanocytic nevi Conclusion Training a neural network can be a daunting task, especially for a beginner. Here, are some useful practices to get the best out of your network. Training Ensembles \u2014 Combine learning from multiple networks. Always go for a lower learning rate. In cases of limited data try better augmentation techniques[20]. Network architectures that have the appropriate depth for our problem \u2014 too many hyperparameters could lead to suboptimal results if we don\u2019t have enough images. Improving loss function and class balancing. In this tutorial we learned how to train a deep neural network for the challenging task of skin-lesion classification. We experimented with two network architectures and provided insights in the attention of the models. Additionally, we achieved 83% overall accuracy on HAM10000 and provided you with more tips and tricks to tackle overfitting and class imbalance. Now you have all the tools to not only beat our performance and participate in the exciting MICCAI Challenges, but to also solve many more medical imaging problems. Happy training!","title":"SkinLesionClassification"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#skin-cancer-classification-an-educational-guide","text":"In this tutorial we aim to provide a simple step-by-step guide to anyone who wants to work on the problem of skin lesion classification regardless of their level or expertise; from medical doctors, to master students and more experienced researchers.","title":"Skin Cancer Classification - An Educational Guide"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#using-this-guide-you-will-learn","text":"How to load the data, visualise it and uncover more about the class distribution and meta-data. How to utilise architectures with varying complexity from a few convolutional layers to hundreds of them. How to train a model with appropriate optimisers and loss functions. How to rigorously test your trained model, providing not only metrics such as accuracy but also visualisations like confusion matrix and Grad \u2014 Cam. How to analyse and understand your results. To conclude with, we will provide a few more tips that are usually utilised by the participants of the ISIC Challenges, that will help you increase your model\u2019s performance even more so that you can beat our performance and explore more advanced training schemes.","title":"Using this guide you will learn:"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#httpsgithubcomifl-campslclassificationaneducationalcode-mec2019","text":"# !pip install imageio # !pip install scikit-image import torch from torch import nn import torch.nn.functional as F import torchvision import torchvision.transforms as transforms import numpy as np import os import numpy as np import pandas as pd from sklearn.model_selection import train_test_split from sklearn.metrics import confusion_matrix , precision_recall_fscore_support import scipy.ndimage from scipy import misc from glob import glob from scipy import stats from sklearn.preprocessing import LabelEncoder , StandardScaler import skimage import imageio import seaborn as sns from PIL import Image import glob import matplotlib.pyplot as plt import matplotlib % matplotlib inline device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) device --------------------------------------------------------------------------- ModuleNotFoundError Traceback (most recent call last) <ipython-input-3-5b38befe3f1d> in <module> 18 import skimage 19 import imageio ---> 20 import seaborn as sns 21 from PIL import Image 22 import glob ModuleNotFoundError: No module named 'seaborn'","title":"https://github.com/IFL-CAMP/SLClassificationAnEducationalCode-MEC2019"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#what-about-data","text":"The HAM10000 (\"Human Against Machine with 10000 training images\") dataset which contains 10,015 dermatoscopic images was made publically available by the Harvard database on June 2018 in the hopes to provide training data for automating the process of skin cancer lesion classifications. The motivation behind this act was to provide the public with an abundance and variability of data source for machine learning training purposes such that the results may be compared with that of human experts. If successful, the appplications would bring cost and time saving regimes to hospitals and medical professions alike. Apart from the 10,015 images, a metadata file with demographic information of each lesion is provided as well. More than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal) You can download the dataset here: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T The 7 classes of skin cancer lesions included in this dataset are: Melanocytic nevi Melanoma Benign keratosis-like lesions Basal cell carcinoma Actinic keratoses Vascular lesions Dermatofibroma","title":"What about data?"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#lets-analyze-the-metadata-of-the-dataset","text":"# importing metadata and checking for its shape data_dir = \"/data/HAM10000\" metadata = pd . read_csv ( data_dir + '/HAM10000_metadata.csv' ) print ( metadata . shape ) # label encoding the seven classes for skin cancers le = LabelEncoder () le . fit ( metadata [ 'dx' ]) LabelEncoder () print ( \"Classes:\" , list ( le . classes_ )) metadata [ 'label' ] = le . transform ( metadata [ \"dx\" ]) metadata . sample ( 10 ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-2-3d00b7e51bd3> in <module> 2 data_dir = \"/data/HAM10000\" 3 ----> 4 metadata = pd.read_csv(data_dir + '/HAM10000_metadata.csv') 5 print(metadata.shape) 6 NameError: name 'pd' is not defined # Getting a sense of what the distribution of each column looks like fig = plt . figure ( figsize = ( 40 , 25 )) ax1 = fig . add_subplot ( 221 ) metadata [ 'dx' ] . value_counts () . plot ( kind = 'bar' , ax = ax1 ) ax1 . set_ylabel ( 'Count' , size = 50 ) ax1 . set_title ( 'Cell Type' , size = 50 ) ax2 = fig . add_subplot ( 222 ) metadata [ 'sex' ] . value_counts () . plot ( kind = 'bar' , ax = ax2 ) ax2 . set_ylabel ( 'Count' , size = 50 ) ax2 . set_title ( 'Sex' , size = 50 ); ax3 = fig . add_subplot ( 223 ) metadata [ 'localization' ] . value_counts () . plot ( kind = 'bar' ) ax3 . set_ylabel ( 'Count' , size = 50 ) ax3 . set_title ( 'Localization' , size = 50 ) ax4 = fig . add_subplot ( 224 ) sample_age = metadata [ pd . notnull ( metadata [ 'age' ])] sns . distplot ( sample_age [ 'age' ], fit = stats . norm , color = 'red' ); ax4 . set_title ( 'Age' , size = 50 ) ax4 . set_xlabel ( 'Year' , size = 50 ) plt . tight_layout () plt . show () As you can see there is imbalance in the number of images per class. There are much more images for the lesion type \"Melanocytic Nevi\" compared to other types. This is an usual occurence for medical datasets and so it is very important to analyze the data from beforehand.","title":"Let's analyze the metadata of the dataset"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#lets-visualize-some-examples","text":"#Visualizing the images label = [ 'akiec' , 'bcc' , 'bkl' , 'df' , 'mel' , 'nv' , 'vasc' ] label_images = [] classes = [ 'actinic keratoses' , 'basal cell carcinoma' , 'benign keratosis-like lesions' , 'dermatofibroma' , 'melanoma' , 'melanocytic nevi' , 'vascular lesions' ] fig = plt . figure ( figsize = ( 55 , 55 )) k = range ( 7 ) for i in label : sample = metadata [ metadata [ 'dx' ] == i ][ 'image_id' ][: 5 ] label_images . extend ( sample ) for position , ID in enumerate ( label_images ): labl = metadata [ metadata [ 'image_id' ] == ID ][ 'dx' ] im_sample = data_dir + \"/\" + labl . values [ 0 ] + f '/ { ID } .jpg' im_sample = imageio . imread ( im_sample ) plt . subplot ( 7 , 5 , position + 1 ) plt . imshow ( im_sample ) plt . axis ( 'off' ) if position % 5 == 0 : title = int ( position / 5 ) plt . title ( classes [ title ], loc = 'left' , size = 50 , weight = \"bold\" ) plt . tight_layout () plt . show ()","title":"Let's visualize some examples"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#median-frequency-balancing","text":"As we saw above that there is class imbalance in our dataset. To solve that we use this method. #print(metadata['dx'].value_counts()) #print(metadata[metadata['dx']=='nv']['dx'].value_counts()) label = [ 'akiec' , 'bcc' , 'bkl' , 'df' , 'mel' , 'nv' , 'vasc' ] def estimate_weights_mfb ( label ): class_weights = np . zeros_like ( label , dtype = np . float ) counts = np . zeros_like ( label ) for i , l in enumerate ( label ): counts [ i ] = metadata [ metadata [ 'dx' ] == str ( l )][ 'dx' ] . value_counts ()[ 0 ] counts = counts . astype ( np . float ) #print(counts) median_freq = np . median ( counts ) #print(median_freq) #print(weights.shape) for i , label in enumerate ( label ): #print(label) class_weights [ i ] = median_freq / counts [ i ] return class_weights classweight = estimate_weights_mfb ( label ) for i in range ( len ( label )): print ( label [ i ], \":\" , classweight [ i ]) akiec : 1.5718654434250765 bcc : 1.0 bkl : 0.467697907188353 df : 4.469565217391304 mel : 0.4618149146451033 nv : 0.07665920954511558 vasc : 3.619718309859155","title":"Median Frequency Balancing"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#pre-processing-the-dataset","text":"Before we load the data we need to alter the dataset structure. When you download the dataset, all the images are together in a folder. To use Pytorch dataloader we need to seggregrate the images into folders of their respetive labels. You can use the following script to automate the process. # import os # import shutil # data_dir = os.getcwd() + \"/HAM10000/\" # dest_dir = data_dir + \"test/\" # metadata = pd.read_csv(data_dir + '/HAM10000_metadata.csv') # label = ['bkl', 'nv', 'df', 'mel', 'vasc', 'bcc', 'akiec'] # label_images = [] # for i in label: # os.mkdir(dest_dir + str(i) + \"/\") # sample = metadata[metadata['dx'] == i]['image_id'][:5] # label_images.extend(sample) # for id in label_images: # shutil.copyfile((data_dir + i + \"/\"+ id +\".jpg\"), (dest_dir + i + \"/\"+id+\".jpg\")) # label_images=[]","title":"Pre-processing the dataset"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#data-augmentation","text":"It is a common fact that medical data is scarce. But to learn a very good model, the network needs a lot of data. So to tackle the problem we perform data augmentation. First we normalize the images. Data normalization is an important step which ensures that each input parameter (pixel, in this case) has a similar data distribution. This makes convergence faster while training the network. Data normalization is done by subtracting the mean from each pixel and then dividing the result by the standard deviation. The distribution of such data would resemble a Gaussian curve centered at zero. Since, skin lesion images are natural images, we use the normalization values (mean and standard deviation) of Imagenet dataset. We also perform data augmentation: - Flipping the image horizontally: RandomHorizontalFlip() - Rotating image 60 degrees: RandomRotation() . 60 degrees is chosen as best practice. You can experiment with other angles. The augmentation is applied using the transform.Compose() function of Pytorch. Take note, we only augment the training set. This is because, augmentation is done to aid the training process. So there is no point in augmenting the test set. data_dir = \"/data/HAM10000\" # normalization values for pretrained resnet on Imagenet norm_mean = ( 0.4914 , 0.4822 , 0.4465 ) norm_std = ( 0.2023 , 0.1994 , 0.2010 ) batch_size = 50 validation_batch_size = 10 test_batch_size = 10 # We compute the weights of individual classes and convert them to tensors class_weights = estimate_weights_mfb ( label ) class_weights = torch . FloatTensor ( class_weights ) transform_train = transforms . Compose ([ transforms . Resize (( 224 , 224 )), transforms . RandomHorizontalFlip (), transforms . RandomRotation ( degrees = 60 ), transforms . ToTensor (), transforms . Normalize ( norm_mean , norm_std ), ]) transform_test = transforms . Compose ([ transforms . Resize (( 224 , 224 )), transforms . ToTensor (), transforms . Normalize (( 0.4914 , 0.4822 , 0.4465 ), ( 0.2023 , 0.1994 , 0.2010 )), ])","title":"Data Augmentation"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#train-test-and-validation-split","text":"We split the entire dataset into 3 parts: - Train: 80% - Test: 20% - Validation: 16% The splitting is done class wise so that we have equal representation of all classes in each subset of the data. import torch as th import math test_size = 0.2 val_size = 0.2 class Sampler ( object ): \"\"\"Base class for all Samplers. \"\"\" def __init__ ( self , data_source ): pass def __iter__ ( self ): raise NotImplementedError def __len__ ( self ): raise NotImplementedError class StratifiedSampler ( Sampler ): \"\"\"Stratified Sampling Provides equal representation of target classes \"\"\" def __init__ ( self , class_vector ): \"\"\" Arguments --------- class_vector : torch tensor a vector of class labels batch_size : integer batch_size \"\"\" self . n_splits = 1 self . class_vector = class_vector self . test_size = test_size def gen_sample_array ( self ): try : from sklearn.model_selection import StratifiedShuffleSplit except : print ( 'Need scikit-learn for this functionality' ) import numpy as np s = StratifiedShuffleSplit ( n_splits = self . n_splits , test_size = self . test_size ) X = th . randn ( self . class_vector . size ( 0 ), 2 ) . numpy () y = self . class_vector . numpy () s . get_n_splits ( X , y ) train_index , test_index = next ( s . split ( X , y )) return train_index , test_index def __iter__ ( self ): return iter ( self . gen_sample_array ()) def __len__ ( self ): return len ( self . class_vector ) dataset = torchvision . datasets . ImageFolder ( root = data_dir ) data_label = [ s [ 1 ] for s in dataset . samples ] ss = StratifiedSampler ( torch . FloatTensor ( data_label ), test_size ) pre_train_indices , test_indices = ss . gen_sample_array () # The \"pre\" is necessary to use array to identify train/ val indices with indices generated by second sampler train_label = np . delete ( data_label , test_indices , None ) ss = StratifiedSampler ( torch . FloatTensor ( train_label ), test_size ) train_indices , val_indices = ss . gen_sample_array () indices = { 'train' : pre_train_indices [ train_indices ], # Indices of second sampler are used on pre_train_indices 'val' : pre_train_indices [ val_indices ], # Indices of second sampler are used on pre_train_indices 'test' : test_indices } train_indices = indices [ 'train' ] val_indices = indices [ 'val' ] test_indices = indices [ 'test' ] print ( \"Train Data Size:\" , len ( train_indices )) print ( \"Test Data Size:\" , len ( test_indices )) print ( \"Validation Data Size:\" , len ( val_indices )) Train Data Size: 6409 Test Data Size: 2003 Validation Data Size: 1603 Now we use Pytorch data loader to load the dataset into the memory. SubsetRandomSampler = torch . utils . data . sampler . SubsetRandomSampler dataset = torchvision . datasets . ImageFolder ( root = data_dir , transform = transform_train ) train_samples = SubsetRandomSampler ( train_indices ) val_samples = SubsetRandomSampler ( val_indices ) test_samples = SubsetRandomSampler ( test_indices ) train_data_loader = torch . utils . data . DataLoader ( dataset , batch_size = batch_size , shuffle = False , num_workers = 1 , sampler = train_samples ) validation_data_loader = torch . utils . data . DataLoader ( dataset , batch_size = validation_batch_size , shuffle = False , sampler = val_samples ) dataset = torchvision . datasets . ImageFolder ( root = data_dir , transform = transform_test ) test_data_loader = torch . utils . data . DataLoader ( dataset , batch_size = test_batch_size , shuffle = False , sampler = test_samples ) Let us see some of the training images. # functions to show an image fig = plt . figure ( figsize = ( 10 , 15 )) def imshow ( img ): img = img / 2 + 0.5 # denormalize change this npimg = img . numpy () plt . imshow ( np . transpose ( npimg , ( 1 , 2 , 0 ))) # get some random training images dataiter = iter ( train_data_loader ) images , labels = dataiter . next () # show images imshow ( torchvision . utils . make_grid ( images )) # print labels print ( ' ' . join ( ' %5s , ' % classes [ labels [ j ]] for j in range ( len ( labels )))) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). melanocytic nevi, actinic keratoses, benign keratosis-like lesions, benign keratosis-like lesions, melanocytic nevi, melanocytic nevi, basal cell carcinoma, melanocytic nevi, melanocytic nevi, benign keratosis-like lesions, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, benign keratosis-like lesions, melanocytic nevi, melanoma, melanocytic nevi, melanocytic nevi, melanoma, melanoma, melanocytic nevi, actinic keratoses, melanocytic nevi, actinic keratoses, melanocytic nevi, melanocytic nevi, melanoma, melanocytic nevi, melanoma, melanoma, melanocytic nevi, melanoma, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanocytic nevi, melanoma, melanocytic nevi, melanocytic nevi, melanocytic nevi, dermatofibroma, basal cell carcinoma, basal cell carcinoma,","title":"Train, Test and Validation Split"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#define-a-convolutional-neural-network","text":"Pytorch makes it very easy to define a neural network. We have layers like Convolutions, ReLU non-linearity, Maxpooling etc. directly from torch library. In this tutorial, we use The LeNet architecture introduced by LeCun et al. in their 1998 paper, Gradient-Based Learning Applied to Document Recognition . As the name of the paper suggests, the authors\u2019 implementation of LeNet was used primarily for OCR and character recognition in documents. The LeNet architecture is straightforward and small, (in terms of memory footprint), making it perfect for teaching the basics of CNNs. num_classes = len ( classes ) class LeNet ( nn . Module ): def __init__ ( self ): super ( LeNet , self ) . __init__ () self . conv1 = nn . Conv2d ( 3 , 6 , ( 5 , 5 ), padding = 2 ) self . conv2 = nn . Conv2d ( 6 , 16 , ( 5 , 5 )) self . fc1 = nn . Linear ( 16 * 54 * 54 , 120 ) self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , num_classes ) def forward ( self , x ): x = F . max_pool2d ( F . relu ( self . conv1 ( x )), ( 2 , 2 )) x = F . max_pool2d ( F . relu ( self . conv2 ( x )), ( 2 , 2 )) x = x . view ( - 1 , self . num_flat_features ( x )) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x def num_flat_features ( self , x ): size = x . size ()[ 1 :] num_features = 1 for s in size : num_features *= s return num_features net = LeNet () net = net . to ( device )","title":"Define a Convolutional Neural Network"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#define-a-loss-function-and-optimizer","text":"Let's use a Classification Cross-Entropy loss. \\(H_{y'} (y) := - \\sum_{i} y_{i}' \\log (y_i)\\) The most common and effective Optimizer currently used is Adam: Adaptive Moments . You can look here for more information. import torch.optim as optim class_weights = class_weights . to ( device ) criterion = nn . CrossEntropyLoss ( weight = class_weights ) optimizer = optim . Adam ( net . parameters (), lr = 1e-5 ) print ( net ) LeNet( (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=46656, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=7, bias=True) ) These are some helper functions to evaluate the training process. from sklearn.metrics import accuracy_score def get_accuracy ( predicted , labels ): batch_len , correct = 0 , 0 batch_len = labels . size ( 0 ) correct = ( predicted == labels ) . sum () . item () return batch_len , correct def evaluate ( model , val_loader ): losses = 0 num_samples_total = 0 correct_total = 0 model . eval () for inputs , labels in val_loader : inputs , labels = inputs . to ( device ), labels . to ( device ) out = model ( inputs ) _ , predicted = torch . max ( out , 1 ) loss = criterion ( out , labels ) losses += loss . item () b_len , corr = get_accuracy ( predicted , labels ) num_samples_total += b_len correct_total += corr accuracy = correct_total / num_samples_total losses = losses / len ( val_loader ) return losses , accuracy","title":"Define a Loss function and Optimizer"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#train-the-network","text":"This is when things start to get interesting. We simply loop over the training data iterator, and feed the inputs to the network and optimize. # number of loops over the dataset num_epochs = 50 accuracy = [] val_accuracy = [] losses = [] val_losses = [] for epoch in range ( num_epochs ): running_loss = 0.0 correct_total = 0.0 num_samples_total = 0.0 for i , data in enumerate ( train_data_loader ): # get the inputs inputs , labels = data inputs , labels = inputs . to ( device ), labels . to ( device ) # set the parameter gradients to zero optimizer . zero_grad () # forward + backward + optimize outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () #compute accuracy _ , predicted = torch . max ( outputs , 1 ) b_len , corr = get_accuracy ( predicted , labels ) num_samples_total += b_len correct_total += corr running_loss += loss . item () running_loss /= len ( train_data_loader ) train_accuracy = correct_total / num_samples_total val_loss , val_acc = evaluate ( net , validation_data_loader ) print ( 'Epoch: %d ' % ( epoch + 1 )) print ( 'Loss: %.3f Accuracy: %.3f ' % ( running_loss , train_accuracy )) print ( 'Validation Loss: %.3f Val Accuracy: %.3f ' % ( val_loss , val_acc )) losses . append ( running_loss ) val_losses . append ( val_loss ) accuracy . append ( train_accuracy ) val_accuracy . append ( val_acc ) print ( 'Finished Training' ) Epoch: 1 Loss: 1.806 Accuracy:0.314 Validation Loss: 1.727 Val Accuracy: 0.403 Epoch: 2 Loss: 1.663 Accuracy:0.371 Validation Loss: 1.631 Val Accuracy: 0.419 Epoch: 3 Loss: 1.589 Accuracy:0.459 Validation Loss: 1.565 Val Accuracy: 0.451 Epoch: 4 Loss: 1.542 Accuracy:0.486 Validation Loss: 1.558 Val Accuracy: 0.431 Epoch: 5 Loss: 1.499 Accuracy:0.494 Validation Loss: 1.483 Val Accuracy: 0.500 Epoch: 6 Loss: 1.472 Accuracy:0.500 Validation Loss: 1.457 Val Accuracy: 0.525 Epoch: 7 Loss: 1.447 Accuracy:0.509 Validation Loss: 1.454 Val Accuracy: 0.498 Epoch: 9 Loss: 1.421 Accuracy:0.503 Validation Loss: 1.406 Val Accuracy: 0.527 Epoch: 10 Loss: 1.399 Accuracy:0.516 Validation Loss: 1.413 Val Accuracy: 0.530 Epoch: 11 Loss: 1.390 Accuracy:0.519 Validation Loss: 1.436 Val Accuracy: 0.496 Epoch: 12 Loss: 1.384 Accuracy:0.519 Validation Loss: 1.396 Val Accuracy: 0.505 Epoch: 13 Loss: 1.373 Accuracy:0.529 Validation Loss: 1.391 Val Accuracy: 0.525 Epoch: 14 Loss: 1.363 Accuracy:0.534 Validation Loss: 1.376 Val Accuracy: 0.518 Epoch: 15 Loss: 1.364 Accuracy:0.531 Validation Loss: 1.365 Val Accuracy: 0.536 Epoch: 16 Loss: 1.352 Accuracy:0.534 Validation Loss: 1.363 Val Accuracy: 0.548 Epoch: 17 Loss: 1.337 Accuracy:0.536 Validation Loss: 1.365 Val Accuracy: 0.532 Epoch: 18 Loss: 1.333 Accuracy:0.540 Validation Loss: 1.340 Val Accuracy: 0.527 Epoch: 19 Loss: 1.327 Accuracy:0.542 Validation Loss: 1.333 Val Accuracy: 0.530 Epoch: 20 Loss: 1.320 Accuracy:0.537 Validation Loss: 1.304 Val Accuracy: 0.558 Epoch: 21 Loss: 1.303 Accuracy:0.555 Validation Loss: 1.373 Val Accuracy: 0.490 Epoch: 23 Loss: 1.293 Accuracy:0.550 Validation Loss: 1.348 Val Accuracy: 0.530 Epoch: 24 Loss: 1.308 Accuracy:0.554 Validation Loss: 1.344 Val Accuracy: 0.558 Epoch: 25 Loss: 1.288 Accuracy:0.559 Validation Loss: 1.329 Val Accuracy: 0.552 Epoch: 26 Loss: 1.288 Accuracy:0.558 Validation Loss: 1.321 Val Accuracy: 0.533 Epoch: 27 Loss: 1.295 Accuracy:0.560 Validation Loss: 1.310 Val Accuracy: 0.558 Epoch: 28 Loss: 1.290 Accuracy:0.562 Validation Loss: 1.303 Val Accuracy: 0.534 Epoch: 29 Loss: 1.278 Accuracy:0.560 Validation Loss: 1.315 Val Accuracy: 0.522 Epoch: 30 Loss: 1.280 Accuracy:0.559 Validation Loss: 1.318 Val Accuracy: 0.540 Epoch: 31 Loss: 1.266 Accuracy:0.561 Validation Loss: 1.284 Val Accuracy: 0.540 Epoch: 32 Loss: 1.275 Accuracy:0.565 Validation Loss: 1.289 Val Accuracy: 0.562 Epoch: 33 Loss: 1.259 Accuracy:0.575 Validation Loss: 1.284 Val Accuracy: 0.585 Epoch: 34 Loss: 1.268 Accuracy:0.561 Validation Loss: 1.313 Val Accuracy: 0.530 Epoch: 35 Loss: 1.257 Accuracy:0.574 Validation Loss: 1.328 Val Accuracy: 0.520 Epoch: 36 Loss: 1.254 Accuracy:0.569 Validation Loss: 1.288 Val Accuracy: 0.555 Epoch: 37 Loss: 1.259 Accuracy:0.574 Validation Loss: 1.289 Val Accuracy: 0.566 Epoch: 38 Loss: 1.251 Accuracy:0.576 Validation Loss: 1.319 Val Accuracy: 0.513 Epoch: 39 Loss: 1.248 Accuracy:0.572 Validation Loss: 1.276 Val Accuracy: 0.571 Epoch: 40 Loss: 1.253 Accuracy:0.582 Validation Loss: 1.300 Val Accuracy: 0.533 Epoch: 41 Loss: 1.236 Accuracy:0.570 Validation Loss: 1.288 Val Accuracy: 0.563 Epoch: 42 Loss: 1.246 Accuracy:0.572 Validation Loss: 1.263 Val Accuracy: 0.564 Epoch: 43 Loss: 1.240 Accuracy:0.581 Validation Loss: 1.332 Val Accuracy: 0.520 Epoch: 44 Loss: 1.253 Accuracy:0.573 Validation Loss: 1.311 Val Accuracy: 0.528 Epoch: 45 Loss: 1.229 Accuracy:0.579 Validation Loss: 1.266 Val Accuracy: 0.558 Epoch: 46 Loss: 1.221 Accuracy:0.585 Validation Loss: 1.264 Val Accuracy: 0.553 Epoch: 47 Loss: 1.232 Accuracy:0.586 Validation Loss: 1.258 Val Accuracy: 0.561 Epoch: 48 Loss: 1.236 Accuracy:0.582 Validation Loss: 1.255 Val Accuracy: 0.588 Epoch: 49 Loss: 1.224 Accuracy:0.583 Validation Loss: 1.258 Val Accuracy: 0.581 Epoch: 50 Loss: 1.234 Accuracy:0.582 Validation Loss: 1.261 Val Accuracy: 0.560 Finished Training Plot the training and validation loss curves. # plt.plot(losses) # plt.show() epoch = range ( 1 , num_epochs + 1 ) fig = plt . figure ( figsize = ( 10 , 15 )) plt . subplot ( 2 , 1 , 2 ) plt . plot ( epoch , losses , label = 'Training loss' ) plt . plot ( epoch , val_losses , label = 'Validation loss' ) plt . title ( 'Training and Validation Loss' ) plt . xlabel ( 'Epochs' ) plt . legend () plt . figure () plt . show () fig = plt . figure ( figsize = ( 10 , 15 )) plt . subplot ( 2 , 1 , 2 ) plt . plot ( epoch , accuracy , label = 'Training accuracy' ) plt . plot ( epoch , val_accuracy , label = 'Validation accuracy' ) plt . title ( 'Training and Validation Accuracy' ) plt . xlabel ( 'Epochs' ) plt . legend () plt . figure () plt . show () <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes>","title":"Train the network"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#test-the-network-on-the-test-data","text":"We have trained the network over the training dataset. But we need to check if the network has learnt anything at all. We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions. Okay, first step. Let us display an image from the test set to get familiar. fig = plt . figure ( figsize = ( 10 , 15 )) dataiter = iter ( test_data_loader ) images , labels = dataiter . next () # print images imshow ( torchvision . utils . make_grid ( images )) print ( 'GroundTruth: ' , ' ' . join ( ' %5s , ' % classes [ labels [ j ]] for j in range ( len ( labels )))) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). GroundTruth: melanocytic nevi, benign keratosis-like lesions, melanocytic nevi, melanoma, melanocytic nevi, benign keratosis-like lesions, melanocytic nevi, melanoma, benign keratosis-like lesions, melanocytic nevi, Okay, now let us check the performance on the test network: correct = 0 total = 0 net . eval () with torch . no_grad (): for data in test_data_loader : images , labels = data images , labels = images . to ( device ), labels . to ( device ) outputs = net ( images ) _ , predicted = torch . max ( outputs . data , 1 ) total += labels . size ( 0 ) correct += ( predicted == labels ) . sum () . item () print ( 'Accuracy of the network on the test images: %d %% ' % ( 100 * correct / total )) Accuracy of the network on the test images: 52 % That looks better than chance, which is about 14% accuracy (randomly picking a class out of 7 classes). Seems like the network learnt something. But maybe it doesn't learn all the classes equally. Let's check which classes that performed well, and which did not. class_correct = list ( 0. for i in range ( len ( classes ))) class_total = list ( 1e-7 for i in range ( len ( classes ))) with torch . no_grad (): for data in test_data_loader : images , labels = data images , labels = images . to ( device ), labels . to ( device ) outputs = net ( images ) _ , predicted = torch . max ( outputs , 1 ) c = ( predicted == labels ) . squeeze () for i in range ( 3 ): label = labels [ i ] class_correct [ label ] += c [ i ] . item () class_total [ label ] += 1 for i in range ( len ( classes )): print ( 'Accuracy of %5s : %2d %% ' % ( classes [ i ], 100 * class_correct [ i ] / class_total [ i ])) Accuracy of actinic keratoses : 27 % Accuracy of basal cell carcinoma : 76 % Accuracy of benign keratosis-like lesions : 4 % Accuracy of dermatofibroma : 39 % Accuracy of melanoma : 73 % Accuracy of melanocytic nevi : 58 % Accuracy of vascular lesions : 0 %","title":"Test the network on the test data"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#confusion-matrix","text":"confusion_matrix = torch . zeros ( len ( classes ), len ( classes )) with torch . no_grad (): for data in test_data_loader : images , labels = data images , labels = images . to ( device ), labels . to ( device ) outputs = net ( images ) _ , predicted = torch . max ( outputs , 1 ) for t , p in zip ( labels . view ( - 1 ), predicted . view ( - 1 )): confusion_matrix [ t . long (), p . long ()] += 1 cm = confusion_matrix . numpy () fig , ax = plt . subplots ( figsize = ( 7 , 7 )) sns . heatmap ( cm / ( cm . astype ( np . float ) . sum ( axis = 1 ) + 1e-9 ), annot = False , ax = ax ) # labels, title and ticks ax . set_xlabel ( 'Predicted' , size = 25 ); ax . set_ylabel ( 'True' , size = 25 ); ax . set_title ( 'Confusion Matrix' , size = 25 ); ax . xaxis . set_ticklabels ([ 'akiec' , 'bcc' , 'bkl' , 'df' , 'mel' , 'nv' , 'vasc' ], size = 15 ); \\ ax . yaxis . set_ticklabels ([ 'akiec' , 'bcc' , 'bkl' , 'df' , 'mel' , 'nv' , 'vasc' ], size = 15 );","title":"Confusion Matrix"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#grad-cam","text":"from collections import OrderedDict , Sequence class _BaseWrapper ( object ): \"\"\" Please modify forward() and backward() according to your task. \"\"\" def __init__ ( self , model ): super ( _BaseWrapper , self ) . __init__ () self . device = next ( model . parameters ()) . device self . model = model self . handlers = [] # a set of hook function handlers def _encode_one_hot ( self , ids ): one_hot = torch . zeros_like ( self . logits ) . to ( self . device ) one_hot . scatter_ ( 1 , ids , 1.0 ) return one_hot def forward ( self , image ): \"\"\" Simple classification \"\"\" self . model . zero_grad () self . logits = self . model ( image ) self . probs = F . softmax ( self . logits , dim = 1 ) return self . probs . sort ( dim = 1 , descending = True ) def backward ( self , ids ): \"\"\" Class-specific backpropagation Either way works: 1. self.logits.backward(gradient=one_hot, retain_graph=True) 2. (self.logits * one_hot).sum().backward(retain_graph=True) \"\"\" one_hot = self . _encode_one_hot ( ids ) self . logits . backward ( gradient = one_hot , retain_graph = True ) def generate ( self ): raise NotImplementedError def remove_hook ( self ): \"\"\" Remove all the forward/backward hook functions \"\"\" for handle in self . handlers : handle . remove () class GradCAM ( _BaseWrapper ): \"\"\" \"Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization\" https://arxiv.org/pdf/1610.02391.pdf Look at Figure 2 on page 4 \"\"\" def __init__ ( self , model , candidate_layers = None ): super ( GradCAM , self ) . __init__ ( model ) self . fmap_pool = OrderedDict () self . grad_pool = OrderedDict () self . candidate_layers = candidate_layers # list def forward_hook ( key ): def forward_hook_ ( module , input , output ): # Save featuremaps self . fmap_pool [ key ] = output . detach () return forward_hook_ def backward_hook ( key ): def backward_hook_ ( module , grad_in , grad_out ): # Save the gradients correspond to the featuremaps self . grad_pool [ key ] = grad_out [ 0 ] . detach () return backward_hook_ # If any candidates are not specified, the hook is registered to all the layers. for name , module in self . model . named_modules (): if self . candidate_layers is None or name in self . candidate_layers : self . handlers . append ( module . register_forward_hook ( forward_hook ( name ))) self . handlers . append ( module . register_backward_hook ( backward_hook ( name ))) def _find ( self , pool , target_layer ): if target_layer in pool . keys (): return pool [ target_layer ] else : raise ValueError ( \"Invalid layer name: {} \" . format ( target_layer )) def _compute_grad_weights ( self , grads ): return F . adaptive_avg_pool2d ( grads , 1 ) def forward ( self , image ): self . image_shape = image . shape [ 2 :] return super ( GradCAM , self ) . forward ( image ) def generate ( self , target_layer ): fmaps = self . _find ( self . fmap_pool , target_layer ) grads = self . _find ( self . grad_pool , target_layer ) weights = self . _compute_grad_weights ( grads ) gcam = torch . mul ( fmaps , weights ) . sum ( dim = 1 , keepdim = True ) gcam = F . relu ( gcam ) gcam = F . interpolate ( gcam , self . image_shape , mode = \"bilinear\" , align_corners = False ) B , C , H , W = gcam . shape gcam = gcam . view ( B , - 1 ) gcam -= gcam . min ( dim = 1 , keepdim = True )[ 0 ] gcam /= gcam . max ( dim = 1 , keepdim = True )[ 0 ] gcam = gcam . view ( B , C , H , W ) return gcam def demo2 ( image , label , model ): \"\"\" Generate Grad-CAM \"\"\" # Model model = model model . to ( device ) model . eval () # The layers target_layers = [ \"conv2\" ] target_class = label # Images images = image . unsqueeze ( 0 ) gcam = GradCAM ( model = model ) probs , ids = gcam . forward ( images ) ids_ = torch . LongTensor ([[ target_class ]] * len ( images )) . to ( device ) gcam . backward ( ids = ids_ ) for target_layer in target_layers : print ( \"Generating Grad-CAM @ {} \" . format ( target_layer )) # Grad-CAM regions = gcam . generate ( target_layer = target_layer ) for j in range ( len ( images )): print ( \" \\t # {} : {} ( {:.5f} )\" . format ( j , classes [ target_class ], float ( probs [ ids == target_class ]) ) ) gcam = regions [ j , 0 ] plt . imshow ( gcam . cpu ()) plt . show () image , label = next ( iter ( test_data_loader )) # Load the model model = net # Grad cam demo2 ( image [ 0 ] . to ( device ), label [ 0 ] . to ( device ), model ) image = np . transpose ( image [ 0 ], ( 1 , 2 , 0 )) image2 = np . add ( np . multiply ( image . numpy (), np . array ( norm_std )) , np . array ( norm_mean )) print ( \"True Class: \" , classes [ label [ 0 ] . cpu ()]) plt . imshow ( image ) plt . show () plt . imshow ( image2 ) plt . show () Generating Grad-CAM @conv2 #0: melanocytic nevi (0.12183) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). True Class: melanocytic nevi","title":"Grad cam"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#analysis-of-the-results","text":"As we can see from the results of the LeNet model, our system is not capable of processing the complexity of the given input images. Our final accuracy on the test data was 61%. About 39% of the images are missclassified, which is a terrible performance for any clinical use case. These results could be substantially improved if we opt for a deeper, more complex network architecture than LeNet, which will allow for a richer learning of the corresponding image features.","title":"Analysis of the results"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#switching-to-superior-network-architectureresnet18","text":"from torch import nn num_classes = len ( classes ) net = torchvision . models . resnet18 ( pretrained = True ) # We replace last layer of resnet to match our number of classes which is 7 net . fc = nn . Linear ( 512 , num_classes ) net = net . to ( device ) Define a Loss function and Optimizer Let's use a Classification Cross-Entropy loss. \\(H_{y'} (y) := - \\sum_{i} y_{i}' \\log (y_i)\\) The most common and effective Optimizer currently used is Adam: Adaptive Moments . You can look here for more information. import torch.optim as optim class_weights = class_weights . to ( device ) criterion = nn . CrossEntropyLoss ( weight = class_weights ) optimizer = optim . Adam ( net . parameters (), lr = 1e-5 ) print ( net ) ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (1): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer2): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer3): Sequential( (0): BasicBlock( (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer4): Sequential( (0): BasicBlock( (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (fc): Linear(in_features=512, out_features=7, bias=True) ) These are some helper functions to evaluate the training process. from sklearn.metrics import accuracy_score def get_accuracy ( predicted , labels ): batch_len , correct = 0 , 0 batch_len = labels . size ( 0 ) correct = ( predicted == labels ) . sum () . item () return batch_len , correct def evaluate ( model , val_loader ): losses = 0 num_samples_total = 0 correct_total = 0 model . eval () for inputs , labels in val_loader : inputs , labels = inputs . to ( device ), labels . to ( device ) out = model ( inputs ) _ , predicted = torch . max ( out , 1 ) loss = criterion ( out , labels ) losses += loss . item () b_len , corr = get_accuracy ( predicted , labels ) num_samples_total += b_len correct_total += corr accuracy = correct_total / num_samples_total losses = losses / len ( val_loader ) return losses , accuracy","title":"Switching to superior network architecture:Resnet18"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#train-the-network_1","text":"This is when things start to get interesting. We simply loop over the training data iterator, and feed the inputs to the network and optimize. # number of loops over the dataset num_epochs = 70 accuracy = [] val_accuracy = [] losses = [] val_losses = [] for epoch in range ( num_epochs ): running_loss = 0.0 correct_total = 0.0 num_samples_total = 0.0 for i , data in enumerate ( train_data_loader ): # get the inputs inputs , labels = data inputs , labels = inputs . to ( device ), labels . to ( device ) # set the parameter gradients to zero optimizer . zero_grad () # forward + backward + optimize outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () #compute accuracy _ , predicted = torch . max ( outputs , 1 ) b_len , corr = get_accuracy ( predicted , labels ) num_samples_total += b_len correct_total += corr running_loss += loss . item () running_loss /= len ( train_data_loader ) train_accuracy = correct_total / num_samples_total val_loss , val_acc = evaluate ( net , validation_data_loader ) print ( 'Epoch: %d ' % ( epoch + 1 )) print ( 'Loss: %.3f Accuracy: %.3f ' % ( running_loss , train_accuracy )) print ( 'Validation Loss: %.3f Val Accuracy: %.3f ' % ( val_loss , val_acc )) losses . append ( running_loss ) val_losses . append ( val_loss ) accuracy . append ( train_accuracy ) val_accuracy . append ( val_acc ) print ( 'Finished Training' ) Epoch: 1 Loss: 1.918 Accuracy:0.098 Validation Loss: 1.588 Val Accuracy: 0.243 Epoch: 2 Loss: 1.125 Accuracy:0.621 Validation Loss: 1.040 Val Accuracy: 0.648 Epoch: 3 Loss: 0.937 Accuracy:0.678 Validation Loss: 0.892 Val Accuracy: 0.674 Epoch: 5 Loss: 0.759 Accuracy:0.724 Validation Loss: 0.929 Val Accuracy: 0.651 Epoch: 6 Loss: 0.690 Accuracy:0.730 Validation Loss: 0.838 Val Accuracy: 0.718 Epoch: 7 Loss: 0.662 Accuracy:0.737 Validation Loss: 0.816 Val Accuracy: 0.709 Epoch: 8 Loss: 0.590 Accuracy:0.763 Validation Loss: 0.819 Val Accuracy: 0.705 Epoch: 9 Loss: 0.564 Accuracy:0.767 Validation Loss: 0.848 Val Accuracy: 0.726 Epoch: 10 Loss: 0.546 Accuracy:0.770 Validation Loss: 0.851 Val Accuracy: 0.719 Epoch: 11 Loss: 0.499 Accuracy:0.778 Validation Loss: 0.766 Val Accuracy: 0.749 Epoch: 12 Loss: 0.499 Accuracy:0.784 Validation Loss: 0.734 Val Accuracy: 0.751 Epoch: 13 Loss: 0.462 Accuracy:0.801 Validation Loss: 0.802 Val Accuracy: 0.757 Epoch: 14 Loss: 0.454 Accuracy:0.805 Validation Loss: 0.757 Val Accuracy: 0.744 Epoch: 15 Loss: 0.414 Accuracy:0.808 Validation Loss: 0.722 Val Accuracy: 0.769 Epoch: 16 Loss: 0.433 Accuracy:0.802 Validation Loss: 0.829 Val Accuracy: 0.787 Epoch: 17 Loss: 0.399 Accuracy:0.813 Validation Loss: 0.791 Val Accuracy: 0.768 Epoch: 18 Loss: 0.372 Accuracy:0.825 Validation Loss: 0.660 Val Accuracy: 0.791 Epoch: 19 Loss: 0.354 Accuracy:0.822 Validation Loss: 0.794 Val Accuracy: 0.784 Epoch: 20 Loss: 0.355 Accuracy:0.829 Validation Loss: 0.789 Val Accuracy: 0.750 Epoch: 21 Loss: 0.318 Accuracy:0.841 Validation Loss: 0.765 Val Accuracy: 0.800 Epoch: 22 Loss: 0.284 Accuracy:0.855 Validation Loss: 0.801 Val Accuracy: 0.777 Epoch: 23 Loss: 0.311 Accuracy:0.839 Validation Loss: 0.849 Val Accuracy: 0.815 Epoch: 24 Loss: 0.277 Accuracy:0.851 Validation Loss: 0.839 Val Accuracy: 0.792 Epoch: 25 Loss: 0.284 Accuracy:0.852 Validation Loss: 0.772 Val Accuracy: 0.770 Epoch: 26 Loss: 0.261 Accuracy:0.863 Validation Loss: 0.770 Val Accuracy: 0.802 Epoch: 27 Loss: 0.244 Accuracy:0.863 Validation Loss: 0.782 Val Accuracy: 0.782 Epoch: 28 Loss: 0.239 Accuracy:0.862 Validation Loss: 0.731 Val Accuracy: 0.805 Epoch: 29 Loss: 0.234 Accuracy:0.870 Validation Loss: 0.786 Val Accuracy: 0.816 Epoch: 30 Loss: 0.248 Accuracy:0.860 Validation Loss: 0.739 Val Accuracy: 0.803 Epoch: 31 Loss: 0.239 Accuracy:0.868 Validation Loss: 0.908 Val Accuracy: 0.779 Epoch: 33 Loss: 0.188 Accuracy:0.884 Validation Loss: 0.771 Val Accuracy: 0.780 Epoch: 34 Loss: 0.180 Accuracy:0.893 Validation Loss: 0.868 Val Accuracy: 0.803 Epoch: 35 Loss: 0.174 Accuracy:0.895 Validation Loss: 0.825 Val Accuracy: 0.800 Epoch: 36 Loss: 0.172 Accuracy:0.893 Validation Loss: 0.893 Val Accuracy: 0.823 Epoch: 37 Loss: 0.180 Accuracy:0.895 Validation Loss: 0.774 Val Accuracy: 0.778 Epoch: 38 Loss: 0.164 Accuracy:0.903 Validation Loss: 0.768 Val Accuracy: 0.776 Epoch: 39 Loss: 0.175 Accuracy:0.897 Validation Loss: 1.080 Val Accuracy: 0.784 Epoch: 40 Loss: 0.150 Accuracy:0.906 Validation Loss: 0.905 Val Accuracy: 0.826 Epoch: 41 Loss: 0.128 Accuracy:0.917 Validation Loss: 0.973 Val Accuracy: 0.809 Epoch: 42 Loss: 0.142 Accuracy:0.912 Validation Loss: 0.944 Val Accuracy: 0.834 Epoch: 43 Loss: 0.127 Accuracy:0.912 Validation Loss: 0.825 Val Accuracy: 0.819 Epoch: 44 Loss: 0.138 Accuracy:0.911 Validation Loss: 0.752 Val Accuracy: 0.810","title":"Train the network"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#plot-the-training-and-validation-loss-curves","text":"# plt.plot(losses) # plt.show() epoch = range ( 1 , num_epochs + 1 ) fig = plt . figure ( figsize = ( 10 , 15 )) plt . subplot ( 2 , 1 , 2 ) plt . plot ( epoch , losses , label = 'Training loss' ) plt . plot ( epoch , val_losses , label = 'Validation loss' ) plt . title ( 'Training and Validation Loss' ) plt . xlabel ( 'Epochs' ) plt . legend () plt . figure () plt . show () fig = plt . figure ( figsize = ( 10 , 15 )) plt . subplot ( 2 , 1 , 2 ) plt . plot ( epoch , accuracy , label = 'Training accuracy' ) plt . plot ( epoch , val_accuracy , label = 'Validation accuracy' ) plt . title ( 'Training and Validation Accuracy' ) plt . xlabel ( 'Epochs' ) plt . legend () plt . figure () plt . show () <Figure size 432x288 with 0 Axes> <Figure size 432x288 with 0 Axes>","title":"Plot the training  and validation loss curves."},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#test-the-network-on-the-test-data_1","text":"We have trained the network over the training dataset. But we need to check if the network has learnt anything at all. We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions. Okay, first step. Let us display an image from the test set to get familiar. fig = plt . figure ( figsize = ( 10 , 15 )) dataiter = iter ( test_data_loader ) images , labels = dataiter . next () # print images imshow ( torchvision . utils . make_grid ( images )) print ( 'GroundTruth: ' , ' ' . join ( ' %5s , ' % classes [ labels [ j ]] for j in range ( len ( labels )))) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). GroundTruth: melanocytic nevi, melanoma, melanocytic nevi, melanoma, melanoma, melanocytic nevi, melanocytic nevi, benign keratosis-like lesions, basal cell carcinoma, melanocytic nevi, Okay, now let us check the performance on the test network: correct = 0 total = 0 net . eval () with torch . no_grad (): for data in test_data_loader : images , labels = data images , labels = images . to ( device ), labels . to ( device ) outputs = net ( images ) _ , predicted = torch . max ( outputs . data , 1 ) total += labels . size ( 0 ) correct += ( predicted == labels ) . sum () . item () print ( 'Accuracy of the network on the test images: %d %% ' % ( 100 * correct / total )) Accuracy of the network on the test images: 85 % class_correct = list ( 0. for i in range ( len ( classes ))) class_total = list ( 1e-7 for i in range ( len ( classes ))) with torch . no_grad (): for data in test_data_loader : images , labels = data images , labels = images . to ( device ), labels . to ( device ) outputs = net ( images ) _ , predicted = torch . max ( outputs , 1 ) c = ( predicted == labels ) . squeeze () for i in range ( 3 ): label = labels [ i ] class_correct [ label ] += c [ i ] . item () class_total [ label ] += 1 for i in range ( len ( classes )): print ( 'Accuracy of %5s : %2d %% ' % ( classes [ i ], 100 * class_correct [ i ] / class_total [ i ])) Accuracy of actinic keratoses : 92 % Accuracy of basal cell carcinoma : 96 % Accuracy of benign keratosis-like lesions : 92 % Accuracy of dermatofibroma : 79 % Accuracy of melanoma : 97 % Accuracy of melanocytic nevi : 85 % Accuracy of vascular lesions : 0 % class_correct = list ( 0. for i in range ( len ( classes ))) class_total = list ( 1e-7 for i in range ( len ( classes ))) net . eval () with torch . no_grad (): for data in validation_data_loader : images , labels = data images , labels = images . to ( device ), labels . to ( device ) outputs = net ( images ) _ , predicted = torch . max ( outputs , 1 ) c = ( predicted == labels ) . squeeze () for i in range ( 3 ): label = labels [ i ] class_correct [ label ] += c [ i ] . item () class_total [ label ] += 1 for i in range ( len ( classes )): print ( 'Accuracy of %5s : %2d %% ' % ( classes [ i ], 100 * class_correct [ i ] / class_total [ i ])) Accuracy of actinic keratoses : 66 % Accuracy of basal cell carcinoma : 77 % Accuracy of benign keratosis-like lesions : 77 % Accuracy of dermatofibroma : 69 % Accuracy of melanoma : 79 % Accuracy of melanocytic nevi : 88 % Accuracy of vascular lesions : 0 %","title":"Test the network on the test data"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#confusion-matrix_1","text":"confusion_matrix = torch . zeros ( len ( classes ), len ( classes )) with torch . no_grad (): for data in test_data_loader : images , labels = data images , labels = images . to ( device ), labels . to ( device ) outputs = net ( images ) _ , predicted = torch . max ( outputs , 1 ) for t , p in zip ( labels . view ( - 1 ), predicted . view ( - 1 )): confusion_matrix [ t . long (), p . long ()] += 1 print ( confusion_matrix ) cm = confusion_matrix . numpy () tensor([[6.0000e+01, 2.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00], [0.0000e+00, 1.0200e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00], [2.0000e+00, 0.0000e+00, 2.0700e+02, 0.0000e+00, 5.0000e+00, 6.0000e+00, 0.0000e+00], [1.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+01, 1.0000e+00, 1.0000e+00, 0.0000e+00], [0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 2.1400e+02, 7.0000e+00, 0.0000e+00], [3.0000e+00, 5.0000e+00, 3.8000e+01, 1.0000e+00, 1.7500e+02, 1.1190e+03, 0.0000e+00], [0.0000e+00, 9.0000e+00, 1.0000e+00, 0.0000e+00, 8.0000e+00, 1.0000e+01, 0.0000e+00]]) fig , ax = plt . subplots ( figsize = ( 7 , 7 )) sns . heatmap ( cm / ( cm . astype ( np . float ) . sum ( axis = 1 ) + 1e-9 ), annot = False , ax = ax ) # labels, title and ticks ax . set_xlabel ( 'Predicted' , size = 25 ); ax . set_ylabel ( 'True' , size = 25 ); ax . set_title ( 'Confusion Matrix' , size = 25 ); ax . xaxis . set_ticklabels ([ 'akiec' , 'bcc' , 'bkl' , 'df' , 'mel' , 'nv' , 'vasc' ], size = 15 ); \\ ax . yaxis . set_ticklabels ([ 'akiec' , 'bcc' , 'bkl' , 'df' , 'mel' , 'nv' , 'vasc' ], size = 15 );","title":"Confusion Matrix"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#grad-cam_1","text":"from collections import OrderedDict , Sequence class _BaseWrapper ( object ): \"\"\" Please modify forward() and backward() according to your task. \"\"\" def __init__ ( self , model ): super ( _BaseWrapper , self ) . __init__ () self . device = next ( model . parameters ()) . device self . model = model self . handlers = [] # a set of hook function handlers def _encode_one_hot ( self , ids ): one_hot = torch . zeros_like ( self . logits ) . to ( self . device ) one_hot . scatter_ ( 1 , ids , 1.0 ) return one_hot def forward ( self , image ): \"\"\" Simple classification \"\"\" self . model . zero_grad () self . logits = self . model ( image ) self . probs = F . softmax ( self . logits , dim = 1 ) return self . probs . sort ( dim = 1 , descending = True ) def backward ( self , ids ): \"\"\" Class-specific backpropagation Either way works: 1. self.logits.backward(gradient=one_hot, retain_graph=True) 2. (self.logits * one_hot).sum().backward(retain_graph=True) \"\"\" one_hot = self . _encode_one_hot ( ids ) self . logits . backward ( gradient = one_hot , retain_graph = True ) def generate ( self ): raise NotImplementedError def remove_hook ( self ): \"\"\" Remove all the forward/backward hook functions \"\"\" for handle in self . handlers : handle . remove () class GradCAM ( _BaseWrapper ): \"\"\" \"Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization\" https://arxiv.org/pdf/1610.02391.pdf Look at Figure 2 on page 4 \"\"\" def __init__ ( self , model , candidate_layers = None ): super ( GradCAM , self ) . __init__ ( model ) self . fmap_pool = OrderedDict () self . grad_pool = OrderedDict () self . candidate_layers = candidate_layers # list def forward_hook ( key ): def forward_hook_ ( module , input , output ): # Save featuremaps self . fmap_pool [ key ] = output . detach () return forward_hook_ def backward_hook ( key ): def backward_hook_ ( module , grad_in , grad_out ): # Save the gradients correspond to the featuremaps self . grad_pool [ key ] = grad_out [ 0 ] . detach () return backward_hook_ # If any candidates are not specified, the hook is registered to all the layers. for name , module in self . model . named_modules (): if self . candidate_layers is None or name in self . candidate_layers : self . handlers . append ( module . register_forward_hook ( forward_hook ( name ))) self . handlers . append ( module . register_backward_hook ( backward_hook ( name ))) def _find ( self , pool , target_layer ): if target_layer in pool . keys (): return pool [ target_layer ] else : raise ValueError ( \"Invalid layer name: {} \" . format ( target_layer )) def _compute_grad_weights ( self , grads ): return F . adaptive_avg_pool2d ( grads , 1 ) def forward ( self , image ): self . image_shape = image . shape [ 2 :] return super ( GradCAM , self ) . forward ( image ) def generate ( self , target_layer ): fmaps = self . _find ( self . fmap_pool , target_layer ) grads = self . _find ( self . grad_pool , target_layer ) weights = self . _compute_grad_weights ( grads ) gcam = torch . mul ( fmaps , weights ) . sum ( dim = 1 , keepdim = True ) gcam = F . relu ( gcam ) gcam = F . interpolate ( gcam , self . image_shape , mode = \"bilinear\" , align_corners = False ) B , C , H , W = gcam . shape gcam = gcam . view ( B , - 1 ) gcam -= gcam . min ( dim = 1 , keepdim = True )[ 0 ] gcam /= gcam . max ( dim = 1 , keepdim = True )[ 0 ] gcam = gcam . view ( B , C , H , W ) return gcam def demo2 ( image , label , model ): \"\"\" Generate Grad-CAM \"\"\" # Model model = model model . to ( device ) model . eval () # The layers target_layers = [ \"layer4\" ] target_class = label # Images images = image . unsqueeze ( 0 ) gcam = GradCAM ( model = model ) probs , ids = gcam . forward ( images ) ids_ = torch . LongTensor ([[ target_class ]] * len ( images )) . to ( device ) gcam . backward ( ids = ids_ ) for target_layer in target_layers : print ( \"Generating Grad-CAM @ {} \" . format ( target_layer )) # Grad-CAM regions = gcam . generate ( target_layer = target_layer ) for j in range ( len ( images )): print ( \" \\t # {} : {} ( {:.5f} )\" . format ( j , classes [ target_class ], float ( probs [ ids == target_class ]) ) ) gcam = regions [ j , 0 ] plt . imshow ( gcam . cpu ()) plt . show () image , label = next ( iter ( test_data_loader )) # Load the model model = net # Grad cam demo2 ( image [ 0 ] . to ( device ), label [ 0 ] . to ( device ), model ) image = np . transpose ( image [ 0 ], ( 1 , 2 , 0 )) image2 = np . add ( np . multiply ( image . numpy (), np . array ( norm_std )) , np . array ( norm_mean )) print ( \"True Class: \" , classes [ label [ 0 ] . cpu ()]) plt . imshow ( image ) plt . show () plt . imshow ( image2 ) plt . show () Generating Grad-CAM @layer4 #0: melanocytic nevi (0.76489) Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). True Class: melanocytic nevi","title":"Grad cam"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/SkinLesionClassification/#conclusion","text":"Training a neural network can be a daunting task, especially for a beginner. Here, are some useful practices to get the best out of your network. Training Ensembles \u2014 Combine learning from multiple networks. Always go for a lower learning rate. In cases of limited data try better augmentation techniques[20]. Network architectures that have the appropriate depth for our problem \u2014 too many hyperparameters could lead to suboptimal results if we don\u2019t have enough images. Improving loss function and class balancing. In this tutorial we learned how to train a deep neural network for the challenging task of skin-lesion classification. We experimented with two network architectures and provided insights in the attention of the models. Additionally, we achieved 83% overall accuracy on HAM10000 and provided you with more tips and tricks to tackle overfitting and class imbalance. Now you have all the tools to not only beat our performance and participate in the exciting MICCAI Challenges, but to also solve many more medical imaging problems. Happy training!","title":"Conclusion"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/neural_network_interpretation/references/keras_google_colab/","text":"import numpy as np import tensorflow as tf from tensorflow import keras # Display from IPython.display import Image , display import matplotlib.pyplot as plt import matplotlib.cm as cm tf . keras . applications . vgg16 . VGG16 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' ) . summary () Model: \"vgg16\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_3 (InputLayer) [(None, 224, 224, 3)] 0 block1_conv1 (Conv2D) (None, 224, 224, 64) 1792 block1_conv2 (Conv2D) (None, 224, 224, 64) 36928 block1_pool (MaxPooling2D) (None, 112, 112, 64) 0 block2_conv1 (Conv2D) (None, 112, 112, 128) 73856 block2_conv2 (Conv2D) (None, 112, 112, 128) 147584 block2_pool (MaxPooling2D) (None, 56, 56, 128) 0 block3_conv1 (Conv2D) (None, 56, 56, 256) 295168 block3_conv2 (Conv2D) (None, 56, 56, 256) 590080 block3_conv3 (Conv2D) (None, 56, 56, 256) 590080 block3_pool (MaxPooling2D) (None, 28, 28, 256) 0 block4_conv1 (Conv2D) (None, 28, 28, 512) 1180160 block4_conv2 (Conv2D) (None, 28, 28, 512) 2359808 block4_conv3 (Conv2D) (None, 28, 28, 512) 2359808 block4_pool (MaxPooling2D) (None, 14, 14, 512) 0 block5_conv1 (Conv2D) (None, 14, 14, 512) 2359808 block5_conv2 (Conv2D) (None, 14, 14, 512) 2359808 block5_conv3 (Conv2D) (None, 14, 14, 512) 2359808 block5_pool (MaxPooling2D) (None, 7, 7, 512) 0 flatten (Flatten) (None, 25088) 0 fc1 (Dense) (None, 4096) 102764544 fc2 (Dense) (None, 4096) 16781312 predictions (Dense) (None, 1000) 4097000 ================================================================= Total params: 138,357,544 Trainable params: 138,357,544 Non-trainable params: 0 _________________________________________________________________ def get_img_array ( img_path , size ): # `img` is a PIL image of size 224x224 img = keras . preprocessing . image . load_img ( img_path , target_size = size ) # `array` is a float32 Numpy array of shape (224, 224, 3) array = keras . preprocessing . image . img_to_array ( img ) # We add a dimension to transform our array into a \"batch\" # of size (1, 224, 224, 3) array = np . expand_dims ( array , axis = 0 ) return array def make_gradcam_heatmap ( img_array , model , last_conv_layer_name , target_category = None ): # First, we create a model that maps the input image to the activations # of the last conv layer as well as the output predictions. # In other words, this is like the forward hook of torch. grad_model = tf . keras . models . Model ( [ model . inputs ], [ model . get_layer ( last_conv_layer_name ) . output , model . output ], ) # Then, we compute the gradient of the top predicted class for our input image # with respect to the activations of the last conv layer with tf . GradientTape () as tape : # last_conv_layer_output: Note this is merely the output when the inputs propagate to the last conv layer. # i.e. this is the output of the last conv layer. and is not flattened yet last_conv_layer_output , y_logits = grad_model ( img_array ) print ( y_logits . shape ) # last_conv_layer_output: shape = (1, 14, 14, 512) # which is 512 number of filters of 14 x 14 filters. # print(last_conv_layer_output.shape) # print(y_logits[:, 386]) should be the same as what we had earlier! if target_category is None : target_category = tf . argmax ( y_logits [ 0 ]) target_category_logits = y_logits [:, target_category ] print ( target_category_logits ) # This is the gradient of the output neuron (top predicted or chosen) # with regard to the output feature map of the last conv layer grads = tape . gradient ( target_category_logits , last_conv_layer_output ) # print(grads.shape) same shape as last conv layer! (1, 14, 14, 512) # do not confuse gradient of loss fn with respect to inputs # we are talking about gradient of y_c with respect to feature maps (not the raw image input array), note the distinction. # so we r checking the rate of change of y_c wrt the feature maps # we are checking the rate of change of elephant wrt to elephants feature maps # This is a vector where each entry is the mean intensity of the gradient # over a specific feature map channel pooled_grads = tf . reduce_mean ( grads , axis = ( 0 , 1 , 2 )) # print(pooled_grads.shape) # (512,) # by hn grads_transposed = np . transpose ( np . squeeze ( grads , axis = 0 ), axes = None ) # print(grads_transposed.shape) for feature_map in grads_transposed : mean_feature_map = np . mean ( feature_map ) print ( mean_feature_map ) # same as print(pooled_grads[0]) print ( pooled_grads [ 0 ]) break # one should readily understand # We multiply each channel in the feature map array # by \"how important this channel is\" with regard to the top predicted class # then sum all the channels to obtain the heatmap class activation last_conv_layer_output = last_conv_layer_output [ 0 ] # this is just squeeze dimension from (1,14,14,512) to (14,14,512) print ( last_conv_layer_output . shape ) # in Python \"...\" means \"all dimensions prior to\" add new axis. # print(pooled_grads[..., tf.newaxis].shape) # (512, ) to (512, 1) print ( last_conv_layer_output ) heatmap = ( last_conv_layer_output @ pooled_grads [ ... , tf . newaxis ] ) # same as heatmap = last_conv_layer_output @ tf.expand_dims(pooled_grads, axis=-1) print ( heatmap . shape ) # (14, 14, 1) heatmap = tf . squeeze ( heatmap ) # (14, 14) # For visualization purpose, we will also normalize the heatmap between 0 & 1 RELU OPS heatmap = tf . maximum ( heatmap , 0 ) / tf . math . reduce_max ( heatmap ) return heatmap . numpy () model_builder = keras . applications . vgg16 . VGG16 img_size = ( 224 , 224 ) preprocess_input = keras . applications . vgg16 . preprocess_input decode_predictions = keras . applications . vgg16 . decode_predictions last_conv_layer_name = \"block5_conv3\" # The local path to our target image img_path = keras . utils . get_file ( \"african_elephant.jpg\" , \"https://i.imgur.com/Bvro0YD.png\" ) # Prepare image img_array = preprocess_input ( get_img_array ( img_path , size = img_size )) # Make model model = model_builder ( weights = \"imagenet\" ) # Remove last layer's softmax model . layers [ - 1 ] . activation = None # Print what the top predicted class is. # preds has a shape of (1, 1000) preds = model . predict ( img_array ) # if you print argmax along column, or simply put # argmax of all logits in the 1000 predictions, we have 386 the elephant as index print ( f \"preds argmax: { preds . argmax ( axis = 1 ) } \\n preds value: { preds [:, preds . argmax ( axis = 1 )] } \" ) # !!! # Important is we did not activate softmax here, in fact, since softmax is monotonic, when pre-softmax, the logits output will tell us already which class is most probable! # means to say even we did not make the logits in between 0 and 1, the ranking is preserved in the sense that values in logits the highest is the most probable when transformed by softmax # decode predictions - this is a convenient function from keras print ( \"Predicted:\" , decode_predictions ( preds , top = 1 )[ 0 ]) preds argmax: [386] preds value: [[23.632017]] Predicted: [('n02504458', 'African_elephant', 23.632017)] # Generate class activation heatmap heatmap = make_gradcam_heatmap ( img_array , model , last_conv_layer_name ) (1, 1000) tf.Tensor([23.632017], shape=(1,), dtype=float32) -0.00016475434 tf.Tensor(-0.00016475434, shape=(), dtype=float32) (14, 14, 512) tf.Tensor( [[[0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] ... [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] ... [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] ... [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.]] ... [[0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] ... [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] ... [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] ... [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.]]], shape=(14, 14, 512), dtype=float32) (14, 14, 1) # Display heatmap plt . matshow ( heatmap ) plt . show () def save_and_display_gradcam ( img_path , heatmap , cam_path = \"cam.jpg\" , alpha = 0.4 ): # Load the original image img = keras . preprocessing . image . load_img ( img_path ) img = keras . preprocessing . image . img_to_array ( img ) # Rescale heatmap to a range 0-255 heatmap = np . uint8 ( 255 * heatmap ) # Use jet colormap to colorize heatmap jet = cm . get_cmap ( \"jet\" ) # Use RGB values of the colormap jet_colors = jet ( np . arange ( 256 ))[:, : 3 ] jet_heatmap = jet_colors [ heatmap ] # Create an image with RGB colorized heatmap jet_heatmap = keras . preprocessing . image . array_to_img ( jet_heatmap ) jet_heatmap = jet_heatmap . resize (( img . shape [ 1 ], img . shape [ 0 ])) jet_heatmap = keras . preprocessing . image . img_to_array ( jet_heatmap ) # Superimpose the heatmap on original image superimposed_img = jet_heatmap * alpha + img superimposed_img = keras . preprocessing . image . array_to_img ( superimposed_img ) # Save the superimposed image superimposed_img . save ( cam_path ) # Display Grad CAM display ( Image ( cam_path )) save_and_display_gradcam ( img_path , heatmap ) img_path = keras . utils . get_file ( \"cat_and_dog.jpg\" , \"https://storage.googleapis.com/petbacker/images/blog/2017/dog-and-cat-cover.jpg\" , ) display ( Image ( img_path )) # Prepare image img_array = preprocess_input ( get_img_array ( img_path , size = img_size )) # Print what the two top predicted classes are preds = model . predict ( img_array ) print ( \"Predicted:\" , decode_predictions ( preds , top = 2 )[ 0 ]) Downloading data from https://storage.googleapis.com/petbacker/images/blog/2017/dog-and-cat-cover.jpg 73728/72452 [==============================] - 0s 0us/step 81920/72452 [=================================] - 0s 0us/step Predicted: [('n02106030', 'collie', 8.145561), ('n02110806', 'basenji', 7.812906)] heatmap = make_gradcam_heatmap ( img_array , model , last_conv_layer_name , pred_index = 260 ) save_and_display_gradcam ( img_path , heatmap ) heatmap = make_gradcam_heatmap ( img_array , model , last_conv_layer_name , pred_index = 285 ) save_and_display_gradcam ( img_path , heatmap )","title":"Keras google colab"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/object_detection/bounding_boxes/","text":"import matplotlib.pyplot as plt import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import torch import torchvision % matplotlib inline import glob import os from math import ceil import random import cv2 import PIL from IPython.core.interactiveshell import InteractiveShell InteractiveShell . ast_node_interactivity = \"all\" from typing import * # importing modules import urllib.request from urllib.request import urlopen from PIL import Image import bounding_boxes cat_dog_p = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/deep_learning/computer_vision/data/misc/catdog.jpg\" # plot cat and dog with title using PIL plt . figure ( figsize = ( 10 , 10 )) cat_dog = PIL . Image . open ( urlopen ( cat_dog_p )) plt . imshow ( cat_dog ) plt . title ( \"Cat and Dog\" ) plt . show (); height , width , channel = np . asarray ( cat_dog ) . shape print ( f \"The height is { height } and the width is { width } and the channel is { channel } \" ) The height is 561 and the width is 728 and the channel is 3 Bounding Boxes In object detection, we usually use a bounding box to describe the spatial location of an object. The bounding box is rectangular, which is determined by the \\(x\\) and \\(y\\) coordinates of the upper-left corner of the rectangle and the such coordinates of the lower-right corner. Another commonly used bounding box representation is the \\((x, y)\\) -axis coordinates of the bounding box center, and the width and height of the box. [ Here we define functions to convert between ] these ( two representations ): box_corner_to_center converts from the two-corner representation to the center-width-height presentation, and box_center_to_corner vice versa. The input argument boxes should be a two-dimensional tensor of shape ( \\(n\\) , 4), where \\(n\\) is the number of bounding boxes. Different conversions https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/ https://github.com/awsaf49/bbox/blob/main/bbox/utils.py Pascal https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/ pascal_voc is a format used by the Pascal VOC dataset . Coordinates of a bounding box are encoded with four values in pixels: [x_min, y_min, x_max, y_max] . x_min and y_min are coordinates of the top-left corner of the bounding box. x_max and y_max are coordinates of bottom-right corner of the bounding box. Coordinates of the example bounding box in this format are [98, 345, 420, 462] . COCO coco is a format used by the Common Objects in Context \\(COCO\\) dataset. In coco , a bounding box is defined by four values in pixels [x_min, y_min, width, height] . They are coordinates of the top-left corner along with the width and height of the bounding box. Coordinates of the example bounding box in this format are [98, 345, 322, 117] . YOLO In yolo , a bounding box is represented by four values [x_center, y_center, width, height] . x_center and y_center are the normalized coordinates of the center of the bounding box. To make coordinates normalized, we take pixel values of x and y, which marks the center of the bounding box on the x- and y-axis. Then we divide the value of x by the width of the image and value of y by the height of the image. width and height represent the width and the height of the bounding box. They are normalized as well. Coordinates of the example bounding box in this format are [((420 + 98) / 2) / 640, ((462 + 345) / 2) / 480, 322 / 640, 117 / 480] which are [0.4046875, 0.840625, 0.503125, 0.24375] . def voc2coco ( bboxes : Union [ np . ndarray , torch . Tensor ], return_tensor : bool = False ) -> np . ndarray : \"\"\"Convert pascal_voc to coco format. voc => [xmin, ymin, xmax, ymax] coco => [xmin, ymin, w, h] Args: bboxes (torch.Tensor): Shape of (N, 4) where N is the number of samples and 4 is the coordinates [xmin, ymin, xmax, ymax]. Returns: coco_bboxes (torch.Tensor): Shape of (N, 4) where N is the number of samples and 4 is the coordinates [xmin, ymin, w, h]. \"\"\" # don't perform in place to avoid mutation if isinstance ( bboxes , torch . Tensor ): bboxes = bboxes . cpu () . detach () . numpy () coco_bboxes = bboxes . copy () for index , each_bbox in enumerate ( bboxes ): xmin , ymin , xmax , ymax = each_bbox w , h = xmax - xmin , ymax - ymin if return_tensor : coco_bboxes [ index ] = torch . tensor ([ xmin , ymin , w , h ]) else : coco_bboxes [ index ] = np . asarray ([ xmin , ymin , w , h ]) return coco_bboxes def coco2voc ( bboxes : Union [ np . ndarray , torch . Tensor ], return_tensor : bool = False ) -> np . ndarray : \"\"\"Convert coco to pascal_voc format. coco => [xmin, ymin, w, h] voc => [xmin, ymin, xmax, ymax] Args: bboxes (torch.Tensor): Shape of (N, 4) where N is the number of samples and 4 is the coordinates [xmin, ymin, w, h]. Returns: voc_bboxes (torch.Tensor): Shape of (N, 4) where N is the number of samples and 4 is the coordinates [xmin, ymin, xmax, ymax]. \"\"\" # don't perform in place to avoid mutation if isinstance ( bboxes , torch . Tensor ): bboxes = bboxes . cpu () . detach () . numpy () voc_bboxes = bboxes . copy () for index , each_bbox in enumerate ( bboxes ): xmin , ymin , w , h = each_bbox xmax , ymax = xmin + w , ymin + h if return_tensor : voc_bboxes [ index ] = torch . tensor ([ xmin , ymin , xmax , ymax ]) else : voc_bboxes [ index ] = np . asarray ([ xmin , ymin , xmax , ymax ]) return voc_bboxes from numba import jit import cv2 import numpy as np import random __all__ = [ 'coco2yolo' , 'yolo2coco' , 'voc2coco' , 'coco2voc' , 'yolo2voc' , 'voc2yolo' , 'bbox_iou' , 'draw_bboxes' , 'load_image' ] def voc2yolo ( bboxes , height = 720 , width = 1280 ): \"\"\" voc => [x1, y1, x2, y1] yolo => [xmid, ymid, w, h] (normalized) \"\"\" if isinstance ( bboxes , torch . Tensor ): bboxes = bboxes . cpu () . detach () . numpy () bboxes = bboxes . copy () . astype ( float ) # otherwise all value will be 0 as voc_pascal dtype is np.int bboxes [ ... , 0 :: 2 ] /= width bboxes [ ... , 1 :: 2 ] /= height bboxes [ ... , 2 ] -= bboxes [ ... , 0 ] bboxes [ ... , 3 ] -= bboxes [ ... , 1 ] bboxes [ ... , 0 ] += bboxes [ ... , 2 ] / 2 bboxes [ ... , 1 ] += bboxes [ ... , 3 ] / 2 return bboxes def yolo2voc ( bboxes , height = 720 , width = 1280 ): \"\"\" yolo => [xmid, ymid, w, h] (normalized) voc => [x1, y1, x2, y1] \"\"\" if isinstance ( bboxes , torch . Tensor ): bboxes = bboxes . cpu () . detach () . numpy () bboxes = bboxes . copy () . astype ( float ) # otherwise all value will be 0 as voc_pascal dtype is np.int bboxes [ ... , 0 :: 2 ] *= width bboxes [ ... , 1 :: 2 ] *= height bboxes [ ... , 0 : 2 ] -= bboxes [ ... , 2 : 4 ] / 2 bboxes [ ... , 2 : 4 ] += bboxes [ ... , 0 : 2 ] return bboxes def coco2yolo ( bboxes , height = 720 , width = 1280 ): \"\"\" https://github.com/awsaf49/bbox/blob/main/bbox/utils.py coco => [xmin, ymin, w, h] yolo => [xmid, ymid, w, h] (normalized) \"\"\" # bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int # normolizinig bboxes [ ... , 0 :: 2 ] /= width bboxes [ ... , 1 :: 2 ] /= height # converstion (xmin, ymin) => (xmid, ymid) bboxes [ ... , 0 : 2 ] += bboxes [ ... , 2 : 4 ] / 2 return bboxes def yolo2coco ( bboxes , height = 720 , width = 1280 ): \"\"\" https://github.com/awsaf49/bbox/blob/main/bbox/utils.py yolo => [xmid, ymid, w, h] (normalized) coco => [xmin, ymin, w, h] \"\"\" # bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int # denormalizing bboxes [ ... , 0 :: 2 ] *= width bboxes [ ... , 1 :: 2 ] *= height # converstion (xmid, ymid) => (xmin, ymin) bboxes [ ... , 0 : 2 ] -= bboxes [ ... , 2 : 4 ] / 2 return bboxes dog_bbox , cat_bbox = [ 60.0 , 45.0 , 378.0 , 516.0 ], [ 400.0 , 112.0 , 655.0 , 493.0 ] bboxes = torch . tensor (( dog_bbox , cat_bbox )) bboxes tensor([[ 60., 45., 378., 516.], [400., 112., 655., 493.]]) VOC-COCO Test np . testing . assert_array_equal ( bboxes , coco2voc ( voc2coco ( bboxes ))) np . array_equal ( bboxes , coco2voc ( voc2coco ( bboxes ))) True VOC-YOLO Test coco2voc ( voc2coco ( bboxes )) array([[ 60., 45., 378., 516.], [400., 112., 655., 493.]], dtype=float32) yolo2voc ( voc2yolo ( bboxes , height = 561 , width = 768 ), height = 561 , width = 768 ) array([[ 60., 45., 378., 516.], [400., 112., 655., 493.]]) yolo2voc ( voc2yolo ( bboxes , height = 561 , width = 768 ), height = 561 , width = 768 ) array([[ 60., 45., 378., 516.], [400., 112., 655., 493.]]) a = voc2coco ( bboxes ) b = coco2voc ( a ) a , b (array([[ 60., 45., 318., 471.], [400., 112., 255., 381.]], dtype=float32), array([[ 60., 45., 378., 516.], [400., 112., 655., 493.]], dtype=float32)) We measure the bounding box coordinates for the cat and dog respectively. Here bbox is the abbreviation for bounding box. The bbox below represents dog_bbox , cat_bbox = [ 60.0 , 45.0 , 378.0 , 516.0 ], [ 400.0 , 112.0 , 655.0 , 493.0 ] def draw_bboxes_on_single_image ( image : Union [ torch . Tensor , np . ndarray ], bboxes : Union [ torch . Tensor , np . ndarray ], labels : Union [ torch . Tensor , np . ndarray , List [ int ]], labels_map : Dict [ int , str ], colors : Dict [ int , Tuple [ int , int , int ]], ) -> np . ndarray : \"\"\"Draws bounding boxes on a single image. Args: image (Union[torch.Tensor, np.ndarray]): The original image to draw on. bboxes (Union[torch.Tensor, np.ndarray]): The bounding boxes of the original image. This should be in voc_pascal format of (xmin, ymin, xmax, ymax). labels (Union[torch.Tensor, np.ndarray, List[int]]): The labels of the bounding boxes corresponding to the bounding boxes. Note they are needed to be in the same order as the bounding boxes. colors (Dict[int, Tuple[int, int, int]]): The color mapping of the labels. Returns: image (np.ndarray): The image with bounding boxes drawn on it. Shapes: - Input: - image: :math:`(H, W, C)` or :math:`(C, H, W)` depending on whether the channels are the first or last dimension. - bboxes: :math:`(N, 4)` where the bounding boxes are in the format of (xmin, ymin, xmax, ymax) and N is the number of bounding boxes. - labels: :math:`(N,)` where N is the number of bounding boxes. - Output: - image: :math:`(H, W, C)` Example: >>> import torch >>> import numpy as np >>> cat_dog_p = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/deep_learning/computer_vision/data/misc/catdog.jpg\" >>> cat_dog = PIL.Image.open(urlopen(cat_dog_p)) >>> dog_bbox, cat_bbox = [60.0, 45.0, 378.0, 516.0], [400.0, 112.0, 655.0, 493.0] >>> bboxes = torch.tensor((dog_bbox, cat_bbox)) # convert to (N, 2) >>> labels = [0, 1] >>> labels_map = {0: \"dog\", 1: \"cat\"} >>> colors = {0: (255, 0, 255), 1: (0, 255, 255)} >>> bbox_img = draw_bboxes_on_single_image(cat_dog, bboxes, labels=labels, labels_map=labels_map, colors=colors) >>> plt.imshow(bbox_img); \"\"\" if isinstance ( image , torch . Tensor ): image = image . cpu () . detach () . numpy () if isinstance ( bboxes , torch . Tensor ): bboxes = bboxes . cpu () . detach () . numpy () if isinstance ( labels , torch . Tensor ): labels = labels . cpu () . detach () . numpy () # make sure it is in np.ndarray format if read as PIL image = np . asarray ( image . copy ()) labels = np . asarray ( labels . copy ()) # if labels is like [[0], [1], [0]] then flatten if len ( labels . shape ) > 1 : labels = labels . flatten () # line/font thickness line_thickness = round ( 0.002 * ( image . shape [ 0 ] + image . shape [ 1 ]) / 2 ) + 1 for i , ( bbox , label ) in enumerate ( zip ( bboxes , labels )): color = colors [ label ] pt1 , pt2 = ( bbox [ 0 ], bbox [ 1 ]), ( bbox [ 2 ], bbox [ 3 ]) pt1 = int ( pt1 [ 0 ]), int ( pt1 [ 1 ]) pt2 = int ( pt2 [ 0 ]), int ( pt2 [ 1 ]) image = cv2 . rectangle ( image . copy (), pt1 , pt2 , color , int ( max ( image . shape [: 2 ]) / 200 ) ) # annotate text label2str = labels_map [ label ] cv2 . putText ( image , label2str , pt1 , cv2 . FONT_HERSHEY_SIMPLEX , line_thickness / 3 , color = [ 0 , 0 , 0 ], thickness = line_thickness , lineType = cv2 . LINE_AA , ) return image >>> import torch >>> import numpy as np >>> cat_dog_p = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/deep_learning/computer_vision/data/misc/catdog.jpg\" >>> cat_dog = PIL . Image . open ( urlopen ( cat_dog_p )) >>> dog_bbox , cat_bbox = [ 60.0 , 45.0 , 378.0 , 516.0 ], [ 400.0 , 112.0 , 655.0 , 493.0 ] >>> bboxes = torch . tensor (( dog_bbox , cat_bbox )) >>> labels = [ 0 , 1 ] >>> labels_map = { 0 : \"dog\" , 1 : \"cat\" } >>> colors = { 0 : ( 255 , 0 , 255 ), 1 : ( 0 , 255 , 255 )} >>> bbox_img = draw_bboxes_on_single_image ( cat_dog , bboxes , labels = labels , labels_map = labels_map , colors = colors ) >>> plt . imshow ( bbox_img ); Anchor Boxes def multibox_prior ( data , sizes , ratios ): \"\"\"Generate anchor boxes with different shapes centered on each pixel.\"\"\" in_height , in_width = data . shape [ - 2 :] device , num_sizes , num_ratios = data . device , len ( sizes ), len ( ratios ) boxes_per_pixel = ( num_sizes + num_ratios - 1 ) size_tensor = torch . tensor ( sizes , device = device ) ratio_tensor = torch . tensor ( ratios , device = device ) # Offsets are required to move the anchor to the center of a pixel. Since # a pixel has height=1 and width=1, we choose to offset our centers by 0.5 offset_h , offset_w = 0.5 , 0.5 steps_h = 1.0 / in_height # Scaled steps in y axis steps_w = 1.0 / in_width # Scaled steps in x axis # Generate all center points for the anchor boxes center_h = ( torch . arange ( in_height , device = device ) + offset_h ) * steps_h center_w = ( torch . arange ( in_width , device = device ) + offset_w ) * steps_w shift_y , shift_x = torch . meshgrid ( center_h , center_w ) shift_y , shift_x = shift_y . reshape ( - 1 ), shift_x . reshape ( - 1 ) # Generate `boxes_per_pixel` number of heights and widths that are later # used to create anchor box corner coordinates (xmin, xmax, ymin, ymax) w = torch . cat (( size_tensor * torch . sqrt ( ratio_tensor [ 0 ]), sizes [ 0 ] * torch . sqrt ( ratio_tensor [ 1 :]))) \\ * in_height / in_width # Handle rectangular inputs h = torch . cat (( size_tensor / torch . sqrt ( ratio_tensor [ 0 ]), sizes [ 0 ] / torch . sqrt ( ratio_tensor [ 1 :]))) # Divide by 2 to get half height and half width anchor_manipulations = torch . stack (( - w , - h , w , h )) . T . repeat ( in_height * in_width , 1 ) / 2 # Each center point will have `boxes_per_pixel` number of anchor boxes, so # generate a grid of all anchor box centers with `boxes_per_pixel` repeats out_grid = torch . stack ([ shift_x , shift_y , shift_x , shift_y ], dim = 1 ) . repeat_interleave ( boxes_per_pixel , dim = 0 ) output = out_grid + anchor_manipulations return output . unsqueeze ( 0 )","title":"Bounding boxes"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/object_detection/bounding_boxes/#bounding-boxes","text":"In object detection, we usually use a bounding box to describe the spatial location of an object. The bounding box is rectangular, which is determined by the \\(x\\) and \\(y\\) coordinates of the upper-left corner of the rectangle and the such coordinates of the lower-right corner. Another commonly used bounding box representation is the \\((x, y)\\) -axis coordinates of the bounding box center, and the width and height of the box. [ Here we define functions to convert between ] these ( two representations ): box_corner_to_center converts from the two-corner representation to the center-width-height presentation, and box_center_to_corner vice versa. The input argument boxes should be a two-dimensional tensor of shape ( \\(n\\) , 4), where \\(n\\) is the number of bounding boxes. Different conversions https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/ https://github.com/awsaf49/bbox/blob/main/bbox/utils.py","title":"Bounding Boxes"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/object_detection/bounding_boxes/#pascal","text":"https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/ pascal_voc is a format used by the Pascal VOC dataset . Coordinates of a bounding box are encoded with four values in pixels: [x_min, y_min, x_max, y_max] . x_min and y_min are coordinates of the top-left corner of the bounding box. x_max and y_max are coordinates of bottom-right corner of the bounding box. Coordinates of the example bounding box in this format are [98, 345, 420, 462] .","title":"Pascal"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/object_detection/bounding_boxes/#coco","text":"coco is a format used by the Common Objects in Context \\(COCO\\) dataset. In coco , a bounding box is defined by four values in pixels [x_min, y_min, width, height] . They are coordinates of the top-left corner along with the width and height of the bounding box. Coordinates of the example bounding box in this format are [98, 345, 322, 117] .","title":"COCO"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/object_detection/bounding_boxes/#yolo","text":"In yolo , a bounding box is represented by four values [x_center, y_center, width, height] . x_center and y_center are the normalized coordinates of the center of the bounding box. To make coordinates normalized, we take pixel values of x and y, which marks the center of the bounding box on the x- and y-axis. Then we divide the value of x by the width of the image and value of y by the height of the image. width and height represent the width and the height of the bounding box. They are normalized as well. Coordinates of the example bounding box in this format are [((420 + 98) / 2) / 640, ((462 + 345) / 2) / 480, 322 / 640, 117 / 480] which are [0.4046875, 0.840625, 0.503125, 0.24375] . def voc2coco ( bboxes : Union [ np . ndarray , torch . Tensor ], return_tensor : bool = False ) -> np . ndarray : \"\"\"Convert pascal_voc to coco format. voc => [xmin, ymin, xmax, ymax] coco => [xmin, ymin, w, h] Args: bboxes (torch.Tensor): Shape of (N, 4) where N is the number of samples and 4 is the coordinates [xmin, ymin, xmax, ymax]. Returns: coco_bboxes (torch.Tensor): Shape of (N, 4) where N is the number of samples and 4 is the coordinates [xmin, ymin, w, h]. \"\"\" # don't perform in place to avoid mutation if isinstance ( bboxes , torch . Tensor ): bboxes = bboxes . cpu () . detach () . numpy () coco_bboxes = bboxes . copy () for index , each_bbox in enumerate ( bboxes ): xmin , ymin , xmax , ymax = each_bbox w , h = xmax - xmin , ymax - ymin if return_tensor : coco_bboxes [ index ] = torch . tensor ([ xmin , ymin , w , h ]) else : coco_bboxes [ index ] = np . asarray ([ xmin , ymin , w , h ]) return coco_bboxes def coco2voc ( bboxes : Union [ np . ndarray , torch . Tensor ], return_tensor : bool = False ) -> np . ndarray : \"\"\"Convert coco to pascal_voc format. coco => [xmin, ymin, w, h] voc => [xmin, ymin, xmax, ymax] Args: bboxes (torch.Tensor): Shape of (N, 4) where N is the number of samples and 4 is the coordinates [xmin, ymin, w, h]. Returns: voc_bboxes (torch.Tensor): Shape of (N, 4) where N is the number of samples and 4 is the coordinates [xmin, ymin, xmax, ymax]. \"\"\" # don't perform in place to avoid mutation if isinstance ( bboxes , torch . Tensor ): bboxes = bboxes . cpu () . detach () . numpy () voc_bboxes = bboxes . copy () for index , each_bbox in enumerate ( bboxes ): xmin , ymin , w , h = each_bbox xmax , ymax = xmin + w , ymin + h if return_tensor : voc_bboxes [ index ] = torch . tensor ([ xmin , ymin , xmax , ymax ]) else : voc_bboxes [ index ] = np . asarray ([ xmin , ymin , xmax , ymax ]) return voc_bboxes from numba import jit import cv2 import numpy as np import random __all__ = [ 'coco2yolo' , 'yolo2coco' , 'voc2coco' , 'coco2voc' , 'yolo2voc' , 'voc2yolo' , 'bbox_iou' , 'draw_bboxes' , 'load_image' ] def voc2yolo ( bboxes , height = 720 , width = 1280 ): \"\"\" voc => [x1, y1, x2, y1] yolo => [xmid, ymid, w, h] (normalized) \"\"\" if isinstance ( bboxes , torch . Tensor ): bboxes = bboxes . cpu () . detach () . numpy () bboxes = bboxes . copy () . astype ( float ) # otherwise all value will be 0 as voc_pascal dtype is np.int bboxes [ ... , 0 :: 2 ] /= width bboxes [ ... , 1 :: 2 ] /= height bboxes [ ... , 2 ] -= bboxes [ ... , 0 ] bboxes [ ... , 3 ] -= bboxes [ ... , 1 ] bboxes [ ... , 0 ] += bboxes [ ... , 2 ] / 2 bboxes [ ... , 1 ] += bboxes [ ... , 3 ] / 2 return bboxes def yolo2voc ( bboxes , height = 720 , width = 1280 ): \"\"\" yolo => [xmid, ymid, w, h] (normalized) voc => [x1, y1, x2, y1] \"\"\" if isinstance ( bboxes , torch . Tensor ): bboxes = bboxes . cpu () . detach () . numpy () bboxes = bboxes . copy () . astype ( float ) # otherwise all value will be 0 as voc_pascal dtype is np.int bboxes [ ... , 0 :: 2 ] *= width bboxes [ ... , 1 :: 2 ] *= height bboxes [ ... , 0 : 2 ] -= bboxes [ ... , 2 : 4 ] / 2 bboxes [ ... , 2 : 4 ] += bboxes [ ... , 0 : 2 ] return bboxes def coco2yolo ( bboxes , height = 720 , width = 1280 ): \"\"\" https://github.com/awsaf49/bbox/blob/main/bbox/utils.py coco => [xmin, ymin, w, h] yolo => [xmid, ymid, w, h] (normalized) \"\"\" # bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int # normolizinig bboxes [ ... , 0 :: 2 ] /= width bboxes [ ... , 1 :: 2 ] /= height # converstion (xmin, ymin) => (xmid, ymid) bboxes [ ... , 0 : 2 ] += bboxes [ ... , 2 : 4 ] / 2 return bboxes def yolo2coco ( bboxes , height = 720 , width = 1280 ): \"\"\" https://github.com/awsaf49/bbox/blob/main/bbox/utils.py yolo => [xmid, ymid, w, h] (normalized) coco => [xmin, ymin, w, h] \"\"\" # bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int # denormalizing bboxes [ ... , 0 :: 2 ] *= width bboxes [ ... , 1 :: 2 ] *= height # converstion (xmid, ymid) => (xmin, ymin) bboxes [ ... , 0 : 2 ] -= bboxes [ ... , 2 : 4 ] / 2 return bboxes dog_bbox , cat_bbox = [ 60.0 , 45.0 , 378.0 , 516.0 ], [ 400.0 , 112.0 , 655.0 , 493.0 ] bboxes = torch . tensor (( dog_bbox , cat_bbox )) bboxes tensor([[ 60., 45., 378., 516.], [400., 112., 655., 493.]])","title":"YOLO"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/object_detection/bounding_boxes/#voc-coco-test","text":"np . testing . assert_array_equal ( bboxes , coco2voc ( voc2coco ( bboxes ))) np . array_equal ( bboxes , coco2voc ( voc2coco ( bboxes ))) True","title":"VOC-COCO Test"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/object_detection/bounding_boxes/#voc-yolo-test","text":"coco2voc ( voc2coco ( bboxes )) array([[ 60., 45., 378., 516.], [400., 112., 655., 493.]], dtype=float32) yolo2voc ( voc2yolo ( bboxes , height = 561 , width = 768 ), height = 561 , width = 768 ) array([[ 60., 45., 378., 516.], [400., 112., 655., 493.]]) yolo2voc ( voc2yolo ( bboxes , height = 561 , width = 768 ), height = 561 , width = 768 ) array([[ 60., 45., 378., 516.], [400., 112., 655., 493.]]) a = voc2coco ( bboxes ) b = coco2voc ( a ) a , b (array([[ 60., 45., 318., 471.], [400., 112., 255., 381.]], dtype=float32), array([[ 60., 45., 378., 516.], [400., 112., 655., 493.]], dtype=float32)) We measure the bounding box coordinates for the cat and dog respectively. Here bbox is the abbreviation for bounding box. The bbox below represents dog_bbox , cat_bbox = [ 60.0 , 45.0 , 378.0 , 516.0 ], [ 400.0 , 112.0 , 655.0 , 493.0 ] def draw_bboxes_on_single_image ( image : Union [ torch . Tensor , np . ndarray ], bboxes : Union [ torch . Tensor , np . ndarray ], labels : Union [ torch . Tensor , np . ndarray , List [ int ]], labels_map : Dict [ int , str ], colors : Dict [ int , Tuple [ int , int , int ]], ) -> np . ndarray : \"\"\"Draws bounding boxes on a single image. Args: image (Union[torch.Tensor, np.ndarray]): The original image to draw on. bboxes (Union[torch.Tensor, np.ndarray]): The bounding boxes of the original image. This should be in voc_pascal format of (xmin, ymin, xmax, ymax). labels (Union[torch.Tensor, np.ndarray, List[int]]): The labels of the bounding boxes corresponding to the bounding boxes. Note they are needed to be in the same order as the bounding boxes. colors (Dict[int, Tuple[int, int, int]]): The color mapping of the labels. Returns: image (np.ndarray): The image with bounding boxes drawn on it. Shapes: - Input: - image: :math:`(H, W, C)` or :math:`(C, H, W)` depending on whether the channels are the first or last dimension. - bboxes: :math:`(N, 4)` where the bounding boxes are in the format of (xmin, ymin, xmax, ymax) and N is the number of bounding boxes. - labels: :math:`(N,)` where N is the number of bounding boxes. - Output: - image: :math:`(H, W, C)` Example: >>> import torch >>> import numpy as np >>> cat_dog_p = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/deep_learning/computer_vision/data/misc/catdog.jpg\" >>> cat_dog = PIL.Image.open(urlopen(cat_dog_p)) >>> dog_bbox, cat_bbox = [60.0, 45.0, 378.0, 516.0], [400.0, 112.0, 655.0, 493.0] >>> bboxes = torch.tensor((dog_bbox, cat_bbox)) # convert to (N, 2) >>> labels = [0, 1] >>> labels_map = {0: \"dog\", 1: \"cat\"} >>> colors = {0: (255, 0, 255), 1: (0, 255, 255)} >>> bbox_img = draw_bboxes_on_single_image(cat_dog, bboxes, labels=labels, labels_map=labels_map, colors=colors) >>> plt.imshow(bbox_img); \"\"\" if isinstance ( image , torch . Tensor ): image = image . cpu () . detach () . numpy () if isinstance ( bboxes , torch . Tensor ): bboxes = bboxes . cpu () . detach () . numpy () if isinstance ( labels , torch . Tensor ): labels = labels . cpu () . detach () . numpy () # make sure it is in np.ndarray format if read as PIL image = np . asarray ( image . copy ()) labels = np . asarray ( labels . copy ()) # if labels is like [[0], [1], [0]] then flatten if len ( labels . shape ) > 1 : labels = labels . flatten () # line/font thickness line_thickness = round ( 0.002 * ( image . shape [ 0 ] + image . shape [ 1 ]) / 2 ) + 1 for i , ( bbox , label ) in enumerate ( zip ( bboxes , labels )): color = colors [ label ] pt1 , pt2 = ( bbox [ 0 ], bbox [ 1 ]), ( bbox [ 2 ], bbox [ 3 ]) pt1 = int ( pt1 [ 0 ]), int ( pt1 [ 1 ]) pt2 = int ( pt2 [ 0 ]), int ( pt2 [ 1 ]) image = cv2 . rectangle ( image . copy (), pt1 , pt2 , color , int ( max ( image . shape [: 2 ]) / 200 ) ) # annotate text label2str = labels_map [ label ] cv2 . putText ( image , label2str , pt1 , cv2 . FONT_HERSHEY_SIMPLEX , line_thickness / 3 , color = [ 0 , 0 , 0 ], thickness = line_thickness , lineType = cv2 . LINE_AA , ) return image >>> import torch >>> import numpy as np >>> cat_dog_p = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/deep_learning/computer_vision/data/misc/catdog.jpg\" >>> cat_dog = PIL . Image . open ( urlopen ( cat_dog_p )) >>> dog_bbox , cat_bbox = [ 60.0 , 45.0 , 378.0 , 516.0 ], [ 400.0 , 112.0 , 655.0 , 493.0 ] >>> bboxes = torch . tensor (( dog_bbox , cat_bbox )) >>> labels = [ 0 , 1 ] >>> labels_map = { 0 : \"dog\" , 1 : \"cat\" } >>> colors = { 0 : ( 255 , 0 , 255 ), 1 : ( 0 , 255 , 255 )} >>> bbox_img = draw_bboxes_on_single_image ( cat_dog , bboxes , labels = labels , labels_map = labels_map , colors = colors ) >>> plt . imshow ( bbox_img );","title":"VOC-YOLO Test"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/computer_vision/object_detection/bounding_boxes/#anchor-boxes","text":"def multibox_prior ( data , sizes , ratios ): \"\"\"Generate anchor boxes with different shapes centered on each pixel.\"\"\" in_height , in_width = data . shape [ - 2 :] device , num_sizes , num_ratios = data . device , len ( sizes ), len ( ratios ) boxes_per_pixel = ( num_sizes + num_ratios - 1 ) size_tensor = torch . tensor ( sizes , device = device ) ratio_tensor = torch . tensor ( ratios , device = device ) # Offsets are required to move the anchor to the center of a pixel. Since # a pixel has height=1 and width=1, we choose to offset our centers by 0.5 offset_h , offset_w = 0.5 , 0.5 steps_h = 1.0 / in_height # Scaled steps in y axis steps_w = 1.0 / in_width # Scaled steps in x axis # Generate all center points for the anchor boxes center_h = ( torch . arange ( in_height , device = device ) + offset_h ) * steps_h center_w = ( torch . arange ( in_width , device = device ) + offset_w ) * steps_w shift_y , shift_x = torch . meshgrid ( center_h , center_w ) shift_y , shift_x = shift_y . reshape ( - 1 ), shift_x . reshape ( - 1 ) # Generate `boxes_per_pixel` number of heights and widths that are later # used to create anchor box corner coordinates (xmin, xmax, ymin, ymax) w = torch . cat (( size_tensor * torch . sqrt ( ratio_tensor [ 0 ]), sizes [ 0 ] * torch . sqrt ( ratio_tensor [ 1 :]))) \\ * in_height / in_width # Handle rectangular inputs h = torch . cat (( size_tensor / torch . sqrt ( ratio_tensor [ 0 ]), sizes [ 0 ] / torch . sqrt ( ratio_tensor [ 1 :]))) # Divide by 2 to get half height and half width anchor_manipulations = torch . stack (( - w , - h , w , h )) . T . repeat ( in_height * in_width , 1 ) / 2 # Each center point will have `boxes_per_pixel` number of anchor boxes, so # generate a grid of all anchor box centers with `boxes_per_pixel` repeats out_grid = torch . stack ([ shift_x , shift_y , shift_x , shift_y ], dim = 1 ) . repeat_interleave ( boxes_per_pixel , dim = 0 ) output = out_grid + anchor_manipulations return output . unsqueeze ( 0 )","title":"Anchor Boxes"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/ensemble_theory/forward_ensemble/","text":"import pandas as pd import numpy as np import os import matplotlib.pyplot as plt from typing import List , Tuple , Callable from sklearn.metrics import roc_auc_score Convert OOFs and Ground Truth to NumPy First, we define a function return_list_of_dataframes to return either the OOFs or the SUBs. At this point, one should be clear what are OOFs, if not, please read the post here . def return_list_of_dataframes ( path : str , is_oof : bool = True ) -> Tuple [ List [ pd . DataFrame ], int ]: \"\"\"Return a list of dataframes from a directory of files. The boolean is_oof is used to determine whether the list of dataframes contains oof or subs. Args: path (str): The path to the directory containing the files. is_oof (bool, optional): Determine whether the list of dataframes contains oof or subs. Defaults to True. Returns: List[pd.DataFrame]: The list of dataframes for either oof or subs. int: The number of files in the directory. \"\"\" oof_and_subs_files = os . listdir ( path ) if is_oof : oof_files_sorted = np . sort ( [ f for f in oof_and_subs_files if \"oof\" in f ] ) return [ pd . read_csv ( os . path . join ( path , k )) for k in oof_files_sorted ], len ( oof_files_sorted ) else : sub_files_sorted = np . sort ( [ f for f in oof_and_subs_files if \"sub\" in f ] ) return [ pd . read_csv ( os . path . join ( path , k )) for k in sub_files_sorted ], len ( sub_files_sorted ) This function is first applied to is_oof=True . For now, we just want all our OOFs converted to a pandas dataframe, and stored in a list. Note, we also conveniently returned the number of files in the director for OOFs and SUBs respectively, it should be clear in this context that the number of files for OOF is the same as the number of files for SUB. oof_and_subs_path = \"./oof_and_subs/toy_examples\" oof_dfs_list , num_oofs = return_list_of_dataframes ( path = oof_and_subs_path , is_oof = True ) display ( oof_dfs_list [ 0 ]) display ( oof_dfs_list [ 1 ]) display ( oof_dfs_list [ 2 ]) print ( f \"We have { num_oofs } oof files. \\n \" ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } image_id y_trues class_0_oof class_1_oof 0 1 1 0.70 0.30 1 2 0 0.70 0.30 2 3 0 0.65 0.35 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } image_id y_trues class_0_oof class_1_oof 0 1 1 0.6 0.4 1 2 0 0.8 0.2 2 3 0 0.4 0.6 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } image_id y_trues class_0_oof class_1_oof 0 1 1 0.1 0.8 1 2 0 0.4 0.8 2 3 0 0.9 0.7 We have 3 oof files. At this junction, we need to be clear of a few things. Let us use an example to illustrate. Let us say we trained our model over 5 folds and get our OOF predictions in terms of the Macro-AUROC with respect to the positive class 1 . We then need to calculate our OOF scores with our corresponding y_trues. Just by eyeballing, we can deduce the Macro-AUROC score for the positive class as follows: oof_1_auroc = roc_auc_score ([ 1 , 0 , 0 ], [ 0.3 , 0.3 , 0.35 ]) -> 0.25 oof_2_auroc = roc_auc_score ([ 1 , 0 , 0 ], [ 0.4 , 0.2 , 0.6 ]) -> 0.5 oof_3_auroc = roc_auc_score ([ 1 , 0 , 0 ], [ 0.8 , 0.8 , 0.7 ]) -> 0.75 To compute the above, we can manually hardcode them, but for larger data, we will have to maintain a better data structure. We will store them into matrices and vectors (numpy) to compute the OOF scores efficiently. To do so, we define two variables: ground_truth_column_name = [ \"y_trues\" ] positive_class_oof_column_name = [ \"class_1_oof\" ] where the first variable is the name of the column(s) for the ground truth, while the second is the name of the column(s) that we will be using to compute the OOF scores. We will then create a function stack_oofs to convert the list of OOF dataframes into an array. def stack_oofs ( oof_dfs : List [ pd . DataFrame ], pred_column_names : List [ str ] ) -> np . ndarray : \"\"\"Stack all oof predictions horziontally. Args: oof_dfs (List[pd.DataFrame]): The list of oof predictions in dataframes. pred_column_names (List[str]): The list of prediction column names. Returns: all_oof_preds (np.ndarray): The stacked oof predictions of shape (num_samples, num_oofs * num_pred_columns). Example: >>> oof_1 = pd.DataFrame([1,2,3], columns=['class_1_oof']) >>> oof_2 = pd.DataFrame([4,5,6], columns=['class_1_oof']) >>> all_oof_preds = stack_oofs([oof_1, oof_2], ['class_1_oof']) >>> all_oof_preds = np.array([1, 4], [2, 5], [3, 6]) \"\"\" num_oofs = len ( oof_dfs ) num_samples = len ( oof_dfs [ 0 ]) num_target_cols = len ( pred_column_names ) all_oof_preds = np . zeros (( num_samples , num_oofs * num_target_cols )) if num_target_cols == 1 : for index , oof_df in enumerate ( oof_dfs ): all_oof_preds [:, index : index + 1 ] = oof_df [ pred_column_names ] . values elif num_target_cols > 1 : # Used in RANZCR where there are 11 target columns for index , oof_df in enumerate ( oof_dfs ): all_oof_preds [ :, index * num_target_cols : ( index + 1 ) * num_target_cols ] = oof_df [ pred_column_names ] . values return all_oof_preds ground_truth_column_name = [ \"y_trues\" ] positive_class_oof_column_name = [ \"class_1_oof\" ] In my oof files, I also saved the corresponding y_trues as a column, we thus take the first oof_df from oof_dfs_list and use it to get the y_trues , assuming they are the same for all oof files. Note of caution, if you use different resampling methods, you will need to change the y_trues accordingly. y_trues = oof_dfs_list [ 0 ][ ground_truth_column_name ] . values all_oof_preds = stack_oofs ( oof_dfs_list , positive_class_oof_column_name ) print ( f \"y_trues shape: { y_trues . shape } \\n This variable is global and holds all ground truth. \\n \" ) print ( f \"all_oof_preds shape: { all_oof_preds . shape } \\n This variable is global and holds all oof predictions stacked horizontally. \\n \" ) y_trues shape: (3, 1) This variable is global and holds all ground truth. all_oof_preds shape: (3, 3) This variable is global and holds all oof predictions stacked horizontally. After converting to numpy, we should have this following representation: \\[ \\textbf{y_true} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} \\in \\mathbb{R}^3 \\quad \\textbf{all_oof_preds} = \\begin{bmatrix} 0.3 & 0.4 & 0.8 \\\\ 0.3 & 0.2 & 0.8 \\\\ 0.35 & 0.6 & 0.7 \\end{bmatrix} \\in \\mathbb{R}^{3 \\times 3} \\] where y_true is a \\(3 \\times 1\\) column vector, each row entry is the corresponding ground truth for sample \\(i\\) (i.e y_true[0] is ground truth for sample 1). For all_oof_preds , this is a \\(3 \\times 3\\) matrix, where each column \\(i\\) represents the OOF predictions made by model \\(i\\) . In other words, the first column \\(\\begin{bmatrix} 0.3 \\\\ 0.35 \\\\ 0.3 \\end{bmatrix}\\) is the OOF predictions made by the first model. It is important to note that we are dealing with classification (binary or multiclass), so it is usually the case that both our target and predicted columns are just \\(1\\) . In multi-label however, we will have multiple target columns, and will be the focus in part II. Compute Scores of OOFs and Find the Best Score This part is very crucial, when we apply our Hill Climbing (Forward Ensembling) technique here, we want to initialize with the best models first and iteratively blend with the rest . In other words def compute_best_oof ( all_oof_preds : np . ndarray , y_trues : np . ndarray , num_oofs : int , performance_metric : Callable , ) -> Tuple [ float , int ]: \"\"\"Compute the oof score of all models using a performance metric and return the best model index and score. Args: all_oof_preds (np.ndarray): The stacked oof predictions of shape (num_samples, num_oofs * num_pred_columns). Taken from stack_oofs. y_trues (np.ndarray): The true labels of shape (num_samples, num_target_cols). num_oofs (int): The number of oof predictions. performance_metric (Callable): The performance metric to use, this is a function. Returns: best_oof_metric_score (float): The best oof score. best_model_index (int): The index of the best model. \"\"\" all_oof_scores = [] for k in range ( num_oofs ): oof_k = all_oof_preds [:, k ] . reshape ( - 1 , 1 ) metric_score = performance_metric ( y_trues , oof_k , num_target_cols = 1 , multilabel = False , ) all_oof_scores . append ( metric_score ) print ( f \"Model { k } has OOF AUC = { metric_score } \" ) best_oof_metric_score , best_oof_index = np . max ( all_oof_scores ), np . argmax ( all_oof_scores ) return best_oof_metric_score , best_oof_index def macro_multilabel_auc ( label , pred , num_target_cols : int = 1 , multilabel : bool = False ): \"\"\"Also works for binary AUC like Melanoma\"\"\" if not multilabel : return roc_auc_score ( label , pred ) else : aucs = [] for i in range ( num_target_cols ): print ( label [:, i ]) print () print ( pred [:, i ]) print ( roc_auc_score ( label [:, i ], pred [:, i ])) aucs . append ( roc_auc_score ( label , pred )) return np . mean ( aucs ) best_oof_metric_score , best_oof_index = compute_best_oof ( all_oof_preds = all_oof_preds , y_trues = y_trues , num_oofs = num_oofs , performance_metric = macro_multilabel_auc , ) print ( f \" \\n ### Computing Best OOF scores among all models ### \\n The best OOF AUC score is { best_oof_metric_score } and the best model index is { best_oof_index } corresponding to the oof file { best_oof_index } \" ) Model 0 has OOF AUC = 0.25 Model 1 has OOF AUC = 0.5 Model 2 has OOF AUC = 0.75 ### Computing Best OOF scores among all models ### The best OOF AUC score is 0.75 and the best model index is 2 corresponding to the oof file 2 The Algorithm Now the logic flows as follows: Start with the model with the best OOF score: we get that from compute_best_oof which yields us the key variables best_oof_index . best_oof_index : 2 indicates that our oof_2 (model 2) has the best OOF score amongst the 3 OOFs (models), as we can see from above, it is indeed the case since Model 2 has OOF AUC of \\(0.75\\) . We now need to blend Model 2 with Model 0 and Model 1 respectively to find out which weight combination gives a better OOF score. We need to define a variable weight_interval , which tells us the weights to sample from. For example, if weight_interval is \\(3\\) , then we will uniformly sample the weights \\(\\frac{0}{3}, \\frac{1}{3}, \\frac{2}{3}\\) . Let us see a concrete example. weight_interval = 3 patience_counter = 0 model_0_oof = all_oof_preds [:, 0 ] . reshape ( y_trues . shape ) model_1_oof = all_oof_preds [:, 1 ] . reshape ( y_trues . shape ) model_2_oof = all_oof_preds [:, best_oof_index ] . reshape ( y_trues . shape ) # best_oof_index=2 We define best_oof_index_list = [ best_oof_index ] best_weights_list = [] which keeps track two lists which holds the best OOFs to blend with and their corresponding weights. We use a naive example to illustrate: best_oof_index_list = [ 2 , 0 , 1 ] best_weights_list = [ 0.3 , 0.8 ] all_oof_preds_matrix = [[ 0.3 , 0.4 , 0.8 ], [ 0.3 , 0.2 , 0.8 ], [ 0.35 , 0.6 , 0.7 ]] initial_best_vector = A_matrix [:, 2 ] In other words, if after our Hill Climbing algorithm, we have the above variables and to calculate the final blended OOF using the above optimal weights, we have: Let \\(\\mathbf{c_i}\\) be the columns of the matrix all_oof_preds_matrix , you can think \\(\\mathbf{c_i}\\) as the Model \\(i\\) 's OOFs predictions, since in this naive example, we see that our initial best model is Model 2. \\[ ((1-0.3) \\times \\mathbf{c_2} + 0.3 \\times \\mathbf{c_0}) \\times (1-0.8) + 0.8 \\times \\mathbf{c_1} \\] To dissect clearly, we start with the first index, which is Model 2, and blend with the next index, which is Model 0, they will be blended with weights of \\(0.3\\) , which means \\((1-0.3) \\times \\mathbf{c_2} + 0.3 \\times \\mathbf{c_0}\\) . We call it oof_blend_1 which indicates the linear combination of the weights of the first blend. Note that this results in a new and better \"OOF predictions\". The next blend will be of oof_blend_1 with Model 1, with a weight of \\(0.8\\) and the assignment is \\((1-0.8) \\times \\textbf{oof_blend_1} + 0.8 \\times \\mathbf{c_0}\\) . best_oof_index_list = [ best_oof_index ] best_weights_list = [] print ( f \"Current Tracked Model List: { best_oof_index_list } \" ) print ( f \"Current Weights List: { best_weights_list } \" ) Current Tracked Model List: [2] Current Weights List: [] First Round - Blending Model 2 with Model 0 We check the blending results of Model 2 and Model 0 over 3 weights: \\(0, \\frac{1}{3}, \\frac{2}{3}\\) . We also assign 3 variables running_best_score , running_best_weight , running_best_oof_index = best_oof_metric_score , 0 , 0 such that whenever a blend of \\(w_1 \\times \\textbf{model_i_oof} + (1-w_2) \\times \\textbf{model_j_oof}\\) produces a better OOF score, then we will assign if temp_ensemble_oof_score >= running_best_score : print ( f \"The blend of weight { temp_weight } of model 2 and model 0 led to a greater or equals to OOF score = { temp_ensemble_oof_score } \\n \" ) running_best_score = temp_ensemble_oof_score running_best_weight = temp_weight running_best_oof_index = 0 Notice that we hardcoded the running_best_oof_index to be \\(0\\) since we know we are only looking at the interaction of Model 2 and Model 0. In proper code, this part should not be hardcoded and you can refer to my full code for clarity. running_best_score , running_best_weight , running_best_oof_index = best_oof_metric_score , 0 , 0 for weight in range ( weight_interval ): temp_weight = weight / weight_interval print ( f \"weight = { temp_weight } \" ) temp_ensemble_oof_preds = ( temp_weight * model_0_oof + ( 1 - temp_weight ) * model_2_oof ) temp_ensemble_oof_score = macro_multilabel_auc ( y_trues , temp_ensemble_oof_preds , num_target_cols = 1 , multilabel = False , ) print ( f \"blended OOF score with model_0_oof = { temp_ensemble_oof_score } \" ) if temp_ensemble_oof_score >= running_best_score : running_best_score = temp_ensemble_oof_score running_best_weight = temp_weight running_best_oof_index = 0 print ( f \"The blend of weight { temp_weight } of model 2 and model { running_best_oof_index } led to a greater or equals to OOF score = { temp_ensemble_oof_score } \\n \" ) weight = 0.0 blended OOF score with model_0_oof = 0.75 The blend of weight 0.0 of model 2 and model 0 led to a greater or equals to OOF score = 0.75 weight = 0.3333333333333333 blended OOF score with model_0_oof = 0.75 The blend of weight 0.3333333333333333 of model 2 and model 0 led to a greater or equals to OOF score = 0.75 weight = 0.6666666666666666 blended OOF score with model_0_oof = 0.5 So now we finished blending Model 2 and Model 0 and we have: running_best_score = 0.75 running_best_weight = 0.333 ... We need to blend Model 2 and Model 1 now to see if Model 2 and Model 1 can give better OOF scores when blended! We repeat the exact same loop as above, but bear in mind that the running_best_score and running_best_weight is already updated to the ones we got in the blend of Model 2 and Model 0 because we want to check if Model 2 and Model 1's blend can give better results than the previous running_best_score . First Round - Blending Model 2 and Model 1 for weight in range ( weight_interval ): temp_weight = weight / weight_interval print ( f \"weight = { temp_weight } \" ) temp_ensemble_oof_preds = ( temp_weight * model_1_oof + ( 1 - temp_weight ) * model_2_oof ) temp_ensemble_oof_score = macro_multilabel_auc ( y_trues , temp_ensemble_oof_preds , num_target_cols = 1 , multilabel = False , ) print ( f \"blended OOF score with model_1_oof = { temp_ensemble_oof_score } \" ) if temp_ensemble_oof_score >= running_best_score : running_best_score = temp_ensemble_oof_score running_best_weight = temp_weight running_best_oof_index = 1 print ( f \"The blend of weight { temp_weight } of model 2 and model { running_best_oof_index } led to a greater or equals to OOF score = { temp_ensemble_oof_score } \\n \" ) weight = 0.0 blended OOF score with model_1_oof = 0.75 The blend of weight 0.0 of model 2 and model 1 led to a greater or equals to OOF score = 0.75 weight = 0.3333333333333333 blended OOF score with model_1_oof = 1.0 The blend of weight 0.3333333333333333 of model 2 and model 1 led to a greater or equals to OOF score = 1.0 weight = 0.6666666666666666 blended OOF score with model_1_oof = 0.5 So now we finished blending Model 2 and Model 1 and we have: running_best_score = 1 running_best_weight = 0.333 ... and we have a new winner in town! After our first round of iterating our initial best OOF Model 2 with the rest (Model 0 and 1), we found out that if we take \\(w_1 = 1 - \\frac{2}{3}\\) and \\(w_2 = \\frac{1}{3}\\) , Model 2 and 1 gives us a better overall score. That is to say: \\[ w_1 * \\textbf{OOF_2} + w_2 \\times \\textbf{OOF_1} \\] leads to the greatest increase in our OOF score! Notice that we hardcoded the running_best_oof_index to be \\(1\\) since we know we are only looking at the interaction of Model 2 and Model 1. In proper code, this part should not be hardcoded and you can refer to my full code for clarity. Technically, we can stop the algorithm now since the metric Macro-AUROC is capped at \\(1\\) , but for the sake of explanation, let us continue. First Round - Save Results for Loop 1 We then append the best OOF index and the corresponding weight to the best_oof_index_list and best_weights_list respectively. best_oof_index_list . append ( running_best_oof_index ) best_weights_list . append ( running_best_weight ) print ( f \"Current Tracked Model List: { best_oof_index_list } \" ) print ( f \"Current Weights List: { best_weights_list } \" ) Current Tracked Model List: [2, 1] Current Weights List: [0.3333333333333333] Second Round - Blend OOF Now we have a brand new OOF after blending Model 2 and Model 1, we call it blended_oof_1 and note that this is our new best OOF! # blended_oof_1 = all_oof_preds[:, best_oof_index_list[0]].reshape(-1, 1) * (1 - best_weights_list[0]) + all_oof_preds[:, best_oof_index_list[1]].reshape(-1, 1) * best_weights_list[0] blended_oof_1 = model_2_oof * ( 1 - 1 / 3 ) + model_1_oof * ( 1 / 3 ) assert macro_multilabel_auc ( y_trues , blended_oof_1 ) == 1 Second Round - Blending blended_oof_1 with Model 0 We continue to try out blended_oof_1 with the rest of the models that were not selected. This means we have to check our Current Tracked Model List best_oof_index_list and see that we already have \\([2, 1]\\) being used up, in our simple example here, there only left with Model 0 to try! So make sure in your code you do not try blended_oof_1 with Model 0, 1 and 2 again since the blended_oof_1 is already made up with Model 1 and 2! for weight in range ( weight_interval ): temp_weight = weight / weight_interval print ( f \" \\n weight = { temp_weight } \" ) temp_ensemble_oof_preds = ( temp_weight * model_0_oof + ( 1 - temp_weight ) * blended_oof_1 ) temp_ensemble_oof_score = macro_multilabel_auc ( y_trues , temp_ensemble_oof_preds , num_target_cols = 1 , multilabel = False , ) print ( f \"blended OOF score with model_0_oof = { temp_ensemble_oof_score } \" ) if temp_ensemble_oof_score >= running_best_score : running_best_score = temp_ensemble_oof_score running_best_weight = temp_weight running_best_oof_index = 0 print ( f \"The blend of weight { temp_weight } of model 2 and model { running_best_oof_index } led to a greater or equals to OOF score = { temp_ensemble_oof_score } \\n \" ) weight = 0.0 blended OOF score with model_0_oof = 1.0 The blend of weight 0.0 of model 2 and model 0 led to a greater or equals to OOF score = 1.0 weight = 0.3333333333333333 blended OOF score with model_0_oof = 0.5 weight = 0.6666666666666666 blended OOF score with model_0_oof = 0.5 Since we have done checking blended_oof_1 with the last remaining Model 0 and found that blending Model 0 with a weight of 0 (what a surprise haha!) yields the best result, we once again update the running metrics and also append to our global lists below. best_oof_index_list . append ( running_best_oof_index ) best_weights_list . append ( running_best_weight ) print ( f \"Current Tracked Model List: { best_oof_index_list } \" ) print ( f \"Current Weights List: { best_weights_list } \" ) Current Tracked Model List: [2, 1, 0] Current Weights List: [0.3333333333333333, 0.0] # blended_oof_2 = blended_oof_1 * (1 - best_weights_list[1]) + all_oof_preds[:, best_oof_index_list[2]].reshape(-1, 1) * best_weights_list[1] blended_oof_2 = blended_oof_1 * ( 1 - 0.0 ) + model_0_oof . reshape ( - 1 , 1 ) * 0.0 assert macro_multilabel_auc ( y_trues , blended_oof_2 ) == 1 Ensembling Model Predictions with the Found Optimal Weights So we end the discussion with what to do with the weights we got. We already established to the readers that our Initial Best OOF is Model 2 with a Macro-AUROC score of \\(0.75\\) , and by way of Hill Climbing, we found out that we can blend the 3 Models with some weights such that their new OOF produces a Macro-AUROC score of \\(1.0\\) , a huge improvement. We aren't done yet! We want to apply these optimal weights to our test set predictions as well. Note that our test set predictions are unseen and our usual ensemble methods can be as simple as mean averaging. More concretely, let us check out the example below. oof_and_subs_path = \"./oof_and_subs/toy_examples\" sub_dfs_list , num_subs = return_list_of_dataframes ( path = oof_and_subs_path , is_oof = False ) display ( sub_dfs_list [ 0 ]) display ( sub_dfs_list [ 1 ]) display ( sub_dfs_list [ 2 ]) print ( f \"We have { num_subs } sub files. \\n \" ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } image_id class_0_preds class_1_preds 0 4 0.2 0.8 1 5 0.3 0.7 2 6 0.6 0.4 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } image_id class_0_preds class_1_preds 0 4 0.3 0.7 1 5 0.9 0.1 2 6 0.2 0.8 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } image_id class_0_preds class_1_preds 0 4 0.3 0.7 1 5 0.7 0.3 2 6 0.8 0.2 We have 3 sub files. The stack_subs function does the same thing as stack_oofs so they can be combined into one function for code clarity. def stack_subs ( sub_dfs : List [ pd . DataFrame ], pred_column_names : List [ str ] ) -> np . ndarray : \"\"\"Stack all sub predictions horziontally. Args: sub_dfs (List[pd.DataFrame]): The list of sub predictions in dataframes. pred_column_names (List[str]): The list of prediction column names. Returns: all_sub_preds (np.ndarray): The stacked oof predictions of shape (num_samples, num_subs * num_pred_columns). \"\"\" num_subs = len ( sub_dfs ) num_samples = len ( sub_dfs [ 0 ]) num_target_cols = len ( pred_column_names ) all_sub_preds = np . zeros (( num_samples , num_subs * num_target_cols )) if num_target_cols == 1 : for index , sub_df in enumerate ( sub_dfs ): all_sub_preds [:, index : index + 1 ] = sub_df [ pred_column_names ] . values elif num_target_cols > 1 : # Used in RANZCR where there are 11 target columns for index , sub_df in enumerate ( sub_dfs ): all_sub_preds [ :, index * num_target_cols : ( index + 1 ) * num_target_cols ] = sub_df [ pred_column_names ] . values return all_sub_preds test_set_target_column_name = [ \"class_1_preds\" ] all_subs_preds = stack_subs ( sub_dfs_list , test_set_target_column_name ) model_0_sub = all_subs_preds [:, 0 ] . reshape ( y_trues . shape ) model_1_sub = all_subs_preds [:, 1 ] . reshape ( y_trues . shape ) model_2_sub = all_subs_preds [:, 2 ] . reshape ( y_trues . shape ) Recall the optimal weights earlier: Current Tracked Model List : [ 2 , 1 , 0 ] Current Weights List : [ 0.3333333333333333 , 0.0 ] and we now have a way to ensemble our model subs accordingly. # blended_oof_1 = all_oof_preds[:, best_oof_index_list[0]].reshape(-1, 1) * (1 - best_weights_list[0]) + all_oof_preds[:, best_oof_index_list[1]].reshape(-1, 1) * best_weights_list[0] blended_sub_1 = model_2_sub * ( 1 - 1 / 3 ) + model_1_sub * ( 1 / 3 ) blended_sub_2 = blended_sub_1 * ( 1 - 0.0 ) + model_0_sub * 0.0 blended_sub_2 array([[0.7 ], [0.23333333], [0.4 ]]) Then blended_sub_2 should be our final test set predictions ! Forward Ensemble with SIIM-ISIC Melanoma Classification This is taken from my repo. import pandas as pd import numpy as np import os import matplotlib.pyplot as plt from typing import List , Tuple , Callable from sklearn.metrics import roc_auc_score def stack_oofs ( oof_dfs : List [ pd . DataFrame ], pred_column_names : List [ str ] ) -> np . ndarray : \"\"\"Stack all oof predictions horziontally. Args: oof_dfs (List[pd.DataFrame]): The list of oof predictions in dataframes. pred_column_names (List[str]): The list of prediction column names. Returns: all_oof_preds (np.ndarray): The stacked oof predictions of shape (num_samples, num_oofs * num_pred_columns). Example: >>> oof_1 = pd.DataFrame([1,2,3], columns=['class_1_oof']) >>> oof_2 = pd.DataFrame([4,5,6], columns=['class_1_oof']) >>> all_oof_preds = stack_oofs([oof_1, oof_2], ['class_1_oof']) >>> all_oof_preds = np.array([1, 4], [2, 5], [3, 6]) \"\"\" num_oofs = len ( oof_dfs ) num_samples = len ( oof_dfs [ 0 ]) num_target_cols = len ( pred_column_names ) all_oof_preds = np . zeros (( num_samples , num_oofs * num_target_cols )) if num_target_cols == 1 : for index , oof_df in enumerate ( oof_dfs ): all_oof_preds [:, index : index + 1 ] = oof_df [ pred_column_names ] . values elif num_target_cols > 1 : # Used in RANZCR where there are 11 target columns for index , oof_df in enumerate ( oof_dfs ): all_oof_preds [ :, index * num_target_cols : ( index + 1 ) * num_target_cols ] = oof_df [ pred_column_names ] . values return all_oof_preds def macro_multilabel_auc ( label , pred , num_target_cols : int = 1 , multilabel : bool = False ): \"\"\"Also works for binary AUC like Melanoma\"\"\" if not multilabel : return roc_auc_score ( label , pred ) else : aucs = [] for i in range ( num_target_cols ): print ( label [:, i ]) print () print ( pred [:, i ]) print ( roc_auc_score ( label [:, i ], pred [:, i ])) aucs . append ( roc_auc_score ( label , pred )) return np . mean ( aucs ) def compute_best_oof ( all_oof_preds : np . ndarray , y_trues : np . ndarray , num_oofs : int , performance_metric : Callable , ) -> Tuple [ float , int ]: \"\"\"Compute the oof score of all models using a performance metric and return the best model index and score. Args: all_oof_preds (np.ndarray): The stacked oof predictions of shape (num_samples, num_oofs * num_pred_columns). Taken from stack_oofs. y_trues (np.ndarray): The true labels of shape (num_samples, num_target_cols). num_oofs (int): The number of oof predictions. performance_metric (Callable): The performance metric to use, this is a function. Returns: best_oof_metric_score (float): The best oof score. best_model_index (int): The index of the best model. \"\"\" all_oof_scores = [] for k in range ( num_oofs ): metric_score = performance_metric ( y_trues , all_oof_preds [:, k ], num_target_cols = 1 , multilabel = False , ) all_oof_scores . append ( metric_score ) print ( f \"Model { k } has OOF AUC = { metric_score } \" ) best_oof_metric_score , best_oof_index = np . max ( all_oof_scores ), np . argmax ( all_oof_scores ) return best_oof_metric_score , best_oof_index def calculate_best_score_over_weight_interval ( weight_interval : float , model_i_oof : np . ndarray , model_j_oof : np . ndarray , y_trues : np . ndarray , performance_metric : Callable , running_best_score : float , running_best_weight : float , patience : int , ) -> Tuple [ float , float ]: \"\"\"Calculate the best score over a weight interval. Args: weight_interval (float): _description_ model_i_oof (np.ndarray): _description_ model_j_oof (np.ndarray): _description_ y_trues (np.ndarray): _description_ performance_metric (Callable): _description_ running_best_score (float): _description_ running_best_weight (float): _description_ patience (int): _description_ Returns: Tuple[float, float]: _description_ \"\"\" patience_counter = 0 for weight in range ( weight_interval ): temp_weight = weight / weight_interval temp_ensemble_oof_preds = ( temp_weight * model_j_oof + ( 1 - temp_weight ) * model_i_oof ) temp_ensemble_oof_score = performance_metric ( y_trues , temp_ensemble_oof_preds , num_target_cols = 1 , multilabel = False , ) # in the first loop, if any of the blending is more than best_oof_metric_score, we will assign it to running_best_score. if temp_ensemble_oof_score > running_best_score : running_best_score = temp_ensemble_oof_score running_best_weight = temp_weight else : patience_counter += 1 if patience_counter > patience : break return running_best_score , running_best_weight def get_blended_oof ( initial_best_model_oof , best_oof_index_list , best_weights_list ): # can be used on both oof and subs curr_model_oof = initial_best_model_oof for index , _ in enumerate ( best_oof_index_list [ 1 :]): model_j_index = best_oof_index_list [ index + 1 ] curr_model_oof = ( 1 - best_weights_list [ index ]) * curr_model_oof + ( best_weights_list [ index ] ) * all_oof_preds [:, model_j_index ] . reshape ( - 1 , 1 ) return curr_model_oof def return_list_of_dataframes ( path : str , is_oof : bool = True ) -> Tuple [ List [ pd . DataFrame ], int ]: \"\"\"Return a list of dataframes from a directory of files. The boolean is_oof is used to determine whether the list of dataframes contains oof or subs. Args: path (str): The path to the directory containing the files. is_oof (bool, optional): Determine whether the list of dataframes contains oof or subs. Defaults to True. Returns: List[pd.DataFrame]: The list of dataframes for either oof or subs. int: The number of files in the directory. \"\"\" oof_and_subs_files = os . listdir ( path ) if is_oof : oof_files_sorted = np . sort ( [ f for f in oof_and_subs_files if \"oof\" in f ] ) return [ pd . read_csv ( os . path . join ( path , k )) for k in oof_files_sorted ], len ( oof_files_sorted ) else : sub_files_sorted = np . sort ( [ f for f in oof_and_subs_files if \"sub\" in f ] ) return [ pd . read_csv ( os . path . join ( path , k )) for k in sub_files_sorted ], len ( sub_files_sorted ) if __name__ == \"__main__\" : oof_and_subs_path = \"./oof_and_subs/melanoma\" # [\"oof_1.csv\", \"sub_1.csv\", \"oof_2.csv\", \"sub_2.csv\"] oof_and_subs_files = os . listdir ( oof_and_subs_path ) # [\"oof_1.csv\", \"oof_2.csv\", \"sub_1.csv\", \"sub_2.csv\"] sorted oof_files_sorted = np . sort ([ f for f in oof_and_subs_files if \"oof\" in f ]) # [oof_1_df, oof_2_df, sub_1_df, sub_2_df] in dataframe oof_dfs_list = [ pd . read_csv ( os . path . join ( oof_and_subs_path , k )) for k in oof_files_sorted ] num_oofs = len ( oof_dfs_list ) # in my oof files, I also saved the corresponding y_trues, we thus take the first oof_df and use it to get the y_trues, assuming they are the same for all oof files. # note of caution, if you use different resampling methods, you will need to change the y_trues accordingly. y_trues_df = oof_dfs_list [ 0 ][[ \"oof_trues\" ]] y_trues = y_trues_df . values print ( f \"We have { len ( oof_files_sorted ) } oof files. \\n \" ) target_cols = [ \"oof_trues\" ] pred_cols = [ \"class_1_oof\" ] num_target_cols = len ( target_cols ) all_oof_preds = stack_oofs ( oof_dfs = oof_dfs_list , pred_column_names = pred_cols ) print ( f \"all_oof_preds shape: { all_oof_preds . shape } \\n This variable is global and holds all oof predictions stacked horizontally. \\n \" ) best_oof_metric_score , best_oof_index = compute_best_oof ( all_oof_preds = all_oof_preds , y_trues = y_trues , num_oofs = num_oofs , performance_metric = macro_multilabel_auc , ) print ( f \" \\n ### Computing Best OOF scores among all models ### \\n The best OOF AUC score is { best_oof_metric_score } and the best model index is { best_oof_index } corresponding to the oof file { oof_files_sorted [ best_oof_index ] } \" ) weight_interval = 1000 # 200 patience = 20 # 10 min_increase = 0.0003 # 0.00003 print ( f \" \\n ### HyperParameters ### \\n weight_interval = { weight_interval } \\n patience = { patience } \\n min_increase = { min_increase } \\n \" ) # keep track of oof index that are blended best_oof_index_list = [ best_oof_index ] best_weights_list = [] print ( f \"Current Tracked Model List: { best_oof_index_list } \" ) print ( f \"Current Weights List: { best_weights_list } \" ) counter = 0 # Initially, this curr_model_oof is the single best model that we got above from [oof_1, oof_2,...] initial_best_model_oof = all_oof_preds [:, best_oof_index ] . reshape ( - 1 , 1 ) old_best_score = best_oof_metric_score model_i_best_score , model_i_index , model_i_weights = 0 , 0 , 0 print ( \"Denote model i as the current model, and model j as the model that we are blending with.\" ) for outer_oof_index in range ( num_oofs ): # basically in the first loop, we already know the current model's oof and we assign it by subsetting the all_oof_preds with the best oof index. curr_model_oof = initial_best_model_oof if counter > 0 : curr_model_oof = get_blended_oof ( initial_best_model_oof , best_oof_index_list , best_weights_list ) print ( curr_model_oof ) for inner_oof_index in range ( num_oofs ): # If we have [oof_1, oof_2] and best_oof_index = 1 (oof_2), then we do not need to blend oof_2 and itself. if inner_oof_index in best_oof_index_list : continue # in the first loop, our running_best_score is the best_oof_metric_score # also our old_best_score is the best_oof_metric_score in the first loop ( running_best_score , running_best_weight , patience_counter ,) = ( 0 , 0 , 0 , ) # what we are doing here is to find the best oof score among all models that we have not blended yet. # for example, if we have [oof_1, oof_2, oof_3], and we know oof_2 is our initial_best_model_oof, # then we need to blend oof_2 with oof_1, then oof_2 with oof_3 to find out which of them yields the best overall oof when blended. ( running_best_score , running_best_weight , ) = calculate_best_score_over_weight_interval ( weight_interval , curr_model_oof , all_oof_preds [:, inner_oof_index ] . reshape ( - 1 , 1 ), y_trues , macro_multilabel_auc , running_best_score , running_best_weight , patience , ) if running_best_score > model_i_best_score : model_i_index = inner_oof_index model_i_best_score = running_best_score model_i_weights = running_best_weight increment = model_i_best_score - old_best_score if increment <= min_increase : print ( \"Increment is too small, stop blending\" ) break # DISPLAY RESULTS print () print ( \"Ensemble AUC = %.4f after adding model %i with weight %.3f . Increase of %.4f \" % ( model_i_best_score , model_i_index , model_i_weights , increment , ) ) print () old_best_score = model_i_best_score best_oof_index_list . append ( model_i_index ) best_weights_list . append ( model_i_weights ) print ( f \"Current Tracked Model List: { best_oof_index_list } \" ) print ( f \"Current Weights List: { best_weights_list } \" ) print ( f \"Current Best Score: { model_i_best_score } \" ) counter += 1 plt . hist ( curr_model_oof , bins = 100 ) plt . title ( \"Ensemble OOF predictions\" ) plt . show () # apply on submission sub_files_sorted = np . sort ([ f for f in oof_and_subs_files if \"sub\" in f ]) sub_dfs_list = [ pd . read_csv ( os . path . join ( oof_and_subs_path , k )) for k in sub_files_sorted ] print ( f \" \\n We have { len ( sub_files_sorted ) } submission files...\" ) print () print ( sub_files_sorted ) y = np . zeros (( len ( sub_dfs_list [ 0 ]), len ( sub_files_sorted ) * len ( pred_cols ))) print ( y . shape ) for k in range ( len ( sub_files_sorted )): y [ :, int ( k * len ( pred_cols )) : int (( k + 1 ) * len ( pred_cols )) ] = sub_dfs_list [ k ][ \"target\" ] . values . reshape ( - 1 , 1 ) print ( y ) md2 = y [ :, int ( best_oof_index_list [ 0 ] * len ( pred_cols )) : int ( ( best_oof_index_list [ 0 ] + 1 ) * len ( pred_cols ) ), ] print ( md2 ) for i , k in enumerate ( best_oof_index_list [ 1 :]): md2 = ( best_weights_list [ i ] * y [:, int ( k * len ( pred_cols )) : int (( k + 1 ) * len ( pred_cols ))] + ( 1 - best_weights_list [ i ]) * md2 ) plt . hist ( md2 , bins = 100 ) plt . show () df = sub_dfs_list [ 0 ] . copy () df [[ \"target\" ]] = md2 df . to_csv ( \"submission.csv\" , index = False ) df . head () We have 6 oof files. all_oof_preds shape: (33126, 6) This variable is global and holds all oof predictions stacked horizontally. Model 0 has OOF AUC = 0.8967598406021975 Model 1 has OOF AUC = 0.897338308007439 Model 2 has OOF AUC = 0.8969099101014242 Model 3 has OOF AUC = 0.8997782002268091 Model 4 has OOF AUC = 0.9021602904318382 Model 5 has OOF AUC = 0.9035525112752076 ### Computing Best OOF scores among all models ### The best OOF AUC score is 0.9035525112752076 and the best model index is 5 corresponding to the oof file oof_tf_efficientnet_b2_ns_tf_efficientnet_b2_ns_5_folds_3c0odinh.csv ### HyperParameters ### weight_interval = 1000 patience = 20 min_increase = 0.0003 Current Tracked Model List: [5] Current Weights List: [] Denote model i as the current model, and model j as the model that we are blending with. Ensemble AUC = 0.9141 after adding model 2 with weight 0.452. Increase of 0.0106 Current Tracked Model List: [5, 2] Current Weights List: [0.452] Current Best Score: 0.9141475652539226 [[4.50905440e-03] [3.01906102e-05] [1.43342172e-03] ... [6.48897682e-05] [1.05257292e-02] [9.18150437e-03]] Ensemble AUC = 0.9175 after adding model 3 with weight 0.290. Increase of 0.0034 Current Tracked Model List: [5, 2, 3] Current Weights List: [0.452, 0.29] Current Best Score: 0.9175226556534317 [[3.58108299e-03] [2.45987573e-05] [1.03199503e-03] ... [4.75034868e-05] [9.02447451e-03] [6.67390628e-03]] Ensemble AUC = 0.9193 after adding model 4 with weight 0.273. Increase of 0.0018 Current Tracked Model List: [5, 2, 3, 4] Current Weights List: [0.452, 0.29, 0.273] Current Best Score: 0.9193341713090691 [[2.65875346e-03] [2.51985486e-05] [8.82538860e-04] ... [4.77394006e-05] [1.76098008e-02] [5.30504798e-03]] Ensemble AUC = 0.9201 after adding model 0 with weight 0.161. Increase of 0.0008 Current Tracked Model List: [5, 2, 3, 4, 0] Current Weights List: [0.452, 0.29, 0.273, 0.161] Current Best Score: 0.9201217730848145 [[2.68508770e-03] [3.33216799e-05] [7.54874316e-04] ... [1.12230140e-04] [2.00920893e-02] [1.02248122e-02]] Increment is too small, stop blending We have 6 submission files... ['sub_tf_efficientnet_b0_ns_tf_efficientnet_b0_ns_5_folds_2dcluilj.csv' 'sub_tf_efficientnet_b0_ns_tf_efficientnet_b0_ns_5_folds_3725vib5.csv' 'sub_tf_efficientnet_b0_ns_tf_efficientnet_b0_ns_5_folds_kh6lm0mc.csv' 'sub_tf_efficientnet_b1_ns_tf_efficientnet_b1_ns_5_folds_9qhxwbbq.csv' 'sub_tf_efficientnet_b2_ns_tf_efficientnet_b2_ns_5_folds_1lvjyja0.csv' 'sub_tf_efficientnet_b2_ns_tf_efficientnet_b2_ns_5_folds_3c0odinh.csv'] (10982, 6) [[1.10712990e-03 4.36813570e-04 5.27769700e-04 5.15609340e-04 7.12666400e-04 4.17358470e-04] [2.20565100e-04 1.78343150e-04 9.28863160e-05 1.78823610e-05 1.48618330e-04 3.16100000e-05] [1.81065010e-04 7.23641860e-05 2.92848130e-04 7.86881400e-05 9.41391550e-05 9.77370900e-05] ... [6.67065500e-02 1.14237880e-01 1.26132040e-01 1.13317326e-01 6.87497260e-02 7.28674750e-02] [6.35771550e-03 6.06310670e-04 8.84217040e-04 9.36840800e-04 5.04250900e-04 5.87228570e-05] [1.41756660e-02 2.95386670e-02 1.08320400e-02 2.21859530e-02 1.42423960e-02 9.72992800e-02]] [[4.1735847e-04] [3.1610000e-05] [9.7737090e-05] ... [7.2867475e-02] [5.8722857e-05] [9.7299280e-02]]","title":"Forward Ensemble (Hill Climbing)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/ensemble_theory/forward_ensemble/#convert-oofs-and-ground-truth-to-numpy","text":"First, we define a function return_list_of_dataframes to return either the OOFs or the SUBs. At this point, one should be clear what are OOFs, if not, please read the post here . def return_list_of_dataframes ( path : str , is_oof : bool = True ) -> Tuple [ List [ pd . DataFrame ], int ]: \"\"\"Return a list of dataframes from a directory of files. The boolean is_oof is used to determine whether the list of dataframes contains oof or subs. Args: path (str): The path to the directory containing the files. is_oof (bool, optional): Determine whether the list of dataframes contains oof or subs. Defaults to True. Returns: List[pd.DataFrame]: The list of dataframes for either oof or subs. int: The number of files in the directory. \"\"\" oof_and_subs_files = os . listdir ( path ) if is_oof : oof_files_sorted = np . sort ( [ f for f in oof_and_subs_files if \"oof\" in f ] ) return [ pd . read_csv ( os . path . join ( path , k )) for k in oof_files_sorted ], len ( oof_files_sorted ) else : sub_files_sorted = np . sort ( [ f for f in oof_and_subs_files if \"sub\" in f ] ) return [ pd . read_csv ( os . path . join ( path , k )) for k in sub_files_sorted ], len ( sub_files_sorted ) This function is first applied to is_oof=True . For now, we just want all our OOFs converted to a pandas dataframe, and stored in a list. Note, we also conveniently returned the number of files in the director for OOFs and SUBs respectively, it should be clear in this context that the number of files for OOF is the same as the number of files for SUB. oof_and_subs_path = \"./oof_and_subs/toy_examples\" oof_dfs_list , num_oofs = return_list_of_dataframes ( path = oof_and_subs_path , is_oof = True ) display ( oof_dfs_list [ 0 ]) display ( oof_dfs_list [ 1 ]) display ( oof_dfs_list [ 2 ]) print ( f \"We have { num_oofs } oof files. \\n \" ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } image_id y_trues class_0_oof class_1_oof 0 1 1 0.70 0.30 1 2 0 0.70 0.30 2 3 0 0.65 0.35 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } image_id y_trues class_0_oof class_1_oof 0 1 1 0.6 0.4 1 2 0 0.8 0.2 2 3 0 0.4 0.6 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } image_id y_trues class_0_oof class_1_oof 0 1 1 0.1 0.8 1 2 0 0.4 0.8 2 3 0 0.9 0.7 We have 3 oof files. At this junction, we need to be clear of a few things. Let us use an example to illustrate. Let us say we trained our model over 5 folds and get our OOF predictions in terms of the Macro-AUROC with respect to the positive class 1 . We then need to calculate our OOF scores with our corresponding y_trues. Just by eyeballing, we can deduce the Macro-AUROC score for the positive class as follows: oof_1_auroc = roc_auc_score ([ 1 , 0 , 0 ], [ 0.3 , 0.3 , 0.35 ]) -> 0.25 oof_2_auroc = roc_auc_score ([ 1 , 0 , 0 ], [ 0.4 , 0.2 , 0.6 ]) -> 0.5 oof_3_auroc = roc_auc_score ([ 1 , 0 , 0 ], [ 0.8 , 0.8 , 0.7 ]) -> 0.75 To compute the above, we can manually hardcode them, but for larger data, we will have to maintain a better data structure. We will store them into matrices and vectors (numpy) to compute the OOF scores efficiently. To do so, we define two variables: ground_truth_column_name = [ \"y_trues\" ] positive_class_oof_column_name = [ \"class_1_oof\" ] where the first variable is the name of the column(s) for the ground truth, while the second is the name of the column(s) that we will be using to compute the OOF scores. We will then create a function stack_oofs to convert the list of OOF dataframes into an array. def stack_oofs ( oof_dfs : List [ pd . DataFrame ], pred_column_names : List [ str ] ) -> np . ndarray : \"\"\"Stack all oof predictions horziontally. Args: oof_dfs (List[pd.DataFrame]): The list of oof predictions in dataframes. pred_column_names (List[str]): The list of prediction column names. Returns: all_oof_preds (np.ndarray): The stacked oof predictions of shape (num_samples, num_oofs * num_pred_columns). Example: >>> oof_1 = pd.DataFrame([1,2,3], columns=['class_1_oof']) >>> oof_2 = pd.DataFrame([4,5,6], columns=['class_1_oof']) >>> all_oof_preds = stack_oofs([oof_1, oof_2], ['class_1_oof']) >>> all_oof_preds = np.array([1, 4], [2, 5], [3, 6]) \"\"\" num_oofs = len ( oof_dfs ) num_samples = len ( oof_dfs [ 0 ]) num_target_cols = len ( pred_column_names ) all_oof_preds = np . zeros (( num_samples , num_oofs * num_target_cols )) if num_target_cols == 1 : for index , oof_df in enumerate ( oof_dfs ): all_oof_preds [:, index : index + 1 ] = oof_df [ pred_column_names ] . values elif num_target_cols > 1 : # Used in RANZCR where there are 11 target columns for index , oof_df in enumerate ( oof_dfs ): all_oof_preds [ :, index * num_target_cols : ( index + 1 ) * num_target_cols ] = oof_df [ pred_column_names ] . values return all_oof_preds ground_truth_column_name = [ \"y_trues\" ] positive_class_oof_column_name = [ \"class_1_oof\" ] In my oof files, I also saved the corresponding y_trues as a column, we thus take the first oof_df from oof_dfs_list and use it to get the y_trues , assuming they are the same for all oof files. Note of caution, if you use different resampling methods, you will need to change the y_trues accordingly. y_trues = oof_dfs_list [ 0 ][ ground_truth_column_name ] . values all_oof_preds = stack_oofs ( oof_dfs_list , positive_class_oof_column_name ) print ( f \"y_trues shape: { y_trues . shape } \\n This variable is global and holds all ground truth. \\n \" ) print ( f \"all_oof_preds shape: { all_oof_preds . shape } \\n This variable is global and holds all oof predictions stacked horizontally. \\n \" ) y_trues shape: (3, 1) This variable is global and holds all ground truth. all_oof_preds shape: (3, 3) This variable is global and holds all oof predictions stacked horizontally. After converting to numpy, we should have this following representation: \\[ \\textbf{y_true} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} \\in \\mathbb{R}^3 \\quad \\textbf{all_oof_preds} = \\begin{bmatrix} 0.3 & 0.4 & 0.8 \\\\ 0.3 & 0.2 & 0.8 \\\\ 0.35 & 0.6 & 0.7 \\end{bmatrix} \\in \\mathbb{R}^{3 \\times 3} \\] where y_true is a \\(3 \\times 1\\) column vector, each row entry is the corresponding ground truth for sample \\(i\\) (i.e y_true[0] is ground truth for sample 1). For all_oof_preds , this is a \\(3 \\times 3\\) matrix, where each column \\(i\\) represents the OOF predictions made by model \\(i\\) . In other words, the first column \\(\\begin{bmatrix} 0.3 \\\\ 0.35 \\\\ 0.3 \\end{bmatrix}\\) is the OOF predictions made by the first model. It is important to note that we are dealing with classification (binary or multiclass), so it is usually the case that both our target and predicted columns are just \\(1\\) . In multi-label however, we will have multiple target columns, and will be the focus in part II.","title":"Convert OOFs and Ground Truth to NumPy"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/ensemble_theory/forward_ensemble/#compute-scores-of-oofs-and-find-the-best-score","text":"This part is very crucial, when we apply our Hill Climbing (Forward Ensembling) technique here, we want to initialize with the best models first and iteratively blend with the rest . In other words def compute_best_oof ( all_oof_preds : np . ndarray , y_trues : np . ndarray , num_oofs : int , performance_metric : Callable , ) -> Tuple [ float , int ]: \"\"\"Compute the oof score of all models using a performance metric and return the best model index and score. Args: all_oof_preds (np.ndarray): The stacked oof predictions of shape (num_samples, num_oofs * num_pred_columns). Taken from stack_oofs. y_trues (np.ndarray): The true labels of shape (num_samples, num_target_cols). num_oofs (int): The number of oof predictions. performance_metric (Callable): The performance metric to use, this is a function. Returns: best_oof_metric_score (float): The best oof score. best_model_index (int): The index of the best model. \"\"\" all_oof_scores = [] for k in range ( num_oofs ): oof_k = all_oof_preds [:, k ] . reshape ( - 1 , 1 ) metric_score = performance_metric ( y_trues , oof_k , num_target_cols = 1 , multilabel = False , ) all_oof_scores . append ( metric_score ) print ( f \"Model { k } has OOF AUC = { metric_score } \" ) best_oof_metric_score , best_oof_index = np . max ( all_oof_scores ), np . argmax ( all_oof_scores ) return best_oof_metric_score , best_oof_index def macro_multilabel_auc ( label , pred , num_target_cols : int = 1 , multilabel : bool = False ): \"\"\"Also works for binary AUC like Melanoma\"\"\" if not multilabel : return roc_auc_score ( label , pred ) else : aucs = [] for i in range ( num_target_cols ): print ( label [:, i ]) print () print ( pred [:, i ]) print ( roc_auc_score ( label [:, i ], pred [:, i ])) aucs . append ( roc_auc_score ( label , pred )) return np . mean ( aucs ) best_oof_metric_score , best_oof_index = compute_best_oof ( all_oof_preds = all_oof_preds , y_trues = y_trues , num_oofs = num_oofs , performance_metric = macro_multilabel_auc , ) print ( f \" \\n ### Computing Best OOF scores among all models ### \\n The best OOF AUC score is { best_oof_metric_score } and the best model index is { best_oof_index } corresponding to the oof file { best_oof_index } \" ) Model 0 has OOF AUC = 0.25 Model 1 has OOF AUC = 0.5 Model 2 has OOF AUC = 0.75 ### Computing Best OOF scores among all models ### The best OOF AUC score is 0.75 and the best model index is 2 corresponding to the oof file 2","title":"Compute Scores of OOFs and Find the Best Score"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/ensemble_theory/forward_ensemble/#the-algorithm","text":"Now the logic flows as follows: Start with the model with the best OOF score: we get that from compute_best_oof which yields us the key variables best_oof_index . best_oof_index : 2 indicates that our oof_2 (model 2) has the best OOF score amongst the 3 OOFs (models), as we can see from above, it is indeed the case since Model 2 has OOF AUC of \\(0.75\\) . We now need to blend Model 2 with Model 0 and Model 1 respectively to find out which weight combination gives a better OOF score. We need to define a variable weight_interval , which tells us the weights to sample from. For example, if weight_interval is \\(3\\) , then we will uniformly sample the weights \\(\\frac{0}{3}, \\frac{1}{3}, \\frac{2}{3}\\) . Let us see a concrete example. weight_interval = 3 patience_counter = 0 model_0_oof = all_oof_preds [:, 0 ] . reshape ( y_trues . shape ) model_1_oof = all_oof_preds [:, 1 ] . reshape ( y_trues . shape ) model_2_oof = all_oof_preds [:, best_oof_index ] . reshape ( y_trues . shape ) # best_oof_index=2 We define best_oof_index_list = [ best_oof_index ] best_weights_list = [] which keeps track two lists which holds the best OOFs to blend with and their corresponding weights. We use a naive example to illustrate: best_oof_index_list = [ 2 , 0 , 1 ] best_weights_list = [ 0.3 , 0.8 ] all_oof_preds_matrix = [[ 0.3 , 0.4 , 0.8 ], [ 0.3 , 0.2 , 0.8 ], [ 0.35 , 0.6 , 0.7 ]] initial_best_vector = A_matrix [:, 2 ] In other words, if after our Hill Climbing algorithm, we have the above variables and to calculate the final blended OOF using the above optimal weights, we have: Let \\(\\mathbf{c_i}\\) be the columns of the matrix all_oof_preds_matrix , you can think \\(\\mathbf{c_i}\\) as the Model \\(i\\) 's OOFs predictions, since in this naive example, we see that our initial best model is Model 2. \\[ ((1-0.3) \\times \\mathbf{c_2} + 0.3 \\times \\mathbf{c_0}) \\times (1-0.8) + 0.8 \\times \\mathbf{c_1} \\] To dissect clearly, we start with the first index, which is Model 2, and blend with the next index, which is Model 0, they will be blended with weights of \\(0.3\\) , which means \\((1-0.3) \\times \\mathbf{c_2} + 0.3 \\times \\mathbf{c_0}\\) . We call it oof_blend_1 which indicates the linear combination of the weights of the first blend. Note that this results in a new and better \"OOF predictions\". The next blend will be of oof_blend_1 with Model 1, with a weight of \\(0.8\\) and the assignment is \\((1-0.8) \\times \\textbf{oof_blend_1} + 0.8 \\times \\mathbf{c_0}\\) . best_oof_index_list = [ best_oof_index ] best_weights_list = [] print ( f \"Current Tracked Model List: { best_oof_index_list } \" ) print ( f \"Current Weights List: { best_weights_list } \" ) Current Tracked Model List: [2] Current Weights List: []","title":"The Algorithm"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/ensemble_theory/forward_ensemble/#first-round-blending-model-2-with-model-0","text":"We check the blending results of Model 2 and Model 0 over 3 weights: \\(0, \\frac{1}{3}, \\frac{2}{3}\\) . We also assign 3 variables running_best_score , running_best_weight , running_best_oof_index = best_oof_metric_score , 0 , 0 such that whenever a blend of \\(w_1 \\times \\textbf{model_i_oof} + (1-w_2) \\times \\textbf{model_j_oof}\\) produces a better OOF score, then we will assign if temp_ensemble_oof_score >= running_best_score : print ( f \"The blend of weight { temp_weight } of model 2 and model 0 led to a greater or equals to OOF score = { temp_ensemble_oof_score } \\n \" ) running_best_score = temp_ensemble_oof_score running_best_weight = temp_weight running_best_oof_index = 0 Notice that we hardcoded the running_best_oof_index to be \\(0\\) since we know we are only looking at the interaction of Model 2 and Model 0. In proper code, this part should not be hardcoded and you can refer to my full code for clarity. running_best_score , running_best_weight , running_best_oof_index = best_oof_metric_score , 0 , 0 for weight in range ( weight_interval ): temp_weight = weight / weight_interval print ( f \"weight = { temp_weight } \" ) temp_ensemble_oof_preds = ( temp_weight * model_0_oof + ( 1 - temp_weight ) * model_2_oof ) temp_ensemble_oof_score = macro_multilabel_auc ( y_trues , temp_ensemble_oof_preds , num_target_cols = 1 , multilabel = False , ) print ( f \"blended OOF score with model_0_oof = { temp_ensemble_oof_score } \" ) if temp_ensemble_oof_score >= running_best_score : running_best_score = temp_ensemble_oof_score running_best_weight = temp_weight running_best_oof_index = 0 print ( f \"The blend of weight { temp_weight } of model 2 and model { running_best_oof_index } led to a greater or equals to OOF score = { temp_ensemble_oof_score } \\n \" ) weight = 0.0 blended OOF score with model_0_oof = 0.75 The blend of weight 0.0 of model 2 and model 0 led to a greater or equals to OOF score = 0.75 weight = 0.3333333333333333 blended OOF score with model_0_oof = 0.75 The blend of weight 0.3333333333333333 of model 2 and model 0 led to a greater or equals to OOF score = 0.75 weight = 0.6666666666666666 blended OOF score with model_0_oof = 0.5 So now we finished blending Model 2 and Model 0 and we have: running_best_score = 0.75 running_best_weight = 0.333 ... We need to blend Model 2 and Model 1 now to see if Model 2 and Model 1 can give better OOF scores when blended! We repeat the exact same loop as above, but bear in mind that the running_best_score and running_best_weight is already updated to the ones we got in the blend of Model 2 and Model 0 because we want to check if Model 2 and Model 1's blend can give better results than the previous running_best_score .","title":"First Round - Blending Model 2 with Model 0"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/ensemble_theory/forward_ensemble/#first-round-blending-model-2-and-model-1","text":"for weight in range ( weight_interval ): temp_weight = weight / weight_interval print ( f \"weight = { temp_weight } \" ) temp_ensemble_oof_preds = ( temp_weight * model_1_oof + ( 1 - temp_weight ) * model_2_oof ) temp_ensemble_oof_score = macro_multilabel_auc ( y_trues , temp_ensemble_oof_preds , num_target_cols = 1 , multilabel = False , ) print ( f \"blended OOF score with model_1_oof = { temp_ensemble_oof_score } \" ) if temp_ensemble_oof_score >= running_best_score : running_best_score = temp_ensemble_oof_score running_best_weight = temp_weight running_best_oof_index = 1 print ( f \"The blend of weight { temp_weight } of model 2 and model { running_best_oof_index } led to a greater or equals to OOF score = { temp_ensemble_oof_score } \\n \" ) weight = 0.0 blended OOF score with model_1_oof = 0.75 The blend of weight 0.0 of model 2 and model 1 led to a greater or equals to OOF score = 0.75 weight = 0.3333333333333333 blended OOF score with model_1_oof = 1.0 The blend of weight 0.3333333333333333 of model 2 and model 1 led to a greater or equals to OOF score = 1.0 weight = 0.6666666666666666 blended OOF score with model_1_oof = 0.5 So now we finished blending Model 2 and Model 1 and we have: running_best_score = 1 running_best_weight = 0.333 ... and we have a new winner in town! After our first round of iterating our initial best OOF Model 2 with the rest (Model 0 and 1), we found out that if we take \\(w_1 = 1 - \\frac{2}{3}\\) and \\(w_2 = \\frac{1}{3}\\) , Model 2 and 1 gives us a better overall score. That is to say: \\[ w_1 * \\textbf{OOF_2} + w_2 \\times \\textbf{OOF_1} \\] leads to the greatest increase in our OOF score! Notice that we hardcoded the running_best_oof_index to be \\(1\\) since we know we are only looking at the interaction of Model 2 and Model 1. In proper code, this part should not be hardcoded and you can refer to my full code for clarity. Technically, we can stop the algorithm now since the metric Macro-AUROC is capped at \\(1\\) , but for the sake of explanation, let us continue.","title":"First Round - Blending Model 2 and Model 1"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/ensemble_theory/forward_ensemble/#first-round-save-results-for-loop-1","text":"We then append the best OOF index and the corresponding weight to the best_oof_index_list and best_weights_list respectively. best_oof_index_list . append ( running_best_oof_index ) best_weights_list . append ( running_best_weight ) print ( f \"Current Tracked Model List: { best_oof_index_list } \" ) print ( f \"Current Weights List: { best_weights_list } \" ) Current Tracked Model List: [2, 1] Current Weights List: [0.3333333333333333]","title":"First Round - Save Results for Loop 1"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/ensemble_theory/forward_ensemble/#second-round-blend-oof","text":"Now we have a brand new OOF after blending Model 2 and Model 1, we call it blended_oof_1 and note that this is our new best OOF! # blended_oof_1 = all_oof_preds[:, best_oof_index_list[0]].reshape(-1, 1) * (1 - best_weights_list[0]) + all_oof_preds[:, best_oof_index_list[1]].reshape(-1, 1) * best_weights_list[0] blended_oof_1 = model_2_oof * ( 1 - 1 / 3 ) + model_1_oof * ( 1 / 3 ) assert macro_multilabel_auc ( y_trues , blended_oof_1 ) == 1","title":"Second Round - Blend OOF"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/ensemble_theory/forward_ensemble/#second-round-blending-blended_oof_1-with-model-0","text":"We continue to try out blended_oof_1 with the rest of the models that were not selected. This means we have to check our Current Tracked Model List best_oof_index_list and see that we already have \\([2, 1]\\) being used up, in our simple example here, there only left with Model 0 to try! So make sure in your code you do not try blended_oof_1 with Model 0, 1 and 2 again since the blended_oof_1 is already made up with Model 1 and 2! for weight in range ( weight_interval ): temp_weight = weight / weight_interval print ( f \" \\n weight = { temp_weight } \" ) temp_ensemble_oof_preds = ( temp_weight * model_0_oof + ( 1 - temp_weight ) * blended_oof_1 ) temp_ensemble_oof_score = macro_multilabel_auc ( y_trues , temp_ensemble_oof_preds , num_target_cols = 1 , multilabel = False , ) print ( f \"blended OOF score with model_0_oof = { temp_ensemble_oof_score } \" ) if temp_ensemble_oof_score >= running_best_score : running_best_score = temp_ensemble_oof_score running_best_weight = temp_weight running_best_oof_index = 0 print ( f \"The blend of weight { temp_weight } of model 2 and model { running_best_oof_index } led to a greater or equals to OOF score = { temp_ensemble_oof_score } \\n \" ) weight = 0.0 blended OOF score with model_0_oof = 1.0 The blend of weight 0.0 of model 2 and model 0 led to a greater or equals to OOF score = 1.0 weight = 0.3333333333333333 blended OOF score with model_0_oof = 0.5 weight = 0.6666666666666666 blended OOF score with model_0_oof = 0.5 Since we have done checking blended_oof_1 with the last remaining Model 0 and found that blending Model 0 with a weight of 0 (what a surprise haha!) yields the best result, we once again update the running metrics and also append to our global lists below. best_oof_index_list . append ( running_best_oof_index ) best_weights_list . append ( running_best_weight ) print ( f \"Current Tracked Model List: { best_oof_index_list } \" ) print ( f \"Current Weights List: { best_weights_list } \" ) Current Tracked Model List: [2, 1, 0] Current Weights List: [0.3333333333333333, 0.0] # blended_oof_2 = blended_oof_1 * (1 - best_weights_list[1]) + all_oof_preds[:, best_oof_index_list[2]].reshape(-1, 1) * best_weights_list[1] blended_oof_2 = blended_oof_1 * ( 1 - 0.0 ) + model_0_oof . reshape ( - 1 , 1 ) * 0.0 assert macro_multilabel_auc ( y_trues , blended_oof_2 ) == 1","title":"Second Round - Blending blended_oof_1 with Model 0"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/ensemble_theory/forward_ensemble/#ensembling-model-predictions-with-the-found-optimal-weights","text":"So we end the discussion with what to do with the weights we got. We already established to the readers that our Initial Best OOF is Model 2 with a Macro-AUROC score of \\(0.75\\) , and by way of Hill Climbing, we found out that we can blend the 3 Models with some weights such that their new OOF produces a Macro-AUROC score of \\(1.0\\) , a huge improvement. We aren't done yet! We want to apply these optimal weights to our test set predictions as well. Note that our test set predictions are unseen and our usual ensemble methods can be as simple as mean averaging. More concretely, let us check out the example below. oof_and_subs_path = \"./oof_and_subs/toy_examples\" sub_dfs_list , num_subs = return_list_of_dataframes ( path = oof_and_subs_path , is_oof = False ) display ( sub_dfs_list [ 0 ]) display ( sub_dfs_list [ 1 ]) display ( sub_dfs_list [ 2 ]) print ( f \"We have { num_subs } sub files. \\n \" ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } image_id class_0_preds class_1_preds 0 4 0.2 0.8 1 5 0.3 0.7 2 6 0.6 0.4 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } image_id class_0_preds class_1_preds 0 4 0.3 0.7 1 5 0.9 0.1 2 6 0.2 0.8 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } image_id class_0_preds class_1_preds 0 4 0.3 0.7 1 5 0.7 0.3 2 6 0.8 0.2 We have 3 sub files. The stack_subs function does the same thing as stack_oofs so they can be combined into one function for code clarity. def stack_subs ( sub_dfs : List [ pd . DataFrame ], pred_column_names : List [ str ] ) -> np . ndarray : \"\"\"Stack all sub predictions horziontally. Args: sub_dfs (List[pd.DataFrame]): The list of sub predictions in dataframes. pred_column_names (List[str]): The list of prediction column names. Returns: all_sub_preds (np.ndarray): The stacked oof predictions of shape (num_samples, num_subs * num_pred_columns). \"\"\" num_subs = len ( sub_dfs ) num_samples = len ( sub_dfs [ 0 ]) num_target_cols = len ( pred_column_names ) all_sub_preds = np . zeros (( num_samples , num_subs * num_target_cols )) if num_target_cols == 1 : for index , sub_df in enumerate ( sub_dfs ): all_sub_preds [:, index : index + 1 ] = sub_df [ pred_column_names ] . values elif num_target_cols > 1 : # Used in RANZCR where there are 11 target columns for index , sub_df in enumerate ( sub_dfs ): all_sub_preds [ :, index * num_target_cols : ( index + 1 ) * num_target_cols ] = sub_df [ pred_column_names ] . values return all_sub_preds test_set_target_column_name = [ \"class_1_preds\" ] all_subs_preds = stack_subs ( sub_dfs_list , test_set_target_column_name ) model_0_sub = all_subs_preds [:, 0 ] . reshape ( y_trues . shape ) model_1_sub = all_subs_preds [:, 1 ] . reshape ( y_trues . shape ) model_2_sub = all_subs_preds [:, 2 ] . reshape ( y_trues . shape ) Recall the optimal weights earlier: Current Tracked Model List : [ 2 , 1 , 0 ] Current Weights List : [ 0.3333333333333333 , 0.0 ] and we now have a way to ensemble our model subs accordingly. # blended_oof_1 = all_oof_preds[:, best_oof_index_list[0]].reshape(-1, 1) * (1 - best_weights_list[0]) + all_oof_preds[:, best_oof_index_list[1]].reshape(-1, 1) * best_weights_list[0] blended_sub_1 = model_2_sub * ( 1 - 1 / 3 ) + model_1_sub * ( 1 / 3 ) blended_sub_2 = blended_sub_1 * ( 1 - 0.0 ) + model_0_sub * 0.0 blended_sub_2 array([[0.7 ], [0.23333333], [0.4 ]]) Then blended_sub_2 should be our final test set predictions !","title":"Ensembling Model Predictions with the Found Optimal Weights"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/ensemble_theory/forward_ensemble/#forward-ensemble-with-siim-isic-melanoma-classification","text":"This is taken from my repo. import pandas as pd import numpy as np import os import matplotlib.pyplot as plt from typing import List , Tuple , Callable from sklearn.metrics import roc_auc_score def stack_oofs ( oof_dfs : List [ pd . DataFrame ], pred_column_names : List [ str ] ) -> np . ndarray : \"\"\"Stack all oof predictions horziontally. Args: oof_dfs (List[pd.DataFrame]): The list of oof predictions in dataframes. pred_column_names (List[str]): The list of prediction column names. Returns: all_oof_preds (np.ndarray): The stacked oof predictions of shape (num_samples, num_oofs * num_pred_columns). Example: >>> oof_1 = pd.DataFrame([1,2,3], columns=['class_1_oof']) >>> oof_2 = pd.DataFrame([4,5,6], columns=['class_1_oof']) >>> all_oof_preds = stack_oofs([oof_1, oof_2], ['class_1_oof']) >>> all_oof_preds = np.array([1, 4], [2, 5], [3, 6]) \"\"\" num_oofs = len ( oof_dfs ) num_samples = len ( oof_dfs [ 0 ]) num_target_cols = len ( pred_column_names ) all_oof_preds = np . zeros (( num_samples , num_oofs * num_target_cols )) if num_target_cols == 1 : for index , oof_df in enumerate ( oof_dfs ): all_oof_preds [:, index : index + 1 ] = oof_df [ pred_column_names ] . values elif num_target_cols > 1 : # Used in RANZCR where there are 11 target columns for index , oof_df in enumerate ( oof_dfs ): all_oof_preds [ :, index * num_target_cols : ( index + 1 ) * num_target_cols ] = oof_df [ pred_column_names ] . values return all_oof_preds def macro_multilabel_auc ( label , pred , num_target_cols : int = 1 , multilabel : bool = False ): \"\"\"Also works for binary AUC like Melanoma\"\"\" if not multilabel : return roc_auc_score ( label , pred ) else : aucs = [] for i in range ( num_target_cols ): print ( label [:, i ]) print () print ( pred [:, i ]) print ( roc_auc_score ( label [:, i ], pred [:, i ])) aucs . append ( roc_auc_score ( label , pred )) return np . mean ( aucs ) def compute_best_oof ( all_oof_preds : np . ndarray , y_trues : np . ndarray , num_oofs : int , performance_metric : Callable , ) -> Tuple [ float , int ]: \"\"\"Compute the oof score of all models using a performance metric and return the best model index and score. Args: all_oof_preds (np.ndarray): The stacked oof predictions of shape (num_samples, num_oofs * num_pred_columns). Taken from stack_oofs. y_trues (np.ndarray): The true labels of shape (num_samples, num_target_cols). num_oofs (int): The number of oof predictions. performance_metric (Callable): The performance metric to use, this is a function. Returns: best_oof_metric_score (float): The best oof score. best_model_index (int): The index of the best model. \"\"\" all_oof_scores = [] for k in range ( num_oofs ): metric_score = performance_metric ( y_trues , all_oof_preds [:, k ], num_target_cols = 1 , multilabel = False , ) all_oof_scores . append ( metric_score ) print ( f \"Model { k } has OOF AUC = { metric_score } \" ) best_oof_metric_score , best_oof_index = np . max ( all_oof_scores ), np . argmax ( all_oof_scores ) return best_oof_metric_score , best_oof_index def calculate_best_score_over_weight_interval ( weight_interval : float , model_i_oof : np . ndarray , model_j_oof : np . ndarray , y_trues : np . ndarray , performance_metric : Callable , running_best_score : float , running_best_weight : float , patience : int , ) -> Tuple [ float , float ]: \"\"\"Calculate the best score over a weight interval. Args: weight_interval (float): _description_ model_i_oof (np.ndarray): _description_ model_j_oof (np.ndarray): _description_ y_trues (np.ndarray): _description_ performance_metric (Callable): _description_ running_best_score (float): _description_ running_best_weight (float): _description_ patience (int): _description_ Returns: Tuple[float, float]: _description_ \"\"\" patience_counter = 0 for weight in range ( weight_interval ): temp_weight = weight / weight_interval temp_ensemble_oof_preds = ( temp_weight * model_j_oof + ( 1 - temp_weight ) * model_i_oof ) temp_ensemble_oof_score = performance_metric ( y_trues , temp_ensemble_oof_preds , num_target_cols = 1 , multilabel = False , ) # in the first loop, if any of the blending is more than best_oof_metric_score, we will assign it to running_best_score. if temp_ensemble_oof_score > running_best_score : running_best_score = temp_ensemble_oof_score running_best_weight = temp_weight else : patience_counter += 1 if patience_counter > patience : break return running_best_score , running_best_weight def get_blended_oof ( initial_best_model_oof , best_oof_index_list , best_weights_list ): # can be used on both oof and subs curr_model_oof = initial_best_model_oof for index , _ in enumerate ( best_oof_index_list [ 1 :]): model_j_index = best_oof_index_list [ index + 1 ] curr_model_oof = ( 1 - best_weights_list [ index ]) * curr_model_oof + ( best_weights_list [ index ] ) * all_oof_preds [:, model_j_index ] . reshape ( - 1 , 1 ) return curr_model_oof def return_list_of_dataframes ( path : str , is_oof : bool = True ) -> Tuple [ List [ pd . DataFrame ], int ]: \"\"\"Return a list of dataframes from a directory of files. The boolean is_oof is used to determine whether the list of dataframes contains oof or subs. Args: path (str): The path to the directory containing the files. is_oof (bool, optional): Determine whether the list of dataframes contains oof or subs. Defaults to True. Returns: List[pd.DataFrame]: The list of dataframes for either oof or subs. int: The number of files in the directory. \"\"\" oof_and_subs_files = os . listdir ( path ) if is_oof : oof_files_sorted = np . sort ( [ f for f in oof_and_subs_files if \"oof\" in f ] ) return [ pd . read_csv ( os . path . join ( path , k )) for k in oof_files_sorted ], len ( oof_files_sorted ) else : sub_files_sorted = np . sort ( [ f for f in oof_and_subs_files if \"sub\" in f ] ) return [ pd . read_csv ( os . path . join ( path , k )) for k in sub_files_sorted ], len ( sub_files_sorted ) if __name__ == \"__main__\" : oof_and_subs_path = \"./oof_and_subs/melanoma\" # [\"oof_1.csv\", \"sub_1.csv\", \"oof_2.csv\", \"sub_2.csv\"] oof_and_subs_files = os . listdir ( oof_and_subs_path ) # [\"oof_1.csv\", \"oof_2.csv\", \"sub_1.csv\", \"sub_2.csv\"] sorted oof_files_sorted = np . sort ([ f for f in oof_and_subs_files if \"oof\" in f ]) # [oof_1_df, oof_2_df, sub_1_df, sub_2_df] in dataframe oof_dfs_list = [ pd . read_csv ( os . path . join ( oof_and_subs_path , k )) for k in oof_files_sorted ] num_oofs = len ( oof_dfs_list ) # in my oof files, I also saved the corresponding y_trues, we thus take the first oof_df and use it to get the y_trues, assuming they are the same for all oof files. # note of caution, if you use different resampling methods, you will need to change the y_trues accordingly. y_trues_df = oof_dfs_list [ 0 ][[ \"oof_trues\" ]] y_trues = y_trues_df . values print ( f \"We have { len ( oof_files_sorted ) } oof files. \\n \" ) target_cols = [ \"oof_trues\" ] pred_cols = [ \"class_1_oof\" ] num_target_cols = len ( target_cols ) all_oof_preds = stack_oofs ( oof_dfs = oof_dfs_list , pred_column_names = pred_cols ) print ( f \"all_oof_preds shape: { all_oof_preds . shape } \\n This variable is global and holds all oof predictions stacked horizontally. \\n \" ) best_oof_metric_score , best_oof_index = compute_best_oof ( all_oof_preds = all_oof_preds , y_trues = y_trues , num_oofs = num_oofs , performance_metric = macro_multilabel_auc , ) print ( f \" \\n ### Computing Best OOF scores among all models ### \\n The best OOF AUC score is { best_oof_metric_score } and the best model index is { best_oof_index } corresponding to the oof file { oof_files_sorted [ best_oof_index ] } \" ) weight_interval = 1000 # 200 patience = 20 # 10 min_increase = 0.0003 # 0.00003 print ( f \" \\n ### HyperParameters ### \\n weight_interval = { weight_interval } \\n patience = { patience } \\n min_increase = { min_increase } \\n \" ) # keep track of oof index that are blended best_oof_index_list = [ best_oof_index ] best_weights_list = [] print ( f \"Current Tracked Model List: { best_oof_index_list } \" ) print ( f \"Current Weights List: { best_weights_list } \" ) counter = 0 # Initially, this curr_model_oof is the single best model that we got above from [oof_1, oof_2,...] initial_best_model_oof = all_oof_preds [:, best_oof_index ] . reshape ( - 1 , 1 ) old_best_score = best_oof_metric_score model_i_best_score , model_i_index , model_i_weights = 0 , 0 , 0 print ( \"Denote model i as the current model, and model j as the model that we are blending with.\" ) for outer_oof_index in range ( num_oofs ): # basically in the first loop, we already know the current model's oof and we assign it by subsetting the all_oof_preds with the best oof index. curr_model_oof = initial_best_model_oof if counter > 0 : curr_model_oof = get_blended_oof ( initial_best_model_oof , best_oof_index_list , best_weights_list ) print ( curr_model_oof ) for inner_oof_index in range ( num_oofs ): # If we have [oof_1, oof_2] and best_oof_index = 1 (oof_2), then we do not need to blend oof_2 and itself. if inner_oof_index in best_oof_index_list : continue # in the first loop, our running_best_score is the best_oof_metric_score # also our old_best_score is the best_oof_metric_score in the first loop ( running_best_score , running_best_weight , patience_counter ,) = ( 0 , 0 , 0 , ) # what we are doing here is to find the best oof score among all models that we have not blended yet. # for example, if we have [oof_1, oof_2, oof_3], and we know oof_2 is our initial_best_model_oof, # then we need to blend oof_2 with oof_1, then oof_2 with oof_3 to find out which of them yields the best overall oof when blended. ( running_best_score , running_best_weight , ) = calculate_best_score_over_weight_interval ( weight_interval , curr_model_oof , all_oof_preds [:, inner_oof_index ] . reshape ( - 1 , 1 ), y_trues , macro_multilabel_auc , running_best_score , running_best_weight , patience , ) if running_best_score > model_i_best_score : model_i_index = inner_oof_index model_i_best_score = running_best_score model_i_weights = running_best_weight increment = model_i_best_score - old_best_score if increment <= min_increase : print ( \"Increment is too small, stop blending\" ) break # DISPLAY RESULTS print () print ( \"Ensemble AUC = %.4f after adding model %i with weight %.3f . Increase of %.4f \" % ( model_i_best_score , model_i_index , model_i_weights , increment , ) ) print () old_best_score = model_i_best_score best_oof_index_list . append ( model_i_index ) best_weights_list . append ( model_i_weights ) print ( f \"Current Tracked Model List: { best_oof_index_list } \" ) print ( f \"Current Weights List: { best_weights_list } \" ) print ( f \"Current Best Score: { model_i_best_score } \" ) counter += 1 plt . hist ( curr_model_oof , bins = 100 ) plt . title ( \"Ensemble OOF predictions\" ) plt . show () # apply on submission sub_files_sorted = np . sort ([ f for f in oof_and_subs_files if \"sub\" in f ]) sub_dfs_list = [ pd . read_csv ( os . path . join ( oof_and_subs_path , k )) for k in sub_files_sorted ] print ( f \" \\n We have { len ( sub_files_sorted ) } submission files...\" ) print () print ( sub_files_sorted ) y = np . zeros (( len ( sub_dfs_list [ 0 ]), len ( sub_files_sorted ) * len ( pred_cols ))) print ( y . shape ) for k in range ( len ( sub_files_sorted )): y [ :, int ( k * len ( pred_cols )) : int (( k + 1 ) * len ( pred_cols )) ] = sub_dfs_list [ k ][ \"target\" ] . values . reshape ( - 1 , 1 ) print ( y ) md2 = y [ :, int ( best_oof_index_list [ 0 ] * len ( pred_cols )) : int ( ( best_oof_index_list [ 0 ] + 1 ) * len ( pred_cols ) ), ] print ( md2 ) for i , k in enumerate ( best_oof_index_list [ 1 :]): md2 = ( best_weights_list [ i ] * y [:, int ( k * len ( pred_cols )) : int (( k + 1 ) * len ( pred_cols ))] + ( 1 - best_weights_list [ i ]) * md2 ) plt . hist ( md2 , bins = 100 ) plt . show () df = sub_dfs_list [ 0 ] . copy () df [[ \"target\" ]] = md2 df . to_csv ( \"submission.csv\" , index = False ) df . head () We have 6 oof files. all_oof_preds shape: (33126, 6) This variable is global and holds all oof predictions stacked horizontally. Model 0 has OOF AUC = 0.8967598406021975 Model 1 has OOF AUC = 0.897338308007439 Model 2 has OOF AUC = 0.8969099101014242 Model 3 has OOF AUC = 0.8997782002268091 Model 4 has OOF AUC = 0.9021602904318382 Model 5 has OOF AUC = 0.9035525112752076 ### Computing Best OOF scores among all models ### The best OOF AUC score is 0.9035525112752076 and the best model index is 5 corresponding to the oof file oof_tf_efficientnet_b2_ns_tf_efficientnet_b2_ns_5_folds_3c0odinh.csv ### HyperParameters ### weight_interval = 1000 patience = 20 min_increase = 0.0003 Current Tracked Model List: [5] Current Weights List: [] Denote model i as the current model, and model j as the model that we are blending with. Ensemble AUC = 0.9141 after adding model 2 with weight 0.452. Increase of 0.0106 Current Tracked Model List: [5, 2] Current Weights List: [0.452] Current Best Score: 0.9141475652539226 [[4.50905440e-03] [3.01906102e-05] [1.43342172e-03] ... [6.48897682e-05] [1.05257292e-02] [9.18150437e-03]] Ensemble AUC = 0.9175 after adding model 3 with weight 0.290. Increase of 0.0034 Current Tracked Model List: [5, 2, 3] Current Weights List: [0.452, 0.29] Current Best Score: 0.9175226556534317 [[3.58108299e-03] [2.45987573e-05] [1.03199503e-03] ... [4.75034868e-05] [9.02447451e-03] [6.67390628e-03]] Ensemble AUC = 0.9193 after adding model 4 with weight 0.273. Increase of 0.0018 Current Tracked Model List: [5, 2, 3, 4] Current Weights List: [0.452, 0.29, 0.273] Current Best Score: 0.9193341713090691 [[2.65875346e-03] [2.51985486e-05] [8.82538860e-04] ... [4.77394006e-05] [1.76098008e-02] [5.30504798e-03]] Ensemble AUC = 0.9201 after adding model 0 with weight 0.161. Increase of 0.0008 Current Tracked Model List: [5, 2, 3, 4, 0] Current Weights List: [0.452, 0.29, 0.273, 0.161] Current Best Score: 0.9201217730848145 [[2.68508770e-03] [3.33216799e-05] [7.54874316e-04] ... [1.12230140e-04] [2.00920893e-02] [1.02248122e-02]] Increment is too small, stop blending We have 6 submission files... ['sub_tf_efficientnet_b0_ns_tf_efficientnet_b0_ns_5_folds_2dcluilj.csv' 'sub_tf_efficientnet_b0_ns_tf_efficientnet_b0_ns_5_folds_3725vib5.csv' 'sub_tf_efficientnet_b0_ns_tf_efficientnet_b0_ns_5_folds_kh6lm0mc.csv' 'sub_tf_efficientnet_b1_ns_tf_efficientnet_b1_ns_5_folds_9qhxwbbq.csv' 'sub_tf_efficientnet_b2_ns_tf_efficientnet_b2_ns_5_folds_1lvjyja0.csv' 'sub_tf_efficientnet_b2_ns_tf_efficientnet_b2_ns_5_folds_3c0odinh.csv'] (10982, 6) [[1.10712990e-03 4.36813570e-04 5.27769700e-04 5.15609340e-04 7.12666400e-04 4.17358470e-04] [2.20565100e-04 1.78343150e-04 9.28863160e-05 1.78823610e-05 1.48618330e-04 3.16100000e-05] [1.81065010e-04 7.23641860e-05 2.92848130e-04 7.86881400e-05 9.41391550e-05 9.77370900e-05] ... [6.67065500e-02 1.14237880e-01 1.26132040e-01 1.13317326e-01 6.87497260e-02 7.28674750e-02] [6.35771550e-03 6.06310670e-04 8.84217040e-04 9.36840800e-04 5.04250900e-04 5.87228570e-05] [1.41756660e-02 2.95386670e-02 1.08320400e-02 2.21859530e-02 1.42423960e-02 9.72992800e-02]] [[4.1735847e-04] [3.1610000e-05] [9.7737090e-05] ... [7.2867475e-02] [5.8722857e-05] [9.7299280e-02]]","title":"Forward Ensemble with SIIM-ISIC Melanoma Classification"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/ensemble_theory/out_of_folds_predictions/","text":"","title":"Out of folds predictions"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/activation_functions/Activation_Functions/","text":"Regularization https://cs231n.github.io/neural-networks-1/ https://machinelearningmastery.com/activation-regularization-for-reducing-generalization-error-in-deep-learning-neural-networks/ CS231N: In the diagram above, we can see that Neural Networks with more neurons can express more complicated functions. However, this is both a blessing (since we can learn to classify more complicated data) and a curse (since it is easier to overfit the training data). Overfitting occurs when a model with high capacity fits the noise in the data instead of the (assumed) underlying relationship. For example, the model with 20 hidden neurons fits all the training data but at the cost of segmenting the space into many disjoint red and green decision regions. The model with 3 hidden neurons only has the representational power to classify the data in broad strokes. It models the data as two blobs and interprets the few red points inside the green cluster as outliers (noise). In practice, this could lead to better generalization on the test set. Softmax The softmax function takes as input a vector \\(z\\) of \\(K\\) real numbers, and normalizes it into a probability distribution consisting of \\(K\\) probabilities proportional to the exponentials of the input numbers. That is, prior to applying softmax, some vector components could be negative, or greater than one; and might not sum to 1; but after applying softmax, each component will be in the interval \\([0, 1]\\) and the components will add up to 1, so that they can be interpreted as probabilities. Furthermore, the larger input components will correspond to larger probabilities. One key difference is softmax takes in a vector of inputs, while sigmoid can only take in one real value. Sigmoid The sigmoid function takes as input a real value and output one real value as well. In Binary classification case, with class 0 and 1, we only need one output neuron (positive class neuron), and when applied sigmoid will get a number between 0 and 1, say \\(p^{+}\\) , then \\(p^{-} = 1 - p^{+}\\) . However the catch is that sigmoid in Binarcy Classification setting works just like softmax, but not when in multi-label! One key difference is softmax takes in a vector of inputs, while sigmoid can only take in one real value. Softmax vs Sigmoid Sigmoid vs Softmax I've noticed people often get directed to this question when searching whether to use sigmoid vs softmax in neural networks. If you are one of those people building a neural network classifier, here is how to decide whether to apply sigmoid or softmax to the raw output values from your network: If you have a multi-label classification problem = there is more than one \"right answer\" = the outputs are NOT mutually exclusive, then use a sigmoid function on each raw output independently. The sigmoid will allow you to have high probability for all of your classes, some of them, or none of them. Example: classifying diseases in a chest x-ray image. The image might contain pneumonia, emphysema, and/or cancer, or none of those findings. If you have a multi-class classification problem = there is only one \"right answer\" = the outputs are mutually exclusive, then use a softmax function. The softmax will enforce that the sum of the probabilities of your output classes are equal to one, so in order to increase the probability of a particular class, your model must correspondingly decrease the probability of at least one of the other classes. Example: classifying images from the MNIST data set of handwritten digits. A single picture of a digit has only one true identity - the picture cannot be a 7 and an 8 at the same time. More reading ReLU Properties https://medium.com/@kanchansarkar/relu-not-a-differentiable-function-why-used-in-gradient-based-optimization-7fef3a4cecec \\(g(z) = \\max(0,z)\\) Differentiable over all points except \\(z = 0\\) . Swish https://stats.stackexchange.com/questions/544739/why-does-being-bounded-below-in-swish-reduces-overfitting Indeed relu is also bounded below, they didn't claim otherwise. The difference is, that swish allows small negative values for small negative inputs, which according to them, increases expressivity and improve gradient flow. The reason behind improving generalization is that, as in regularization, small, approaching zero, weights improve generalization as the function become more smooth and it reduces the effect of fitting the noise. They claim that by bounding large negative vales in the activation function, the effect is that the network \"forgets\" large negative inputs and thus helping the weights to approach to zero. See the image they added, large negative values, which are common before training are forgotten and after training the negative scale is much smaller. There is a tradeoff between bounded which improve generaliztion and unbounded that avoids saturation of gradients, and help the network to stay in the linear regime. Properties When we design or choose an activation function, we need to ensure the follows: (Smoothness) Differentiable and Continuous: For example, the sigmoid function is continuous and hence differentiable. If the property is not fulfilled, we might face issues as backpropagation may not be performed properly since we cannot differentiate it.If you notice, the heaviside function is not. We cant perform GD using the HF as we cannot compute gradients but for the logistic function we can. The gradient of sigmoid function g is g(1-g) conveniently Monotonic: This helps the model to converge faster. But spoiler alert, Swish is not monotonic. The properties of Swish are as follows: Bounded below: It is claimed in the paper it serves as a strong regularization. Smoothness: More smooth than ReLU which allows the model to optimize better, the error landscape, when smoothed, is easier to traverse in order to find a minima. An intuitive idea is the hill again, imagine you traverse down Bukit Timah Hill, vs traversing down Mount Himalaya LOL!!! Let us see how swish looks like when plotted. # Import matplotlib, numpy and math import matplotlib.pyplot as plt import numpy as np import math def swish ( x ): sigmoid = 1 / ( 1 + np . exp ( - x )) swish = x * sigmoid return swish epsilon = 1e-20 x = np . linspace ( - 10 , 10 , 10 ) z = swish ( x ) print ( f \"x= { x } \" ) print ( f \" \\n z=swish(x)= { z } \" ) print ( f \" \\n min z = { min ( z ) } \" ) x=[-10. -7.77777778 -5.55555556 -3.33333333 -1.11111111 1.11111111 3.33333333 5.55555556 7.77777778 10. ] z=swish(x)=[-4.53978687e-04 -3.25707421e-03 -2.13946242e-02 -1.14817319e-01 -2.75182001e-01 8.35929110e-01 3.21851601e+00 5.53416093e+00 7.77452070e+00 9.99954602e+00] min z = -0.27518200126563513 plt . plot ( x , z ) plt . xlabel ( \"x\" ) plt . ylabel ( \"Swish(X)\" ) plt . show ();","title":"Regularization"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/activation_functions/Activation_Functions/#regularization","text":"https://cs231n.github.io/neural-networks-1/ https://machinelearningmastery.com/activation-regularization-for-reducing-generalization-error-in-deep-learning-neural-networks/ CS231N: In the diagram above, we can see that Neural Networks with more neurons can express more complicated functions. However, this is both a blessing (since we can learn to classify more complicated data) and a curse (since it is easier to overfit the training data). Overfitting occurs when a model with high capacity fits the noise in the data instead of the (assumed) underlying relationship. For example, the model with 20 hidden neurons fits all the training data but at the cost of segmenting the space into many disjoint red and green decision regions. The model with 3 hidden neurons only has the representational power to classify the data in broad strokes. It models the data as two blobs and interprets the few red points inside the green cluster as outliers (noise). In practice, this could lead to better generalization on the test set.","title":"Regularization"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/activation_functions/Activation_Functions/#softmax","text":"The softmax function takes as input a vector \\(z\\) of \\(K\\) real numbers, and normalizes it into a probability distribution consisting of \\(K\\) probabilities proportional to the exponentials of the input numbers. That is, prior to applying softmax, some vector components could be negative, or greater than one; and might not sum to 1; but after applying softmax, each component will be in the interval \\([0, 1]\\) and the components will add up to 1, so that they can be interpreted as probabilities. Furthermore, the larger input components will correspond to larger probabilities. One key difference is softmax takes in a vector of inputs, while sigmoid can only take in one real value.","title":"Softmax"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/activation_functions/Activation_Functions/#sigmoid","text":"The sigmoid function takes as input a real value and output one real value as well. In Binary classification case, with class 0 and 1, we only need one output neuron (positive class neuron), and when applied sigmoid will get a number between 0 and 1, say \\(p^{+}\\) , then \\(p^{-} = 1 - p^{+}\\) . However the catch is that sigmoid in Binarcy Classification setting works just like softmax, but not when in multi-label! One key difference is softmax takes in a vector of inputs, while sigmoid can only take in one real value.","title":"Sigmoid"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/activation_functions/Activation_Functions/#softmax-vs-sigmoid","text":"Sigmoid vs Softmax I've noticed people often get directed to this question when searching whether to use sigmoid vs softmax in neural networks. If you are one of those people building a neural network classifier, here is how to decide whether to apply sigmoid or softmax to the raw output values from your network: If you have a multi-label classification problem = there is more than one \"right answer\" = the outputs are NOT mutually exclusive, then use a sigmoid function on each raw output independently. The sigmoid will allow you to have high probability for all of your classes, some of them, or none of them. Example: classifying diseases in a chest x-ray image. The image might contain pneumonia, emphysema, and/or cancer, or none of those findings. If you have a multi-class classification problem = there is only one \"right answer\" = the outputs are mutually exclusive, then use a softmax function. The softmax will enforce that the sum of the probabilities of your output classes are equal to one, so in order to increase the probability of a particular class, your model must correspondingly decrease the probability of at least one of the other classes. Example: classifying images from the MNIST data set of handwritten digits. A single picture of a digit has only one true identity - the picture cannot be a 7 and an 8 at the same time. More reading","title":"Softmax vs Sigmoid"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/activation_functions/Activation_Functions/#relu","text":"","title":"ReLU"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/activation_functions/Activation_Functions/#properties","text":"https://medium.com/@kanchansarkar/relu-not-a-differentiable-function-why-used-in-gradient-based-optimization-7fef3a4cecec \\(g(z) = \\max(0,z)\\) Differentiable over all points except \\(z = 0\\) .","title":"Properties"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/activation_functions/Activation_Functions/#swish","text":"https://stats.stackexchange.com/questions/544739/why-does-being-bounded-below-in-swish-reduces-overfitting Indeed relu is also bounded below, they didn't claim otherwise. The difference is, that swish allows small negative values for small negative inputs, which according to them, increases expressivity and improve gradient flow. The reason behind improving generalization is that, as in regularization, small, approaching zero, weights improve generalization as the function become more smooth and it reduces the effect of fitting the noise. They claim that by bounding large negative vales in the activation function, the effect is that the network \"forgets\" large negative inputs and thus helping the weights to approach to zero. See the image they added, large negative values, which are common before training are forgotten and after training the negative scale is much smaller. There is a tradeoff between bounded which improve generaliztion and unbounded that avoids saturation of gradients, and help the network to stay in the linear regime.","title":"Swish"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/activation_functions/Activation_Functions/#properties_1","text":"When we design or choose an activation function, we need to ensure the follows: (Smoothness) Differentiable and Continuous: For example, the sigmoid function is continuous and hence differentiable. If the property is not fulfilled, we might face issues as backpropagation may not be performed properly since we cannot differentiate it.If you notice, the heaviside function is not. We cant perform GD using the HF as we cannot compute gradients but for the logistic function we can. The gradient of sigmoid function g is g(1-g) conveniently Monotonic: This helps the model to converge faster. But spoiler alert, Swish is not monotonic. The properties of Swish are as follows: Bounded below: It is claimed in the paper it serves as a strong regularization. Smoothness: More smooth than ReLU which allows the model to optimize better, the error landscape, when smoothed, is easier to traverse in order to find a minima. An intuitive idea is the hill again, imagine you traverse down Bukit Timah Hill, vs traversing down Mount Himalaya LOL!!! Let us see how swish looks like when plotted. # Import matplotlib, numpy and math import matplotlib.pyplot as plt import numpy as np import math def swish ( x ): sigmoid = 1 / ( 1 + np . exp ( - x )) swish = x * sigmoid return swish epsilon = 1e-20 x = np . linspace ( - 10 , 10 , 10 ) z = swish ( x ) print ( f \"x= { x } \" ) print ( f \" \\n z=swish(x)= { z } \" ) print ( f \" \\n min z = { min ( z ) } \" ) x=[-10. -7.77777778 -5.55555556 -3.33333333 -1.11111111 1.11111111 3.33333333 5.55555556 7.77777778 10. ] z=swish(x)=[-4.53978687e-04 -3.25707421e-03 -2.13946242e-02 -1.14817319e-01 -2.75182001e-01 8.35929110e-01 3.21851601e+00 5.53416093e+00 7.77452070e+00 9.99954602e+00] min z = -0.27518200126563513 plt . plot ( x , z ) plt . xlabel ( \"x\" ) plt . ylabel ( \"Swish(X)\" ) plt . show ();","title":"Properties"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/learning_rate_schedulers/pytorch_gradual_warmup_scheduler/notebook/guide-to-pytorch-learning-rate-scheduling/","text":"# This Python 3 environment comes with many helpful analytics libraries installed # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python # For example, here's several helpful packages to load import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) # Input data files are available in the read-only \"../input/\" directory # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory import os for dirname , _ , filenames in os . walk ( '/kaggle/input' ): for filename in filenames : print ( os . path . join ( dirname , filename )) # You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session import torch import matplotlib.pyplot as plt 1. LAMBDA LR Sets the learning rate of each parameter group to the initial lr times a given function. When last_epoch=-1, sets initial lr as lr. \\[ l r_{\\text {epoch}} = l r_{\\text {initial}} * Lambda(epoch) \\] model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) lambda1 = lambda epoch : 0.65 ** epoch scheduler = torch . optim . lr_scheduler . LambdaLR ( optimizer , lr_lambda = lambda1 ) lrs = [] for i in range ( 10 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \", round(0.65 ** i,3),\" , Learning Rate = \",round(optimizer.param_groups[0][\"lr\"],3)) scheduler . step () plt . plot ( range ( 10 ), lrs ) [<matplotlib.lines.Line2D at 0x7f53451ba510>] 2. MultiplicativeLR Multiply the learning rate of each parameter group by the factor given in the specified function. When last_epoch=-1, sets initial lr as lr. \\[ l r_{\\text {epoch}} = l r_{\\text {epoch - 1}} * Lambda(epoch) \\] model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) lmbda = lambda epoch : 0.65 ** epoch scheduler = torch . optim . lr_scheduler . MultiplicativeLR ( optimizer , lr_lambda = lmbda ) lrs = [] for i in range ( 10 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",0.95,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( range ( 10 ), lrs ) [<matplotlib.lines.Line2D at 0x7f53450df590>] 3. StepLR Decays the learning rate of each parameter group by gamma every step_size epochs. Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler. When last_epoch=-1, sets initial lr as lr. \\[ l r_{\\text {epoch}}=\\left\\{\\begin{array}{ll} Gamma * l r_{\\text {epoch - 1}}, & \\text { if } {\\text {epoch % step_size}}=0 \\\\ l r_{\\text {epoch - 1}}, & \\text { otherwise } \\end{array}\\right. \\] model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) scheduler = torch . optim . lr_scheduler . StepLR ( optimizer , step_size = 2 , gamma = 0.1 ) lrs = [] for i in range ( 10 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",0.1 if i!=0 and i%2!=0 else 1,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( range ( 10 ), lrs ) [<matplotlib.lines.Line2D at 0x7f534505af10>] 4. MultiStepLR Decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones. Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler. When last_epoch=-1, sets initial lr as lr. \\[ l r_{\\text {epoch}}=\\left\\{\\begin{array}{ll} Gamma * l r_{\\text {epoch - 1}}, & \\text { if } {\\text{ epoch in [milestones]}} \\\\ l r_{\\text {epoch - 1}}, & \\text { otherwise } \\end{array}\\right. \\] model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) scheduler = torch . optim . lr_scheduler . MultiStepLR ( optimizer , milestones = [ 6 , 8 , 9 ], gamma = 0.1 ) lrs = [] for i in range ( 10 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",0.1 if i in [6,8,9] else 1,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( range ( 10 ), lrs ) [<matplotlib.lines.Line2D at 0x7f5344fc5ad0>] 5. ExponentialLR Decays the learning rate of each parameter group by gamma every epoch. When last_epoch=-1, sets initial lr as lr. \\[ l r_{\\text {epoch}}= Gamma * l r_{\\text {epoch - 1}} \\] model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) scheduler = torch . optim . lr_scheduler . ExponentialLR ( optimizer , gamma = 0.1 ) lrs = [] for i in range ( 10 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",0.1,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344fad990>] 6. CosineAnnealingLR Set the learning rate of each parameter group using a cosine annealing schedule. When last_epoch=-1, sets initial lr as lr. Notice that because the schedule is defined recursively, the learning rate can be simultaneously modified outside this scheduler by other operators. If the learning rate is set solely by this scheduler, the learning rate at each step becomes: \\[ \\eta_{t}=\\eta_{\\min }+\\frac{1}{2}\\left(\\eta_{\\max }-\\eta_{\\min }\\right)\\left(1+\\cos \\left(\\frac{T_{c u r}}{T_{\\max }} \\pi\\right)\\right) \\] It has been proposed in SGDR: Stochastic Gradient Descent with Warm Restarts. Note that this only implements the cosine annealing part of SGDR, and not the restarts.https://arxiv.org/abs/1608.03983 model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) scheduler = torch . optim . lr_scheduler . CosineAnnealingLR ( optimizer , T_max = 10 , eta_min = 0 ) lrs = [] for i in range ( 100 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f534503ce90>] 7. CyclicLR - triangular model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 0.1 ) scheduler = torch . optim . lr_scheduler . CyclicLR ( optimizer , base_lr = 0.001 , max_lr = 0.1 , step_size_up = 5 , mode = \"triangular\" ) lrs = [] for i in range ( 100 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344e82a10>] 7. CyclicLR - triangular2 model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 0.1 ) scheduler = torch . optim . lr_scheduler . CyclicLR ( optimizer , base_lr = 0.001 , max_lr = 0.1 , step_size_up = 5 , mode = \"triangular2\" ) lrs = [] for i in range ( 100 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344e16690>] 7. CyclicLR - exp_range model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) scheduler = torch . optim . lr_scheduler . CyclicLR ( optimizer , base_lr = 0.001 , max_lr = 0.1 , step_size_up = 5 , mode = \"exp_range\" , gamma = 0.85 ) lrs = [] for i in range ( 100 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344dd4d90>] 8.OneCycleLR - cos Sets the learning rate of each parameter group according to the 1cycle learning rate policy. The 1cycle policy anneals the learning rate from an initial learning rate to some maximum learning rate and then from that maximum learning rate to some minimum learning rate much lower than the initial learning rate. This policy was initially described in the paper Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates. The 1cycle learning rate policy changes the learning rate after every batch. step should be called after a batch has been used for training. This scheduler is not chainable. model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 0.1 ) scheduler = torch . optim . lr_scheduler . OneCycleLR ( optimizer , max_lr = 0.1 , steps_per_epoch = 10 , epochs = 10 ) lrs = [] for i in range ( 100 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344d64c50>] 8.OneCycleLR - linear model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 0.1 ) scheduler = torch . optim . lr_scheduler . OneCycleLR ( optimizer , max_lr = 0.1 , steps_per_epoch = 10 , epochs = 10 , anneal_strategy = 'linear' ) lrs = [] for i in range ( 100 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344d283d0>] 9.CosineAnnealingWarmRestarts Set the learning rate of each parameter group using a cosine annealing schedule, and restarts after Ti epochs. \\[ \\eta_{t}=\\eta_{\\min }+\\frac{1}{2}\\left(\\eta_{\\max }-\\eta_{\\min }\\right)\\left(1+\\cos \\left(\\frac{T_{\\operatorname{cur}}}{T_{i}} \\pi\\right)\\right) \\] import torch import matplotlib.pyplot as plt model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 0.1 ) lr_sched = torch . optim . lr_scheduler . CosineAnnealingWarmRestarts ( optimizer , T_0 = 10 , T_mult = 1 , eta_min = 0.001 , last_epoch =- 1 ) lrs = [] for i in range ( 100 ): lr_sched . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ] ) plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344c93ad0>] import torch import matplotlib.pyplot as plt model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 0.1 ) lr_sched = torch . optim . lr_scheduler . CosineAnnealingWarmRestarts ( optimizer , T_0 = 10 , T_mult = 2 , eta_min = 0.01 , last_epoch =- 1 ) lrs = [] for i in range ( 300 ): lr_sched . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ] ) plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344bffa10>]","title":"Guide to pytorch learning rate scheduling"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/learning_rate_schedulers/pytorch_gradual_warmup_scheduler/notebook/guide-to-pytorch-learning-rate-scheduling/#1-lambda-lr","text":"Sets the learning rate of each parameter group to the initial lr times a given function. When last_epoch=-1, sets initial lr as lr. \\[ l r_{\\text {epoch}} = l r_{\\text {initial}} * Lambda(epoch) \\] model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) lambda1 = lambda epoch : 0.65 ** epoch scheduler = torch . optim . lr_scheduler . LambdaLR ( optimizer , lr_lambda = lambda1 ) lrs = [] for i in range ( 10 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \", round(0.65 ** i,3),\" , Learning Rate = \",round(optimizer.param_groups[0][\"lr\"],3)) scheduler . step () plt . plot ( range ( 10 ), lrs ) [<matplotlib.lines.Line2D at 0x7f53451ba510>]","title":"1. LAMBDA LR"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/learning_rate_schedulers/pytorch_gradual_warmup_scheduler/notebook/guide-to-pytorch-learning-rate-scheduling/#2-multiplicativelr","text":"Multiply the learning rate of each parameter group by the factor given in the specified function. When last_epoch=-1, sets initial lr as lr. \\[ l r_{\\text {epoch}} = l r_{\\text {epoch - 1}} * Lambda(epoch) \\] model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) lmbda = lambda epoch : 0.65 ** epoch scheduler = torch . optim . lr_scheduler . MultiplicativeLR ( optimizer , lr_lambda = lmbda ) lrs = [] for i in range ( 10 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",0.95,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( range ( 10 ), lrs ) [<matplotlib.lines.Line2D at 0x7f53450df590>]","title":"2. MultiplicativeLR"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/learning_rate_schedulers/pytorch_gradual_warmup_scheduler/notebook/guide-to-pytorch-learning-rate-scheduling/#3-steplr","text":"Decays the learning rate of each parameter group by gamma every step_size epochs. Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler. When last_epoch=-1, sets initial lr as lr. \\[ l r_{\\text {epoch}}=\\left\\{\\begin{array}{ll} Gamma * l r_{\\text {epoch - 1}}, & \\text { if } {\\text {epoch % step_size}}=0 \\\\ l r_{\\text {epoch - 1}}, & \\text { otherwise } \\end{array}\\right. \\] model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) scheduler = torch . optim . lr_scheduler . StepLR ( optimizer , step_size = 2 , gamma = 0.1 ) lrs = [] for i in range ( 10 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",0.1 if i!=0 and i%2!=0 else 1,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( range ( 10 ), lrs ) [<matplotlib.lines.Line2D at 0x7f534505af10>]","title":"3. StepLR"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/learning_rate_schedulers/pytorch_gradual_warmup_scheduler/notebook/guide-to-pytorch-learning-rate-scheduling/#4-multisteplr","text":"Decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones. Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler. When last_epoch=-1, sets initial lr as lr. \\[ l r_{\\text {epoch}}=\\left\\{\\begin{array}{ll} Gamma * l r_{\\text {epoch - 1}}, & \\text { if } {\\text{ epoch in [milestones]}} \\\\ l r_{\\text {epoch - 1}}, & \\text { otherwise } \\end{array}\\right. \\] model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) scheduler = torch . optim . lr_scheduler . MultiStepLR ( optimizer , milestones = [ 6 , 8 , 9 ], gamma = 0.1 ) lrs = [] for i in range ( 10 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",0.1 if i in [6,8,9] else 1,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( range ( 10 ), lrs ) [<matplotlib.lines.Line2D at 0x7f5344fc5ad0>]","title":"4. MultiStepLR"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/learning_rate_schedulers/pytorch_gradual_warmup_scheduler/notebook/guide-to-pytorch-learning-rate-scheduling/#5-exponentiallr","text":"Decays the learning rate of each parameter group by gamma every epoch. When last_epoch=-1, sets initial lr as lr. \\[ l r_{\\text {epoch}}= Gamma * l r_{\\text {epoch - 1}} \\] model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) scheduler = torch . optim . lr_scheduler . ExponentialLR ( optimizer , gamma = 0.1 ) lrs = [] for i in range ( 10 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",0.1,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344fad990>]","title":"5. ExponentialLR"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/learning_rate_schedulers/pytorch_gradual_warmup_scheduler/notebook/guide-to-pytorch-learning-rate-scheduling/#6-cosineannealinglr","text":"Set the learning rate of each parameter group using a cosine annealing schedule. When last_epoch=-1, sets initial lr as lr. Notice that because the schedule is defined recursively, the learning rate can be simultaneously modified outside this scheduler by other operators. If the learning rate is set solely by this scheduler, the learning rate at each step becomes: \\[ \\eta_{t}=\\eta_{\\min }+\\frac{1}{2}\\left(\\eta_{\\max }-\\eta_{\\min }\\right)\\left(1+\\cos \\left(\\frac{T_{c u r}}{T_{\\max }} \\pi\\right)\\right) \\] It has been proposed in SGDR: Stochastic Gradient Descent with Warm Restarts. Note that this only implements the cosine annealing part of SGDR, and not the restarts.https://arxiv.org/abs/1608.03983 model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) scheduler = torch . optim . lr_scheduler . CosineAnnealingLR ( optimizer , T_max = 10 , eta_min = 0 ) lrs = [] for i in range ( 100 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f534503ce90>]","title":"6. CosineAnnealingLR"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/learning_rate_schedulers/pytorch_gradual_warmup_scheduler/notebook/guide-to-pytorch-learning-rate-scheduling/#7-cycliclr-triangular","text":"model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 0.1 ) scheduler = torch . optim . lr_scheduler . CyclicLR ( optimizer , base_lr = 0.001 , max_lr = 0.1 , step_size_up = 5 , mode = \"triangular\" ) lrs = [] for i in range ( 100 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344e82a10>]","title":"7. CyclicLR - triangular"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/learning_rate_schedulers/pytorch_gradual_warmup_scheduler/notebook/guide-to-pytorch-learning-rate-scheduling/#7-cycliclr-triangular2","text":"model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 0.1 ) scheduler = torch . optim . lr_scheduler . CyclicLR ( optimizer , base_lr = 0.001 , max_lr = 0.1 , step_size_up = 5 , mode = \"triangular2\" ) lrs = [] for i in range ( 100 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344e16690>]","title":"7. CyclicLR - triangular2"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/learning_rate_schedulers/pytorch_gradual_warmup_scheduler/notebook/guide-to-pytorch-learning-rate-scheduling/#7-cycliclr-exp_range","text":"model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) scheduler = torch . optim . lr_scheduler . CyclicLR ( optimizer , base_lr = 0.001 , max_lr = 0.1 , step_size_up = 5 , mode = \"exp_range\" , gamma = 0.85 ) lrs = [] for i in range ( 100 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344dd4d90>]","title":"7. CyclicLR - exp_range"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/learning_rate_schedulers/pytorch_gradual_warmup_scheduler/notebook/guide-to-pytorch-learning-rate-scheduling/#8onecyclelr-cos","text":"Sets the learning rate of each parameter group according to the 1cycle learning rate policy. The 1cycle policy anneals the learning rate from an initial learning rate to some maximum learning rate and then from that maximum learning rate to some minimum learning rate much lower than the initial learning rate. This policy was initially described in the paper Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates. The 1cycle learning rate policy changes the learning rate after every batch. step should be called after a batch has been used for training. This scheduler is not chainable. model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 0.1 ) scheduler = torch . optim . lr_scheduler . OneCycleLR ( optimizer , max_lr = 0.1 , steps_per_epoch = 10 , epochs = 10 ) lrs = [] for i in range ( 100 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344d64c50>]","title":"8.OneCycleLR - cos"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/learning_rate_schedulers/pytorch_gradual_warmup_scheduler/notebook/guide-to-pytorch-learning-rate-scheduling/#8onecyclelr-linear","text":"model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 0.1 ) scheduler = torch . optim . lr_scheduler . OneCycleLR ( optimizer , max_lr = 0.1 , steps_per_epoch = 10 , epochs = 10 , anneal_strategy = 'linear' ) lrs = [] for i in range ( 100 ): optimizer . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) scheduler . step () plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344d283d0>]","title":"8.OneCycleLR - linear"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/learning_rate_schedulers/pytorch_gradual_warmup_scheduler/notebook/guide-to-pytorch-learning-rate-scheduling/#9cosineannealingwarmrestarts","text":"Set the learning rate of each parameter group using a cosine annealing schedule, and restarts after Ti epochs. \\[ \\eta_{t}=\\eta_{\\min }+\\frac{1}{2}\\left(\\eta_{\\max }-\\eta_{\\min }\\right)\\left(1+\\cos \\left(\\frac{T_{\\operatorname{cur}}}{T_{i}} \\pi\\right)\\right) \\] import torch import matplotlib.pyplot as plt model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 0.1 ) lr_sched = torch . optim . lr_scheduler . CosineAnnealingWarmRestarts ( optimizer , T_0 = 10 , T_mult = 1 , eta_min = 0.001 , last_epoch =- 1 ) lrs = [] for i in range ( 100 ): lr_sched . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ] ) plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344c93ad0>] import torch import matplotlib.pyplot as plt model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 0.1 ) lr_sched = torch . optim . lr_scheduler . CosineAnnealingWarmRestarts ( optimizer , T_0 = 10 , T_mult = 2 , eta_min = 0.01 , last_epoch =- 1 ) lrs = [] for i in range ( 300 ): lr_sched . step () lrs . append ( optimizer . param_groups [ 0 ][ \"lr\" ] ) plt . plot ( lrs ) [<matplotlib.lines.Line2D at 0x7f5344bffa10>]","title":"9.CosineAnnealingWarmRestarts"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss/","text":"\\[ \\newcommand{\\ytrue}{\\mathbf{y_{\\textbf{true}}}} \\newcommand{\\yprob}{\\mathbf{y_{\\textbf{prob}}}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\x}{\\mathbf{x}} \\] Cross-Entropy as a Loss Function Intuition We need to make sense of entropy in the form of a loss function, we have to just enhance our thinking a little. We define our target to be a one-hot encoded vector of class 0 and 1. target = [ 0 , 1 ] Intuitively, take the cat vs dog binary classification again, we made 11 predictions for ONLY ONE query image using different model, and find that after going through many layers, the softmax predictions on the logits are as such: [ [ 0.0 , 1.0 ], [ 0.1 , 0.9 ], [ 0.2 , 0.8 ], [ 0.3 , 0.7 ], [ 0.4 , 0.6 ], [ 0.5 , 0.5 ], [ 0.6 , 0.4 ], [ 0.7 , 0.3 ], [ 0.8 , 0.2 ], [ 0.9 , 0.1 ], [ 1.0 , 0.0 ], ] where the first index corresponds to the logits of class 0 and second index corresponds to the logits of class 1. For example, [1, 0] means the model is 100 percent confident the prediction is a class 0 (cat), and obviously we need to punish the model for spitting nonsense like this. As we can see in the binary_cross_entropy function below, we only need to add up two things. And note that we are hinging on class 1 and therefore y_true[0] * log(y_pred[0]+eps) goes to 0 as we are just relying on our feedback of probability of class 1. And in our graph, we can see that as predictions gets more wrong, meaning to say, if the query image is a dog, but our predictions is [1, 0] , which says it is a cat, our entropy loss will blow up to very high because y_true [ 1 ] * log ( y_pred [ 1 ] + eps ) -> 1 * log ( 1 + eps ) -> almost infinity Note again we do not calculate for class 0 because We one-hot encoded. We only look at class 1's probability and that's enough as we can deduce class 0's probability anyways. And conversely, note how the entropy loss goes to 0 if our prediction is say [0, 1] . In general, as our probability for the query image gets close to 1, or in agreement with our class, then our entropy loss becomes smaller. Cross-Entropy on one Example We first understand the idea and intuition of Cross-Entropy Loss on one single example. Consider a dataset of cat (class 0) and dogs (class 1) where after one hot encoding we have class 0 to be \\([1, 0]\\) and class 1 to be \\([0, 1]\\) . We are given the following: \\(\\mathcal{D}\\) : The dataset. \\(\\mathbf{x}_q\\) : One single query image (i.e one image only). This can be a random variable . \\(\\mathbf{y}_q\\) : The corresponding label - dog (class 1) which is \\([0, 1]\\) . \\(P\\) : The probability distribution for the ground truth target - which is \\([0, 1]\\) , one can understand it as the distribution where cat's probability is 0, and dog's probability is 1. \\(Q\\) : The probability distribtion of the estimate on the \\(\\mathbf{x}_q\\) , which is say, \\([0.1, 0.9]\\) . Thus, we can compute the cross entropy loss of this single image by: import numpy as np import torch import torch.nn.functional as F torch . __version__ '1.10.1+cpu' def torch_to_np ( tensor : torch . Tensor ) -> np . ndarray : \"\"\"Convert a PyTorch tensor to a numpy array. Args: tensor (torch.Tensor): The PyTorch tensor to convert. Returns: np.ndarray: The converted numpy array. \"\"\" return tensor . detach () . cpu () . numpy () def compare_equality_two_tensors ( tensor1 : torch . Tensor , tensor2 : torch . Tensor ) -> bool : \"\"\"Compare two PyTorch tensors for equality. Args: tensor1 (torch.Tensor): The first PyTorch tensor to compare. tensor2 (torch.Tensor): The second PyTorch tensor to compare. Returns: bool: Whether the two tensors are equal. \"\"\" if torch . all ( torch . eq ( tensor1 , tensor2 )): return True return False def compare_closeness_two_tensors ( tensor1 : torch . Tensor , tensor2 : torch . Tensor , epsilon : float , * args , ** kwargs ) -> bool : \"\"\"Compare two PyTorch tensors for closeness. Args: tensor1 (torch.Tensor): The first PyTorch tensor to compare. tensor2 (torch.Tensor): The second PyTorch tensor to compare. epsilon (float): The epsilon value to use for closeness. Returns: bool: Whether the two tensors are close. \"\"\" if torch . allclose ( tensor1 , tensor2 , atol = epsilon , * args , ** kwargs ): return True return False z_logits = torch . tensor ([[ 1 , 2 , 3 ], [ 2 , 4 , 6 ]], dtype = torch . float32 ) y_true = torch . tensor ([ 0 , 2 ], dtype = torch . long ) y_true_ohe = torch . tensor ([[ 1 , 0 , 0 ], [ 0 , 0 , 1 ]], dtype = torch . long ) compare_equality_two_tensors ( y_true_ohe , torch . nn . functional . one_hot ( y_true , num_classes = 3 )) True def compute_softargmax ( z : torch . Tensor ) -> torch . Tensor : \"\"\"Compute the softargmax of a PyTorch tensor. Args: z (torch.Tensor): The PyTorch tensor to compute the softargmax of. Returns: torch.Tensor: The softargmax of the PyTorch tensor. \"\"\" # the output matrix should be the same size as the input matrix z_softargmax = torch . zeros ( size = z . size (), dtype = torch . float32 ) for row_index , each_row in enumerate ( z ): denominator = torch . sum ( torch . exp ( each_row )) for element_index , each_element in enumerate ( each_row ): z_softargmax [ row_index , element_index ] = ( torch . exp ( each_element ) / denominator ) assert compare_closeness_two_tensors ( z_softargmax , torch . nn . Softmax ( dim = 1 )( z ), 1e-15 ) return z_softargmax z_softargmax = compute_softargmax ( z_logits ) torch . nn . CrossEntropyLoss ()( z_logits , y_true ) tensor(1.2753) z_logits tensor([[1., 2., 3.], [2., 4., 6.]]) z_softargmax tensor([[0.0900, 0.2447, 0.6652], [0.0159, 0.1173, 0.8668]]) y_true_ohe tensor([[1, 0, 0], [0, 0, 1]]) ( - 1 * torch . log ( z_softargmax )) . T tensor([[2.4076, 4.1429], [1.4076, 2.1429], [0.4076, 0.1429]]) m = y_true_ohe . float () . matmul (( - 1 * torch . log ( z_softargmax )) . T ) m tensor([[2.4076, 4.1429], [0.4076, 0.1429]]) torch . diagonal ( m , 0 ) . sum () tensor(2.5505) Categorical Cross Entropy Loss We will start with this because the Binary Cross Entropy Loss is merely a special case of this. Finding the full compact formula for this took me a while since most tutorials cover the binary case. Given \\(N\\) samples, and \\(C\\) classes, the Categorical Cross Entropy Loss is the average loss across \\(N\\) samples, given by: \\[\\textbf{CE}(\\ytrue, \\yprob) = -\\dfrac{1}{N}\\sum_{i=1}^N\\sum_{c=1}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\] where The outer loop \\(i\\) iterates over \\(N\\) observations/samples. The inner loop \\(c\\) iterates over \\(C\\) classes. \\(\\y_i\\) represents the true label (in this formula it should be one-hot encoded) of the \\(i\\) -th sample. \\(\\mathbb{1}_{y_{i} \\in C_c}\\) is an indicator function, simply put, for sample \\(i\\) , if the true label \\(\\y_i\\) belongs to the \\(c\\) -th category, then we assign a \\(1\\) , else \\(0\\) . We can see it with an example later. \\(\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) means the probability predicted by the model for the \\(i\\) -th observation that belongs to the \\(c\\) -th class category. \\[ \\ytrue = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\] \\[ \\textbf{z_logits} = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\end{bmatrix} \\] \\[ \\yprob = \\textbf{z_softargmax} = \\begin{bmatrix} 0.09 & 0.2447 & 0.6652 \\\\ 0.0159 & 0.1173 & 0.8668\\end{bmatrix} \\] We first look at the first sample, index \\(i = 1\\) : We have the one-hot encoded label for first sample to be \\(\\y_1 = \\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix}\\) . This means the label is a cat since the sequence is cat, dog and pig, and thus 1, 0, 0 corresponds to cat 1, dog 0 and pig 0. We have the one-hot encoded probability predicted by the model for the first sample to be \\(\\hat{\\y_1} = \\begin{bmatrix} 0.09 & 0.2447 & 0.6652 \\end{bmatrix}\\) . This means the probability associated with this sample \\(1\\) is probability of a cat from the model is \\(9\\%\\) , a dog \\(24.47\\%\\) and a pig \\(66.52\\%\\) . With these information, we go on to the first outer loop's content: \\(\\sum_{c=1}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) We are looping through the classes, which in this case is loop from \\(c=1\\) to \\(c=3\\) since \\(C=3\\) (3 classes). \\(c = 1\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{1} \\in C_1}\\) : The true label for the first sample is actually the first class, and hence belongs to the \\(c=1\\) category, so our indicator function returns me a \\(1\\) . \\(\\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right) = \\log\\left(p_{\\textbf{model}}[\\y_1 \\in C_1]\\right)\\) : Applies the log function (natural log here) to the each probability associated with the class. So in this case, since \\(c=1\\) , we apply the log function to the first entry \\(0.09\\) . We get \\(\\log(0.09) = -2.4079\\) \\(c = 2\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{1} \\in C_2}\\) : The true label for the first sample is actually the first class, and hence does not belong to the \\(c=2\\) category, so our indicator function returns me a \\(0\\) . Regardless, the log of this probability is \\(\\log(0.2447) = -1.4076\\) \\(c = 3\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{1} \\in C_3}\\) : The true label for the first sample is actually the first class, and hence does not belong to the \\(c=3\\) category, so our indicator function returns me a \\(0\\) . Regardless, the log of this probability is \\(\\log(0.6652) = -0.4076\\) Lastly, we sum them up and get \\(-2.4076 + 0 + 0 = -2.4076\\) , note here we only have the first entry! The second and third are \\(0\\) . In code, this corresponds to the following: # loop = 1 current_sample_loss = 0 for each_y_true_element , each_y_prob_element in zip ( each_y_true_one_hot_vector , each_y_prob_one_hot_vector ): # Indicator Function if each_y_true_element == 1 : current_sample_loss += - 1 * torch . log ( each_y_prob_element ) else : current_sample_loss += 0 Bonus: If you realize this is just a vector dot product: \\(\\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix} \\cdot \\log\\left(\\begin{bmatrix} 0.09 \\\\ 0.2447 \\\\ 0.6652 \\end{bmatrix}\\right) = \\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix} \\cdot \\left(\\begin{bmatrix} -2.4076 \\\\ -1.4076 \\\\ -0.4076 \\end{bmatrix}\\right) = -2.4076\\) We now look at the second sample, index \\(i = 2\\) : We have the one-hot encoded label for second sample to be \\(\\y_2 = \\begin{bmatrix} 0 & 0 & 1 \\end{bmatrix}\\) . This means the label is a pig since the sequence is cat, dog and pig, and thus 0, 0, 1 corresponds to cat 0, dog 0 and pig 1. We have the one-hot encoded probability predicted by the model for the second sample to be \\(\\hat{\\y_2} = \\begin{bmatrix} 0.0159 & 0.1173 & 0.8868 \\end{bmatrix}\\) . This means the probability associated with this sample \\(2\\) is probability of a cat from the model is \\(1.59\\%\\) , a dog \\(11.73\\%\\) and a pig \\(88.68\\%\\) . With these information, we go on to the second outer loop's content: \\(\\sum_{c=2}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) \\(c = 2\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{2} \\in C_1}\\) : The true label for the second sample is actually the third class, and hence belongs to the \\(c=3\\) category, so our indicator function returns me a \\(0\\) . \\(\\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) : Applies the log function (natural log here) to the each probability associated with the class. So in this case, since \\(c=1\\) , we apply the log function to the first entry \\(0.0159\\) . We get \\(\\log(0.0159) = -4.1429\\) \\(c = 2\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{2} \\in C_2}\\) : The true label for the second sample is actually the third class, and hence does not belong to the \\(c=2\\) category, so our indicator function returns me a \\(0\\) . Regardless, the log of this probability is \\(\\log(0.1173) = -2.1429\\) \\(c = 3\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{2} \\in C_3}\\) : The true label for the second sample is actually the third class, so our indicator function returns me a \\(1\\) . The log of this probability is \\(\\log(0.6652) = -0.1429\\) Lastly, we sum them up and get \\(0 + 0 + (-0.1429) = -0.1429\\) , note here we only have the third entry! The first and second entries are \\(0\\) . In code, this corresponds to the following: # loop = 2 current_sample_loss = 0 for each_y_true_element , each_y_prob_element in zip ( each_y_true_one_hot_vector , each_y_prob_one_hot_vector ): # Indicator Function if each_y_true_element == 1 : current_sample_loss += - 1 * torch . log ( each_y_prob_element ) else : current_sample_loss += 0 Bonus: If you realize this is just a vector dot product: \\(\\begin{bmatrix} 0 & 0 & 1 \\end{bmatrix} \\cdot \\log\\left(\\begin{bmatrix} 0.0159 \\\\ 0.1173 \\\\ 0.8868\\end{bmatrix}\\right) = \\begin{bmatrix} 0 & 0 & 1 \\end{bmatrix} \\cdot \\left(\\begin{bmatrix} -4.1429 \\\\ -2.1429 \\\\ -0.1429 \\end{bmatrix}\\right) = -0.1429\\) To summarize the whole process: set all_samples_loss = 0 Start Outer Loop: loop over first sample i = 1 (actually index is 0 in python): set current_sample_loss = 0 loop over \\(C=3\\) classes: when \\(c = 1\\) : the loss associated is \\(-2.4076\\) . Add this to current_sample_loss . when \\(c = 2\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . when \\(c = 3\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . end first loop: update all_samples_loss by adding current_sample_loss to be all_samples_loss = -2.4076 . loop over second sample i = 2 (actually index is 1 in python): set current_sample_loss = 0 loop over \\(C=3\\) classes: when \\(c = 1\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . when \\(c = 2\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . when \\(c = 3\\) : the loss associated is \\(-0.1429\\) . Add this to current_sample_loss . end second loop: update all_samples_loss by adding current_sample_loss to be all_samples_loss = -2.4076 + (-0.1429) = -2.5505 . End all loops: You can multiply by negative \\(-1\\) to make all_samples_loss positive and get all_samples_average_loss = all_samples_loss / num_of_samples = 2.5505 / 2 = 1.2753 . def compute_categorical_cross_entropy_loss ( y_true : torch . Tensor , y_prob : torch . Tensor ) -> torch . Tensor : \"\"\"Compute the categorical cross entropy loss between two PyTorch tensors. Args: y_true (torch.Tensor): The true labels. y_prob (torch.Tensor): The predicted labels. Returns: torch.Tensor: The categorical cross entropy loss. \"\"\" all_samples_loss = 0 for each_y_true_one_hot_vector , each_y_prob_one_hot_vector in zip ( y_true , y_prob ): current_sample_loss = 0 for each_y_true_element , each_y_prob_element in zip ( each_y_true_one_hot_vector , each_y_prob_one_hot_vector ): # Indicator Function if each_y_true_element == 1 : current_sample_loss += - 1 * torch . log ( each_y_prob_element ) else : current_sample_loss += 0 all_samples_loss += current_sample_loss all_samples_average_loss = all_samples_loss / y_true . shape [ 0 ] return all_samples_average_loss Using Dot Product to Calculate \\[ \\begin{aligned} \\textbf{CE}(\\ytrue, \\yprob) &= -\\dfrac{1}{N}\\sum_{i=1}^N\\sum_{c=1}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\\\ &= \\textbf{SUM}\\left[\\textbf{diag}\\left(\\ytrue \\cdot -\\log(\\yprob)^\\top\\right)\\right] \\end{aligned}\\] We can easily see \\[ \\ytrue = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\] \\[ \\textbf{z_logits} = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\end{bmatrix} \\] \\[ \\yprob = \\textbf{z_softargmax} = \\begin{bmatrix} 0.09 & 0.2447 & 0.6652 \\\\ 0.0159 & 0.1173 & 0.8668\\end{bmatrix} \\] \\[\\log(\\yprob) = \\begin{bmatrix} 2.4076 & 1.4076 & 0.4076 \\\\ 4.1429 & 2.1429 & 0.1429 \\end{bmatrix}\\] \\[ \\ytrue \\cdot -\\log(\\yprob)^\\top = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\cdot \\begin{bmatrix} 2.4076 & 4.1429 \\\\ 1.4076 & 2.1429 \\\\ 0.4076 & 0.1429 \\end{bmatrix} = \\begin{bmatrix} 2.4076 & 4.1429 \\\\ 0.4076 & 0.1429 \\end{bmatrix} \\] The matrix \\(\\ytrue \\cdot -\\log(\\yprob)^\\top\\) diagonals are what we need, where we sum them up and divide by the number of samples. That is \\(\\frac{2.4076+0.1429}{2} = \\frac{2.5505}{2} = 1.2753\\) . This makes sense because the one hot encoded \\(\\ytrue\\) vector guarantees only the indicator functions 1 gets activated and the rest gets zeroed out. Furthermore, we are only interested in the diagonal of the matrix as we are only interested in the dot product between the \\(i\\) -th row and the \\(i\\) -th column of \\(\\ytrue\\) and \\(-\\log(\\yprob)^\\top\\) respectively. def compute_categorical_cross_entropy_loss_dot_product ( y_true : torch . Tensor , y_prob : torch . Tensor ) -> torch . Tensor : \"\"\"Compute the categorical cross entropy loss between two PyTorch tensors using dot product. Args: y_true (torch.Tensor): The true labels in one-hot form. y_prob (torch.Tensor): The predicted labels in one-hot form. Returns: torch.Tensor: The categorical cross entropy loss. \"\"\" m = torch . matmul ( y_true . float (), torch . neg ( torch . log ( y_prob . float ()) . T )) all_loss_vector = torch . diagonal ( m , 0 ) all_loss_sum = torch . sum ( all_loss_vector , dim = 0 ) average_loss = all_loss_sum / y_true . shape [ 0 ] return average_loss compute_categorical_cross_entropy_loss ( y_true = y_true_ohe , y_prob = compute_softargmax ( z_logits )) tensor(1.2753) compute_categorical_cross_entropy_loss_dot_product ( y_true = y_true_ohe , y_prob = compute_softargmax ( z_logits )) tensor(1.2753) compute_softargmax ( z_logits ) tensor([[0.0900, 0.2447, 0.6652], [0.0159, 0.1173, 0.8668]]) def cross_entropy ( y_true : np . ndarray , y_pred : np . ndarray , epsilon : float = 1e-12 ): \"\"\" https://stackoverflow.com/questions/47377222/what-is-the-problem-with-my-implementation-of-the-cross-entropy-function Computes cross entropy between targets (encoded as one-hot vectors) and y_pred. Input: y_pred (N, k) ndarray y_true (N, k) ndarray Returns: scalar predictions = np.array([[0.25,0.25,0.25,0.25], [0.01,0.01,0.01,0.96]]) targets = np.array([[0,0,0,1], [0,0,0,1]]) ans = 0.71355817782 #Correct answer x = cross_entropy(predictions, targets) print(np.isclose(x,ans)) \"\"\" y_pred = np . clip ( y_pred , epsilon , 1.0 - epsilon ) # take note that y_pred is of shape 1 x n_samples as stated in our framework n_samples = y_pred . shape [ 1 ] # cross entropy function cross_entropy_function = y_true * np . log ( y_pred ) + ( 1 - y_true ) * np . log ( 1 - y_pred ) # cross entropy function here is same shape as y_true and y_pred since we are # just performing element wise operations on both of them. assert cross_entropy_function . shape == ( 1 , n_samples ) # we sum up all the loss for each individual sample total_cross_entropy_loss = - np . sum ( cross_entropy_function , axis = 1 ) assert total_cross_entropy_loss . shape == ( 1 ,) # we then average out the total loss across m samples, but we squeeze it to # make it a scalar; squeeze along axis = None since there is no column axix average_cross_entropy_loss = np . squeeze ( total_cross_entropy_loss / n_samples , axis = None ) # cross_entropy_loss = -np.sum(y_true * np.log(y_pred)) / n_samples # print(np.isclose(average_cross_entropy_loss, cross_entropy_loss)) return average_cross_entropy_loss cross_entropy ( y_true = np . asarray ([[ 0 , 1 ]]), y_pred = np . asarray ([[ 0.01 , 0.99 ]])) array(0.01005034) from math import log # calculate cross-entropy def cross_entropy ( p , q , ets = 1e-15 ): return - sum ([ p [ i ] * log ( q [ i ] + ets ) for i in range ( len ( p ))]) def binary_cross_entropy ( y_true , y_pred , eps = 1e-15 ): return - ( y_true [ 0 ] * log ( y_pred [ 0 ] + eps ) + y_true [ 1 ] * log ( y_pred [ 1 ] + eps )) # define the target distribution for two events target = [ 0.0 , 1.0 ] # define probabilities for the first event probs = [ [ 0.0 , 1.0 ], # cat is 0% and dog is 100% confidence [ 0.1 , 0.9 ], [ 0.2 , 0.8 ], [ 0.3 , 0.7 ], [ 0.4 , 0.6 ], [ 0.5 , 0.5 ], [ 0.6 , 0.4 ], [ 0.7 , 0.3 ], [ 0.8 , 0.2 ], [ 0.9 , 0.1 ], [ 1.0 , 0.0 ], ] # create probability distributions for the two events # dists = [[1.0 - p, p] for p in probs] # calculate cross-entropy for each distribution ents = [ binary_cross_entropy ( y_true = target , y_pred = d ) for d in probs ] # plot probability distribution vs cross-entropy pyplot . plot ([ p [ 1 ] for p in probs ], ents , marker = '.' ) pyplot . title ( 'Probability Distribution vs Cross-Entropy' ) #pyplot.xticks([1-p for p in probs], ['[%.1f,%.1f]'%(d[0],d[1]) for d in dists], rotation=70) pyplot . subplots_adjust ( bottom = 0.2 ) pyplot . xlabel ( 'Probability Distribution for Query Image when ground truth is 1' ) pyplot . ylabel ( 'Cross-Entropy (nats)' ) pyplot . show () analytics-vidhya-entropy-loss cross-entropy-loss-machine-learning-mastery entropy-how-decision-trees-make-decisions https://ramsane.github.io/articles/cross-entropy-explained-with-entropy-and-kl-divergence https://neptune.ai/blog/cross-entropy-loss-and-its-applications-in-deep-learning https://stackoverflow.com/questions/41990250/what-is-cross-entropy/41990932 https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e https://neptune.ai/blog/cross-entropy-loss-and-its-applications-in-deep-learning https://machinelearningmastery.com/cross-entropy-for-machine-learning/ https://d2l.ai/chapter_linear-networks/softmax-regression.html https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html#invertibility https://leimao.github.io/blog/Cross-Entropy-KL-Divergence-MLE/ https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451 https://gist.github.com/yang-zhang/217dcc6ae9171d7a46ce42e215c1fee0 https://datascience.stackexchange.com/questions/20296/cross-entropy-loss-explanation https://ramsane.github.io/articles/cross-entropy-explained-with-entropy-and-kl-divergence","title":"Cross entropy loss"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss/#cross-entropy-as-a-loss-function","text":"","title":"Cross-Entropy as a Loss Function"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss/#intuition","text":"We need to make sense of entropy in the form of a loss function, we have to just enhance our thinking a little. We define our target to be a one-hot encoded vector of class 0 and 1. target = [ 0 , 1 ] Intuitively, take the cat vs dog binary classification again, we made 11 predictions for ONLY ONE query image using different model, and find that after going through many layers, the softmax predictions on the logits are as such: [ [ 0.0 , 1.0 ], [ 0.1 , 0.9 ], [ 0.2 , 0.8 ], [ 0.3 , 0.7 ], [ 0.4 , 0.6 ], [ 0.5 , 0.5 ], [ 0.6 , 0.4 ], [ 0.7 , 0.3 ], [ 0.8 , 0.2 ], [ 0.9 , 0.1 ], [ 1.0 , 0.0 ], ] where the first index corresponds to the logits of class 0 and second index corresponds to the logits of class 1. For example, [1, 0] means the model is 100 percent confident the prediction is a class 0 (cat), and obviously we need to punish the model for spitting nonsense like this. As we can see in the binary_cross_entropy function below, we only need to add up two things. And note that we are hinging on class 1 and therefore y_true[0] * log(y_pred[0]+eps) goes to 0 as we are just relying on our feedback of probability of class 1. And in our graph, we can see that as predictions gets more wrong, meaning to say, if the query image is a dog, but our predictions is [1, 0] , which says it is a cat, our entropy loss will blow up to very high because y_true [ 1 ] * log ( y_pred [ 1 ] + eps ) -> 1 * log ( 1 + eps ) -> almost infinity Note again we do not calculate for class 0 because We one-hot encoded. We only look at class 1's probability and that's enough as we can deduce class 0's probability anyways. And conversely, note how the entropy loss goes to 0 if our prediction is say [0, 1] . In general, as our probability for the query image gets close to 1, or in agreement with our class, then our entropy loss becomes smaller.","title":"Intuition"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss/#cross-entropy-on-one-example","text":"We first understand the idea and intuition of Cross-Entropy Loss on one single example. Consider a dataset of cat (class 0) and dogs (class 1) where after one hot encoding we have class 0 to be \\([1, 0]\\) and class 1 to be \\([0, 1]\\) . We are given the following: \\(\\mathcal{D}\\) : The dataset. \\(\\mathbf{x}_q\\) : One single query image (i.e one image only). This can be a random variable . \\(\\mathbf{y}_q\\) : The corresponding label - dog (class 1) which is \\([0, 1]\\) . \\(P\\) : The probability distribution for the ground truth target - which is \\([0, 1]\\) , one can understand it as the distribution where cat's probability is 0, and dog's probability is 1. \\(Q\\) : The probability distribtion of the estimate on the \\(\\mathbf{x}_q\\) , which is say, \\([0.1, 0.9]\\) . Thus, we can compute the cross entropy loss of this single image by: import numpy as np import torch import torch.nn.functional as F torch . __version__ '1.10.1+cpu' def torch_to_np ( tensor : torch . Tensor ) -> np . ndarray : \"\"\"Convert a PyTorch tensor to a numpy array. Args: tensor (torch.Tensor): The PyTorch tensor to convert. Returns: np.ndarray: The converted numpy array. \"\"\" return tensor . detach () . cpu () . numpy () def compare_equality_two_tensors ( tensor1 : torch . Tensor , tensor2 : torch . Tensor ) -> bool : \"\"\"Compare two PyTorch tensors for equality. Args: tensor1 (torch.Tensor): The first PyTorch tensor to compare. tensor2 (torch.Tensor): The second PyTorch tensor to compare. Returns: bool: Whether the two tensors are equal. \"\"\" if torch . all ( torch . eq ( tensor1 , tensor2 )): return True return False def compare_closeness_two_tensors ( tensor1 : torch . Tensor , tensor2 : torch . Tensor , epsilon : float , * args , ** kwargs ) -> bool : \"\"\"Compare two PyTorch tensors for closeness. Args: tensor1 (torch.Tensor): The first PyTorch tensor to compare. tensor2 (torch.Tensor): The second PyTorch tensor to compare. epsilon (float): The epsilon value to use for closeness. Returns: bool: Whether the two tensors are close. \"\"\" if torch . allclose ( tensor1 , tensor2 , atol = epsilon , * args , ** kwargs ): return True return False z_logits = torch . tensor ([[ 1 , 2 , 3 ], [ 2 , 4 , 6 ]], dtype = torch . float32 ) y_true = torch . tensor ([ 0 , 2 ], dtype = torch . long ) y_true_ohe = torch . tensor ([[ 1 , 0 , 0 ], [ 0 , 0 , 1 ]], dtype = torch . long ) compare_equality_two_tensors ( y_true_ohe , torch . nn . functional . one_hot ( y_true , num_classes = 3 )) True def compute_softargmax ( z : torch . Tensor ) -> torch . Tensor : \"\"\"Compute the softargmax of a PyTorch tensor. Args: z (torch.Tensor): The PyTorch tensor to compute the softargmax of. Returns: torch.Tensor: The softargmax of the PyTorch tensor. \"\"\" # the output matrix should be the same size as the input matrix z_softargmax = torch . zeros ( size = z . size (), dtype = torch . float32 ) for row_index , each_row in enumerate ( z ): denominator = torch . sum ( torch . exp ( each_row )) for element_index , each_element in enumerate ( each_row ): z_softargmax [ row_index , element_index ] = ( torch . exp ( each_element ) / denominator ) assert compare_closeness_two_tensors ( z_softargmax , torch . nn . Softmax ( dim = 1 )( z ), 1e-15 ) return z_softargmax z_softargmax = compute_softargmax ( z_logits ) torch . nn . CrossEntropyLoss ()( z_logits , y_true ) tensor(1.2753) z_logits tensor([[1., 2., 3.], [2., 4., 6.]]) z_softargmax tensor([[0.0900, 0.2447, 0.6652], [0.0159, 0.1173, 0.8668]]) y_true_ohe tensor([[1, 0, 0], [0, 0, 1]]) ( - 1 * torch . log ( z_softargmax )) . T tensor([[2.4076, 4.1429], [1.4076, 2.1429], [0.4076, 0.1429]]) m = y_true_ohe . float () . matmul (( - 1 * torch . log ( z_softargmax )) . T ) m tensor([[2.4076, 4.1429], [0.4076, 0.1429]]) torch . diagonal ( m , 0 ) . sum () tensor(2.5505)","title":"Cross-Entropy on one Example"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss/#categorical-cross-entropy-loss","text":"We will start with this because the Binary Cross Entropy Loss is merely a special case of this. Finding the full compact formula for this took me a while since most tutorials cover the binary case. Given \\(N\\) samples, and \\(C\\) classes, the Categorical Cross Entropy Loss is the average loss across \\(N\\) samples, given by: \\[\\textbf{CE}(\\ytrue, \\yprob) = -\\dfrac{1}{N}\\sum_{i=1}^N\\sum_{c=1}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\] where The outer loop \\(i\\) iterates over \\(N\\) observations/samples. The inner loop \\(c\\) iterates over \\(C\\) classes. \\(\\y_i\\) represents the true label (in this formula it should be one-hot encoded) of the \\(i\\) -th sample. \\(\\mathbb{1}_{y_{i} \\in C_c}\\) is an indicator function, simply put, for sample \\(i\\) , if the true label \\(\\y_i\\) belongs to the \\(c\\) -th category, then we assign a \\(1\\) , else \\(0\\) . We can see it with an example later. \\(\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) means the probability predicted by the model for the \\(i\\) -th observation that belongs to the \\(c\\) -th class category. \\[ \\ytrue = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\] \\[ \\textbf{z_logits} = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\end{bmatrix} \\] \\[ \\yprob = \\textbf{z_softargmax} = \\begin{bmatrix} 0.09 & 0.2447 & 0.6652 \\\\ 0.0159 & 0.1173 & 0.8668\\end{bmatrix} \\] We first look at the first sample, index \\(i = 1\\) : We have the one-hot encoded label for first sample to be \\(\\y_1 = \\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix}\\) . This means the label is a cat since the sequence is cat, dog and pig, and thus 1, 0, 0 corresponds to cat 1, dog 0 and pig 0. We have the one-hot encoded probability predicted by the model for the first sample to be \\(\\hat{\\y_1} = \\begin{bmatrix} 0.09 & 0.2447 & 0.6652 \\end{bmatrix}\\) . This means the probability associated with this sample \\(1\\) is probability of a cat from the model is \\(9\\%\\) , a dog \\(24.47\\%\\) and a pig \\(66.52\\%\\) . With these information, we go on to the first outer loop's content: \\(\\sum_{c=1}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) We are looping through the classes, which in this case is loop from \\(c=1\\) to \\(c=3\\) since \\(C=3\\) (3 classes). \\(c = 1\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{1} \\in C_1}\\) : The true label for the first sample is actually the first class, and hence belongs to the \\(c=1\\) category, so our indicator function returns me a \\(1\\) . \\(\\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right) = \\log\\left(p_{\\textbf{model}}[\\y_1 \\in C_1]\\right)\\) : Applies the log function (natural log here) to the each probability associated with the class. So in this case, since \\(c=1\\) , we apply the log function to the first entry \\(0.09\\) . We get \\(\\log(0.09) = -2.4079\\) \\(c = 2\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{1} \\in C_2}\\) : The true label for the first sample is actually the first class, and hence does not belong to the \\(c=2\\) category, so our indicator function returns me a \\(0\\) . Regardless, the log of this probability is \\(\\log(0.2447) = -1.4076\\) \\(c = 3\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{1} \\in C_3}\\) : The true label for the first sample is actually the first class, and hence does not belong to the \\(c=3\\) category, so our indicator function returns me a \\(0\\) . Regardless, the log of this probability is \\(\\log(0.6652) = -0.4076\\) Lastly, we sum them up and get \\(-2.4076 + 0 + 0 = -2.4076\\) , note here we only have the first entry! The second and third are \\(0\\) . In code, this corresponds to the following: # loop = 1 current_sample_loss = 0 for each_y_true_element , each_y_prob_element in zip ( each_y_true_one_hot_vector , each_y_prob_one_hot_vector ): # Indicator Function if each_y_true_element == 1 : current_sample_loss += - 1 * torch . log ( each_y_prob_element ) else : current_sample_loss += 0 Bonus: If you realize this is just a vector dot product: \\(\\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix} \\cdot \\log\\left(\\begin{bmatrix} 0.09 \\\\ 0.2447 \\\\ 0.6652 \\end{bmatrix}\\right) = \\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix} \\cdot \\left(\\begin{bmatrix} -2.4076 \\\\ -1.4076 \\\\ -0.4076 \\end{bmatrix}\\right) = -2.4076\\) We now look at the second sample, index \\(i = 2\\) : We have the one-hot encoded label for second sample to be \\(\\y_2 = \\begin{bmatrix} 0 & 0 & 1 \\end{bmatrix}\\) . This means the label is a pig since the sequence is cat, dog and pig, and thus 0, 0, 1 corresponds to cat 0, dog 0 and pig 1. We have the one-hot encoded probability predicted by the model for the second sample to be \\(\\hat{\\y_2} = \\begin{bmatrix} 0.0159 & 0.1173 & 0.8868 \\end{bmatrix}\\) . This means the probability associated with this sample \\(2\\) is probability of a cat from the model is \\(1.59\\%\\) , a dog \\(11.73\\%\\) and a pig \\(88.68\\%\\) . With these information, we go on to the second outer loop's content: \\(\\sum_{c=2}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) \\(c = 2\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{2} \\in C_1}\\) : The true label for the second sample is actually the third class, and hence belongs to the \\(c=3\\) category, so our indicator function returns me a \\(0\\) . \\(\\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) : Applies the log function (natural log here) to the each probability associated with the class. So in this case, since \\(c=1\\) , we apply the log function to the first entry \\(0.0159\\) . We get \\(\\log(0.0159) = -4.1429\\) \\(c = 2\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{2} \\in C_2}\\) : The true label for the second sample is actually the third class, and hence does not belong to the \\(c=2\\) category, so our indicator function returns me a \\(0\\) . Regardless, the log of this probability is \\(\\log(0.1173) = -2.1429\\) \\(c = 3\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{2} \\in C_3}\\) : The true label for the second sample is actually the third class, so our indicator function returns me a \\(1\\) . The log of this probability is \\(\\log(0.6652) = -0.1429\\) Lastly, we sum them up and get \\(0 + 0 + (-0.1429) = -0.1429\\) , note here we only have the third entry! The first and second entries are \\(0\\) . In code, this corresponds to the following: # loop = 2 current_sample_loss = 0 for each_y_true_element , each_y_prob_element in zip ( each_y_true_one_hot_vector , each_y_prob_one_hot_vector ): # Indicator Function if each_y_true_element == 1 : current_sample_loss += - 1 * torch . log ( each_y_prob_element ) else : current_sample_loss += 0 Bonus: If you realize this is just a vector dot product: \\(\\begin{bmatrix} 0 & 0 & 1 \\end{bmatrix} \\cdot \\log\\left(\\begin{bmatrix} 0.0159 \\\\ 0.1173 \\\\ 0.8868\\end{bmatrix}\\right) = \\begin{bmatrix} 0 & 0 & 1 \\end{bmatrix} \\cdot \\left(\\begin{bmatrix} -4.1429 \\\\ -2.1429 \\\\ -0.1429 \\end{bmatrix}\\right) = -0.1429\\) To summarize the whole process: set all_samples_loss = 0 Start Outer Loop: loop over first sample i = 1 (actually index is 0 in python): set current_sample_loss = 0 loop over \\(C=3\\) classes: when \\(c = 1\\) : the loss associated is \\(-2.4076\\) . Add this to current_sample_loss . when \\(c = 2\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . when \\(c = 3\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . end first loop: update all_samples_loss by adding current_sample_loss to be all_samples_loss = -2.4076 . loop over second sample i = 2 (actually index is 1 in python): set current_sample_loss = 0 loop over \\(C=3\\) classes: when \\(c = 1\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . when \\(c = 2\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . when \\(c = 3\\) : the loss associated is \\(-0.1429\\) . Add this to current_sample_loss . end second loop: update all_samples_loss by adding current_sample_loss to be all_samples_loss = -2.4076 + (-0.1429) = -2.5505 . End all loops: You can multiply by negative \\(-1\\) to make all_samples_loss positive and get all_samples_average_loss = all_samples_loss / num_of_samples = 2.5505 / 2 = 1.2753 . def compute_categorical_cross_entropy_loss ( y_true : torch . Tensor , y_prob : torch . Tensor ) -> torch . Tensor : \"\"\"Compute the categorical cross entropy loss between two PyTorch tensors. Args: y_true (torch.Tensor): The true labels. y_prob (torch.Tensor): The predicted labels. Returns: torch.Tensor: The categorical cross entropy loss. \"\"\" all_samples_loss = 0 for each_y_true_one_hot_vector , each_y_prob_one_hot_vector in zip ( y_true , y_prob ): current_sample_loss = 0 for each_y_true_element , each_y_prob_element in zip ( each_y_true_one_hot_vector , each_y_prob_one_hot_vector ): # Indicator Function if each_y_true_element == 1 : current_sample_loss += - 1 * torch . log ( each_y_prob_element ) else : current_sample_loss += 0 all_samples_loss += current_sample_loss all_samples_average_loss = all_samples_loss / y_true . shape [ 0 ] return all_samples_average_loss","title":"Categorical Cross Entropy Loss"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss/#using-dot-product-to-calculate","text":"\\[ \\begin{aligned} \\textbf{CE}(\\ytrue, \\yprob) &= -\\dfrac{1}{N}\\sum_{i=1}^N\\sum_{c=1}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\\\ &= \\textbf{SUM}\\left[\\textbf{diag}\\left(\\ytrue \\cdot -\\log(\\yprob)^\\top\\right)\\right] \\end{aligned}\\] We can easily see \\[ \\ytrue = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\] \\[ \\textbf{z_logits} = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\end{bmatrix} \\] \\[ \\yprob = \\textbf{z_softargmax} = \\begin{bmatrix} 0.09 & 0.2447 & 0.6652 \\\\ 0.0159 & 0.1173 & 0.8668\\end{bmatrix} \\] \\[\\log(\\yprob) = \\begin{bmatrix} 2.4076 & 1.4076 & 0.4076 \\\\ 4.1429 & 2.1429 & 0.1429 \\end{bmatrix}\\] \\[ \\ytrue \\cdot -\\log(\\yprob)^\\top = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\cdot \\begin{bmatrix} 2.4076 & 4.1429 \\\\ 1.4076 & 2.1429 \\\\ 0.4076 & 0.1429 \\end{bmatrix} = \\begin{bmatrix} 2.4076 & 4.1429 \\\\ 0.4076 & 0.1429 \\end{bmatrix} \\] The matrix \\(\\ytrue \\cdot -\\log(\\yprob)^\\top\\) diagonals are what we need, where we sum them up and divide by the number of samples. That is \\(\\frac{2.4076+0.1429}{2} = \\frac{2.5505}{2} = 1.2753\\) . This makes sense because the one hot encoded \\(\\ytrue\\) vector guarantees only the indicator functions 1 gets activated and the rest gets zeroed out. Furthermore, we are only interested in the diagonal of the matrix as we are only interested in the dot product between the \\(i\\) -th row and the \\(i\\) -th column of \\(\\ytrue\\) and \\(-\\log(\\yprob)^\\top\\) respectively. def compute_categorical_cross_entropy_loss_dot_product ( y_true : torch . Tensor , y_prob : torch . Tensor ) -> torch . Tensor : \"\"\"Compute the categorical cross entropy loss between two PyTorch tensors using dot product. Args: y_true (torch.Tensor): The true labels in one-hot form. y_prob (torch.Tensor): The predicted labels in one-hot form. Returns: torch.Tensor: The categorical cross entropy loss. \"\"\" m = torch . matmul ( y_true . float (), torch . neg ( torch . log ( y_prob . float ()) . T )) all_loss_vector = torch . diagonal ( m , 0 ) all_loss_sum = torch . sum ( all_loss_vector , dim = 0 ) average_loss = all_loss_sum / y_true . shape [ 0 ] return average_loss compute_categorical_cross_entropy_loss ( y_true = y_true_ohe , y_prob = compute_softargmax ( z_logits )) tensor(1.2753) compute_categorical_cross_entropy_loss_dot_product ( y_true = y_true_ohe , y_prob = compute_softargmax ( z_logits )) tensor(1.2753) compute_softargmax ( z_logits ) tensor([[0.0900, 0.2447, 0.6652], [0.0159, 0.1173, 0.8668]]) def cross_entropy ( y_true : np . ndarray , y_pred : np . ndarray , epsilon : float = 1e-12 ): \"\"\" https://stackoverflow.com/questions/47377222/what-is-the-problem-with-my-implementation-of-the-cross-entropy-function Computes cross entropy between targets (encoded as one-hot vectors) and y_pred. Input: y_pred (N, k) ndarray y_true (N, k) ndarray Returns: scalar predictions = np.array([[0.25,0.25,0.25,0.25], [0.01,0.01,0.01,0.96]]) targets = np.array([[0,0,0,1], [0,0,0,1]]) ans = 0.71355817782 #Correct answer x = cross_entropy(predictions, targets) print(np.isclose(x,ans)) \"\"\" y_pred = np . clip ( y_pred , epsilon , 1.0 - epsilon ) # take note that y_pred is of shape 1 x n_samples as stated in our framework n_samples = y_pred . shape [ 1 ] # cross entropy function cross_entropy_function = y_true * np . log ( y_pred ) + ( 1 - y_true ) * np . log ( 1 - y_pred ) # cross entropy function here is same shape as y_true and y_pred since we are # just performing element wise operations on both of them. assert cross_entropy_function . shape == ( 1 , n_samples ) # we sum up all the loss for each individual sample total_cross_entropy_loss = - np . sum ( cross_entropy_function , axis = 1 ) assert total_cross_entropy_loss . shape == ( 1 ,) # we then average out the total loss across m samples, but we squeeze it to # make it a scalar; squeeze along axis = None since there is no column axix average_cross_entropy_loss = np . squeeze ( total_cross_entropy_loss / n_samples , axis = None ) # cross_entropy_loss = -np.sum(y_true * np.log(y_pred)) / n_samples # print(np.isclose(average_cross_entropy_loss, cross_entropy_loss)) return average_cross_entropy_loss cross_entropy ( y_true = np . asarray ([[ 0 , 1 ]]), y_pred = np . asarray ([[ 0.01 , 0.99 ]])) array(0.01005034) from math import log # calculate cross-entropy def cross_entropy ( p , q , ets = 1e-15 ): return - sum ([ p [ i ] * log ( q [ i ] + ets ) for i in range ( len ( p ))]) def binary_cross_entropy ( y_true , y_pred , eps = 1e-15 ): return - ( y_true [ 0 ] * log ( y_pred [ 0 ] + eps ) + y_true [ 1 ] * log ( y_pred [ 1 ] + eps )) # define the target distribution for two events target = [ 0.0 , 1.0 ] # define probabilities for the first event probs = [ [ 0.0 , 1.0 ], # cat is 0% and dog is 100% confidence [ 0.1 , 0.9 ], [ 0.2 , 0.8 ], [ 0.3 , 0.7 ], [ 0.4 , 0.6 ], [ 0.5 , 0.5 ], [ 0.6 , 0.4 ], [ 0.7 , 0.3 ], [ 0.8 , 0.2 ], [ 0.9 , 0.1 ], [ 1.0 , 0.0 ], ] # create probability distributions for the two events # dists = [[1.0 - p, p] for p in probs] # calculate cross-entropy for each distribution ents = [ binary_cross_entropy ( y_true = target , y_pred = d ) for d in probs ] # plot probability distribution vs cross-entropy pyplot . plot ([ p [ 1 ] for p in probs ], ents , marker = '.' ) pyplot . title ( 'Probability Distribution vs Cross-Entropy' ) #pyplot.xticks([1-p for p in probs], ['[%.1f,%.1f]'%(d[0],d[1]) for d in dists], rotation=70) pyplot . subplots_adjust ( bottom = 0.2 ) pyplot . xlabel ( 'Probability Distribution for Query Image when ground truth is 1' ) pyplot . ylabel ( 'Cross-Entropy (nats)' ) pyplot . show () analytics-vidhya-entropy-loss cross-entropy-loss-machine-learning-mastery entropy-how-decision-trees-make-decisions https://ramsane.github.io/articles/cross-entropy-explained-with-entropy-and-kl-divergence https://neptune.ai/blog/cross-entropy-loss-and-its-applications-in-deep-learning https://stackoverflow.com/questions/41990250/what-is-cross-entropy/41990932 https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e https://neptune.ai/blog/cross-entropy-loss-and-its-applications-in-deep-learning https://machinelearningmastery.com/cross-entropy-for-machine-learning/ https://d2l.ai/chapter_linear-networks/softmax-regression.html https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html#invertibility https://leimao.github.io/blog/Cross-Entropy-KL-Divergence-MLE/ https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451 https://gist.github.com/yang-zhang/217dcc6ae9171d7a46ce42e215c1fee0 https://datascience.stackexchange.com/questions/20296/cross-entropy-loss-explanation https://ramsane.github.io/articles/cross-entropy-explained-with-entropy-and-kl-divergence","title":"Using Dot Product to Calculate"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss_from_scratch/","text":"\\[ \\newcommand{\\ytrue}{\\mathbf{y_{\\textbf{true}}}} \\newcommand{\\yprob}{\\mathbf{y_{\\textbf{prob}}}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\x}{\\mathbf{x}} \\] Imports and Utils import numpy as np import torch import torch.nn.functional as F torch . __version__ '1.10.1+cpu' def torch_to_np ( tensor : torch . Tensor ) -> np . ndarray : \"\"\"Convert a PyTorch tensor to a numpy array. Args: tensor (torch.Tensor): The PyTorch tensor to convert. Returns: np.ndarray: The converted numpy array. \"\"\" return tensor . detach () . cpu () . numpy () def compare_equality_two_tensors ( tensor1 : torch . Tensor , tensor2 : torch . Tensor ) -> bool : \"\"\"Compare two PyTorch tensors for equality. Args: tensor1 (torch.Tensor): The first PyTorch tensor to compare. tensor2 (torch.Tensor): The second PyTorch tensor to compare. Returns: bool: Whether the two tensors are equal. \"\"\" if torch . all ( torch . eq ( tensor1 , tensor2 )): return True return False def compare_closeness_two_tensors ( tensor1 : torch . Tensor , tensor2 : torch . Tensor , epsilon : float , * args , ** kwargs ) -> bool : \"\"\"Compare two PyTorch tensors for closeness. Args: tensor1 (torch.Tensor): The first PyTorch tensor to compare. tensor2 (torch.Tensor): The second PyTorch tensor to compare. epsilon (float): The epsilon value to use for closeness. Returns: bool: Whether the two tensors are close. \"\"\" if torch . allclose ( tensor1 , tensor2 , atol = epsilon , * args , ** kwargs ): return True return False Cross-Entropy as a Loss Function Cross-Entropy Setup We first understand the idea and intuition of Cross-Entropy Loss on one single example. Consider a dataset of cat (class 0) and dogs (class 1) where after one hot encoding we have class 0 to be \\([1, 0]\\) and class 1 to be \\([0, 1]\\) . We first understand the idea and intuition of Cross-Entropy Loss on one single example. Consider a dataset of cat (class 0) and dogs (class 1) where after one hot encoding we have class 0 to be \\([1, 0]\\) and class 1 to be \\([0, 1]\\) . We are given the following: \\(\\mathcal{D}\\) : The dataset \\(\\mathcal{D} = (\\mathcal{X}, \\mathcal{y})\\) . \\(\\mathcal{X}\\) : This is a \\(2 \\times 3 \\times 224 \\times 224\\) tensor of the shape \\(B \\times C \\times H \\times W\\) . This can be understood as 2 RGB images of size 224. \\(\\mathcal{y}\\) : This is the corresponding ground truth one-hot encoded matrix, we have cat, dog and pig respectively (3 classes): \\( \\(\\ytrue = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\\) \\) \\(\\mathbf{x}_i\\) : We represent each \\(x_{i}\\) as the \\(i\\) -th image. This can be a random variable . Image 1 is a cat, and Image 2 is a pig. \\(\\mathbf{y}_i\\) : The corresponding label for the \\(i\\) -th sample/image, for sample 1, it is \\(\\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix}\\) . \\(P\\) : The probability distribution for the ground truth target - when it is \\([1, 0, 0]\\) , one can understand it as the distribution where cat's probability is 1, and dog's probability is 0 and pig 0. \\(Q\\) : The probability distribtion of the estimate on the \\(\\mathbf{x}_i\\) , which is say, \\([0.9, 0.01, 0.09]\\) . X = torch . zeros ( size = ( 2 , 3 , 224 , 224 ), dtype = torch . float32 ) y_true = torch . tensor ([ 0 , 2 ], dtype = torch . long ) y_true_ohe = torch . tensor ([[ 1 , 0 , 0 ], [ 0 , 0 , 1 ]], dtype = torch . long ) print ( y_true_ohe ) compare_equality_two_tensors ( y_true_ohe , torch . nn . functional . one_hot ( y_true , num_classes = 3 )) tensor([[1, 0, 0], [0, 0, 1]]) True Z Logits Then we have the following, assume a hypothesis \\(h_{\\theta}(\\mathcal{X})\\) on the dataset \\(\\mathcal{X}\\) and it outputs logits of the form, note that we are passing in inputs of shape \\((2, 3, 224, 224)\\) but after some transformations we have the logits to be shape \\((2, 3)\\) : z_logits: \\( \\(\\textbf{z_logits} = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\end{bmatrix}\\) \\) z_logits = torch . tensor ([[ 1 , 2 , 3 ], [ 2 , 4 , 6 ]], dtype = torch . float32 ) print ( z_logits ) tensor([[1., 2., 3.], [2., 4., 6.]]) Softmax 1 The softmax function takes as input a vector \\(\\mathbf{z}\\) of \\(K\\) real numbers, and normalizes it into a probability distribution consisting of \\(K\\) probabilities proportional to the exponentials of the input numbers. That is, prior to applying softmax, some vector components could be negative, or greater than one; and might not sum to 1; but after applying softmax, each component will be in the interval of 0 and 1, and the components will add up to 1, so that they can be interpreted as probabilities. Furthermore, the larger input components will correspond to larger probabilities. The standard (unit) softmax function \\[\\sigma : \\mathbb{R}^K\\to (0,1)^K\\] is defined when \\(K\\) is greater than one by the formula: \\[ \\sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}} \\ \\ \\ \\ \\text{ for } i = 1, \\dotsc , K \\text{ and } \\mathbf z=(z_1,\\dotsc,z_K) \\in \\mathbb{R}^K \\] In linear algebra notation, the \\(\\sigma\\) soft(arg)max function takes in a real vector \\(\\mathbf{z}\\) from the \\(K\\) dimensional space, indicating that the vector \\(\\mathbf{z} \\in \\mathbb{R}^K\\) has \\(K\\) number of elements, and maps to the \\(K\\) dimensional 0-1 space, which is also a vector of \\(K\\) elements; in other words, given an input vector \\(\\mathbf{z} \\in \\mathbb{R}^K\\) , the soft(arg)max maps it to \\(\\sigma(\\mathbf{z}) \\in (0,1)^K\\) . Now we break down what the soft(arg)max function actually does. It applies the standard exponential function to each element \\(z_i\\) of the input vector \\(\\mathbf{z}\\) and normalizes these values by dividing by the sum of all these exponentials; this normalization ensures that the sum of the components of the output vector \\(\\sigma(\\mathbf z)\\) is 1. After applying softmax to the logits we have: y_prob = z_softargmax: \\( \\(\\yprob = \\textbf{z_softargmax} = \\begin{bmatrix} 0.09 & 0.2447 & 0.6652 \\\\ 0.0159 & 0.1173 & 0.8668\\end{bmatrix}\\) \\) def compute_softargmax ( z : torch . Tensor ) -> torch . Tensor : \"\"\"Compute the softargmax of a PyTorch tensor. Args: z (torch.Tensor): The PyTorch tensor to compute the softargmax of. Returns: torch.Tensor: The softargmax of the PyTorch tensor. \"\"\" # the output matrix should be the same size as the input matrix z_softargmax = torch . zeros ( size = z . size (), dtype = torch . float32 ) for row_index , each_row in enumerate ( z ): denominator = torch . sum ( torch . exp ( each_row )) for element_index , each_element in enumerate ( each_row ): z_softargmax [ row_index , element_index ] = ( torch . exp ( each_element ) / denominator ) assert compare_closeness_two_tensors ( z_softargmax , torch . nn . Softmax ( dim = 1 )( z ), 1e-15 ) return z_softargmax z_softargmax = compute_softargmax ( z_logits ) print ( z_softargmax ) tensor([[0.0900, 0.2447, 0.6652], [0.0159, 0.1173, 0.8668]]) Categorical Cross Entropy Loss We will start with this because the Binary Cross Entropy Loss is merely a special case of this. Finding the full compact formula for this took me a while since most tutorials cover the binary case. Given \\(N\\) samples, and \\(C\\) classes, the Categorical Cross Entropy Loss is the average loss across \\(N\\) samples, given by: \\[\\textbf{CE}(\\ytrue, \\yprob) = -\\dfrac{1}{N}\\sum_{i=1}^N\\sum_{c=1}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\] where The outer loop \\(i\\) iterates over \\(N\\) observations/samples. The inner loop \\(c\\) iterates over \\(C\\) classes. \\(\\y_i\\) represents the true label (in this formula it should be one-hot encoded) of the \\(i\\) -th sample. \\(\\mathbb{1}_{y_{i} \\in C_c}\\) is an indicator function, simply put, for sample \\(i\\) , if the true label \\(\\y_i\\) belongs to the \\(c\\) -th category, then we assign a \\(1\\) , else \\(0\\) . We can see it with an example later. \\(\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) means the probability predicted by the model for the \\(i\\) -th observation that belongs to the \\(c\\) -th class category. \\[ \\ytrue = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\] \\[ \\textbf{z_logits} = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\end{bmatrix} \\] \\[ \\yprob = \\textbf{z_softargmax} = \\begin{bmatrix} 0.09 & 0.2447 & 0.6652 \\\\ 0.0159 & 0.1173 & 0.8668\\end{bmatrix} \\] We first look at the first sample, index \\(i = 1\\) : We have the one-hot encoded label for first sample to be \\(\\y_1 = \\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix}\\) . This means the label is a cat since the sequence is cat, dog and pig, and thus 1, 0, 0 corresponds to cat 1, dog 0 and pig 0. We have the one-hot encoded probability predicted by the model for the first sample to be \\(\\hat{\\y_1} = \\begin{bmatrix} 0.09 & 0.2447 & 0.6652 \\end{bmatrix}\\) . This means the probability associated with this sample \\(1\\) is probability of a cat from the model is \\(9\\%\\) , a dog \\(24.47\\%\\) and a pig \\(66.52\\%\\) . With these information, we go on to the first outer loop's content: \\(\\sum_{c=1}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) We are looping through the classes, which in this case is loop from \\(c=1\\) to \\(c=3\\) since \\(C=3\\) (3 classes). \\(c = 1\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{1} \\in C_1}\\) : The true label for the first sample is actually the first class, and hence belongs to the \\(c=1\\) category, so our indicator function returns me a \\(1\\) . \\(\\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right) = \\log\\left(p_{\\textbf{model}}[\\y_1 \\in C_1]\\right)\\) : Applies the log function (natural log here) to the each probability associated with the class. So in this case, since \\(c=1\\) , we apply the log function to the first entry \\(0.09\\) . We get \\(\\log(0.09) = -2.4079\\) \\(c = 2\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{1} \\in C_2}\\) : The true label for the first sample is actually the first class, and hence does not belong to the \\(c=2\\) category, so our indicator function returns me a \\(0\\) . Regardless, the log of this probability is \\(\\log(0.2447) = -1.4076\\) \\(c = 3\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{1} \\in C_3}\\) : The true label for the first sample is actually the first class, and hence does not belong to the \\(c=3\\) category, so our indicator function returns me a \\(0\\) . Regardless, the log of this probability is \\(\\log(0.6652) = -0.4076\\) Lastly, we sum them up and get \\(-2.4076 + 0 + 0 = -2.4076\\) , note here we only have the first entry! The second and third are \\(0\\) . In code, this corresponds to the following: # loop = 1 current_sample_loss = 0 for each_y_true_element , each_y_prob_element in zip ( each_y_true_one_hot_vector , each_y_prob_one_hot_vector ): # Indicator Function if each_y_true_element == 1 : current_sample_loss += - 1 * torch . log ( each_y_prob_element ) else : current_sample_loss += 0 Bonus: If you realize this is just a vector dot product: \\(\\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix} \\cdot \\log\\left(\\begin{bmatrix} 0.09 \\\\ 0.2447 \\\\ 0.6652 \\end{bmatrix}\\right) = \\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix} \\cdot \\left(\\begin{bmatrix} -2.4076 \\\\ -1.4076 \\\\ -0.4076 \\end{bmatrix}\\right) = -2.4076\\) We now look at the second sample, index \\(i = 2\\) : We have the one-hot encoded label for second sample to be \\(\\y_2 = \\begin{bmatrix} 0 & 0 & 1 \\end{bmatrix}\\) . This means the label is a pig since the sequence is cat, dog and pig, and thus 0, 0, 1 corresponds to cat 0, dog 0 and pig 1. We have the one-hot encoded probability predicted by the model for the second sample to be \\(\\hat{\\y_2} = \\begin{bmatrix} 0.0159 & 0.1173 & 0.8868 \\end{bmatrix}\\) . This means the probability associated with this sample \\(2\\) is probability of a cat from the model is \\(1.59\\%\\) , a dog \\(11.73\\%\\) and a pig \\(88.68\\%\\) . With these information, we go on to the second outer loop's content: \\(\\sum_{c=2}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) \\(c = 2\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{2} \\in C_1}\\) : The true label for the second sample is actually the third class, and hence belongs to the \\(c=3\\) category, so our indicator function returns me a \\(0\\) . \\(\\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) : Applies the log function (natural log here) to the each probability associated with the class. So in this case, since \\(c=1\\) , we apply the log function to the first entry \\(0.0159\\) . We get \\(\\log(0.0159) = -4.1429\\) \\(c = 2\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{2} \\in C_2}\\) : The true label for the second sample is actually the third class, and hence does not belong to the \\(c=2\\) category, so our indicator function returns me a \\(0\\) . Regardless, the log of this probability is \\(\\log(0.1173) = -2.1429\\) \\(c = 3\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{2} \\in C_3}\\) : The true label for the second sample is actually the third class, so our indicator function returns me a \\(1\\) . The log of this probability is \\(\\log(0.6652) = -0.1429\\) Lastly, we sum them up and get \\(0 + 0 + (-0.1429) = -0.1429\\) , note here we only have the third entry! The first and second entries are \\(0\\) . In code, this corresponds to the following: # loop = 2 current_sample_loss = 0 for each_y_true_element , each_y_prob_element in zip ( each_y_true_one_hot_vector , each_y_prob_one_hot_vector ): # Indicator Function if each_y_true_element == 1 : current_sample_loss += - 1 * torch . log ( each_y_prob_element ) else : current_sample_loss += 0 Bonus: If you realize this is just a vector dot product: \\(\\begin{bmatrix} 0 & 0 & 1 \\end{bmatrix} \\cdot \\log\\left(\\begin{bmatrix} 0.0159 \\\\ 0.1173 \\\\ 0.8868\\end{bmatrix}\\right) = \\begin{bmatrix} 0 & 0 & 1 \\end{bmatrix} \\cdot \\left(\\begin{bmatrix} -4.1429 \\\\ -2.1429 \\\\ -0.1429 \\end{bmatrix}\\right) = -0.1429\\) To summarize the whole process: set all_samples_loss = 0 Start Outer Loop: loop over first sample i = 1 (actually index is 0 in python): set current_sample_loss = 0 loop over \\(C=3\\) classes: when \\(c = 1\\) : the loss associated is \\(-2.4076\\) . Add this to current_sample_loss . when \\(c = 2\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . when \\(c = 3\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . end first loop: update all_samples_loss by adding current_sample_loss to be all_samples_loss = -2.4076 . loop over second sample i = 2 (actually index is 1 in python): set current_sample_loss = 0 loop over \\(C=3\\) classes: when \\(c = 1\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . when \\(c = 2\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . when \\(c = 3\\) : the loss associated is \\(-0.1429\\) . Add this to current_sample_loss . end second loop: update all_samples_loss by adding current_sample_loss to be all_samples_loss = -2.4076 + (-0.1429) = -2.5505 . End all loops: You can multiply by negative \\(-1\\) to make all_samples_loss positive and get all_samples_average_loss = all_samples_loss / num_of_samples = 2.5505 / 2 = 1.2753 . def compute_categorical_cross_entropy_loss ( y_true : torch . Tensor , y_prob : torch . Tensor ) -> torch . Tensor : \"\"\"Compute the categorical cross entropy loss between two PyTorch tensors. Args: y_true (torch.Tensor): The true labels. y_prob (torch.Tensor): The predicted labels. Returns: torch.Tensor: The categorical cross entropy loss. \"\"\" all_samples_loss = 0 for each_y_true_one_hot_vector , each_y_prob_one_hot_vector in zip ( y_true , y_prob ): current_sample_loss = 0 for each_y_true_element , each_y_prob_element in zip ( each_y_true_one_hot_vector , each_y_prob_one_hot_vector ): # in case y_prob has elements that is 0 or very small, then torch.log(0) might go to -inf each_y_prob_element = torch . clamp ( each_y_prob_element , min = 1.0e-20 , max = 1.0 - 1.0e-20 , out = None ) # Indicator Function if each_y_true_element == 1 : current_sample_loss += - 1 * torch . log ( each_y_prob_element ) else : current_sample_loss += 0 all_samples_loss += current_sample_loss all_samples_average_loss = all_samples_loss / y_true . shape [ 0 ] return all_samples_average_loss Using Dot Product to Calculate \\[ \\begin{aligned} \\textbf{CE}(\\ytrue, \\yprob) &= -\\dfrac{1}{N}\\sum_{i=1}^N\\sum_{c=1}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\\\ &= \\textbf{SUM}\\left[\\textbf{diag}\\left(\\ytrue \\cdot -\\log(\\yprob)^\\top\\right)\\right] \\end{aligned}\\] We can easily see \\[ \\ytrue = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\] \\[ \\textbf{z_logits} = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\end{bmatrix} \\] \\[ \\yprob = \\textbf{z_softargmax} = \\begin{bmatrix} 0.09 & 0.2447 & 0.6652 \\\\ 0.0159 & 0.1173 & 0.8668\\end{bmatrix} \\] \\[\\log(\\yprob) = \\begin{bmatrix} 2.4076 & 1.4076 & 0.4076 \\\\ 4.1429 & 2.1429 & 0.1429 \\end{bmatrix}\\] \\[ \\ytrue \\cdot -\\log(\\yprob)^\\top = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\cdot \\begin{bmatrix} 2.4076 & 4.1429 \\\\ 1.4076 & 2.1429 \\\\ 0.4076 & 0.1429 \\end{bmatrix} = \\begin{bmatrix} 2.4076 & 4.1429 \\\\ 0.4076 & 0.1429 \\end{bmatrix} \\] The matrix \\(\\ytrue \\cdot -\\log(\\yprob)^\\top\\) diagonals are what we need, where we sum them up and divide by the number of samples. That is \\(\\frac{2.4076+0.1429}{2} = \\frac{2.5505}{2} = 1.2753\\) . This makes sense because the one hot encoded \\(\\ytrue\\) vector guarantees only the indicator functions 1 gets activated and the rest gets zeroed out. Furthermore, we are only interested in the diagonal of the matrix as we are only interested in the dot product between the \\(i\\) -th row and the \\(i\\) -th column of \\(\\ytrue\\) and \\(-\\log(\\yprob)^\\top\\) respectively. def compute_categorical_cross_entropy_loss_dot_product ( y_true : torch . Tensor , y_prob : torch . Tensor ) -> torch . Tensor : \"\"\"Compute the categorical cross entropy loss between two PyTorch tensors using dot product. Args: y_true (torch.Tensor): The true labels in one-hot form. y_prob (torch.Tensor): The predicted labels in one-hot form. Returns: torch.Tensor: The categorical cross entropy loss. \"\"\" m = torch . matmul ( y_true . float (), torch . neg ( torch . log ( y_prob . float ()) . T )) all_loss_vector = torch . diagonal ( m , 0 ) all_loss_sum = torch . sum ( all_loss_vector , dim = 0 ) average_loss = all_loss_sum / y_true . shape [ 0 ] return average_loss compute_categorical_cross_entropy_loss ( y_true = y_true_ohe , y_prob = compute_softargmax ( z_logits )) tensor(1.2753) compute_categorical_cross_entropy_loss_dot_product ( y_true = y_true_ohe , y_prob = compute_softargmax ( z_logits )) tensor(1.2753) https://en.wikipedia.org/wiki/Softmax_function \u21a9","title":"Cross Entropy Loss"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss_from_scratch/#imports-and-utils","text":"import numpy as np import torch import torch.nn.functional as F torch . __version__ '1.10.1+cpu' def torch_to_np ( tensor : torch . Tensor ) -> np . ndarray : \"\"\"Convert a PyTorch tensor to a numpy array. Args: tensor (torch.Tensor): The PyTorch tensor to convert. Returns: np.ndarray: The converted numpy array. \"\"\" return tensor . detach () . cpu () . numpy () def compare_equality_two_tensors ( tensor1 : torch . Tensor , tensor2 : torch . Tensor ) -> bool : \"\"\"Compare two PyTorch tensors for equality. Args: tensor1 (torch.Tensor): The first PyTorch tensor to compare. tensor2 (torch.Tensor): The second PyTorch tensor to compare. Returns: bool: Whether the two tensors are equal. \"\"\" if torch . all ( torch . eq ( tensor1 , tensor2 )): return True return False def compare_closeness_two_tensors ( tensor1 : torch . Tensor , tensor2 : torch . Tensor , epsilon : float , * args , ** kwargs ) -> bool : \"\"\"Compare two PyTorch tensors for closeness. Args: tensor1 (torch.Tensor): The first PyTorch tensor to compare. tensor2 (torch.Tensor): The second PyTorch tensor to compare. epsilon (float): The epsilon value to use for closeness. Returns: bool: Whether the two tensors are close. \"\"\" if torch . allclose ( tensor1 , tensor2 , atol = epsilon , * args , ** kwargs ): return True return False","title":"Imports and Utils"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss_from_scratch/#cross-entropy-as-a-loss-function","text":"","title":"Cross-Entropy as a Loss Function"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss_from_scratch/#cross-entropy-setup","text":"We first understand the idea and intuition of Cross-Entropy Loss on one single example. Consider a dataset of cat (class 0) and dogs (class 1) where after one hot encoding we have class 0 to be \\([1, 0]\\) and class 1 to be \\([0, 1]\\) . We first understand the idea and intuition of Cross-Entropy Loss on one single example. Consider a dataset of cat (class 0) and dogs (class 1) where after one hot encoding we have class 0 to be \\([1, 0]\\) and class 1 to be \\([0, 1]\\) . We are given the following: \\(\\mathcal{D}\\) : The dataset \\(\\mathcal{D} = (\\mathcal{X}, \\mathcal{y})\\) . \\(\\mathcal{X}\\) : This is a \\(2 \\times 3 \\times 224 \\times 224\\) tensor of the shape \\(B \\times C \\times H \\times W\\) . This can be understood as 2 RGB images of size 224. \\(\\mathcal{y}\\) : This is the corresponding ground truth one-hot encoded matrix, we have cat, dog and pig respectively (3 classes): \\( \\(\\ytrue = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\\) \\) \\(\\mathbf{x}_i\\) : We represent each \\(x_{i}\\) as the \\(i\\) -th image. This can be a random variable . Image 1 is a cat, and Image 2 is a pig. \\(\\mathbf{y}_i\\) : The corresponding label for the \\(i\\) -th sample/image, for sample 1, it is \\(\\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix}\\) . \\(P\\) : The probability distribution for the ground truth target - when it is \\([1, 0, 0]\\) , one can understand it as the distribution where cat's probability is 1, and dog's probability is 0 and pig 0. \\(Q\\) : The probability distribtion of the estimate on the \\(\\mathbf{x}_i\\) , which is say, \\([0.9, 0.01, 0.09]\\) . X = torch . zeros ( size = ( 2 , 3 , 224 , 224 ), dtype = torch . float32 ) y_true = torch . tensor ([ 0 , 2 ], dtype = torch . long ) y_true_ohe = torch . tensor ([[ 1 , 0 , 0 ], [ 0 , 0 , 1 ]], dtype = torch . long ) print ( y_true_ohe ) compare_equality_two_tensors ( y_true_ohe , torch . nn . functional . one_hot ( y_true , num_classes = 3 )) tensor([[1, 0, 0], [0, 0, 1]]) True","title":"Cross-Entropy Setup"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss_from_scratch/#z-logits","text":"Then we have the following, assume a hypothesis \\(h_{\\theta}(\\mathcal{X})\\) on the dataset \\(\\mathcal{X}\\) and it outputs logits of the form, note that we are passing in inputs of shape \\((2, 3, 224, 224)\\) but after some transformations we have the logits to be shape \\((2, 3)\\) : z_logits: \\( \\(\\textbf{z_logits} = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\end{bmatrix}\\) \\) z_logits = torch . tensor ([[ 1 , 2 , 3 ], [ 2 , 4 , 6 ]], dtype = torch . float32 ) print ( z_logits ) tensor([[1., 2., 3.], [2., 4., 6.]])","title":"Z Logits"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss_from_scratch/#softmax1","text":"The softmax function takes as input a vector \\(\\mathbf{z}\\) of \\(K\\) real numbers, and normalizes it into a probability distribution consisting of \\(K\\) probabilities proportional to the exponentials of the input numbers. That is, prior to applying softmax, some vector components could be negative, or greater than one; and might not sum to 1; but after applying softmax, each component will be in the interval of 0 and 1, and the components will add up to 1, so that they can be interpreted as probabilities. Furthermore, the larger input components will correspond to larger probabilities. The standard (unit) softmax function \\[\\sigma : \\mathbb{R}^K\\to (0,1)^K\\] is defined when \\(K\\) is greater than one by the formula: \\[ \\sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}} \\ \\ \\ \\ \\text{ for } i = 1, \\dotsc , K \\text{ and } \\mathbf z=(z_1,\\dotsc,z_K) \\in \\mathbb{R}^K \\] In linear algebra notation, the \\(\\sigma\\) soft(arg)max function takes in a real vector \\(\\mathbf{z}\\) from the \\(K\\) dimensional space, indicating that the vector \\(\\mathbf{z} \\in \\mathbb{R}^K\\) has \\(K\\) number of elements, and maps to the \\(K\\) dimensional 0-1 space, which is also a vector of \\(K\\) elements; in other words, given an input vector \\(\\mathbf{z} \\in \\mathbb{R}^K\\) , the soft(arg)max maps it to \\(\\sigma(\\mathbf{z}) \\in (0,1)^K\\) . Now we break down what the soft(arg)max function actually does. It applies the standard exponential function to each element \\(z_i\\) of the input vector \\(\\mathbf{z}\\) and normalizes these values by dividing by the sum of all these exponentials; this normalization ensures that the sum of the components of the output vector \\(\\sigma(\\mathbf z)\\) is 1. After applying softmax to the logits we have: y_prob = z_softargmax: \\( \\(\\yprob = \\textbf{z_softargmax} = \\begin{bmatrix} 0.09 & 0.2447 & 0.6652 \\\\ 0.0159 & 0.1173 & 0.8668\\end{bmatrix}\\) \\) def compute_softargmax ( z : torch . Tensor ) -> torch . Tensor : \"\"\"Compute the softargmax of a PyTorch tensor. Args: z (torch.Tensor): The PyTorch tensor to compute the softargmax of. Returns: torch.Tensor: The softargmax of the PyTorch tensor. \"\"\" # the output matrix should be the same size as the input matrix z_softargmax = torch . zeros ( size = z . size (), dtype = torch . float32 ) for row_index , each_row in enumerate ( z ): denominator = torch . sum ( torch . exp ( each_row )) for element_index , each_element in enumerate ( each_row ): z_softargmax [ row_index , element_index ] = ( torch . exp ( each_element ) / denominator ) assert compare_closeness_two_tensors ( z_softargmax , torch . nn . Softmax ( dim = 1 )( z ), 1e-15 ) return z_softargmax z_softargmax = compute_softargmax ( z_logits ) print ( z_softargmax ) tensor([[0.0900, 0.2447, 0.6652], [0.0159, 0.1173, 0.8668]])","title":"Softmax1"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss_from_scratch/#categorical-cross-entropy-loss","text":"We will start with this because the Binary Cross Entropy Loss is merely a special case of this. Finding the full compact formula for this took me a while since most tutorials cover the binary case. Given \\(N\\) samples, and \\(C\\) classes, the Categorical Cross Entropy Loss is the average loss across \\(N\\) samples, given by: \\[\\textbf{CE}(\\ytrue, \\yprob) = -\\dfrac{1}{N}\\sum_{i=1}^N\\sum_{c=1}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\] where The outer loop \\(i\\) iterates over \\(N\\) observations/samples. The inner loop \\(c\\) iterates over \\(C\\) classes. \\(\\y_i\\) represents the true label (in this formula it should be one-hot encoded) of the \\(i\\) -th sample. \\(\\mathbb{1}_{y_{i} \\in C_c}\\) is an indicator function, simply put, for sample \\(i\\) , if the true label \\(\\y_i\\) belongs to the \\(c\\) -th category, then we assign a \\(1\\) , else \\(0\\) . We can see it with an example later. \\(\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) means the probability predicted by the model for the \\(i\\) -th observation that belongs to the \\(c\\) -th class category. \\[ \\ytrue = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\] \\[ \\textbf{z_logits} = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\end{bmatrix} \\] \\[ \\yprob = \\textbf{z_softargmax} = \\begin{bmatrix} 0.09 & 0.2447 & 0.6652 \\\\ 0.0159 & 0.1173 & 0.8668\\end{bmatrix} \\] We first look at the first sample, index \\(i = 1\\) : We have the one-hot encoded label for first sample to be \\(\\y_1 = \\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix}\\) . This means the label is a cat since the sequence is cat, dog and pig, and thus 1, 0, 0 corresponds to cat 1, dog 0 and pig 0. We have the one-hot encoded probability predicted by the model for the first sample to be \\(\\hat{\\y_1} = \\begin{bmatrix} 0.09 & 0.2447 & 0.6652 \\end{bmatrix}\\) . This means the probability associated with this sample \\(1\\) is probability of a cat from the model is \\(9\\%\\) , a dog \\(24.47\\%\\) and a pig \\(66.52\\%\\) . With these information, we go on to the first outer loop's content: \\(\\sum_{c=1}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) We are looping through the classes, which in this case is loop from \\(c=1\\) to \\(c=3\\) since \\(C=3\\) (3 classes). \\(c = 1\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{1} \\in C_1}\\) : The true label for the first sample is actually the first class, and hence belongs to the \\(c=1\\) category, so our indicator function returns me a \\(1\\) . \\(\\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right) = \\log\\left(p_{\\textbf{model}}[\\y_1 \\in C_1]\\right)\\) : Applies the log function (natural log here) to the each probability associated with the class. So in this case, since \\(c=1\\) , we apply the log function to the first entry \\(0.09\\) . We get \\(\\log(0.09) = -2.4079\\) \\(c = 2\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{1} \\in C_2}\\) : The true label for the first sample is actually the first class, and hence does not belong to the \\(c=2\\) category, so our indicator function returns me a \\(0\\) . Regardless, the log of this probability is \\(\\log(0.2447) = -1.4076\\) \\(c = 3\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{1} \\in C_3}\\) : The true label for the first sample is actually the first class, and hence does not belong to the \\(c=3\\) category, so our indicator function returns me a \\(0\\) . Regardless, the log of this probability is \\(\\log(0.6652) = -0.4076\\) Lastly, we sum them up and get \\(-2.4076 + 0 + 0 = -2.4076\\) , note here we only have the first entry! The second and third are \\(0\\) . In code, this corresponds to the following: # loop = 1 current_sample_loss = 0 for each_y_true_element , each_y_prob_element in zip ( each_y_true_one_hot_vector , each_y_prob_one_hot_vector ): # Indicator Function if each_y_true_element == 1 : current_sample_loss += - 1 * torch . log ( each_y_prob_element ) else : current_sample_loss += 0 Bonus: If you realize this is just a vector dot product: \\(\\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix} \\cdot \\log\\left(\\begin{bmatrix} 0.09 \\\\ 0.2447 \\\\ 0.6652 \\end{bmatrix}\\right) = \\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix} \\cdot \\left(\\begin{bmatrix} -2.4076 \\\\ -1.4076 \\\\ -0.4076 \\end{bmatrix}\\right) = -2.4076\\) We now look at the second sample, index \\(i = 2\\) : We have the one-hot encoded label for second sample to be \\(\\y_2 = \\begin{bmatrix} 0 & 0 & 1 \\end{bmatrix}\\) . This means the label is a pig since the sequence is cat, dog and pig, and thus 0, 0, 1 corresponds to cat 0, dog 0 and pig 1. We have the one-hot encoded probability predicted by the model for the second sample to be \\(\\hat{\\y_2} = \\begin{bmatrix} 0.0159 & 0.1173 & 0.8868 \\end{bmatrix}\\) . This means the probability associated with this sample \\(2\\) is probability of a cat from the model is \\(1.59\\%\\) , a dog \\(11.73\\%\\) and a pig \\(88.68\\%\\) . With these information, we go on to the second outer loop's content: \\(\\sum_{c=2}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) \\(c = 2\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{2} \\in C_1}\\) : The true label for the second sample is actually the third class, and hence belongs to the \\(c=3\\) category, so our indicator function returns me a \\(0\\) . \\(\\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\) : Applies the log function (natural log here) to the each probability associated with the class. So in this case, since \\(c=1\\) , we apply the log function to the first entry \\(0.0159\\) . We get \\(\\log(0.0159) = -4.1429\\) \\(c = 2\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{2} \\in C_2}\\) : The true label for the second sample is actually the third class, and hence does not belong to the \\(c=2\\) category, so our indicator function returns me a \\(0\\) . Regardless, the log of this probability is \\(\\log(0.1173) = -2.1429\\) \\(c = 3\\) : \\(\\mathbb{1}_{\\y_{i} \\in C_c} = \\mathbb{1}_{\\y_{2} \\in C_3}\\) : The true label for the second sample is actually the third class, so our indicator function returns me a \\(1\\) . The log of this probability is \\(\\log(0.6652) = -0.1429\\) Lastly, we sum them up and get \\(0 + 0 + (-0.1429) = -0.1429\\) , note here we only have the third entry! The first and second entries are \\(0\\) . In code, this corresponds to the following: # loop = 2 current_sample_loss = 0 for each_y_true_element , each_y_prob_element in zip ( each_y_true_one_hot_vector , each_y_prob_one_hot_vector ): # Indicator Function if each_y_true_element == 1 : current_sample_loss += - 1 * torch . log ( each_y_prob_element ) else : current_sample_loss += 0 Bonus: If you realize this is just a vector dot product: \\(\\begin{bmatrix} 0 & 0 & 1 \\end{bmatrix} \\cdot \\log\\left(\\begin{bmatrix} 0.0159 \\\\ 0.1173 \\\\ 0.8868\\end{bmatrix}\\right) = \\begin{bmatrix} 0 & 0 & 1 \\end{bmatrix} \\cdot \\left(\\begin{bmatrix} -4.1429 \\\\ -2.1429 \\\\ -0.1429 \\end{bmatrix}\\right) = -0.1429\\) To summarize the whole process: set all_samples_loss = 0 Start Outer Loop: loop over first sample i = 1 (actually index is 0 in python): set current_sample_loss = 0 loop over \\(C=3\\) classes: when \\(c = 1\\) : the loss associated is \\(-2.4076\\) . Add this to current_sample_loss . when \\(c = 2\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . when \\(c = 3\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . end first loop: update all_samples_loss by adding current_sample_loss to be all_samples_loss = -2.4076 . loop over second sample i = 2 (actually index is 1 in python): set current_sample_loss = 0 loop over \\(C=3\\) classes: when \\(c = 1\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . when \\(c = 2\\) : the loss associated is \\(0\\) . Add this to current_sample_loss . when \\(c = 3\\) : the loss associated is \\(-0.1429\\) . Add this to current_sample_loss . end second loop: update all_samples_loss by adding current_sample_loss to be all_samples_loss = -2.4076 + (-0.1429) = -2.5505 . End all loops: You can multiply by negative \\(-1\\) to make all_samples_loss positive and get all_samples_average_loss = all_samples_loss / num_of_samples = 2.5505 / 2 = 1.2753 . def compute_categorical_cross_entropy_loss ( y_true : torch . Tensor , y_prob : torch . Tensor ) -> torch . Tensor : \"\"\"Compute the categorical cross entropy loss between two PyTorch tensors. Args: y_true (torch.Tensor): The true labels. y_prob (torch.Tensor): The predicted labels. Returns: torch.Tensor: The categorical cross entropy loss. \"\"\" all_samples_loss = 0 for each_y_true_one_hot_vector , each_y_prob_one_hot_vector in zip ( y_true , y_prob ): current_sample_loss = 0 for each_y_true_element , each_y_prob_element in zip ( each_y_true_one_hot_vector , each_y_prob_one_hot_vector ): # in case y_prob has elements that is 0 or very small, then torch.log(0) might go to -inf each_y_prob_element = torch . clamp ( each_y_prob_element , min = 1.0e-20 , max = 1.0 - 1.0e-20 , out = None ) # Indicator Function if each_y_true_element == 1 : current_sample_loss += - 1 * torch . log ( each_y_prob_element ) else : current_sample_loss += 0 all_samples_loss += current_sample_loss all_samples_average_loss = all_samples_loss / y_true . shape [ 0 ] return all_samples_average_loss","title":"Categorical Cross Entropy Loss"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss_from_scratch/#using-dot-product-to-calculate","text":"\\[ \\begin{aligned} \\textbf{CE}(\\ytrue, \\yprob) &= -\\dfrac{1}{N}\\sum_{i=1}^N\\sum_{c=1}^C \\mathbb{1}_{\\y_{i} \\in C_c} \\log\\left(p_{\\textbf{model}}[\\y_i \\in C_c]\\right)\\\\ &= \\textbf{SUM}\\left[\\textbf{diag}\\left(\\ytrue \\cdot -\\log(\\yprob)^\\top\\right)\\right] \\end{aligned}\\] We can easily see \\[ \\ytrue = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\] \\[ \\textbf{z_logits} = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\end{bmatrix} \\] \\[ \\yprob = \\textbf{z_softargmax} = \\begin{bmatrix} 0.09 & 0.2447 & 0.6652 \\\\ 0.0159 & 0.1173 & 0.8668\\end{bmatrix} \\] \\[\\log(\\yprob) = \\begin{bmatrix} 2.4076 & 1.4076 & 0.4076 \\\\ 4.1429 & 2.1429 & 0.1429 \\end{bmatrix}\\] \\[ \\ytrue \\cdot -\\log(\\yprob)^\\top = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\cdot \\begin{bmatrix} 2.4076 & 4.1429 \\\\ 1.4076 & 2.1429 \\\\ 0.4076 & 0.1429 \\end{bmatrix} = \\begin{bmatrix} 2.4076 & 4.1429 \\\\ 0.4076 & 0.1429 \\end{bmatrix} \\] The matrix \\(\\ytrue \\cdot -\\log(\\yprob)^\\top\\) diagonals are what we need, where we sum them up and divide by the number of samples. That is \\(\\frac{2.4076+0.1429}{2} = \\frac{2.5505}{2} = 1.2753\\) . This makes sense because the one hot encoded \\(\\ytrue\\) vector guarantees only the indicator functions 1 gets activated and the rest gets zeroed out. Furthermore, we are only interested in the diagonal of the matrix as we are only interested in the dot product between the \\(i\\) -th row and the \\(i\\) -th column of \\(\\ytrue\\) and \\(-\\log(\\yprob)^\\top\\) respectively. def compute_categorical_cross_entropy_loss_dot_product ( y_true : torch . Tensor , y_prob : torch . Tensor ) -> torch . Tensor : \"\"\"Compute the categorical cross entropy loss between two PyTorch tensors using dot product. Args: y_true (torch.Tensor): The true labels in one-hot form. y_prob (torch.Tensor): The predicted labels in one-hot form. Returns: torch.Tensor: The categorical cross entropy loss. \"\"\" m = torch . matmul ( y_true . float (), torch . neg ( torch . log ( y_prob . float ()) . T )) all_loss_vector = torch . diagonal ( m , 0 ) all_loss_sum = torch . sum ( all_loss_vector , dim = 0 ) average_loss = all_loss_sum / y_true . shape [ 0 ] return average_loss compute_categorical_cross_entropy_loss ( y_true = y_true_ohe , y_prob = compute_softargmax ( z_logits )) tensor(1.2753) compute_categorical_cross_entropy_loss_dot_product ( y_true = y_true_ohe , y_prob = compute_softargmax ( z_logits )) tensor(1.2753) https://en.wikipedia.org/wiki/Softmax_function \u21a9","title":"Using Dot Product to Calculate"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/entropy_and_information_gain/","text":"Introduction Entropy will appear in two areas of Machine Learning: Entropy and Information Gain in Decision Trees. Entropy as a Loss Function Entropy in Decision Trees Please read entropy-how-decision-trees-make-decisions first. If you are like me, who touched on Entropy as a loss function, then it is slightly confusing for the entropy here. Entropy is a measure of disorder and chaos. Definition (Entropy) In information theory , the entropy of a random variable is the average level of \\\"information\\\", \\\"surprise\\\", or \\\"uncertainty\\\" inherent to the variable\\'s possible outcomes. Given a discrete random variable \\(Y\\) , with possible outcomes \\(y_1, ..., y_n\\) , which occur with probability \\[\\mathrm{P}(Y=y_1), ..., \\mathrm{P}(Y=y_n)\\] the entropy of \\(Y\\) is formally defined as: \\[\\mathrm{H}(Y)= -\\sum _{i=1}^{n}{\\mathrm{P}(y_{i})\\log \\mathrm{P}(y_{i})}\\] where \\(\\Sigma\\) denotes the sum over the variable\\'s possible values. The choice of base for \\(\\log\\) , the logarithm , varies for different applications. Base 2 gives the unit of bits (or \\\" shannons \\\"), while base e gives \\\"natural units\\\" nat , and base 10 gives units of \\\"dits\\\", \\\"bans\\\", or \\\" hartleys \\\". An equivalent definition of entropy is the expected value of the self-information of a variable. Intuition (Entropy and Information Theory) From Wikipedia: Consider making my own example to reinforce concept. Intuitively, if we are predicting an image of a cat vs dog, and we pass in a query image \\(x_{q}\\) of pixels, we expect the \\(y_{q}\\) to take on class 0 or 1. However, taking a step back, in ML setting, we often have a calibrated probability \\(y_{q}\\) before the classifier tells us whether it is a 0 or 1 based on a decision (say if probability more than 0.5, then its 1, and 0 otherwwise). This probability is a soft label and in our scenario, should output an array y_q = [ probability of x_q being a cat 0 , probability of x_q being a dog 1 ] = [ 0.5 , 0.5 ] In this case, we can say that our prediction \\(Y\\) is a DISCRETE random variable with probability distribution \\(p\\) , and thus the entropy of \\(Y\\) can be formally defined as: \\[\\mathrm{H}(Y)= -\\sum _{i=1}^{n}{\\mathrm{P}(y_{i})\\log \\mathrm{P}(y_{i})}\\] where we are summing over all values that \\(Y\\) took on. In this case, it is entropy of y_q = - ( 0.5 * lg 0.5 + 0.5 * lg 0.5 ) = - ( - 0.5 + - 0.5 ) = 1 Note we are using lg base 2 here and so our maximum entropy is 1. Entropy is maximum if each random variable is equi-probable. Entropy Loss is usually used as a loss function in ML as it penalizes \"wrong predictions\" and favours confident predictions. In the image below, let's say \\(Y\\) is a random variable taking on a uniform distribution, for example, if we are predicting a cat or dog image, where \\(y\\) is the probability output from a classifier, taking on 0 to 1. If we were to assume \\(y \\sim U[0,1]\\) , then it follows that \\(H(y) = 1\\) as \\(y\\) will always be of \\([0.5, 0.5]\\) in prediction. Let us now see two different cases if \\(y\\) follows a gaussian distribution, \\(y_{1} \\sim \\mathcal{N_1}[0,1]\\) and \\(y_{2} \\sim \\mathcal{N_2}[0,1]\\) Visually, we can see that the second gaussian has a higher peak than the first, hence we can deduce that \\(H(y_{2}) < H(y_{1})\\) because since the higher peak suggest that the points of \\(y_{2}\\) are tightly spread around each other, and since the points are close, there is less penalty in the \\(\\log\\) . Even more geometrically, if we take \"uniform distribution\" as the one with highest entropy, we can say that as the gaussian curve smoothes out -> becoming more uniform, then the entropy rises. Fig; By Hongnan G. Python Code (Entropy in Information Gain) from math import log2 from typing import * from typing import List import numpy as np import scipy Given a list of labels, (i.e. ground truth labels of 5 images of cats and dogs): Ground Truth Labels: ['dog', 'dog', 'cat', 'cat', 'dog'] = [0, 0, 1, 1, 0] Class Probabilities: Note carefully in this entropy context, this class probabilities IS NOT the softmax activation, instead, it is just the FREQUENCY of each class. [3/5, 2/5] where dog has frequency of \\(\\frac{3}{5}\\) and cat \\(\\frac{2}{5}\\) . from math import log2 from typing import * from typing import List import numpy as np import scipy def compute_class_probabilities ( labels : List [ Any ]) -> List [ float ]: \"\"\"Calculate frequency of each class. From DSFS book, it mentions that we do not actually care about which label is associated with which probability. Thus it is okay to use a dictionary which does not preserve order. Args: labels (List[Any]): The labels of the data. Returns: label_probs (List[float]): The frequency of each class. Example: >>> labels = ['dog', 'dog', 'cat', 'cat', 'dog'] = [0, 0, 1, 1, 0] >>> assert compute_class_probabilities(labels) == [2/5, 3/5] or class_probabilities(labels) == [3/5, 2/5] \"\"\" num_samples = len ( labels ) label_count : Dict = {} label_probs : List = [] for label in labels : if label not in label_count : label_count [ label ] = 1 else : label_count [ label ] += 1 for label , count in label_count . items (): label_probs . append ( count / num_samples ) return label_probs def compute_entropy_with_class_probability ( class_probabilities : List [ float ], epsilon : float = 1e-15 , log_base : int = 2 , ) -> float : \"\"\"The formula for entropy is: $$\\mathrm{H}(Y)= -\\sum _{i=1}^{n}{\\mathrm{P}(y_{i})\\log \\mathrm{P}(y_{i})}$$ Args: class_probabilities (List[float]): Frequency probability of class occurences. Returns: entropy (float): The entropy of the dataset. Example: >>> # maximum chaos -> entropy = 1 >>> class_probabilities = [1/2, 1/2] >>> assert compute_entropy_with_class_probability(class_probabilities) == 1 >>> # minimum chaos -> entropy = 0 >>> class_probabilities = [1, 0] # or [0, 1] >>> assert np.isclose(compute_entropy_with_class_probability(class_probabilities), 0) >>> class_probabilities = [2/5, 3/5] >>> assert compute_entropy_with_class_probability(class_probabilities) == 0.9709505944546686 \"\"\" assert ( np . sum ( class_probabilities ) == 1 ), f \"Probabilities do not sum to 1 and is { np . sum ( class_probabilities ) } !\" assert log_base in [ 2 , 10 , ], f \"log_base must be either 2 or 10. Got { log_base } !\" if log_base == 2 : log_fn = getattr ( np , \"log2\" ) else : log_fn = getattr ( np , \"log10\" ) entropy = 0 for y in class_probabilities : if y == 0 : y = epsilon entropy += y * log_fn ( y ) entropy = - 1 * entropy return entropy def compute_entropy_with_class_labels ( labels : List [ Any ], * args , ** kwargs ) -> float : \"\"\"Compute the entropy of the dataset given class labels. Args: labels (List[Any]): The labels of the data. Returns: entropy (float): The entropy of the dataset. Example: >>> from scipy.stats import entropy >>> labels = [0, 0, 1, 1, 0] # ['dog', 'dog', 'cat', 'cat', 'dog'] >>> # Note scipy's entropy takes in class freq >>> np.isclose(compute_entropy_with_class_labels(labels=labels, epsilon=1e-15, log_base=2), entropy([3/5, 2/5], base=2)) \"\"\" return compute_entropy_with_class_probability ( compute_class_probabilities ( labels ), * args , ** kwargs ) >>> # maximum chaos -> entropy = 1 >>> class_probabilities = [ 1 / 2 , 1 / 2 ] >>> assert compute_entropy_with_class_probability ( class_probabilities ) == 1 >>> # minimum chaos -> entropy = 0 >>> class_probabilities = [ 1 , 0 ] # or [0, 1] >>> assert np . isclose ( compute_entropy_with_class_probability ( class_probabilities ), 0 ) >>> class_probabilities = [ 2 / 5 , 3 / 5 ] >>> assert compute_entropy_with_class_probability ( class_probabilities ) == 0.9709505944546686 >>> from scipy.stats import entropy >>> labels = [ 0 , 0 , 1 , 1 , 0 ] # ['dog', 'dog', 'cat', 'cat', 'dog'] >>> # Note scipy's entropy takes in class freq >>> np . isclose ( compute_entropy_with_class_labels ( labels = labels , epsilon = 1e-15 , log_base = 2 ), entropy ([ 3 / 5 , 2 / 5 ], base = 2 )) True Entropy Graph vs Different Class Distributions We see that the Entropy of each point in the plot below, and find that on the extreme, [0, 1] and [1, 0] , our entropy is the lowest with 0. The plot below is akin to our dataset having 2 distinct classes, but with different class frequencies. Consider a dataset with 10 cats and dogs (0 and 1 respectively), then the scenario below illustrates: [0, 1] represents there are 0 cats and 10 dogs. This dataset is considered pure and has 0 entropy. Think of it as easy for us to distinguish cats and dogs in a dataset with only dogs. [0.1, 0.9] represents 1 cats and 9 dogs. The entropy is a little higher since we need to spend some effort to distinguish the 1 cat from 9 dogs. [0.5, 0.5] represents 5 cats and 5 dogs. The entropy is highest here and the most impure since there is an equal mixture and distribution of cats and dogs. [1, 0] similar case to [0, 1] . # Reference to machine learning mastery # compare probability distributions vs entropy from math import log2 from matplotlib import pyplot from matplotlib.pyplot import figure figure ( figsize = ( 16 , 8 ), dpi = 80 ) # calculate entropy def entropy ( events , ets = 1e-15 ): return - sum ([ p * log2 ( p + ets ) for p in events ]) # define probabilities probs = [ 0.0 , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 , 0.9 , 1. ] # create probability distribution dists = [[ round ( p , 1 ) , round (( 1.0 - p ), 1 )] for p in probs ] # calculate entropy for each distribution ents = [ entropy ( d ) for d in dists ] # plot probability distribution vs entropy pyplot . plot ( probs , ents , marker = '.' ) pyplot . title ( 'Probability Distribution vs Entropy' ) pyplot . xticks ( probs , [ str ( d ) for d in dists ]) pyplot . xlabel ( 'Probability Distribution' ) pyplot . ylabel ( 'Entropy (bits)' ) pyplot . show () Entropy as a loss function Read more in the section cross_entropy_loss . machinelearningmastery-information-entropy analytics-vidhya-entropy-loss cross-entropy-loss-machine-learning-mastery entropy-how-decision-trees-make-decisions https://ramsane.github.io/articles/cross-entropy-explained-with-entropy-and-kl-divergence https://neptune.ai/blog/cross-entropy-loss-and-its-applications-in-deep-learning","title":"Entropy and information gain"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/entropy_and_information_gain/#introduction","text":"Entropy will appear in two areas of Machine Learning: Entropy and Information Gain in Decision Trees. Entropy as a Loss Function","title":"Introduction"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/entropy_and_information_gain/#entropy-in-decision-trees","text":"Please read entropy-how-decision-trees-make-decisions first. If you are like me, who touched on Entropy as a loss function, then it is slightly confusing for the entropy here. Entropy is a measure of disorder and chaos.","title":"Entropy in Decision Trees"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/entropy_and_information_gain/#definition-entropy","text":"In information theory , the entropy of a random variable is the average level of \\\"information\\\", \\\"surprise\\\", or \\\"uncertainty\\\" inherent to the variable\\'s possible outcomes. Given a discrete random variable \\(Y\\) , with possible outcomes \\(y_1, ..., y_n\\) , which occur with probability \\[\\mathrm{P}(Y=y_1), ..., \\mathrm{P}(Y=y_n)\\] the entropy of \\(Y\\) is formally defined as: \\[\\mathrm{H}(Y)= -\\sum _{i=1}^{n}{\\mathrm{P}(y_{i})\\log \\mathrm{P}(y_{i})}\\] where \\(\\Sigma\\) denotes the sum over the variable\\'s possible values. The choice of base for \\(\\log\\) , the logarithm , varies for different applications. Base 2 gives the unit of bits (or \\\" shannons \\\"), while base e gives \\\"natural units\\\" nat , and base 10 gives units of \\\"dits\\\", \\\"bans\\\", or \\\" hartleys \\\". An equivalent definition of entropy is the expected value of the self-information of a variable.","title":"Definition (Entropy)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/entropy_and_information_gain/#intuition-entropy-and-information-theory","text":"From Wikipedia: Consider making my own example to reinforce concept. Intuitively, if we are predicting an image of a cat vs dog, and we pass in a query image \\(x_{q}\\) of pixels, we expect the \\(y_{q}\\) to take on class 0 or 1. However, taking a step back, in ML setting, we often have a calibrated probability \\(y_{q}\\) before the classifier tells us whether it is a 0 or 1 based on a decision (say if probability more than 0.5, then its 1, and 0 otherwwise). This probability is a soft label and in our scenario, should output an array y_q = [ probability of x_q being a cat 0 , probability of x_q being a dog 1 ] = [ 0.5 , 0.5 ] In this case, we can say that our prediction \\(Y\\) is a DISCRETE random variable with probability distribution \\(p\\) , and thus the entropy of \\(Y\\) can be formally defined as: \\[\\mathrm{H}(Y)= -\\sum _{i=1}^{n}{\\mathrm{P}(y_{i})\\log \\mathrm{P}(y_{i})}\\] where we are summing over all values that \\(Y\\) took on. In this case, it is entropy of y_q = - ( 0.5 * lg 0.5 + 0.5 * lg 0.5 ) = - ( - 0.5 + - 0.5 ) = 1 Note we are using lg base 2 here and so our maximum entropy is 1. Entropy is maximum if each random variable is equi-probable. Entropy Loss is usually used as a loss function in ML as it penalizes \"wrong predictions\" and favours confident predictions. In the image below, let's say \\(Y\\) is a random variable taking on a uniform distribution, for example, if we are predicting a cat or dog image, where \\(y\\) is the probability output from a classifier, taking on 0 to 1. If we were to assume \\(y \\sim U[0,1]\\) , then it follows that \\(H(y) = 1\\) as \\(y\\) will always be of \\([0.5, 0.5]\\) in prediction. Let us now see two different cases if \\(y\\) follows a gaussian distribution, \\(y_{1} \\sim \\mathcal{N_1}[0,1]\\) and \\(y_{2} \\sim \\mathcal{N_2}[0,1]\\) Visually, we can see that the second gaussian has a higher peak than the first, hence we can deduce that \\(H(y_{2}) < H(y_{1})\\) because since the higher peak suggest that the points of \\(y_{2}\\) are tightly spread around each other, and since the points are close, there is less penalty in the \\(\\log\\) . Even more geometrically, if we take \"uniform distribution\" as the one with highest entropy, we can say that as the gaussian curve smoothes out -> becoming more uniform, then the entropy rises. Fig; By Hongnan G.","title":"Intuition (Entropy and Information Theory)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/entropy_and_information_gain/#python-code-entropy-in-information-gain","text":"from math import log2 from typing import * from typing import List import numpy as np import scipy Given a list of labels, (i.e. ground truth labels of 5 images of cats and dogs): Ground Truth Labels: ['dog', 'dog', 'cat', 'cat', 'dog'] = [0, 0, 1, 1, 0] Class Probabilities: Note carefully in this entropy context, this class probabilities IS NOT the softmax activation, instead, it is just the FREQUENCY of each class. [3/5, 2/5] where dog has frequency of \\(\\frac{3}{5}\\) and cat \\(\\frac{2}{5}\\) . from math import log2 from typing import * from typing import List import numpy as np import scipy def compute_class_probabilities ( labels : List [ Any ]) -> List [ float ]: \"\"\"Calculate frequency of each class. From DSFS book, it mentions that we do not actually care about which label is associated with which probability. Thus it is okay to use a dictionary which does not preserve order. Args: labels (List[Any]): The labels of the data. Returns: label_probs (List[float]): The frequency of each class. Example: >>> labels = ['dog', 'dog', 'cat', 'cat', 'dog'] = [0, 0, 1, 1, 0] >>> assert compute_class_probabilities(labels) == [2/5, 3/5] or class_probabilities(labels) == [3/5, 2/5] \"\"\" num_samples = len ( labels ) label_count : Dict = {} label_probs : List = [] for label in labels : if label not in label_count : label_count [ label ] = 1 else : label_count [ label ] += 1 for label , count in label_count . items (): label_probs . append ( count / num_samples ) return label_probs def compute_entropy_with_class_probability ( class_probabilities : List [ float ], epsilon : float = 1e-15 , log_base : int = 2 , ) -> float : \"\"\"The formula for entropy is: $$\\mathrm{H}(Y)= -\\sum _{i=1}^{n}{\\mathrm{P}(y_{i})\\log \\mathrm{P}(y_{i})}$$ Args: class_probabilities (List[float]): Frequency probability of class occurences. Returns: entropy (float): The entropy of the dataset. Example: >>> # maximum chaos -> entropy = 1 >>> class_probabilities = [1/2, 1/2] >>> assert compute_entropy_with_class_probability(class_probabilities) == 1 >>> # minimum chaos -> entropy = 0 >>> class_probabilities = [1, 0] # or [0, 1] >>> assert np.isclose(compute_entropy_with_class_probability(class_probabilities), 0) >>> class_probabilities = [2/5, 3/5] >>> assert compute_entropy_with_class_probability(class_probabilities) == 0.9709505944546686 \"\"\" assert ( np . sum ( class_probabilities ) == 1 ), f \"Probabilities do not sum to 1 and is { np . sum ( class_probabilities ) } !\" assert log_base in [ 2 , 10 , ], f \"log_base must be either 2 or 10. Got { log_base } !\" if log_base == 2 : log_fn = getattr ( np , \"log2\" ) else : log_fn = getattr ( np , \"log10\" ) entropy = 0 for y in class_probabilities : if y == 0 : y = epsilon entropy += y * log_fn ( y ) entropy = - 1 * entropy return entropy def compute_entropy_with_class_labels ( labels : List [ Any ], * args , ** kwargs ) -> float : \"\"\"Compute the entropy of the dataset given class labels. Args: labels (List[Any]): The labels of the data. Returns: entropy (float): The entropy of the dataset. Example: >>> from scipy.stats import entropy >>> labels = [0, 0, 1, 1, 0] # ['dog', 'dog', 'cat', 'cat', 'dog'] >>> # Note scipy's entropy takes in class freq >>> np.isclose(compute_entropy_with_class_labels(labels=labels, epsilon=1e-15, log_base=2), entropy([3/5, 2/5], base=2)) \"\"\" return compute_entropy_with_class_probability ( compute_class_probabilities ( labels ), * args , ** kwargs ) >>> # maximum chaos -> entropy = 1 >>> class_probabilities = [ 1 / 2 , 1 / 2 ] >>> assert compute_entropy_with_class_probability ( class_probabilities ) == 1 >>> # minimum chaos -> entropy = 0 >>> class_probabilities = [ 1 , 0 ] # or [0, 1] >>> assert np . isclose ( compute_entropy_with_class_probability ( class_probabilities ), 0 ) >>> class_probabilities = [ 2 / 5 , 3 / 5 ] >>> assert compute_entropy_with_class_probability ( class_probabilities ) == 0.9709505944546686 >>> from scipy.stats import entropy >>> labels = [ 0 , 0 , 1 , 1 , 0 ] # ['dog', 'dog', 'cat', 'cat', 'dog'] >>> # Note scipy's entropy takes in class freq >>> np . isclose ( compute_entropy_with_class_labels ( labels = labels , epsilon = 1e-15 , log_base = 2 ), entropy ([ 3 / 5 , 2 / 5 ], base = 2 )) True","title":"Python Code (Entropy in Information Gain)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/entropy_and_information_gain/#entropy-graph-vs-different-class-distributions","text":"We see that the Entropy of each point in the plot below, and find that on the extreme, [0, 1] and [1, 0] , our entropy is the lowest with 0. The plot below is akin to our dataset having 2 distinct classes, but with different class frequencies. Consider a dataset with 10 cats and dogs (0 and 1 respectively), then the scenario below illustrates: [0, 1] represents there are 0 cats and 10 dogs. This dataset is considered pure and has 0 entropy. Think of it as easy for us to distinguish cats and dogs in a dataset with only dogs. [0.1, 0.9] represents 1 cats and 9 dogs. The entropy is a little higher since we need to spend some effort to distinguish the 1 cat from 9 dogs. [0.5, 0.5] represents 5 cats and 5 dogs. The entropy is highest here and the most impure since there is an equal mixture and distribution of cats and dogs. [1, 0] similar case to [0, 1] . # Reference to machine learning mastery # compare probability distributions vs entropy from math import log2 from matplotlib import pyplot from matplotlib.pyplot import figure figure ( figsize = ( 16 , 8 ), dpi = 80 ) # calculate entropy def entropy ( events , ets = 1e-15 ): return - sum ([ p * log2 ( p + ets ) for p in events ]) # define probabilities probs = [ 0.0 , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 , 0.9 , 1. ] # create probability distribution dists = [[ round ( p , 1 ) , round (( 1.0 - p ), 1 )] for p in probs ] # calculate entropy for each distribution ents = [ entropy ( d ) for d in dists ] # plot probability distribution vs entropy pyplot . plot ( probs , ents , marker = '.' ) pyplot . title ( 'Probability Distribution vs Entropy' ) pyplot . xticks ( probs , [ str ( d ) for d in dists ]) pyplot . xlabel ( 'Probability Distribution' ) pyplot . ylabel ( 'Entropy (bits)' ) pyplot . show ()","title":"Entropy Graph vs Different Class Distributions"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/fundamentals/loss_functions/cross_entropy_loss/entropy_and_information_gain/#entropy-as-a-loss-function","text":"Read more in the section cross_entropy_loss . machinelearningmastery-information-entropy analytics-vidhya-entropy-loss cross-entropy-loss-machine-learning-mastery entropy-how-decision-trees-make-decisions https://ramsane.github.io/articles/cross-entropy-explained-with-entropy-and-kl-divergence https://neptune.ai/blog/cross-entropy-loss-and-its-applications-in-deep-learning","title":"Entropy as a loss function"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/accuracy/","text":"! pip install - q scikit - learn == 1.0.1 from sklearn import metrics import numpy as np Definition Definition Formally, if \\(\\hat{y}^{(i)}\\) is the predicted value of the i-th sample and the ground truth is \\(y^{(i)}\\) , then accuracy can be defined as the fraction of predictions that our classifier/hypothesis/model predicted correctly, over the total number of samples in question. \\[ \\begin{aligned} \\text{accuracy}(\\hat{y}^{(i)}, y^{(i)}) &= \\dfrac{1}{\\text{num_samples}}\\sum_{i=1}^{\\text{num_samples}}\\mathrm{1}(y^{(i)}\\hat{y}^{(i)}) \\\\ &= \\dfrac{\\text{Number of correctly classified cases}}{\\text{Number for all cases}} \\end{aligned} \\] where \\(\\mathrm{1}(x)\\) is the indicator function . Note Accuracy is a simple enough metric such that the definition for both binary and multiclass classification is the same. When to use Accuracy as a metric Classes are well balanced: Accuracy is a valid choice of evaluation for classification problems which are well balanced and not skewed or no class imbalance. Typically, one should plot EDA and see the classes - if they are roughly equal, then accuracy can be used. However, accuracy should not be the only metric to look at in a classification problem. When NOT to use Accuracy as a metric Danger Consider an imbalanced set, where the training data set has 100 patients (data points), and the ground truth is 90 patients are of class = 0, which means that these patients do not have cancer, whereas the remaining 10 patients are in class 1, where they do have cancer. This is an example of class imbalance where the ratio of class 1 to class 0 is \\(1:9\\) . Next, we consider a baseline (almost trivial) classifier : def baselineModel ( patient_data ): training ... return benign where we predict the patient's class as the most frequent class. Meaning, the most frequent class in this question is the class = 0, where patients do not have cancer, so we just assign this class to everyone in this set. By doing this, we will inevitably achieve a in-sample accuracy rate of \\(\\frac{90}{100} = 90\\%\\) . But unfortunately, this supposedly high accuracy value is completely useless, because this classifier did not label any of the cancer patients correctly. The consequence can be serious, assuming the test set has the same distribution as our training set, where if we have a test set of 1000 patients, there are 900 negative and 100 positive. Our model just literally predict every one of them as benign, yielding a \\(90\\%\\) out-of-sample accuracy. What did we conclude? Well, for one, our accuracy can be 90% high and looks good to the laymen, but it failed to predict the most important class of people. Implementation of Accuracy def accuracy ( y_true : np . ndarray , y_pred : np . ndarray ) -> float : \"\"\"Calculates accuracy score of a prediction. Can be used for both binary and multiclass classification. Args: y_true (np.ndarray): the correct labels, shape (n_samples, ) y_pred (np.ndarray): the predicted labels, shape (n_samples, ) Returns: accuracy_score (float): the accuracy score \"\"\" accuracy_count = 0 # numerator num_samples = len ( y_true ) # denominator for y_t , y_p in zip ( y_true , y_pred ): if y_t == y_p : accuracy_count += 1 accuracy_score = accuracy_count / num_samples return accuracy_score # Binary Classification y_true = np . asarray ([ 1 , 1 , 0 , 1 , 0 , 0 ]) y_pred = np . asarray ([ 1 , 1 , 1 , 0 , 0 , 0 ]) print ( f \"hn accuracy: { accuracy ( y_true , y_pred ) } \" ) print ( f \"sklearn accuracy: { metrics . accuracy_score ( y_true , y_pred , normalize = True ) } \" ) # Multiclass Classification y_pred = np . asarray ([ 0 , 2 , 1 , 3 ]) y_true = np . asarray ([ 0 , 1 , 2 , 3 ]) print ( f \"hn accuracy: { accuracy ( y_true , y_pred ) } \" ) print ( f \"sklearn accuracy: { metrics . accuracy_score ( y_true , y_pred , normalize = True ) } \" ) hn accuracy: 0.6666666666666666 sklearn accuracy: 0.6666666666666666 hn accuracy: 0.5 sklearn accuracy: 0.5","title":"Accuracy"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/accuracy/#definition","text":"Definition Formally, if \\(\\hat{y}^{(i)}\\) is the predicted value of the i-th sample and the ground truth is \\(y^{(i)}\\) , then accuracy can be defined as the fraction of predictions that our classifier/hypothesis/model predicted correctly, over the total number of samples in question. \\[ \\begin{aligned} \\text{accuracy}(\\hat{y}^{(i)}, y^{(i)}) &= \\dfrac{1}{\\text{num_samples}}\\sum_{i=1}^{\\text{num_samples}}\\mathrm{1}(y^{(i)}\\hat{y}^{(i)}) \\\\ &= \\dfrac{\\text{Number of correctly classified cases}}{\\text{Number for all cases}} \\end{aligned} \\] where \\(\\mathrm{1}(x)\\) is the indicator function . Note Accuracy is a simple enough metric such that the definition for both binary and multiclass classification is the same.","title":"Definition"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/accuracy/#when-to-use-accuracy-as-a-metric","text":"Classes are well balanced: Accuracy is a valid choice of evaluation for classification problems which are well balanced and not skewed or no class imbalance. Typically, one should plot EDA and see the classes - if they are roughly equal, then accuracy can be used. However, accuracy should not be the only metric to look at in a classification problem.","title":"When to use Accuracy as a metric"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/accuracy/#when-not-to-use-accuracy-as-a-metric","text":"Danger Consider an imbalanced set, where the training data set has 100 patients (data points), and the ground truth is 90 patients are of class = 0, which means that these patients do not have cancer, whereas the remaining 10 patients are in class 1, where they do have cancer. This is an example of class imbalance where the ratio of class 1 to class 0 is \\(1:9\\) . Next, we consider a baseline (almost trivial) classifier : def baselineModel ( patient_data ): training ... return benign where we predict the patient's class as the most frequent class. Meaning, the most frequent class in this question is the class = 0, where patients do not have cancer, so we just assign this class to everyone in this set. By doing this, we will inevitably achieve a in-sample accuracy rate of \\(\\frac{90}{100} = 90\\%\\) . But unfortunately, this supposedly high accuracy value is completely useless, because this classifier did not label any of the cancer patients correctly. The consequence can be serious, assuming the test set has the same distribution as our training set, where if we have a test set of 1000 patients, there are 900 negative and 100 positive. Our model just literally predict every one of them as benign, yielding a \\(90\\%\\) out-of-sample accuracy. What did we conclude? Well, for one, our accuracy can be 90% high and looks good to the laymen, but it failed to predict the most important class of people.","title":"When NOT to use Accuracy as a metric"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/accuracy/#implementation-of-accuracy","text":"def accuracy ( y_true : np . ndarray , y_pred : np . ndarray ) -> float : \"\"\"Calculates accuracy score of a prediction. Can be used for both binary and multiclass classification. Args: y_true (np.ndarray): the correct labels, shape (n_samples, ) y_pred (np.ndarray): the predicted labels, shape (n_samples, ) Returns: accuracy_score (float): the accuracy score \"\"\" accuracy_count = 0 # numerator num_samples = len ( y_true ) # denominator for y_t , y_p in zip ( y_true , y_pred ): if y_t == y_p : accuracy_count += 1 accuracy_score = accuracy_count / num_samples return accuracy_score # Binary Classification y_true = np . asarray ([ 1 , 1 , 0 , 1 , 0 , 0 ]) y_pred = np . asarray ([ 1 , 1 , 1 , 0 , 0 , 0 ]) print ( f \"hn accuracy: { accuracy ( y_true , y_pred ) } \" ) print ( f \"sklearn accuracy: { metrics . accuracy_score ( y_true , y_pred , normalize = True ) } \" ) # Multiclass Classification y_pred = np . asarray ([ 0 , 2 , 1 , 3 ]) y_true = np . asarray ([ 0 , 1 , 2 , 3 ]) print ( f \"hn accuracy: { accuracy ( y_true , y_pred ) } \" ) print ( f \"sklearn accuracy: { metrics . accuracy_score ( y_true , y_pred , normalize = True ) } \" ) hn accuracy: 0.6666666666666666 sklearn accuracy: 0.6666666666666666 hn accuracy: 0.5 sklearn accuracy: 0.5","title":"Implementation of Accuracy"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/classification_metrics/","text":"This notebook attempts to describe the commonly used Classification Metrics in details; you will find the pros and cons of each metric, alongside with examples to illustrate. I will refer to scikit-learn's official website for reference, specifically, the section on Model Evaluation . I may quote some definitions verbatim, if necessary. We will be going through three major types of classification problems. Binary Classification Multiclass Classification Multilabel Classification Motivation Unlike Kaggle competitions, metrics have to be carefully chosen in business. A wrong metric may lead to disastrous outcomes. We open with a classic example. Failure Consider a training dataset consisting of 1000 patients where we want to train a classifier to \"accurately\" classify whether a patient has cancer (positive class 1) or no cancer (negative class 0). The dataset is dichotimized by 950 benign patients and the remaining 50, cancerous. The ZeroR classifier (baseline classification model) predicts only the majority class. And in our case, the in-sample training set accuracy will be \\(0.95\\%\\) since it predicts all sample to be benign; for completeness, we also assume a validation set with 1000 patients (990 benign and 10 cancerous), it follows that our validation set's accuracy will be \\(0.99\\%\\) . Euphoria is at all time high over this result, surprised that a baseline model can perform so well, you then happily reported this result to your boss, and gets fired immediately. You drown in tears and googled \"Is accuracy a bad metric?\", only to learn a valuable lesson: since the model you trained will predict benign no matter the input, this means it completely missed out every single cancerous patient even though you get a 99 percent accuracy. Should your model ever be deployed as a \"cancer detector\", you will be responsible for indirectly causing many patients' death. TODOs Thresholds To add threshold explanation in future changes. For example, talk more about how we can use different thresholds to make business decisions. Benefit Structure","title":"Introduction"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/classification_metrics/#motivation","text":"Unlike Kaggle competitions, metrics have to be carefully chosen in business. A wrong metric may lead to disastrous outcomes. We open with a classic example. Failure Consider a training dataset consisting of 1000 patients where we want to train a classifier to \"accurately\" classify whether a patient has cancer (positive class 1) or no cancer (negative class 0). The dataset is dichotimized by 950 benign patients and the remaining 50, cancerous. The ZeroR classifier (baseline classification model) predicts only the majority class. And in our case, the in-sample training set accuracy will be \\(0.95\\%\\) since it predicts all sample to be benign; for completeness, we also assume a validation set with 1000 patients (990 benign and 10 cancerous), it follows that our validation set's accuracy will be \\(0.99\\%\\) . Euphoria is at all time high over this result, surprised that a baseline model can perform so well, you then happily reported this result to your boss, and gets fired immediately. You drown in tears and googled \"Is accuracy a bad metric?\", only to learn a valuable lesson: since the model you trained will predict benign no matter the input, this means it completely missed out every single cancerous patient even though you get a 99 percent accuracy. Should your model ever be deployed as a \"cancer detector\", you will be responsible for indirectly causing many patients' death.","title":"Motivation"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/classification_metrics/#todos","text":"","title":"TODOs"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/classification_metrics/#thresholds","text":"To add threshold explanation in future changes. For example, talk more about how we can use different thresholds to make business decisions.","title":"Thresholds"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/classification_metrics/#benefit-structure","text":"","title":"Benefit Structure"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/cohens_kappa/","text":"! pip install - q scikit - learn == 1.0.1 import numpy as np import pandas as pd from sklearn.metrics import confusion_matrix , roc_auc_score , brier_score_loss , cohen_kappa_score , make_scorer import itertools from sklearn import datasets import seaborn as sns import matplotlib.pyplot as plt import random from typing import Dict , List from IPython.core.interactiveshell import InteractiveShell InteractiveShell . ast_node_interactivity = \"all\" Quadratic Weighted Kappa The below explanation will correspond to my notebook during the PANDAS competition . ## Table of Contents 1. Intuition of QWK 2. Step 1: Create the NxN histogram matrix O 3. Step 2: Create the Weighted Matrix w 4. Step 3: Create the Expected Matrix 5. Step 4: Final Step: Weighted Kappa formula and Its python codes Intuition of QWK TLDR: one can skip to the last section on the python code implementation of QWK and also take reference to CPMP's Fast QWK Computation as well. Kappa or Cohen\u2019s Kappa is like classification accuracy, except that it is normalized at the baseline of random chance on your dataset: It basically tells you how much better your classifier is performing over the performance of a classifier that simply guesses at random according to the frequency of each class. First off, we define the formula exactly as mentioned. Quoting from the evaluation page: Submissions are scored based on the quadratic weighted kappa, which measures the agreement between two outcomes. This metric typically varies from 0 (random agreement) to 1 (complete agreement). In the event that there is less agreement than expected by chance, the metric may go below 0. The quadratic weighted kappa is calculated as follows. First, an N x N histogram matrix O is constructed, such that \\(O_{i,j}\\) corresponds to the number of isup_grade 's i (actual) that received a predicted value j. An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted values: \\[w_{i,j} = \\dfrac{(i-j)^2}{(N-1)^2}\\] An N-by-N histogram matrix of expected outcomes, E, is calculated assuming that there is no correlation between values.This is calculated as the outer product between the actual histogram vector of outcomes and the predicted histogram vector, normalized such that E and O have the same sum. Finally, from these three matrices, the quadratic weighted kappa is calculated as: \\[\\kappa = 1 - \\dfrac{\\sum_{i,j}\\text{w}_{i,j}O_{i,j}}{\\sum_{i,j}\\text{w}_{i,j}E_{i,j}}\\] where \\(w\\) is the weighted matrix, \\(O\\) is the histogram matrix and \\(E\\) being the expected matrix. Step 1: Create the NxN histogram matrix O Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon. Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon. Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon. Reminder: Although it is a counter example, it still illustrates what a NxN histogram matrix is! We will now call our histogram matrix C instead because in actual fact, the histogram matrix is merely a multi class confusion matrix between actual and predicted values We use a naive example where there are 5 classes (note our competition is_up grade has 6 classes; but this is just an example. Our y_true is the ground truth labels and correspondingly, our y_pred is the predicted values. y_true = pd . Series ([ 'cat' , 'cat' , 'dog' , 'cat' , 'cat' , 'cat' , 'pig' , 'pig' , 'hen' , 'pig' ], name = 'Actual' ) y_pred = pd . Series ([ 'bird' , 'hen' , 'pig' , 'bird' , 'bird' , 'bird' , 'pig' , 'pig' , 'hen' , 'pig' ], name = 'Predicted' ) print ( \"Ground truth: \\n {} \" . format ( y_true )) print ( \"-\" * 40 ) print ( \"Predicted Values: \\n {} \" . format ( y_pred )) Ground truth: 0 cat 1 cat 2 dog 3 cat 4 cat 5 cat 6 pig 7 pig 8 hen 9 pig Name: Actual, dtype: object ---------------------------------------- Predicted Values: 0 bird 1 hen 2 pig 3 bird 4 bird 5 bird 6 pig 7 pig 8 hen 9 pig Name: Predicted, dtype: object First, an N x N confusion matrix C is constructed, such that \\(\\text{C}_{i,j}\\) is the entry that corresponds to the number of animal i (actual) that received a predicted value j . classes = [ 'bird' , 'cat' , 'dog' , 'hen' , 'pig' ] # thank you https://datascience.stackexchange.com/questions/40067/confusion-matrix-three-classes-python def plot_confusion_matrix ( cm , classes , normalize = False , title = 'Confusion matrix' , cmap = plt . cm . Blues ): \"\"\" This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`. \"\"\" if normalize : cm = cm . astype ( 'float' ) / cm . sum ( axis = 1 )[:, np . newaxis ] print ( \"Normalized confusion matrix\" ) else : print ( 'Confusion matrix, without normalization' ) plt . imshow ( cm , interpolation = 'nearest' , cmap = cmap ) plt . title ( title ) plt . colorbar () tick_marks = np . arange ( len ( classes )) plt . xticks ( tick_marks , classes , rotation = 45 ) plt . yticks ( tick_marks , classes ) fmt = '.2f' if normalize else 'd' thresh = cm . max () / 2. for i , j in itertools . product ( range ( cm . shape [ 0 ]), range ( cm . shape [ 1 ])): plt . text ( j , i , format ( cm [ i , j ], fmt ), horizontalalignment = \"center\" , color = \"white\" if cm [ i , j ] > thresh else \"black\" ) plt . ylabel ( 'True label' ) plt . xlabel ( 'Predicted label' ) plt . tight_layout () cnf_matrix = confusion_matrix ( y_true , y_pred , labels = [ 'bird' , 'cat' , 'dog' , 'hen' , 'pig' ],) np . set_printoptions ( precision = 2 ) # Plot non-normalized confusion matrix plt . figure () plot_confusion_matrix ( cnf_matrix , classes = [ 'bird' , 'cat' , 'dog' , 'hen' , 'pig' ], title = 'Confusion matrix C, without normalization' ) <Figure size 432x288 with 0 Axes> Confusion matrix, without normalization Example using our competition's dataset The above matrix is a multi class confusion matrix . As an example, for the 2nd row, we predicted 4 cats to be birds, and 1 cat to be predicted as hen. More compactly, it can be represented as the matrix \\(C_{2,1}\\) = 4. We can easily reconcile our example above to relate back to our competition: After the biopsy is assigned a Gleason score, it is converted into an ISUP grade on a 1-5 scale . For now, I will include the label 0 because it is the background/non-tissue. What I do next is to take the ground truth and call it y_true which is a series. I then generate a dummy y_pred by using np.random.choice and randomly generate numbers from 0 to 5. train = pd . read_csv ( \"../data/datasets/prostate-cancer-grade-assessment-train.csv\" ) y_true = train . isup_grade y_true y_pred = np . random . choice ( 6 , 10616 , replace = True ) y_pred = pd . Series ( y_pred ) y_pred 0 0 1 0 2 4 3 4 4 0 .. 10611 0 10612 5 10613 0 10614 2 10615 4 Name: isup_grade, Length: 10616, dtype: int64 0 2 1 2 2 4 3 1 4 5 .. 10611 2 10612 2 10613 1 10614 5 10615 1 Length: 10616, dtype: int32 The following confusion matrix, is what we mean by the \"N by N\" (6 by 6) histogram matrix . cm = confusion_matrix ( y_true , y_pred , labels = [ 0 , 1 , 2 , 3 , 4 , 5 ],) plot_confusion_matrix ( cm , classes = [ 0 , 1 , 2 , 3 , 4 , 5 ], title = 'Confusion matrix C, without normalization' ) Confusion matrix, without normalization So far we have settled the first portion, construction the histogram matrix. Step 2: Create the Weighted Matrix w An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted rating scores. The formula is as follows: \\( \\(w_{i,j} = \\dfrac{(i-j)^2}{(N-1)^2}\\) \\) Under Step-2, each element is weighted. Predictions that are further away from actuals are marked harshly than predictions that are closer to actuals. However, I suddenly realized that these animals above have no obvious hierarchy in them. Therefore, it is not correct to say that predicting a cat as a bird is any better/worse off than predicting a cat as hen. Consequently, this is a realization. Because now I start to understand why certain competitions use metrics like quadratic weighted kappa! Consider the same example as animals just now, but instead of animals, we change to isup_grade ). So there is an inherent order within the isup_grade 0 - 5 such that 0 and 1 is closer than 0 and 2, 1 and 2 is closer to 1 and 3 etc. \\( \\(0 > 1 > 2 > 3 > 4 > 5\\) \\) For example, let's use a simplified example: y_true = [2,2,2,1,2,3,4,5,0,1] y_pred = [1,2,4,1,2,3,4,5,0,1] As a result, our purpose of the weighted matrix is to allocate a higher penalty score if our prediction is further away from the actual value. That is, if our isup_grade is 2 but we predicted it as 1 (see the example), then based on our formula above, we have i = 2 and j = 1 (entry \\(C_{2,1}\\) ), the penalty is \\( \\(\\dfrac{(2-1)^2}{(5-1)^2} = 0.0625\\) \\) but if our isup_grade is 2 and we predicted it as 4 (see the example), then the penalty involved is higher \\( \\(\\dfrac{(2-4)^2}{(5-1)^2} = 0.25\\) \\) Indeed, the weight matrix helped us assign a heavier penalty to predicting 2 as 4 than 2 as 1. Lastly, we also observe that the formula will give us 0 for the diagonals of the weighted matrix. This means penalty is 0 whenever we correctly predict something. To calculate weighted matrix in python code, here is the code with reference to Aman Arora . # We construct the weighted matrix starting from a zero matrix, it is like constructing a # list, we usually start from an empty list and add things inside using loops. def weighted_matrix ( N ): weighted = np . zeros (( N , N )) for i in range ( len ( weighted )): for j in range ( len ( weighted )): weighted [ i ][ j ] = float ((( i - j ) ** 2 ) / ( N - 1 ) ** 2 ) return weighted print ( weighted_matrix ( 5 )) [[0. 0.06 0.25 0.56 1. ] [0.06 0. 0.06 0.25 0.56] [0.25 0.06 0. 0.06 0.25] [0.56 0.25 0.06 0. 0.06] [1. 0.56 0.25 0.06 0. ]] Remember, the further away from the diagonal you get, the worse off is your prediction and it will be penalized harder by a bigger weight. As you can easily infer from the weighted matrix above, we use the first row as an example in case one did not understand. Basically, the weighted matrix's first row's first element is 0, because it means we predicted correctly and no penalty is meted out; but as we move further to the left, you can see that the punishment gets harsher and harsher: \\( \\(0 < 0.06 < 0.25 < 0.56 < 1\\) \\) Step 3: Create the Expected Matrix ## dummy example actual = pd . Series ([ 2 , 2 , 2 , 3 , 4 , 5 , 5 , 5 , 5 , 5 ]) pred = pd . Series ([ 2 , 2 , 2 , 3 , 2 , 1 , 1 , 1 , 1 , 3 ]) C = confusion_matrix ( actual , pred ) N = 5 act_hist = np . zeros ([ N ]) for item in actual : act_hist [ item - 1 ] += 1 pred_hist = np . zeros ([ N ]) for item in pred : pred_hist [ item - 1 ] += 1 print ( f 'Actuals value counts: { act_hist } , \\n Prediction value counts: { pred_hist } ' ) Actuals value counts:[0. 3. 1. 1. 5.], Prediction value counts:[4. 4. 2. 0. 0.] This part is the most difficult to understand, especially for someone who has little statistic backgrounds (mind you when I was majoring in applied math back then, I only took one statistic module in my whole tenure.) Googling the idea of expected matrix is not apparently clear to me, but luckily someone pointed to me to read expected frequency of Chi-Square test and then and, there I start to slowly understand. For the purpose of better understanding, we call our actual values to be rater A and our prediction model to be rater B. We want to quantify the agreement between rater A and rater B. Here are some terminologies to get hold of first. There are a total number of \\(k = 5\\) classes in this example; There are a total number of \\(n = 10\\) observations in this example; Define Y to be the random variable that rater A has chosen (aka our actual classes 1,2,3,4,5); and \\(\\widehat{Y}\\) be the random variable that rater \\(B\\) has chosen (aka our predicted classes 1,2,3,4,5 by rater B) \\(r_i\\) be the i-th entry of the column vector for actual value counts shown above, \\(c_i\\) be the i-th entry of the column vector for prediction value counts shown above. Then the probability of rater A choosing class 2 and rater B choosing class 2 for example, is given by \\( \\(P(Y = 2 \\text{ and } \\widehat{Y} = 2) = P(Y = 2) \\cdot P(\\widehat{Y} = 2) = 30\\% \\times 40\\% = 12\\%\\) \\) This is under the assumption that both raters are independent of each other . Note that \\(P(Y = 2) = 30\\%\\) because as we see from the actual value counts of rater \\(A\\) , there are a total of 3 class 2's and therefore the probability of Y being 2 is just the proportion. Similarly, we calculate \\(\\widehat{Y}\\) the same way. In general, the formula of rater A choosing class i and rater B choosing (predicting) class j is given as follows: \\( \\(P(Y = i \\text{ and } \\widehat{Y} = j) = P(Y = i) \\times P (\\widehat{Y} = j)\\) \\) Now the real question comes: On average, if you have \\(n\\) number of points to predict, how many times (what is the frequency) would you expect to see rater A choose class i and rater B choose class j. To reiterate, recall that the probability of the actual class being 1 and (super important word here, it means a joint distribution) and the predicted class to be 1 as well is \\(P(Y = 1 \\text{ and } \\widehat{Y} = 1)\\) , similarly, the probability of the actual class being 1 and the predicted class to be 2 is \\(P(Y = 1 \\text{ and } \\widehat{Y} = 2)\\) . Generalizing, the probability of the actual class being \\(i\\) and the predicted class being \\(j\\) is the joint probability \\( \\(P(Y = i \\text{ and } \\widehat{Y} = j)\\) \\) So the intuition lies here: based on the joint probability above, what is the expected number of times (frequency) that \\(Y = i\\) and \\(\\widehat{Y} = j\\) happened (this means Y is i but rater B predict \\(\\widehat{Y}\\) as j) out of 10 times? Easy, just use \\(n \\times P(Y = i \\text{ and } \\widehat{Y} = j)\\) . So for rater B, our prediction model, by just using theoretical probability , should have \\(n \\times P(Y = i \\text{ and } \\widehat{Y} = j)\\) for each \\(i,j\\) . But in reality, this may not be the case. Reconcile this idea with the classic coin toss example: Example on coin toss: Expected frequency is defined as the number of times that we predict an event will occur based on a calculation using theoretical probabilities. You know how a coin has two sides, heads or tails? That means that the probability of the coin landing on any one side is 50% (or 1/2, because it can land on one side out of two possible sides). If you flip a coin 1,000 times, how many times would you expect to get heads? About half the time, or 500 out of the 1,000 flips. To calculate the expected frequency, all we need to do is multiply the total number of tosses (1,000) by the probability of getting a heads (1/2), and we get 1,000 * 1/2 = 500 heads. if event A has prob of p happening, and sample size of n, then the average or expected number of times that A happens is \\(np\\) . The expected frequency of heads is 500 out of 1,000 total tosses. The expected frequency is based on our knowledge of probability - we haven't actually done any coin tossing. However, if we had enough time on our hands, we could actually flip a coin 1,000 times to experimentally test our prediction. If we did this, we would be calculating the experimental frequency. The experimental frequency is defined as the number of times that we observe an event to occur when we actually perform an experiment, test, or trial in real life. If you flipped a coin 1,000 times and it landed on heads 479 times, then the experimental frequency of heads is 479. But wait - didn't we predict the coin would land on heads 500 times? Why did it actually land on heads only 479 times? Well, the expected frequency was just that - what we expected to happen, based on our knowledge of probability. There are no guarantees when it comes to probability, what we expect to happen might differ from what actually happens. Since we know \\( \\(E_{2,2} = 10 \\times P(Y = 2 \\text{ and } \\widehat{Y} = 2) = 10 \\times P(Y = 2) \\cdot P(\\widehat{Y} = 2) = 10 \\times 30\\% \\times 40\\% = 1.2\\) \\) This \\(E_{2,2}\\) means that we only expect the rater A to choose 2 and rater B to choose 2 at the same time only 1.2 times out of 10 times. In other words, our predicted model classify 2 as 2 1.2 times. However, from our observations in our matrix C (confusion/histogram matrix), rater A choosing 2 and rater B choosing 2 have a frequency of 3! In other words, our predicted model classified 2 as 2 three times! So we kinda exceeded expectation for this particular configuration. \\[C = \\begin{bmatrix} 0 & 0 & 0 & 0 & 0\\\\ 0 & 3 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 0\\\\ 0 & 1 & 0 & 0 & 0\\\\ 4 & 0 & 1 & 0 & 0\\\\ \\end{bmatrix}\\] Let me give you one more example, \\( \\(E_{5,2} = 10 \\times P(Y = 5 \\text{ and } \\widehat{Y} = 2) = 10 \\times P(Y = 5) \\cdot P(\\widehat{Y} = 2) = 10 \\times 50\\% \\times 40\\% = 2\\) \\) This means that we only expect the rater A to choose 5 and rater B to choose 2 at the same time only 2 times out of 10 times! But in reality, our observations say that our rater B classified 5 as 2 zero times! We calculate \\(E_{i,j}\\) given by the formula: \\( \\(E_{i,j} = n \\times P(Y = i \\text{ and } \\widehat{Y} = j) = n \\times P(Y = i) \\times P (\\widehat{Y} = j) = n \\times \\dfrac{r_i}{n} \\times \\dfrac{c_j}{n}\\) \\) \\[E = \\begin{bmatrix} 0 & 0 & 0 & 0 & 0\\\\ 1.2 & 1.2 & 0.6 & 0 & 0 \\\\ 0.4 & 0.4 & 0.2 & 0 & 0\\\\ 0.4 & 0.4 & 0.2 & 0 & 0\\\\ 2 & 2 & 1 & 0 & 0\\\\ \\end{bmatrix}\\] Note \\(r_i \\times c_j\\) is the \\((i,j)\\) entry of the outer product between the actual histogram vector of outcomes (actual value counts) and the predicted histogram vector (prediction value counts). What does the random chance mean here? Simple, it just means that the probability for rater A (actual) to be class i AND for rater B (predicted) to be class j is \\(p\\%\\) (say 10%). Therefore, if we have made 100 predictions, random chance aka the theoratical probability tells us you should only have \\(100 \\times 10\\% = 10\\) predictions to be of this configuration (rater A class i AND rater B class j). Writing out the expected matrix in python So to get the expected matrix, E, is calculated assuming that there is no correlation between values. This is calculated as the outer product between the actual histogram vector of outcomes and the predicted histogram vector, normalized such that E and C have the same sum. Note carefully below that we do not need to normalize both, we just need to normalize E to the same sum as C. E = np . outer ( act_hist , pred_hist ) / 10 E C array([[0. , 0. , 0. , 0. , 0. ], [1.2, 1.2, 0.6, 0. , 0. ], [0.4, 0.4, 0.2, 0. , 0. ], [0.4, 0.4, 0.2, 0. , 0. ], [2. , 2. , 1. , 0. , 0. ]]) array([[0, 0, 0, 0, 0], [0, 3, 0, 0, 0], [0, 0, 1, 0, 0], [0, 1, 0, 0, 0], [4, 0, 1, 0, 0]], dtype=int64) Step 4: Final Step: Weighted Kappa formula and Its python codes From these three matrices: E, C and weighted, the quadratic weighted kappa is calculated as: \\[\\kappa = 1 - \\dfrac{\\sum_{i,j}\\text{weighted}_{i,j}C_{i,j}}{\\sum_{i,j}\\text{weighted}_{i,j}E_{i,j}}\\] Note that a higher value generally means your prediction model is way better than a random model, but there is no consensus on which value is really good or bad. \\[\\text{Weighted} = \\begin{bmatrix} 0 & 0.0625 & 0.25 & 0.5625 & 1\\\\ 0.0625 & 0 & 0.0625 & 0.25 & 0.5625 \\\\ 0.25 & 0.0625 & 0 & 0.0625 & 0.25\\\\ 0.5625 & 0.25 & 0.0625 & 0 & 0.0625\\\\ 1 & 0.5625 & 0.25 & 0.0625 & 0\\\\ \\end{bmatrix}\\] The notation \\(\\sum_{i,j}\\text{W}_{i,j}C_{i,j}\\) is just \\( \\(\\sum_{i=1}^{k}\\sum_{j=1}^{k} W_{i,j} C_{i,j} = (W_{1,1}C_{1,1} + W_{1,2}C_{1,2} + ...+ W_{1,k}C_{1,k}) + (W_{2,1}C_{2,1}+...+W_{2,k}C_{2,k}) +...+(W_{k,1}C_{k,1}+...+W_{k,k}C_{k,k})\\) \\) To put our understanding into perspective, consider just one entry \\(W_{5,1}C_{5,1} = 1 \\times 4 = 4\\) . This roughly means that our predicted model classified class 5 as class 1 FOUR times (re: \\(C_{5,1} = 4\\) ), and since class 5 is so far away from class 1, we need to punish this wrong prediction more than the others. And we did see that the corresponding weight \\(W_{5,1} = 1\\) is the highest weight. Consequently, the numerator being \\(\\sum_{i,j}\\text{W}_{i,j}C_{i,j}\\) calculates the total \"penalty cost\" for the rater A (our predicted model), and similarly, \\(\\sum_{i,j}\\text{W}_{i,j}E_{i,j}\\) calculates the total \"penalty cost\" for the rater B (our \"expected\" model). Therefore, you can think both values (num and den) as a cost function, and the lesser the better. And kappa formula tells us, if our \\(\\sum_{i,j}\\text{W}_{i,j}C_{i,j}\\) is significantly smaller than \\(\\sum_{i,j}\\text{W}_{i,j}E_{i,j}\\) , this will yield a very small value of \\( \\(\\dfrac{\\sum_{i,j}\\text{weighted}_{i,j}C_{i,j}}{\\sum_{i,j}\\text{weighted}_{i,j}E_{i,j}}\\) \\) which will yield a very high kappa value - signifying a better model. # Method 1 # apply the weights to the confusion matrix weighted = weighted_matrix ( 5 ) num = np . sum ( np . multiply ( weighted , C )) # apply the weights to the histograms den = np . sum ( np . multiply ( weighted , E )) kappa = 1 - np . divide ( num , den ) kappa -0.13924050632911378 # Method 2 num = 0 den = 0 for i in range ( len ( weighted )): for j in range ( len ( weighted )): num += weighted [ i ][ j ] * C [ i ][ j ] den += weighted [ i ][ j ] * E [ i ][ j ] weighted_kappa = ( 1 - ( num / den )); weighted_kappa -0.13924050632911378 # Method 3: Just use sk learn library cohen_kappa_score ( actual , pred , labels = None , weights = 'quadratic' , sample_weight = None ) -0.13924050632911378 Just a side note that one can also use SK learn's cohen_kappa_score function calculate the quadratic weighted kappa in this competition, with weights set to quadratic. Also please do refer to CPMP's discussion topic for fast QWK computation","title":"Cohen's Kappa"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/cohens_kappa/#quadratic-weighted-kappa","text":"The below explanation will correspond to my notebook during the PANDAS competition . ## Table of Contents 1. Intuition of QWK 2. Step 1: Create the NxN histogram matrix O 3. Step 2: Create the Weighted Matrix w 4. Step 3: Create the Expected Matrix 5. Step 4: Final Step: Weighted Kappa formula and Its python codes","title":"Quadratic Weighted Kappa"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/cohens_kappa/#intuition-of-qwk","text":"TLDR: one can skip to the last section on the python code implementation of QWK and also take reference to CPMP's Fast QWK Computation as well. Kappa or Cohen\u2019s Kappa is like classification accuracy, except that it is normalized at the baseline of random chance on your dataset: It basically tells you how much better your classifier is performing over the performance of a classifier that simply guesses at random according to the frequency of each class. First off, we define the formula exactly as mentioned. Quoting from the evaluation page: Submissions are scored based on the quadratic weighted kappa, which measures the agreement between two outcomes. This metric typically varies from 0 (random agreement) to 1 (complete agreement). In the event that there is less agreement than expected by chance, the metric may go below 0. The quadratic weighted kappa is calculated as follows. First, an N x N histogram matrix O is constructed, such that \\(O_{i,j}\\) corresponds to the number of isup_grade 's i (actual) that received a predicted value j. An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted values: \\[w_{i,j} = \\dfrac{(i-j)^2}{(N-1)^2}\\] An N-by-N histogram matrix of expected outcomes, E, is calculated assuming that there is no correlation between values.This is calculated as the outer product between the actual histogram vector of outcomes and the predicted histogram vector, normalized such that E and O have the same sum. Finally, from these three matrices, the quadratic weighted kappa is calculated as: \\[\\kappa = 1 - \\dfrac{\\sum_{i,j}\\text{w}_{i,j}O_{i,j}}{\\sum_{i,j}\\text{w}_{i,j}E_{i,j}}\\] where \\(w\\) is the weighted matrix, \\(O\\) is the histogram matrix and \\(E\\) being the expected matrix.","title":"Intuition of QWK  "},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/cohens_kappa/#step-1-create-the-nxn-histogram-matrix-o","text":"Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon. Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon. Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon. Reminder: Although it is a counter example, it still illustrates what a NxN histogram matrix is! We will now call our histogram matrix C instead because in actual fact, the histogram matrix is merely a multi class confusion matrix between actual and predicted values We use a naive example where there are 5 classes (note our competition is_up grade has 6 classes; but this is just an example. Our y_true is the ground truth labels and correspondingly, our y_pred is the predicted values. y_true = pd . Series ([ 'cat' , 'cat' , 'dog' , 'cat' , 'cat' , 'cat' , 'pig' , 'pig' , 'hen' , 'pig' ], name = 'Actual' ) y_pred = pd . Series ([ 'bird' , 'hen' , 'pig' , 'bird' , 'bird' , 'bird' , 'pig' , 'pig' , 'hen' , 'pig' ], name = 'Predicted' ) print ( \"Ground truth: \\n {} \" . format ( y_true )) print ( \"-\" * 40 ) print ( \"Predicted Values: \\n {} \" . format ( y_pred )) Ground truth: 0 cat 1 cat 2 dog 3 cat 4 cat 5 cat 6 pig 7 pig 8 hen 9 pig Name: Actual, dtype: object ---------------------------------------- Predicted Values: 0 bird 1 hen 2 pig 3 bird 4 bird 5 bird 6 pig 7 pig 8 hen 9 pig Name: Predicted, dtype: object First, an N x N confusion matrix C is constructed, such that \\(\\text{C}_{i,j}\\) is the entry that corresponds to the number of animal i (actual) that received a predicted value j . classes = [ 'bird' , 'cat' , 'dog' , 'hen' , 'pig' ] # thank you https://datascience.stackexchange.com/questions/40067/confusion-matrix-three-classes-python def plot_confusion_matrix ( cm , classes , normalize = False , title = 'Confusion matrix' , cmap = plt . cm . Blues ): \"\"\" This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`. \"\"\" if normalize : cm = cm . astype ( 'float' ) / cm . sum ( axis = 1 )[:, np . newaxis ] print ( \"Normalized confusion matrix\" ) else : print ( 'Confusion matrix, without normalization' ) plt . imshow ( cm , interpolation = 'nearest' , cmap = cmap ) plt . title ( title ) plt . colorbar () tick_marks = np . arange ( len ( classes )) plt . xticks ( tick_marks , classes , rotation = 45 ) plt . yticks ( tick_marks , classes ) fmt = '.2f' if normalize else 'd' thresh = cm . max () / 2. for i , j in itertools . product ( range ( cm . shape [ 0 ]), range ( cm . shape [ 1 ])): plt . text ( j , i , format ( cm [ i , j ], fmt ), horizontalalignment = \"center\" , color = \"white\" if cm [ i , j ] > thresh else \"black\" ) plt . ylabel ( 'True label' ) plt . xlabel ( 'Predicted label' ) plt . tight_layout () cnf_matrix = confusion_matrix ( y_true , y_pred , labels = [ 'bird' , 'cat' , 'dog' , 'hen' , 'pig' ],) np . set_printoptions ( precision = 2 ) # Plot non-normalized confusion matrix plt . figure () plot_confusion_matrix ( cnf_matrix , classes = [ 'bird' , 'cat' , 'dog' , 'hen' , 'pig' ], title = 'Confusion matrix C, without normalization' ) <Figure size 432x288 with 0 Axes> Confusion matrix, without normalization","title":"Step 1: Create the NxN histogram matrix O "},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/cohens_kappa/#example-using-our-competitions-dataset","text":"The above matrix is a multi class confusion matrix . As an example, for the 2nd row, we predicted 4 cats to be birds, and 1 cat to be predicted as hen. More compactly, it can be represented as the matrix \\(C_{2,1}\\) = 4. We can easily reconcile our example above to relate back to our competition: After the biopsy is assigned a Gleason score, it is converted into an ISUP grade on a 1-5 scale . For now, I will include the label 0 because it is the background/non-tissue. What I do next is to take the ground truth and call it y_true which is a series. I then generate a dummy y_pred by using np.random.choice and randomly generate numbers from 0 to 5. train = pd . read_csv ( \"../data/datasets/prostate-cancer-grade-assessment-train.csv\" ) y_true = train . isup_grade y_true y_pred = np . random . choice ( 6 , 10616 , replace = True ) y_pred = pd . Series ( y_pred ) y_pred 0 0 1 0 2 4 3 4 4 0 .. 10611 0 10612 5 10613 0 10614 2 10615 4 Name: isup_grade, Length: 10616, dtype: int64 0 2 1 2 2 4 3 1 4 5 .. 10611 2 10612 2 10613 1 10614 5 10615 1 Length: 10616, dtype: int32 The following confusion matrix, is what we mean by the \"N by N\" (6 by 6) histogram matrix . cm = confusion_matrix ( y_true , y_pred , labels = [ 0 , 1 , 2 , 3 , 4 , 5 ],) plot_confusion_matrix ( cm , classes = [ 0 , 1 , 2 , 3 , 4 , 5 ], title = 'Confusion matrix C, without normalization' ) Confusion matrix, without normalization So far we have settled the first portion, construction the histogram matrix.","title":"Example using our competition's dataset"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/cohens_kappa/#step-2-create-the-weighted-matrix-w","text":"An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted rating scores. The formula is as follows: \\( \\(w_{i,j} = \\dfrac{(i-j)^2}{(N-1)^2}\\) \\) Under Step-2, each element is weighted. Predictions that are further away from actuals are marked harshly than predictions that are closer to actuals. However, I suddenly realized that these animals above have no obvious hierarchy in them. Therefore, it is not correct to say that predicting a cat as a bird is any better/worse off than predicting a cat as hen. Consequently, this is a realization. Because now I start to understand why certain competitions use metrics like quadratic weighted kappa! Consider the same example as animals just now, but instead of animals, we change to isup_grade ). So there is an inherent order within the isup_grade 0 - 5 such that 0 and 1 is closer than 0 and 2, 1 and 2 is closer to 1 and 3 etc. \\( \\(0 > 1 > 2 > 3 > 4 > 5\\) \\) For example, let's use a simplified example: y_true = [2,2,2,1,2,3,4,5,0,1] y_pred = [1,2,4,1,2,3,4,5,0,1] As a result, our purpose of the weighted matrix is to allocate a higher penalty score if our prediction is further away from the actual value. That is, if our isup_grade is 2 but we predicted it as 1 (see the example), then based on our formula above, we have i = 2 and j = 1 (entry \\(C_{2,1}\\) ), the penalty is \\( \\(\\dfrac{(2-1)^2}{(5-1)^2} = 0.0625\\) \\) but if our isup_grade is 2 and we predicted it as 4 (see the example), then the penalty involved is higher \\( \\(\\dfrac{(2-4)^2}{(5-1)^2} = 0.25\\) \\) Indeed, the weight matrix helped us assign a heavier penalty to predicting 2 as 4 than 2 as 1. Lastly, we also observe that the formula will give us 0 for the diagonals of the weighted matrix. This means penalty is 0 whenever we correctly predict something. To calculate weighted matrix in python code, here is the code with reference to Aman Arora . # We construct the weighted matrix starting from a zero matrix, it is like constructing a # list, we usually start from an empty list and add things inside using loops. def weighted_matrix ( N ): weighted = np . zeros (( N , N )) for i in range ( len ( weighted )): for j in range ( len ( weighted )): weighted [ i ][ j ] = float ((( i - j ) ** 2 ) / ( N - 1 ) ** 2 ) return weighted print ( weighted_matrix ( 5 )) [[0. 0.06 0.25 0.56 1. ] [0.06 0. 0.06 0.25 0.56] [0.25 0.06 0. 0.06 0.25] [0.56 0.25 0.06 0. 0.06] [1. 0.56 0.25 0.06 0. ]] Remember, the further away from the diagonal you get, the worse off is your prediction and it will be penalized harder by a bigger weight. As you can easily infer from the weighted matrix above, we use the first row as an example in case one did not understand. Basically, the weighted matrix's first row's first element is 0, because it means we predicted correctly and no penalty is meted out; but as we move further to the left, you can see that the punishment gets harsher and harsher: \\( \\(0 < 0.06 < 0.25 < 0.56 < 1\\) \\)","title":"Step 2: Create the Weighted Matrix w "},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/cohens_kappa/#step-3-create-the-expected-matrix","text":"## dummy example actual = pd . Series ([ 2 , 2 , 2 , 3 , 4 , 5 , 5 , 5 , 5 , 5 ]) pred = pd . Series ([ 2 , 2 , 2 , 3 , 2 , 1 , 1 , 1 , 1 , 3 ]) C = confusion_matrix ( actual , pred ) N = 5 act_hist = np . zeros ([ N ]) for item in actual : act_hist [ item - 1 ] += 1 pred_hist = np . zeros ([ N ]) for item in pred : pred_hist [ item - 1 ] += 1 print ( f 'Actuals value counts: { act_hist } , \\n Prediction value counts: { pred_hist } ' ) Actuals value counts:[0. 3. 1. 1. 5.], Prediction value counts:[4. 4. 2. 0. 0.] This part is the most difficult to understand, especially for someone who has little statistic backgrounds (mind you when I was majoring in applied math back then, I only took one statistic module in my whole tenure.) Googling the idea of expected matrix is not apparently clear to me, but luckily someone pointed to me to read expected frequency of Chi-Square test and then and, there I start to slowly understand. For the purpose of better understanding, we call our actual values to be rater A and our prediction model to be rater B. We want to quantify the agreement between rater A and rater B. Here are some terminologies to get hold of first. There are a total number of \\(k = 5\\) classes in this example; There are a total number of \\(n = 10\\) observations in this example; Define Y to be the random variable that rater A has chosen (aka our actual classes 1,2,3,4,5); and \\(\\widehat{Y}\\) be the random variable that rater \\(B\\) has chosen (aka our predicted classes 1,2,3,4,5 by rater B) \\(r_i\\) be the i-th entry of the column vector for actual value counts shown above, \\(c_i\\) be the i-th entry of the column vector for prediction value counts shown above. Then the probability of rater A choosing class 2 and rater B choosing class 2 for example, is given by \\( \\(P(Y = 2 \\text{ and } \\widehat{Y} = 2) = P(Y = 2) \\cdot P(\\widehat{Y} = 2) = 30\\% \\times 40\\% = 12\\%\\) \\) This is under the assumption that both raters are independent of each other . Note that \\(P(Y = 2) = 30\\%\\) because as we see from the actual value counts of rater \\(A\\) , there are a total of 3 class 2's and therefore the probability of Y being 2 is just the proportion. Similarly, we calculate \\(\\widehat{Y}\\) the same way. In general, the formula of rater A choosing class i and rater B choosing (predicting) class j is given as follows: \\( \\(P(Y = i \\text{ and } \\widehat{Y} = j) = P(Y = i) \\times P (\\widehat{Y} = j)\\) \\) Now the real question comes: On average, if you have \\(n\\) number of points to predict, how many times (what is the frequency) would you expect to see rater A choose class i and rater B choose class j. To reiterate, recall that the probability of the actual class being 1 and (super important word here, it means a joint distribution) and the predicted class to be 1 as well is \\(P(Y = 1 \\text{ and } \\widehat{Y} = 1)\\) , similarly, the probability of the actual class being 1 and the predicted class to be 2 is \\(P(Y = 1 \\text{ and } \\widehat{Y} = 2)\\) . Generalizing, the probability of the actual class being \\(i\\) and the predicted class being \\(j\\) is the joint probability \\( \\(P(Y = i \\text{ and } \\widehat{Y} = j)\\) \\) So the intuition lies here: based on the joint probability above, what is the expected number of times (frequency) that \\(Y = i\\) and \\(\\widehat{Y} = j\\) happened (this means Y is i but rater B predict \\(\\widehat{Y}\\) as j) out of 10 times? Easy, just use \\(n \\times P(Y = i \\text{ and } \\widehat{Y} = j)\\) . So for rater B, our prediction model, by just using theoretical probability , should have \\(n \\times P(Y = i \\text{ and } \\widehat{Y} = j)\\) for each \\(i,j\\) . But in reality, this may not be the case. Reconcile this idea with the classic coin toss example: Example on coin toss: Expected frequency is defined as the number of times that we predict an event will occur based on a calculation using theoretical probabilities. You know how a coin has two sides, heads or tails? That means that the probability of the coin landing on any one side is 50% (or 1/2, because it can land on one side out of two possible sides). If you flip a coin 1,000 times, how many times would you expect to get heads? About half the time, or 500 out of the 1,000 flips. To calculate the expected frequency, all we need to do is multiply the total number of tosses (1,000) by the probability of getting a heads (1/2), and we get 1,000 * 1/2 = 500 heads. if event A has prob of p happening, and sample size of n, then the average or expected number of times that A happens is \\(np\\) . The expected frequency of heads is 500 out of 1,000 total tosses. The expected frequency is based on our knowledge of probability - we haven't actually done any coin tossing. However, if we had enough time on our hands, we could actually flip a coin 1,000 times to experimentally test our prediction. If we did this, we would be calculating the experimental frequency. The experimental frequency is defined as the number of times that we observe an event to occur when we actually perform an experiment, test, or trial in real life. If you flipped a coin 1,000 times and it landed on heads 479 times, then the experimental frequency of heads is 479. But wait - didn't we predict the coin would land on heads 500 times? Why did it actually land on heads only 479 times? Well, the expected frequency was just that - what we expected to happen, based on our knowledge of probability. There are no guarantees when it comes to probability, what we expect to happen might differ from what actually happens. Since we know \\( \\(E_{2,2} = 10 \\times P(Y = 2 \\text{ and } \\widehat{Y} = 2) = 10 \\times P(Y = 2) \\cdot P(\\widehat{Y} = 2) = 10 \\times 30\\% \\times 40\\% = 1.2\\) \\) This \\(E_{2,2}\\) means that we only expect the rater A to choose 2 and rater B to choose 2 at the same time only 1.2 times out of 10 times. In other words, our predicted model classify 2 as 2 1.2 times. However, from our observations in our matrix C (confusion/histogram matrix), rater A choosing 2 and rater B choosing 2 have a frequency of 3! In other words, our predicted model classified 2 as 2 three times! So we kinda exceeded expectation for this particular configuration. \\[C = \\begin{bmatrix} 0 & 0 & 0 & 0 & 0\\\\ 0 & 3 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 0\\\\ 0 & 1 & 0 & 0 & 0\\\\ 4 & 0 & 1 & 0 & 0\\\\ \\end{bmatrix}\\] Let me give you one more example, \\( \\(E_{5,2} = 10 \\times P(Y = 5 \\text{ and } \\widehat{Y} = 2) = 10 \\times P(Y = 5) \\cdot P(\\widehat{Y} = 2) = 10 \\times 50\\% \\times 40\\% = 2\\) \\) This means that we only expect the rater A to choose 5 and rater B to choose 2 at the same time only 2 times out of 10 times! But in reality, our observations say that our rater B classified 5 as 2 zero times! We calculate \\(E_{i,j}\\) given by the formula: \\( \\(E_{i,j} = n \\times P(Y = i \\text{ and } \\widehat{Y} = j) = n \\times P(Y = i) \\times P (\\widehat{Y} = j) = n \\times \\dfrac{r_i}{n} \\times \\dfrac{c_j}{n}\\) \\) \\[E = \\begin{bmatrix} 0 & 0 & 0 & 0 & 0\\\\ 1.2 & 1.2 & 0.6 & 0 & 0 \\\\ 0.4 & 0.4 & 0.2 & 0 & 0\\\\ 0.4 & 0.4 & 0.2 & 0 & 0\\\\ 2 & 2 & 1 & 0 & 0\\\\ \\end{bmatrix}\\] Note \\(r_i \\times c_j\\) is the \\((i,j)\\) entry of the outer product between the actual histogram vector of outcomes (actual value counts) and the predicted histogram vector (prediction value counts). What does the random chance mean here? Simple, it just means that the probability for rater A (actual) to be class i AND for rater B (predicted) to be class j is \\(p\\%\\) (say 10%). Therefore, if we have made 100 predictions, random chance aka the theoratical probability tells us you should only have \\(100 \\times 10\\% = 10\\) predictions to be of this configuration (rater A class i AND rater B class j).","title":"Step 3: Create the Expected Matrix "},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/cohens_kappa/#writing-out-the-expected-matrix-in-python","text":"So to get the expected matrix, E, is calculated assuming that there is no correlation between values. This is calculated as the outer product between the actual histogram vector of outcomes and the predicted histogram vector, normalized such that E and C have the same sum. Note carefully below that we do not need to normalize both, we just need to normalize E to the same sum as C. E = np . outer ( act_hist , pred_hist ) / 10 E C array([[0. , 0. , 0. , 0. , 0. ], [1.2, 1.2, 0.6, 0. , 0. ], [0.4, 0.4, 0.2, 0. , 0. ], [0.4, 0.4, 0.2, 0. , 0. ], [2. , 2. , 1. , 0. , 0. ]]) array([[0, 0, 0, 0, 0], [0, 3, 0, 0, 0], [0, 0, 1, 0, 0], [0, 1, 0, 0, 0], [4, 0, 1, 0, 0]], dtype=int64)","title":"Writing out the expected matrix in python"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/cohens_kappa/#step-4-final-step-weighted-kappa-formula-and-its-python-codes","text":"From these three matrices: E, C and weighted, the quadratic weighted kappa is calculated as: \\[\\kappa = 1 - \\dfrac{\\sum_{i,j}\\text{weighted}_{i,j}C_{i,j}}{\\sum_{i,j}\\text{weighted}_{i,j}E_{i,j}}\\] Note that a higher value generally means your prediction model is way better than a random model, but there is no consensus on which value is really good or bad. \\[\\text{Weighted} = \\begin{bmatrix} 0 & 0.0625 & 0.25 & 0.5625 & 1\\\\ 0.0625 & 0 & 0.0625 & 0.25 & 0.5625 \\\\ 0.25 & 0.0625 & 0 & 0.0625 & 0.25\\\\ 0.5625 & 0.25 & 0.0625 & 0 & 0.0625\\\\ 1 & 0.5625 & 0.25 & 0.0625 & 0\\\\ \\end{bmatrix}\\] The notation \\(\\sum_{i,j}\\text{W}_{i,j}C_{i,j}\\) is just \\( \\(\\sum_{i=1}^{k}\\sum_{j=1}^{k} W_{i,j} C_{i,j} = (W_{1,1}C_{1,1} + W_{1,2}C_{1,2} + ...+ W_{1,k}C_{1,k}) + (W_{2,1}C_{2,1}+...+W_{2,k}C_{2,k}) +...+(W_{k,1}C_{k,1}+...+W_{k,k}C_{k,k})\\) \\) To put our understanding into perspective, consider just one entry \\(W_{5,1}C_{5,1} = 1 \\times 4 = 4\\) . This roughly means that our predicted model classified class 5 as class 1 FOUR times (re: \\(C_{5,1} = 4\\) ), and since class 5 is so far away from class 1, we need to punish this wrong prediction more than the others. And we did see that the corresponding weight \\(W_{5,1} = 1\\) is the highest weight. Consequently, the numerator being \\(\\sum_{i,j}\\text{W}_{i,j}C_{i,j}\\) calculates the total \"penalty cost\" for the rater A (our predicted model), and similarly, \\(\\sum_{i,j}\\text{W}_{i,j}E_{i,j}\\) calculates the total \"penalty cost\" for the rater B (our \"expected\" model). Therefore, you can think both values (num and den) as a cost function, and the lesser the better. And kappa formula tells us, if our \\(\\sum_{i,j}\\text{W}_{i,j}C_{i,j}\\) is significantly smaller than \\(\\sum_{i,j}\\text{W}_{i,j}E_{i,j}\\) , this will yield a very small value of \\( \\(\\dfrac{\\sum_{i,j}\\text{weighted}_{i,j}C_{i,j}}{\\sum_{i,j}\\text{weighted}_{i,j}E_{i,j}}\\) \\) which will yield a very high kappa value - signifying a better model. # Method 1 # apply the weights to the confusion matrix weighted = weighted_matrix ( 5 ) num = np . sum ( np . multiply ( weighted , C )) # apply the weights to the histograms den = np . sum ( np . multiply ( weighted , E )) kappa = 1 - np . divide ( num , den ) kappa -0.13924050632911378 # Method 2 num = 0 den = 0 for i in range ( len ( weighted )): for j in range ( len ( weighted )): num += weighted [ i ][ j ] * C [ i ][ j ] den += weighted [ i ][ j ] * E [ i ][ j ] weighted_kappa = ( 1 - ( num / den )); weighted_kappa -0.13924050632911378 # Method 3: Just use sk learn library cohen_kappa_score ( actual , pred , labels = None , weights = 'quadratic' , sample_weight = None ) -0.13924050632911378 Just a side note that one can also use SK learn's cohen_kappa_score function calculate the quadratic weighted kappa in this competition, with weights set to quadratic. Also please do refer to CPMP's discussion topic for fast QWK computation","title":"Step 4: Final Step: Weighted Kappa formula and Its python codes "},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/confusion_matrix/","text":"# !pip install -q scikit-learn==1.0.1 from typing import List import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns from sklearn import metrics , preprocessing import itertools d = { \"index\" : [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ], \"predicted_y\" : [ \"malignant\" , \"malignant\" , \"benign\" , \"benign\" , \"benign\" , \"benign\" , \"benign\" , \"benign\" , \"benign\" , \"malignant\" , ], \"actual_y\" : [ \"malignant\" , \"malignant\" , \"malignant\" , \"malignant\" , \"malignant\" , \"benign\" , \"benign\" , \"benign\" , \"benign\" , \"benign\" , ], } tumour = pd . DataFrame ( data = d ) d = { \"index\" : [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 ], \"predicted_y\" : [ \"malignant\" , \"malignant\" , \"benign\" , \"benign\" , \"benign\" , \"benign\" , \"benign\" , \"benign\" , \"benign\" , \"malignant\" , \"borderline\" , \"borderline\" ], \"actual_y\" : [ \"malignant\" , \"malignant\" , \"malignant\" , \"malignant\" , \"malignant\" , \"benign\" , \"benign\" , \"benign\" , \"benign\" , \"benign\" , \"borderline\" , \"malignant\" ], } tumour_multiclass = pd . DataFrame ( data = d ) # tumour_multiclass.to_markdown(index=False) Confusion Matrix Before we move on to give the definition of Confusion Matrix, we need to understand the below 4 terminologies. We will use the tumour table as reference. Note Note that actual_y ( \\(y\\) ) and predicted_y ( \\(\\hat{y}\\) ) are used interchangeably with ground_truth and predicted_value respectively. index predicted_y actual_y 1 malignant malignant 2 malignant malignant 3 benign malignant 4 benign malignant 5 benign malignant 6 benign benign 7 benign benign 8 benign benign 9 benign benign 10 malignant benign True Positive (TP) Definition The actual_y is positive label and the predicted_y from the classifier is also positive label. True Negative (TN) Definition The actual_y is negative label and the predicted_y from the classifier is also negative label. False Positive (FP) Definition The actual_y is negative label and the predicted_y from the classifier is also positive label. This is also called the Type 1 Error. False Negative (FN) Definition The actual_y is positive label and the predicted_y from the classifier is also negative label. This is also called the Type 2 Error. Confusion Matrix Definition In binary classification, a confusion matrix is a \\(2 \\times 2\\) matrix 1 which reports the number of false positives, false negatives, true positives, and true negatives. Conventionally, the matrix's first row is made up of TP and FP while the second row is made up of FN and TN. Binary Confusion Matrix, by Hongnan G. This allows more detailed analysis than mere proportion of correct classifications such as Accuracy. As we have seen earlier, Accuracy is not a reliable metric for the real performance of a classifier, because it will yield misleading results if the data set is imbalanced (that is, when the numbers of observations in different classes vary greatly). Warning Based on your use case, it is important to define clearly which is your positive class. In our tumour classification example, I mentioned that is the positive class. Let us see both in action, in the first figure below, we use scikit-learn's confusion matrix class; take note that the confusion matrix in scikit-learn outputs the opposite direction as what we have mentioned: TN, FP, FN, TP. We input the labels=[\"benign\", \"malignant\"] to indicate that malignant is treated as the positive class and vice versa. def plot_confusion_matrix ( y_true : np . ndarray , y_pred : np . ndarray , title : str , labels : List [ str ], tick_labels : List [ str ], ) -> None : \"\"\"Plots a Binary Confusion Matrix. Args: y_true (np.ndarray): the actual labels. y_pred (np.ndarray): the predicted labels. title (str): the title of the plot. tick_labels (List[str]): The labels for the ticks. \"\"\" # Unravel into tn, fp, fn and tp tn , fp , fn , tp = metrics . confusion_matrix ( y_true , y_pred , labels = labels ) . ravel () # reshape into tp, fp, fn, tn - this is personal preference reshaped_cm = np . asarray ([[ tp , fp ], [ fn , tn ]]) # flatten this 2d array cm_flattened = reshaped_cm . flatten () labels = [ \"True Positive\" , \"False Positive\" , \"False Negative\" , \"True Negative\" , ] annot = ( np . asarray ( [ f \" { label } \\n { cm_count } \" for label , cm_count in zip ( labels , cm_flattened ) ] ) ) . reshape ( 2 , 2 ) ax = plt . subplot () heatmap = sns . heatmap ( reshaped_cm , annot = annot , fmt = \"\" , cmap = \"Greens\" , ax = ax , xticklabels = tick_labels , yticklabels = tick_labels , ) ax . set_title ( title ) ax . set_xlabel ( \"Predicted labels\" ) ax . set_ylabel ( \"True labels\" ) plt . show () y_true = tumour . actual_y y_pred = tumour . predicted_y plot_confusion_matrix ( y_true , y_pred , title = \"Confusion Matrix (Malignant as +)\" , labels = [ \"benign\" , \"malignant\" ], tick_labels = [ \"benign\" , \"malignant\" ], ) plot_confusion_matrix ( y_true , y_pred , title = \"Confusion Matrix (Benign as +)\" , labels = [ \"malignant\" , \"benign\" ], tick_labels = [ \"malignant\" , \"benign\" ], ) When to use Confusion Matrix? The Confusion matrix in itself is not a performance measure, but the information that it carries is so valuable that almost all the other classification metrics will need to refer to the confusion matrix. For example, the AUROC score can be calculated from confusion matrix. Benefit Structure We may ask ourselves, if we cannot minimize both FN and FP together at the same time due to a tradeoff, which one should we place more emphasis on? In our case study, we note that since our positive class is malignant, then it is apparent that we want to minimize the False Negatives, because misclassifying a cancer patient as benign yields a higher cost than misclassifying a benign patient as cancer. We introduce a benefit structure as follows: TP: +$10000 FN: -$10000 FP: -$1000 TP+FP: -$100 The above metrics indicates a cost-benefit structure. The cost of the screening costs $100, note that if the doctor say during the visit that you have no cancer, then you won't be send to screen (i.e. TN + FN). Each True Positive will yield us a profit of $10000, each False Negative will cost us $10000, and each FP costs us $1000. Hence, we can easily deduce from the confusion matrix that the cost in our example is: \\[2 * 10000 - 3 * 10000 - 1 * 1000 - 3 * 100\\] Implementation of Confusion Matrix def confusion_matrix_ ( y_true : np . ndarray , y_pred : np . ndarray ) -> np . ndarray : \"\"\"Calculates the confusion matrix. We assume that the inputs are binarized already. This can be used in both binary and multiclass classification provided that we label binarized the multiclass labels. Args: y_true (np.ndarray): the correct labels, shape (n_samples, ) y_pred (np.ndarray): the predicted labels, shape (n_samples, ) Returns: cm (np.ndarray): the confusion matrix, shape (n_classes, n_classes) with [[tp, fp], [fn, tn]] \"\"\" tp , fp , fn , tn = 0 , 0 , 0 , 0 for y_t , y_p in zip ( y_true , y_pred ): # if actual and predicted both are positive class if y_t == y_p == 1 : tp += 1 # if actual and predicted both are negative class elif y_t == y_p == 0 : tn += 1 # if actual is negative and predicted is positive elif y_t == 0 and y_p == 1 : fp += 1 # if actual is positive and predicted is negative elif y_t == 1 and y_p == 0 : fn += 1 cm = np . asarray ([[ tp , fp ], [ fn , tn ]]) return cm y_true = np . asarray ([ 1 , 1 , 0 , 1 , 0 , 0 , 1 , 1 ]) y_pred = np . asarray ([ 1 , 1 , 1 , 0 , 0 , 0 , 1 , 1 ]) tp , fp , fn , tn = confusion_matrix_ ( y_true , y_pred ) . ravel () print ( \"Outcome values : \\n \" , tp , fn , fp , tn ) print ( \"Outcome values : \\n \" , confusion_matrix_ ( y_true , y_pred )) # We can check against `sklearn`'s confusion matrix, set positive class to be positive 1. # Note it returns tn, fp, fn and tp and not tp, fp, fn and tn. tn , fp , fn , tp = metrics . confusion_matrix ( y_true , y_pred , labels = [ 0 , 1 ]) . ravel () print ( \"Confusion matrix : \\n \" , metrics . confusion_matrix ( y_true , y_pred , labels = [ 0 , 1 ]), ) print ( \"Outcome values : \\n \" , tp , fn , fp , tn ) Outcome values : 4 1 1 2 Outcome values : [[4 1] [1 2]] Confusion matrix : [[2 1] [1 4]] Outcome values : 4 1 1 2 Multiclass Confusion Matrix Question Now suppose we add another class to the dataset, how should we then calculate the confusion matrix? We first use scikit-learn to plot it out. index predicted_y actual_y 1 malignant malignant 2 malignant malignant 3 benign malignant 4 benign malignant 5 benign malignant 6 benign benign 7 benign benign 8 benign benign 9 benign benign 10 malignant benign 11 borderline borderline 12 borderline malignant def plot_multiclass_confusion_matrix ( cm , classes , normalize = False , title = \"Confusion matrix\" , cmap = plt . cm . Greens ): \"\"\" Reference: https://datascience.stackexchange.com/questions/40067/ confusion-matrix-three-classes-python This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`. \"\"\" if normalize : cm = cm . astype ( \"float\" ) / cm . sum ( axis = 1 )[:, np . newaxis ] print ( \"Normalized confusion matrix\" ) else : print ( \"Confusion matrix, without normalization\" ) plt . imshow ( cm , interpolation = \"nearest\" , cmap = cmap ) plt . title ( title ) plt . colorbar () tick_marks = np . arange ( len ( classes )) plt . xticks ( tick_marks , classes , rotation = 45 ) plt . yticks ( tick_marks , classes ) fmt = \".2f\" if normalize else \"d\" thresh = cm . max () / 2.0 for i , j in itertools . product ( range ( cm . shape [ 0 ]), range ( cm . shape [ 1 ])): plt . text ( j , i , format ( cm [ i , j ], fmt ), horizontalalignment = \"center\" , color = \"white\" if cm [ i , j ] > thresh else \"black\" , ) plt . ylabel ( \"True label\" ) plt . xlabel ( \"Predicted label\" ) plt . tight_layout () y_true = tumour_multiclass . actual_y y_pred = tumour_multiclass . predicted_y cm_multiclass = metrics . confusion_matrix ( y_true , y_pred , labels = [ \"benign\" , \"borderline\" , \"malignant\" ] ) plot_multiclass_confusion_matrix ( cm_multiclass , classes = [ \"benign\" , \"borderline\" , \"malignant\" ] ) Confusion matrix, without normalization Example Notice that we still can have a \"confusion matrix\" because plotting the above does not require you to define which label is positive or not, we just need labels to plot the values out. Note However, if we were to treat benign as the positive class, and treat both borderline and malignant as the negative class, then we can make sense of the definitions of TP, FP, FN and TN here. In fact, this scheme is called One-vs-Rest and we will have 3 different confusion matrices, parametrized by the number of classes (so if num_classes = n, then there will be n different confusion matrices). The below image illustrates the three different scenarios. Multiclass Confusion Matrix by Hongnan G. The above idea looks simple on paper, but there are a few details that one should know. More specifically, micro-average and macro-average of multiclass evaluation metrics, which we will go through in the next section. Multilabel Confusion Matrix TODO: 1 https://scikit-learn.org/stable/modules/generated/sklearn.metrics.multilabel_confusion_matrix.html \u21a9 \u21a9","title":"Confusion Matrix"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/confusion_matrix/#confusion-matrix","text":"Before we move on to give the definition of Confusion Matrix, we need to understand the below 4 terminologies. We will use the tumour table as reference. Note Note that actual_y ( \\(y\\) ) and predicted_y ( \\(\\hat{y}\\) ) are used interchangeably with ground_truth and predicted_value respectively. index predicted_y actual_y 1 malignant malignant 2 malignant malignant 3 benign malignant 4 benign malignant 5 benign malignant 6 benign benign 7 benign benign 8 benign benign 9 benign benign 10 malignant benign","title":"Confusion Matrix"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/confusion_matrix/#true-positive-tp","text":"Definition The actual_y is positive label and the predicted_y from the classifier is also positive label.","title":"True Positive (TP)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/confusion_matrix/#true-negative-tn","text":"Definition The actual_y is negative label and the predicted_y from the classifier is also negative label.","title":"True Negative (TN)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/confusion_matrix/#false-positive-fp","text":"Definition The actual_y is negative label and the predicted_y from the classifier is also positive label. This is also called the Type 1 Error.","title":"False Positive (FP)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/confusion_matrix/#false-negative-fn","text":"Definition The actual_y is positive label and the predicted_y from the classifier is also negative label. This is also called the Type 2 Error.","title":"False Negative (FN)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/confusion_matrix/#confusion-matrix_1","text":"Definition In binary classification, a confusion matrix is a \\(2 \\times 2\\) matrix 1 which reports the number of false positives, false negatives, true positives, and true negatives. Conventionally, the matrix's first row is made up of TP and FP while the second row is made up of FN and TN. Binary Confusion Matrix, by Hongnan G. This allows more detailed analysis than mere proportion of correct classifications such as Accuracy. As we have seen earlier, Accuracy is not a reliable metric for the real performance of a classifier, because it will yield misleading results if the data set is imbalanced (that is, when the numbers of observations in different classes vary greatly). Warning Based on your use case, it is important to define clearly which is your positive class. In our tumour classification example, I mentioned that is the positive class. Let us see both in action, in the first figure below, we use scikit-learn's confusion matrix class; take note that the confusion matrix in scikit-learn outputs the opposite direction as what we have mentioned: TN, FP, FN, TP. We input the labels=[\"benign\", \"malignant\"] to indicate that malignant is treated as the positive class and vice versa. def plot_confusion_matrix ( y_true : np . ndarray , y_pred : np . ndarray , title : str , labels : List [ str ], tick_labels : List [ str ], ) -> None : \"\"\"Plots a Binary Confusion Matrix. Args: y_true (np.ndarray): the actual labels. y_pred (np.ndarray): the predicted labels. title (str): the title of the plot. tick_labels (List[str]): The labels for the ticks. \"\"\" # Unravel into tn, fp, fn and tp tn , fp , fn , tp = metrics . confusion_matrix ( y_true , y_pred , labels = labels ) . ravel () # reshape into tp, fp, fn, tn - this is personal preference reshaped_cm = np . asarray ([[ tp , fp ], [ fn , tn ]]) # flatten this 2d array cm_flattened = reshaped_cm . flatten () labels = [ \"True Positive\" , \"False Positive\" , \"False Negative\" , \"True Negative\" , ] annot = ( np . asarray ( [ f \" { label } \\n { cm_count } \" for label , cm_count in zip ( labels , cm_flattened ) ] ) ) . reshape ( 2 , 2 ) ax = plt . subplot () heatmap = sns . heatmap ( reshaped_cm , annot = annot , fmt = \"\" , cmap = \"Greens\" , ax = ax , xticklabels = tick_labels , yticklabels = tick_labels , ) ax . set_title ( title ) ax . set_xlabel ( \"Predicted labels\" ) ax . set_ylabel ( \"True labels\" ) plt . show () y_true = tumour . actual_y y_pred = tumour . predicted_y plot_confusion_matrix ( y_true , y_pred , title = \"Confusion Matrix (Malignant as +)\" , labels = [ \"benign\" , \"malignant\" ], tick_labels = [ \"benign\" , \"malignant\" ], ) plot_confusion_matrix ( y_true , y_pred , title = \"Confusion Matrix (Benign as +)\" , labels = [ \"malignant\" , \"benign\" ], tick_labels = [ \"malignant\" , \"benign\" ], )","title":"Confusion Matrix"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/confusion_matrix/#when-to-use-confusion-matrix","text":"The Confusion matrix in itself is not a performance measure, but the information that it carries is so valuable that almost all the other classification metrics will need to refer to the confusion matrix. For example, the AUROC score can be calculated from confusion matrix.","title":"When to use Confusion Matrix?"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/confusion_matrix/#benefit-structure","text":"We may ask ourselves, if we cannot minimize both FN and FP together at the same time due to a tradeoff, which one should we place more emphasis on? In our case study, we note that since our positive class is malignant, then it is apparent that we want to minimize the False Negatives, because misclassifying a cancer patient as benign yields a higher cost than misclassifying a benign patient as cancer. We introduce a benefit structure as follows: TP: +$10000 FN: -$10000 FP: -$1000 TP+FP: -$100 The above metrics indicates a cost-benefit structure. The cost of the screening costs $100, note that if the doctor say during the visit that you have no cancer, then you won't be send to screen (i.e. TN + FN). Each True Positive will yield us a profit of $10000, each False Negative will cost us $10000, and each FP costs us $1000. Hence, we can easily deduce from the confusion matrix that the cost in our example is: \\[2 * 10000 - 3 * 10000 - 1 * 1000 - 3 * 100\\]","title":"Benefit Structure"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/confusion_matrix/#implementation-of-confusion-matrix","text":"def confusion_matrix_ ( y_true : np . ndarray , y_pred : np . ndarray ) -> np . ndarray : \"\"\"Calculates the confusion matrix. We assume that the inputs are binarized already. This can be used in both binary and multiclass classification provided that we label binarized the multiclass labels. Args: y_true (np.ndarray): the correct labels, shape (n_samples, ) y_pred (np.ndarray): the predicted labels, shape (n_samples, ) Returns: cm (np.ndarray): the confusion matrix, shape (n_classes, n_classes) with [[tp, fp], [fn, tn]] \"\"\" tp , fp , fn , tn = 0 , 0 , 0 , 0 for y_t , y_p in zip ( y_true , y_pred ): # if actual and predicted both are positive class if y_t == y_p == 1 : tp += 1 # if actual and predicted both are negative class elif y_t == y_p == 0 : tn += 1 # if actual is negative and predicted is positive elif y_t == 0 and y_p == 1 : fp += 1 # if actual is positive and predicted is negative elif y_t == 1 and y_p == 0 : fn += 1 cm = np . asarray ([[ tp , fp ], [ fn , tn ]]) return cm y_true = np . asarray ([ 1 , 1 , 0 , 1 , 0 , 0 , 1 , 1 ]) y_pred = np . asarray ([ 1 , 1 , 1 , 0 , 0 , 0 , 1 , 1 ]) tp , fp , fn , tn = confusion_matrix_ ( y_true , y_pred ) . ravel () print ( \"Outcome values : \\n \" , tp , fn , fp , tn ) print ( \"Outcome values : \\n \" , confusion_matrix_ ( y_true , y_pred )) # We can check against `sklearn`'s confusion matrix, set positive class to be positive 1. # Note it returns tn, fp, fn and tp and not tp, fp, fn and tn. tn , fp , fn , tp = metrics . confusion_matrix ( y_true , y_pred , labels = [ 0 , 1 ]) . ravel () print ( \"Confusion matrix : \\n \" , metrics . confusion_matrix ( y_true , y_pred , labels = [ 0 , 1 ]), ) print ( \"Outcome values : \\n \" , tp , fn , fp , tn ) Outcome values : 4 1 1 2 Outcome values : [[4 1] [1 2]] Confusion matrix : [[2 1] [1 4]] Outcome values : 4 1 1 2","title":"Implementation of Confusion Matrix"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/confusion_matrix/#multiclass-confusion-matrix","text":"Question Now suppose we add another class to the dataset, how should we then calculate the confusion matrix? We first use scikit-learn to plot it out. index predicted_y actual_y 1 malignant malignant 2 malignant malignant 3 benign malignant 4 benign malignant 5 benign malignant 6 benign benign 7 benign benign 8 benign benign 9 benign benign 10 malignant benign 11 borderline borderline 12 borderline malignant def plot_multiclass_confusion_matrix ( cm , classes , normalize = False , title = \"Confusion matrix\" , cmap = plt . cm . Greens ): \"\"\" Reference: https://datascience.stackexchange.com/questions/40067/ confusion-matrix-three-classes-python This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`. \"\"\" if normalize : cm = cm . astype ( \"float\" ) / cm . sum ( axis = 1 )[:, np . newaxis ] print ( \"Normalized confusion matrix\" ) else : print ( \"Confusion matrix, without normalization\" ) plt . imshow ( cm , interpolation = \"nearest\" , cmap = cmap ) plt . title ( title ) plt . colorbar () tick_marks = np . arange ( len ( classes )) plt . xticks ( tick_marks , classes , rotation = 45 ) plt . yticks ( tick_marks , classes ) fmt = \".2f\" if normalize else \"d\" thresh = cm . max () / 2.0 for i , j in itertools . product ( range ( cm . shape [ 0 ]), range ( cm . shape [ 1 ])): plt . text ( j , i , format ( cm [ i , j ], fmt ), horizontalalignment = \"center\" , color = \"white\" if cm [ i , j ] > thresh else \"black\" , ) plt . ylabel ( \"True label\" ) plt . xlabel ( \"Predicted label\" ) plt . tight_layout () y_true = tumour_multiclass . actual_y y_pred = tumour_multiclass . predicted_y cm_multiclass = metrics . confusion_matrix ( y_true , y_pred , labels = [ \"benign\" , \"borderline\" , \"malignant\" ] ) plot_multiclass_confusion_matrix ( cm_multiclass , classes = [ \"benign\" , \"borderline\" , \"malignant\" ] ) Confusion matrix, without normalization Example Notice that we still can have a \"confusion matrix\" because plotting the above does not require you to define which label is positive or not, we just need labels to plot the values out. Note However, if we were to treat benign as the positive class, and treat both borderline and malignant as the negative class, then we can make sense of the definitions of TP, FP, FN and TN here. In fact, this scheme is called One-vs-Rest and we will have 3 different confusion matrices, parametrized by the number of classes (so if num_classes = n, then there will be n different confusion matrices). The below image illustrates the three different scenarios. Multiclass Confusion Matrix by Hongnan G. The above idea looks simple on paper, but there are a few details that one should know. More specifically, micro-average and macro-average of multiclass evaluation metrics, which we will go through in the next section.","title":"Multiclass Confusion Matrix"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/confusion_matrix/#multilabel-confusion-matrix","text":"TODO: 1 https://scikit-learn.org/stable/modules/generated/sklearn.metrics.multilabel_confusion_matrix.html \u21a9 \u21a9","title":"Multilabel Confusion Matrix"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/","text":"Dependencies and Utils # !pip install -q scikit-learn==1.0.1 from typing import List import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns from sklearn import metrics , preprocessing import itertools from typing import List , Dict , Optional , Union def confusion_matrix_ ( y_true : np . ndarray , y_pred : np . ndarray ) -> np . ndarray : \"\"\"Calculates the confusion matrix. We assume that the inputs are binarized already. This can be used in both binary and multiclass classification provided that we label binarized the multiclass labels. Args: y_true (np.ndarray): the correct labels, shape (n_samples, ) y_pred (np.ndarray): the predicted labels, shape (n_samples, ) Returns: cm (np.ndarray): the confusion matrix, shape (n_classes, n_classes) with [[tp, fp], [fn, tn]] \"\"\" tp , fp , fn , tn = 0 , 0 , 0 , 0 for y_t , y_p in zip ( y_true , y_pred ): # if actual and predicted both are positive class if y_t == y_p == 1 : tp += 1 # if actual and predicted both are negative class elif y_t == y_p == 0 : tn += 1 # if actual is negative and predicted is positive elif y_t == 0 and y_p == 1 : fp += 1 # if actual is positive and predicted is negative elif y_t == 1 and y_p == 0 : fn += 1 cm = np . asarray ([[ tp , fp ], [ fn , tn ]]) return cm def plot_confusion_matrix ( y_true : np . ndarray , y_pred : np . ndarray , title : str , labels : List [ str ], tick_labels : List [ str ], ) -> None : \"\"\"Plots a Binary Confusion Matrix. Args: y_true (np.ndarray): the actual labels. y_pred (np.ndarray): the predicted labels. title (str): the title of the plot. tick_labels (List[str]): The labels for the ticks. \"\"\" # Unravel into tn, fp, fn and tp tn , fp , fn , tp = metrics . confusion_matrix ( y_true , y_pred , labels = labels ) . ravel () # reshape into tp, fp, fn, tn - this is personal preference reshaped_cm = np . asarray ([[ tp , fp ], [ fn , tn ]]) # flatten this 2d array cm_flattened = reshaped_cm . flatten () labels = [ \"True Positive\" , \"False Positive\" , \"False Negative\" , \"True Negative\" , ] annot = ( np . asarray ( [ f \" { label } \\n { cm_count } \" for label , cm_count in zip ( labels , cm_flattened ) ] ) ) . reshape ( 2 , 2 ) ax = plt . subplot () heatmap = sns . heatmap ( reshaped_cm , annot = annot , fmt = \"\" , cmap = \"Greens\" , ax = ax , xticklabels = tick_labels , yticklabels = tick_labels , ) ax . set_title ( title ) ax . set_xlabel ( \"Predicted labels\" ) ax . set_ylabel ( \"True labels\" ) plt . show () Precision Definition Definition Precision measures how many of the samples predicted as positive are actually positive. Mathematically, it is expressed as: \\[\\text{Precision} = \\dfrac{\\text{TP}}{\\text{TP} + \\text{FP}}=P(Y=1 | \\hat{Y} = 1)\\] Probablistic Interpretation Notice that the above definition has a probabilitic interpretation \\(P(Y = 1 | \\hat{Y} = 1)\\) , where \\(Y\\) and \\(\\hat{Y}\\) refers to the actual label and predicted labels respectively. We interpreted precision and recall not as ratios but as estimations of probabilities . Precision is then the estimated probability that a random point selected from the samples are positive. This might be a tough pill to swallow as someone who was never good in statistics but it is just conditional probability. If you try to think a bit further, you can form an intuition as follows: If your classifier \\(h\\) is trained and the last layer is say, sigmoid, which in binary classification, calibrates the logits and turn them into probabilities. Then it can be interpretated that given a randomly chosen point \\(x \\in X_{train}\\) , what is the probability of this point \\(x\\) to be positive given that it is predicted as positive by the classifer? Informally, precision answers the question what proportion of positive predictions was actually correct ? In other words, out of all the positive predictions made by the model, how many of those positive predictions were actually positive when compared to the ground truth? When I learned this back then, it is not immediately obvious what the denominator is doing. Dissecting the formula helps. The loose dynamics is that TP and FP are inversely related, and assuming a fixed threshold, the denominator is fixed as follows: \\[\\text{Predicted Number of Positives} = \\text{TP} + \\text{FP}\\] Thus, minimizing FP is equivalent to maximizing TP, doing so will lead to an increase in precision. Note Just like the confusion matrix, we yield different precision score should we treat benign as the positive class. Example Consider a email company that developed a email spam detector for their uses. There are two outcomes/classes: positive class = spam negative class = not spam From the company's perspective, they will be optimizing precision over recall because they want the spam detector to have minimal False Positives because predicting an not spam (which could be an important email) email as spam is much more costly than predicting a spam email as not spam. Imagine your important emails being put into spam folder by the spam detector?! When to use Precision? When your company needs you to restrict the number of False Positives . Prime examples are email spam prediction. There is a trade-off between precision and recall, and restricting the number of FP may give rise to the increase in FN. So ultimately, bear in mind that it is not simply a matter of restricting the number of False Positives but a matter of use cases in your business setting, on whether achieving lesser FP is more important than achieving a lesser FN . When NOT to use Precision? Danger If you have a precision score of 1, then this means that \\(TP = TP + FP = 1 \\implies FP = 0\\) . This means it can be achieved if your predictions have 0 False Positives, but this does not tell us anything about the False Negatives. When you prioritize recall/sensitivity more than precision for your business needs. You should never ever use precision as a single metric. Implementation of Precision y_true = np . array ([ 1 , 1 , 0 , 1 , 0 , 0 , 1 , 0 , 0 , 1 ]) y_pred = np . array ([ 1 , 1 , 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 ]) tp , fp , fn , tn = confusion_matrix_ ( y_true , y_pred ) . ravel () reighns_precision = tp / ( tp + fp ) print ( f \"our precision: { reighns_precision } \" ) sklearn_precision = metrics . precision_score ( y_true , y_pred , average = \"binary\" ) print ( f \"sklearn precision: { sklearn_precision } \" ) our precision: 0.75 sklearn precision: 0.75 Recall/Sensitivity/True Positive Rate Definition Definition Recall measures the following: out of all the actual positives (say, the real cancer patients), how many of them were identified correctly by the classifier? Mathematically, it is expressed as: \\[\\text{Recall}= \\dfrac{\\text{TP}}{\\text{TP} + \\text{FN}}= P(\\hat{Y}=1 | Y = 1)=1-FNR\\] Probabilistic Interpretation Similarly, we can interpret recall probabilistically like how we did to precision. Recall is the conditional probability of the sample being predicted as positive given that the sample is positive. Note From the formula, we see the denominator to be defined as TP + FN, which is unsurprising as this gives you the actual number of positives. The dynamics is also similar to the one in precision. Example For cancer data modeling, anything that doesn't account for false-negatives is like committing a crime indirectly (a strong statement, but lives are at stake here!). Recall is a better measure than precision in this aspect assuming that the positive class is malignant. positive class = malignant negative class = benign A healthcare company came up with a cancer test kit. Instead of reporting its accuracy, we should examine the recall first as the test kit should have minimum False Negatives because predicting a patient with cancer as benign yields a much higher cost than predicting a healthy patient to have cancer. You really do not want to miss any sick patients, you will see later on how we can tune the decision threshold of a classifier to achieve a higher recall at the expense of lowering precision. When to use Recall? When your company needs you to restrict the number of False Negatives . When to NOT use Recall? Danger If you have a recall score of 1, then this means that \\(TP = TP + FN = 1 \\implies FN = 0\\) ; there are 0 False Negatives, but this does not tell us anything about the False Positives. When you prioritize precision more than recall for your business needs. You almost never ever use recall as a single metric. Implementation of Recall y_true = np . array ([ 1 , 1 , 0 , 1 , 0 , 0 , 1 , 0 , 0 , 1 ]) y_pred = np . array ([ 1 , 1 , 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 ]) tp , fp , fn , tn = confusion_matrix_ ( y_true , y_pred ) . ravel () reighns_recall = tp / ( tp + fn ) print ( f \"our recall: { reighns_recall } \" ) sklearn_recall = metrics . recall_score ( y_true , y_pred , average = \"binary\" ) print ( f \"sklearn recall: { sklearn_recall } \" ) our recall: 0.6 sklearn recall: 0.6 The Precision-Recall Tradeoff Does this term reminisce with the Bias-Variance Tradeoff? More specifically, when we talk about precision and recall in the sections above, we are fixated at one decision threshold of our classifier. One should note that both metrics are parametrized by \\(t\\) , the decision threshold. We can tune our threshold to achieve a better precision or recall, but usually not both, hence the tradeoff. We can read more from Google's Machine Learning Crash Course on Precison and Recall . Specificity/True Negative Rate Definition \\[TNR = \\dfrac{TN}{TN + FP} = P(\\hat{Y} = 0| Y=0) = 1 - FPR\\] False Positive Rate Definition Out of all the real negative classes (negative ground truth), how many were predicted wrongly (predicted as positive from the model). \\[FPR = \\dfrac{FP}{FP + TN}=1-TNR\\] False Negative Rate Definition \\[TNR = \\dfrac{FN}{FN + TP} = 1 - TPR\\] F1-Score Intuition Motivated by the examples above, where using single precision or recall do not tell us much about the whole story. We thus turn to a combination of the above metrics. Penalizes extreme values of precision and recall more than arithmetic mean 1 . Definition Definition The F1 score is the harmonic mean between Precision and Recall, bounded between 0 and 1. \\[F1 = \\dfrac{2(\\text{Precision} \\times \\text{Recall})}{\\text{Precision} + \\text{Recall}}\\] Example TO CITE: For example, imagine that the blood protein levels in diseased people and healthy people are normally distributed with means of 2 g/dL and 1 g/dL respectively. A medical test might measure the level of a certain protein in a blood sample and classify any number above a certain threshold as indicating disease. The experimenter can adjust the threshold (black vertical line in the figure), which will in turn change the false positive rate. Increasing the threshold would result in fewer false positives (and more false negatives), corresponding to a leftward movement on the curve. The actual shape of the curve is determined by how much overlap the two distributions have. Multiclass Classification We can extend the binary classification metrics to a multiclass classification setting. Initially, it is not entirely clear how we should handle precision, recall and f1-score because metrics like False Negatives are not well defined - we simply do not know who is the \"positive\" and \"negative\" class here. It turns out that this is not a problem if we use the One-vs-Rest scheme. We introduce two ways to do so, which is either using micro-averaging, or macro-averaging. Before we go deeper, we first need to understand the notion of One-vs-Rest. Consider a multiclass problem with 3 labels: # Our dataset is as follows label_dict = { \"benign\" : 0 , \"borderline\" : 1 , \"malignant\" : 2 } classes = [ 0 , 1 , 2 ] y_true = np . array ( [ \"benign\" , \"borderline\" , \"malignant\" , \"benign\" , \"borderline\" , \"malignant\" ] ) y_pred = np . array ( [ \"benign\" , \"malignant\" , \"borderline\" , \"benign\" , \"benign\" , \"borderline\" ] ) # Turn them into numbers in the label_dict y_true = np . array ([ label_dict [ label ] for label in y_true ]) y_pred = np . array ([ label_dict [ label ] for label in y_pred ]) We can calculate the metrics (precision etc) for each label indepedently. What we mean here is that we treat an n-class problem as n-binary classification problem, such as the following: Benign as Positive Class If we take benign as positive class, which is represented as 1, and both borderline and malignant as the negative class 0, then logically (even without the fancy term label binarize), we can just simply replace as follows: y_true = [ 0 , 1 , 2 , 0 , 1 , 2 ] -> y_true = [ 1 , 0 , 0 , 1 , 0 , 0 ] y_pred = [ 0 , 2 , 1 , 0 , 0 , 1 ] -> y_pred = [ 1 , 0 , 0 , 1 , 1 , 0 ] where we just replace all 0 (initially benign) to 1, and all 1 and 2 (initially borderline and malignant) to 0 (may be confusing at first). Borderline as Positive Class If we take borderline as positive class, which is represented as 1, and both benign and malignant as the negative class 0, then logically (even without the fancy term label binarize), we can just simply replace as follows: y_true = [ 0 , 1 , 2 , 0 , 1 , 2 ] -> y_true = [ 0 , 1 , 0 , 0 , 1 , 0 ] y_pred = [ 0 , 2 , 1 , 0 , 0 , 1 ] -> y_pred = [ 0 , 0 , 1 , 0 , 0 , 1 ] where we just replace all 1 (initially borderline) to 1, and all 0 and 2 (initially benign and malignant) to 0. Malignant as Positive Class If we take malignant as positive class, which is represented as 2, and both benign and borderline as the negative class 0, then logically (even without the fancy term label binarize), we can just simply replace as follows: y_true = [ 0 , 1 , 2 , 0 , 1 , 2 ] -> y_true = [ 0 , 0 , 1 , 0 , 0 , 1 ] y_pred = [ 0 , 2 , 1 , 0 , 0 , 1 ] -> y_pred = [ 0 , 1 , 0 , 0 , 0 , 0 ] where we just replace all 2 (initially malignant) to 1, and all 0 and 1 (initially benign and borderline) to 0. In this case, we have 3 different confusion matrices, one for each class (diagram). In the example above, we did not mention a crucial technique, which is called label binarizer 1 . We will introduce it in code below. # Our dataset is as follows label_dict = { \"benign\" : 0 , \"borderline\" : 1 , \"malignant\" : 2 } classes = [ 0 , 1 , 2 ] y_true = np . array ( [ \"benign\" , \"borderline\" , \"malignant\" , \"benign\" , \"borderline\" , \"malignant\" ] ) y_pred = np . array ( [ \"benign\" , \"malignant\" , \"borderline\" , \"benign\" , \"benign\" , \"borderline\" ] ) # Turn them into numbers in the label_dict y_true = np . array ([ label_dict [ label ] for label in y_true ]) y_pred = np . array ([ label_dict [ label ] for label in y_pred ]) Label Binarize What we have just done in the previous example is that we binarized both y_true and y_pred . The process of treating each class \\(C_i\\) as an independent class and then applying the \"replacement\" technique is called label binarizing. Label Binarizing, by Hongnan G. Steps to label binarize For each label (0, 1 and 2 here), we call np.where such that whenever the y array has this label, we replace it with 1 (positive class), and 0 otherwise (negative class). binarized_cols = [] for label in classes : binarize_col = np . where ( y_true == label , 1 , 0 ) binarized_cols . append ( binarize_col ) Conventially, we stack them column wise as follows: binarized_cols = np . vstack ( binarized_cols ) binarized_cols = binarized_cols . T Let us look at the binarized array for y_true , notice that the first column [1,0,0,1,0,0] corresponds exactly to the example above when we treat benign as positive class (we can verify the same for the rest). array ([[ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 0 , 0 , 1 ], [ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 0 , 0 , 1 ]]) We note that it is commom practice to label binarize the y values first before passing in for metric calculation. Setup: classes : [0, 1, 2] y_true : ([0, 1, 2, 0, 1, 2]) label_binarized_y : ([[ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 0 , 0 , 1 ], [ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 0 , 0 , 1 ]]) First way: binarized_cols = [] # this is a column wise operation but should eventually show \"transposed\" for label in classes : # in the first loop, label = 0, so replace all instance of 0 in y_true with pos class 1 and others 0 binarize_col = np . where ( y_true == label , 1 , 0 ) binarized_cols . append ( binarize_col ) label_binarized_y = np . vstack ( binarized_cols ) . T [1 0 0 1 0 0] [0 1 0 0 1 0] [0 0 1 0 0 1] Second way: Initialize label_binarized_y with shape (len(y_true), len(classes)) . That is, if y_true is of length 6 elements, and we have 3 classes, then it is necessary that after binarizing (one-hot), we must have \\((6, 3)\\) shape. loop through y_true with enumerate : if we encounter y_true = 0 , then we should have [1, 0, 0] , since we initialized our label_binarized_y as all zeros, then label_binarized_y[y_index] is just [0, 0, 0] , we want to assign the 0-th index (coincides with the class index by the way) as 1, so we do label_binarized_y[y_index][int(each_y_true_element)] = 1 . if we encounter y_true = 1 , then we should have [0, 1, 0] , since we initialized our label_binarized_y as all zeros, then label_binarized_y[y_index] is just [0, 0, 0] , we want to assign the 1-st index (coincides with the class index by the way) as 1, so we do label_binarized_y[y_index][int(each_y_true_element)] = 1 . if we encounter y_true = 2 , then we should have [0, 0, 1] , since we initialized our label_binarized_y as all zeros, then label_binarized_y[y_index] is just [0, 0, 0] , we want to assign the 2-nd index (coincides with the class index by the way) as 1, so we do label_binarized_y[y_index][int(each_y_true_element)] = 1 . label_binarized_y = np . zeros ( shape = ( len ( y_true ), len ( classes ))) # this is a column wise operation but should eventually show \"transposed\" for y_index , each_y_true_element in enumerate ( y_true ): label_binarized_y [ y_index ][ int ( each_y_true_element )] = 1 Macro-Averaging Back to where we ended off, we have 3 confusion matrices, we filled up each cell manually by inspection over which is considered TP, FP, FN or TN. Well, the good news is, with label binarizing done, we can just use our good ol' confusion_matrix_ function done earlier to calculate them for us! We encode the second method, the bad thing about this method is it has less flexibility than the first, if we wish to define \"custom\" positive label then we need to make more changes. For example, if positive label is defined to be 3, then this function can no longer take advantage that the class labels will always be in the form of [0, 1, 2, ...] where we easily index them. # def multiclass_label_binarize( # y: np.ndarray, class_labels: List[int], pos_label=1, neg_label=0 # ): # \"\"\"Binarize labels in one-vs-all fashion. # Args: # y (np.ndarray) Sequence of integer labels to encode # class_labels (array-like) Labels for each class # pos_label (int) Value for positive labels # neg_label (int) Value for negative labels # Returns: # np.ndarray of shape (n_samples, n_classes) Encoded dataset # \"\"\" # if isinstance(y, list): # y = np.asarray(y) # columns = [ # np.where(y == label, pos_label, neg_label) for label in class_labels # ] # label_binarized_y = np.vstack(columns).T # return label_binarized_y def multiclass_label_binarize ( y : np . ndarray , class_labels : List [ int ]): \"\"\"Binarize labels in one-vs-all fashion. Args: y (np.ndarray) Sequence of integer labels to encode class_labels (array-like) Labels for each class, must start from 0 and be in order. Returns: np.ndarray of shape (n_samples, n_classes) Encoded dataset Example: >>> y_true = np.array([0, 1, 2, 0, 1, 2]) >>> class_labels = [0, 1, 2] >>> y_true_binarized = multiclass_label_binarize(y_true, class_labels) >>> from sklearn.preprocessing import label_binarize >>> assert label_binarize(y_true, classes = classes) == y_true_binarized \"\"\" if isinstance ( y , list ): y = np . asarray ( y ) label_binarized_y = np . zeros ( shape = ( len ( y ), len ( class_labels ))) # this is a column wise operation but should eventually show \"transposed\" for y_index , each_y_element in enumerate ( y ): label_binarized_y [ y_index ][ int ( each_y_element )] = 1 return label_binarized_y # Binarize the labels y_true_binarized = multiclass_label_binarize ( y_true , classes ) y_pred_binarized = multiclass_label_binarize ( y_pred , classes ) from sklearn.preprocessing import label_binarize label_binarize ( y_true , classes = classes ) == y_true_binarized array([[ True, True, True], [ True, True, True], [ True, True, True], [ True, True, True], [ True, True, True], [ True, True, True]]) tp_c1 , fp_c1 , fn_c1 , tn_c1 = \\ confusion_matrix_ ( y_true_binarized [:, 0 ], y_pred_binarized [:, 0 ] ) . ravel () tp_c2 , fp_c2 , fn_c2 , tn_c2 = \\ confusion_matrix_ ( y_true_binarized [:, 1 ], y_pred_binarized [:, 1 ] ) . ravel () tp_c3 , fp_c3 , fn_c3 , tn_c3 = \\ confusion_matrix_ ( y_true_binarized [:, 2 ], y_pred_binarized [:, 2 ] ) . ravel () plot_confusion_matrix ( y_true_binarized [:, 0 ], y_pred_binarized [:, 0 ], title = \"Confusion Matrix (Benign as +)\" , labels = [ 0 , 1 ], tick_labels = [ \"not benign\" , \"benign\" ], ) plot_confusion_matrix ( y_true_binarized [:, 1 ], y_pred_binarized [:, 1 ], title = \"Confusion Matrix (Borderline as +)\" , labels = [ 0 , 1 ], tick_labels = [ \"not borderline\" , \"borderline\" ], ) plot_confusion_matrix ( y_true_binarized [:, 2 ], y_pred_binarized [:, 2 ], title = \"Confusion Matrix (Malignant as +)\" , labels = [ 0 , 1 ], tick_labels = [ \"not malignant\" , \"malignant\" ], ) Then Macro-Average is calculated for each confusion matrix, and then averaged over the total number of classes. \\[\\text{Macro-Average Precision} = \\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}P_{i}\\] where \\(P_i\\) is the precision score for each individual confusion matrix for each class. This can be extended for recall and f1 etc. # Macro-Average precision_c1 = tp_c1 / ( tp_c1 + fp_c1 ) # precision for confusion matrix 1 where benign is + precision_c2 = tp_c2 / ( tp_c2 + fp_c2 ) precision_c3 = tp_c3 / ( tp_c3 + fp_c3 ) print ( precision_c1 , precision_c2 , precision_c3 ) print ( f \"Macro-Averaged Precision: { np . sum ([ precision_c1 , precision_c2 , precision_c3 ]) / len ( classes ) } \" ) 0.6666666666666666 0.0 0.0 Macro-Averaged Precision: 0.2222222222222222 Micro-Averaging Similar to Micro-Averaging, we still have 3 confusion matrices, but we first aggregate all the 3 confusion matrices into one single confusion matrices. \\[TP_{\\text{agg}}=\\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}TP_{i}\\] \\[FP_{\\text{agg}}=\\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}FP_{i}\\] \\[FN_{\\text{agg}}=\\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}FN_{i}\\] \\[TN_{\\text{agg}}=\\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}TN_{i}\\] And then once we get the aggregated metrics, we can apply the normal calculation to it. \\[\\text{Precision} = \\frac{TP_{\\text{agg}}}{TP_{\\text{agg}} + FP_{\\text{agg}}}\\] tp_c1 , fp_c1 , fn_c1 , tn_c1 = \\ confusion_matrix_ ( y_true_binarized [:, 0 ], y_pred_binarized [:, 0 ] ) . ravel () tp_c2 , fp_c2 , fn_c2 , tn_c2 = \\ confusion_matrix_ ( y_true_binarized [:, 1 ], y_pred_binarized [:, 1 ] ) . ravel () tp_c3 , fp_c3 , fn_c3 , tn_c3 = \\ confusion_matrix_ ( y_true_binarized [:, 2 ], y_pred_binarized [:, 2 ] ) . ravel () # Aggregation tp_agg = ( tp_c1 + tp_c2 + tp_c3 ) / 3 fp_agg = ( fp_c1 + fp_c2 + fp_c3 ) / 3 fn_agg = ( fn_c1 + fn_c2 + fn_c3 ) / 3 tn_agg = ( tn_c1 + tn_c2 + tn_c3 ) / 3 # Calculate precision using Micro-Averaging print ( f \"Micro-Averaged Precision: { tp_agg / ( tp_agg + fp_agg ) } \" ) Micro-Averaged Precision: 0.3333333333333333 Micro vs Macro The following content is taken from DataScienceExchange 1 . Micro- and macro-averages (for whatever metric) will compute slightly different things, and thus their interpretation differs. A macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average will aggregate the contributions of all classes to compute the average metric. In a multi-class classification setup, micro-average is preferable if you suspect there might be class imbalance (i.e you may have many more examples of one class than of other classes). To illustrate why, take for example precision \\(Pr=\\frac{TP}{(TP+FP)}\\) . Let's imagine you have a One-vs-All (there is only one correct class output per example) multi-class classification system with four classes and the following numbers when tested: Class A: 1 TP and 1 FP Class B: 10 TP and 90 FP Class C: 1 TP and 1 FP Class D: 1 TP and 1 FP You can see easily that \\(Pr_A = Pr_C = Pr_D = 0.5\\) , whereas \\(Pr_B=0.1\\) . A macro-average will then compute: \\(Pr=\\frac{0.5+0.1+0.5+0.5}{4}=0.4\\) A micro-average will compute: \\(Pr=\\frac{1+10+1+1}{2+100+2+2}=0.123\\) These are quite different values for precision. Intuitively, in the macro-average the \"good\" precision (0.5) of classes A, C and D is contributing to maintain a \"decent\" overall precision (0.4). While this is technically true (across classes, the average precision is 0.4), it is a bit misleading, since a large number of examples are not properly classified. These examples predominantly correspond to class B, so they only contribute 1/4 towards the average in spite of constituting 94.3% of your test data. The micro-average will adequately capture this class imbalance, and bring the overall precision average down to 0.123 (more in line with the precision of the dominating class B (0.1)). For computational reasons, it may sometimes be more convenient to compute class averages and then macro-average them. If class imbalance is known to be an issue, there are several ways around it. One is to report not only the macro-average, but also its standard deviation (for 3 or more classes). Another is to compute a weighted macro-average, in which each class contribution to the average is weighted by the relative number of examples available for it. In the above scenario, we obtain: \\(Pr_{macro-mean}={0.25\u00b70.5+0.25\u00b70.1+0.25\u00b70.5+0.25\u00b70.5}=0.4\\) \\(Pr_{macro-stdev}=0.173\\) \\(Pr_{macro-weighted}={0.0189\u00b70.5+0.943\u00b70.1+0.0189\u00b70.5+0.0189\u00b70.5}={0.009+0.094+0.009+0.009}=0.123\\) The large standard deviation (0.173) already tells us that the 0.4 average does not stem from a uniform precision among classes, but it might be just easier to compute the weighted macro-average, which in essence is another way of computing the micro-average. Building our own Classification Report Just like scikit-learn's classification report , we can build our own and test if it correct. The code is made easy to follow such that you can detail each step in details if you do not understand how micro or macro is calculated. def classification_report_ ( y_true : np . ndarray , y_pred : np . ndarray , class_labels : List [ int ], display_labels : Union [ Optional [ List [ str ]], Optional [ List [ int ]]] = None , ) -> Union [ List [ float ], Dict [ str , float ]]: \"\"\"Classification report that reports precision, recall and f1-score. Args: y_true (np.ndarray): Ground truth (correct) target values. y_pred (np.ndarray): Predicted target values. class_labels (List[int]): List of class labels. display_labels: List of display labels. (if None, class_labels is used). Returns: confusion_matrices (List[np.ndarray]): List of confusion matrices. tp_fp_fn_tn (Dict[str, float]): List of true positive, false positive, true negative and false negative values. metrics Dict[str, float]: List of precision, recall and f1-score values. \"\"\" if display_labels is None : # assign display labels to default labels if none is passed in. display_labels = class_labels y_true = np . asarray ( y_true ) y_pred = np . asarray ( y_pred ) y_true_binarized = multiclass_label_binarize ( y_true , class_labels , pos_label = 1 , neg_label = 0 ) y_pred_binarized = multiclass_label_binarize ( y_pred , class_labels , pos_label = 1 , neg_label = 0 ) confusion_matrices : Dict [ str , List [ int ]] = {} tp_fp_fn_tn : Dict [ str , List [ float ]] = {} metrics : Dict [ str , List [ float ]] = {} for index , label in enumerate ( class_labels ): assert ( index == label ), \"Index should coincide with label, \\ if not, please check how your classes are labelled.\" cm = confusion_matrix_ ( y_true_binarized [:, index ], y_pred_binarized [:, index ] ) confusion_matrices [ display_labels [ index ]] = cm tp , fp , fn , tn = cm . ravel () precision = tp / ( tp + fp ) recall = tp / ( tp + fn ) f1 = ( 2 * ( precision * recall ) / ( precision + recall ) if ( precision + recall ) != 0 else 0 ) tp_fp_fn_tn [ display_labels [ index ]] = { \"precision\" : precision , \"recall\" : recall , \"f1\" : f1 , } def calculate_micro_avg ( confusion_matrices ) -> Dict [ str , float ]: \"\"\"Calculate micro average for precision, recall and f1-score. Args: confusion_matrices ([type]): Pass in from local scope. Returns: Dict[str, float]: Dictionary of micro average values. \"\"\" tp_agg , fp_agg , fn_agg , tn_agg = 0 , 0 , 0 , 0 micro_metrics : Dict [ str , List [ float ]] = {} total_count = 0 for cm in confusion_matrices . values (): tp , fp , fn , tn = cm . ravel () tp_agg += tp fp_agg += fp fn_agg += fn tn_agg += tn total_count += 1 assert total_count == len ( class_labels ), \"Denominator total_count should equal number of class labels.\" tp_agg , fp_agg , fn_agg , tn_agg = ( np . asarray ([ tp_agg , fp_agg , fn_agg , tn_agg ]) / total_count ) # aggregation is performed here using numpy broadcasting micro_precision = tp_agg / ( tp_agg + fp_agg ) micro_recall = tp_agg / ( tp_agg + fn_agg ) micro_f1 = ( 2 * ( micro_precision * micro_recall ) / ( micro_precision + micro_recall ) if ( micro_precision + micro_recall ) != 0 else 0 ) return { \"micro_precision\" : micro_precision , \"micro_recall\" : micro_recall , \"micro_f1\" : micro_f1 , } metrics [ \"micro_scores\" ] = calculate_micro_avg ( confusion_matrices ) def calculate_macro_avg ( confusion_matrices ) -> Dict [ str , float ]: \"\"\"Calculate macro average for precision, recall and f1-score. Args: confusion_matrices ([type]): Pass in from local scope. Returns: Dict[str, float]: Dictionary of macro average values. \"\"\" macro_precision , macro_recall , macro_f1 = 0 , 0 , 0 for cm in confusion_matrices . values (): tp , fp , fn , tn = cm . ravel () precision = tp / ( tp + fp ) recall = tp / ( tp + fn ) f1 = ( 2 * ( precision * recall ) / ( precision + recall ) if ( precision + recall ) != 0 else 0 ) macro_precision += precision macro_recall += recall macro_f1 += f1 macro_precision = macro_precision / len ( class_labels ) macro_recall = macro_recall / len ( class_labels ) macro_f1 = macro_f1 / len ( class_labels ) return { \"macro_precision\" : macro_precision , \"macro_recall\" : macro_recall , \"macro_f1\" : macro_f1 , } metrics [ \"macro_scores\" ] = calculate_macro_avg ( confusion_matrices ) return confusion_matrices , tp_fp_fn_tn , metrics confusion_matrices , tp_fp_fn_tn , metrics_report = classification_report_ ( y_true , y_pred , class_labels = classes , display_labels = [ \"benign\" , \"borderline\" , \"malignant\" ], ) sklearn_classification_report = metrics . classification_report ( y_true , y_pred , output_dict = True , labels = classes , target_names = [ \"benign\" , \"borderline\" , \"malignant\" ], ) print ( f \"Our own classification report: { metrics_report } \" ) print ( f \"scikit-learn's classification report: { sklearn_classification_report } \" ) Our own classification report: {'micro_scores': {'micro_precision': 0.3333333333333333, 'micro_recall': 0.3333333333333333, 'micro_f1': 0.3333333333333333}, 'macro_scores': {'macro_precision': 0.2222222222222222, 'macro_recall': 0.3333333333333333, 'macro_f1': 0.26666666666666666}} scikit-learn's classification report: {'benign': {'precision': 0.6666666666666666, 'recall': 1.0, 'f1-score': 0.8, 'support': 2}, 'borderline': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'malignant': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'accuracy': 0.3333333333333333, 'macro avg': {'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1-score': 0.26666666666666666, 'support': 6}, 'weighted avg': {'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1-score': 0.26666666666666666, 'support': 6}} We have successfully coded out classification report to behave the same way as scikit-learn's one. https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html \u21a9 \u21a9 \u21a9","title":"Precision-Recall-F1"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#dependencies-and-utils","text":"# !pip install -q scikit-learn==1.0.1 from typing import List import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns from sklearn import metrics , preprocessing import itertools from typing import List , Dict , Optional , Union def confusion_matrix_ ( y_true : np . ndarray , y_pred : np . ndarray ) -> np . ndarray : \"\"\"Calculates the confusion matrix. We assume that the inputs are binarized already. This can be used in both binary and multiclass classification provided that we label binarized the multiclass labels. Args: y_true (np.ndarray): the correct labels, shape (n_samples, ) y_pred (np.ndarray): the predicted labels, shape (n_samples, ) Returns: cm (np.ndarray): the confusion matrix, shape (n_classes, n_classes) with [[tp, fp], [fn, tn]] \"\"\" tp , fp , fn , tn = 0 , 0 , 0 , 0 for y_t , y_p in zip ( y_true , y_pred ): # if actual and predicted both are positive class if y_t == y_p == 1 : tp += 1 # if actual and predicted both are negative class elif y_t == y_p == 0 : tn += 1 # if actual is negative and predicted is positive elif y_t == 0 and y_p == 1 : fp += 1 # if actual is positive and predicted is negative elif y_t == 1 and y_p == 0 : fn += 1 cm = np . asarray ([[ tp , fp ], [ fn , tn ]]) return cm def plot_confusion_matrix ( y_true : np . ndarray , y_pred : np . ndarray , title : str , labels : List [ str ], tick_labels : List [ str ], ) -> None : \"\"\"Plots a Binary Confusion Matrix. Args: y_true (np.ndarray): the actual labels. y_pred (np.ndarray): the predicted labels. title (str): the title of the plot. tick_labels (List[str]): The labels for the ticks. \"\"\" # Unravel into tn, fp, fn and tp tn , fp , fn , tp = metrics . confusion_matrix ( y_true , y_pred , labels = labels ) . ravel () # reshape into tp, fp, fn, tn - this is personal preference reshaped_cm = np . asarray ([[ tp , fp ], [ fn , tn ]]) # flatten this 2d array cm_flattened = reshaped_cm . flatten () labels = [ \"True Positive\" , \"False Positive\" , \"False Negative\" , \"True Negative\" , ] annot = ( np . asarray ( [ f \" { label } \\n { cm_count } \" for label , cm_count in zip ( labels , cm_flattened ) ] ) ) . reshape ( 2 , 2 ) ax = plt . subplot () heatmap = sns . heatmap ( reshaped_cm , annot = annot , fmt = \"\" , cmap = \"Greens\" , ax = ax , xticklabels = tick_labels , yticklabels = tick_labels , ) ax . set_title ( title ) ax . set_xlabel ( \"Predicted labels\" ) ax . set_ylabel ( \"True labels\" ) plt . show ()","title":"Dependencies and Utils"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#precision","text":"","title":"Precision"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#definition","text":"Definition Precision measures how many of the samples predicted as positive are actually positive. Mathematically, it is expressed as: \\[\\text{Precision} = \\dfrac{\\text{TP}}{\\text{TP} + \\text{FP}}=P(Y=1 | \\hat{Y} = 1)\\] Probablistic Interpretation Notice that the above definition has a probabilitic interpretation \\(P(Y = 1 | \\hat{Y} = 1)\\) , where \\(Y\\) and \\(\\hat{Y}\\) refers to the actual label and predicted labels respectively. We interpreted precision and recall not as ratios but as estimations of probabilities . Precision is then the estimated probability that a random point selected from the samples are positive. This might be a tough pill to swallow as someone who was never good in statistics but it is just conditional probability. If you try to think a bit further, you can form an intuition as follows: If your classifier \\(h\\) is trained and the last layer is say, sigmoid, which in binary classification, calibrates the logits and turn them into probabilities. Then it can be interpretated that given a randomly chosen point \\(x \\in X_{train}\\) , what is the probability of this point \\(x\\) to be positive given that it is predicted as positive by the classifer? Informally, precision answers the question what proportion of positive predictions was actually correct ? In other words, out of all the positive predictions made by the model, how many of those positive predictions were actually positive when compared to the ground truth? When I learned this back then, it is not immediately obvious what the denominator is doing. Dissecting the formula helps. The loose dynamics is that TP and FP are inversely related, and assuming a fixed threshold, the denominator is fixed as follows: \\[\\text{Predicted Number of Positives} = \\text{TP} + \\text{FP}\\] Thus, minimizing FP is equivalent to maximizing TP, doing so will lead to an increase in precision. Note Just like the confusion matrix, we yield different precision score should we treat benign as the positive class. Example Consider a email company that developed a email spam detector for their uses. There are two outcomes/classes: positive class = spam negative class = not spam From the company's perspective, they will be optimizing precision over recall because they want the spam detector to have minimal False Positives because predicting an not spam (which could be an important email) email as spam is much more costly than predicting a spam email as not spam. Imagine your important emails being put into spam folder by the spam detector?!","title":"Definition"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#when-to-use-precision","text":"When your company needs you to restrict the number of False Positives . Prime examples are email spam prediction. There is a trade-off between precision and recall, and restricting the number of FP may give rise to the increase in FN. So ultimately, bear in mind that it is not simply a matter of restricting the number of False Positives but a matter of use cases in your business setting, on whether achieving lesser FP is more important than achieving a lesser FN .","title":"When to use Precision?"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#when-not-to-use-precision","text":"Danger If you have a precision score of 1, then this means that \\(TP = TP + FP = 1 \\implies FP = 0\\) . This means it can be achieved if your predictions have 0 False Positives, but this does not tell us anything about the False Negatives. When you prioritize recall/sensitivity more than precision for your business needs. You should never ever use precision as a single metric.","title":"When NOT to use Precision?"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#implementation-of-precision","text":"y_true = np . array ([ 1 , 1 , 0 , 1 , 0 , 0 , 1 , 0 , 0 , 1 ]) y_pred = np . array ([ 1 , 1 , 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 ]) tp , fp , fn , tn = confusion_matrix_ ( y_true , y_pred ) . ravel () reighns_precision = tp / ( tp + fp ) print ( f \"our precision: { reighns_precision } \" ) sklearn_precision = metrics . precision_score ( y_true , y_pred , average = \"binary\" ) print ( f \"sklearn precision: { sklearn_precision } \" ) our precision: 0.75 sklearn precision: 0.75","title":"Implementation of Precision"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#recallsensitivitytrue-positive-rate","text":"","title":"Recall/Sensitivity/True Positive Rate"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#definition_1","text":"Definition Recall measures the following: out of all the actual positives (say, the real cancer patients), how many of them were identified correctly by the classifier? Mathematically, it is expressed as: \\[\\text{Recall}= \\dfrac{\\text{TP}}{\\text{TP} + \\text{FN}}= P(\\hat{Y}=1 | Y = 1)=1-FNR\\] Probabilistic Interpretation Similarly, we can interpret recall probabilistically like how we did to precision. Recall is the conditional probability of the sample being predicted as positive given that the sample is positive. Note From the formula, we see the denominator to be defined as TP + FN, which is unsurprising as this gives you the actual number of positives. The dynamics is also similar to the one in precision. Example For cancer data modeling, anything that doesn't account for false-negatives is like committing a crime indirectly (a strong statement, but lives are at stake here!). Recall is a better measure than precision in this aspect assuming that the positive class is malignant. positive class = malignant negative class = benign A healthcare company came up with a cancer test kit. Instead of reporting its accuracy, we should examine the recall first as the test kit should have minimum False Negatives because predicting a patient with cancer as benign yields a much higher cost than predicting a healthy patient to have cancer. You really do not want to miss any sick patients, you will see later on how we can tune the decision threshold of a classifier to achieve a higher recall at the expense of lowering precision.","title":"Definition"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#when-to-use-recall","text":"When your company needs you to restrict the number of False Negatives .","title":"When to use Recall?"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#when-to-not-use-recall","text":"Danger If you have a recall score of 1, then this means that \\(TP = TP + FN = 1 \\implies FN = 0\\) ; there are 0 False Negatives, but this does not tell us anything about the False Positives. When you prioritize precision more than recall for your business needs. You almost never ever use recall as a single metric.","title":"When to NOT use Recall?"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#implementation-of-recall","text":"y_true = np . array ([ 1 , 1 , 0 , 1 , 0 , 0 , 1 , 0 , 0 , 1 ]) y_pred = np . array ([ 1 , 1 , 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 ]) tp , fp , fn , tn = confusion_matrix_ ( y_true , y_pred ) . ravel () reighns_recall = tp / ( tp + fn ) print ( f \"our recall: { reighns_recall } \" ) sklearn_recall = metrics . recall_score ( y_true , y_pred , average = \"binary\" ) print ( f \"sklearn recall: { sklearn_recall } \" ) our recall: 0.6 sklearn recall: 0.6","title":"Implementation of Recall"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#the-precision-recall-tradeoff","text":"Does this term reminisce with the Bias-Variance Tradeoff? More specifically, when we talk about precision and recall in the sections above, we are fixated at one decision threshold of our classifier. One should note that both metrics are parametrized by \\(t\\) , the decision threshold. We can tune our threshold to achieve a better precision or recall, but usually not both, hence the tradeoff. We can read more from Google's Machine Learning Crash Course on Precison and Recall .","title":"The Precision-Recall Tradeoff"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#specificitytrue-negative-rate","text":"Definition \\[TNR = \\dfrac{TN}{TN + FP} = P(\\hat{Y} = 0| Y=0) = 1 - FPR\\]","title":"Specificity/True Negative Rate"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#false-positive-rate","text":"Definition Out of all the real negative classes (negative ground truth), how many were predicted wrongly (predicted as positive from the model). \\[FPR = \\dfrac{FP}{FP + TN}=1-TNR\\]","title":"False Positive Rate"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#false-negative-rate","text":"Definition \\[TNR = \\dfrac{FN}{FN + TP} = 1 - TPR\\]","title":"False Negative Rate"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#f1-score","text":"","title":"F1-Score"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#intuition","text":"Motivated by the examples above, where using single precision or recall do not tell us much about the whole story. We thus turn to a combination of the above metrics. Penalizes extreme values of precision and recall more than arithmetic mean 1 .","title":"Intuition"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#definition_2","text":"Definition The F1 score is the harmonic mean between Precision and Recall, bounded between 0 and 1. \\[F1 = \\dfrac{2(\\text{Precision} \\times \\text{Recall})}{\\text{Precision} + \\text{Recall}}\\] Example TO CITE: For example, imagine that the blood protein levels in diseased people and healthy people are normally distributed with means of 2 g/dL and 1 g/dL respectively. A medical test might measure the level of a certain protein in a blood sample and classify any number above a certain threshold as indicating disease. The experimenter can adjust the threshold (black vertical line in the figure), which will in turn change the false positive rate. Increasing the threshold would result in fewer false positives (and more false negatives), corresponding to a leftward movement on the curve. The actual shape of the curve is determined by how much overlap the two distributions have.","title":"Definition"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#multiclass-classification","text":"We can extend the binary classification metrics to a multiclass classification setting. Initially, it is not entirely clear how we should handle precision, recall and f1-score because metrics like False Negatives are not well defined - we simply do not know who is the \"positive\" and \"negative\" class here. It turns out that this is not a problem if we use the One-vs-Rest scheme. We introduce two ways to do so, which is either using micro-averaging, or macro-averaging. Before we go deeper, we first need to understand the notion of One-vs-Rest. Consider a multiclass problem with 3 labels: # Our dataset is as follows label_dict = { \"benign\" : 0 , \"borderline\" : 1 , \"malignant\" : 2 } classes = [ 0 , 1 , 2 ] y_true = np . array ( [ \"benign\" , \"borderline\" , \"malignant\" , \"benign\" , \"borderline\" , \"malignant\" ] ) y_pred = np . array ( [ \"benign\" , \"malignant\" , \"borderline\" , \"benign\" , \"benign\" , \"borderline\" ] ) # Turn them into numbers in the label_dict y_true = np . array ([ label_dict [ label ] for label in y_true ]) y_pred = np . array ([ label_dict [ label ] for label in y_pred ]) We can calculate the metrics (precision etc) for each label indepedently. What we mean here is that we treat an n-class problem as n-binary classification problem, such as the following: Benign as Positive Class If we take benign as positive class, which is represented as 1, and both borderline and malignant as the negative class 0, then logically (even without the fancy term label binarize), we can just simply replace as follows: y_true = [ 0 , 1 , 2 , 0 , 1 , 2 ] -> y_true = [ 1 , 0 , 0 , 1 , 0 , 0 ] y_pred = [ 0 , 2 , 1 , 0 , 0 , 1 ] -> y_pred = [ 1 , 0 , 0 , 1 , 1 , 0 ] where we just replace all 0 (initially benign) to 1, and all 1 and 2 (initially borderline and malignant) to 0 (may be confusing at first). Borderline as Positive Class If we take borderline as positive class, which is represented as 1, and both benign and malignant as the negative class 0, then logically (even without the fancy term label binarize), we can just simply replace as follows: y_true = [ 0 , 1 , 2 , 0 , 1 , 2 ] -> y_true = [ 0 , 1 , 0 , 0 , 1 , 0 ] y_pred = [ 0 , 2 , 1 , 0 , 0 , 1 ] -> y_pred = [ 0 , 0 , 1 , 0 , 0 , 1 ] where we just replace all 1 (initially borderline) to 1, and all 0 and 2 (initially benign and malignant) to 0. Malignant as Positive Class If we take malignant as positive class, which is represented as 2, and both benign and borderline as the negative class 0, then logically (even without the fancy term label binarize), we can just simply replace as follows: y_true = [ 0 , 1 , 2 , 0 , 1 , 2 ] -> y_true = [ 0 , 0 , 1 , 0 , 0 , 1 ] y_pred = [ 0 , 2 , 1 , 0 , 0 , 1 ] -> y_pred = [ 0 , 1 , 0 , 0 , 0 , 0 ] where we just replace all 2 (initially malignant) to 1, and all 0 and 1 (initially benign and borderline) to 0. In this case, we have 3 different confusion matrices, one for each class (diagram). In the example above, we did not mention a crucial technique, which is called label binarizer 1 . We will introduce it in code below. # Our dataset is as follows label_dict = { \"benign\" : 0 , \"borderline\" : 1 , \"malignant\" : 2 } classes = [ 0 , 1 , 2 ] y_true = np . array ( [ \"benign\" , \"borderline\" , \"malignant\" , \"benign\" , \"borderline\" , \"malignant\" ] ) y_pred = np . array ( [ \"benign\" , \"malignant\" , \"borderline\" , \"benign\" , \"benign\" , \"borderline\" ] ) # Turn them into numbers in the label_dict y_true = np . array ([ label_dict [ label ] for label in y_true ]) y_pred = np . array ([ label_dict [ label ] for label in y_pred ])","title":"Multiclass Classification"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#label-binarize","text":"What we have just done in the previous example is that we binarized both y_true and y_pred . The process of treating each class \\(C_i\\) as an independent class and then applying the \"replacement\" technique is called label binarizing. Label Binarizing, by Hongnan G. Steps to label binarize For each label (0, 1 and 2 here), we call np.where such that whenever the y array has this label, we replace it with 1 (positive class), and 0 otherwise (negative class). binarized_cols = [] for label in classes : binarize_col = np . where ( y_true == label , 1 , 0 ) binarized_cols . append ( binarize_col ) Conventially, we stack them column wise as follows: binarized_cols = np . vstack ( binarized_cols ) binarized_cols = binarized_cols . T Let us look at the binarized array for y_true , notice that the first column [1,0,0,1,0,0] corresponds exactly to the example above when we treat benign as positive class (we can verify the same for the rest). array ([[ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 0 , 0 , 1 ], [ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 0 , 0 , 1 ]]) We note that it is commom practice to label binarize the y values first before passing in for metric calculation. Setup: classes : [0, 1, 2] y_true : ([0, 1, 2, 0, 1, 2]) label_binarized_y : ([[ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 0 , 0 , 1 ], [ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 0 , 0 , 1 ]]) First way: binarized_cols = [] # this is a column wise operation but should eventually show \"transposed\" for label in classes : # in the first loop, label = 0, so replace all instance of 0 in y_true with pos class 1 and others 0 binarize_col = np . where ( y_true == label , 1 , 0 ) binarized_cols . append ( binarize_col ) label_binarized_y = np . vstack ( binarized_cols ) . T [1 0 0 1 0 0] [0 1 0 0 1 0] [0 0 1 0 0 1] Second way: Initialize label_binarized_y with shape (len(y_true), len(classes)) . That is, if y_true is of length 6 elements, and we have 3 classes, then it is necessary that after binarizing (one-hot), we must have \\((6, 3)\\) shape. loop through y_true with enumerate : if we encounter y_true = 0 , then we should have [1, 0, 0] , since we initialized our label_binarized_y as all zeros, then label_binarized_y[y_index] is just [0, 0, 0] , we want to assign the 0-th index (coincides with the class index by the way) as 1, so we do label_binarized_y[y_index][int(each_y_true_element)] = 1 . if we encounter y_true = 1 , then we should have [0, 1, 0] , since we initialized our label_binarized_y as all zeros, then label_binarized_y[y_index] is just [0, 0, 0] , we want to assign the 1-st index (coincides with the class index by the way) as 1, so we do label_binarized_y[y_index][int(each_y_true_element)] = 1 . if we encounter y_true = 2 , then we should have [0, 0, 1] , since we initialized our label_binarized_y as all zeros, then label_binarized_y[y_index] is just [0, 0, 0] , we want to assign the 2-nd index (coincides with the class index by the way) as 1, so we do label_binarized_y[y_index][int(each_y_true_element)] = 1 . label_binarized_y = np . zeros ( shape = ( len ( y_true ), len ( classes ))) # this is a column wise operation but should eventually show \"transposed\" for y_index , each_y_true_element in enumerate ( y_true ): label_binarized_y [ y_index ][ int ( each_y_true_element )] = 1","title":"Label Binarize"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#macro-averaging","text":"Back to where we ended off, we have 3 confusion matrices, we filled up each cell manually by inspection over which is considered TP, FP, FN or TN. Well, the good news is, with label binarizing done, we can just use our good ol' confusion_matrix_ function done earlier to calculate them for us! We encode the second method, the bad thing about this method is it has less flexibility than the first, if we wish to define \"custom\" positive label then we need to make more changes. For example, if positive label is defined to be 3, then this function can no longer take advantage that the class labels will always be in the form of [0, 1, 2, ...] where we easily index them. # def multiclass_label_binarize( # y: np.ndarray, class_labels: List[int], pos_label=1, neg_label=0 # ): # \"\"\"Binarize labels in one-vs-all fashion. # Args: # y (np.ndarray) Sequence of integer labels to encode # class_labels (array-like) Labels for each class # pos_label (int) Value for positive labels # neg_label (int) Value for negative labels # Returns: # np.ndarray of shape (n_samples, n_classes) Encoded dataset # \"\"\" # if isinstance(y, list): # y = np.asarray(y) # columns = [ # np.where(y == label, pos_label, neg_label) for label in class_labels # ] # label_binarized_y = np.vstack(columns).T # return label_binarized_y def multiclass_label_binarize ( y : np . ndarray , class_labels : List [ int ]): \"\"\"Binarize labels in one-vs-all fashion. Args: y (np.ndarray) Sequence of integer labels to encode class_labels (array-like) Labels for each class, must start from 0 and be in order. Returns: np.ndarray of shape (n_samples, n_classes) Encoded dataset Example: >>> y_true = np.array([0, 1, 2, 0, 1, 2]) >>> class_labels = [0, 1, 2] >>> y_true_binarized = multiclass_label_binarize(y_true, class_labels) >>> from sklearn.preprocessing import label_binarize >>> assert label_binarize(y_true, classes = classes) == y_true_binarized \"\"\" if isinstance ( y , list ): y = np . asarray ( y ) label_binarized_y = np . zeros ( shape = ( len ( y ), len ( class_labels ))) # this is a column wise operation but should eventually show \"transposed\" for y_index , each_y_element in enumerate ( y ): label_binarized_y [ y_index ][ int ( each_y_element )] = 1 return label_binarized_y # Binarize the labels y_true_binarized = multiclass_label_binarize ( y_true , classes ) y_pred_binarized = multiclass_label_binarize ( y_pred , classes ) from sklearn.preprocessing import label_binarize label_binarize ( y_true , classes = classes ) == y_true_binarized array([[ True, True, True], [ True, True, True], [ True, True, True], [ True, True, True], [ True, True, True], [ True, True, True]]) tp_c1 , fp_c1 , fn_c1 , tn_c1 = \\ confusion_matrix_ ( y_true_binarized [:, 0 ], y_pred_binarized [:, 0 ] ) . ravel () tp_c2 , fp_c2 , fn_c2 , tn_c2 = \\ confusion_matrix_ ( y_true_binarized [:, 1 ], y_pred_binarized [:, 1 ] ) . ravel () tp_c3 , fp_c3 , fn_c3 , tn_c3 = \\ confusion_matrix_ ( y_true_binarized [:, 2 ], y_pred_binarized [:, 2 ] ) . ravel () plot_confusion_matrix ( y_true_binarized [:, 0 ], y_pred_binarized [:, 0 ], title = \"Confusion Matrix (Benign as +)\" , labels = [ 0 , 1 ], tick_labels = [ \"not benign\" , \"benign\" ], ) plot_confusion_matrix ( y_true_binarized [:, 1 ], y_pred_binarized [:, 1 ], title = \"Confusion Matrix (Borderline as +)\" , labels = [ 0 , 1 ], tick_labels = [ \"not borderline\" , \"borderline\" ], ) plot_confusion_matrix ( y_true_binarized [:, 2 ], y_pred_binarized [:, 2 ], title = \"Confusion Matrix (Malignant as +)\" , labels = [ 0 , 1 ], tick_labels = [ \"not malignant\" , \"malignant\" ], ) Then Macro-Average is calculated for each confusion matrix, and then averaged over the total number of classes. \\[\\text{Macro-Average Precision} = \\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}P_{i}\\] where \\(P_i\\) is the precision score for each individual confusion matrix for each class. This can be extended for recall and f1 etc. # Macro-Average precision_c1 = tp_c1 / ( tp_c1 + fp_c1 ) # precision for confusion matrix 1 where benign is + precision_c2 = tp_c2 / ( tp_c2 + fp_c2 ) precision_c3 = tp_c3 / ( tp_c3 + fp_c3 ) print ( precision_c1 , precision_c2 , precision_c3 ) print ( f \"Macro-Averaged Precision: { np . sum ([ precision_c1 , precision_c2 , precision_c3 ]) / len ( classes ) } \" ) 0.6666666666666666 0.0 0.0 Macro-Averaged Precision: 0.2222222222222222","title":"Macro-Averaging"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#micro-averaging","text":"Similar to Micro-Averaging, we still have 3 confusion matrices, but we first aggregate all the 3 confusion matrices into one single confusion matrices. \\[TP_{\\text{agg}}=\\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}TP_{i}\\] \\[FP_{\\text{agg}}=\\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}FP_{i}\\] \\[FN_{\\text{agg}}=\\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}FN_{i}\\] \\[TN_{\\text{agg}}=\\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}TN_{i}\\] And then once we get the aggregated metrics, we can apply the normal calculation to it. \\[\\text{Precision} = \\frac{TP_{\\text{agg}}}{TP_{\\text{agg}} + FP_{\\text{agg}}}\\] tp_c1 , fp_c1 , fn_c1 , tn_c1 = \\ confusion_matrix_ ( y_true_binarized [:, 0 ], y_pred_binarized [:, 0 ] ) . ravel () tp_c2 , fp_c2 , fn_c2 , tn_c2 = \\ confusion_matrix_ ( y_true_binarized [:, 1 ], y_pred_binarized [:, 1 ] ) . ravel () tp_c3 , fp_c3 , fn_c3 , tn_c3 = \\ confusion_matrix_ ( y_true_binarized [:, 2 ], y_pred_binarized [:, 2 ] ) . ravel () # Aggregation tp_agg = ( tp_c1 + tp_c2 + tp_c3 ) / 3 fp_agg = ( fp_c1 + fp_c2 + fp_c3 ) / 3 fn_agg = ( fn_c1 + fn_c2 + fn_c3 ) / 3 tn_agg = ( tn_c1 + tn_c2 + tn_c3 ) / 3 # Calculate precision using Micro-Averaging print ( f \"Micro-Averaged Precision: { tp_agg / ( tp_agg + fp_agg ) } \" ) Micro-Averaged Precision: 0.3333333333333333","title":"Micro-Averaging"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#micro-vs-macro","text":"The following content is taken from DataScienceExchange 1 . Micro- and macro-averages (for whatever metric) will compute slightly different things, and thus their interpretation differs. A macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average will aggregate the contributions of all classes to compute the average metric. In a multi-class classification setup, micro-average is preferable if you suspect there might be class imbalance (i.e you may have many more examples of one class than of other classes). To illustrate why, take for example precision \\(Pr=\\frac{TP}{(TP+FP)}\\) . Let's imagine you have a One-vs-All (there is only one correct class output per example) multi-class classification system with four classes and the following numbers when tested: Class A: 1 TP and 1 FP Class B: 10 TP and 90 FP Class C: 1 TP and 1 FP Class D: 1 TP and 1 FP You can see easily that \\(Pr_A = Pr_C = Pr_D = 0.5\\) , whereas \\(Pr_B=0.1\\) . A macro-average will then compute: \\(Pr=\\frac{0.5+0.1+0.5+0.5}{4}=0.4\\) A micro-average will compute: \\(Pr=\\frac{1+10+1+1}{2+100+2+2}=0.123\\) These are quite different values for precision. Intuitively, in the macro-average the \"good\" precision (0.5) of classes A, C and D is contributing to maintain a \"decent\" overall precision (0.4). While this is technically true (across classes, the average precision is 0.4), it is a bit misleading, since a large number of examples are not properly classified. These examples predominantly correspond to class B, so they only contribute 1/4 towards the average in spite of constituting 94.3% of your test data. The micro-average will adequately capture this class imbalance, and bring the overall precision average down to 0.123 (more in line with the precision of the dominating class B (0.1)). For computational reasons, it may sometimes be more convenient to compute class averages and then macro-average them. If class imbalance is known to be an issue, there are several ways around it. One is to report not only the macro-average, but also its standard deviation (for 3 or more classes). Another is to compute a weighted macro-average, in which each class contribution to the average is weighted by the relative number of examples available for it. In the above scenario, we obtain: \\(Pr_{macro-mean}={0.25\u00b70.5+0.25\u00b70.1+0.25\u00b70.5+0.25\u00b70.5}=0.4\\) \\(Pr_{macro-stdev}=0.173\\) \\(Pr_{macro-weighted}={0.0189\u00b70.5+0.943\u00b70.1+0.0189\u00b70.5+0.0189\u00b70.5}={0.009+0.094+0.009+0.009}=0.123\\) The large standard deviation (0.173) already tells us that the 0.4 average does not stem from a uniform precision among classes, but it might be just easier to compute the weighted macro-average, which in essence is another way of computing the micro-average.","title":"Micro vs Macro"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/precision_recall_f1/#building-our-own-classification-report","text":"Just like scikit-learn's classification report , we can build our own and test if it correct. The code is made easy to follow such that you can detail each step in details if you do not understand how micro or macro is calculated. def classification_report_ ( y_true : np . ndarray , y_pred : np . ndarray , class_labels : List [ int ], display_labels : Union [ Optional [ List [ str ]], Optional [ List [ int ]]] = None , ) -> Union [ List [ float ], Dict [ str , float ]]: \"\"\"Classification report that reports precision, recall and f1-score. Args: y_true (np.ndarray): Ground truth (correct) target values. y_pred (np.ndarray): Predicted target values. class_labels (List[int]): List of class labels. display_labels: List of display labels. (if None, class_labels is used). Returns: confusion_matrices (List[np.ndarray]): List of confusion matrices. tp_fp_fn_tn (Dict[str, float]): List of true positive, false positive, true negative and false negative values. metrics Dict[str, float]: List of precision, recall and f1-score values. \"\"\" if display_labels is None : # assign display labels to default labels if none is passed in. display_labels = class_labels y_true = np . asarray ( y_true ) y_pred = np . asarray ( y_pred ) y_true_binarized = multiclass_label_binarize ( y_true , class_labels , pos_label = 1 , neg_label = 0 ) y_pred_binarized = multiclass_label_binarize ( y_pred , class_labels , pos_label = 1 , neg_label = 0 ) confusion_matrices : Dict [ str , List [ int ]] = {} tp_fp_fn_tn : Dict [ str , List [ float ]] = {} metrics : Dict [ str , List [ float ]] = {} for index , label in enumerate ( class_labels ): assert ( index == label ), \"Index should coincide with label, \\ if not, please check how your classes are labelled.\" cm = confusion_matrix_ ( y_true_binarized [:, index ], y_pred_binarized [:, index ] ) confusion_matrices [ display_labels [ index ]] = cm tp , fp , fn , tn = cm . ravel () precision = tp / ( tp + fp ) recall = tp / ( tp + fn ) f1 = ( 2 * ( precision * recall ) / ( precision + recall ) if ( precision + recall ) != 0 else 0 ) tp_fp_fn_tn [ display_labels [ index ]] = { \"precision\" : precision , \"recall\" : recall , \"f1\" : f1 , } def calculate_micro_avg ( confusion_matrices ) -> Dict [ str , float ]: \"\"\"Calculate micro average for precision, recall and f1-score. Args: confusion_matrices ([type]): Pass in from local scope. Returns: Dict[str, float]: Dictionary of micro average values. \"\"\" tp_agg , fp_agg , fn_agg , tn_agg = 0 , 0 , 0 , 0 micro_metrics : Dict [ str , List [ float ]] = {} total_count = 0 for cm in confusion_matrices . values (): tp , fp , fn , tn = cm . ravel () tp_agg += tp fp_agg += fp fn_agg += fn tn_agg += tn total_count += 1 assert total_count == len ( class_labels ), \"Denominator total_count should equal number of class labels.\" tp_agg , fp_agg , fn_agg , tn_agg = ( np . asarray ([ tp_agg , fp_agg , fn_agg , tn_agg ]) / total_count ) # aggregation is performed here using numpy broadcasting micro_precision = tp_agg / ( tp_agg + fp_agg ) micro_recall = tp_agg / ( tp_agg + fn_agg ) micro_f1 = ( 2 * ( micro_precision * micro_recall ) / ( micro_precision + micro_recall ) if ( micro_precision + micro_recall ) != 0 else 0 ) return { \"micro_precision\" : micro_precision , \"micro_recall\" : micro_recall , \"micro_f1\" : micro_f1 , } metrics [ \"micro_scores\" ] = calculate_micro_avg ( confusion_matrices ) def calculate_macro_avg ( confusion_matrices ) -> Dict [ str , float ]: \"\"\"Calculate macro average for precision, recall and f1-score. Args: confusion_matrices ([type]): Pass in from local scope. Returns: Dict[str, float]: Dictionary of macro average values. \"\"\" macro_precision , macro_recall , macro_f1 = 0 , 0 , 0 for cm in confusion_matrices . values (): tp , fp , fn , tn = cm . ravel () precision = tp / ( tp + fp ) recall = tp / ( tp + fn ) f1 = ( 2 * ( precision * recall ) / ( precision + recall ) if ( precision + recall ) != 0 else 0 ) macro_precision += precision macro_recall += recall macro_f1 += f1 macro_precision = macro_precision / len ( class_labels ) macro_recall = macro_recall / len ( class_labels ) macro_f1 = macro_f1 / len ( class_labels ) return { \"macro_precision\" : macro_precision , \"macro_recall\" : macro_recall , \"macro_f1\" : macro_f1 , } metrics [ \"macro_scores\" ] = calculate_macro_avg ( confusion_matrices ) return confusion_matrices , tp_fp_fn_tn , metrics confusion_matrices , tp_fp_fn_tn , metrics_report = classification_report_ ( y_true , y_pred , class_labels = classes , display_labels = [ \"benign\" , \"borderline\" , \"malignant\" ], ) sklearn_classification_report = metrics . classification_report ( y_true , y_pred , output_dict = True , labels = classes , target_names = [ \"benign\" , \"borderline\" , \"malignant\" ], ) print ( f \"Our own classification report: { metrics_report } \" ) print ( f \"scikit-learn's classification report: { sklearn_classification_report } \" ) Our own classification report: {'micro_scores': {'micro_precision': 0.3333333333333333, 'micro_recall': 0.3333333333333333, 'micro_f1': 0.3333333333333333}, 'macro_scores': {'macro_precision': 0.2222222222222222, 'macro_recall': 0.3333333333333333, 'macro_f1': 0.26666666666666666}} scikit-learn's classification report: {'benign': {'precision': 0.6666666666666666, 'recall': 1.0, 'f1-score': 0.8, 'support': 2}, 'borderline': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'malignant': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'accuracy': 0.3333333333333333, 'macro avg': {'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1-score': 0.26666666666666666, 'support': 6}, 'weighted avg': {'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1-score': 0.26666666666666666, 'support': 6}} We have successfully coded out classification report to behave the same way as scikit-learn's one. https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html \u21a9 \u21a9 \u21a9","title":"Building our own Classification Report"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/","text":"! pip install - q scikit - learn == 1.0.1 import numpy as np import pandas as pd from sklearn.metrics import confusion_matrix , roc_auc_score , brier_score_loss , cohen_kappa_score , make_scorer import itertools from sklearn import datasets import seaborn as sns import matplotlib.pyplot as plt import random from typing import Dict , List from IPython.core.interactiveshell import InteractiveShell InteractiveShell . ast_node_interactivity = \"all\" Receiver operating characteristic (ROC) Intuition Mathematically, ROC graphs are two dimensional graphs in which the x-axis is the False Positive Rate (FPR) and the y-axis, the True Positive Rate (TPR). The curve is parametrized by the parameter \\(\\vec{thr}\\) which represents the threshold of the classifier. The graph also depicts the tradeoffs between TPR and FPR, much like the dilemma of the Bias-Variance tradeoff. Also note that in the ROC space, each point on the graph represents a threshold, and therefore each point can have its own confusion matrix as well. We come up with an example from the Melanoma Competition where we denote a malignant cell to be 1, and benign to be 0. If we treat the malignance class as positive class , and the model you trained on outputs a probability vector (using softmax here) \\([0.7, 0.3]\\) corresponding to class 0 and 1 respectively, the value of 0.3 translates to saying that the image is 30% positive that it is malignant; in other words, it is 70% sure that this image is a benign cell. If we choose the default threshold to be the traditional \\(\\vec{thr}=0.5\\) , then the classifier will label this image as a \\(0\\) . This is because the thresholds defines our hard label from the soft label , and thus anything above the threshold 0.5, will be classified as a positive class 1, and negative class otherwise. If however, you lower your classification threshold, say from 0.5 to 0.2, then our image will become now become positive class, indicating the image's cell to be malignant. Intuitively, the consequence is that more images will be classified to become positive as lowering the threshold will allow the model to predict true more often. The consequence is that the TPR will go up, and so will the FPR. Example: There are 10 ground truth targets of y_true = [1,1,1,0,0,0,0,0,1,0,0] and your model predicts y_pred = [0.6,0.7,0.4,0.6,0.55,0.4,0.3,0.2,0.6,0.1] which if you apply argmax to y_pred, then it will become y_pred_argmax = [1,1,0,1,1,0,0,0,1,0]. The TPR here is given by $\\frac{2}{4}$ since there are 4 positive ground truth, and among the predicted labels, the model correctly classify 2 positives correctly. The FPR is given by $\\frac{3}{6}$ because we gave 3 people the false alarm, predicting them to have cancer whereas they don't. Now if you lower you threshold to 0.2, then you can see that the new predicted label array to be [1,1,1,1,1,1,1,0,1,0] where the new calibrated TPR is $\\frac{3}{4}$ and the FPR is $\\frac{5}{6}$. Therefore, without any proofs, just intuition, one should be convinced that if you lower the threshold, more patients will be classified as positive, consequently, the TPR and FPR both increase. Conversely, if you increase the threshold, then the TPR and FPR will both decrease. This may not hold true in a monotone manner, as wrongly described earlier, as it can jolly well be the TPR or FPR do not change, as can be seen in the diagram in the section Ranking. Definition of ROC Curve Definition: The ROC Curve is a graph that plots the True Positive Rate on the y-axis and False Positive Rate on the x-axis, furthermore, this curve is parametrized by a threshold vector $\\vec{t}$. From Wikipedia: In binary classification, the class prediction for each instance is often made based on a continuous random variable \\(X\\) , which is a \"score\" computed for the instance (e.g. the estimated probability in logistic regression). Given a threshold parameter \\(T\\) , the instance is classified as \"positive\" if \\(X > T\\) , and \"negative\" otherwise. \\(X\\) follows a probability density \\(f_1(x)\\) if the instance actually belongs to class \"positive\", and \\(f_0(x)\\) if otherwise. Therefore, the true positive rate is given by \\(TPR(T) = \\int_{T}^{\\infty}f_1(x)dx\\) and the false positive rate is given by \\(FPR(T) = \\int_{T}^{\\infty}f_0(x)dx\\) . The ROC curve plots parametrically TPR(T) with FPR(T) as the varying parameter. Example: For example, imagine that the blood protein levels in diseased people and healthy people are normally distributed with means of 2 g/dL and 1 g/dL respectively. A medical test might measure the level of a certain protein in a blood sample and classify any number above a certain threshold as indicating disease. The experimenter can adjust the threshold (black vertical line in the figure), which will in turn change the false positive rate. Increasing the threshold would result in fewer false positives (and more false negatives), corresponding to a leftward movement on the curve. The actual shape of the curve is determined by how much overlap the two distributions have. Definition of Area under ROC Curve Definition: The AUROC is thus the area under the ROC Curve. More formally, in the probabilistic perspective of AUC , AUC is the probability of a randomly chosen positive case outranks a randomly chosen negative case based on the classifier. \\[ \\begin{aligned} AUC &= P(f(x+)>f(x\u2212)|\\text{class}(x+)=1, \\text{class}(x\u2212)=0)\\\\ &= \\frac{1}{PN}\\sum_{i=1}^{P}\\sum_{j=1}^{N}1(f(x+)\u2212f(x\u2212)) \\end{aligned} \\] where \\(f(x)\\) : classifier P : # of true positive item, N : # of true negative item Or expressed in another digestable way: The AUC of a classifier is equal to the probability that the classifier will rank a randomly chosen positive example higher than a randomly chosen negative example, i.e. \\(P\\Big(\\text{score}(x^+) > \\text{score}(x^-)\\Big)\\) This line above means that if you randomly take two samples, one positive and one negative, the AUC score, say 0.8, says that the probability of your positive sample being ranked higher (means probability higher) than the negative sample is 0.8. In other words, it measures how well the probability ranks based on their true classes. Thus, it is a threshold-invariant and scale-invariant metrics and only the sequence matters in the predicted probabilities. Based on this property, models with higher AUC indicate better discrimination between the two classes. However, the probabilities output from models with higher AUC don\u2019t always generate well-calibrated probabilities. More information can be found here: Safe Handling Instructions for Probabilistic Classification . Another answer from Stackoverflow, to reference it. Although I'm a bit late to the party, but here's my 5 cents. @FranckDernoncourt (+1) already mentioned possible interpretations of AUC ROC, and my favorite one is the first on his list (I use different wording, but it's the same): the AUC of a classifier is equal to the probability that the classifier will rank a randomly chosen positive example higher than a randomly chosen negative example, i.e. \\(P\\Big(\\text{score}(x^+) > \\text{score}(x^-)\\Big)\\) Consider this example (auc=0.68): Let's try to simulate it: draw random positive and negative examples and then calculate the proportion of cases when positives have greater score than negatives cls = c('P', 'P', 'N', 'P', 'P', 'P', 'N', 'N', 'P', 'N', 'P', 'N', 'P', 'N', 'N', 'N', 'P', 'N', 'P', 'N') score = c(0.9, 0.8, 0.7, 0.6, 0.55, 0.51, 0.49, 0.43, 0.42, 0.39, 0.33, 0.31, 0.23, 0.22, 0.19, 0.15, 0.12, 0.11, 0.04, 0.01) pos = score[cls == 'P'] neg = score[cls == 'N'] set.seed(14) p = replicate(50000, sample(pos, size=1) > sample(neg, size=1)) mean(p) And we get 0.67926. Quite close, isn't it? By the way, in R I typically use ROCR package for drawing ROC curves and calculating AUC. library('ROCR') pred = prediction(score, cls) roc = performance(pred, \"tpr\", \"fpr\") plot(roc, lwd=2, colorize=TRUE) lines(x=c(0, 1), y=c(0, 1), col=\"black\", lwd=1) auc = performance(pred, \"auc\") auc = unlist(auc@y.values) auc AUROC as a Ranking One confusing aspect of ROC space is the ranking system. This can be seen in the notebook I created here. Remember, if you code it out yourself from scratch, then it will be more beneficial as you can understand where ranking come into play (without using sklearn). The algorithm starts from the point where threshold is \\infty or in sklearn it starts with some other number. A threshold of infinity will guarantee that the point starts at (0,0). Thus, our very first point MUST start from the origin in this algorithm. Then assuming we do not consider an infinity number of thresholds, as this is too computationally expensive, we consider say 10 threshold values that we want to test (a common number is the number in the dataset). We divide the 10 values into 0.9,0.8,0.7,...,0.1, (for example only). Then we start from 0.9, the highest threshold, and move down to the lowest, in order (ranking). As we have seen just now, as you lower the threshold, both your TPR and FPR go up. Therefore, if you don't want to get your hands dirty, then the intuition is that if you have ground truth [0,1,1,0] and pred_1 = [0.03,0.99,0.05,0.06] and pred_2 = [0.15,0.92,0.89,0.91] then if you then imagine that your thresholds are given by thres_1 = [infinity,0.99,0.06,0.05,0.03] and thres_2 = [infinity, 0.92,0.91,0.89,0.15] , then you can calculate that the TPR and FPR rate at each of the threshold for both predictions are actually the same, consequently, forming the same ROC curve. (Consider plotting it). The idea here is we do not care what your values of the predictions are, in fact, in neural networks, transforming logits through softmax may not be a well calibrated (refer to my calibrated probability notes) probability anyways. We do however, care about the ranking, as you can see our thresholds are sorted in descending order, noticed that we only need that many thresholds for the dataset because only the thresholds at the predictions matter. If you take a number between 0.06 and 0.99 for the first threshold set, you will notice that between this threshold, the TPR and FPR will always be the same. Therefore, we conclude, without proof, that if two arrays of prediction has the exact same relative order, then the AUC for both predictions will be the same, which means that AUC is invariant to the scale of the predictions, and in fact invariant to any sort of transformation, that preserves the order (i.e. a non-negative linear transformation); (you can have numbers greater than 1 and the AUC will be the same try [100,200,150,160]). A corollary of this is we can\u2019t treat outputs of an AUC-optimized model as the likelihood that it\u2019s true. Some models may be poorly calibrated (eg: its output is always between 0.3 and 0.32) but still achieve a good AUC score because its relative ordering is correct. This is something to look out for when blending together predictions of different models. Furthermore, if you see my notebook example, you can predict wrongly, but still have an AUC of 1. One last thing is about the predictions ordering, there is no rule that your predictions must SORT IN DESCENDING ORDER, for example: This will give you an AUC score of 1, even though it may not seem to predict everything correctly. Because the below order gives rise to the best AUC, which is 1 in this case, and hence this will give you 1 as well. If you switch a few numbers inside y_pred you will notice it can still stay at 1. However, if you reverse the list order, then you will get an AUC of 0 (the opposite of the best). y_true = [ 1 , 1 , 1 , 1 , 1 , 1 , 0 , 0 , 0 , 0 ] y_pred = [ 0.99999 , 0.98 , 0.97 , 0.96 , 0.95 , 0.94 , 0.68139 , 0.50961 , 0.48880 , 0.44951 ] full_score_example = sklearn . metrics . roc_auc_score ( y_true , y_pred ) print ( full_score_example ) -> 1 y_true = [ 1 , 0 , 1 , 1 , 0 ] y_pred = [ 0.5 , 0.25 , 0.2 , 0.3 , 0.1 ] y_pred_same_rank = [ 100 , 25 , 20 , 30 , 10 ] fpr_rank_1 , tpr_rank_1 , threshold_rank_1 = sklearn . metrics . roc_curve ( y_true , y_pred , drop_intermediate = True ) fpr_rank_2 , tpr_rank_2 , threshold_rank_2 = sklearn . metrics . roc_curve ( y_true , y_pred_same_rank , drop_intermediate = True ) roc_rank_1 = sklearn . metrics . roc_auc_score ( y_true = y_true , y_score = y_pred , average = \"macro\" , sample_weight = None , max_fpr = None ) # 0.833 roc_rank_2 = sklearn . metrics . roc_auc_score ( y_true = y_true , y_score = y_pred_same_rank , average = \"macro\" , sample_weight = None , max_fpr = None ) # 0.833 import matplotlib.pyplot as plt plt . figure ( figsize = [ 10 , 9 ]) plt . title ( 'Receiver Operating Characteristic' ) plt . plot ( fpr_rank_1 , tpr_rank_1 , 'b' , label = 'AUC = %0.2f ' % roc_rank_1 ) plt . plot ( fpr_rank_2 , tpr_rank_2 , 'b' , label = 'AUC = %0.2f ' % roc_rank_2 ) plt . legend ( loc = 'lower right' ) plt . plot ([ 0 , 1 ], [ 0 , 1 ], 'r--' ) plt . xlim ([ 0 , 1 ]) plt . ylim ([ 0 , 1 ]) plt . ylabel ( 'True Positive Rate' ) plt . xlabel ( 'False Positive Rate' ) plt . show (); ROC as C-Statistic ROC can be interpreted as c-statistics . ROC AUC has the property that it coincides with the \\(c\\) statistic. The \\(c\\) statistic measures the probability that a positive example is ranked higher than a negative example. In this sense, the ROC AUC answers the question of how well the model discriminates between the two classes. A model with high discrimination is not necessarily well calibrated. Suppose a logistic regression model predicts probabilities of 0.52 for positives and 0.51 for negatives (imagine 10 ground truth where 6 is positive and 4 is negative, then the author meant the associated probabilities with each of these ground truth is 0.52 and 0.51 respectively, for the positive and negative classes). This model has an AUC of 1 (recall you need not predict everything correctly to get an AUC of 1) but the probabilities aren't helpful in the sense of identifying which purported positives are highest-risk. Because all of the positives are assigned the same posterior probability, they can't be differentiated. Moreover, a well-calibrated model will have its maximum ROC AUC fixed by the ratio of positives to negatives in the data. This means that a model which has some very desirable probabilities (i.e. its posterior probabilities match the true probability) has a cap on its performance, and therefore an uncalibrated model could \"dominate\" in terms of ROC AUC. ROC AUC doesn't tell you anything about the costs of different kinds of errors. For example, if you're trying to detect fraud, a 10,000 dollar purchase of uncertain provenance represents a larger potential loss than a 10 dollar purchase. But ROC AUC would treat both events as if they have the same weight -- obviously any reasonable model should be able to distinguish between these two types of error. ROC AUC also tends to be dominated by the \"high FPR\" points. Depending on the application, these points may be the least relevant. Consider the case where the model is used to refer high-risk transactions to experts who will conduct further vetting. There may only be enough humans to assess 50 transactions per unit time; since the most highly-ranked transactions occur on the \"left hand\" size of the ROC curve by definition, this is also the region with the lowest area. So by looking at the whole AUC, you're optimistically biasing your results upwards, i.e. ROC AUC is buoyed by the observations \"to the right\" of the actual set of observations which humans will vet. (Illustration is simple. Draw a vertical line at FPR<0.5 on any ROC curve. The area to left is higher for all such vertical lines.) To avoid this, some people use partial ROC AUC, which has its own host of problems, chief among them that software implementations tend to assume that you're interested in truncation at some value of FPR. But in the case that you care about the top \\(n\\) transactions, this approach is obviously wrong because the top \\(n\\) transactions will happen at different FPR values for different classifiers. Standardization of partial AUC (to preserve the property that AUC < 0.5 is worse than random, 1 is perfect, 0 is worthless) incurs further difficulties. The ROC curve itself is of little interest. \"Dominating\" classifiers can be assessed by AUC. Stochastic equivalence can be assessed by tests of equivalence of ranks. Prof. Harrell's comment drives at a consistent theme of his work, which is that the real question diagnostics should answer is one of risk assessment and utility optimization. Examining ROC AUC tends to encourage selection of truncation points, which should be avoided because it only provides partial information to decision makers. Alternative measures of performance (e.g. log-likelihood) characterize the calibration of the model and proper scoring rules generally have the quality that they encourage honest forecasts. Pros and Cons of AUROC Before we go ham on the Drawbacks of AUROC , we first try to think the following: Food For Thought: I think intuitively you can say that if your model needs to perform equally well on the positive class as the negative class (for example, for classifying images between cats and dogs, you would like the model to perform well on the cats as well as on the dogs. For this you would use the AUROC.) On the other hand, if you're not really interested in how the model performs on the negative class, but just want to make sure every positive prediction is correct (precision), and that you get as many of the positives predicted as positives as possible (recall), then you should choose PRAUC (more with it later). For example, for detecting cancer, you don't care how many of the negative predictions are correct, you want to make sure all the positive predictions are correct, and that you don't miss any. (In fact, in this case missing a cancer would be worse than a false positive so you'd want to put more weight towards recall.) Pros: When your classes are more balanced ROC curves are insensitive to changes in class distribution. Quote unquote from \"The analysis of ROC Curves\", we see that the if the proportion of positive to negative instances changes in a test set, the ROC curves will not change . This is because the AUC is equals to the probability of ranking a random positive example over a random negative example, and by definition this happens after you have drawn a positive and a negative, which indicates that we do not need to know anything about the original distribution and the class proportions. AUROC curve better reflects the total amount of False Positives independent of in which class they come up. We can see this by a simple math example: Essentially, AUROC is measuring the TPR vs FPR ratio: We can interpret it as such \\[TPR:FPR = \\dfrac{TP}{TP + FN} : \\dfrac{FP}{FP+TN} = \\dfrac{TP}{TP+FN} \\times \\dfrac{FP + TN}{FP} = \\dfrac{TP}{|+|} \\times \\dfrac{|-|}{FP}=\\dfrac{|-|}{|+|} \\times \\dfrac{TP}{FP}\\] Pros: Scale Invariant See section on AUROC as a Ranking for code example . AUC measures how well predictions are ranked, rather than their absolute values. This means that your score from the model need not be calibrated into a strict probability. You can predict any score you want. This allows us to compare different classifiers that predict values on a different scale. This can be a con as highlighted in Cons: uncalibrated. Pros: Classification Threshold Invariant AUC measures the quality of the model's predictions irrespective of what classification threshold is chosen. What this means is if you compare an example to accuracy, how do you compute it? You say that if threshold is more than \\(t\\) , then you proceed to calculate the accuracy score - and different threshold gives different accuracies. But in ROC, the nuance is that our final metric is area under the ROC curve, over various (all possible) thresholds \\(t\\) , so as you see, we do not depend on the threshold to calculate the final score! This may be good in the sense that it gives you an overall performance on the binary classifier. This can also be a con when you want to specifically minimize one metric like False Negatives or False Positives. For example, in cancer detection where malignant is the positive class, you will likely want to minimize False Negatives, even if it results in a huge increase in False Positives , then ROC may not be best suited. So if you only have the ROC curve for analysis, then you can choose your threshold according to the curve, in this case we choose the point which maximizes TPR as maximizing TPR is equivalent to minimizng FN. Cons: Imbalanced Imbalanced Data: We examine the case in which the dataset is imbalanced and further assume that the positive class is the minority, (note if you assume positive class is majority, then ROC may perform very well here, so the assumption is that the minority is of the positive class). We assume further that the negative class is 90% and positive class is 10%. Intuitively, in an imbalanced dataset, the model **usually does not have trouble predicting the majority class**, and this suggests that they will often get the negatives correct in this case, leading to a high TN. By looking at the FPR, we notice that $\\frac{FP}{FP + TN}$ suggests that FP will be low and TN will be high simply because of the aforementioned idea that the model will likely get the TN correct, and if TN is high, then the FP is low. Consequently, FPR is high. The following [on why AUC can be misleading](https://stats.stackexchange.com/questions/360017/when-is-an-auc-score-misleadingly-high/360040#360040) One possible reason you can get high AUROC with what some might consider a mediocre prediction is if you have imbalanced data (in favor of the \"zero\" prediction), high recall, and low precision. That is, you're predicting most of the ones at the higher end of your prediction probabilities, but most of the outcomes at the higher end of your prediction probabilities are still zero. This is because the ROC score still gets most of its \"lift\" at the early part of the plot, i.e., for only a small fraction of the zero-predictions. For example, if 5% of the test set are \"ones\" and all of the ones appear in the top 10% of your predictions, then your AUC will be at least 18/19 because, after 18/19 of the zeroes are predicted, already 100% of the ones were predicted. Even if the top 5% are all zeroes. Whether this is a \"bad\" prediction depends on your priorities. If you think that false negatives are terrible and false positives are tolerable, then this prediction is okay. But if it's the opposite, then this prediction is pretty bad. from sklearn.metrics import roc_auc_score import numpy as np import matplotlib.pyplot as plt yTest = [ 0 , 0 , 1 , 1 , 0 , 1 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ] yPredicted = np . linspace ( 0.9 , 0.1 , num = len ( yTest )) print ( yPredicted ) print () imbalanced_roc = roc_auc_score ( yTest , yPredicted ) # ~0.89 print ( f \"roc score: { imbalanced_roc } \" ) print () fpr_imbalanced , tpr_imbalanced , threshold_imbalanced = sklearn . metrics . roc_curve ( yTest , yPredicted , drop_intermediate = True ) print ( f \"fpr: \\n { list ( np . round ( fpr_imbalanced , 3 )) } \" ) print () print ( f \"tpr: \\n { list ( np . round ( tpr_imbalanced , 3 )) } \" ) print () print ( f \"thresholds: \\n { list ( np . round ( threshold_imbalanced , 3 )) } \" ) print () plt . plot ( fpr_imbalanced , tpr_imbalanced ); [0.9 0.87333333 0.84666667 0.82 0.79333333 0.76666667 0.74 0.71333333 0.68666667 0.66 0.63333333 0.60666667 0.58 0.55333333 0.52666667 0.5 0.47333333 0.44666667 0.42 0.39333333 0.36666667 0.34 0.31333333 0.28666667 0.26 0.23333333 0.20666667 0.18 0.15333333 0.12666667 0.1 ] roc score: 0.888888888888889 fpr: [0.0, 0.037, 0.074, 0.074, 0.111, 0.111, 0.185, 0.185, 1.0] tpr: [0.0, 0.0, 0.0, 0.5, 0.5, 0.75, 0.75, 1.0, 1.0] thresholds: [1.9, 0.9, 0.873, 0.82, 0.793, 0.767, 0.713, 0.687, 0.1] This diagram above says a thousand words. Because one perpetual question I had was how does class imbalance really plays a part in giving AUROC an overly optimistic picture. Note that the above I put drop_intermediate=True , which means we are only shown meaningful thresholds. In the thresholds above, we can see the fpr consistently is low, with low tpr at first. Then at the second last point, the fpr is 0.185 and tpr is 1, meaning we classified all positive points correctly. We see that this corresponding threshold is 0.687, and indeed, if we check the yTest and yPredicted, all the 1s have HIGHER probability than 0.687, which is the \"trick here\", thus once the threshold is set to > 0.687, all POSITIVE POINTS will be classified correctly, but this does not mean there is no FP, but now the FP is a lot at the expense, because we predict many as positive but it is actually negative, but fpr will be low, because fpr = fp/fp+tn, and even if fp is high, our tn is very big, pulling our denominator big, and as a result, making fpr seem deceptively low. Cons: Uncalibrated Uncalibrated: A model with high AUROC does not necessarily imply a well calibrated model. By this I mean a model with all extreme predictions for of say, it predicts all positive ground truths to be 0.52 and all negative ground truths to be 0.51. This model has an AUC of 1, but the probabilities aren't helpful in the sense of identifying which purported positives are highest-risk. Because all of the positives are assigned the same posterior probability, they can't be differentiated. Note that models like logistic regression are naturally well calibrated, but models like neural networks output logits, and hence we have to apply `sigmoid` or `softmax` to make it probabilities. Below is the \"phenomenon\" that AUC of 1 but the models look bad. Notice that even though we have a perfect AUROC score of 1, the model is not at all confident with the predictions in the sense that we cannot pin point any two positive labels and say that one of them is of higher probability than the other. If you are not convinced, the below code illustrates the point and the plot shows you. y_true = [ 1 , 0 , 1 , 0 , 1 , 0 , 1 , 0 , 1 , 1 ] y_pred = [ 0.52 , 0.51 , 0.52 , 0.51 , 0.52 , 0.51 , 0.52 , 0.51 , 0.52 , 0.52 ] uncalibrated_roc = sklearn . metrics . roc_auc_score ( y_true , y_pred ) print ( f \"roc score: { uncalibrated_roc } \" ) fpr_uncalibrated , tpr_uncalibrated , threshold_uncalibrated = sklearn . metrics . roc_curve ( y_true , y_pred , drop_intermediate = True ) print ( fpr_uncalibrated , tpr_uncalibrated , threshold_uncalibrated ) # Another example # y_true = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0] # y_pred = [0.99999, 0.98, 0.97, 0.96, 0.95, 0.94, 0.68139, 0.50961, 0.48880, 0.44951] # full_score_example = sklearn.metrics.roc_auc_score(y_true, y_pred) # print(full_score_example) -> 1 roc score: 1.0 [0. 0. 1.] [0. 1. 1.] [1.52 0.52 0.51] import matplotlib.pyplot as plt import seaborn as sns sns . set () plt . figure ( figsize = ( 15 , 7 )) plt . scatter ( fpr_uncalibrated , tpr_uncalibrated , color = \"#0F9D58\" , s = 100 ) plt . plot ( fpr_uncalibrated , tpr_uncalibrated , color = \"#0F9D58\" , label = f \"auc: { uncalibrated_roc } \" ) plt . title ( \"ROC Curve\" , fontsize = 20 ) plt . legend ( loc = 4 ) plt . xlabel ( \"False Positive Rate\" , fontsize = 16 ) plt . ylabel ( \"True Positive Rate\" , fontsize = 16 ); Implementation of ROC and AUC This implementation follows closely to Implementation of ROC - roc-curve-and-auc-from-scratch-in-numpy-visualized - TDS . Step 1: Problem Setup y_true_binary = np . asarray ([ 0 , 0 , 1 , 1 , 0 , 0 , 1 , 1 ]) y_pred_binary = np . asarray ([ 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 ]) We have a binary classification problem with the targets and predictions shown above. We further note that the predictions are probabilities output from the Sigmoid layer in a logistic classifier. y_true_binary = np . asarray ([ 0 , 0 , 1 , 1 , 0 , 0 , 1 , 1 ]) y_pred_binary = np . asarray ([ 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 ]) Step 2: Define Threshold Range For our classifier, our usual default threshold is as such: if y_pred_binary [ i ] > 0.5 : assign y_pred_binary as positive class (+) else : assign y_pred_binary as negative class (-) Then it follows that different thresholds will result to different TPR and FPR. We can discretize our thresholds uniformly. Note that scikit-learn uses a different method to find the thresholds and are more optimized. For starter, we will just set our threshold range from 0 to 1 with uniform interval of 0.1. threshold_range = np . arange ( 0 , 11 , 1 ) / 10 print ( threshold_range ) [0. 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ] Step 3: Classify prediction according to threshold The next step we need to do is to classify our y_pred_binary from probabilities into hard labels, a 0 or 1 label. We create a dictionary y_pred_thresholded which has the threshold as key, and the value is the corresponding hard labels. y_pred_thresholded = { 0.0 : [ 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.1 : [ 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.2 : [ 0 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.3 : [ 0 , 0 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.4 : [ 0 , 0 , 0 , 1 , 1 , 1 , 1 , 1 ], 0.5 : [ 0 , 0 , 0 , 0 , 1 , 1 , 1 , 1 ], 0.6 : [ 0 , 0 , 0 , 0 , 0 , 1 , 1 , 1 ], 0.7 : [ 0 , 0 , 0 , 0 , 0 , 0 , 1 , 1 ], 0.8 : [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 ], 0.9 : [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ], 1.0 : [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ], } y_pred_thresholded : Dict = {} for threshold in threshold_range : if threshold not in y_pred_thresholded : y_pred_thresholded [ threshold ] = [] for y_p in y_pred_binary : if y_p >= threshold : y_pred_thresholded [ threshold ] . append ( 1 ) else : y_pred_thresholded [ threshold ] . append ( 0 ) Step 4: Calculate TPR and FPR Now we calculate the respective TPR and FPR for each thresholds's hard labels against the y_true_binary . We will make use of our reighns_confusion_matrix defined earlier to calculate. tpr_fpr = [ [ 1.0 , 1.0 ], [ 1.0 , 1.0 ], [ 1.0 , 0.75 ], [ 1.0 , 0.5 ], [ 0.75 , 0.5 ], [ 0.5 , 0.5 ], [ 0.5 , 0.25 ], [ 0.5 , 0.0 ], [ 0.25 , 0.0 ], [ 0.0 , 0.0 ], [ 0.0 , 0.0 ], ] where the first element of the inner list is tpr and the second element is fpr . tpr_fpr : Dict = { \"tpr\" : [], \"fpr\" : []} for y_pred in y_pred_thresholded . values (): tp , fp , tn , fn = reighns_confusion_matrix ( y_true_binary , y_pred ) tpr = tp / ( tp + fn ) fpr = fp / ( tn + fp ) tpr_fpr [ \"tpr\" ] . append ( tpr ) tpr_fpr [ \"fpr\" ] . append ( fpr ) print ( tpr_fpr ) {'tpr': [1.0, 1.0, 1.0, 1.0, 0.75, 0.5, 0.5, 0.5, 0.25, 0.0, 0.0], 'fpr': [1.0, 1.0, 0.75, 0.5, 0.5, 0.5, 0.25, 0.0, 0.0, 0.0, 0.0]} Step 5: Plot the points as ROC Curve The main idea of ROC Curve is to plot various pairs of [TPR, FPR] at different threshold on the graph, as shown below. Note that we reversed our tpr and fpr to be in line with Scikit-Learn. It does not affect the end result. import matplotlib.pyplot as plt import seaborn as sns sns . set () plt . figure ( figsize = ( 15 , 7 )) tpr_reighns = tpr_fpr [ \"tpr\" ][:: - 1 ] fpr_reighns = tpr_fpr [ \"fpr\" ][:: - 1 ] plt . scatter ( fpr_reighns , tpr_reighns , color = \"#0F9D58\" , s = 100 ) plt . title ( \"ROC Curve\" , fontsize = 20 ) plt . xlabel ( \"False Positive Rate\" , fontsize = 16 ) plt . ylabel ( \"True Positive Rate\" , fontsize = 16 ); Let us compare to the scikit-learn's version! from sklearn.metrics import roc_curve fpr_sklearn , tpr_sklearn , thresholds_sklearn = roc_curve ( y_true_binary , y_pred_binary ) plt . figure ( figsize = ( 15 , 7 )) plt . scatter ( fpr_sklearn , tpr_sklearn , s = 100 , alpha = 0.5 , color = \"blue\" , label = \"Scikit-learn\" ) plt . scatter ( fpr_reighns , tpr_reighns , color = \"#0F9D58\" , s = 100 , alpha = 0.3 , label = \"Our implementation\" ) plt . title ( \"ROC Curve\" , fontsize = 20 ) plt . xlabel ( \"False Positive Rate\" , fontsize = 16 ) plt . ylabel ( \"True Positive Rate\" , fontsize = 16 ) plt . legend (); Notice that in Scikit-Learn's version, they have 3 less points that us, this is discussed in details in the reference links I appended below. But just know that the end result is the same when we go to AUC! Starting and Ending Point: Notice that the starting point and ending point of the ROC curve always start with (0, 0) and (1, 1). See the `y_pred_thresholded` we got earlier. y_true_binary = np . asarray ([ 0 , 0 , 1 , 1 , 0 , 0 , 1 , 1 ]) y_pred_thresholded = { 0.0 : [ 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.1 : [ 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.2 : [ 0 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.3 : [ 0 , 0 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.4 : [ 0 , 0 , 0 , 1 , 1 , 1 , 1 , 1 ], 0.5 : [ 0 , 0 , 0 , 0 , 1 , 1 , 1 , 1 ], 0.6 : [ 0 , 0 , 0 , 0 , 0 , 1 , 1 , 1 ], 0.7 : [ 0 , 0 , 0 , 0 , 0 , 0 , 1 , 1 ], 0.8 : [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 ], 0.9 : [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ], 1.0 : [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ], } A bit of probing reveals that if you discretize your threshold from 0 to 1 inclusive, then it follows that at the threshold 1, everything is predicted as the negative class as shown, then by definition, TPR is 0 because the numerator of TPR is TP, and there is 0 TP because every single prediction made is of negative class, similarly, FPR is also 0 because the numerator of FPR is FP, and the model did not miss any negatives since it predicted every single one as negative. The same logic can be applied to when the threshold is 0, we instead have FPR and TPR to be both 1. Step 6: Area under ROC Curve In the Implementation of ROC - roc-curve-and-auc-from-scratch-in-numpy-visualized - TDS visualization, we understand that we can approximate AUROC score by \"integrating\" over the rectangles. In a way, this is calculating areas of rectangles under the curve, as follows. rectangle_area = 0 for k in range ( len ( threshold_range )): rectangle_area += ( fpr_reighns [ k + 1 ] - fpr_reighns [ k ]) * tpr_reighns [ k ] if k == ( len ( threshold_range ) - 2 ): break print ( f \"reighns roc_auc_score: { rectangle_area } \" ) from sklearn.metrics import roc_auc_score roc_auc_sklearn = roc_auc_score ( y_true_binary , y_pred_binary ) print ( f \"sklearn roc_auc_score: { roc_auc_sklearn } \" ) reighns roc_auc_score: 0.75 sklearn roc_auc_score: 0.75 # alternatively, we can use np.trapz to calculate the area under the curve. roc_area = np . trapz ( y = tpr_reighns , x = fpr_reighns ) print ( roc_area ) 0.75 Couple ROC with Brier Score https://medium.com/@penggongting/understanding-roc-auc-pros-and-cons-why-is-bier-score-a-great-supplement-c7a0c976b679 Summary AUC is a threshold-free metrics capable of measuring the overall performance of binary classifier. AUC should be used in binary classification. In multinomial classification, one-to-rest AUC would be an option using the average of each class. AUC is a good metric when the rank of output probabilities is of interest. Note that if you have 2 classes, then finding the AUROC of the positive class (class 1) is equivalent to 1 minus the AUROC of the negative class (class 0). This is not true when we deal with PR-curve. Although AUC is powerful, it is not a cure-all. AUC is not suitable for heavily imbalanced class distribution and when the goal is to have well-calibrated probabilities. Models with maximized AUC treat the weight between positive and negative class equally. AUROC would be the metric to use if the goal of the model is to perform equally well on both classes. Image classification between cats & dogs is a good example because the performance on cats is equally important on dogs. AUPRC would be the metric to use if the focus of the model is to identify correctly as many positive samples as possible. Take spam detectors for example, the goal is to find all the possible spams. Regular emails are not of interest at all \u2014 they overshadow the number of positives. There are no defined rules to select the suitable metrics. It really depends on the data and the application. It is important to think thoroughly about the purpose of the model before jumping into the modeling process. One thing to note here is that the PR AUC serves as an alternative metric. If the model doesn\u2019t work after the metric is changed, there are still other remedies to deal with imbalanced data, such as downsampling/upsampling. We\u2019ll cover it later in future posts. SKLEARN Definition of Binary Classification ROC-AUC sklearn.metrics.roc_auc_score(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None) y_score: array-like of shape (n_samples,) or (n_samples, n_classes) Target scores. In the binary and multilabel cases, these can be either probability estimates or non-thresholded decision values (as returned by decision_function on some classifiers). In the multiclass case, these must be probability estimates which sum to 1. The binary case expects a shape (n_samples,), and the scores must be the scores of the class with the greater label. The multiclass and multilabel cases expect a shape (n_samples, n_classes). In the multiclass case, the order of the class scores must correspond to the order of labels, if provided, or else to the numerical or lexicographical order of the labels in y_true. Understanding the binary case is important, it says that the binary case expects a list/array of shape (n_samples,) , a 1d-array, where the scores inside the 1d-array must be the scores of the greater label . In other words, if you have class 0 and 1, then the greater label is np.argmax(0,1) = 1 . As a consequence, it is important that you should only pass the \"positive class\" which is the \"greater label\" here into the y_score . In multiclass, there are two cases, either you provide a labels argument in, say labels = [0,2,1] or labels = [0,1,2] , or if you do not provide, then the y_score will necessarily be in the order of the numerical/alphabetical order of the labels in y_true . In other words, if y_true has 3 unique labels: 0, 1 and 2; then the y_score will be a 2d-array in the form of y_score = [[0.2, 0.3, 0.5],[...],[...]] where y_score[0] = [0.2,0.3,0.5] must correspond to class 1, 2 and 3 respectively, unless otherwise stated in labels . First Interpretation Now ROC curve is a TPR vs FPR graph, and the AUC is the area under the curve literally. To find the ROC-AUC, we need to plot many different pairs of points on the graph, and compute the area under it. As we can see from the above naive and simple example, there are a total of 6 pairs of points to plot. Those are from fpr , tpr respectively --> Allow me to further explain with this example where 1 is the positive class: y_true_1 = [0,0,1,1,0,0,1,1] y_preds_1 = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8] We need to initialize the thresholds with a large number usually - usually roc_curve is written so that ROC point corresponding to the highest threshold (fpr[0], tpr[0]) is always (0, 0) . If this is not the case, a new threshold is created with an arbitrary value of max(y_score)+1 . Therefore, in this case, we get 1.8 as the first threshold. This large number will ensure the fpr, tpr starts at (0,0). Next, when the threshold is \\(T=0.8\\) , then one can see that y_preds_1 has 1 predictions 1, so y_preds_1=[0,0,0,0,0,0,0,1] and hence we can calculate the FPR and TPR: FPR will be 0 because no negative samples 0 are misclassified as 1 in our prediction. TPR will be 0.25 because by definition TPR=TP/TP+FN = 1/1+3=0.25 by definition. Therefore (fpr, tpr) = (0,0.25) \\(T=0.7 \\rightarrow\\) y_preds_1 = [0,0,0,0,0,0,1,1] , same logic, FPR will be 0 cause no negative samples 0 are classified as 1 by our classifier! But TPR will be 0.5 because TPR = TP/TP+FN = 2/2+2 = 0.5. Therefore (fpr, tpr) = (0,0.5) We continue this way until we exhaust all thresholds given [array([1.8, 0.8, 0.7, 0.5, 0.3, 0.1])] . And we plot on the graph. How then, do we calculate the area under this curve? One can refer to the source code auc in sklearn.metrics.auc and see that they used Trapezoidal Rule to solve it. So one have a rough idea, how the ROC-AUC area is computed, and one has to bear in mind that the area is calculated over all thresholds (apparently not the case as sklearn discretized the thresholds to reduce computing time, so you will not see the full range of thresholds here). Precision-Recall Curve Loss function and Decision Function Loss function and decision Function link A decision function is a function which takes a dataset as input and gives a decision as output. What the decision can be depends on the problem at hand. Examples include: Estimation problems: the \"decision\" is the estimate. Hypothesis testing problems: the decision is to reject or not reject the null hypothesis. Think of Linear Regression problems, they are mostly related to hypothesis testing. Classification problems: the decision is to classify a new observation (or observations) into a category. Model selection problems: the decision is to chose one of the candidate models. Typically, there are an infinite number of decision functions available for a problem. If we for instance are interested in estimating the height of Swedish males based on ten observations \\(\\mathbf{x}=(x_1,x_2,\\ldots,x_{10})\\) , we can use any of the following decision functions \\(d(\\mathbf{x})\\) : The sample mean: \\(d(\\mathbf{x})=\\frac{1}{10}\\sum_{i=1}^{10}x_i\\) . The median of the sample: \\(d(\\mathbf{x})=\\mbox{median}(\\mathbf{x})\\) The geometric mean of the sample: \\(d(\\mathbf{x})=\\sqrt[10]{x_1\\cdots x_{10}}\\) The function that always returns 1: \\(d(\\mathbf{x})=1\\) , regardless of the value of \\(\\mathbf{x}\\) . Silly, yes, but it is nevertheless a valid decision function. How then can we determine which of these decision functions to use? One way is to use a loss function , which describes the loss (or cost) associated with all possible decisions. Different decision functions will tend to lead to different types of mistakes. The loss function tells us which type of mistakes we should be more concerned about. The best decision function is the function that yields the lowest expected loss . What is meant by expected loss depends on the setting (in particular, whether we are talking about frequentist or Bayesian statistics). In summary: Decision functions are used to make decisions based on data. Loss functions are used to determine which decision function to use. An extensive study on Precision-Recall Curve Before I start, I will quote Frank Harrell's first and his second article. I will also use the links on stack exchange here and here by Stephan Kolassa . They are really good and the entire intuition is from him, I will almost use his intuition verbatim and everything in this section will be credited to the links above; I just find it too difficult to phrase it in my own words because their answers are perfect. Basically, let me put it up front now: Accuracy, Sensitivity and Specificity are one-sided or conditional versions of classification accuracy. As such they are also discontinuous improper accuracy scores, and optimizing them will result in the wrong model. The confusion matrix and the classification report provide a very detailed analysis of a particular set of predictions. However, the predictions themselves already threw away a lot of information that is contained in the model - to explain this statement further: We consider the example of a logistic regression classifier, used to predict whether a patient has cancer (1, positive class) or not (0, negative class). We defined Y as our response variable, outputting only 1 or 0, while \\(X\\) is the set of predictors. In the case of our cancer classification model, (which we assume to be a logistic regression classifier), we remember that the positive class (class = 1) is the patient has cancer, and the negative class (class = 0) is the patient does not have cancer. And to delve a little deeper, our default classification threshold is: \\(\\begin{equation} Y=\\begin{cases} 1, & \\text{if \\(P(Y=1 ~|~X) \\geq 0.5\\) }\\ 0, & \\text{if \\(P(Y=1~|~X) < 0.5\\) }\\\\ \\end{cases} \\end{equation}\\) which means that whenever our logistic regression outputs a probability of the patient getting cancer is more than \\(0.5\\) , we classify the patient to be in the positive class (predict him/her to have cancer). When we use the LogisticClassifier() to fit and predict, we are actually predicting the probability \\(p(X)\\) , i.e.the probability of the patient having cancer given predictors X; Consequently, we need to further set a threshold, or to make a decision on whether to classify a patient as cancer or benign based on the probability we get from \\( \\(p(X) = \\dfrac{e^{\\beta_0}+\\beta_1X_1+...+\\beta_nX_n}{1+ e^{\\beta_0}+\\beta_1X_1+...+\\beta_nX_n}\\) \\) The threshold is defaulted to 0.5 in predict_proba . As we discussed earlier, most classifiers provide a decision_function or a predict_proba method to assess degrees of certainty about predictions. Making predictions can be seen as thresholding the output of decision_function or predict_proba at a certain fixed point; in binary classification we use 0 for the decision function and 0.5 for predict_proba as default. To fully evaluate the effectiveness of a model, you must examine both precision and recall. Unfortunately, precision and recall are often in tension. That is, improving precision typically reduces recall and vice versa. Explore this notion by looking at the following figure, which shows 30 predictions made by an email classification model. Those to the right of the classification threshold are classified as \"spam\", while those to the left are classified as \"not spam.\" Always remember, do not ever just use a single metric like recall, precision to gauge your classifier. This is because your classifier (say SVM() may somehow trivially classify everything as the positive class, and then you will get 100% recall). When to use Precision-Recall Precision-Recall curves should be used when there is a moderate to large class imbalance. . In particular, when the positive class Precision and recall, however, don't consider true negatives and thus won't be affected by the relative imbalance (which is precisely why they're used for imbalanced datasets). Kaggle Forum As goes for any metric, your metric depends entirely on what I you mean to do with the data. I think intuitively you can say that if your model needs to perform equally well on the positive class as the negative class (for example, for classifying images between cats and dogs, you would like the model to perform well on the cats as well as on the dogs. For this you would use the ROC AUC. On the other hand, if you're not really interested in how the model performs on the negative class, but just want to make sure every positive prediction is correct (precision), and that you get as many of the positives predicted as positives as possible (recall), then you should choose PR AUC. For example, for detecting cancer, you don't care how many of the negative predictions are correct, you want to make sure all the positive predictions are correct, and that you don't miss any. (In fact, in this case missing a cancer would be worse then a false positive so you'd want to put more weight towards recall.) True negatives need to be meaningful for ROC to be a good choice of measure. In his example, if we've got 1,000 pictures of cats and dogs and our model determines whether the picture is a cat (target = 0) or a dog (target = 1), we probably care just as much about getting the cats right as the dogs, and so ROC is a good choice of metric. If instead, we've got a collection of 1,000,000 pictures and we build a model to try to identify the 1,000 dog pictures mixed in it, correctly identifying \"not-dog\" pictures is not quite as useful. Instead, it makes more sense to measure how often a picture is a dog when our model says it's a dog (i.e., precision) and how many of the dogs in the picture set we found (i.e., recall). Perspective: In the cancer example above, your AUROC score might be very bad, simply because your False Positives might be high, as a result of minimizing False Negatives, but your AUPRC might be good, because you are maximizing precision! When NOT to use Precision-Recall Majority Negative: Notice that PR curve does not have TN in their equations, and this implies that PR curves are useful when there are minority positive samples and majority negative samples. But if it is the other way round, with minority negative samples, then PR curve will not tell you useful things. Implementation of PR-Curve The Debate: AUROC vs AUPRC I just finished reading this discussion. They argue that PR AUC is better than ROC AUC on imbalanced dataset. For example, we have 10 samples in test dataset. 9 samples are positive and 1 is negative. We have a terrible model which predicts everything positive. Thus, we will have a metric that TP = 9, FP = 1, TN = 0, FN = 0. Then, Precision = 0.9, Recall = 1.0. The precision and recall are both very high, but we have a poor classifier. On the other hand, TPR = TP/(TP+FN) = 1.0, FPR = FP/(FP+TN) = 1.0. Because the FPR is very high, we can identify that this is not a good classifier. Clearly, ROC is better than PR on imbalanced datasets. Can somebody explain why PR is better? Usually when I do imbalanced models, even balanced models, I look at PR for ALL my classes. In your example, yes, your positive class has P = 0.9 and R = 1.0. But what you should look at are ALL your classes. So for your negative class, your P = 0 and your R = 0. And you usually don't just look at PR scores individually. You want to look at F1-score (F1 macro or F1 micro, depending on your problem) that is a harmonic average of your PR scores for both class 1 and class 0. Your class 1 PR score is super good, but combine that with your class 0 PR score, your F1-score will be TERRIBLE, which is the correct conclusion for your scenario. TL,DR: Look at PR scores for ALL your classes, and combine them with a metric like F1-score to have a realistic conclusion about your model performance. The F1-score for your scenario will be TERRIBLE, which is the correct conclusion for your scenario. Metrics for Multi-Class-Label Classification Most Metrics discussed in Binary Classification can be extended to Multi-Class Classification. Multi-Class ROC Intuition ROC is originally used for Binary Classification only, a natural extension to Multi-Class model is the In multi-class model, we can plot N number of AUC ROC Curves for N number classes using One vs ALL methodology. So for Example, If you have three classes named X, Y and Z, you will have one ROC for X classified against Y and Z, another ROC for Y classified against X and Z, and a third one of Z classified against Y and X. Firstly, you need to make use of the below code in source where we are using the concept of One-Vs-All (ovr) and first thing first, for all y_true labels, we need to label_binarize them. As we can see, we must pass in the y_true and classes in which if our classes are [0,1,2,3,4,5] then we need to specify in the labels argument of roc_auc_curve . If we do not specify, the _encode will help us as well, so it is up to one's preference if your labels order matter. else : # ovr is same as multi-label y_true_multilabel = label_binarize ( y_true , classes = classes ) return _average_binary_score ( _binary_roc_auc_score , y_true_multilabel , y_score , average , sample_weight = sample_weight ) Implementation of OVR Multi-Class ROC Step 1: Problem Setup Multi-Class: 3 classes of 0, 1 and 2. Number of samples: 4 Predictions: output using Softmax import scipy y_true_multiclass = np . asarray ([ 0 , 1 , 2 , 1 ]) y_logit_multiclass = np . asarray ( [ [ 0.0802 , 0.0347 , 0.05 ], [ 0.2640 , - 0.0701 , 0.03 ], [ - 0.0087 , 0.0502 , 0.0039 ], [ 0.0496 , 0.0059 , 0.0123 ], ] ) y_pred_multiclass = scipy . special . softmax ( y_logit_multiclass , axis = 1 ) y_pred_multiclass = np . asarray ( [ [ 0.34 , 0.33 , 0.33 ], [ 0.4 , 0.29 , 0.32 ], [ 0.33 , 0.35 , 0.33 ], [ 0.34 , 0.33 , 0.33 ]] ) Step 2: Binarize We need to binarize the y_true_multiclass . array ([[ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 0 , 0 , 1 ], [ 0 , 1 , 0 ]]) where we need to interpret as follows: Class 1 Class 2 Class 3 1 0 0 0 1 0 0 0 1 0 1 0 where [1,0,0,0] (first column) represents the case where class 1 is the positive class and class 2 and 3 are considered the negative class (both are class 0). Class 1 Preds Class 2 Preds Class 3 Preds 0.34 0.33 0.33 0.4 0.29 0.32 0.33 0.35 0.33 0.34 0.33 0.33 where [0.34, 0.4, 0.33, 0.34] (first column) represents the probability of class 1 being the positive class. And to avoid confusion, the second column [0.33, 0.29, 0.35, 0.33] represents the probability of class 2 being the positive class (class 1). Note that I labelled the above as class 1, 2 and 3 but in our code it is class 0, 1 and 2. This does not affect the ultimate score but just note in case of confusion. y_binarize = sklearn . preprocessing . label_binarize ( y_true_multiclass , classes = [ 0 , 1 , 2 ]) print ( y_binarize ) [[1 0 0] [0 1 0] [0 0 1] [0 1 0]] Step 3: ROC score for each class At this step, we calculate the ROC score for each class. We have have 3 different scores, one for each class. That is to say, the first score is class 0 vs the rest, where we treated class 0 as the positive class. num_classes = 3 fpr_dict = dict () tpr_dict = dict () threshold_dict = dict () roc_auc_dict = dict () for label_num in range ( num_classes ): y_true_for_curr_class = y_binarize [:, label_num ] y_pred_for_curr_class = y_pred_multiclass [:, label_num ] # calculate fpr,tpr and thresholds across various decision thresholds; pos_label = 1 because one hot encode guarantees it fpr_dict [ label_num ], tpr_dict [ label_num ], threshold_dict [ label_num ] = sklearn . metrics . roc_curve ( y_true = y_true_for_curr_class , y_score = y_pred_for_curr_class , pos_label = 1 ) roc_auc_dict [ label_num ] = sklearn . metrics . auc ( fpr_dict [ label_num ], tpr_dict [ label_num ]) print ( f \"ROC score for class { label_num } is { roc_auc_dict [ label_num ] } . \\n Note we are considering class { label_num } as the positive class and treating other classes as negative class. \\n \" ) print ( fpr_dict ) print ( tpr_dict ) print ( threshold_dict ) ROC score for class 0 is 0.5. Note we are considering class 0 as the positive class and treating other classes as negative class. ROC score for class 1 is 0.125. Note we are considering class 1 as the positive class and treating other classes as negative class. ROC score for class 2 is 0.6666666666666667. Note we are considering class 2 as the positive class and treating other classes as negative class. {0: array([0. , 0.33333333, 0.66666667, 1. ]), 1: array([0. , 0.5, 1. , 1. ]), 2: array([0. , 0.66666667, 1. ])} {0: array([0., 0., 1., 1.]), 1: array([0. , 0. , 0.5, 1. ]), 2: array([0., 1., 1.])} {0: array([1.4 , 0.4 , 0.34, 0.33]), 1: array([1.35, 0.35, 0.33, 0.29]), 2: array([1.33, 0.33, 0.32])} # plotting plt . plot ( fpr_dict [ 0 ], tpr_dict [ 0 ], linestyle = '--' , color = 'orange' , label = 'Class 0 vs Rest' ) plt . plot ( fpr_dict [ 1 ], tpr_dict [ 1 ], linestyle = '--' , color = 'green' , label = 'Class 1 vs Rest' ) plt . plot ( fpr_dict [ 2 ], tpr_dict [ 2 ], linestyle = '--' , color = 'blue' , label = 'Class 2 vs Rest' ) plt . title ( 'Multiclass ROC curve' ) plt . xlabel ( 'False Positive Rate' ) plt . ylabel ( 'True Positive rate' ) plt . legend ( loc = 'best' ) plt . savefig ( 'Multiclass ROC' , dpi = 300 ); Step 4: One Vs Rest We will do a arithmetic mean over the scores we get. This concludes the OvR algorithm. macro_average_roc_score = np . mean ( list ( roc_auc_dict . values ())) print ( macro_average_roc_score ) 0.4305555555555556 Step 5: Modularize # This code belows also WORKS for Binary class if you are using Softmax Predictions! # replicating from https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#multiclass-settings def multiclass_roc ( y_true , y_logit , config ): label_dict = dict () fpr = dict () tpr = dict () roc_auc = dict () roc_scores = [] for label_num in range ( len ( config . class_list )): # get y_true_multilabel binarized version for each loop (end of each epoch) y_true_multiclass_array = sklearn . preprocessing . label_binarize ( y_true , classes = config . class_list ) y_true_for_curr_class = y_true_multiclass_array [:, label_num ] y_pred_for_curr_class = y_logit [:, label_num ] # calculate fpr,tpr and thresholds across various decision thresholds # pos_label = 1 because one hot encode guarantees it fpr [ label_num ], tpr [ label_num ], _ = sklearn . metrics . roc_curve ( y_true = y_true_for_curr_class , y_score = y_pred_for_curr_class , pos_label = 1 ) roc_auc [ label_num ] = sklearn . metrics . auc ( fpr [ label_num ], tpr [ label_num ]) roc_scores . append ( roc_auc [ label_num ]) # if binary class, the one hot encode will (n_samples,1) and therefore will only need to slice [:,0] ONLY. # that is why usually for binary class, we do not need to use this piece of code, just for testing purposes. # However, it will now treat our 0 (negative class) as positive, hence returning the roc for 0, in which case # to get both 0 and 1, you just need to use 1-roc(0)value if config . num_classes == 2 : roc_auc [ config . class_list [ 1 ]] = 1 - roc_auc [ label_num ] break avg_roc_score = np . mean ( roc_scores ) return roc_auc , avg_roc_score Multi-Label ROC Incidentally, the way we compute OVR Multi-Class ROC can be used in Multi-Label ROC as well. Quadratic Weighted Kappa The below explanation will correspond to my notebook during the PANDAS competition . ## Table of Contents 1. Intuition of QWK 2. Step 1: Create the NxN histogram matrix O 3. Step 2: Create the Weighted Matrix w 4. Step 3: Create the Expected Matrix 5. Step 4: Final Step: Weighted Kappa formula and Its python codes Intuition of QWK TLDR: one can skip to the last section on the python code implementation of QWK and also take reference to CPMP's Fast QWK Computation as well. Kappa or Cohen\u2019s Kappa is like classification accuracy, except that it is normalized at the baseline of random chance on your dataset: It basically tells you how much better your classifier is performing over the performance of a classifier that simply guesses at random according to the frequency of each class. First off, we define the formula exactly as mentioned. Quoting from the evaluation page: Submissions are scored based on the quadratic weighted kappa, which measures the agreement between two outcomes. This metric typically varies from 0 (random agreement) to 1 (complete agreement). In the event that there is less agreement than expected by chance, the metric may go below 0. The quadratic weighted kappa is calculated as follows. First, an N x N histogram matrix O is constructed, such that \\(O_{i,j}\\) corresponds to the number of isup_grade 's i (actual) that received a predicted value j. An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted values: \\[w_{i,j} = \\dfrac{(i-j)^2}{(N-1)^2}\\] An N-by-N histogram matrix of expected outcomes, E, is calculated assuming that there is no correlation between values.This is calculated as the outer product between the actual histogram vector of outcomes and the predicted histogram vector, normalized such that E and O have the same sum. Finally, from these three matrices, the quadratic weighted kappa is calculated as: \\[\\kappa = 1 - \\dfrac{\\sum_{i,j}\\text{w}_{i,j}O_{i,j}}{\\sum_{i,j}\\text{w}_{i,j}E_{i,j}}\\] where \\(w\\) is the weighted matrix, \\(O\\) is the histogram matrix and \\(E\\) being the expected matrix. Step 1: Create the NxN histogram matrix O Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon. Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon. Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon. Reminder: Although it is a counter example, it still illustrates what a NxN histogram matrix is! We will now call our histogram matrix C instead because in actual fact, the histogram matrix is merely a multi class confusion matrix between actual and predicted values We use a naive example where there are 5 classes (note our competition is_up grade has 6 classes; but this is just an example. Our y_true is the ground truth labels and correspondingly, our y_pred is the predicted values. y_true = pd . Series ([ 'cat' , 'cat' , 'dog' , 'cat' , 'cat' , 'cat' , 'pig' , 'pig' , 'hen' , 'pig' ], name = 'Actual' ) y_pred = pd . Series ([ 'bird' , 'hen' , 'pig' , 'bird' , 'bird' , 'bird' , 'pig' , 'pig' , 'hen' , 'pig' ], name = 'Predicted' ) print ( \"Ground truth: \\n {} \" . format ( y_true )) print ( \"-\" * 40 ) print ( \"Predicted Values: \\n {} \" . format ( y_pred )) Ground truth: 0 cat 1 cat 2 dog 3 cat 4 cat 5 cat 6 pig 7 pig 8 hen 9 pig Name: Actual, dtype: object ---------------------------------------- Predicted Values: 0 bird 1 hen 2 pig 3 bird 4 bird 5 bird 6 pig 7 pig 8 hen 9 pig Name: Predicted, dtype: object First, an N x N confusion matrix C is constructed, such that \\(\\text{C}_{i,j}\\) is the entry that corresponds to the number of animal i (actual) that received a predicted value j . classes = [ 'bird' , 'cat' , 'dog' , 'hen' , 'pig' ] # thank you https://datascience.stackexchange.com/questions/40067/confusion-matrix-three-classes-python def plot_confusion_matrix ( cm , classes , normalize = False , title = 'Confusion matrix' , cmap = plt . cm . Blues ): \"\"\" This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`. \"\"\" if normalize : cm = cm . astype ( 'float' ) / cm . sum ( axis = 1 )[:, np . newaxis ] print ( \"Normalized confusion matrix\" ) else : print ( 'Confusion matrix, without normalization' ) plt . imshow ( cm , interpolation = 'nearest' , cmap = cmap ) plt . title ( title ) plt . colorbar () tick_marks = np . arange ( len ( classes )) plt . xticks ( tick_marks , classes , rotation = 45 ) plt . yticks ( tick_marks , classes ) fmt = '.2f' if normalize else 'd' thresh = cm . max () / 2. for i , j in itertools . product ( range ( cm . shape [ 0 ]), range ( cm . shape [ 1 ])): plt . text ( j , i , format ( cm [ i , j ], fmt ), horizontalalignment = \"center\" , color = \"white\" if cm [ i , j ] > thresh else \"black\" ) plt . ylabel ( 'True label' ) plt . xlabel ( 'Predicted label' ) plt . tight_layout () cnf_matrix = confusion_matrix ( y_true , y_pred , labels = [ 'bird' , 'cat' , 'dog' , 'hen' , 'pig' ],) np . set_printoptions ( precision = 2 ) # Plot non-normalized confusion matrix plt . figure () plot_confusion_matrix ( cnf_matrix , classes = [ 'bird' , 'cat' , 'dog' , 'hen' , 'pig' ], title = 'Confusion matrix C, without normalization' ) <Figure size 432x288 with 0 Axes> Confusion matrix, without normalization Example using our competition's dataset The above matrix is a multi class confusion matrix . As an example, for the 2nd row, we predicted 4 cats to be birds, and 1 cat to be predicted as hen. More compactly, it can be represented as the matrix \\(C_{2,1}\\) = 4. We can easily reconcile our example above to relate back to our competition: After the biopsy is assigned a Gleason score, it is converted into an ISUP grade on a 1-5 scale . For now, I will include the label 0 because it is the background/non-tissue. What I do next is to take the ground truth and call it y_true which is a series. I then generate a dummy y_pred by using np.random.choice and randomly generate numbers from 0 to 5. train = pd . read_csv ( \"../data/datasets/prostate-cancer-grade-assessment-train.csv\" ) y_true = train . isup_grade y_true y_pred = np . random . choice ( 6 , 10616 , replace = True ) y_pred = pd . Series ( y_pred ) y_pred 0 0 1 0 2 4 3 4 4 0 .. 10611 0 10612 5 10613 0 10614 2 10615 4 Name: isup_grade, Length: 10616, dtype: int64 0 2 1 2 2 4 3 1 4 5 .. 10611 2 10612 2 10613 1 10614 5 10615 1 Length: 10616, dtype: int32 The following confusion matrix, is what we mean by the \"N by N\" (6 by 6) histogram matrix . cm = confusion_matrix ( y_true , y_pred , labels = [ 0 , 1 , 2 , 3 , 4 , 5 ],) plot_confusion_matrix ( cm , classes = [ 0 , 1 , 2 , 3 , 4 , 5 ], title = 'Confusion matrix C, without normalization' ) Confusion matrix, without normalization So far we have settled the first portion, construction the histogram matrix. Step 2: Create the Weighted Matrix w An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted rating scores. The formula is as follows: \\( \\(w_{i,j} = \\dfrac{(i-j)^2}{(N-1)^2}\\) \\) Under Step-2, each element is weighted. Predictions that are further away from actuals are marked harshly than predictions that are closer to actuals. However, I suddenly realized that these animals above have no obvious hierarchy in them. Therefore, it is not correct to say that predicting a cat as a bird is any better/worse off than predicting a cat as hen. Consequently, this is a realization. Because now I start to understand why certain competitions use metrics like quadratic weighted kappa! Consider the same example as animals just now, but instead of animals, we change to isup_grade ). So there is an inherent order within the isup_grade 0 - 5 such that 0 and 1 is closer than 0 and 2, 1 and 2 is closer to 1 and 3 etc. \\( \\(0 > 1 > 2 > 3 > 4 > 5\\) \\) For example, let's use a simplified example: y_true = [2,2,2,1,2,3,4,5,0,1] y_pred = [1,2,4,1,2,3,4,5,0,1] As a result, our purpose of the weighted matrix is to allocate a higher penalty score if our prediction is further away from the actual value. That is, if our isup_grade is 2 but we predicted it as 1 (see the example), then based on our formula above, we have i = 2 and j = 1 (entry \\(C_{2,1}\\) ), the penalty is \\( \\(\\dfrac{(2-1)^2}{(5-1)^2} = 0.0625\\) \\) but if our isup_grade is 2 and we predicted it as 4 (see the example), then the penalty involved is higher \\( \\(\\dfrac{(2-4)^2}{(5-1)^2} = 0.25\\) \\) Indeed, the weight matrix helped us assign a heavier penalty to predicting 2 as 4 than 2 as 1. Lastly, we also observe that the formula will give us 0 for the diagonals of the weighted matrix. This means penalty is 0 whenever we correctly predict something. To calculate weighted matrix in python code, here is the code with reference to Aman Arora . # We construct the weighted matrix starting from a zero matrix, it is like constructing a # list, we usually start from an empty list and add things inside using loops. def weighted_matrix ( N ): weighted = np . zeros (( N , N )) for i in range ( len ( weighted )): for j in range ( len ( weighted )): weighted [ i ][ j ] = float ((( i - j ) ** 2 ) / ( N - 1 ) ** 2 ) return weighted print ( weighted_matrix ( 5 )) [[0. 0.06 0.25 0.56 1. ] [0.06 0. 0.06 0.25 0.56] [0.25 0.06 0. 0.06 0.25] [0.56 0.25 0.06 0. 0.06] [1. 0.56 0.25 0.06 0. ]] Remember, the further away from the diagonal you get, the worse off is your prediction and it will be penalized harder by a bigger weight. As you can easily infer from the weighted matrix above, we use the first row as an example in case one did not understand. Basically, the weighted matrix's first row's first element is 0, because it means we predicted correctly and no penalty is meted out; but as we move further to the left, you can see that the punishment gets harsher and harsher: \\( \\(0 < 0.06 < 0.25 < 0.56 < 1\\) \\) Step 3: Create the Expected Matrix ## dummy example actual = pd . Series ([ 2 , 2 , 2 , 3 , 4 , 5 , 5 , 5 , 5 , 5 ]) pred = pd . Series ([ 2 , 2 , 2 , 3 , 2 , 1 , 1 , 1 , 1 , 3 ]) C = confusion_matrix ( actual , pred ) N = 5 act_hist = np . zeros ([ N ]) for item in actual : act_hist [ item - 1 ] += 1 pred_hist = np . zeros ([ N ]) for item in pred : pred_hist [ item - 1 ] += 1 print ( f 'Actuals value counts: { act_hist } , \\n Prediction value counts: { pred_hist } ' ) Actuals value counts:[0. 3. 1. 1. 5.], Prediction value counts:[4. 4. 2. 0. 0.] This part is the most difficult to understand, especially for someone who has little statistic backgrounds (mind you when I was majoring in applied math back then, I only took one statistic module in my whole tenure.) Googling the idea of expected matrix is not apparently clear to me, but luckily someone pointed to me to read expected frequency of Chi-Square test and then and, there I start to slowly understand. For the purpose of better understanding, we call our actual values to be rater A and our prediction model to be rater B. We want to quantify the agreement between rater A and rater B. Here are some terminologies to get hold of first. There are a total number of \\(k = 5\\) classes in this example; There are a total number of \\(n = 10\\) observations in this example; Define Y to be the random variable that rater A has chosen (aka our actual classes 1,2,3,4,5); and \\(\\widehat{Y}\\) be the random variable that rater \\(B\\) has chosen (aka our predicted classes 1,2,3,4,5 by rater B) \\(r_i\\) be the i-th entry of the column vector for actual value counts shown above, \\(c_i\\) be the i-th entry of the column vector for prediction value counts shown above. Then the probability of rater A choosing class 2 and rater B choosing class 2 for example, is given by \\( \\(P(Y = 2 \\text{ and } \\widehat{Y} = 2) = P(Y = 2) \\cdot P(\\widehat{Y} = 2) = 30\\% \\times 40\\% = 12\\%\\) \\) This is under the assumption that both raters are independent of each other . Note that \\(P(Y = 2) = 30\\%\\) because as we see from the actual value counts of rater \\(A\\) , there are a total of 3 class 2's and therefore the probability of Y being 2 is just the proportion. Similarly, we calculate \\(\\widehat{Y}\\) the same way. In general, the formula of rater A choosing class i and rater B choosing (predicting) class j is given as follows: \\( \\(P(Y = i \\text{ and } \\widehat{Y} = j) = P(Y = i) \\times P (\\widehat{Y} = j)\\) \\) Now the real question comes: On average, if you have \\(n\\) number of points to predict, how many times (what is the frequency) would you expect to see rater A choose class i and rater B choose class j. To reiterate, recall that the probability of the actual class being 1 and (super important word here, it means a joint distribution) and the predicted class to be 1 as well is \\(P(Y = 1 \\text{ and } \\widehat{Y} = 1)\\) , similarly, the probability of the actual class being 1 and the predicted class to be 2 is \\(P(Y = 1 \\text{ and } \\widehat{Y} = 2)\\) . Generalizing, the probability of the actual class being \\(i\\) and the predicted class being \\(j\\) is the joint probability \\( \\(P(Y = i \\text{ and } \\widehat{Y} = j)\\) \\) So the intuition lies here: based on the joint probability above, what is the expected number of times (frequency) that \\(Y = i\\) and \\(\\widehat{Y} = j\\) happened (this means Y is i but rater B predict \\(\\widehat{Y}\\) as j) out of 10 times? Easy, just use \\(n \\times P(Y = i \\text{ and } \\widehat{Y} = j)\\) . So for rater B, our prediction model, by just using theoretical probability , should have \\(n \\times P(Y = i \\text{ and } \\widehat{Y} = j)\\) for each \\(i,j\\) . But in reality, this may not be the case. Reconcile this idea with the classic coin toss example: Example on coin toss: Expected frequency is defined as the number of times that we predict an event will occur based on a calculation using theoretical probabilities. You know how a coin has two sides, heads or tails? That means that the probability of the coin landing on any one side is 50% (or 1/2, because it can land on one side out of two possible sides). If you flip a coin 1,000 times, how many times would you expect to get heads? About half the time, or 500 out of the 1,000 flips. To calculate the expected frequency, all we need to do is multiply the total number of tosses (1,000) by the probability of getting a heads (1/2), and we get 1,000 * 1/2 = 500 heads. if event A has prob of p happening, and sample size of n, then the average or expected number of times that A happens is \\(np\\) . The expected frequency of heads is 500 out of 1,000 total tosses. The expected frequency is based on our knowledge of probability - we haven't actually done any coin tossing. However, if we had enough time on our hands, we could actually flip a coin 1,000 times to experimentally test our prediction. If we did this, we would be calculating the experimental frequency. The experimental frequency is defined as the number of times that we observe an event to occur when we actually perform an experiment, test, or trial in real life. If you flipped a coin 1,000 times and it landed on heads 479 times, then the experimental frequency of heads is 479. But wait - didn't we predict the coin would land on heads 500 times? Why did it actually land on heads only 479 times? Well, the expected frequency was just that - what we expected to happen, based on our knowledge of probability. There are no guarantees when it comes to probability, what we expect to happen might differ from what actually happens. Since we know \\( \\(E_{2,2} = 10 \\times P(Y = 2 \\text{ and } \\widehat{Y} = 2) = 10 \\times P(Y = 2) \\cdot P(\\widehat{Y} = 2) = 10 \\times 30\\% \\times 40\\% = 1.2\\) \\) This \\(E_{2,2}\\) means that we only expect the rater A to choose 2 and rater B to choose 2 at the same time only 1.2 times out of 10 times. In other words, our predicted model classify 2 as 2 1.2 times. However, from our observations in our matrix C (confusion/histogram matrix), rater A choosing 2 and rater B choosing 2 have a frequency of 3! In other words, our predicted model classified 2 as 2 three times! So we kinda exceeded expectation for this particular configuration. \\[C = \\begin{bmatrix} 0 & 0 & 0 & 0 & 0\\\\ 0 & 3 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 0\\\\ 0 & 1 & 0 & 0 & 0\\\\ 4 & 0 & 1 & 0 & 0\\\\ \\end{bmatrix}\\] Let me give you one more example, \\( \\(E_{5,2} = 10 \\times P(Y = 5 \\text{ and } \\widehat{Y} = 2) = 10 \\times P(Y = 5) \\cdot P(\\widehat{Y} = 2) = 10 \\times 50\\% \\times 40\\% = 2\\) \\) This means that we only expect the rater A to choose 5 and rater B to choose 2 at the same time only 2 times out of 10 times! But in reality, our observations say that our rater B classified 5 as 2 zero times! We calculate \\(E_{i,j}\\) given by the formula: \\( \\(E_{i,j} = n \\times P(Y = i \\text{ and } \\widehat{Y} = j) = n \\times P(Y = i) \\times P (\\widehat{Y} = j) = n \\times \\dfrac{r_i}{n} \\times \\dfrac{c_j}{n}\\) \\) \\[E = \\begin{bmatrix} 0 & 0 & 0 & 0 & 0\\\\ 1.2 & 1.2 & 0.6 & 0 & 0 \\\\ 0.4 & 0.4 & 0.2 & 0 & 0\\\\ 0.4 & 0.4 & 0.2 & 0 & 0\\\\ 2 & 2 & 1 & 0 & 0\\\\ \\end{bmatrix}\\] Note \\(r_i \\times c_j\\) is the \\((i,j)\\) entry of the outer product between the actual histogram vector of outcomes (actual value counts) and the predicted histogram vector (prediction value counts). What does the random chance mean here? Simple, it just means that the probability for rater A (actual) to be class i AND for rater B (predicted) to be class j is \\(p\\%\\) (say 10%). Therefore, if we have made 100 predictions, random chance aka the theoratical probability tells us you should only have \\(100 \\times 10\\% = 10\\) predictions to be of this configuration (rater A class i AND rater B class j). Writing out the expected matrix in python So to get the expected matrix, E, is calculated assuming that there is no correlation between values. This is calculated as the outer product between the actual histogram vector of outcomes and the predicted histogram vector, normalized such that E and C have the same sum. Note carefully below that we do not need to normalize both, we just need to normalize E to the same sum as C. E = np . outer ( act_hist , pred_hist ) / 10 E C array([[0. , 0. , 0. , 0. , 0. ], [1.2, 1.2, 0.6, 0. , 0. ], [0.4, 0.4, 0.2, 0. , 0. ], [0.4, 0.4, 0.2, 0. , 0. ], [2. , 2. , 1. , 0. , 0. ]]) array([[0, 0, 0, 0, 0], [0, 3, 0, 0, 0], [0, 0, 1, 0, 0], [0, 1, 0, 0, 0], [4, 0, 1, 0, 0]], dtype=int64) Step 4: Final Step: Weighted Kappa formula and Its python codes From these three matrices: E, C and weighted, the quadratic weighted kappa is calculated as: \\[\\kappa = 1 - \\dfrac{\\sum_{i,j}\\text{weighted}_{i,j}C_{i,j}}{\\sum_{i,j}\\text{weighted}_{i,j}E_{i,j}}\\] Note that a higher value generally means your prediction model is way better than a random model, but there is no consensus on which value is really good or bad. \\[\\text{Weighted} = \\begin{bmatrix} 0 & 0.0625 & 0.25 & 0.5625 & 1\\\\ 0.0625 & 0 & 0.0625 & 0.25 & 0.5625 \\\\ 0.25 & 0.0625 & 0 & 0.0625 & 0.25\\\\ 0.5625 & 0.25 & 0.0625 & 0 & 0.0625\\\\ 1 & 0.5625 & 0.25 & 0.0625 & 0\\\\ \\end{bmatrix}\\] The notation \\(\\sum_{i,j}\\text{W}_{i,j}C_{i,j}\\) is just \\( \\(\\sum_{i=1}^{k}\\sum_{j=1}^{k} W_{i,j} C_{i,j} = (W_{1,1}C_{1,1} + W_{1,2}C_{1,2} + ...+ W_{1,k}C_{1,k}) + (W_{2,1}C_{2,1}+...+W_{2,k}C_{2,k}) +...+(W_{k,1}C_{k,1}+...+W_{k,k}C_{k,k})\\) \\) To put our understanding into perspective, consider just one entry \\(W_{5,1}C_{5,1} = 1 \\times 4 = 4\\) . This roughly means that our predicted model classified class 5 as class 1 FOUR times (re: \\(C_{5,1} = 4\\) ), and since class 5 is so far away from class 1, we need to punish this wrong prediction more than the others. And we did see that the corresponding weight \\(W_{5,1} = 1\\) is the highest weight. Consequently, the numerator being \\(\\sum_{i,j}\\text{W}_{i,j}C_{i,j}\\) calculates the total \"penalty cost\" for the rater A (our predicted model), and similarly, \\(\\sum_{i,j}\\text{W}_{i,j}E_{i,j}\\) calculates the total \"penalty cost\" for the rater B (our \"expected\" model). Therefore, you can think both values (num and den) as a cost function, and the lesser the better. And kappa formula tells us, if our \\(\\sum_{i,j}\\text{W}_{i,j}C_{i,j}\\) is significantly smaller than \\(\\sum_{i,j}\\text{W}_{i,j}E_{i,j}\\) , this will yield a very small value of \\( \\(\\dfrac{\\sum_{i,j}\\text{weighted}_{i,j}C_{i,j}}{\\sum_{i,j}\\text{weighted}_{i,j}E_{i,j}}\\) \\) which will yield a very high kappa value - signifying a better model. # Method 1 # apply the weights to the confusion matrix weighted = weighted_matrix ( 5 ) num = np . sum ( np . multiply ( weighted , C )) # apply the weights to the histograms den = np . sum ( np . multiply ( weighted , E )) kappa = 1 - np . divide ( num , den ) kappa -0.13924050632911378 # Method 2 num = 0 den = 0 for i in range ( len ( weighted )): for j in range ( len ( weighted )): num += weighted [ i ][ j ] * C [ i ][ j ] den += weighted [ i ][ j ] * E [ i ][ j ] weighted_kappa = ( 1 - ( num / den )); weighted_kappa -0.13924050632911378 # Method 3: Just use sk learn library cohen_kappa_score ( actual , pred , labels = None , weights = 'quadratic' , sample_weight = None ) -0.13924050632911378 Just a side note that one can also use SK learn's cohen_kappa_score function calculate the quadratic weighted kappa in this competition, with weights set to quadratic. Also please do refer to CPMP's discussion topic for fast QWK computation References Reference I Reference II Reference III Accuracy Indicator Function - Wikipedia Why is accuracy not the best measure for assessing classification models? - StackExchange Example when using accuracy as an outcome measure will lead to a wrong conclusion - StackExchange Precision-Recall - Precision-Recall: Estimations of Probabilities - Wikipedia - Loss function and Decision Function - StatsExchange - Precision and Recall Tradeoff - Google Receiver Operating Characteristic (ROC) Interpretation of ROC Wikipedia has an extensive explanation of the probability behind ROC Different Interpretations of AUC - StatsExchange Probabilistic Perspective of AUC AUC - Insider's Guide to the Theory and Applications Safe Handling Instructions for Probabilistic Classification . c-statistics . SIIM Melanoma ROC An Introduction to ROC analysis Pros and Cons of AUROC The Relationship Between Precision-Recall and ROC Curves Drawbacks of AUROC . ROC vs precision-and-recall curves ROC vs Precision-recall curves on imbalanced dataset on why AUC can be misleading AUC scale and threshold invariant - TDS Implementation Implementation of ROC - roc-curve-and-auc-from-scratch-in-numpy-visualized - TDS Trapezoid Rule On why thresholds return 2 sometimes (https://stackoverflow.com/questions/23200518/scikit-learn-roc-curve-why-does-it-return-a-threshold-value-2-some-time) PR-Curve vs ROC-Curve https://stackoverflow.com/questions/59666138/sklearn-roc-auc-score-with-multi-class-ovr-should-have-none-average-available https://stackoverflow.com/questions/39685740/calculate-sklearn-roc-auc-score-for-multi-class https://datascience.stackexchange.com/questions/36862/macro-or-micro-average-for-imbalanced-class-problems#:~:text=Micro%2Daverage%20is%20preferable%20if,your%20dataset%20varies%20in%20size. https://www.google.com/search?q=roc_auc_score+multiclass+site:stackoverflow.com&rlz=1C1CHBF_enSG891SG891&sxsrf=ALeKk018tRSfmKgIUw63SPI8dsdkvJgPuw:1608711331403&sa=X&ved=2ahUKEwjg7NDb1OPtAhUXVH0KHVNHCmwQrQIoBHoECAMQBQ&biw=1280&bih=610 https://stackoverflow.com/questions/56227246/how-to-calculate-roc-auc-score-having-3-classes https://glassboxmedicine.com/2019/02/23/measuring-performance-auc-auroc/ https://stackoverflow.com/questions/56227246/how-to-calculate-roc-auc-score-having-3-classes Precision-Recall Curve Interpretation of PR Damage Caused by Classification Accuracy and Other Discontinuous Improper Accuracy Scoring Rules - Frank Harrell Classification vs. Prediction - Frank Harrell","title":"ROC and PR Curves"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#receiver-operating-characteristic-roc","text":"","title":"Receiver operating characteristic (ROC)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#intuition","text":"Mathematically, ROC graphs are two dimensional graphs in which the x-axis is the False Positive Rate (FPR) and the y-axis, the True Positive Rate (TPR). The curve is parametrized by the parameter \\(\\vec{thr}\\) which represents the threshold of the classifier. The graph also depicts the tradeoffs between TPR and FPR, much like the dilemma of the Bias-Variance tradeoff. Also note that in the ROC space, each point on the graph represents a threshold, and therefore each point can have its own confusion matrix as well. We come up with an example from the Melanoma Competition where we denote a malignant cell to be 1, and benign to be 0. If we treat the malignance class as positive class , and the model you trained on outputs a probability vector (using softmax here) \\([0.7, 0.3]\\) corresponding to class 0 and 1 respectively, the value of 0.3 translates to saying that the image is 30% positive that it is malignant; in other words, it is 70% sure that this image is a benign cell. If we choose the default threshold to be the traditional \\(\\vec{thr}=0.5\\) , then the classifier will label this image as a \\(0\\) . This is because the thresholds defines our hard label from the soft label , and thus anything above the threshold 0.5, will be classified as a positive class 1, and negative class otherwise. If however, you lower your classification threshold, say from 0.5 to 0.2, then our image will become now become positive class, indicating the image's cell to be malignant. Intuitively, the consequence is that more images will be classified to become positive as lowering the threshold will allow the model to predict true more often. The consequence is that the TPR will go up, and so will the FPR. Example: There are 10 ground truth targets of y_true = [1,1,1,0,0,0,0,0,1,0,0] and your model predicts y_pred = [0.6,0.7,0.4,0.6,0.55,0.4,0.3,0.2,0.6,0.1] which if you apply argmax to y_pred, then it will become y_pred_argmax = [1,1,0,1,1,0,0,0,1,0]. The TPR here is given by $\\frac{2}{4}$ since there are 4 positive ground truth, and among the predicted labels, the model correctly classify 2 positives correctly. The FPR is given by $\\frac{3}{6}$ because we gave 3 people the false alarm, predicting them to have cancer whereas they don't. Now if you lower you threshold to 0.2, then you can see that the new predicted label array to be [1,1,1,1,1,1,1,0,1,0] where the new calibrated TPR is $\\frac{3}{4}$ and the FPR is $\\frac{5}{6}$. Therefore, without any proofs, just intuition, one should be convinced that if you lower the threshold, more patients will be classified as positive, consequently, the TPR and FPR both increase. Conversely, if you increase the threshold, then the TPR and FPR will both decrease. This may not hold true in a monotone manner, as wrongly described earlier, as it can jolly well be the TPR or FPR do not change, as can be seen in the diagram in the section Ranking.","title":"Intuition"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#definition-of-roc-curve","text":"Definition: The ROC Curve is a graph that plots the True Positive Rate on the y-axis and False Positive Rate on the x-axis, furthermore, this curve is parametrized by a threshold vector $\\vec{t}$. From Wikipedia: In binary classification, the class prediction for each instance is often made based on a continuous random variable \\(X\\) , which is a \"score\" computed for the instance (e.g. the estimated probability in logistic regression). Given a threshold parameter \\(T\\) , the instance is classified as \"positive\" if \\(X > T\\) , and \"negative\" otherwise. \\(X\\) follows a probability density \\(f_1(x)\\) if the instance actually belongs to class \"positive\", and \\(f_0(x)\\) if otherwise. Therefore, the true positive rate is given by \\(TPR(T) = \\int_{T}^{\\infty}f_1(x)dx\\) and the false positive rate is given by \\(FPR(T) = \\int_{T}^{\\infty}f_0(x)dx\\) . The ROC curve plots parametrically TPR(T) with FPR(T) as the varying parameter. Example: For example, imagine that the blood protein levels in diseased people and healthy people are normally distributed with means of 2 g/dL and 1 g/dL respectively. A medical test might measure the level of a certain protein in a blood sample and classify any number above a certain threshold as indicating disease. The experimenter can adjust the threshold (black vertical line in the figure), which will in turn change the false positive rate. Increasing the threshold would result in fewer false positives (and more false negatives), corresponding to a leftward movement on the curve. The actual shape of the curve is determined by how much overlap the two distributions have.","title":"Definition of ROC Curve"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#definition-of-area-under-roc-curve","text":"Definition: The AUROC is thus the area under the ROC Curve. More formally, in the probabilistic perspective of AUC , AUC is the probability of a randomly chosen positive case outranks a randomly chosen negative case based on the classifier. \\[ \\begin{aligned} AUC &= P(f(x+)>f(x\u2212)|\\text{class}(x+)=1, \\text{class}(x\u2212)=0)\\\\ &= \\frac{1}{PN}\\sum_{i=1}^{P}\\sum_{j=1}^{N}1(f(x+)\u2212f(x\u2212)) \\end{aligned} \\] where \\(f(x)\\) : classifier P : # of true positive item, N : # of true negative item Or expressed in another digestable way: The AUC of a classifier is equal to the probability that the classifier will rank a randomly chosen positive example higher than a randomly chosen negative example, i.e. \\(P\\Big(\\text{score}(x^+) > \\text{score}(x^-)\\Big)\\) This line above means that if you randomly take two samples, one positive and one negative, the AUC score, say 0.8, says that the probability of your positive sample being ranked higher (means probability higher) than the negative sample is 0.8. In other words, it measures how well the probability ranks based on their true classes. Thus, it is a threshold-invariant and scale-invariant metrics and only the sequence matters in the predicted probabilities. Based on this property, models with higher AUC indicate better discrimination between the two classes. However, the probabilities output from models with higher AUC don\u2019t always generate well-calibrated probabilities. More information can be found here: Safe Handling Instructions for Probabilistic Classification . Another answer from Stackoverflow, to reference it. Although I'm a bit late to the party, but here's my 5 cents. @FranckDernoncourt (+1) already mentioned possible interpretations of AUC ROC, and my favorite one is the first on his list (I use different wording, but it's the same): the AUC of a classifier is equal to the probability that the classifier will rank a randomly chosen positive example higher than a randomly chosen negative example, i.e. \\(P\\Big(\\text{score}(x^+) > \\text{score}(x^-)\\Big)\\) Consider this example (auc=0.68): Let's try to simulate it: draw random positive and negative examples and then calculate the proportion of cases when positives have greater score than negatives cls = c('P', 'P', 'N', 'P', 'P', 'P', 'N', 'N', 'P', 'N', 'P', 'N', 'P', 'N', 'N', 'N', 'P', 'N', 'P', 'N') score = c(0.9, 0.8, 0.7, 0.6, 0.55, 0.51, 0.49, 0.43, 0.42, 0.39, 0.33, 0.31, 0.23, 0.22, 0.19, 0.15, 0.12, 0.11, 0.04, 0.01) pos = score[cls == 'P'] neg = score[cls == 'N'] set.seed(14) p = replicate(50000, sample(pos, size=1) > sample(neg, size=1)) mean(p) And we get 0.67926. Quite close, isn't it? By the way, in R I typically use ROCR package for drawing ROC curves and calculating AUC. library('ROCR') pred = prediction(score, cls) roc = performance(pred, \"tpr\", \"fpr\") plot(roc, lwd=2, colorize=TRUE) lines(x=c(0, 1), y=c(0, 1), col=\"black\", lwd=1) auc = performance(pred, \"auc\") auc = unlist(auc@y.values) auc","title":"Definition of Area under ROC Curve"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#auroc-as-a-ranking","text":"One confusing aspect of ROC space is the ranking system. This can be seen in the notebook I created here. Remember, if you code it out yourself from scratch, then it will be more beneficial as you can understand where ranking come into play (without using sklearn). The algorithm starts from the point where threshold is \\infty or in sklearn it starts with some other number. A threshold of infinity will guarantee that the point starts at (0,0). Thus, our very first point MUST start from the origin in this algorithm. Then assuming we do not consider an infinity number of thresholds, as this is too computationally expensive, we consider say 10 threshold values that we want to test (a common number is the number in the dataset). We divide the 10 values into 0.9,0.8,0.7,...,0.1, (for example only). Then we start from 0.9, the highest threshold, and move down to the lowest, in order (ranking). As we have seen just now, as you lower the threshold, both your TPR and FPR go up. Therefore, if you don't want to get your hands dirty, then the intuition is that if you have ground truth [0,1,1,0] and pred_1 = [0.03,0.99,0.05,0.06] and pred_2 = [0.15,0.92,0.89,0.91] then if you then imagine that your thresholds are given by thres_1 = [infinity,0.99,0.06,0.05,0.03] and thres_2 = [infinity, 0.92,0.91,0.89,0.15] , then you can calculate that the TPR and FPR rate at each of the threshold for both predictions are actually the same, consequently, forming the same ROC curve. (Consider plotting it). The idea here is we do not care what your values of the predictions are, in fact, in neural networks, transforming logits through softmax may not be a well calibrated (refer to my calibrated probability notes) probability anyways. We do however, care about the ranking, as you can see our thresholds are sorted in descending order, noticed that we only need that many thresholds for the dataset because only the thresholds at the predictions matter. If you take a number between 0.06 and 0.99 for the first threshold set, you will notice that between this threshold, the TPR and FPR will always be the same. Therefore, we conclude, without proof, that if two arrays of prediction has the exact same relative order, then the AUC for both predictions will be the same, which means that AUC is invariant to the scale of the predictions, and in fact invariant to any sort of transformation, that preserves the order (i.e. a non-negative linear transformation); (you can have numbers greater than 1 and the AUC will be the same try [100,200,150,160]). A corollary of this is we can\u2019t treat outputs of an AUC-optimized model as the likelihood that it\u2019s true. Some models may be poorly calibrated (eg: its output is always between 0.3 and 0.32) but still achieve a good AUC score because its relative ordering is correct. This is something to look out for when blending together predictions of different models. Furthermore, if you see my notebook example, you can predict wrongly, but still have an AUC of 1. One last thing is about the predictions ordering, there is no rule that your predictions must SORT IN DESCENDING ORDER, for example: This will give you an AUC score of 1, even though it may not seem to predict everything correctly. Because the below order gives rise to the best AUC, which is 1 in this case, and hence this will give you 1 as well. If you switch a few numbers inside y_pred you will notice it can still stay at 1. However, if you reverse the list order, then you will get an AUC of 0 (the opposite of the best). y_true = [ 1 , 1 , 1 , 1 , 1 , 1 , 0 , 0 , 0 , 0 ] y_pred = [ 0.99999 , 0.98 , 0.97 , 0.96 , 0.95 , 0.94 , 0.68139 , 0.50961 , 0.48880 , 0.44951 ] full_score_example = sklearn . metrics . roc_auc_score ( y_true , y_pred ) print ( full_score_example ) -> 1 y_true = [ 1 , 0 , 1 , 1 , 0 ] y_pred = [ 0.5 , 0.25 , 0.2 , 0.3 , 0.1 ] y_pred_same_rank = [ 100 , 25 , 20 , 30 , 10 ] fpr_rank_1 , tpr_rank_1 , threshold_rank_1 = sklearn . metrics . roc_curve ( y_true , y_pred , drop_intermediate = True ) fpr_rank_2 , tpr_rank_2 , threshold_rank_2 = sklearn . metrics . roc_curve ( y_true , y_pred_same_rank , drop_intermediate = True ) roc_rank_1 = sklearn . metrics . roc_auc_score ( y_true = y_true , y_score = y_pred , average = \"macro\" , sample_weight = None , max_fpr = None ) # 0.833 roc_rank_2 = sklearn . metrics . roc_auc_score ( y_true = y_true , y_score = y_pred_same_rank , average = \"macro\" , sample_weight = None , max_fpr = None ) # 0.833 import matplotlib.pyplot as plt plt . figure ( figsize = [ 10 , 9 ]) plt . title ( 'Receiver Operating Characteristic' ) plt . plot ( fpr_rank_1 , tpr_rank_1 , 'b' , label = 'AUC = %0.2f ' % roc_rank_1 ) plt . plot ( fpr_rank_2 , tpr_rank_2 , 'b' , label = 'AUC = %0.2f ' % roc_rank_2 ) plt . legend ( loc = 'lower right' ) plt . plot ([ 0 , 1 ], [ 0 , 1 ], 'r--' ) plt . xlim ([ 0 , 1 ]) plt . ylim ([ 0 , 1 ]) plt . ylabel ( 'True Positive Rate' ) plt . xlabel ( 'False Positive Rate' ) plt . show ();","title":"AUROC as a Ranking"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#roc-as-c-statistic","text":"ROC can be interpreted as c-statistics . ROC AUC has the property that it coincides with the \\(c\\) statistic. The \\(c\\) statistic measures the probability that a positive example is ranked higher than a negative example. In this sense, the ROC AUC answers the question of how well the model discriminates between the two classes. A model with high discrimination is not necessarily well calibrated. Suppose a logistic regression model predicts probabilities of 0.52 for positives and 0.51 for negatives (imagine 10 ground truth where 6 is positive and 4 is negative, then the author meant the associated probabilities with each of these ground truth is 0.52 and 0.51 respectively, for the positive and negative classes). This model has an AUC of 1 (recall you need not predict everything correctly to get an AUC of 1) but the probabilities aren't helpful in the sense of identifying which purported positives are highest-risk. Because all of the positives are assigned the same posterior probability, they can't be differentiated. Moreover, a well-calibrated model will have its maximum ROC AUC fixed by the ratio of positives to negatives in the data. This means that a model which has some very desirable probabilities (i.e. its posterior probabilities match the true probability) has a cap on its performance, and therefore an uncalibrated model could \"dominate\" in terms of ROC AUC. ROC AUC doesn't tell you anything about the costs of different kinds of errors. For example, if you're trying to detect fraud, a 10,000 dollar purchase of uncertain provenance represents a larger potential loss than a 10 dollar purchase. But ROC AUC would treat both events as if they have the same weight -- obviously any reasonable model should be able to distinguish between these two types of error. ROC AUC also tends to be dominated by the \"high FPR\" points. Depending on the application, these points may be the least relevant. Consider the case where the model is used to refer high-risk transactions to experts who will conduct further vetting. There may only be enough humans to assess 50 transactions per unit time; since the most highly-ranked transactions occur on the \"left hand\" size of the ROC curve by definition, this is also the region with the lowest area. So by looking at the whole AUC, you're optimistically biasing your results upwards, i.e. ROC AUC is buoyed by the observations \"to the right\" of the actual set of observations which humans will vet. (Illustration is simple. Draw a vertical line at FPR<0.5 on any ROC curve. The area to left is higher for all such vertical lines.) To avoid this, some people use partial ROC AUC, which has its own host of problems, chief among them that software implementations tend to assume that you're interested in truncation at some value of FPR. But in the case that you care about the top \\(n\\) transactions, this approach is obviously wrong because the top \\(n\\) transactions will happen at different FPR values for different classifiers. Standardization of partial AUC (to preserve the property that AUC < 0.5 is worse than random, 1 is perfect, 0 is worthless) incurs further difficulties. The ROC curve itself is of little interest. \"Dominating\" classifiers can be assessed by AUC. Stochastic equivalence can be assessed by tests of equivalence of ranks. Prof. Harrell's comment drives at a consistent theme of his work, which is that the real question diagnostics should answer is one of risk assessment and utility optimization. Examining ROC AUC tends to encourage selection of truncation points, which should be avoided because it only provides partial information to decision makers. Alternative measures of performance (e.g. log-likelihood) characterize the calibration of the model and proper scoring rules generally have the quality that they encourage honest forecasts.","title":"ROC as C-Statistic"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#pros-and-cons-of-auroc","text":"Before we go ham on the Drawbacks of AUROC , we first try to think the following: Food For Thought: I think intuitively you can say that if your model needs to perform equally well on the positive class as the negative class (for example, for classifying images between cats and dogs, you would like the model to perform well on the cats as well as on the dogs. For this you would use the AUROC.) On the other hand, if you're not really interested in how the model performs on the negative class, but just want to make sure every positive prediction is correct (precision), and that you get as many of the positives predicted as positives as possible (recall), then you should choose PRAUC (more with it later). For example, for detecting cancer, you don't care how many of the negative predictions are correct, you want to make sure all the positive predictions are correct, and that you don't miss any. (In fact, in this case missing a cancer would be worse than a false positive so you'd want to put more weight towards recall.)","title":"Pros and Cons of AUROC"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#pros-when-your-classes-are-more-balanced","text":"ROC curves are insensitive to changes in class distribution. Quote unquote from \"The analysis of ROC Curves\", we see that the if the proportion of positive to negative instances changes in a test set, the ROC curves will not change . This is because the AUC is equals to the probability of ranking a random positive example over a random negative example, and by definition this happens after you have drawn a positive and a negative, which indicates that we do not need to know anything about the original distribution and the class proportions. AUROC curve better reflects the total amount of False Positives independent of in which class they come up. We can see this by a simple math example: Essentially, AUROC is measuring the TPR vs FPR ratio: We can interpret it as such \\[TPR:FPR = \\dfrac{TP}{TP + FN} : \\dfrac{FP}{FP+TN} = \\dfrac{TP}{TP+FN} \\times \\dfrac{FP + TN}{FP} = \\dfrac{TP}{|+|} \\times \\dfrac{|-|}{FP}=\\dfrac{|-|}{|+|} \\times \\dfrac{TP}{FP}\\]","title":"Pros: When your classes are more balanced"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#pros-scale-invariant","text":"See section on AUROC as a Ranking for code example . AUC measures how well predictions are ranked, rather than their absolute values. This means that your score from the model need not be calibrated into a strict probability. You can predict any score you want. This allows us to compare different classifiers that predict values on a different scale. This can be a con as highlighted in Cons: uncalibrated.","title":"Pros: Scale Invariant"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#pros-classification-threshold-invariant","text":"AUC measures the quality of the model's predictions irrespective of what classification threshold is chosen. What this means is if you compare an example to accuracy, how do you compute it? You say that if threshold is more than \\(t\\) , then you proceed to calculate the accuracy score - and different threshold gives different accuracies. But in ROC, the nuance is that our final metric is area under the ROC curve, over various (all possible) thresholds \\(t\\) , so as you see, we do not depend on the threshold to calculate the final score! This may be good in the sense that it gives you an overall performance on the binary classifier. This can also be a con when you want to specifically minimize one metric like False Negatives or False Positives. For example, in cancer detection where malignant is the positive class, you will likely want to minimize False Negatives, even if it results in a huge increase in False Positives , then ROC may not be best suited. So if you only have the ROC curve for analysis, then you can choose your threshold according to the curve, in this case we choose the point which maximizes TPR as maximizing TPR is equivalent to minimizng FN.","title":"Pros: Classification Threshold Invariant"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#cons-imbalanced","text":"Imbalanced Data: We examine the case in which the dataset is imbalanced and further assume that the positive class is the minority, (note if you assume positive class is majority, then ROC may perform very well here, so the assumption is that the minority is of the positive class). We assume further that the negative class is 90% and positive class is 10%. Intuitively, in an imbalanced dataset, the model **usually does not have trouble predicting the majority class**, and this suggests that they will often get the negatives correct in this case, leading to a high TN. By looking at the FPR, we notice that $\\frac{FP}{FP + TN}$ suggests that FP will be low and TN will be high simply because of the aforementioned idea that the model will likely get the TN correct, and if TN is high, then the FP is low. Consequently, FPR is high. The following [on why AUC can be misleading](https://stats.stackexchange.com/questions/360017/when-is-an-auc-score-misleadingly-high/360040#360040) One possible reason you can get high AUROC with what some might consider a mediocre prediction is if you have imbalanced data (in favor of the \"zero\" prediction), high recall, and low precision. That is, you're predicting most of the ones at the higher end of your prediction probabilities, but most of the outcomes at the higher end of your prediction probabilities are still zero. This is because the ROC score still gets most of its \"lift\" at the early part of the plot, i.e., for only a small fraction of the zero-predictions. For example, if 5% of the test set are \"ones\" and all of the ones appear in the top 10% of your predictions, then your AUC will be at least 18/19 because, after 18/19 of the zeroes are predicted, already 100% of the ones were predicted. Even if the top 5% are all zeroes. Whether this is a \"bad\" prediction depends on your priorities. If you think that false negatives are terrible and false positives are tolerable, then this prediction is okay. But if it's the opposite, then this prediction is pretty bad. from sklearn.metrics import roc_auc_score import numpy as np import matplotlib.pyplot as plt yTest = [ 0 , 0 , 1 , 1 , 0 , 1 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ] yPredicted = np . linspace ( 0.9 , 0.1 , num = len ( yTest )) print ( yPredicted ) print () imbalanced_roc = roc_auc_score ( yTest , yPredicted ) # ~0.89 print ( f \"roc score: { imbalanced_roc } \" ) print () fpr_imbalanced , tpr_imbalanced , threshold_imbalanced = sklearn . metrics . roc_curve ( yTest , yPredicted , drop_intermediate = True ) print ( f \"fpr: \\n { list ( np . round ( fpr_imbalanced , 3 )) } \" ) print () print ( f \"tpr: \\n { list ( np . round ( tpr_imbalanced , 3 )) } \" ) print () print ( f \"thresholds: \\n { list ( np . round ( threshold_imbalanced , 3 )) } \" ) print () plt . plot ( fpr_imbalanced , tpr_imbalanced ); [0.9 0.87333333 0.84666667 0.82 0.79333333 0.76666667 0.74 0.71333333 0.68666667 0.66 0.63333333 0.60666667 0.58 0.55333333 0.52666667 0.5 0.47333333 0.44666667 0.42 0.39333333 0.36666667 0.34 0.31333333 0.28666667 0.26 0.23333333 0.20666667 0.18 0.15333333 0.12666667 0.1 ] roc score: 0.888888888888889 fpr: [0.0, 0.037, 0.074, 0.074, 0.111, 0.111, 0.185, 0.185, 1.0] tpr: [0.0, 0.0, 0.0, 0.5, 0.5, 0.75, 0.75, 1.0, 1.0] thresholds: [1.9, 0.9, 0.873, 0.82, 0.793, 0.767, 0.713, 0.687, 0.1] This diagram above says a thousand words. Because one perpetual question I had was how does class imbalance really plays a part in giving AUROC an overly optimistic picture. Note that the above I put drop_intermediate=True , which means we are only shown meaningful thresholds. In the thresholds above, we can see the fpr consistently is low, with low tpr at first. Then at the second last point, the fpr is 0.185 and tpr is 1, meaning we classified all positive points correctly. We see that this corresponding threshold is 0.687, and indeed, if we check the yTest and yPredicted, all the 1s have HIGHER probability than 0.687, which is the \"trick here\", thus once the threshold is set to > 0.687, all POSITIVE POINTS will be classified correctly, but this does not mean there is no FP, but now the FP is a lot at the expense, because we predict many as positive but it is actually negative, but fpr will be low, because fpr = fp/fp+tn, and even if fp is high, our tn is very big, pulling our denominator big, and as a result, making fpr seem deceptively low.","title":"Cons: Imbalanced"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#cons-uncalibrated","text":"Uncalibrated: A model with high AUROC does not necessarily imply a well calibrated model. By this I mean a model with all extreme predictions for of say, it predicts all positive ground truths to be 0.52 and all negative ground truths to be 0.51. This model has an AUC of 1, but the probabilities aren't helpful in the sense of identifying which purported positives are highest-risk. Because all of the positives are assigned the same posterior probability, they can't be differentiated. Note that models like logistic regression are naturally well calibrated, but models like neural networks output logits, and hence we have to apply `sigmoid` or `softmax` to make it probabilities. Below is the \"phenomenon\" that AUC of 1 but the models look bad. Notice that even though we have a perfect AUROC score of 1, the model is not at all confident with the predictions in the sense that we cannot pin point any two positive labels and say that one of them is of higher probability than the other. If you are not convinced, the below code illustrates the point and the plot shows you. y_true = [ 1 , 0 , 1 , 0 , 1 , 0 , 1 , 0 , 1 , 1 ] y_pred = [ 0.52 , 0.51 , 0.52 , 0.51 , 0.52 , 0.51 , 0.52 , 0.51 , 0.52 , 0.52 ] uncalibrated_roc = sklearn . metrics . roc_auc_score ( y_true , y_pred ) print ( f \"roc score: { uncalibrated_roc } \" ) fpr_uncalibrated , tpr_uncalibrated , threshold_uncalibrated = sklearn . metrics . roc_curve ( y_true , y_pred , drop_intermediate = True ) print ( fpr_uncalibrated , tpr_uncalibrated , threshold_uncalibrated ) # Another example # y_true = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0] # y_pred = [0.99999, 0.98, 0.97, 0.96, 0.95, 0.94, 0.68139, 0.50961, 0.48880, 0.44951] # full_score_example = sklearn.metrics.roc_auc_score(y_true, y_pred) # print(full_score_example) -> 1 roc score: 1.0 [0. 0. 1.] [0. 1. 1.] [1.52 0.52 0.51] import matplotlib.pyplot as plt import seaborn as sns sns . set () plt . figure ( figsize = ( 15 , 7 )) plt . scatter ( fpr_uncalibrated , tpr_uncalibrated , color = \"#0F9D58\" , s = 100 ) plt . plot ( fpr_uncalibrated , tpr_uncalibrated , color = \"#0F9D58\" , label = f \"auc: { uncalibrated_roc } \" ) plt . title ( \"ROC Curve\" , fontsize = 20 ) plt . legend ( loc = 4 ) plt . xlabel ( \"False Positive Rate\" , fontsize = 16 ) plt . ylabel ( \"True Positive Rate\" , fontsize = 16 );","title":"Cons: Uncalibrated"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#implementation-of-roc-and-auc","text":"This implementation follows closely to Implementation of ROC - roc-curve-and-auc-from-scratch-in-numpy-visualized - TDS .","title":"Implementation of ROC and AUC"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-1-problem-setup","text":"y_true_binary = np . asarray ([ 0 , 0 , 1 , 1 , 0 , 0 , 1 , 1 ]) y_pred_binary = np . asarray ([ 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 ]) We have a binary classification problem with the targets and predictions shown above. We further note that the predictions are probabilities output from the Sigmoid layer in a logistic classifier. y_true_binary = np . asarray ([ 0 , 0 , 1 , 1 , 0 , 0 , 1 , 1 ]) y_pred_binary = np . asarray ([ 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 ])","title":"Step 1: Problem Setup"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-2-define-threshold-range","text":"For our classifier, our usual default threshold is as such: if y_pred_binary [ i ] > 0.5 : assign y_pred_binary as positive class (+) else : assign y_pred_binary as negative class (-) Then it follows that different thresholds will result to different TPR and FPR. We can discretize our thresholds uniformly. Note that scikit-learn uses a different method to find the thresholds and are more optimized. For starter, we will just set our threshold range from 0 to 1 with uniform interval of 0.1. threshold_range = np . arange ( 0 , 11 , 1 ) / 10 print ( threshold_range ) [0. 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]","title":"Step 2: Define Threshold Range"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-3-classify-prediction-according-to-threshold","text":"The next step we need to do is to classify our y_pred_binary from probabilities into hard labels, a 0 or 1 label. We create a dictionary y_pred_thresholded which has the threshold as key, and the value is the corresponding hard labels. y_pred_thresholded = { 0.0 : [ 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.1 : [ 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.2 : [ 0 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.3 : [ 0 , 0 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.4 : [ 0 , 0 , 0 , 1 , 1 , 1 , 1 , 1 ], 0.5 : [ 0 , 0 , 0 , 0 , 1 , 1 , 1 , 1 ], 0.6 : [ 0 , 0 , 0 , 0 , 0 , 1 , 1 , 1 ], 0.7 : [ 0 , 0 , 0 , 0 , 0 , 0 , 1 , 1 ], 0.8 : [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 ], 0.9 : [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ], 1.0 : [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ], } y_pred_thresholded : Dict = {} for threshold in threshold_range : if threshold not in y_pred_thresholded : y_pred_thresholded [ threshold ] = [] for y_p in y_pred_binary : if y_p >= threshold : y_pred_thresholded [ threshold ] . append ( 1 ) else : y_pred_thresholded [ threshold ] . append ( 0 )","title":"Step 3: Classify prediction according to threshold"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-4-calculate-tpr-and-fpr","text":"Now we calculate the respective TPR and FPR for each thresholds's hard labels against the y_true_binary . We will make use of our reighns_confusion_matrix defined earlier to calculate. tpr_fpr = [ [ 1.0 , 1.0 ], [ 1.0 , 1.0 ], [ 1.0 , 0.75 ], [ 1.0 , 0.5 ], [ 0.75 , 0.5 ], [ 0.5 , 0.5 ], [ 0.5 , 0.25 ], [ 0.5 , 0.0 ], [ 0.25 , 0.0 ], [ 0.0 , 0.0 ], [ 0.0 , 0.0 ], ] where the first element of the inner list is tpr and the second element is fpr . tpr_fpr : Dict = { \"tpr\" : [], \"fpr\" : []} for y_pred in y_pred_thresholded . values (): tp , fp , tn , fn = reighns_confusion_matrix ( y_true_binary , y_pred ) tpr = tp / ( tp + fn ) fpr = fp / ( tn + fp ) tpr_fpr [ \"tpr\" ] . append ( tpr ) tpr_fpr [ \"fpr\" ] . append ( fpr ) print ( tpr_fpr ) {'tpr': [1.0, 1.0, 1.0, 1.0, 0.75, 0.5, 0.5, 0.5, 0.25, 0.0, 0.0], 'fpr': [1.0, 1.0, 0.75, 0.5, 0.5, 0.5, 0.25, 0.0, 0.0, 0.0, 0.0]}","title":"Step 4: Calculate TPR and FPR"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-5-plot-the-points-as-roc-curve","text":"The main idea of ROC Curve is to plot various pairs of [TPR, FPR] at different threshold on the graph, as shown below. Note that we reversed our tpr and fpr to be in line with Scikit-Learn. It does not affect the end result. import matplotlib.pyplot as plt import seaborn as sns sns . set () plt . figure ( figsize = ( 15 , 7 )) tpr_reighns = tpr_fpr [ \"tpr\" ][:: - 1 ] fpr_reighns = tpr_fpr [ \"fpr\" ][:: - 1 ] plt . scatter ( fpr_reighns , tpr_reighns , color = \"#0F9D58\" , s = 100 ) plt . title ( \"ROC Curve\" , fontsize = 20 ) plt . xlabel ( \"False Positive Rate\" , fontsize = 16 ) plt . ylabel ( \"True Positive Rate\" , fontsize = 16 ); Let us compare to the scikit-learn's version! from sklearn.metrics import roc_curve fpr_sklearn , tpr_sklearn , thresholds_sklearn = roc_curve ( y_true_binary , y_pred_binary ) plt . figure ( figsize = ( 15 , 7 )) plt . scatter ( fpr_sklearn , tpr_sklearn , s = 100 , alpha = 0.5 , color = \"blue\" , label = \"Scikit-learn\" ) plt . scatter ( fpr_reighns , tpr_reighns , color = \"#0F9D58\" , s = 100 , alpha = 0.3 , label = \"Our implementation\" ) plt . title ( \"ROC Curve\" , fontsize = 20 ) plt . xlabel ( \"False Positive Rate\" , fontsize = 16 ) plt . ylabel ( \"True Positive Rate\" , fontsize = 16 ) plt . legend (); Notice that in Scikit-Learn's version, they have 3 less points that us, this is discussed in details in the reference links I appended below. But just know that the end result is the same when we go to AUC! Starting and Ending Point: Notice that the starting point and ending point of the ROC curve always start with (0, 0) and (1, 1). See the `y_pred_thresholded` we got earlier. y_true_binary = np . asarray ([ 0 , 0 , 1 , 1 , 0 , 0 , 1 , 1 ]) y_pred_thresholded = { 0.0 : [ 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.1 : [ 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.2 : [ 0 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.3 : [ 0 , 0 , 1 , 1 , 1 , 1 , 1 , 1 ], 0.4 : [ 0 , 0 , 0 , 1 , 1 , 1 , 1 , 1 ], 0.5 : [ 0 , 0 , 0 , 0 , 1 , 1 , 1 , 1 ], 0.6 : [ 0 , 0 , 0 , 0 , 0 , 1 , 1 , 1 ], 0.7 : [ 0 , 0 , 0 , 0 , 0 , 0 , 1 , 1 ], 0.8 : [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 ], 0.9 : [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ], 1.0 : [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ], } A bit of probing reveals that if you discretize your threshold from 0 to 1 inclusive, then it follows that at the threshold 1, everything is predicted as the negative class as shown, then by definition, TPR is 0 because the numerator of TPR is TP, and there is 0 TP because every single prediction made is of negative class, similarly, FPR is also 0 because the numerator of FPR is FP, and the model did not miss any negatives since it predicted every single one as negative. The same logic can be applied to when the threshold is 0, we instead have FPR and TPR to be both 1.","title":"Step 5: Plot the points as ROC Curve"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-6-area-under-roc-curve","text":"In the Implementation of ROC - roc-curve-and-auc-from-scratch-in-numpy-visualized - TDS visualization, we understand that we can approximate AUROC score by \"integrating\" over the rectangles. In a way, this is calculating areas of rectangles under the curve, as follows. rectangle_area = 0 for k in range ( len ( threshold_range )): rectangle_area += ( fpr_reighns [ k + 1 ] - fpr_reighns [ k ]) * tpr_reighns [ k ] if k == ( len ( threshold_range ) - 2 ): break print ( f \"reighns roc_auc_score: { rectangle_area } \" ) from sklearn.metrics import roc_auc_score roc_auc_sklearn = roc_auc_score ( y_true_binary , y_pred_binary ) print ( f \"sklearn roc_auc_score: { roc_auc_sklearn } \" ) reighns roc_auc_score: 0.75 sklearn roc_auc_score: 0.75 # alternatively, we can use np.trapz to calculate the area under the curve. roc_area = np . trapz ( y = tpr_reighns , x = fpr_reighns ) print ( roc_area ) 0.75","title":"Step 6: Area under ROC Curve"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#couple-roc-with-brier-score","text":"https://medium.com/@penggongting/understanding-roc-auc-pros-and-cons-why-is-bier-score-a-great-supplement-c7a0c976b679","title":"Couple ROC with Brier Score"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#summary","text":"AUC is a threshold-free metrics capable of measuring the overall performance of binary classifier. AUC should be used in binary classification. In multinomial classification, one-to-rest AUC would be an option using the average of each class. AUC is a good metric when the rank of output probabilities is of interest. Note that if you have 2 classes, then finding the AUROC of the positive class (class 1) is equivalent to 1 minus the AUROC of the negative class (class 0). This is not true when we deal with PR-curve. Although AUC is powerful, it is not a cure-all. AUC is not suitable for heavily imbalanced class distribution and when the goal is to have well-calibrated probabilities. Models with maximized AUC treat the weight between positive and negative class equally. AUROC would be the metric to use if the goal of the model is to perform equally well on both classes. Image classification between cats & dogs is a good example because the performance on cats is equally important on dogs. AUPRC would be the metric to use if the focus of the model is to identify correctly as many positive samples as possible. Take spam detectors for example, the goal is to find all the possible spams. Regular emails are not of interest at all \u2014 they overshadow the number of positives. There are no defined rules to select the suitable metrics. It really depends on the data and the application. It is important to think thoroughly about the purpose of the model before jumping into the modeling process. One thing to note here is that the PR AUC serves as an alternative metric. If the model doesn\u2019t work after the metric is changed, there are still other remedies to deal with imbalanced data, such as downsampling/upsampling. We\u2019ll cover it later in future posts.","title":"Summary"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#sklearn-definition-of-binary-classification-roc-auc","text":"sklearn.metrics.roc_auc_score(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None) y_score: array-like of shape (n_samples,) or (n_samples, n_classes) Target scores. In the binary and multilabel cases, these can be either probability estimates or non-thresholded decision values (as returned by decision_function on some classifiers). In the multiclass case, these must be probability estimates which sum to 1. The binary case expects a shape (n_samples,), and the scores must be the scores of the class with the greater label. The multiclass and multilabel cases expect a shape (n_samples, n_classes). In the multiclass case, the order of the class scores must correspond to the order of labels, if provided, or else to the numerical or lexicographical order of the labels in y_true. Understanding the binary case is important, it says that the binary case expects a list/array of shape (n_samples,) , a 1d-array, where the scores inside the 1d-array must be the scores of the greater label . In other words, if you have class 0 and 1, then the greater label is np.argmax(0,1) = 1 . As a consequence, it is important that you should only pass the \"positive class\" which is the \"greater label\" here into the y_score . In multiclass, there are two cases, either you provide a labels argument in, say labels = [0,2,1] or labels = [0,1,2] , or if you do not provide, then the y_score will necessarily be in the order of the numerical/alphabetical order of the labels in y_true . In other words, if y_true has 3 unique labels: 0, 1 and 2; then the y_score will be a 2d-array in the form of y_score = [[0.2, 0.3, 0.5],[...],[...]] where y_score[0] = [0.2,0.3,0.5] must correspond to class 1, 2 and 3 respectively, unless otherwise stated in labels .","title":"SKLEARN Definition of Binary Classification ROC-AUC"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#first-interpretation","text":"Now ROC curve is a TPR vs FPR graph, and the AUC is the area under the curve literally. To find the ROC-AUC, we need to plot many different pairs of points on the graph, and compute the area under it. As we can see from the above naive and simple example, there are a total of 6 pairs of points to plot. Those are from fpr , tpr respectively --> Allow me to further explain with this example where 1 is the positive class: y_true_1 = [0,0,1,1,0,0,1,1] y_preds_1 = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8] We need to initialize the thresholds with a large number usually - usually roc_curve is written so that ROC point corresponding to the highest threshold (fpr[0], tpr[0]) is always (0, 0) . If this is not the case, a new threshold is created with an arbitrary value of max(y_score)+1 . Therefore, in this case, we get 1.8 as the first threshold. This large number will ensure the fpr, tpr starts at (0,0). Next, when the threshold is \\(T=0.8\\) , then one can see that y_preds_1 has 1 predictions 1, so y_preds_1=[0,0,0,0,0,0,0,1] and hence we can calculate the FPR and TPR: FPR will be 0 because no negative samples 0 are misclassified as 1 in our prediction. TPR will be 0.25 because by definition TPR=TP/TP+FN = 1/1+3=0.25 by definition. Therefore (fpr, tpr) = (0,0.25) \\(T=0.7 \\rightarrow\\) y_preds_1 = [0,0,0,0,0,0,1,1] , same logic, FPR will be 0 cause no negative samples 0 are classified as 1 by our classifier! But TPR will be 0.5 because TPR = TP/TP+FN = 2/2+2 = 0.5. Therefore (fpr, tpr) = (0,0.5) We continue this way until we exhaust all thresholds given [array([1.8, 0.8, 0.7, 0.5, 0.3, 0.1])] . And we plot on the graph. How then, do we calculate the area under this curve? One can refer to the source code auc in sklearn.metrics.auc and see that they used Trapezoidal Rule to solve it. So one have a rough idea, how the ROC-AUC area is computed, and one has to bear in mind that the area is calculated over all thresholds (apparently not the case as sklearn discretized the thresholds to reduce computing time, so you will not see the full range of thresholds here).","title":"First Interpretation"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#precision-recall-curve","text":"","title":"Precision-Recall Curve"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#loss-function-and-decision-function","text":"Loss function and decision Function link A decision function is a function which takes a dataset as input and gives a decision as output. What the decision can be depends on the problem at hand. Examples include: Estimation problems: the \"decision\" is the estimate. Hypothesis testing problems: the decision is to reject or not reject the null hypothesis. Think of Linear Regression problems, they are mostly related to hypothesis testing. Classification problems: the decision is to classify a new observation (or observations) into a category. Model selection problems: the decision is to chose one of the candidate models. Typically, there are an infinite number of decision functions available for a problem. If we for instance are interested in estimating the height of Swedish males based on ten observations \\(\\mathbf{x}=(x_1,x_2,\\ldots,x_{10})\\) , we can use any of the following decision functions \\(d(\\mathbf{x})\\) : The sample mean: \\(d(\\mathbf{x})=\\frac{1}{10}\\sum_{i=1}^{10}x_i\\) . The median of the sample: \\(d(\\mathbf{x})=\\mbox{median}(\\mathbf{x})\\) The geometric mean of the sample: \\(d(\\mathbf{x})=\\sqrt[10]{x_1\\cdots x_{10}}\\) The function that always returns 1: \\(d(\\mathbf{x})=1\\) , regardless of the value of \\(\\mathbf{x}\\) . Silly, yes, but it is nevertheless a valid decision function. How then can we determine which of these decision functions to use? One way is to use a loss function , which describes the loss (or cost) associated with all possible decisions. Different decision functions will tend to lead to different types of mistakes. The loss function tells us which type of mistakes we should be more concerned about. The best decision function is the function that yields the lowest expected loss . What is meant by expected loss depends on the setting (in particular, whether we are talking about frequentist or Bayesian statistics). In summary: Decision functions are used to make decisions based on data. Loss functions are used to determine which decision function to use.","title":"Loss function and Decision Function"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#an-extensive-study-on-precision-recall-curve","text":"Before I start, I will quote Frank Harrell's first and his second article. I will also use the links on stack exchange here and here by Stephan Kolassa . They are really good and the entire intuition is from him, I will almost use his intuition verbatim and everything in this section will be credited to the links above; I just find it too difficult to phrase it in my own words because their answers are perfect. Basically, let me put it up front now: Accuracy, Sensitivity and Specificity are one-sided or conditional versions of classification accuracy. As such they are also discontinuous improper accuracy scores, and optimizing them will result in the wrong model. The confusion matrix and the classification report provide a very detailed analysis of a particular set of predictions. However, the predictions themselves already threw away a lot of information that is contained in the model - to explain this statement further: We consider the example of a logistic regression classifier, used to predict whether a patient has cancer (1, positive class) or not (0, negative class). We defined Y as our response variable, outputting only 1 or 0, while \\(X\\) is the set of predictors. In the case of our cancer classification model, (which we assume to be a logistic regression classifier), we remember that the positive class (class = 1) is the patient has cancer, and the negative class (class = 0) is the patient does not have cancer. And to delve a little deeper, our default classification threshold is: \\(\\begin{equation} Y=\\begin{cases} 1, & \\text{if \\(P(Y=1 ~|~X) \\geq 0.5\\) }\\ 0, & \\text{if \\(P(Y=1~|~X) < 0.5\\) }\\\\ \\end{cases} \\end{equation}\\) which means that whenever our logistic regression outputs a probability of the patient getting cancer is more than \\(0.5\\) , we classify the patient to be in the positive class (predict him/her to have cancer). When we use the LogisticClassifier() to fit and predict, we are actually predicting the probability \\(p(X)\\) , i.e.the probability of the patient having cancer given predictors X; Consequently, we need to further set a threshold, or to make a decision on whether to classify a patient as cancer or benign based on the probability we get from \\( \\(p(X) = \\dfrac{e^{\\beta_0}+\\beta_1X_1+...+\\beta_nX_n}{1+ e^{\\beta_0}+\\beta_1X_1+...+\\beta_nX_n}\\) \\) The threshold is defaulted to 0.5 in predict_proba . As we discussed earlier, most classifiers provide a decision_function or a predict_proba method to assess degrees of certainty about predictions. Making predictions can be seen as thresholding the output of decision_function or predict_proba at a certain fixed point; in binary classification we use 0 for the decision function and 0.5 for predict_proba as default. To fully evaluate the effectiveness of a model, you must examine both precision and recall. Unfortunately, precision and recall are often in tension. That is, improving precision typically reduces recall and vice versa. Explore this notion by looking at the following figure, which shows 30 predictions made by an email classification model. Those to the right of the classification threshold are classified as \"spam\", while those to the left are classified as \"not spam.\" Always remember, do not ever just use a single metric like recall, precision to gauge your classifier. This is because your classifier (say SVM() may somehow trivially classify everything as the positive class, and then you will get 100% recall).","title":"An extensive study on Precision-Recall Curve"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#when-to-use-precision-recall","text":"Precision-Recall curves should be used when there is a moderate to large class imbalance. . In particular, when the positive class Precision and recall, however, don't consider true negatives and thus won't be affected by the relative imbalance (which is precisely why they're used for imbalanced datasets). Kaggle Forum As goes for any metric, your metric depends entirely on what I you mean to do with the data. I think intuitively you can say that if your model needs to perform equally well on the positive class as the negative class (for example, for classifying images between cats and dogs, you would like the model to perform well on the cats as well as on the dogs. For this you would use the ROC AUC. On the other hand, if you're not really interested in how the model performs on the negative class, but just want to make sure every positive prediction is correct (precision), and that you get as many of the positives predicted as positives as possible (recall), then you should choose PR AUC. For example, for detecting cancer, you don't care how many of the negative predictions are correct, you want to make sure all the positive predictions are correct, and that you don't miss any. (In fact, in this case missing a cancer would be worse then a false positive so you'd want to put more weight towards recall.) True negatives need to be meaningful for ROC to be a good choice of measure. In his example, if we've got 1,000 pictures of cats and dogs and our model determines whether the picture is a cat (target = 0) or a dog (target = 1), we probably care just as much about getting the cats right as the dogs, and so ROC is a good choice of metric. If instead, we've got a collection of 1,000,000 pictures and we build a model to try to identify the 1,000 dog pictures mixed in it, correctly identifying \"not-dog\" pictures is not quite as useful. Instead, it makes more sense to measure how often a picture is a dog when our model says it's a dog (i.e., precision) and how many of the dogs in the picture set we found (i.e., recall). Perspective: In the cancer example above, your AUROC score might be very bad, simply because your False Positives might be high, as a result of minimizing False Negatives, but your AUPRC might be good, because you are maximizing precision!","title":"When to use Precision-Recall"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#when-not-to-use-precision-recall","text":"Majority Negative: Notice that PR curve does not have TN in their equations, and this implies that PR curves are useful when there are minority positive samples and majority negative samples. But if it is the other way round, with minority negative samples, then PR curve will not tell you useful things.","title":"When NOT to use Precision-Recall"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#implementation-of-pr-curve","text":"","title":"Implementation of PR-Curve"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#the-debate-auroc-vs-auprc","text":"I just finished reading this discussion. They argue that PR AUC is better than ROC AUC on imbalanced dataset. For example, we have 10 samples in test dataset. 9 samples are positive and 1 is negative. We have a terrible model which predicts everything positive. Thus, we will have a metric that TP = 9, FP = 1, TN = 0, FN = 0. Then, Precision = 0.9, Recall = 1.0. The precision and recall are both very high, but we have a poor classifier. On the other hand, TPR = TP/(TP+FN) = 1.0, FPR = FP/(FP+TN) = 1.0. Because the FPR is very high, we can identify that this is not a good classifier. Clearly, ROC is better than PR on imbalanced datasets. Can somebody explain why PR is better? Usually when I do imbalanced models, even balanced models, I look at PR for ALL my classes. In your example, yes, your positive class has P = 0.9 and R = 1.0. But what you should look at are ALL your classes. So for your negative class, your P = 0 and your R = 0. And you usually don't just look at PR scores individually. You want to look at F1-score (F1 macro or F1 micro, depending on your problem) that is a harmonic average of your PR scores for both class 1 and class 0. Your class 1 PR score is super good, but combine that with your class 0 PR score, your F1-score will be TERRIBLE, which is the correct conclusion for your scenario. TL,DR: Look at PR scores for ALL your classes, and combine them with a metric like F1-score to have a realistic conclusion about your model performance. The F1-score for your scenario will be TERRIBLE, which is the correct conclusion for your scenario.","title":"The Debate: AUROC vs AUPRC"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#metrics-for-multi-class-label-classification","text":"Most Metrics discussed in Binary Classification can be extended to Multi-Class Classification.","title":"Metrics for Multi-Class-Label Classification"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#multi-class-roc","text":"","title":"Multi-Class ROC"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#intuition_1","text":"ROC is originally used for Binary Classification only, a natural extension to Multi-Class model is the In multi-class model, we can plot N number of AUC ROC Curves for N number classes using One vs ALL methodology. So for Example, If you have three classes named X, Y and Z, you will have one ROC for X classified against Y and Z, another ROC for Y classified against X and Z, and a third one of Z classified against Y and X. Firstly, you need to make use of the below code in source where we are using the concept of One-Vs-All (ovr) and first thing first, for all y_true labels, we need to label_binarize them. As we can see, we must pass in the y_true and classes in which if our classes are [0,1,2,3,4,5] then we need to specify in the labels argument of roc_auc_curve . If we do not specify, the _encode will help us as well, so it is up to one's preference if your labels order matter. else : # ovr is same as multi-label y_true_multilabel = label_binarize ( y_true , classes = classes ) return _average_binary_score ( _binary_roc_auc_score , y_true_multilabel , y_score , average , sample_weight = sample_weight )","title":"Intuition"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#implementation-of-ovr-multi-class-roc","text":"","title":"Implementation of OVR Multi-Class ROC"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-1-problem-setup_1","text":"Multi-Class: 3 classes of 0, 1 and 2. Number of samples: 4 Predictions: output using Softmax import scipy y_true_multiclass = np . asarray ([ 0 , 1 , 2 , 1 ]) y_logit_multiclass = np . asarray ( [ [ 0.0802 , 0.0347 , 0.05 ], [ 0.2640 , - 0.0701 , 0.03 ], [ - 0.0087 , 0.0502 , 0.0039 ], [ 0.0496 , 0.0059 , 0.0123 ], ] ) y_pred_multiclass = scipy . special . softmax ( y_logit_multiclass , axis = 1 ) y_pred_multiclass = np . asarray ( [ [ 0.34 , 0.33 , 0.33 ], [ 0.4 , 0.29 , 0.32 ], [ 0.33 , 0.35 , 0.33 ], [ 0.34 , 0.33 , 0.33 ]] )","title":"Step 1: Problem Setup"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-2-binarize","text":"We need to binarize the y_true_multiclass . array ([[ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 0 , 0 , 1 ], [ 0 , 1 , 0 ]]) where we need to interpret as follows: Class 1 Class 2 Class 3 1 0 0 0 1 0 0 0 1 0 1 0 where [1,0,0,0] (first column) represents the case where class 1 is the positive class and class 2 and 3 are considered the negative class (both are class 0). Class 1 Preds Class 2 Preds Class 3 Preds 0.34 0.33 0.33 0.4 0.29 0.32 0.33 0.35 0.33 0.34 0.33 0.33 where [0.34, 0.4, 0.33, 0.34] (first column) represents the probability of class 1 being the positive class. And to avoid confusion, the second column [0.33, 0.29, 0.35, 0.33] represents the probability of class 2 being the positive class (class 1). Note that I labelled the above as class 1, 2 and 3 but in our code it is class 0, 1 and 2. This does not affect the ultimate score but just note in case of confusion. y_binarize = sklearn . preprocessing . label_binarize ( y_true_multiclass , classes = [ 0 , 1 , 2 ]) print ( y_binarize ) [[1 0 0] [0 1 0] [0 0 1] [0 1 0]]","title":"Step 2: Binarize"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-3-roc-score-for-each-class","text":"At this step, we calculate the ROC score for each class. We have have 3 different scores, one for each class. That is to say, the first score is class 0 vs the rest, where we treated class 0 as the positive class. num_classes = 3 fpr_dict = dict () tpr_dict = dict () threshold_dict = dict () roc_auc_dict = dict () for label_num in range ( num_classes ): y_true_for_curr_class = y_binarize [:, label_num ] y_pred_for_curr_class = y_pred_multiclass [:, label_num ] # calculate fpr,tpr and thresholds across various decision thresholds; pos_label = 1 because one hot encode guarantees it fpr_dict [ label_num ], tpr_dict [ label_num ], threshold_dict [ label_num ] = sklearn . metrics . roc_curve ( y_true = y_true_for_curr_class , y_score = y_pred_for_curr_class , pos_label = 1 ) roc_auc_dict [ label_num ] = sklearn . metrics . auc ( fpr_dict [ label_num ], tpr_dict [ label_num ]) print ( f \"ROC score for class { label_num } is { roc_auc_dict [ label_num ] } . \\n Note we are considering class { label_num } as the positive class and treating other classes as negative class. \\n \" ) print ( fpr_dict ) print ( tpr_dict ) print ( threshold_dict ) ROC score for class 0 is 0.5. Note we are considering class 0 as the positive class and treating other classes as negative class. ROC score for class 1 is 0.125. Note we are considering class 1 as the positive class and treating other classes as negative class. ROC score for class 2 is 0.6666666666666667. Note we are considering class 2 as the positive class and treating other classes as negative class. {0: array([0. , 0.33333333, 0.66666667, 1. ]), 1: array([0. , 0.5, 1. , 1. ]), 2: array([0. , 0.66666667, 1. ])} {0: array([0., 0., 1., 1.]), 1: array([0. , 0. , 0.5, 1. ]), 2: array([0., 1., 1.])} {0: array([1.4 , 0.4 , 0.34, 0.33]), 1: array([1.35, 0.35, 0.33, 0.29]), 2: array([1.33, 0.33, 0.32])} # plotting plt . plot ( fpr_dict [ 0 ], tpr_dict [ 0 ], linestyle = '--' , color = 'orange' , label = 'Class 0 vs Rest' ) plt . plot ( fpr_dict [ 1 ], tpr_dict [ 1 ], linestyle = '--' , color = 'green' , label = 'Class 1 vs Rest' ) plt . plot ( fpr_dict [ 2 ], tpr_dict [ 2 ], linestyle = '--' , color = 'blue' , label = 'Class 2 vs Rest' ) plt . title ( 'Multiclass ROC curve' ) plt . xlabel ( 'False Positive Rate' ) plt . ylabel ( 'True Positive rate' ) plt . legend ( loc = 'best' ) plt . savefig ( 'Multiclass ROC' , dpi = 300 );","title":"Step 3: ROC score for each class"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-4-one-vs-rest","text":"We will do a arithmetic mean over the scores we get. This concludes the OvR algorithm. macro_average_roc_score = np . mean ( list ( roc_auc_dict . values ())) print ( macro_average_roc_score ) 0.4305555555555556","title":"Step 4: One Vs Rest"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-5-modularize","text":"# This code belows also WORKS for Binary class if you are using Softmax Predictions! # replicating from https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#multiclass-settings def multiclass_roc ( y_true , y_logit , config ): label_dict = dict () fpr = dict () tpr = dict () roc_auc = dict () roc_scores = [] for label_num in range ( len ( config . class_list )): # get y_true_multilabel binarized version for each loop (end of each epoch) y_true_multiclass_array = sklearn . preprocessing . label_binarize ( y_true , classes = config . class_list ) y_true_for_curr_class = y_true_multiclass_array [:, label_num ] y_pred_for_curr_class = y_logit [:, label_num ] # calculate fpr,tpr and thresholds across various decision thresholds # pos_label = 1 because one hot encode guarantees it fpr [ label_num ], tpr [ label_num ], _ = sklearn . metrics . roc_curve ( y_true = y_true_for_curr_class , y_score = y_pred_for_curr_class , pos_label = 1 ) roc_auc [ label_num ] = sklearn . metrics . auc ( fpr [ label_num ], tpr [ label_num ]) roc_scores . append ( roc_auc [ label_num ]) # if binary class, the one hot encode will (n_samples,1) and therefore will only need to slice [:,0] ONLY. # that is why usually for binary class, we do not need to use this piece of code, just for testing purposes. # However, it will now treat our 0 (negative class) as positive, hence returning the roc for 0, in which case # to get both 0 and 1, you just need to use 1-roc(0)value if config . num_classes == 2 : roc_auc [ config . class_list [ 1 ]] = 1 - roc_auc [ label_num ] break avg_roc_score = np . mean ( roc_scores ) return roc_auc , avg_roc_score","title":"Step 5: Modularize"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#multi-label-roc","text":"Incidentally, the way we compute OVR Multi-Class ROC can be used in Multi-Label ROC as well.","title":"Multi-Label ROC"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#quadratic-weighted-kappa","text":"The below explanation will correspond to my notebook during the PANDAS competition . ## Table of Contents 1. Intuition of QWK 2. Step 1: Create the NxN histogram matrix O 3. Step 2: Create the Weighted Matrix w 4. Step 3: Create the Expected Matrix 5. Step 4: Final Step: Weighted Kappa formula and Its python codes","title":"Quadratic Weighted Kappa"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#intuition-of-qwk","text":"TLDR: one can skip to the last section on the python code implementation of QWK and also take reference to CPMP's Fast QWK Computation as well. Kappa or Cohen\u2019s Kappa is like classification accuracy, except that it is normalized at the baseline of random chance on your dataset: It basically tells you how much better your classifier is performing over the performance of a classifier that simply guesses at random according to the frequency of each class. First off, we define the formula exactly as mentioned. Quoting from the evaluation page: Submissions are scored based on the quadratic weighted kappa, which measures the agreement between two outcomes. This metric typically varies from 0 (random agreement) to 1 (complete agreement). In the event that there is less agreement than expected by chance, the metric may go below 0. The quadratic weighted kappa is calculated as follows. First, an N x N histogram matrix O is constructed, such that \\(O_{i,j}\\) corresponds to the number of isup_grade 's i (actual) that received a predicted value j. An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted values: \\[w_{i,j} = \\dfrac{(i-j)^2}{(N-1)^2}\\] An N-by-N histogram matrix of expected outcomes, E, is calculated assuming that there is no correlation between values.This is calculated as the outer product between the actual histogram vector of outcomes and the predicted histogram vector, normalized such that E and O have the same sum. Finally, from these three matrices, the quadratic weighted kappa is calculated as: \\[\\kappa = 1 - \\dfrac{\\sum_{i,j}\\text{w}_{i,j}O_{i,j}}{\\sum_{i,j}\\text{w}_{i,j}E_{i,j}}\\] where \\(w\\) is the weighted matrix, \\(O\\) is the histogram matrix and \\(E\\) being the expected matrix.","title":"Intuition of QWK  "},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-1-create-the-nxn-histogram-matrix-o","text":"Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon. Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon. Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon. Reminder: Although it is a counter example, it still illustrates what a NxN histogram matrix is! We will now call our histogram matrix C instead because in actual fact, the histogram matrix is merely a multi class confusion matrix between actual and predicted values We use a naive example where there are 5 classes (note our competition is_up grade has 6 classes; but this is just an example. Our y_true is the ground truth labels and correspondingly, our y_pred is the predicted values. y_true = pd . Series ([ 'cat' , 'cat' , 'dog' , 'cat' , 'cat' , 'cat' , 'pig' , 'pig' , 'hen' , 'pig' ], name = 'Actual' ) y_pred = pd . Series ([ 'bird' , 'hen' , 'pig' , 'bird' , 'bird' , 'bird' , 'pig' , 'pig' , 'hen' , 'pig' ], name = 'Predicted' ) print ( \"Ground truth: \\n {} \" . format ( y_true )) print ( \"-\" * 40 ) print ( \"Predicted Values: \\n {} \" . format ( y_pred )) Ground truth: 0 cat 1 cat 2 dog 3 cat 4 cat 5 cat 6 pig 7 pig 8 hen 9 pig Name: Actual, dtype: object ---------------------------------------- Predicted Values: 0 bird 1 hen 2 pig 3 bird 4 bird 5 bird 6 pig 7 pig 8 hen 9 pig Name: Predicted, dtype: object First, an N x N confusion matrix C is constructed, such that \\(\\text{C}_{i,j}\\) is the entry that corresponds to the number of animal i (actual) that received a predicted value j . classes = [ 'bird' , 'cat' , 'dog' , 'hen' , 'pig' ] # thank you https://datascience.stackexchange.com/questions/40067/confusion-matrix-three-classes-python def plot_confusion_matrix ( cm , classes , normalize = False , title = 'Confusion matrix' , cmap = plt . cm . Blues ): \"\"\" This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`. \"\"\" if normalize : cm = cm . astype ( 'float' ) / cm . sum ( axis = 1 )[:, np . newaxis ] print ( \"Normalized confusion matrix\" ) else : print ( 'Confusion matrix, without normalization' ) plt . imshow ( cm , interpolation = 'nearest' , cmap = cmap ) plt . title ( title ) plt . colorbar () tick_marks = np . arange ( len ( classes )) plt . xticks ( tick_marks , classes , rotation = 45 ) plt . yticks ( tick_marks , classes ) fmt = '.2f' if normalize else 'd' thresh = cm . max () / 2. for i , j in itertools . product ( range ( cm . shape [ 0 ]), range ( cm . shape [ 1 ])): plt . text ( j , i , format ( cm [ i , j ], fmt ), horizontalalignment = \"center\" , color = \"white\" if cm [ i , j ] > thresh else \"black\" ) plt . ylabel ( 'True label' ) plt . xlabel ( 'Predicted label' ) plt . tight_layout () cnf_matrix = confusion_matrix ( y_true , y_pred , labels = [ 'bird' , 'cat' , 'dog' , 'hen' , 'pig' ],) np . set_printoptions ( precision = 2 ) # Plot non-normalized confusion matrix plt . figure () plot_confusion_matrix ( cnf_matrix , classes = [ 'bird' , 'cat' , 'dog' , 'hen' , 'pig' ], title = 'Confusion matrix C, without normalization' ) <Figure size 432x288 with 0 Axes> Confusion matrix, without normalization","title":"Step 1: Create the NxN histogram matrix O "},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#example-using-our-competitions-dataset","text":"The above matrix is a multi class confusion matrix . As an example, for the 2nd row, we predicted 4 cats to be birds, and 1 cat to be predicted as hen. More compactly, it can be represented as the matrix \\(C_{2,1}\\) = 4. We can easily reconcile our example above to relate back to our competition: After the biopsy is assigned a Gleason score, it is converted into an ISUP grade on a 1-5 scale . For now, I will include the label 0 because it is the background/non-tissue. What I do next is to take the ground truth and call it y_true which is a series. I then generate a dummy y_pred by using np.random.choice and randomly generate numbers from 0 to 5. train = pd . read_csv ( \"../data/datasets/prostate-cancer-grade-assessment-train.csv\" ) y_true = train . isup_grade y_true y_pred = np . random . choice ( 6 , 10616 , replace = True ) y_pred = pd . Series ( y_pred ) y_pred 0 0 1 0 2 4 3 4 4 0 .. 10611 0 10612 5 10613 0 10614 2 10615 4 Name: isup_grade, Length: 10616, dtype: int64 0 2 1 2 2 4 3 1 4 5 .. 10611 2 10612 2 10613 1 10614 5 10615 1 Length: 10616, dtype: int32 The following confusion matrix, is what we mean by the \"N by N\" (6 by 6) histogram matrix . cm = confusion_matrix ( y_true , y_pred , labels = [ 0 , 1 , 2 , 3 , 4 , 5 ],) plot_confusion_matrix ( cm , classes = [ 0 , 1 , 2 , 3 , 4 , 5 ], title = 'Confusion matrix C, without normalization' ) Confusion matrix, without normalization So far we have settled the first portion, construction the histogram matrix.","title":"Example using our competition's dataset"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-2-create-the-weighted-matrix-w","text":"An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted rating scores. The formula is as follows: \\( \\(w_{i,j} = \\dfrac{(i-j)^2}{(N-1)^2}\\) \\) Under Step-2, each element is weighted. Predictions that are further away from actuals are marked harshly than predictions that are closer to actuals. However, I suddenly realized that these animals above have no obvious hierarchy in them. Therefore, it is not correct to say that predicting a cat as a bird is any better/worse off than predicting a cat as hen. Consequently, this is a realization. Because now I start to understand why certain competitions use metrics like quadratic weighted kappa! Consider the same example as animals just now, but instead of animals, we change to isup_grade ). So there is an inherent order within the isup_grade 0 - 5 such that 0 and 1 is closer than 0 and 2, 1 and 2 is closer to 1 and 3 etc. \\( \\(0 > 1 > 2 > 3 > 4 > 5\\) \\) For example, let's use a simplified example: y_true = [2,2,2,1,2,3,4,5,0,1] y_pred = [1,2,4,1,2,3,4,5,0,1] As a result, our purpose of the weighted matrix is to allocate a higher penalty score if our prediction is further away from the actual value. That is, if our isup_grade is 2 but we predicted it as 1 (see the example), then based on our formula above, we have i = 2 and j = 1 (entry \\(C_{2,1}\\) ), the penalty is \\( \\(\\dfrac{(2-1)^2}{(5-1)^2} = 0.0625\\) \\) but if our isup_grade is 2 and we predicted it as 4 (see the example), then the penalty involved is higher \\( \\(\\dfrac{(2-4)^2}{(5-1)^2} = 0.25\\) \\) Indeed, the weight matrix helped us assign a heavier penalty to predicting 2 as 4 than 2 as 1. Lastly, we also observe that the formula will give us 0 for the diagonals of the weighted matrix. This means penalty is 0 whenever we correctly predict something. To calculate weighted matrix in python code, here is the code with reference to Aman Arora . # We construct the weighted matrix starting from a zero matrix, it is like constructing a # list, we usually start from an empty list and add things inside using loops. def weighted_matrix ( N ): weighted = np . zeros (( N , N )) for i in range ( len ( weighted )): for j in range ( len ( weighted )): weighted [ i ][ j ] = float ((( i - j ) ** 2 ) / ( N - 1 ) ** 2 ) return weighted print ( weighted_matrix ( 5 )) [[0. 0.06 0.25 0.56 1. ] [0.06 0. 0.06 0.25 0.56] [0.25 0.06 0. 0.06 0.25] [0.56 0.25 0.06 0. 0.06] [1. 0.56 0.25 0.06 0. ]] Remember, the further away from the diagonal you get, the worse off is your prediction and it will be penalized harder by a bigger weight. As you can easily infer from the weighted matrix above, we use the first row as an example in case one did not understand. Basically, the weighted matrix's first row's first element is 0, because it means we predicted correctly and no penalty is meted out; but as we move further to the left, you can see that the punishment gets harsher and harsher: \\( \\(0 < 0.06 < 0.25 < 0.56 < 1\\) \\)","title":"Step 2: Create the Weighted Matrix w "},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-3-create-the-expected-matrix","text":"## dummy example actual = pd . Series ([ 2 , 2 , 2 , 3 , 4 , 5 , 5 , 5 , 5 , 5 ]) pred = pd . Series ([ 2 , 2 , 2 , 3 , 2 , 1 , 1 , 1 , 1 , 3 ]) C = confusion_matrix ( actual , pred ) N = 5 act_hist = np . zeros ([ N ]) for item in actual : act_hist [ item - 1 ] += 1 pred_hist = np . zeros ([ N ]) for item in pred : pred_hist [ item - 1 ] += 1 print ( f 'Actuals value counts: { act_hist } , \\n Prediction value counts: { pred_hist } ' ) Actuals value counts:[0. 3. 1. 1. 5.], Prediction value counts:[4. 4. 2. 0. 0.] This part is the most difficult to understand, especially for someone who has little statistic backgrounds (mind you when I was majoring in applied math back then, I only took one statistic module in my whole tenure.) Googling the idea of expected matrix is not apparently clear to me, but luckily someone pointed to me to read expected frequency of Chi-Square test and then and, there I start to slowly understand. For the purpose of better understanding, we call our actual values to be rater A and our prediction model to be rater B. We want to quantify the agreement between rater A and rater B. Here are some terminologies to get hold of first. There are a total number of \\(k = 5\\) classes in this example; There are a total number of \\(n = 10\\) observations in this example; Define Y to be the random variable that rater A has chosen (aka our actual classes 1,2,3,4,5); and \\(\\widehat{Y}\\) be the random variable that rater \\(B\\) has chosen (aka our predicted classes 1,2,3,4,5 by rater B) \\(r_i\\) be the i-th entry of the column vector for actual value counts shown above, \\(c_i\\) be the i-th entry of the column vector for prediction value counts shown above. Then the probability of rater A choosing class 2 and rater B choosing class 2 for example, is given by \\( \\(P(Y = 2 \\text{ and } \\widehat{Y} = 2) = P(Y = 2) \\cdot P(\\widehat{Y} = 2) = 30\\% \\times 40\\% = 12\\%\\) \\) This is under the assumption that both raters are independent of each other . Note that \\(P(Y = 2) = 30\\%\\) because as we see from the actual value counts of rater \\(A\\) , there are a total of 3 class 2's and therefore the probability of Y being 2 is just the proportion. Similarly, we calculate \\(\\widehat{Y}\\) the same way. In general, the formula of rater A choosing class i and rater B choosing (predicting) class j is given as follows: \\( \\(P(Y = i \\text{ and } \\widehat{Y} = j) = P(Y = i) \\times P (\\widehat{Y} = j)\\) \\) Now the real question comes: On average, if you have \\(n\\) number of points to predict, how many times (what is the frequency) would you expect to see rater A choose class i and rater B choose class j. To reiterate, recall that the probability of the actual class being 1 and (super important word here, it means a joint distribution) and the predicted class to be 1 as well is \\(P(Y = 1 \\text{ and } \\widehat{Y} = 1)\\) , similarly, the probability of the actual class being 1 and the predicted class to be 2 is \\(P(Y = 1 \\text{ and } \\widehat{Y} = 2)\\) . Generalizing, the probability of the actual class being \\(i\\) and the predicted class being \\(j\\) is the joint probability \\( \\(P(Y = i \\text{ and } \\widehat{Y} = j)\\) \\) So the intuition lies here: based on the joint probability above, what is the expected number of times (frequency) that \\(Y = i\\) and \\(\\widehat{Y} = j\\) happened (this means Y is i but rater B predict \\(\\widehat{Y}\\) as j) out of 10 times? Easy, just use \\(n \\times P(Y = i \\text{ and } \\widehat{Y} = j)\\) . So for rater B, our prediction model, by just using theoretical probability , should have \\(n \\times P(Y = i \\text{ and } \\widehat{Y} = j)\\) for each \\(i,j\\) . But in reality, this may not be the case. Reconcile this idea with the classic coin toss example: Example on coin toss: Expected frequency is defined as the number of times that we predict an event will occur based on a calculation using theoretical probabilities. You know how a coin has two sides, heads or tails? That means that the probability of the coin landing on any one side is 50% (or 1/2, because it can land on one side out of two possible sides). If you flip a coin 1,000 times, how many times would you expect to get heads? About half the time, or 500 out of the 1,000 flips. To calculate the expected frequency, all we need to do is multiply the total number of tosses (1,000) by the probability of getting a heads (1/2), and we get 1,000 * 1/2 = 500 heads. if event A has prob of p happening, and sample size of n, then the average or expected number of times that A happens is \\(np\\) . The expected frequency of heads is 500 out of 1,000 total tosses. The expected frequency is based on our knowledge of probability - we haven't actually done any coin tossing. However, if we had enough time on our hands, we could actually flip a coin 1,000 times to experimentally test our prediction. If we did this, we would be calculating the experimental frequency. The experimental frequency is defined as the number of times that we observe an event to occur when we actually perform an experiment, test, or trial in real life. If you flipped a coin 1,000 times and it landed on heads 479 times, then the experimental frequency of heads is 479. But wait - didn't we predict the coin would land on heads 500 times? Why did it actually land on heads only 479 times? Well, the expected frequency was just that - what we expected to happen, based on our knowledge of probability. There are no guarantees when it comes to probability, what we expect to happen might differ from what actually happens. Since we know \\( \\(E_{2,2} = 10 \\times P(Y = 2 \\text{ and } \\widehat{Y} = 2) = 10 \\times P(Y = 2) \\cdot P(\\widehat{Y} = 2) = 10 \\times 30\\% \\times 40\\% = 1.2\\) \\) This \\(E_{2,2}\\) means that we only expect the rater A to choose 2 and rater B to choose 2 at the same time only 1.2 times out of 10 times. In other words, our predicted model classify 2 as 2 1.2 times. However, from our observations in our matrix C (confusion/histogram matrix), rater A choosing 2 and rater B choosing 2 have a frequency of 3! In other words, our predicted model classified 2 as 2 three times! So we kinda exceeded expectation for this particular configuration. \\[C = \\begin{bmatrix} 0 & 0 & 0 & 0 & 0\\\\ 0 & 3 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 0\\\\ 0 & 1 & 0 & 0 & 0\\\\ 4 & 0 & 1 & 0 & 0\\\\ \\end{bmatrix}\\] Let me give you one more example, \\( \\(E_{5,2} = 10 \\times P(Y = 5 \\text{ and } \\widehat{Y} = 2) = 10 \\times P(Y = 5) \\cdot P(\\widehat{Y} = 2) = 10 \\times 50\\% \\times 40\\% = 2\\) \\) This means that we only expect the rater A to choose 5 and rater B to choose 2 at the same time only 2 times out of 10 times! But in reality, our observations say that our rater B classified 5 as 2 zero times! We calculate \\(E_{i,j}\\) given by the formula: \\( \\(E_{i,j} = n \\times P(Y = i \\text{ and } \\widehat{Y} = j) = n \\times P(Y = i) \\times P (\\widehat{Y} = j) = n \\times \\dfrac{r_i}{n} \\times \\dfrac{c_j}{n}\\) \\) \\[E = \\begin{bmatrix} 0 & 0 & 0 & 0 & 0\\\\ 1.2 & 1.2 & 0.6 & 0 & 0 \\\\ 0.4 & 0.4 & 0.2 & 0 & 0\\\\ 0.4 & 0.4 & 0.2 & 0 & 0\\\\ 2 & 2 & 1 & 0 & 0\\\\ \\end{bmatrix}\\] Note \\(r_i \\times c_j\\) is the \\((i,j)\\) entry of the outer product between the actual histogram vector of outcomes (actual value counts) and the predicted histogram vector (prediction value counts). What does the random chance mean here? Simple, it just means that the probability for rater A (actual) to be class i AND for rater B (predicted) to be class j is \\(p\\%\\) (say 10%). Therefore, if we have made 100 predictions, random chance aka the theoratical probability tells us you should only have \\(100 \\times 10\\% = 10\\) predictions to be of this configuration (rater A class i AND rater B class j).","title":"Step 3: Create the Expected Matrix "},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#writing-out-the-expected-matrix-in-python","text":"So to get the expected matrix, E, is calculated assuming that there is no correlation between values. This is calculated as the outer product between the actual histogram vector of outcomes and the predicted histogram vector, normalized such that E and C have the same sum. Note carefully below that we do not need to normalize both, we just need to normalize E to the same sum as C. E = np . outer ( act_hist , pred_hist ) / 10 E C array([[0. , 0. , 0. , 0. , 0. ], [1.2, 1.2, 0.6, 0. , 0. ], [0.4, 0.4, 0.2, 0. , 0. ], [0.4, 0.4, 0.2, 0. , 0. ], [2. , 2. , 1. , 0. , 0. ]]) array([[0, 0, 0, 0, 0], [0, 3, 0, 0, 0], [0, 0, 1, 0, 0], [0, 1, 0, 0, 0], [4, 0, 1, 0, 0]], dtype=int64)","title":"Writing out the expected matrix in python"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#step-4-final-step-weighted-kappa-formula-and-its-python-codes","text":"From these three matrices: E, C and weighted, the quadratic weighted kappa is calculated as: \\[\\kappa = 1 - \\dfrac{\\sum_{i,j}\\text{weighted}_{i,j}C_{i,j}}{\\sum_{i,j}\\text{weighted}_{i,j}E_{i,j}}\\] Note that a higher value generally means your prediction model is way better than a random model, but there is no consensus on which value is really good or bad. \\[\\text{Weighted} = \\begin{bmatrix} 0 & 0.0625 & 0.25 & 0.5625 & 1\\\\ 0.0625 & 0 & 0.0625 & 0.25 & 0.5625 \\\\ 0.25 & 0.0625 & 0 & 0.0625 & 0.25\\\\ 0.5625 & 0.25 & 0.0625 & 0 & 0.0625\\\\ 1 & 0.5625 & 0.25 & 0.0625 & 0\\\\ \\end{bmatrix}\\] The notation \\(\\sum_{i,j}\\text{W}_{i,j}C_{i,j}\\) is just \\( \\(\\sum_{i=1}^{k}\\sum_{j=1}^{k} W_{i,j} C_{i,j} = (W_{1,1}C_{1,1} + W_{1,2}C_{1,2} + ...+ W_{1,k}C_{1,k}) + (W_{2,1}C_{2,1}+...+W_{2,k}C_{2,k}) +...+(W_{k,1}C_{k,1}+...+W_{k,k}C_{k,k})\\) \\) To put our understanding into perspective, consider just one entry \\(W_{5,1}C_{5,1} = 1 \\times 4 = 4\\) . This roughly means that our predicted model classified class 5 as class 1 FOUR times (re: \\(C_{5,1} = 4\\) ), and since class 5 is so far away from class 1, we need to punish this wrong prediction more than the others. And we did see that the corresponding weight \\(W_{5,1} = 1\\) is the highest weight. Consequently, the numerator being \\(\\sum_{i,j}\\text{W}_{i,j}C_{i,j}\\) calculates the total \"penalty cost\" for the rater A (our predicted model), and similarly, \\(\\sum_{i,j}\\text{W}_{i,j}E_{i,j}\\) calculates the total \"penalty cost\" for the rater B (our \"expected\" model). Therefore, you can think both values (num and den) as a cost function, and the lesser the better. And kappa formula tells us, if our \\(\\sum_{i,j}\\text{W}_{i,j}C_{i,j}\\) is significantly smaller than \\(\\sum_{i,j}\\text{W}_{i,j}E_{i,j}\\) , this will yield a very small value of \\( \\(\\dfrac{\\sum_{i,j}\\text{weighted}_{i,j}C_{i,j}}{\\sum_{i,j}\\text{weighted}_{i,j}E_{i,j}}\\) \\) which will yield a very high kappa value - signifying a better model. # Method 1 # apply the weights to the confusion matrix weighted = weighted_matrix ( 5 ) num = np . sum ( np . multiply ( weighted , C )) # apply the weights to the histograms den = np . sum ( np . multiply ( weighted , E )) kappa = 1 - np . divide ( num , den ) kappa -0.13924050632911378 # Method 2 num = 0 den = 0 for i in range ( len ( weighted )): for j in range ( len ( weighted )): num += weighted [ i ][ j ] * C [ i ][ j ] den += weighted [ i ][ j ] * E [ i ][ j ] weighted_kappa = ( 1 - ( num / den )); weighted_kappa -0.13924050632911378 # Method 3: Just use sk learn library cohen_kappa_score ( actual , pred , labels = None , weights = 'quadratic' , sample_weight = None ) -0.13924050632911378 Just a side note that one can also use SK learn's cohen_kappa_score function calculate the quadratic weighted kappa in this competition, with weights set to quadratic. Also please do refer to CPMP's discussion topic for fast QWK computation","title":"Step 4: Final Step: Weighted Kappa formula and Its python codes "},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#references","text":"Reference I Reference II Reference III","title":"References"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#accuracy","text":"Indicator Function - Wikipedia Why is accuracy not the best measure for assessing classification models? - StackExchange Example when using accuracy as an outcome measure will lead to a wrong conclusion - StackExchange Precision-Recall - Precision-Recall: Estimations of Probabilities - Wikipedia - Loss function and Decision Function - StatsExchange - Precision and Recall Tradeoff - Google","title":"Accuracy"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#receiver-operating-characteristic-roc_1","text":"","title":"Receiver Operating Characteristic (ROC)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#interpretation-of-roc","text":"Wikipedia has an extensive explanation of the probability behind ROC Different Interpretations of AUC - StatsExchange Probabilistic Perspective of AUC AUC - Insider's Guide to the Theory and Applications Safe Handling Instructions for Probabilistic Classification . c-statistics . SIIM Melanoma ROC An Introduction to ROC analysis","title":"Interpretation of ROC"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#pros-and-cons-of-auroc_1","text":"The Relationship Between Precision-Recall and ROC Curves Drawbacks of AUROC . ROC vs precision-and-recall curves ROC vs Precision-recall curves on imbalanced dataset on why AUC can be misleading AUC scale and threshold invariant - TDS","title":"Pros and Cons of AUROC"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#implementation","text":"Implementation of ROC - roc-curve-and-auc-from-scratch-in-numpy-visualized - TDS Trapezoid Rule On why thresholds return 2 sometimes (https://stackoverflow.com/questions/23200518/scikit-learn-roc-curve-why-does-it-return-a-threshold-value-2-some-time) PR-Curve vs ROC-Curve https://stackoverflow.com/questions/59666138/sklearn-roc-auc-score-with-multi-class-ovr-should-have-none-average-available https://stackoverflow.com/questions/39685740/calculate-sklearn-roc-auc-score-for-multi-class https://datascience.stackexchange.com/questions/36862/macro-or-micro-average-for-imbalanced-class-problems#:~:text=Micro%2Daverage%20is%20preferable%20if,your%20dataset%20varies%20in%20size. https://www.google.com/search?q=roc_auc_score+multiclass+site:stackoverflow.com&rlz=1C1CHBF_enSG891SG891&sxsrf=ALeKk018tRSfmKgIUw63SPI8dsdkvJgPuw:1608711331403&sa=X&ved=2ahUKEwjg7NDb1OPtAhUXVH0KHVNHCmwQrQIoBHoECAMQBQ&biw=1280&bih=610 https://stackoverflow.com/questions/56227246/how-to-calculate-roc-auc-score-having-3-classes https://glassboxmedicine.com/2019/02/23/measuring-performance-auc-auroc/ https://stackoverflow.com/questions/56227246/how-to-calculate-roc-auc-score-having-3-classes","title":"Implementation"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#precision-recall-curve_1","text":"","title":"Precision-Recall Curve"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/#interpretation-of-pr","text":"Damage Caused by Classification Accuracy and Other Discontinuous Improper Accuracy Scoring Rules - Frank Harrell Classification vs. Prediction - Frank Harrell","title":"Interpretation of PR"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\yhat}{\\mathbf{\\hat{y}}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\] Mean Absolute Error Mean Absolute Error is a risk metric corresponding to the expected value of the absolute error loss or \\(l1\\) -norm loss. Definition (Mean Absolute Error) Given a dataset of \\(n\\) samples indexed by the tuple pair \\((x_i, y_i)\\) , the mean absolute error (MAE) is defined as: \\[ \\textbf{MAE} = \\dfrac{\\sum_{i=1}^n |\\hat{y}_i - y_i|}{n} \\] Theorem (Optimality) In simple words, this is the property of the median minimizes the sum of absolute error ( \\({\\ell}_{1}\\) loss). This is important that one realises this when doing linear regression, and in complement to the mean minimizes the root mean squared error . For some proofs: https://en.wikipedia.org/wiki/Mean_absolute_error https://math.stackexchange.com/questions/113270/the-median-minimizes-the-sum-of-absolute-deviations-the-ell-1-norm Implementation of MAE import numpy as np def mean_absolute_error_ ( y_true : np . ndarray , y_pred : np . ndarray ) -> float : \"\"\"Mean absolute error regression loss. Args: y_true (np.ndarray): Ground truth (correct) target values. y_pred (np.ndarray): Estimated target values. Shape: y_true: (n_samples, ) y_pred: (n_samples, ) Returns: loss (float): The mean absolute error. Examples: >>> y_true = [3, -0.5, 2, 7] >>> y_pred = [2.5, 0.0, 2, 8] >>> mean_absolute_error_(y_true, y_pred) 0.5 \"\"\" y_true = np . asarray ( y_true ) . flatten () y_pred = np . asarray ( y_pred ) . flatten () loss = np . mean ( np . abs ( y_true - y_pred )) return loss >>> y_true = [ 3 , - 0.5 , 2 , 7 ] >>> y_pred = [ 2.5 , 0.0 , 2 , 8 ] >>> mean_absolute_error_ ( y_true , y_pred ) 0.5 (Root) Mean Squared Error Mean Squared Error is a risk metric corresponding to the expected value of the mean error loss or \\(l2\\) -norm loss. Definition (Root Mean Squared Error) Given a dataset of \\(n\\) samples indexed by the tuple pair \\((x_i, y_i)\\) , the mean squared error (MSE) is defined as: \\[ \\textbf{MSE} = \\dfrac{\\sum_{i=1}^n \\left(\\hat{y}_i - y_i\\right)^2}{n} \\] and for root mean squared error (RMSE) \\[ \\textbf{RMSE} = \\sqrt{\\dfrac{\\sum_{i=1}^n \\left(\\hat{y}_i - y_i\\right)^2}{n}} \\] Estimator The MSE of an estimator \\(\\hat{\\theta}\\) with respect to an unknown parameter \\(\\theta\\) is definend as: \\[ \\textbf{MSE}(\\hat{\\theta}) = E_{\\theta}\\left[\\left(\\hat{\\theta} - \\theta \\right)^2 \\right] \\] The MSE can also be written as the sum of the variance and squared bias of the estimator, in which case if the estimators are unbiased, we recover the MSE to be equivalent as the variance: \\[ \\textbf{MSE}(\\hat{\\theta}) = \\textbf{Var}_{\\theta}\\left(\\hat{\\theta} \\right) + \\textbf{Bias}\\left(\\hat{\\theta}, \\theta \\right)^2 \\] Proof of which can be found in Wikipedia: Mean_squared_error . Theorem (Optimality) The mean minimizes the mean squared error. Proof: https://math.stackexchange.com/questions/2554243/understanding-the-mean-minimizes-the-mean-squared-error Implementation of MSE def mean_squared_error_ ( y_true : np . ndarray , y_pred : np . ndarray , squared : bool = True ) -> float : \"\"\"Mean squared error regression loss. Args: y_true (np.ndarray): Ground truth (correct) target values. y_pred (np.ndarray): Estimated target values. squared (bool): If True, returns MSE; if False, returns RMSE. Shape: y_true: (n_samples, ) y_pred: (n_samples, ) Returns: loss (float): The mean squared error. Examples: >>> y_true = [3, -0.5, 2, 7] >>> y_pred = [2.5, 0.0, 2, 8] >>> mean_squared_error_(y_true, y_pred) 0.375 >>> mean_squared_error_(y_true, y_pred, squared=False) 0.612... \"\"\" y_true = np . asarray ( y_true ) . flatten () y_pred = np . asarray ( y_pred ) . flatten () loss = np . mean (( y_true - y_pred ) ** 2 ) return loss if squared else np . sqrt ( loss ) >>> y_true = [ 3 , - 0.5 , 2 , 7 ] >>> y_pred = [ 2.5 , 0.0 , 2 , 8 ] >>> mean_squared_error_ ( y_true , y_pred ) 0.375 >>> mean_squared_error_ ( y_true , y_pred , squared = False ) 0.6123724356957945 Probabilistic Interpretation We can also understand regression metrics through the lens of statistics. For further reading, one should understand the below topics: Loss Function: https://en.wikipedia.org/wiki/Loss_function#Expected_loss Risk Function: https://en.wikipedia.org/wiki/Risk_function In particular, one should have a basic knowledge on empirical risk minimization , that MSE can be understood as the empirical risk (average loss on an observed data set), as an estimate of the true MSE where the true risk refers to the average loss on the actual population distribution) 1 . MAE vs R(MSE) For convenience sake, we compare MAE vs MSE and only mention RMSE for some special properties. Robustness to Outliers The naive rule of thumb points to the urban saying that MSE penalizes large errors while MAE does not. Let us see a simple example: \\(y = 10\\) ; \\(\\hat{y}_{1} = 15\\) \\(\\hat{y}_{2} = 20\\) where \\(\\hat{y}_{1}\\) and \\(\\hat{y}_{2}\\) are both predictions made on the ground truth \\(y = 10\\) . Then we easily see that: \\(\\textbf{MAE}(y, \\hat{y}_{1}) = 5\\) \\(\\textbf{MAE}(y, \\hat{y}_{2}) = 10\\) \\(\\textbf{MSE}(y, \\hat{y}_{1}) = 25\\) \\(\\textbf{MSE}(y, \\hat{y}_{2}) = 100\\) We note that \\(\\hat{y}_{1}\\) is off by 5 and \\(\\hat{y}_{2}\\) is off by 10 from the ground truth. When comparing \\(\\hat{y}_{1}\\) to \\(\\hat{y}_{2}\\) , we conclude that \\(\\hat{y}_{2}\\) is off by exactly twice as \\(\\hat{y}_{1}\\) . Now, if we use MAE, we find out that by definition, the loss of \\(\\hat{y}_{2}\\) will also be exactly twice of that \\(\\hat{y}_{1}\\) but for MSE, it will be four times. We then can naively conclude that if your errors being off by 10 if twice as bad as being off by 5, then one should use MAE, if you foresee that being off by 10 is more than twice as bad as being off by 5, then MSE is better. 2 To put things in perspective, if you are predicting (.. fill in a good example). Ease of Interpretation MAE clearly wins as the interpretation of this metric is simple. The units are on the same scale. References https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d https://en.wikipedia.org/wiki/Mean_squared_error \u21a9 https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d \u21a9","title":"MAE and MSE"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/#mean-absolute-error","text":"Mean Absolute Error is a risk metric corresponding to the expected value of the absolute error loss or \\(l1\\) -norm loss.","title":"Mean Absolute Error"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/#definition-mean-absolute-error","text":"Given a dataset of \\(n\\) samples indexed by the tuple pair \\((x_i, y_i)\\) , the mean absolute error (MAE) is defined as: \\[ \\textbf{MAE} = \\dfrac{\\sum_{i=1}^n |\\hat{y}_i - y_i|}{n} \\]","title":"Definition (Mean Absolute Error)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/#theorem-optimality","text":"In simple words, this is the property of the median minimizes the sum of absolute error ( \\({\\ell}_{1}\\) loss). This is important that one realises this when doing linear regression, and in complement to the mean minimizes the root mean squared error . For some proofs: https://en.wikipedia.org/wiki/Mean_absolute_error https://math.stackexchange.com/questions/113270/the-median-minimizes-the-sum-of-absolute-deviations-the-ell-1-norm","title":"Theorem (Optimality)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/#implementation-of-mae","text":"import numpy as np def mean_absolute_error_ ( y_true : np . ndarray , y_pred : np . ndarray ) -> float : \"\"\"Mean absolute error regression loss. Args: y_true (np.ndarray): Ground truth (correct) target values. y_pred (np.ndarray): Estimated target values. Shape: y_true: (n_samples, ) y_pred: (n_samples, ) Returns: loss (float): The mean absolute error. Examples: >>> y_true = [3, -0.5, 2, 7] >>> y_pred = [2.5, 0.0, 2, 8] >>> mean_absolute_error_(y_true, y_pred) 0.5 \"\"\" y_true = np . asarray ( y_true ) . flatten () y_pred = np . asarray ( y_pred ) . flatten () loss = np . mean ( np . abs ( y_true - y_pred )) return loss >>> y_true = [ 3 , - 0.5 , 2 , 7 ] >>> y_pred = [ 2.5 , 0.0 , 2 , 8 ] >>> mean_absolute_error_ ( y_true , y_pred ) 0.5","title":"Implementation of MAE"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/#root-mean-squared-error","text":"Mean Squared Error is a risk metric corresponding to the expected value of the mean error loss or \\(l2\\) -norm loss.","title":"(Root) Mean Squared Error"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/#definition-root-mean-squared-error","text":"Given a dataset of \\(n\\) samples indexed by the tuple pair \\((x_i, y_i)\\) , the mean squared error (MSE) is defined as: \\[ \\textbf{MSE} = \\dfrac{\\sum_{i=1}^n \\left(\\hat{y}_i - y_i\\right)^2}{n} \\] and for root mean squared error (RMSE) \\[ \\textbf{RMSE} = \\sqrt{\\dfrac{\\sum_{i=1}^n \\left(\\hat{y}_i - y_i\\right)^2}{n}} \\]","title":"Definition (Root Mean Squared Error)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/#estimator","text":"The MSE of an estimator \\(\\hat{\\theta}\\) with respect to an unknown parameter \\(\\theta\\) is definend as: \\[ \\textbf{MSE}(\\hat{\\theta}) = E_{\\theta}\\left[\\left(\\hat{\\theta} - \\theta \\right)^2 \\right] \\] The MSE can also be written as the sum of the variance and squared bias of the estimator, in which case if the estimators are unbiased, we recover the MSE to be equivalent as the variance: \\[ \\textbf{MSE}(\\hat{\\theta}) = \\textbf{Var}_{\\theta}\\left(\\hat{\\theta} \\right) + \\textbf{Bias}\\left(\\hat{\\theta}, \\theta \\right)^2 \\] Proof of which can be found in Wikipedia: Mean_squared_error .","title":"Estimator"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/#theorem-optimality_1","text":"The mean minimizes the mean squared error. Proof: https://math.stackexchange.com/questions/2554243/understanding-the-mean-minimizes-the-mean-squared-error","title":"Theorem (Optimality)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/#implementation-of-mse","text":"def mean_squared_error_ ( y_true : np . ndarray , y_pred : np . ndarray , squared : bool = True ) -> float : \"\"\"Mean squared error regression loss. Args: y_true (np.ndarray): Ground truth (correct) target values. y_pred (np.ndarray): Estimated target values. squared (bool): If True, returns MSE; if False, returns RMSE. Shape: y_true: (n_samples, ) y_pred: (n_samples, ) Returns: loss (float): The mean squared error. Examples: >>> y_true = [3, -0.5, 2, 7] >>> y_pred = [2.5, 0.0, 2, 8] >>> mean_squared_error_(y_true, y_pred) 0.375 >>> mean_squared_error_(y_true, y_pred, squared=False) 0.612... \"\"\" y_true = np . asarray ( y_true ) . flatten () y_pred = np . asarray ( y_pred ) . flatten () loss = np . mean (( y_true - y_pred ) ** 2 ) return loss if squared else np . sqrt ( loss ) >>> y_true = [ 3 , - 0.5 , 2 , 7 ] >>> y_pred = [ 2.5 , 0.0 , 2 , 8 ] >>> mean_squared_error_ ( y_true , y_pred ) 0.375 >>> mean_squared_error_ ( y_true , y_pred , squared = False ) 0.6123724356957945","title":"Implementation of MSE"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/#probabilistic-interpretation","text":"We can also understand regression metrics through the lens of statistics. For further reading, one should understand the below topics: Loss Function: https://en.wikipedia.org/wiki/Loss_function#Expected_loss Risk Function: https://en.wikipedia.org/wiki/Risk_function In particular, one should have a basic knowledge on empirical risk minimization , that MSE can be understood as the empirical risk (average loss on an observed data set), as an estimate of the true MSE where the true risk refers to the average loss on the actual population distribution) 1 .","title":"Probabilistic Interpretation"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/#mae-vs-rmse","text":"For convenience sake, we compare MAE vs MSE and only mention RMSE for some special properties.","title":"MAE vs R(MSE)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/#robustness-to-outliers","text":"The naive rule of thumb points to the urban saying that MSE penalizes large errors while MAE does not. Let us see a simple example: \\(y = 10\\) ; \\(\\hat{y}_{1} = 15\\) \\(\\hat{y}_{2} = 20\\) where \\(\\hat{y}_{1}\\) and \\(\\hat{y}_{2}\\) are both predictions made on the ground truth \\(y = 10\\) . Then we easily see that: \\(\\textbf{MAE}(y, \\hat{y}_{1}) = 5\\) \\(\\textbf{MAE}(y, \\hat{y}_{2}) = 10\\) \\(\\textbf{MSE}(y, \\hat{y}_{1}) = 25\\) \\(\\textbf{MSE}(y, \\hat{y}_{2}) = 100\\) We note that \\(\\hat{y}_{1}\\) is off by 5 and \\(\\hat{y}_{2}\\) is off by 10 from the ground truth. When comparing \\(\\hat{y}_{1}\\) to \\(\\hat{y}_{2}\\) , we conclude that \\(\\hat{y}_{2}\\) is off by exactly twice as \\(\\hat{y}_{1}\\) . Now, if we use MAE, we find out that by definition, the loss of \\(\\hat{y}_{2}\\) will also be exactly twice of that \\(\\hat{y}_{1}\\) but for MSE, it will be four times. We then can naively conclude that if your errors being off by 10 if twice as bad as being off by 5, then one should use MAE, if you foresee that being off by 10 is more than twice as bad as being off by 5, then MSE is better. 2 To put things in perspective, if you are predicting (.. fill in a good example).","title":"Robustness to Outliers"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/#ease-of-interpretation","text":"MAE clearly wins as the interpretation of this metric is simple. The units are on the same scale.","title":"Ease of Interpretation"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mae_rmse/#references","text":"https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d https://en.wikipedia.org/wiki/Mean_squared_error \u21a9 https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d \u21a9","title":"References"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mape/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\yhat}{\\mathbf{\\hat{y}}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\] Mean Absolute Percentage Error This is a metric that measures the relative error and hence an intuitive metric. Definition (Mean Absolute Percentage Error) Given a dataset of \\(n\\) samples indexed by the tuple pair \\((x_i, y_i)\\) , the mean absolute percentage error (MAPE) is defined as: \\[ \\textbf{MAPE} = \\dfrac{1}{n} \\dfrac{\\sum_{i=1}^n |\\hat{y}_i - y_i|}{\\max(\\epsilon, |y_i|)} \\] where \\(\\epsilon\\) is an arbitarily small and positive number in case the ground truth \\(y_i\\) is \\(0\\) . Implementation of MAPE def mean_absolute_percentage_error_ ( y_true : np . ndarray , y_pred : np . ndarray , epsilon : float = 1e-5 ) -> float : \"\"\"Mean absolute percentage error (MAPE) regression loss. Note: Loss can be extremely high when `y_true` is near 0 since the denominator will be epislon, and np.abs(y_true - y_pred) / epislon will be very large. Args: y_true (np.ndarray): Ground truth (correct) target values. y_pred (np.ndarray): Estimated target values. epsilon (float, optional): An arbitrarily small positive number for numerical stability in case y_true is 0 or near 0. Defaults to 1e-5. Shape: y_true: (n_samples, ) y_pred: (n_samples, ) Returns: loss (float): The mean absolute percentage error. Examples: >>> y_true = [3, -0.5, 2, 7] >>> y_pred = [2.5, 0.0, 2, 8] >>> mean_absolute_percentage_error_(y_true, y_pred) 0.3273... \"\"\" y_true = np . asarray ( y_true ) . flatten () y_pred = np . asarray ( y_pred ) . flatten () print ( np . maximum . outer ( y_true , epsilon )) loss = np . mean ( np . abs (( y_true - y_pred ) / np . maximum . outer ( np . abs ( y_true ), epsilon )) ) return loss >>> y_true = [ 3 , - 0.5 , 2 , 7 ] >>> y_pred = [ 2.5 , 0.0 , 2 , 8 ] >>> mean_absolute_percentage_error_ ( y_true , y_pred ) [3.e+00 1.e-05 2.e+00 7.e+00] 0.3273809523809524","title":"MAPE"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mape/#mean-absolute-percentage-error","text":"This is a metric that measures the relative error and hence an intuitive metric.","title":"Mean Absolute Percentage Error"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mape/#definition-mean-absolute-percentage-error","text":"Given a dataset of \\(n\\) samples indexed by the tuple pair \\((x_i, y_i)\\) , the mean absolute percentage error (MAPE) is defined as: \\[ \\textbf{MAPE} = \\dfrac{1}{n} \\dfrac{\\sum_{i=1}^n |\\hat{y}_i - y_i|}{\\max(\\epsilon, |y_i|)} \\] where \\(\\epsilon\\) is an arbitarily small and positive number in case the ground truth \\(y_i\\) is \\(0\\) .","title":"Definition (Mean Absolute Percentage Error)"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/mape/#implementation-of-mape","text":"def mean_absolute_percentage_error_ ( y_true : np . ndarray , y_pred : np . ndarray , epsilon : float = 1e-5 ) -> float : \"\"\"Mean absolute percentage error (MAPE) regression loss. Note: Loss can be extremely high when `y_true` is near 0 since the denominator will be epislon, and np.abs(y_true - y_pred) / epislon will be very large. Args: y_true (np.ndarray): Ground truth (correct) target values. y_pred (np.ndarray): Estimated target values. epsilon (float, optional): An arbitrarily small positive number for numerical stability in case y_true is 0 or near 0. Defaults to 1e-5. Shape: y_true: (n_samples, ) y_pred: (n_samples, ) Returns: loss (float): The mean absolute percentage error. Examples: >>> y_true = [3, -0.5, 2, 7] >>> y_pred = [2.5, 0.0, 2, 8] >>> mean_absolute_percentage_error_(y_true, y_pred) 0.3273... \"\"\" y_true = np . asarray ( y_true ) . flatten () y_pred = np . asarray ( y_pred ) . flatten () print ( np . maximum . outer ( y_true , epsilon )) loss = np . mean ( np . abs (( y_true - y_pred ) / np . maximum . outer ( np . abs ( y_true ), epsilon )) ) return loss >>> y_true = [ 3 , - 0.5 , 2 , 7 ] >>> y_pred = [ 2.5 , 0.0 , 2 , 8 ] >>> mean_absolute_percentage_error_ ( y_true , y_pred ) [3.e+00 1.e-05 2.e+00 7.e+00] 0.3273809523809524","title":"Implementation of MAPE"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/regression_metrics/","text":"This notebook attempts to describe the commonly used Regression Metrics in details; you will find the pros and cons of each metric, alongside with examples to illustrate. I will refer to scikit-learn's official website for reference, specifically, the section on Model Evaluation . I may quote some definitions verbatim, if necessary. Predicting a scalar Squared error penalizes larger differences more than Absolute error, but it is prone to outliers. If you can about making sense of units, then root mean squared error. Predicting a vector See Word2Vec. Cosine Similarity","title":"Introduction"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/regression_metrics/#predicting-a-scalar","text":"Squared error penalizes larger differences more than Absolute error, but it is prone to outliers. If you can about making sense of units, then root mean squared error.","title":"Predicting a scalar"},{"location":"reighns_ml_journey/machine_learning_and_deep_learning/metrics/regression_metrics/regression_metrics/#predicting-a-vector","text":"See Word2Vec. Cosine Similarity","title":"Predicting a vector"},{"location":"reighns_ml_journey/mathematics/general_mathematical_terms_and_definitions/","text":"Contour Plots Khan's Academy: Watch this first! PythonDataScienceHandbook","title":"General Mathematic Terms and Definitions"},{"location":"reighns_ml_journey/mathematics/general_mathematical_terms_and_definitions/#contour-plots","text":"Khan's Academy: Watch this first! PythonDataScienceHandbook","title":"Contour Plots"},{"location":"reighns_ml_journey/mathematics/gradient_descent/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\x}{\\mathbf{x}} \\] Gradient Descent In mathematics, gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent. 1 This blog answers two questions: How does the gradient descent algorithm work? Why does the gradient points in the direction of the steepest ascent? In many articles and courses, gradient descent is often used to find the minimum of a function, by way of the following procedure: \\({\\color{red} \\textbf{To rewrite this pseudocode}}\\) 1. Start at the initial point. 2. Take a step in the opposite direction of the gradient. 3. Repeat steps 2 and 3 until the function is no longer decreasing. 4. The point where the function is no longer decreasing is the minimum. Our second question is equivalent to answering the point 2, on why do we take a step in the opposite direction of the gradient. The Intuition Quote wikipedia's example. The idea of neighbourhood Let us start with an one-dimensional example to illustrate the idea of neighbourhood. Define \\(f: \\R \\to \\R\\) to be \\(f(x) = x^2\\) , then the gradient of \\(f\\) at a point \\(x = x_0\\) is \\(\\frac {\\partial f(x)} {\\partial x} \\vert x_0 = 2x_0\\) . A wrong interpretation is to treat the understanding of gradient as if it is a linear function. Let us fix a point \\(x = 2\\) , its output \\(f(x) = 4\\) and the gradient at that point is \\(\\frac {\\partial f(x)} {\\partial x} \\vert_{x=2} = 4\\) . It is wrong to say that for every \\(1\\) unit increase of \\(x\\) , \\(f(x)\\) will increase by \\(4\\) , where \\(4\\) is the gradient at that point. One can indeed verify that if \\(x\\) is increased by \\(1\\) unit from \\(x=2\\) to \\(x = 3\\) , then \\(f(x) = 3^2 = 9\\) , where \\(f(x)\\) is increased by \\(5\\) units, and not by \\(4\\) . Unlike the case of a linear function, the gradient of \\(f\\) at a point \\(x = x_0\\) is not fixed, but depends on the value of \\(x_0\\) . Consequently, the meaning of the gradient in such a function is only well defined in a small \\(\\epsilon\\) -neighbourhood 2 around \\(x = 2\\) . Within this small neighbourhood, we can \"loosely\" visualize the portion of the function to be a \"linear function\" with a slope of \\(2\\) , as illustrated in the following figure. The enclosed green box is the neighborhood of \\(x = 2\\) , where if we zoom in, the portion of the function inside looks like a linear function with a slope of \\(2\\) . Neighbourhood around x = 2. Indeed, if we set \\(\\epsilon = 0.001\\) , then if \\(x = 2\\) , we have \\(f(x) = 4\\) ; moving \\(x\\) by \\(\\epsilon\\) from \\(x = 2\\) to \\(x = 2.001\\) yields us \\(f(x) \\approxeq 4.004\\) . We now see that \\(x\\) increasing by \\(0.001\\) unit indeed yields us an increase of \\(4.004 - 4 = 0.004\\) , a factor of \\(4\\) increase to the output \\(f(x)\\) . Gradient Vector Definition: Gradient Vector Let \\(f: \\R^n \\to \\R\\) be a function that maps \\(\\x\\) to \\(f(\\x)\\) : \\[ \\begin{align*} f \\colon \\R^n &\\longrightarrow \\R \\\\ \\x &\\longmapsto f(\\x) \\\\ \\end{align*} \\] where \\(\\x = [x_1, x_2, \\ldots, x_n]^\\top\\) is a vector of \\(n\\) variables. Then the gradient of \\(f\\) is the vector of first-order partial derivatives of \\(f\\) with respect to each of the \\(n\\) variables. \\[ \\begin{equation} \\nabla f(\\x) = \\bigg[\\frac{\\partial f(\\x)}{\\partial x_1}, \\frac{\\partial f(\\x)}{\\partial x_2}, \\ldots, \\frac{\\partial f(\\x)}{\\partial x_n} \\bigg]^\\top \\label{eq:grad_vec} \\end{equation} \\] We can also replace the notation \\(\\frac{\\partial f(\\x)}{\\partial x_i}\\) in equation \\(\\eqref{eq:grad_vec}\\) with \\(f_{x_i}\\) . Directional Derivatives Definition: Directional Derivative Let \\(f: \\R^n \\to \\R\\) be a function that maps \\(\\x\\) to \\(f(\\x)\\) : \\[ \\begin{align*} f \\colon \\R^n &\\longrightarrow \\R \\\\ \\x &\\longmapsto f(\\x) \\\\ \\end{align*} \\] where \\(\\x = [x_1, x_2, \\ldots, x_n]^\\top\\) is a vector of \\(n\\) variables. Then the directional derivative of \\(f\\) at a point \\(\\x\\) along a direction vector \\[ \\v = [v_1, v_2, \\ldots, v_n]^\\top \\] is the function \\(D_{\\v}(f)\\) defined by the limit: \\[ \\begin{equation} D_{\\v}(f) = \\lim_{h \\to 0} \\frac{f(\\x + h\\v) - f(\\x)}{h} \\label{eq:directional_derivative_def} \\end{equation} \\] To avoid notation confusion and also understand the definition better, we use a simple example in 2-dimensional to illustrate the definition of the directional derivative. Example: Directional Derivative Let \\(f: \\R^2 \\to \\R\\) be defined as \\[ f(\\x) = f(x_1, x_2) = x_1^2 + x_2^2 \\] where \\(\\x\\) is a vector of scalar values \\(x_1\\) and \\(x_2\\) , both corresponds to the x- and y-coordinates of a point in the plane respectively. Following closely the definition, we need to define a direction vector \\(\\v\\) . Since the definition did not say what \\(\\v\\) was, we can define \\(\\v\\) to be the unit vector in the south-east direction. \\[ \\v = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} \\] We also note that we want to compute the directional derivative of \\(f\\) at a point \\((x_1, x_2)\\) , where we arbitrarily choose \\((x_1, x_2) = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\) . Then, we can define the directional derivative of \\(f\\) at the point \\(\\x = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\) along \\(\\v = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}\\) as: \\[ \\begin{equation*} \\begin{split} D_{\\v}(f(1, 1)) &= \\lim_{h \\to 0} \\frac{f(\\x + h\\v) - f(\\x)}{h} \\\\ &= \\lim_{h \\to 0} \\frac{f(x_1 + hv_1, x_2 + hv_2) - f(x_1, x_2)}{h} \\\\ &= \\lim_{h \\to 0} \\frac{f(1 + h, 1 - h) - f(1, 1)}{h} \\end{split} \\end{equation*} \\] which evaluates to how much \\(f\\) changes when it moves a small unit distance \\(h\\) from \\(\\x\\) to \\(\\x + h\\) along the direction \\(\\v\\) . Intuition of Directional Derivative This section builds up to an important derivation of the idea of the directional derivative. Warning In this section, we should constantly recall the idea of a neighbourhood whenever we talk about per unit change, we should visualize that this unit is very small. Let us restrict our focus to 2-variable mutlivariate function \\(f(x, y)\\) , bearing in mind that it can be scaled up to \\(n\\) variables. The components of \\(\\nabla f\\) are the partial derivatives of \\(f\\) with respect to \\(x\\) and \\(y\\) . More concretely, given the partial derivative \\[ \\begin{equation} \\frac{\\partial f(x, y)}{\\partial x} \\label{eq:partial_x} \\end{equation} \\] equation \\(\\eqref{eq:partial_x}\\) answers the question: how much does the value of \\(f\\) change when we hold \\(y\\) constant and nudge \\(x\\) by a small amount in the \\(x\\) direction (i.e. in the direction pointed to by the vector \\(\\begin{bmatrix} 1 & 0 \\end{bmatrix}^\\top\\) )? 3 In a similar vein, given the partial derivative \\[ \\begin{equation} \\frac{\\partial f(x, y)}{\\partial y} \\label{eq:partial_y} \\end{equation} \\] equation \\(\\eqref{eq:partial_y}\\) answers the question: how much does the value of \\(f\\) change when we hold \\(x\\) constant and nudge \\(y\\) by a small amount in the \\(y\\) direction (i.e. in the direction pointed to by the vector \\(\\begin{bmatrix} 0 & 1 \\end{bmatrix}^\\top\\) )? 4 Finally, it is often useful to note that \\(x\\) and \\(y\\) can move in tandem (i.e. we do not hold any of them constant), how do we then calculate how much \\(f\\) changes when we nudge both \\(x\\) and \\(y\\) by a small amount. Note that moving \\(x\\) and \\(y\\) both by \\(a\\) and \\(b\\) respectively is synonymous with moving the point \\((x, y)\\) by the vector \\(\\begin{bmatrix} a & b \\end{bmatrix}^\\top\\) . With vector in the playing field, we now attach the notion of a \"direction\". We can use equation \\(\\eqref{eq:directional_derivative_def}\\) to compute how much \\(f\\) changes when we nudge the points \\(x\\) and \\(y\\) by a small amount in the \\(x\\) and \\(y\\) directions respectively. However, the calculation is cumbersome if we use the definition of the directional derivative. We will now use an example to derive an alternate formula by relating directional derivative to their partial derivatives composition. Example If we want to move \\(x\\) and \\(y\\) by \\(1\\) and \\(-1\\) respectively, then it simply means that \\(x\\) is moved 1 unit along the \\(x\\) axis and \\(y\\) is moved -1 unit along the \\(y\\) axis. In vector terms, this means we moved \\((x, y)\\) in the direction \\(\\begin{bmatrix} 1 & -1 \\end{bmatrix}^\\top\\) . More generically, let \\(x\\) and \\(y\\) move \\(a\\) and \\(b\\) units respectively, then we moved \\((x, y)\\) in the direction \\(\\begin{bmatrix} a & b \\end{bmatrix}^\\top\\) . It turns out that the amount that \\(f\\) changes when we move in the \\(\\v = \\begin{bmatrix} a & b \\end{bmatrix}^\\top\\) direction is exactly how much \\(f\\) changes when we move \\(a\\) units along the \\(x\\) axis and \\(b\\) units along the \\(y\\) axis 5 . Recall that we know how much \\(f\\) changes when we move \\(x\\) by 1 unit: The partial derivative of \\(f\\) with respect to \\(x\\) : \\(\\frac{\\partial f(x, y)}{\\partial x}\\) Recall that we know how much \\(f\\) changes when we move \\(y\\) by 1 unit: The partial derivative of \\(f\\) with respect to \\(y\\) : \\(\\frac{\\partial f(x, y)}{\\partial y}\\) It follows that if we move \\(x\\) by \\(a\\) units, then \\(f\\) changes by \\(a \\cdot \\frac{\\partial f(x, y)}{\\partial x}\\) and if we move \\(y\\) by \\(b\\) units, then \\(f\\) changes by \\(b \\cdot \\frac{\\partial f(x, y)}{\\partial y}\\) Therefore, the amount that \\(f\\) changes when we move \\(x\\) by \\(a\\) units and \\(y\\) by \\(b\\) units is \\(a \\cdot \\frac{\\partial f(x, y)}{\\partial x} + b \\cdot \\frac{\\partial f(x, y)}{\\partial y}\\) One might notice that for multivariate \\(f:\\R^n \\to \\R\\) , the derivative \\(D_{\\v}(f)\\) at the point \\(x \\in \\R^n\\) is defined to be a linear map \\(T: \\R^n \\to \\R\\) . Therefore, the linearity rule applies. If the above is still not obvious, then we can approach it geometrically. Recall that we are mapping from \\(\\R^2\\) to \\(\\R\\) , the below diagram illustrates the mapping. Geometric Intuition. Theorem (The Direction Derivative) The intuition developed in the previous section allows us to derive a new formula to calculate the directional derivative of \\(f\\) at a point \\(\\x\\) when moved in the direction of \\(\\v\\) . Although the example used is in 2-dimensions, we can generalize to \\(n\\) variables and we state it formally. Theorem: Directional Derivative Let \\(f: \\R^n \\to \\R\\) be a function \\(f(\\x)\\) where \\(\\x = [x_1, x_2, \\ldots, x_n]^\\top\\) is a vector of \\(n\\) variables. If \\(f\\) is differentiable at \\(\\x\\) , then the directional derivative \\(D_{\\v}(f)\\) at \\(\\x\\) is defined as follows: \\[ \\begin{equation} D_{\\v}(f(\\x)) = \\nabla f(\\x) \\cdot \\v \\label{eq:directional_derivative_theorem} \\end{equation} \\] In most textbooks, we will normalize the direction vector \\(\\v\\) to the standard unit vector \\(\\u\\) . However, the usage of unit vector simplifies the derivation and other applications 6 7 , it is not an universal rule. Important It is extremely important to remember that the gradient vector of \\(f\\) at \\(\\x\\) is already defined as \\(\\nabla f(\\x)\\) , to be the vector of partial derivatives of \\(f\\) at \\(\\x\\) . This has two consequences: Given the gradient vector of \\(f\\) at \\(\\x\\) and any direction \\(\\v\\) , we can recover the directional derivative \\(D_{\\v}(f)\\) at \\(\\x\\) by simply multiplying it by \\(\\v\\) . Given the gradient vector of \\(f\\) at \\(\\x\\) and a scalar value directional derivative \\(D_{\\v}(f)\\) , we can recover the direction \\(\\v\\) by division. One variant of the proof: Info The Difference between Gradient and Directional Derivative 8 When I was learning multivariate calculus, I have had my fair share of trouble with the difference between the gradient and the directional derivative. It is easy to confuse the two terms. Let us go back to the definitions: The gradient of a mutlivariate function \\(f\\) at a point \\(\\x\\) is the vector of partial derivatives of \\(f\\) at \\(\\x\\) , as defined in equation \\(\\eqref{eq:grad_vec}\\) . \\[ \\nabla f(\\x) = \\bigg[\\frac{\\partial f(\\x)}{\\partial x_1}, \\frac{\\partial f(\\x)}{\\partial x_2}, \\ldots, \\frac{\\partial f(\\x)}{\\partial x_n} \\bigg]^\\top \\] The directional derivative of a mutlivariate function \\(f\\) at a point \\(\\x\\) is the scalar value of the partial derivative of \\(f\\) at \\(\\x\\) in the direction of \\(\\v\\) , as defined in equation \\(\\eqref{eq:directional_derivative_def}\\) and \\(\\eqref{eq:directional_derivative_theorem}\\) . There are infinite directional derivatives around a point \\(\\x\\) since there are infinitely many directions \\(\\v\\) . However, there is only one gradient vector around a point \\(\\x\\) and this is defined to be the vector that is the steepest ascent, which we will prove in the next section. Consider the following example: We have a point \\((x, y)\\) in \\(f\\) , where \\(f\\) is a function of two variables. Since this function can be graphed in 3-dimensions, we can visualize that there are infinite number of directions around the point \\((x, y)\\) . We can categorize the directions around the point as vectors \\(\\v\\) . For simplicity, we restrict \\(\\v\\) to be unit vectors. Recall the definition of the directional derivative of \\(f\\) at a point \\(\\x\\) to be a scalar-valued function \\(D_{\\v}(f)\\) parametrized by the direction vector \\(\\v\\) . We also note that \\(D_{\\v}(f)\\) is the instantaneous rate of change of \\(f\\) when we move in the direction \\(\\v\\) . There exists infinite number of such directional derivatives of \\(f\\) at a point \\(\\x\\) since there are infinite number of directions \\(\\v\\) . This can be seen by the orange arrows. However, there exists an unique direction \\(\\v\\) which gives rise to the fastest instantaneous rate of change of \\(f\\) when moved in that direction. This unique direction points in the same direction as the gradient vector \\(\\v\\) . Infinite directions around a point in cross-sectional plane of 3d-figure. Gradient Points to the Direction of Steepest Ascent We finally have the necessary definitions and theorems to prove the following statement: The direction of steepest ascent of a function \\(f: \\R^n \\to \\R\\) is given by the gradient vector of \\(f\\) at a point \\(\\x = \\begin{bmatrix} x_1 & x_2 & \\ldots & x_n \\end{bmatrix}^\\top\\) . In other words, \\(f\\) increases the fastest when we move in the direction of the gradient vector . Before we prove this, it is best for us to rephrase the question to: Given a function \\(f\\) and a point \\(\\x\\) , which direction vector (unit vector) \\(\\v\\) gives the fastest rate of change of \\(f\\) when moved in that direction? This can be then be found easily by following the theorem/definition in the section on the alternative definition of the directional derivative . Info The logic is that the directional derivative of \\(f\\) at \\(\\x\\) is the rate of change , then it suffices to find the direction vector \\(\\v\\) that gives the fastest rate of change . The definition \\(\\eqref{eq:directional_derivative_theorem}\\) states that \\(D_{\\v}(f(\\x)) = \\nabla f(\\x) \\cdot \\v\\) . We then seek to solve the optimization problem: \\[ \\begin{align} \\v_{\\max} &= \\underset{\\v, \\lVert \\v \\rVert = 1}{\\operatorname{argmax}}D_{\\v}(f(\\x)) \\label{eq:steepest_ascent_1} \\\\ &= \\underset{\\v, \\lVert \\v \\rVert = 1}{\\operatorname{argmax}}\\nabla f(\\x) \\cdot \\v \\label{eq:steepest_ascent_2} \\\\ &= \\underset{\\v, \\lVert \\v \\rVert = 1}{\\operatorname{argmax}} \\lVert \\nabla f(\\x) \\rVert \\cdot \\lVert \\v \\rVert \\cos(\\theta) \\label{eq:steepest_ascent_3} \\\\ \\end{align} \\] where we want to find the unique \\(\\v_{\\max}\\) such that \\(D_{\\v}(f(\\x))\\) is the maximum . In equation \\(\\eqref{eq:steepest_ascent_3}\\) , we invoked the geometric definition of the dot product to represent the dot product as the cosine of the angle between the two vectors . Since we are optimizing over \\(\\v\\) and the length of \\(\\v\\) is 1, we can simplify the expression to: \\[ \\begin{align} \\v_{\\max} &= \\underset{\\v, \\lVert \\v \\rVert = 1}{\\operatorname{argmax}} \\lVert \\nabla f(\\x) \\rVert \\cdot \\lVert \\v \\rVert \\cos(\\theta) \\\\ &= \\underset{\\v}{\\operatorname{argmax}} \\lVert \\nabla f(\\x) \\rVert \\cos(\\theta) \\label{eq:steepest_ascent_4} \\\\ &= \\underset{\\v}{\\operatorname{argmax}} \\cos(\\theta) \\label{eq:steepest_ascent_5} \\\\ \\end{align} \\] where In equation \\(\\eqref{eq:steepest_ascent_4}\\) , \\(\\lVert \\v \\rVert\\) was dropped since it is 1; In equation \\(\\eqref{eq:steepest_ascent_5}\\) , \\(\\lVert \\nabla f(\\x) \\rVert\\) was dropped since it is not a function of \\(\\v\\) and hence it is irrelevant. \\(\\theta\\) , however, being the angle between \\(\\v\\) and \\(\\nabla f(\\x)\\) , is dependent on \\(\\v\\) . Therefore, \\(\\cos(\\theta)\\) is maximal when \\(\\cos(\\theta) = 1 \\implies \\theta = 0\\) . Consequently, \\(\\theta = 0\\) implies \\(\\nabla f(\\x)\\) and \\(\\v\\) are parallel. Note At this point, we have answered the question posed: Given a function \\(f\\) and a point \\(\\x\\) , which direction vector (unit vector) \\(\\v\\) gives the fastest rate of change of \\(f\\) when moved in that direction? It turns out this direction/unit vector we are finding is the gradient vector \\(\\nabla f(\\x)\\) itself, but reduced to its unit vector since we proved that \\(\\v \\parallel \\nabla f(\\x)\\) . As a result, we can then say that \\(f\\) increases the fastest when we move in the direction of the gradient vector \\(\\nabla f(\\x)\\) . It is worth noting that the rate of change of \\(f\\) at a point \\(\\x\\) in the direction of the gradient vector \\(\\nabla f(\\x)\\) is given by the magnitude of the gradient vector itself. 9 Success We finally convinced ourselves that subtracting the gradient vector indeed (local) minimizes the objective/loss function provided it's differentiable. References Bibliography. https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/the-gradient https://sootlasten.github.io/2017/gradient-steepest-ascent/ \"Gradient Descent,\" Wikipedia (Wikimedia Foundation, June 28, 2022), https://en.wikipedia.org/wiki/Gradient_descent. \u21a9 \\(\\epsilon\\) is often denoted \\(h\\) in the limit definition of derivatives. \u21a9 Proof That the Gradient Points in the Direction of Steepest Ascent : Sten Sootla's Blog, Sten Sootla, March 15, 2017. \u21a9 Proof That the Gradient Points in the Direction of Steepest Ascent : Sten Sootla's Blog, Sten Sootla, March 15, 2017. \u21a9 Proof That the Gradient Points in the Direction of Steepest Ascent : Sten Sootla's Blog, Sten Sootla, March 15, 2017. \u21a9 Why in a directional derivative it has to be a unit vector \u21a9 why normalize and the definition of directional derivative \u21a9 What is the difference between the gradient and the directional derivative? \u21a9 Proof the magnitude of the gradient vector is exactly the rate of change in that direction : Sten Sootla's Blog, Sten Sootla, March 15, 2017. \u21a9","title":"Gradient Descent"},{"location":"reighns_ml_journey/mathematics/gradient_descent/#gradient-descent","text":"In mathematics, gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent. 1 This blog answers two questions: How does the gradient descent algorithm work? Why does the gradient points in the direction of the steepest ascent? In many articles and courses, gradient descent is often used to find the minimum of a function, by way of the following procedure: \\({\\color{red} \\textbf{To rewrite this pseudocode}}\\) 1. Start at the initial point. 2. Take a step in the opposite direction of the gradient. 3. Repeat steps 2 and 3 until the function is no longer decreasing. 4. The point where the function is no longer decreasing is the minimum. Our second question is equivalent to answering the point 2, on why do we take a step in the opposite direction of the gradient.","title":"Gradient Descent"},{"location":"reighns_ml_journey/mathematics/gradient_descent/#the-intuition","text":"Quote wikipedia's example.","title":"The Intuition"},{"location":"reighns_ml_journey/mathematics/gradient_descent/#the-idea-of-neighbourhood","text":"Let us start with an one-dimensional example to illustrate the idea of neighbourhood. Define \\(f: \\R \\to \\R\\) to be \\(f(x) = x^2\\) , then the gradient of \\(f\\) at a point \\(x = x_0\\) is \\(\\frac {\\partial f(x)} {\\partial x} \\vert x_0 = 2x_0\\) . A wrong interpretation is to treat the understanding of gradient as if it is a linear function. Let us fix a point \\(x = 2\\) , its output \\(f(x) = 4\\) and the gradient at that point is \\(\\frac {\\partial f(x)} {\\partial x} \\vert_{x=2} = 4\\) . It is wrong to say that for every \\(1\\) unit increase of \\(x\\) , \\(f(x)\\) will increase by \\(4\\) , where \\(4\\) is the gradient at that point. One can indeed verify that if \\(x\\) is increased by \\(1\\) unit from \\(x=2\\) to \\(x = 3\\) , then \\(f(x) = 3^2 = 9\\) , where \\(f(x)\\) is increased by \\(5\\) units, and not by \\(4\\) . Unlike the case of a linear function, the gradient of \\(f\\) at a point \\(x = x_0\\) is not fixed, but depends on the value of \\(x_0\\) . Consequently, the meaning of the gradient in such a function is only well defined in a small \\(\\epsilon\\) -neighbourhood 2 around \\(x = 2\\) . Within this small neighbourhood, we can \"loosely\" visualize the portion of the function to be a \"linear function\" with a slope of \\(2\\) , as illustrated in the following figure. The enclosed green box is the neighborhood of \\(x = 2\\) , where if we zoom in, the portion of the function inside looks like a linear function with a slope of \\(2\\) . Neighbourhood around x = 2. Indeed, if we set \\(\\epsilon = 0.001\\) , then if \\(x = 2\\) , we have \\(f(x) = 4\\) ; moving \\(x\\) by \\(\\epsilon\\) from \\(x = 2\\) to \\(x = 2.001\\) yields us \\(f(x) \\approxeq 4.004\\) . We now see that \\(x\\) increasing by \\(0.001\\) unit indeed yields us an increase of \\(4.004 - 4 = 0.004\\) , a factor of \\(4\\) increase to the output \\(f(x)\\) .","title":"The idea of neighbourhood"},{"location":"reighns_ml_journey/mathematics/gradient_descent/#gradient-vector","text":"Definition: Gradient Vector Let \\(f: \\R^n \\to \\R\\) be a function that maps \\(\\x\\) to \\(f(\\x)\\) : \\[ \\begin{align*} f \\colon \\R^n &\\longrightarrow \\R \\\\ \\x &\\longmapsto f(\\x) \\\\ \\end{align*} \\] where \\(\\x = [x_1, x_2, \\ldots, x_n]^\\top\\) is a vector of \\(n\\) variables. Then the gradient of \\(f\\) is the vector of first-order partial derivatives of \\(f\\) with respect to each of the \\(n\\) variables. \\[ \\begin{equation} \\nabla f(\\x) = \\bigg[\\frac{\\partial f(\\x)}{\\partial x_1}, \\frac{\\partial f(\\x)}{\\partial x_2}, \\ldots, \\frac{\\partial f(\\x)}{\\partial x_n} \\bigg]^\\top \\label{eq:grad_vec} \\end{equation} \\] We can also replace the notation \\(\\frac{\\partial f(\\x)}{\\partial x_i}\\) in equation \\(\\eqref{eq:grad_vec}\\) with \\(f_{x_i}\\) .","title":"Gradient Vector"},{"location":"reighns_ml_journey/mathematics/gradient_descent/#directional-derivatives","text":"Definition: Directional Derivative Let \\(f: \\R^n \\to \\R\\) be a function that maps \\(\\x\\) to \\(f(\\x)\\) : \\[ \\begin{align*} f \\colon \\R^n &\\longrightarrow \\R \\\\ \\x &\\longmapsto f(\\x) \\\\ \\end{align*} \\] where \\(\\x = [x_1, x_2, \\ldots, x_n]^\\top\\) is a vector of \\(n\\) variables. Then the directional derivative of \\(f\\) at a point \\(\\x\\) along a direction vector \\[ \\v = [v_1, v_2, \\ldots, v_n]^\\top \\] is the function \\(D_{\\v}(f)\\) defined by the limit: \\[ \\begin{equation} D_{\\v}(f) = \\lim_{h \\to 0} \\frac{f(\\x + h\\v) - f(\\x)}{h} \\label{eq:directional_derivative_def} \\end{equation} \\] To avoid notation confusion and also understand the definition better, we use a simple example in 2-dimensional to illustrate the definition of the directional derivative. Example: Directional Derivative Let \\(f: \\R^2 \\to \\R\\) be defined as \\[ f(\\x) = f(x_1, x_2) = x_1^2 + x_2^2 \\] where \\(\\x\\) is a vector of scalar values \\(x_1\\) and \\(x_2\\) , both corresponds to the x- and y-coordinates of a point in the plane respectively. Following closely the definition, we need to define a direction vector \\(\\v\\) . Since the definition did not say what \\(\\v\\) was, we can define \\(\\v\\) to be the unit vector in the south-east direction. \\[ \\v = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} \\] We also note that we want to compute the directional derivative of \\(f\\) at a point \\((x_1, x_2)\\) , where we arbitrarily choose \\((x_1, x_2) = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\) . Then, we can define the directional derivative of \\(f\\) at the point \\(\\x = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\) along \\(\\v = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}\\) as: \\[ \\begin{equation*} \\begin{split} D_{\\v}(f(1, 1)) &= \\lim_{h \\to 0} \\frac{f(\\x + h\\v) - f(\\x)}{h} \\\\ &= \\lim_{h \\to 0} \\frac{f(x_1 + hv_1, x_2 + hv_2) - f(x_1, x_2)}{h} \\\\ &= \\lim_{h \\to 0} \\frac{f(1 + h, 1 - h) - f(1, 1)}{h} \\end{split} \\end{equation*} \\] which evaluates to how much \\(f\\) changes when it moves a small unit distance \\(h\\) from \\(\\x\\) to \\(\\x + h\\) along the direction \\(\\v\\) .","title":"Directional Derivatives"},{"location":"reighns_ml_journey/mathematics/gradient_descent/#intuition-of-directional-derivative","text":"This section builds up to an important derivation of the idea of the directional derivative. Warning In this section, we should constantly recall the idea of a neighbourhood whenever we talk about per unit change, we should visualize that this unit is very small. Let us restrict our focus to 2-variable mutlivariate function \\(f(x, y)\\) , bearing in mind that it can be scaled up to \\(n\\) variables. The components of \\(\\nabla f\\) are the partial derivatives of \\(f\\) with respect to \\(x\\) and \\(y\\) . More concretely, given the partial derivative \\[ \\begin{equation} \\frac{\\partial f(x, y)}{\\partial x} \\label{eq:partial_x} \\end{equation} \\] equation \\(\\eqref{eq:partial_x}\\) answers the question: how much does the value of \\(f\\) change when we hold \\(y\\) constant and nudge \\(x\\) by a small amount in the \\(x\\) direction (i.e. in the direction pointed to by the vector \\(\\begin{bmatrix} 1 & 0 \\end{bmatrix}^\\top\\) )? 3 In a similar vein, given the partial derivative \\[ \\begin{equation} \\frac{\\partial f(x, y)}{\\partial y} \\label{eq:partial_y} \\end{equation} \\] equation \\(\\eqref{eq:partial_y}\\) answers the question: how much does the value of \\(f\\) change when we hold \\(x\\) constant and nudge \\(y\\) by a small amount in the \\(y\\) direction (i.e. in the direction pointed to by the vector \\(\\begin{bmatrix} 0 & 1 \\end{bmatrix}^\\top\\) )? 4 Finally, it is often useful to note that \\(x\\) and \\(y\\) can move in tandem (i.e. we do not hold any of them constant), how do we then calculate how much \\(f\\) changes when we nudge both \\(x\\) and \\(y\\) by a small amount. Note that moving \\(x\\) and \\(y\\) both by \\(a\\) and \\(b\\) respectively is synonymous with moving the point \\((x, y)\\) by the vector \\(\\begin{bmatrix} a & b \\end{bmatrix}^\\top\\) . With vector in the playing field, we now attach the notion of a \"direction\". We can use equation \\(\\eqref{eq:directional_derivative_def}\\) to compute how much \\(f\\) changes when we nudge the points \\(x\\) and \\(y\\) by a small amount in the \\(x\\) and \\(y\\) directions respectively. However, the calculation is cumbersome if we use the definition of the directional derivative. We will now use an example to derive an alternate formula by relating directional derivative to their partial derivatives composition. Example If we want to move \\(x\\) and \\(y\\) by \\(1\\) and \\(-1\\) respectively, then it simply means that \\(x\\) is moved 1 unit along the \\(x\\) axis and \\(y\\) is moved -1 unit along the \\(y\\) axis. In vector terms, this means we moved \\((x, y)\\) in the direction \\(\\begin{bmatrix} 1 & -1 \\end{bmatrix}^\\top\\) . More generically, let \\(x\\) and \\(y\\) move \\(a\\) and \\(b\\) units respectively, then we moved \\((x, y)\\) in the direction \\(\\begin{bmatrix} a & b \\end{bmatrix}^\\top\\) . It turns out that the amount that \\(f\\) changes when we move in the \\(\\v = \\begin{bmatrix} a & b \\end{bmatrix}^\\top\\) direction is exactly how much \\(f\\) changes when we move \\(a\\) units along the \\(x\\) axis and \\(b\\) units along the \\(y\\) axis 5 . Recall that we know how much \\(f\\) changes when we move \\(x\\) by 1 unit: The partial derivative of \\(f\\) with respect to \\(x\\) : \\(\\frac{\\partial f(x, y)}{\\partial x}\\) Recall that we know how much \\(f\\) changes when we move \\(y\\) by 1 unit: The partial derivative of \\(f\\) with respect to \\(y\\) : \\(\\frac{\\partial f(x, y)}{\\partial y}\\) It follows that if we move \\(x\\) by \\(a\\) units, then \\(f\\) changes by \\(a \\cdot \\frac{\\partial f(x, y)}{\\partial x}\\) and if we move \\(y\\) by \\(b\\) units, then \\(f\\) changes by \\(b \\cdot \\frac{\\partial f(x, y)}{\\partial y}\\) Therefore, the amount that \\(f\\) changes when we move \\(x\\) by \\(a\\) units and \\(y\\) by \\(b\\) units is \\(a \\cdot \\frac{\\partial f(x, y)}{\\partial x} + b \\cdot \\frac{\\partial f(x, y)}{\\partial y}\\) One might notice that for multivariate \\(f:\\R^n \\to \\R\\) , the derivative \\(D_{\\v}(f)\\) at the point \\(x \\in \\R^n\\) is defined to be a linear map \\(T: \\R^n \\to \\R\\) . Therefore, the linearity rule applies. If the above is still not obvious, then we can approach it geometrically. Recall that we are mapping from \\(\\R^2\\) to \\(\\R\\) , the below diagram illustrates the mapping. Geometric Intuition.","title":"Intuition of Directional Derivative"},{"location":"reighns_ml_journey/mathematics/gradient_descent/#theorem-the-direction-derivative","text":"The intuition developed in the previous section allows us to derive a new formula to calculate the directional derivative of \\(f\\) at a point \\(\\x\\) when moved in the direction of \\(\\v\\) . Although the example used is in 2-dimensions, we can generalize to \\(n\\) variables and we state it formally. Theorem: Directional Derivative Let \\(f: \\R^n \\to \\R\\) be a function \\(f(\\x)\\) where \\(\\x = [x_1, x_2, \\ldots, x_n]^\\top\\) is a vector of \\(n\\) variables. If \\(f\\) is differentiable at \\(\\x\\) , then the directional derivative \\(D_{\\v}(f)\\) at \\(\\x\\) is defined as follows: \\[ \\begin{equation} D_{\\v}(f(\\x)) = \\nabla f(\\x) \\cdot \\v \\label{eq:directional_derivative_theorem} \\end{equation} \\] In most textbooks, we will normalize the direction vector \\(\\v\\) to the standard unit vector \\(\\u\\) . However, the usage of unit vector simplifies the derivation and other applications 6 7 , it is not an universal rule. Important It is extremely important to remember that the gradient vector of \\(f\\) at \\(\\x\\) is already defined as \\(\\nabla f(\\x)\\) , to be the vector of partial derivatives of \\(f\\) at \\(\\x\\) . This has two consequences: Given the gradient vector of \\(f\\) at \\(\\x\\) and any direction \\(\\v\\) , we can recover the directional derivative \\(D_{\\v}(f)\\) at \\(\\x\\) by simply multiplying it by \\(\\v\\) . Given the gradient vector of \\(f\\) at \\(\\x\\) and a scalar value directional derivative \\(D_{\\v}(f)\\) , we can recover the direction \\(\\v\\) by division. One variant of the proof: Info The","title":"Theorem (The Direction Derivative)"},{"location":"reighns_ml_journey/mathematics/gradient_descent/#difference-between-gradient-and-directional-derivative8","text":"When I was learning multivariate calculus, I have had my fair share of trouble with the difference between the gradient and the directional derivative. It is easy to confuse the two terms. Let us go back to the definitions: The gradient of a mutlivariate function \\(f\\) at a point \\(\\x\\) is the vector of partial derivatives of \\(f\\) at \\(\\x\\) , as defined in equation \\(\\eqref{eq:grad_vec}\\) . \\[ \\nabla f(\\x) = \\bigg[\\frac{\\partial f(\\x)}{\\partial x_1}, \\frac{\\partial f(\\x)}{\\partial x_2}, \\ldots, \\frac{\\partial f(\\x)}{\\partial x_n} \\bigg]^\\top \\] The directional derivative of a mutlivariate function \\(f\\) at a point \\(\\x\\) is the scalar value of the partial derivative of \\(f\\) at \\(\\x\\) in the direction of \\(\\v\\) , as defined in equation \\(\\eqref{eq:directional_derivative_def}\\) and \\(\\eqref{eq:directional_derivative_theorem}\\) . There are infinite directional derivatives around a point \\(\\x\\) since there are infinitely many directions \\(\\v\\) . However, there is only one gradient vector around a point \\(\\x\\) and this is defined to be the vector that is the steepest ascent, which we will prove in the next section. Consider the following example: We have a point \\((x, y)\\) in \\(f\\) , where \\(f\\) is a function of two variables. Since this function can be graphed in 3-dimensions, we can visualize that there are infinite number of directions around the point \\((x, y)\\) . We can categorize the directions around the point as vectors \\(\\v\\) . For simplicity, we restrict \\(\\v\\) to be unit vectors. Recall the definition of the directional derivative of \\(f\\) at a point \\(\\x\\) to be a scalar-valued function \\(D_{\\v}(f)\\) parametrized by the direction vector \\(\\v\\) . We also note that \\(D_{\\v}(f)\\) is the instantaneous rate of change of \\(f\\) when we move in the direction \\(\\v\\) . There exists infinite number of such directional derivatives of \\(f\\) at a point \\(\\x\\) since there are infinite number of directions \\(\\v\\) . This can be seen by the orange arrows. However, there exists an unique direction \\(\\v\\) which gives rise to the fastest instantaneous rate of change of \\(f\\) when moved in that direction. This unique direction points in the same direction as the gradient vector \\(\\v\\) . Infinite directions around a point in cross-sectional plane of 3d-figure.","title":"Difference between Gradient and Directional Derivative8"},{"location":"reighns_ml_journey/mathematics/gradient_descent/#gradient-points-to-the-direction-of-steepest-ascent","text":"We finally have the necessary definitions and theorems to prove the following statement: The direction of steepest ascent of a function \\(f: \\R^n \\to \\R\\) is given by the gradient vector of \\(f\\) at a point \\(\\x = \\begin{bmatrix} x_1 & x_2 & \\ldots & x_n \\end{bmatrix}^\\top\\) . In other words, \\(f\\) increases the fastest when we move in the direction of the gradient vector . Before we prove this, it is best for us to rephrase the question to: Given a function \\(f\\) and a point \\(\\x\\) , which direction vector (unit vector) \\(\\v\\) gives the fastest rate of change of \\(f\\) when moved in that direction? This can be then be found easily by following the theorem/definition in the section on the alternative definition of the directional derivative . Info The logic is that the directional derivative of \\(f\\) at \\(\\x\\) is the rate of change , then it suffices to find the direction vector \\(\\v\\) that gives the fastest rate of change . The definition \\(\\eqref{eq:directional_derivative_theorem}\\) states that \\(D_{\\v}(f(\\x)) = \\nabla f(\\x) \\cdot \\v\\) . We then seek to solve the optimization problem: \\[ \\begin{align} \\v_{\\max} &= \\underset{\\v, \\lVert \\v \\rVert = 1}{\\operatorname{argmax}}D_{\\v}(f(\\x)) \\label{eq:steepest_ascent_1} \\\\ &= \\underset{\\v, \\lVert \\v \\rVert = 1}{\\operatorname{argmax}}\\nabla f(\\x) \\cdot \\v \\label{eq:steepest_ascent_2} \\\\ &= \\underset{\\v, \\lVert \\v \\rVert = 1}{\\operatorname{argmax}} \\lVert \\nabla f(\\x) \\rVert \\cdot \\lVert \\v \\rVert \\cos(\\theta) \\label{eq:steepest_ascent_3} \\\\ \\end{align} \\] where we want to find the unique \\(\\v_{\\max}\\) such that \\(D_{\\v}(f(\\x))\\) is the maximum . In equation \\(\\eqref{eq:steepest_ascent_3}\\) , we invoked the geometric definition of the dot product to represent the dot product as the cosine of the angle between the two vectors . Since we are optimizing over \\(\\v\\) and the length of \\(\\v\\) is 1, we can simplify the expression to: \\[ \\begin{align} \\v_{\\max} &= \\underset{\\v, \\lVert \\v \\rVert = 1}{\\operatorname{argmax}} \\lVert \\nabla f(\\x) \\rVert \\cdot \\lVert \\v \\rVert \\cos(\\theta) \\\\ &= \\underset{\\v}{\\operatorname{argmax}} \\lVert \\nabla f(\\x) \\rVert \\cos(\\theta) \\label{eq:steepest_ascent_4} \\\\ &= \\underset{\\v}{\\operatorname{argmax}} \\cos(\\theta) \\label{eq:steepest_ascent_5} \\\\ \\end{align} \\] where In equation \\(\\eqref{eq:steepest_ascent_4}\\) , \\(\\lVert \\v \\rVert\\) was dropped since it is 1; In equation \\(\\eqref{eq:steepest_ascent_5}\\) , \\(\\lVert \\nabla f(\\x) \\rVert\\) was dropped since it is not a function of \\(\\v\\) and hence it is irrelevant. \\(\\theta\\) , however, being the angle between \\(\\v\\) and \\(\\nabla f(\\x)\\) , is dependent on \\(\\v\\) . Therefore, \\(\\cos(\\theta)\\) is maximal when \\(\\cos(\\theta) = 1 \\implies \\theta = 0\\) . Consequently, \\(\\theta = 0\\) implies \\(\\nabla f(\\x)\\) and \\(\\v\\) are parallel. Note At this point, we have answered the question posed: Given a function \\(f\\) and a point \\(\\x\\) , which direction vector (unit vector) \\(\\v\\) gives the fastest rate of change of \\(f\\) when moved in that direction? It turns out this direction/unit vector we are finding is the gradient vector \\(\\nabla f(\\x)\\) itself, but reduced to its unit vector since we proved that \\(\\v \\parallel \\nabla f(\\x)\\) . As a result, we can then say that \\(f\\) increases the fastest when we move in the direction of the gradient vector \\(\\nabla f(\\x)\\) . It is worth noting that the rate of change of \\(f\\) at a point \\(\\x\\) in the direction of the gradient vector \\(\\nabla f(\\x)\\) is given by the magnitude of the gradient vector itself. 9 Success We finally convinced ourselves that subtracting the gradient vector indeed (local) minimizes the objective/loss function provided it's differentiable.","title":"Gradient Points to the Direction of Steepest Ascent"},{"location":"reighns_ml_journey/mathematics/gradient_descent/#references","text":"Bibliography. https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/the-gradient https://sootlasten.github.io/2017/gradient-steepest-ascent/ \"Gradient Descent,\" Wikipedia (Wikimedia Foundation, June 28, 2022), https://en.wikipedia.org/wiki/Gradient_descent. \u21a9 \\(\\epsilon\\) is often denoted \\(h\\) in the limit definition of derivatives. \u21a9 Proof That the Gradient Points in the Direction of Steepest Ascent : Sten Sootla's Blog, Sten Sootla, March 15, 2017. \u21a9 Proof That the Gradient Points in the Direction of Steepest Ascent : Sten Sootla's Blog, Sten Sootla, March 15, 2017. \u21a9 Proof That the Gradient Points in the Direction of Steepest Ascent : Sten Sootla's Blog, Sten Sootla, March 15, 2017. \u21a9 Why in a directional derivative it has to be a unit vector \u21a9 why normalize and the definition of directional derivative \u21a9 What is the difference between the gradient and the directional derivative? \u21a9 Proof the magnitude of the gradient vector is exactly the rate of change in that direction : Sten Sootla's Blog, Sten Sootla, March 15, 2017. \u21a9","title":"References"},{"location":"reighns_ml_journey/mathematics/linear_algebra/Linear%20Equations%20%28MacroAnalyst%29/","text":"! pip install vtk == 9.0.1 ipympl mayavi Requirement already satisfied: vtk==9.0.1 in /usr/local/lib/python3.7/dist-packages (9.0.1) Requirement already satisfied: ipympl in /usr/local/lib/python3.7/dist-packages (0.8.5) Requirement already satisfied: mayavi in /usr/local/lib/python3.7/dist-packages (4.7.4) Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.7/dist-packages (from ipympl) (5.1.1) Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from ipympl) (0.2.0) Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ipympl) (1.19.5) Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from ipympl) (7.1.2) Requirement already satisfied: ipywidgets<8,>=7.6.0 in /usr/local/lib/python3.7/dist-packages (from ipympl) (7.6.5) Requirement already satisfied: matplotlib<4,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipympl) (3.2.2) Requirement already satisfied: ipython<8 in /usr/local/lib/python3.7/dist-packages (from ipympl) (5.5.0) Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython<8->ipympl) (57.4.0) Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython<8->ipympl) (1.0.18) Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython<8->ipympl) (4.4.2) Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython<8->ipympl) (0.8.1) Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython<8->ipympl) (0.7.5) Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython<8->ipympl) (4.8.0) Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython<8->ipympl) (2.6.1) Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7.6.0->ipympl) (1.0.2) Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7.6.0->ipympl) (5.1.3) Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7.6.0->ipympl) (3.5.2) Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7.6.0->ipympl) (4.10.1) Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.6.0->ipympl) (5.3.5) Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.6.0->ipympl) (5.1.1) Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.0.0->ipympl) (0.11.0) Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.0.0->ipympl) (1.3.2) Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.0.0->ipympl) (2.8.2) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.0.0->ipympl) (3.0.6) Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipympl) (4.3.3) Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipympl) (4.9.1) Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipympl) (21.4.0) Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipympl) (4.10.0) Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipympl) (5.4.0) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipympl) (3.10.0.2) Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipympl) (0.18.0) Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipympl) (3.7.0) Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython<8->ipympl) (1.15.0) Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython<8->ipympl) (0.2.5) Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (5.3.1) Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (2.11.3) Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (5.6.1) Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.12.1) Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (1.8.0) Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7.6.0->ipympl) (22.3.0) Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.7.0) Requirement already satisfied: apptools in /usr/local/lib/python3.7/dist-packages (from mayavi) (5.1.0) Requirement already satisfied: envisage in /usr/local/lib/python3.7/dist-packages (from mayavi) (6.0.1) Requirement already satisfied: pyface>=6.1.1 in /usr/local/lib/python3.7/dist-packages (from mayavi) (7.3.0) Requirement already satisfied: traits>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from mayavi) (6.3.2) Requirement already satisfied: traitsui>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from mayavi) (7.2.1) Requirement already satisfied: configobj in /usr/local/lib/python3.7/dist-packages (from apptools->mayavi) (5.0.6) Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (2.0.1) Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (1.5.0) Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.5.0) Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.8.4) Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (4.1.0) Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.7.1) Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.3) Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (21.3) Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.5.1) ! apt - get install vtk6 ! apt - get install libvtk6 - dev python - vtk6 Reading package lists... Done Building dependency tree Reading state information... Done vtk6 is already the newest version (6.3.0+dfsg1-11build1). 0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded. Reading package lists... Done Building dependency tree Reading state information... Done libvtk6-dev is already the newest version (6.3.0+dfsg1-11build1). python-vtk6 is already the newest version (6.3.0+dfsg1-11build1). 0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded. ! pip install mayavi Requirement already satisfied: mayavi in /usr/local/lib/python3.7/dist-packages (4.7.4) Requirement already satisfied: apptools in /usr/local/lib/python3.7/dist-packages (from mayavi) (5.1.0) Requirement already satisfied: envisage in /usr/local/lib/python3.7/dist-packages (from mayavi) (6.0.1) Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mayavi) (1.19.5) Requirement already satisfied: pyface>=6.1.1 in /usr/local/lib/python3.7/dist-packages (from mayavi) (7.3.0) Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from mayavi) (2.6.1) Requirement already satisfied: traits>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from mayavi) (6.3.2) Requirement already satisfied: traitsui>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from mayavi) (7.2.1) Requirement already satisfied: vtk in /usr/local/lib/python3.7/dist-packages (from mayavi) (9.0.1) Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from pyface>=6.1.1->mayavi) (4.10.0) Requirement already satisfied: importlib-resources>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from pyface>=6.1.1->mayavi) (5.4.0) Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.1.0->pyface>=6.1.1->mayavi) (3.7.0) Requirement already satisfied: configobj in /usr/local/lib/python3.7/dist-packages (from apptools->mayavi) (5.0.6) Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from configobj->apptools->mayavi) (1.15.0) Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from envisage->mayavi) (57.4.0) Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->pyface>=6.1.1->mayavi) (3.10.0.2) % matplotlib widget from mayavi import mlab /usr/local/lib/python3.7/dist-packages/traits/etsconfig/etsconfig.py:412: UserWarning: Environment variable \"HOME\" not set, setting home directory to /tmp % (environment_variable, parent_directory) ******************************************************************************** WARNING: Imported VTK version (9.0) does not match the one used to build the TVTK classes (9.1). This may cause problems. Please rebuild TVTK. ******************************************************************************** import matplotlib.pyplot as plt import numpy as np from mpl_toolkits.mplot3d import Axes3D import scipy as sp import scipy.linalg import sympy as sy sy . init_printing () np . set_printoptions ( precision = 3 ) np . set_printoptions ( suppress = True ) mlab . init_notebook ( backend = 'x3d' ) Notebook initialized with x3d backend. We start from plotting basics in Python environment, in the meanwhile refresh the system of linear equations. Visualisation of A System of Two Linear Equations Consider a linear system of two equations: \\begin{align} x+y&=6\\ x-y&=-4 \\end{align} Easy to solve: \\((x, y)^T = (1, 5)^T\\) . Let's plot the linear system. x = np . linspace ( - 5 , 5 , 100 ) y1 = - x + 6 y2 = x + 4 fig , ax = plt . subplots ( figsize = ( 12 , 7 )) ax . scatter ( 1 , 5 , s = 200 , zorder = 5 , color = \"r\" , alpha = 0.8 ) ax . plot ( x , y1 , lw = 3 , label = \"$x+y=6$\" ) ax . plot ( x , y2 , lw = 3 , label = \"$x-y=-4$\" ) ax . plot ([ 1 , 1 ], [ 0 , 5 ], ls = \"--\" , color = \"b\" , alpha = 0.5 ) ax . plot ([ - 5 , 1 ], [ 5 , 5 ], ls = \"--\" , color = \"b\" , alpha = 0.5 ) ax . set_xlim ([ - 5 , 5 ]) ax . set_ylim ([ 0 , 12 ]) ax . legend () s = \"$(1,5)$\" ax . text ( 1 , 5.5 , s , fontsize = 20 ) ax . set_title ( \"Solution of $x+y=6$, $x-y=-4$\" , size = 22 ) ax . grid () Figure from google.colab import output output . enable_custom_widget_manager () How to Draw a Plane Before drawing a plane, let's refresh the logic of Matplotlib 3D plotting. This should be familiar to you if you are a MATLAB user. First, create meshgrids. x , y = [ - 1 , 0 , 1 ], [ - 1 , 0 , 1 ] X , Y = np . meshgrid ( x , y ) Mathematically, meshgrids are the coordinates of Cartesian product . To illustrate, we can plot all the coordinates of these meshgrids. So the x, y = [-1, 0, 1], [-1, 0, 1] translates to \\(9\\) coordinates since it represent Cartesian Product . More concretely, np.meshgrid(x, y) will have 9 coordinates (-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 0), (0, 1), (1, -1), (1, 0), (1, 1) . fig , ax = plt . subplots ( figsize = ( 12 , 7 )) ax . scatter ( X , Y , s = 200 , color = 'red' ) ax . axis ([ - 2 , 3.01 , - 2.01 , 2 ]) ax . spines [ 'left' ] . set_position ( 'zero' ) # alternative position is 'center' ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'bottom' ] . set_position ( 'zero' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . grid () plt . show () Figure Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Try a more complicated meshgrid. x , y = np . arange ( - 3 , 4 , 1 ), np . arange ( - 3 , 4 , 1 ) X , Y = np . meshgrid ( x , y ) fig , ax = plt . subplots ( figsize = ( 12 , 12 )) ax . scatter ( X , Y , s = 200 , color = 'red' , zorder = 3 ) ax . axis ([ - 5 , 5 , - 5 , 5 ]) ax . spines [ 'left' ] . set_position ( 'zero' ) # alternative position is 'center' ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'bottom' ] . set_position ( 'zero' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . grid () Figure Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Now consider the function \\(z = f(x, y)\\) , \\(z\\) is in the \\(3rd\\) dimension. Though Matplotlib is not meant for delicate plotting of 3D graphics, basic 3D plotting is still acceptable. For example, we define a simple plane as \\( \\(z= x + y\\) \\) Then plot \\(z\\) . Recall that we have already defined our \\(X, Y\\) plane through np.meshgrid . Thus, if a plane is defined by \\(z = x + y\\) , then the coordinates of each point on the plane is \\((x, y, z)\\) and we can use a 3d-scatter to mimic a plane. Z = X + Y fig = plt . figure ( figsize = ( 9 , 9 )) ax = fig . add_subplot ( 111 , projection = '3d' ) ax . scatter ( X , Y , Z , s = 100 , label = '$z=x+y$' ) ax . legend () plt . show () Figure Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Or we can plot it as a surface, Matplotlib will automatically interpolate values among the Cartesian coordinates such that the graph will look like a surface. fig = plt . figure ( figsize = ( 9 , 9 )) ax = fig . add_subplot ( 111 , projection = '3d' ) ax . plot_surface ( X , Y , Z , cmap = 'viridis' ) # MATLAB default color map ax . set_xlabel ( 'x-axis' ) ax . set_ylabel ( 'y-axis' ) ax . set_zlabel ( 'z-axis' ) ax . set_title ( '$z=x+y$' , size = 18 ) plt . show () Figure Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Visualisation of A System of Three Linear Equations We have reviewed on plotting planes, now we are ready to plot several planes all together. Consider this system of linear equations \\begin{align} x_1- 2x_2+x_3&=0\\ 2x_2-8x_3&=8\\ -4x_1+5x_2+9x_3&=-9 \\end{align} And solution is \\((x_1, x_2, x_3)^T = (29, 16, 3)^T\\) . Let's reproduce the system visually. x1 = np . linspace ( 25 , 35 , 20 ) x2 = np . linspace ( 10 , 20 , 20 ) X1 , X2 = np . meshgrid ( x1 , x2 ) fig = plt . figure ( figsize = ( 9 , 9 )) ax = fig . add_subplot ( 111 , projection = '3d' ) X3 = 2 * X2 - X1 ax . plot_surface ( X1 , X2 , X3 , cmap = 'viridis' , alpha = 1 ) X3 = .25 * X2 - 1 ax . plot_surface ( X1 , X2 , X3 , cmap = 'summer' , alpha = 1 ) X3 = - 5 / 9 * X2 + 4 / 9 * X1 - 1 ax . plot_surface ( X1 , X2 , X3 , cmap = 'spring' , alpha = 1 ) ax . scatter ( 29 , 16 , 3 , s = 200 , color = 'black' ) plt . show () Figure Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} We are certain there is a solution, however the graph does not show the intersection of planes. The problem originates from Matplotlib's rendering algorithm, which is not designed for drawing genuine 3D graphics. It merely projects 3D objects onto 2D dimension to imitate 3D features. Mayavi is much professional in rendering 3D graphics, we give an example here. If not installed, run conda install -c anaconda mayavi . mlab . clf () X1 , X2 = np . mgrid [ - 10 : 10 : 21 * 1 j , - 5 : 10 : 21 * 1 j ] X3 = 6 - X1 - X2 mlab . mesh ( X1 , X2 , X3 , colormap = \"spring\" ) X3 = 3 - 2 * X1 + X2 mlab . mesh ( X1 , X2 , X3 , colormap = \"winter\" ) X3 = 3 * X1 + 2 * X2 - 4 mlab . mesh ( X1 , X2 , X3 , colormap = \"summer\" ) mlab . axes () mlab . outline () mlab . points3d ( 1 , 2 , 3 , color = ( .8 , 0.2 , .2 ), ) mlab . title ( 'A System of Linear Equations' ) Visualisation of An Inconsistent System Now let's visualise the linear system that does not have a solution. \\begin{align} x+y+z&=1\\ x-y-2z&=2\\ 2x-z&=1 \\end{align} Rearrange the system to solve for \\(z\\) : \\[\\begin{align} z&=1-x-y\\\\ z&=\\frac{x}{2}-\\frac{y}{2}+1\\\\ z&=2x-1 \\end{align}\\] mlab . clf () X , Y = np . mgrid [ - 5 : 5 : 21 * 1 j , - 5 : 5 : 21 * 1 j ] Z = 1 - X - Y mlab . mesh ( X , Y , Z , colormap = \"spring\" ) Z = X / 2 - Y / 2 + 1 mlab . mesh ( X , Y , Z , colormap = \"summer\" ) Z = 2 * X - 1 mlab . mesh ( X , Y , Z , colormap = \"autumn\" ) mlab . axes () mlab . outline () mlab . title ( 'A Inconsistent System of Linear Equations' ) Visualisation of A System With Infinite Numbers of Solutions Our system of equations is given \\[\\begin{align} y-z=&4\\\\ 2x+y+2z=&4\\\\ 2x+2y+z=&8 \\end{align}\\] Rearrange to solve for \\(z\\) \\[\\begin{align} z=&y-4\\\\ z=&2-x-\\frac{y}{2}\\\\ z=&8-2x-2y \\end{align}\\] mlab . clf () X , Y = np . mgrid [ - 2 : 2 : 21 * 1 j , 2 : 6 : 21 * 1 j ] Z = Y - 4 mlab . mesh ( X , Y , Z , colormap = \"spring\" ) Z = 2 - X - Y / 2 mlab . mesh ( X , Y , Z , colormap = \"summer\" ) Z = 8 - 2 * X - 2 * Y mlab . mesh ( X , Y , Z , colormap = \"autumn\" ) mlab . axes () mlab . outline () mlab . title ( 'A System of Linear Equations With Infinite Number of Solutions' ) The solution of the system is \\((x,y,z)=(-3z/2,z+4,z)^T\\) , where \\(z\\) is a free variable . The solution is an infinite line in \\(\\mathbb{R}^3\\) , to visualise the solution requires setting a range of \\(x\\) and \\(y\\) , for instance we can set \\[\\begin{align} -2 \\leq x \\leq 2\\\\ 2 \\leq y \\leq 6 \\end{align}\\] which means \\[\\begin{align} -2\\leq -\\frac32z\\leq 2\\\\ 2\\leq z+4 \\leq 6 \\end{align}\\] We can pick one inequality to set the range of \\(z\\) , e.g. second inequality: \\(-2 \\leq z \\leq 2\\) . Then plot the planes and the solutions together. mlab . clf () X , Y = np . mgrid [ - 2 : 2 : 21 * 1 j , 2 : 6 : 21 * 1 j ] Z = Y - 4 mlab . mesh ( X , Y , Z , colormap = \"spring\" ) Z = 2 - X - Y / 2 mlab . mesh ( X , Y , Z , colormap = \"summer\" ) Z = 8 - 2 * X - 2 * Y mlab . mesh ( X , Y , Z , colormap = \"autumn\" ) ZL = np . linspace ( - 2 , 2 , 20 ) # ZL means Z for line, we have chosen the range [-2, 2] X = - 3 * ZL / 2 Y = ZL + 4 mlab . plot3d ( X , Y , ZL ) mlab . axes () mlab . outline () mlab . title ( 'A System of Linear Equations With Infinite Number of Solutions' ) Reduced Row Echelon Form For easy demonstration, we will be using SymPy frequently in lectures. SymPy is a very power symbolic computation library, we will see its basic features as the lectures move forward. We define a SymPy matrix: M = sy . Matrix ([[ 5 , 0 , 11 , 3 ], [ 7 , 23 , - 3 , 7 ], [ 12 , 11 , 3 , - 4 ]]); M Think of it as an augmented matrix which combines coefficients of linear system. With row operations, we can solve the system quickly. Let's turn it into a row reduced echelon form . M_rref = M . rref (); M_rref # .rref() is the SymPy method for row reduced echelon form Take out the first element in the big parentheses, i.e. the rref matrix. M_rref = np . array ( M_rref [ 0 ]); M_rref If you don't like fractions, convert it into float type. M_rref . astype ( float ) The last column of the rref matrix is the solution of the system. Example: rref and Visualisation Let's use .rref() method to compute a solution of a system then visualise it. Consider the system: \\[\\begin{align} 3x+6y+2z&=-13\\\\ x+2y+z&=-5\\\\ -5x-10y-2z&=19 \\end{align}\\] Extract the augmented matrix into a SymPy matrix: A = sy . Matrix ([[ 3 , 6 , 2 , - 13 ], [ 1 , 2 , 1 , - 5 ], [ - 5 , - 10 , - 2 , 19 ]]); A A_rref = A . rref (); A_rref In case you are wondering what's \\((0, 2)\\) : they are the column number of pivot columns, in the augmented matrix above the pivot columns resides on the \\(0\\) th and \\(2\\) nd column. Because it's not a rank matrix, therefore solutions is in general form \\begin{align} x + 2y & = -3\\ z &= -2\\ y &= free \\end{align} Let's pick 3 different values of \\(y\\) , for instance \\((3, 5, 7)\\) , to calculate \\(3\\) special solutions: point1 = ( - 2 * 3 - 3 , 3 , - 2 ) point2 = ( - 2 * 5 - 3 , 5 , - 2 ) point3 = ( - 2 * 7 - 3 , 7 , - 2 ) special_solution = np . array ([ point1 , point2 , point3 ]); special_solution # each row is a special solution We can visualise the general solution, and the 3 specific solutions altogether. y = np . linspace ( 2 , 8 , 20 ) # y is the free variable x = - 3 - 2 * y z = np . full (( len ( y ), ), - 2 ) # z is a constant fig = plt . figure ( figsize = ( 12 , 9 )) ax = fig . add_subplot ( 111 , projection = '3d' ) ax . plot ( x , y , z , lw = 3 , color = 'red' ) ax . scatter ( special_solution [:, 0 ], special_solution [:, 1 ], special_solution [:, 2 ], s = 200 ) ax . set_title ( 'General Solution and Special Solution of the Linear Sytem' , size = 16 ) plt . show () Example: A Symbolic Solution Consider a system where all right-hand side values are indeterminate: \\[\\begin{align} x + 2y - 3z &= a\\\\ 4x - y + 8z &= b\\\\ 2x - 6y - 4z &= c \\end{align}\\] We define \\(a, b, c\\) as SymPy objects, then extract the augmented matrix a , b , c = sy . symbols ( 'a, b, c' , real = True ) A = sy . Matrix ([[ 1 , 2 , - 3 , a ], [ 4 , - 1 , 8 , b ], [ 2 , - 6 , - 4 , c ]]); A We can immediately achieve the symbolic solution by using .rref() method. A_rref = A . rref (); A_rref Of course, we can substitute values of \\(a\\) , \\(b\\) and \\(c\\) to get a specific solution. vDict = { a : 3 , b : 6 , c : 7 } A_rref = A_rref [ 0 ] . subs ( vDict ); A_rref # define a dictionary for special values to substitute in Example: Polynomials Consider this question : How to find a cubic polynomial that passes through each of these points \\((1,3)\\) , \\((2, -2)\\) , \\((3, -5)\\) , and \\((4, 0)\\) . The form of cubic polynomial is \\begin{align} y=a_0+a_1x+a_2x^2+a_3x^3 \\end{align} We substitute all the points: \\[\\begin{align} (x,y)&=(1,3)\\qquad\\longrightarrow\\qquad \\ 2=a_0+3a_1+9a_2 +27a_3 \\\\ (x,y)&=(2,-2)\\qquad\\longrightarrow\\qquad 3=a_0+a_1+a_2+a_3\\\\ (x,y)&=(3,-5)\\qquad\\longrightarrow\\qquad 2=a_0-4a_1+16a_2-64a_3\\\\ (x,y)&=(4,0)\\qquad\\longrightarrow\\qquad -2=a_0+2a_1+4a_2+8a_3 \\end{align}\\] It turns to be a linear system, the rest should be familiar already. The augmented matrix is A = sy . Matrix ([[ 1 , 1 , 1 , 1 , 3 ], [ 1 , 2 , 4 , 8 , - 2 ], [ 1 , 3 , 9 , 27 , - 5 ], [ 1 , 4 , 16 , 64 , 0 ]]); A A_rref = A . rref (); A_rref A_rref = np . array ( A_rref [ 0 ]); A_rref The last column is the solution, i.e. the coefficients of the cubic polynomial. poly_coef = A_rref . astype ( float )[:, - 1 ]; poly_coef Cubic polynomial form is: \\begin{align} y = 4 + 3x - 5x^2 + x^3 \\end{align} Since we have the specific form of the cubic polynomial, we can plot it x = np . linspace ( - 5 , 5 , 40 ) y = poly_coef [ 0 ] + poly_coef [ 1 ] * x + poly_coef [ 2 ] * x ** 2 + poly_coef [ 3 ] * x ** 3 fig , ax = plt . subplots ( figsize = ( 8 , 8 )) ax . plot ( x , y , lw = 3 , color = 'red' ) ax . scatter ([ 1 , 2 , 3 , 4 ], [ 3 , - 2 , - 5 , 0 ], s = 100 , color = 'blue' , zorder = 3 ) ax . grid () ax . set_xlim ([ 0 , 5 ]) ax . set_ylim ([ - 10 , 10 ]) ax . text ( 1 , 3.5 , '$(1, 3)$' , fontsize = 15 ) ax . text ( 1.5 , - 2.5 , '$(2, -2)$' , fontsize = 15 ) ax . text ( 2.7 , - 4 , '$(3, -5.5)$' , fontsize = 15 ) ax . text ( 4.1 , 0 , '$(4, .5)$' , fontsize = 15 ) plt . show () Now you know the trick, try another 5 points: \\((1,2)\\) , \\((2,5)\\) , \\((3,8)\\) , \\((4,6)\\) , \\((5, 9)\\) . And polynomial form is \\begin{align} y=a_0+a_1x+a_2x^2+a_3x^3+a_4x^4 \\end{align} The augmented matrix is A = sy . Matrix ([[ 1 , 1 , 1 , 1 , 1 , 2 ], [ 1 , 2 , 4 , 8 , 16 , 5 ], [ 1 , 3 , 9 , 27 , 81 , 8 ], [ 1 , 4 , 16 , 64 , 256 , 6 ], [ 1 , 5 , 25 , 125 , 625 , 9 ]]); A A_rref = A . rref () A_rref = np . array ( A_rref [ 0 ]) coef = A_rref . astype ( float )[:, - 1 ]; coef x = np . linspace ( 0 , 6 , 100 ) y = coef [ 0 ] + coef [ 1 ] * x + coef [ 2 ] * x ** 2 + coef [ 3 ] * x ** 3 + coef [ 4 ] * x ** 4 fig , ax = plt . subplots ( figsize = ( 8 , 8 )) ax . plot ( x , y , lw = 3 ) ax . scatter ([ 1 , 2 , 3 , 4 , 5 ], [ 2 , 5 , 8 , 6 , 9 ], s = 100 , color = 'red' , zorder = 3 ) ax . grid () Solving The System of Linear Equations By NumPy Set up the system \\(A x = b\\) , generate a random \\(A\\) and \\(b\\) A = np . round ( 10 * np . random . rand ( 5 , 5 )) b = np . round ( 10 * np . random . rand ( 5 ,)) x = np . linalg . solve ( A , b ); x Let's verify if $ Ax = b$ A @x - b They are technically zeros, due to some round-off errors omitted, that's why there is \\(-\\) in front \\(0\\) .","title":"Linear Equations (MacroAnalyst)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/Linear%20Equations%20%28MacroAnalyst%29/#visualisation-of-a-system-of-two-linear-equations","text":"Consider a linear system of two equations: \\begin{align} x+y&=6\\ x-y&=-4 \\end{align} Easy to solve: \\((x, y)^T = (1, 5)^T\\) . Let's plot the linear system. x = np . linspace ( - 5 , 5 , 100 ) y1 = - x + 6 y2 = x + 4 fig , ax = plt . subplots ( figsize = ( 12 , 7 )) ax . scatter ( 1 , 5 , s = 200 , zorder = 5 , color = \"r\" , alpha = 0.8 ) ax . plot ( x , y1 , lw = 3 , label = \"$x+y=6$\" ) ax . plot ( x , y2 , lw = 3 , label = \"$x-y=-4$\" ) ax . plot ([ 1 , 1 ], [ 0 , 5 ], ls = \"--\" , color = \"b\" , alpha = 0.5 ) ax . plot ([ - 5 , 1 ], [ 5 , 5 ], ls = \"--\" , color = \"b\" , alpha = 0.5 ) ax . set_xlim ([ - 5 , 5 ]) ax . set_ylim ([ 0 , 12 ]) ax . legend () s = \"$(1,5)$\" ax . text ( 1 , 5.5 , s , fontsize = 20 ) ax . set_title ( \"Solution of $x+y=6$, $x-y=-4$\" , size = 22 ) ax . grid () Figure from google.colab import output output . enable_custom_widget_manager ()","title":" Visualisation of A System of Two Linear Equations "},{"location":"reighns_ml_journey/mathematics/linear_algebra/Linear%20Equations%20%28MacroAnalyst%29/#how-to-draw-a-plane","text":"Before drawing a plane, let's refresh the logic of Matplotlib 3D plotting. This should be familiar to you if you are a MATLAB user. First, create meshgrids. x , y = [ - 1 , 0 , 1 ], [ - 1 , 0 , 1 ] X , Y = np . meshgrid ( x , y ) Mathematically, meshgrids are the coordinates of Cartesian product . To illustrate, we can plot all the coordinates of these meshgrids. So the x, y = [-1, 0, 1], [-1, 0, 1] translates to \\(9\\) coordinates since it represent Cartesian Product . More concretely, np.meshgrid(x, y) will have 9 coordinates (-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 0), (0, 1), (1, -1), (1, 0), (1, 1) . fig , ax = plt . subplots ( figsize = ( 12 , 7 )) ax . scatter ( X , Y , s = 200 , color = 'red' ) ax . axis ([ - 2 , 3.01 , - 2.01 , 2 ]) ax . spines [ 'left' ] . set_position ( 'zero' ) # alternative position is 'center' ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'bottom' ] . set_position ( 'zero' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . grid () plt . show () Figure Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Try a more complicated meshgrid. x , y = np . arange ( - 3 , 4 , 1 ), np . arange ( - 3 , 4 , 1 ) X , Y = np . meshgrid ( x , y ) fig , ax = plt . subplots ( figsize = ( 12 , 12 )) ax . scatter ( X , Y , s = 200 , color = 'red' , zorder = 3 ) ax . axis ([ - 5 , 5 , - 5 , 5 ]) ax . spines [ 'left' ] . set_position ( 'zero' ) # alternative position is 'center' ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'bottom' ] . set_position ( 'zero' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . grid () Figure Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Now consider the function \\(z = f(x, y)\\) , \\(z\\) is in the \\(3rd\\) dimension. Though Matplotlib is not meant for delicate plotting of 3D graphics, basic 3D plotting is still acceptable. For example, we define a simple plane as \\( \\(z= x + y\\) \\) Then plot \\(z\\) . Recall that we have already defined our \\(X, Y\\) plane through np.meshgrid . Thus, if a plane is defined by \\(z = x + y\\) , then the coordinates of each point on the plane is \\((x, y, z)\\) and we can use a 3d-scatter to mimic a plane. Z = X + Y fig = plt . figure ( figsize = ( 9 , 9 )) ax = fig . add_subplot ( 111 , projection = '3d' ) ax . scatter ( X , Y , Z , s = 100 , label = '$z=x+y$' ) ax . legend () plt . show () Figure Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Or we can plot it as a surface, Matplotlib will automatically interpolate values among the Cartesian coordinates such that the graph will look like a surface. fig = plt . figure ( figsize = ( 9 , 9 )) ax = fig . add_subplot ( 111 , projection = '3d' ) ax . plot_surface ( X , Y , Z , cmap = 'viridis' ) # MATLAB default color map ax . set_xlabel ( 'x-axis' ) ax . set_ylabel ( 'y-axis' ) ax . set_zlabel ( 'z-axis' ) ax . set_title ( '$z=x+y$' , size = 18 ) plt . show () Figure Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5}","title":" How to Draw a Plane "},{"location":"reighns_ml_journey/mathematics/linear_algebra/Linear%20Equations%20%28MacroAnalyst%29/#visualisation-of-a-system-of-three-linear-equations","text":"We have reviewed on plotting planes, now we are ready to plot several planes all together. Consider this system of linear equations \\begin{align} x_1- 2x_2+x_3&=0\\ 2x_2-8x_3&=8\\ -4x_1+5x_2+9x_3&=-9 \\end{align} And solution is \\((x_1, x_2, x_3)^T = (29, 16, 3)^T\\) . Let's reproduce the system visually. x1 = np . linspace ( 25 , 35 , 20 ) x2 = np . linspace ( 10 , 20 , 20 ) X1 , X2 = np . meshgrid ( x1 , x2 ) fig = plt . figure ( figsize = ( 9 , 9 )) ax = fig . add_subplot ( 111 , projection = '3d' ) X3 = 2 * X2 - X1 ax . plot_surface ( X1 , X2 , X3 , cmap = 'viridis' , alpha = 1 ) X3 = .25 * X2 - 1 ax . plot_surface ( X1 , X2 , X3 , cmap = 'summer' , alpha = 1 ) X3 = - 5 / 9 * X2 + 4 / 9 * X1 - 1 ax . plot_surface ( X1 , X2 , X3 , cmap = 'spring' , alpha = 1 ) ax . scatter ( 29 , 16 , 3 , s = 200 , color = 'black' ) plt . show () Figure Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} Unhandled message type set_device_pixel_ratio. {'type': 'set_device_pixel_ratio', 'device_pixel_ratio': 1.5} We are certain there is a solution, however the graph does not show the intersection of planes. The problem originates from Matplotlib's rendering algorithm, which is not designed for drawing genuine 3D graphics. It merely projects 3D objects onto 2D dimension to imitate 3D features. Mayavi is much professional in rendering 3D graphics, we give an example here. If not installed, run conda install -c anaconda mayavi . mlab . clf () X1 , X2 = np . mgrid [ - 10 : 10 : 21 * 1 j , - 5 : 10 : 21 * 1 j ] X3 = 6 - X1 - X2 mlab . mesh ( X1 , X2 , X3 , colormap = \"spring\" ) X3 = 3 - 2 * X1 + X2 mlab . mesh ( X1 , X2 , X3 , colormap = \"winter\" ) X3 = 3 * X1 + 2 * X2 - 4 mlab . mesh ( X1 , X2 , X3 , colormap = \"summer\" ) mlab . axes () mlab . outline () mlab . points3d ( 1 , 2 , 3 , color = ( .8 , 0.2 , .2 ), ) mlab . title ( 'A System of Linear Equations' )","title":" Visualisation of A System of Three Linear Equations  "},{"location":"reighns_ml_journey/mathematics/linear_algebra/Linear%20Equations%20%28MacroAnalyst%29/#visualisation-of-an-inconsistent-system","text":"Now let's visualise the linear system that does not have a solution. \\begin{align} x+y+z&=1\\ x-y-2z&=2\\ 2x-z&=1 \\end{align} Rearrange the system to solve for \\(z\\) : \\[\\begin{align} z&=1-x-y\\\\ z&=\\frac{x}{2}-\\frac{y}{2}+1\\\\ z&=2x-1 \\end{align}\\] mlab . clf () X , Y = np . mgrid [ - 5 : 5 : 21 * 1 j , - 5 : 5 : 21 * 1 j ] Z = 1 - X - Y mlab . mesh ( X , Y , Z , colormap = \"spring\" ) Z = X / 2 - Y / 2 + 1 mlab . mesh ( X , Y , Z , colormap = \"summer\" ) Z = 2 * X - 1 mlab . mesh ( X , Y , Z , colormap = \"autumn\" ) mlab . axes () mlab . outline () mlab . title ( 'A Inconsistent System of Linear Equations' )","title":" Visualisation of An Inconsistent System "},{"location":"reighns_ml_journey/mathematics/linear_algebra/Linear%20Equations%20%28MacroAnalyst%29/#visualisation-of-a-system-with-infinite-numbers-of-solutions","text":"Our system of equations is given \\[\\begin{align} y-z=&4\\\\ 2x+y+2z=&4\\\\ 2x+2y+z=&8 \\end{align}\\] Rearrange to solve for \\(z\\) \\[\\begin{align} z=&y-4\\\\ z=&2-x-\\frac{y}{2}\\\\ z=&8-2x-2y \\end{align}\\] mlab . clf () X , Y = np . mgrid [ - 2 : 2 : 21 * 1 j , 2 : 6 : 21 * 1 j ] Z = Y - 4 mlab . mesh ( X , Y , Z , colormap = \"spring\" ) Z = 2 - X - Y / 2 mlab . mesh ( X , Y , Z , colormap = \"summer\" ) Z = 8 - 2 * X - 2 * Y mlab . mesh ( X , Y , Z , colormap = \"autumn\" ) mlab . axes () mlab . outline () mlab . title ( 'A System of Linear Equations With Infinite Number of Solutions' ) The solution of the system is \\((x,y,z)=(-3z/2,z+4,z)^T\\) , where \\(z\\) is a free variable . The solution is an infinite line in \\(\\mathbb{R}^3\\) , to visualise the solution requires setting a range of \\(x\\) and \\(y\\) , for instance we can set \\[\\begin{align} -2 \\leq x \\leq 2\\\\ 2 \\leq y \\leq 6 \\end{align}\\] which means \\[\\begin{align} -2\\leq -\\frac32z\\leq 2\\\\ 2\\leq z+4 \\leq 6 \\end{align}\\] We can pick one inequality to set the range of \\(z\\) , e.g. second inequality: \\(-2 \\leq z \\leq 2\\) . Then plot the planes and the solutions together. mlab . clf () X , Y = np . mgrid [ - 2 : 2 : 21 * 1 j , 2 : 6 : 21 * 1 j ] Z = Y - 4 mlab . mesh ( X , Y , Z , colormap = \"spring\" ) Z = 2 - X - Y / 2 mlab . mesh ( X , Y , Z , colormap = \"summer\" ) Z = 8 - 2 * X - 2 * Y mlab . mesh ( X , Y , Z , colormap = \"autumn\" ) ZL = np . linspace ( - 2 , 2 , 20 ) # ZL means Z for line, we have chosen the range [-2, 2] X = - 3 * ZL / 2 Y = ZL + 4 mlab . plot3d ( X , Y , ZL ) mlab . axes () mlab . outline () mlab . title ( 'A System of Linear Equations With Infinite Number of Solutions' )","title":" Visualisation of A System With Infinite Numbers of Solutions "},{"location":"reighns_ml_journey/mathematics/linear_algebra/Linear%20Equations%20%28MacroAnalyst%29/#reduced-row-echelon-form","text":"For easy demonstration, we will be using SymPy frequently in lectures. SymPy is a very power symbolic computation library, we will see its basic features as the lectures move forward. We define a SymPy matrix: M = sy . Matrix ([[ 5 , 0 , 11 , 3 ], [ 7 , 23 , - 3 , 7 ], [ 12 , 11 , 3 , - 4 ]]); M Think of it as an augmented matrix which combines coefficients of linear system. With row operations, we can solve the system quickly. Let's turn it into a row reduced echelon form . M_rref = M . rref (); M_rref # .rref() is the SymPy method for row reduced echelon form Take out the first element in the big parentheses, i.e. the rref matrix. M_rref = np . array ( M_rref [ 0 ]); M_rref If you don't like fractions, convert it into float type. M_rref . astype ( float ) The last column of the rref matrix is the solution of the system.","title":" Reduced Row Echelon Form "},{"location":"reighns_ml_journey/mathematics/linear_algebra/Linear%20Equations%20%28MacroAnalyst%29/#example-rref-and-visualisation","text":"Let's use .rref() method to compute a solution of a system then visualise it. Consider the system: \\[\\begin{align} 3x+6y+2z&=-13\\\\ x+2y+z&=-5\\\\ -5x-10y-2z&=19 \\end{align}\\] Extract the augmented matrix into a SymPy matrix: A = sy . Matrix ([[ 3 , 6 , 2 , - 13 ], [ 1 , 2 , 1 , - 5 ], [ - 5 , - 10 , - 2 , 19 ]]); A A_rref = A . rref (); A_rref In case you are wondering what's \\((0, 2)\\) : they are the column number of pivot columns, in the augmented matrix above the pivot columns resides on the \\(0\\) th and \\(2\\) nd column. Because it's not a rank matrix, therefore solutions is in general form \\begin{align} x + 2y & = -3\\ z &= -2\\ y &= free \\end{align} Let's pick 3 different values of \\(y\\) , for instance \\((3, 5, 7)\\) , to calculate \\(3\\) special solutions: point1 = ( - 2 * 3 - 3 , 3 , - 2 ) point2 = ( - 2 * 5 - 3 , 5 , - 2 ) point3 = ( - 2 * 7 - 3 , 7 , - 2 ) special_solution = np . array ([ point1 , point2 , point3 ]); special_solution # each row is a special solution We can visualise the general solution, and the 3 specific solutions altogether. y = np . linspace ( 2 , 8 , 20 ) # y is the free variable x = - 3 - 2 * y z = np . full (( len ( y ), ), - 2 ) # z is a constant fig = plt . figure ( figsize = ( 12 , 9 )) ax = fig . add_subplot ( 111 , projection = '3d' ) ax . plot ( x , y , z , lw = 3 , color = 'red' ) ax . scatter ( special_solution [:, 0 ], special_solution [:, 1 ], special_solution [:, 2 ], s = 200 ) ax . set_title ( 'General Solution and Special Solution of the Linear Sytem' , size = 16 ) plt . show ()","title":" Example: rref and Visualisation "},{"location":"reighns_ml_journey/mathematics/linear_algebra/Linear%20Equations%20%28MacroAnalyst%29/#example-a-symbolic-solution","text":"Consider a system where all right-hand side values are indeterminate: \\[\\begin{align} x + 2y - 3z &= a\\\\ 4x - y + 8z &= b\\\\ 2x - 6y - 4z &= c \\end{align}\\] We define \\(a, b, c\\) as SymPy objects, then extract the augmented matrix a , b , c = sy . symbols ( 'a, b, c' , real = True ) A = sy . Matrix ([[ 1 , 2 , - 3 , a ], [ 4 , - 1 , 8 , b ], [ 2 , - 6 , - 4 , c ]]); A We can immediately achieve the symbolic solution by using .rref() method. A_rref = A . rref (); A_rref Of course, we can substitute values of \\(a\\) , \\(b\\) and \\(c\\) to get a specific solution. vDict = { a : 3 , b : 6 , c : 7 } A_rref = A_rref [ 0 ] . subs ( vDict ); A_rref # define a dictionary for special values to substitute in","title":" Example: A Symbolic Solution "},{"location":"reighns_ml_journey/mathematics/linear_algebra/Linear%20Equations%20%28MacroAnalyst%29/#example-polynomials","text":"Consider this question : How to find a cubic polynomial that passes through each of these points \\((1,3)\\) , \\((2, -2)\\) , \\((3, -5)\\) , and \\((4, 0)\\) . The form of cubic polynomial is \\begin{align} y=a_0+a_1x+a_2x^2+a_3x^3 \\end{align} We substitute all the points: \\[\\begin{align} (x,y)&=(1,3)\\qquad\\longrightarrow\\qquad \\ 2=a_0+3a_1+9a_2 +27a_3 \\\\ (x,y)&=(2,-2)\\qquad\\longrightarrow\\qquad 3=a_0+a_1+a_2+a_3\\\\ (x,y)&=(3,-5)\\qquad\\longrightarrow\\qquad 2=a_0-4a_1+16a_2-64a_3\\\\ (x,y)&=(4,0)\\qquad\\longrightarrow\\qquad -2=a_0+2a_1+4a_2+8a_3 \\end{align}\\] It turns to be a linear system, the rest should be familiar already. The augmented matrix is A = sy . Matrix ([[ 1 , 1 , 1 , 1 , 3 ], [ 1 , 2 , 4 , 8 , - 2 ], [ 1 , 3 , 9 , 27 , - 5 ], [ 1 , 4 , 16 , 64 , 0 ]]); A A_rref = A . rref (); A_rref A_rref = np . array ( A_rref [ 0 ]); A_rref The last column is the solution, i.e. the coefficients of the cubic polynomial. poly_coef = A_rref . astype ( float )[:, - 1 ]; poly_coef Cubic polynomial form is: \\begin{align} y = 4 + 3x - 5x^2 + x^3 \\end{align} Since we have the specific form of the cubic polynomial, we can plot it x = np . linspace ( - 5 , 5 , 40 ) y = poly_coef [ 0 ] + poly_coef [ 1 ] * x + poly_coef [ 2 ] * x ** 2 + poly_coef [ 3 ] * x ** 3 fig , ax = plt . subplots ( figsize = ( 8 , 8 )) ax . plot ( x , y , lw = 3 , color = 'red' ) ax . scatter ([ 1 , 2 , 3 , 4 ], [ 3 , - 2 , - 5 , 0 ], s = 100 , color = 'blue' , zorder = 3 ) ax . grid () ax . set_xlim ([ 0 , 5 ]) ax . set_ylim ([ - 10 , 10 ]) ax . text ( 1 , 3.5 , '$(1, 3)$' , fontsize = 15 ) ax . text ( 1.5 , - 2.5 , '$(2, -2)$' , fontsize = 15 ) ax . text ( 2.7 , - 4 , '$(3, -5.5)$' , fontsize = 15 ) ax . text ( 4.1 , 0 , '$(4, .5)$' , fontsize = 15 ) plt . show () Now you know the trick, try another 5 points: \\((1,2)\\) , \\((2,5)\\) , \\((3,8)\\) , \\((4,6)\\) , \\((5, 9)\\) . And polynomial form is \\begin{align} y=a_0+a_1x+a_2x^2+a_3x^3+a_4x^4 \\end{align} The augmented matrix is A = sy . Matrix ([[ 1 , 1 , 1 , 1 , 1 , 2 ], [ 1 , 2 , 4 , 8 , 16 , 5 ], [ 1 , 3 , 9 , 27 , 81 , 8 ], [ 1 , 4 , 16 , 64 , 256 , 6 ], [ 1 , 5 , 25 , 125 , 625 , 9 ]]); A A_rref = A . rref () A_rref = np . array ( A_rref [ 0 ]) coef = A_rref . astype ( float )[:, - 1 ]; coef x = np . linspace ( 0 , 6 , 100 ) y = coef [ 0 ] + coef [ 1 ] * x + coef [ 2 ] * x ** 2 + coef [ 3 ] * x ** 3 + coef [ 4 ] * x ** 4 fig , ax = plt . subplots ( figsize = ( 8 , 8 )) ax . plot ( x , y , lw = 3 ) ax . scatter ([ 1 , 2 , 3 , 4 , 5 ], [ 2 , 5 , 8 , 6 , 9 ], s = 100 , color = 'red' , zorder = 3 ) ax . grid ()","title":" Example: Polynomials "},{"location":"reighns_ml_journey/mathematics/linear_algebra/Linear%20Equations%20%28MacroAnalyst%29/#solving-the-system-of-linear-equations-by-numpy","text":"Set up the system \\(A x = b\\) , generate a random \\(A\\) and \\(b\\) A = np . round ( 10 * np . random . rand ( 5 , 5 )) b = np . round ( 10 * np . random . rand ( 5 ,)) x = np . linalg . solve ( A , b ); x Let's verify if $ Ax = b$ A @x - b They are technically zeros, due to some round-off errors omitted, that's why there is \\(-\\) in front \\(0\\) .","title":" Solving The System of Linear Equations By NumPy "},{"location":"reighns_ml_journey/mathematics/linear_algebra/characteristic%20polynomial/","text":"Characteristic Polynomial Definition (Characteristic Polynomial)","title":"Characteristic polynomial"},{"location":"reighns_ml_journey/mathematics/linear_algebra/characteristic%20polynomial/#characteristic-polynomial","text":"","title":"Characteristic Polynomial"},{"location":"reighns_ml_journey/mathematics/linear_algebra/characteristic%20polynomial/#definition-characteristic-polynomial","text":"","title":"Definition (Characteristic Polynomial)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_interview_questions/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\r}{\\mathbf{r}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\det}{\\textbf{det}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\U}{\\mathrm{U}} \\newcommand{\\V}{\\mathrm{V}} \\newcommand{\\W}{\\mathrm{W}} \\newcommand{\\L}{\\mathcal{L}} \\] Linear Algebra Interview Questions Given matrix \\(\\A \\in \\R^{m \\times n}\\) . For what vectors \\(\\mathbf{b} \\in \\mathbb{R}^{m}\\) does \\(\\mathbf{A}\\mathbf{x} = \\mathbf{b}\\) have a solution \\(\\mathbf{x} \\in \\mathbb{R}^{n}\\) ? We need to realize a few key points before answering the question. \\(\\A\\x = \\b\\) is equivalent to a system of equations, where there are \\(m\\) equations and \\(n\\) variables (unknowns) and we have a few cases to enumerate: All cases enumerated from the cartesian product \\(\\{\\textbf{Underdetermined, Exactly Determined, Overdetermined}\\} \\times \\{\\textbf{Consistent, Inconsistent}\\}\\) If one finds the definition in the previous point unfamiliar/vague, then please read here 1 . Since we know that right matrix-vector multiplication of \\(\\A\\) on \\(\\x\\) means: \\[ \\A\\x = x_1 \\begin{bmatrix} a_{11} \\\\ a_{21} \\\\ \\vdots \\\\ a_{m1} \\end{bmatrix} + x_2 \\begin{bmatrix} a_{12} \\\\ a_{22} \\\\ \\vdots \\\\ a_{m2} \\end{bmatrix} + \\cdots + x_n \\begin{bmatrix} a_{1n} \\\\ a_{2n} \\\\ \\vdots \\\\ a_{mn} \\end{bmatrix} \\] which is made up of linear combination of columns of \\(\\A\\) with elements of \\(\\x\\) as coefficients. Case 1: m > n We first need to realize that this is an overdetermined system because we have more equations than unknowns. Let us point back to the question, what kind of \\(\\b\\) allows us to have a solution \\(\\x\\) that solves this equation? Certainly not all kinds of \\(\\b\\) ! Why? We can illustrate with an easy example, if \\(m = 4, n = 3\\) , then \\(\\b\\) is made up of linear combination of columns of \\(\\A\\) , but we only have \\(3\\) columns, and at most we have something like \\(\\lambda_1 \\c_1 + \\lambda_2 \\c_2 + \\lambda_3 \\c_3\\) where \\(\\lambda \\in \\R, \\c_i \\in \\R^{4}\\) , \\(\\c_i\\) being the columns of \\(\\A\\) . However, we know from my previous chapter on Basis and Dimension 's Theorem (Equivalent Basis Definition) that we necessarily need \\(4\\) vectors in \\(\\R^{4}\\) to span this subspace. Consequently, \\(3\\) vectors (columns of \\(\\A\\) ) cannot possibly span the entire \\(\\R^4\\) ( column space of \\(\\A\\) here ) and hence there are vectors \\(\\b\\) that are not linear combinations of columns of \\(\\A\\) . Consistent With the above in mind, then if \\(\\b\\) is in the column space of \\(\\A\\) , then \\(\\b\\) is solvable and thus has a solution. Inconsistent If \\(\\b \\not \\in C(\\A)\\) , then no solution \\(\\x\\) exists. Case 2: m < n We first need to realize that this is an underdetermined system because we have more unknowns than equations. Let us point back to the question, what kind of \\(\\b\\) allows us to have a solution \\(\\x\\) that solves this equation? One would've thought that all kinds of \\(\\b\\) will have a solution \\(\\x\\) , as opposed to the overdetermined system , but this is not true! Why? - - We can illustrate with an easy example, if \\(m = 3, n = 4\\) , then \\(\\b\\) is made up of linear combination of columns of \\(\\A\\) , although we have \\(4\\) columns, that does not mean all columns span the entire \\(\\R^4\\) space. Consider the \\(4\\) columns, but \\(\\r_2, \\r_3, \\r_4\\) are multiples of \\(\\r_1\\) , and hence these \\(4\\) columns only managed to span the 1D-subspace in \\(\\R^4\\) , consequently, there are \"many\" \\(\\b\\) 's that cannot be represented by these \\(4\\) columns. We leave to the readers to construct and enumerate all examples. Case 3: m = n This is an exercise for the reader \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 How are \\(\\mathbf{A}\\mathbf{x} = \\mathbf{b}\\) and \\(\\mathbf{A}\\mathbf{x} = \\mathbf{0}\\) related in the context of Machine Learning? Read Linear Algebra: Theory, Intuition, Code, 2021. (pp. 230-231) . Why do we say that matrices are linear transformations? 2 Naive Interpretation: Let \\(\\A = (\\a_{ij}) \\in \\F^{m \\times n}\\) be an \\(m \\times n\\) matrix with entries in a field \\(\\F\\) . Let us first define the matrix-vector multiplication \\(\\A\\x = \\b\\) where \\(\\x \\in \\F^{n}\\) and \\(\\b \\in \\F^{m}\\) , and specifically, let \\(\\F^n\\) and \\(\\F^m\\) be our vector spaces \\(\\V\\) and \\(\\W\\) respectively. Define the map \\[T_{\\A}: \\F_{c}^{n} \\rightarrow F_{c}^{m}\\] \\[\\x = \\begin{bmatrix} x_{1}\\\\ x_{2}\\\\ x_{3}\\\\ \\vdots\\\\ x_{n} \\end{bmatrix} \\mapsto \\A\\x \\] Then \\(T_{\\A}\\) is a linear transformation (associated with the matrix \\(\\A\\) ) where we are mapping (sending) the vector \\(\\x\\) from \\(n\\) dimensional space to the vector \\(\\b = \\A\\x\\) in the \\(m\\) dimensional space . Important for readers: \\(T_{\\A}(\\x) = \\A\\x\\) . What does the determinant of a matrix represent (geometrically)?[^chip_huyen_5.1.2.3] Geometrically, if we are given a 2 by 2 matrix \\(\\A = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\\) , then denote the columns as \\(\\v_1 = \\begin{bmatrix} a \\\\ b \\end{bmatrix}\\) and \\(\\v_2 = \\begin{bmatrix} c \\\\ d \\end{bmatrix}\\) . We can show that the \\(\\det(\\A) = ad - bc\\) is actually the area of the parallelogram spanned by the 2 vectors. This generalizes to \\(n\\) dimensional space (i.e. 3 by 3 matrix corresponds to a volume of a cuboid) https://math.stackexchange.com/questions/668/whats-an-intuitive-way-to-think-about-the-determinant https://www.khanacademy.org/math/linear-algebra/matrix-transformations/determinant-depth/v/linear-algebra-determinant-and-area-of-a-parallelogram https://www.khanacademy.org/math/linear-algebra/matrix-transformations/determinant-depth/v/linear-algebra-determinant-as-scaling-factor 3blue1brown: https://www.youtube.com/watch?v=Ip3X9LOh2dk Name some applications with examples of a determinant of a matrix. What is the direct sum decomposition? It makes sense that a vector \\(\\v \\in V\\) can be decomposed uniquely to \\(\\u + \\w\\) from two orthogonal subspaces that complement each other. After all, imagine a 2d R2, we already know that nullspace and row space of A form R2, then it follows that if we take one vector from V, then we take one vector from nullspace, then assume nullspace not empty, then it follows that there must exists another vector from row space of A that is linearly independent from the vector in nullspace, that makes up the https://www.khanacademy.org/math/linear-algebra/alternate-bases/orthogonal-projections/v/linear-algebra-projections-onto-subspaces?modal=1 Relationship of Covariance matrix and Gram Matrix?[^chip_huyen_5.1.2.7] https://stats.stackexchange.com/questions/164997/relationship-between-gram-and-covariance-matrices https://en.wikipedia.org/wiki/Consistent_and_inconsistent_equations \u21a9 Chip Huyen: ML Interviews Book, 2021. section 5.1.2, Q1 \u21a9","title":"Interview"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_interview_questions/#linear-algebra-interview-questions","text":"","title":"Linear Algebra Interview Questions"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_interview_questions/#given-matrix-a-in-rm-times-n-for-what-vectors-mathbfb-in-mathbbrm-does-mathbfamathbfx-mathbfb-have-a-solution-mathbfx-in-mathbbrn","text":"We need to realize a few key points before answering the question. \\(\\A\\x = \\b\\) is equivalent to a system of equations, where there are \\(m\\) equations and \\(n\\) variables (unknowns) and we have a few cases to enumerate: All cases enumerated from the cartesian product \\(\\{\\textbf{Underdetermined, Exactly Determined, Overdetermined}\\} \\times \\{\\textbf{Consistent, Inconsistent}\\}\\) If one finds the definition in the previous point unfamiliar/vague, then please read here 1 . Since we know that right matrix-vector multiplication of \\(\\A\\) on \\(\\x\\) means: \\[ \\A\\x = x_1 \\begin{bmatrix} a_{11} \\\\ a_{21} \\\\ \\vdots \\\\ a_{m1} \\end{bmatrix} + x_2 \\begin{bmatrix} a_{12} \\\\ a_{22} \\\\ \\vdots \\\\ a_{m2} \\end{bmatrix} + \\cdots + x_n \\begin{bmatrix} a_{1n} \\\\ a_{2n} \\\\ \\vdots \\\\ a_{mn} \\end{bmatrix} \\] which is made up of linear combination of columns of \\(\\A\\) with elements of \\(\\x\\) as coefficients.","title":"Given matrix \\(\\A \\in \\R^{m \\times n}\\). For what vectors \\(\\mathbf{b} \\in \\mathbb{R}^{m}\\) does \\(\\mathbf{A}\\mathbf{x} = \\mathbf{b}\\) have a solution \\(\\mathbf{x} \\in \\mathbb{R}^{n}\\)?"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_interview_questions/#case-1-m-n","text":"We first need to realize that this is an overdetermined system because we have more equations than unknowns. Let us point back to the question, what kind of \\(\\b\\) allows us to have a solution \\(\\x\\) that solves this equation? Certainly not all kinds of \\(\\b\\) ! Why? We can illustrate with an easy example, if \\(m = 4, n = 3\\) , then \\(\\b\\) is made up of linear combination of columns of \\(\\A\\) , but we only have \\(3\\) columns, and at most we have something like \\(\\lambda_1 \\c_1 + \\lambda_2 \\c_2 + \\lambda_3 \\c_3\\) where \\(\\lambda \\in \\R, \\c_i \\in \\R^{4}\\) , \\(\\c_i\\) being the columns of \\(\\A\\) . However, we know from my previous chapter on Basis and Dimension 's Theorem (Equivalent Basis Definition) that we necessarily need \\(4\\) vectors in \\(\\R^{4}\\) to span this subspace. Consequently, \\(3\\) vectors (columns of \\(\\A\\) ) cannot possibly span the entire \\(\\R^4\\) ( column space of \\(\\A\\) here ) and hence there are vectors \\(\\b\\) that are not linear combinations of columns of \\(\\A\\) .","title":"Case 1: m &gt; n"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_interview_questions/#consistent","text":"With the above in mind, then if \\(\\b\\) is in the column space of \\(\\A\\) , then \\(\\b\\) is solvable and thus has a solution.","title":"Consistent"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_interview_questions/#inconsistent","text":"If \\(\\b \\not \\in C(\\A)\\) , then no solution \\(\\x\\) exists.","title":"Inconsistent"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_interview_questions/#case-2-m-n","text":"We first need to realize that this is an underdetermined system because we have more unknowns than equations. Let us point back to the question, what kind of \\(\\b\\) allows us to have a solution \\(\\x\\) that solves this equation? One would've thought that all kinds of \\(\\b\\) will have a solution \\(\\x\\) , as opposed to the overdetermined system , but this is not true! Why? - - We can illustrate with an easy example, if \\(m = 3, n = 4\\) , then \\(\\b\\) is made up of linear combination of columns of \\(\\A\\) , although we have \\(4\\) columns, that does not mean all columns span the entire \\(\\R^4\\) space. Consider the \\(4\\) columns, but \\(\\r_2, \\r_3, \\r_4\\) are multiples of \\(\\r_1\\) , and hence these \\(4\\) columns only managed to span the 1D-subspace in \\(\\R^4\\) , consequently, there are \"many\" \\(\\b\\) 's that cannot be represented by these \\(4\\) columns. We leave to the readers to construct and enumerate all examples.","title":"Case 2: m &lt; n"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_interview_questions/#case-3-m-n","text":"This is an exercise for the reader \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02","title":"Case 3: m = n"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_interview_questions/#how-are-mathbfamathbfx-mathbfb-and-mathbfamathbfx-mathbf0-related-in-the-context-of-machine-learning","text":"Read Linear Algebra: Theory, Intuition, Code, 2021. (pp. 230-231) .","title":"How are \\(\\mathbf{A}\\mathbf{x} = \\mathbf{b}\\) and \\(\\mathbf{A}\\mathbf{x} = \\mathbf{0}\\) related in the context of Machine Learning?"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_interview_questions/#why-do-we-say-that-matrices-are-linear-transformations2","text":"Naive Interpretation: Let \\(\\A = (\\a_{ij}) \\in \\F^{m \\times n}\\) be an \\(m \\times n\\) matrix with entries in a field \\(\\F\\) . Let us first define the matrix-vector multiplication \\(\\A\\x = \\b\\) where \\(\\x \\in \\F^{n}\\) and \\(\\b \\in \\F^{m}\\) , and specifically, let \\(\\F^n\\) and \\(\\F^m\\) be our vector spaces \\(\\V\\) and \\(\\W\\) respectively. Define the map \\[T_{\\A}: \\F_{c}^{n} \\rightarrow F_{c}^{m}\\] \\[\\x = \\begin{bmatrix} x_{1}\\\\ x_{2}\\\\ x_{3}\\\\ \\vdots\\\\ x_{n} \\end{bmatrix} \\mapsto \\A\\x \\] Then \\(T_{\\A}\\) is a linear transformation (associated with the matrix \\(\\A\\) ) where we are mapping (sending) the vector \\(\\x\\) from \\(n\\) dimensional space to the vector \\(\\b = \\A\\x\\) in the \\(m\\) dimensional space . Important for readers: \\(T_{\\A}(\\x) = \\A\\x\\) .","title":"Why do we say that matrices are linear transformations?2"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_interview_questions/#what-does-the-determinant-of-a-matrix-represent-geometricallychip_huyen_5123","text":"Geometrically, if we are given a 2 by 2 matrix \\(\\A = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\\) , then denote the columns as \\(\\v_1 = \\begin{bmatrix} a \\\\ b \\end{bmatrix}\\) and \\(\\v_2 = \\begin{bmatrix} c \\\\ d \\end{bmatrix}\\) . We can show that the \\(\\det(\\A) = ad - bc\\) is actually the area of the parallelogram spanned by the 2 vectors. This generalizes to \\(n\\) dimensional space (i.e. 3 by 3 matrix corresponds to a volume of a cuboid) https://math.stackexchange.com/questions/668/whats-an-intuitive-way-to-think-about-the-determinant https://www.khanacademy.org/math/linear-algebra/matrix-transformations/determinant-depth/v/linear-algebra-determinant-and-area-of-a-parallelogram https://www.khanacademy.org/math/linear-algebra/matrix-transformations/determinant-depth/v/linear-algebra-determinant-as-scaling-factor 3blue1brown: https://www.youtube.com/watch?v=Ip3X9LOh2dk","title":"What does the determinant of a matrix represent (geometrically)?[^chip_huyen_5.1.2.3]"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_interview_questions/#name-some-applications-with-examples-of-a-determinant-of-a-matrix","text":"","title":"Name some applications with examples of a determinant of a matrix."},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_interview_questions/#what-is-the-direct-sum-decomposition","text":"It makes sense that a vector \\(\\v \\in V\\) can be decomposed uniquely to \\(\\u + \\w\\) from two orthogonal subspaces that complement each other. After all, imagine a 2d R2, we already know that nullspace and row space of A form R2, then it follows that if we take one vector from V, then we take one vector from nullspace, then assume nullspace not empty, then it follows that there must exists another vector from row space of A that is linearly independent from the vector in nullspace, that makes up the https://www.khanacademy.org/math/linear-algebra/alternate-bases/orthogonal-projections/v/linear-algebra-projections-onto-subspaces?modal=1","title":"What is the direct sum decomposition?"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_interview_questions/#relationship-of-covariance-matrix-and-gram-matrixchip_huyen_5127","text":"https://stats.stackexchange.com/questions/164997/relationship-between-gram-and-covariance-matrices https://en.wikipedia.org/wiki/Consistent_and_inconsistent_equations \u21a9 Chip Huyen: ML Interviews Book, 2021. section 5.1.2, Q1 \u21a9","title":"Relationship of Covariance matrix and Gram Matrix?[^chip_huyen_5.1.2.7]"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_matrix_determinant/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\C}{\\mathbb{C}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\det}{\\textbf{det}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\Q}{\\mathbf{Q}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\q}{\\mathbf{q}} \\newcommand{\\e}{\\mathbf{e}} \\newcommand{\\I}{\\mathbf{I}} \\] Determinant Definition (Determinant of a 2x2 Matrix) We start off with the base case first. Given a 2 by 2 matrix \\(\\A = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\\) . the determinant of the \\(\\A\\) is given by: \\[ \\det(\\A) = ad - bc \\] Theorem (Rank-Reduced Matrix has Determinant of Zero) We first prove this in 2 by 2 setting, and note that it can be generalized to \\(n\\) dimensions. Consider a 2 by 2 matrix \\(\\A\\) , without loss of generality, let us represent the rank-reduced matrix such that: \\[ \\A = \\begin{bmatrix} a & b \\\\ \\lambda a & \\lambda b \\end{bmatrix} \\] where we note that the second row is \\(\\lambda\\) of the first. We can easily deduce the determinant to be: \\[ \\det(\\A) = a \\lambda b - b \\lambda a = 0 \\] This results hold for any \\(\\lambda\\) and thus is true for any rank-reduced matrix. Determinant of Triangular Matrix","title":"Linear algebra matrix determinant"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_matrix_determinant/#determinant","text":"","title":"Determinant"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_matrix_determinant/#definition-determinant-of-a-2x2-matrix","text":"We start off with the base case first. Given a 2 by 2 matrix \\(\\A = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\\) . the determinant of the \\(\\A\\) is given by: \\[ \\det(\\A) = ad - bc \\]","title":"Definition (Determinant of a 2x2 Matrix)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_matrix_determinant/#theorem-rank-reduced-matrix-has-determinant-of-zero","text":"We first prove this in 2 by 2 setting, and note that it can be generalized to \\(n\\) dimensions. Consider a 2 by 2 matrix \\(\\A\\) , without loss of generality, let us represent the rank-reduced matrix such that: \\[ \\A = \\begin{bmatrix} a & b \\\\ \\lambda a & \\lambda b \\end{bmatrix} \\] where we note that the second row is \\(\\lambda\\) of the first. We can easily deduce the determinant to be: \\[ \\det(\\A) = a \\lambda b - b \\lambda a = 0 \\] This results hold for any \\(\\lambda\\) and thus is true for any rank-reduced matrix.","title":"Theorem (Rank-Reduced Matrix has Determinant of Zero)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/linear_algebra_matrix_determinant/#determinant-of-triangular-matrix","text":"","title":"Determinant of Triangular Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/fields/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\] The following notes use reference from Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. , Sheldon Axler: Linear Algebra Done Right, 2015. and Wikipedia for intuitions, examples, formal definitions and theorems. Since I am at the introductory chapters, I will breeze through them until vector spaces. Table of Contents Learning Objectives Field Definition (Field) Examples of Fields Notation of Fields Summary of Fields Learning Objectives Definition of a Field Field Info The treatment of the idea (definition) of a field is stated first. As we venture into the vector spaces, we can connect back with the idea of a field. Definition (Field) Definition A field 1 is an ordered quintuple, \\((\\F,+,0;\\times,1)\\) , where \\(\\F\\) is a set, \\(+\\colon \\F\\times \\F \\to \\F\\) and \\(\\times\\colon \\F \\times \\F\\to \\F\\) are well defined binary operations 2 such that: \\(\\textbf{Well Defined}\\) : For all \\(a, b \\in \\F\\) , we have \\(a + b \\in \\F\\) and \\(a \\times b \\in \\F\\) . \\(\\textbf{Commutative Law for Addition}\\) : For all \\(a,b \\in \\F\\) , \\(a+b = b+a\\) . \\(\\textbf{Associative Law for Addition}\\) : For all \\(a,b,c \\in \\F\\) , \\((a+b)+c = a+(b+c)\\) . \\(\\textbf{Existence of the Additive Identity}\\) : There exists \\(\\mathbf{0} \\in \\F\\) such that \\(\\mathbf{0}+a=a+\\mathbf{0}=a\\) for all \\(a\\in \\F\\) . In other words, an additive identity for the set \\(\\F\\) is any element \\(e\\) such that for any element \\(x \\in \\F\\) , we have \\(e + x = x = x + e\\) . In familiar fields like the Real Numbers \\(\\R\\) , the additive identity is \\(\\mathbf{0}\\) . \\(\\textbf{Existence of Additive Inverse}\\) : For every \\(a \\in \\F\\) there exists \\(b\\in \\F\\) such that \\(a+b=b+a=0\\) . We call \\(b\\) the additive inverse and denote \\(b\\) by \\(-a\\) . \\(\\textbf{Commutative Law for Multiplication}\\) : For all \\(a,b \\in \\F\\) , \\(ab = ba\\) . \\(\\textbf{Associative Law for Multiplication}\\) : For all \\(a,b,c \\in \\F\\) , \\((ab)c = a(bc)\\) \\(\\textbf{Existence of the Multiplicative Identity}\\) : There exists \\(\\mathbf{1}\\in \\F\\) such that \\(\\mathbf{1} \\times a = a\\times \\mathbf{1} = a\\) for all \\(a\\in \\F\\) . \\(\\textbf{Existence of Multiplicative Inverse}\\) : For every \\(a\\in \\F\\) , \\(a\\neq 0\\) , there exists \\(b\\in \\F\\) such that \\(a\\times b = b\\times a = 1\\) . We call \\(b\\) the multiplicative inverse of \\(a\\) and denote \\(b\\) to be \\(a^{-1}\\) . \\(\\textbf{Distributive Law}\\) : \\(\\times\\) distributes over \\(+\\) on the left: for all \\(a,b,c\\in \\F\\) , \\(a\\times(b+c) = (a\\times b)+(a\\times c)\\) . \\(\\times\\) distributes over \\(+\\) on the right: for all \\(a,b,c\\in \\F\\) , \\((b+c)\\times a = (b\\times a)+(c\\times a)\\) . Examples of Fields Example For the number system, \\(\\mathbb{Q}, \\mathbb{R}, \\mathbb{C}\\) are all fields while \\(\\mathbb{N}, \\mathbb{Z}\\) are not fields. One can easily verify that \\(\\mathbb{R}\\) is a field by the definition above. To show that a set is not a field, \\(\\mathbb{N}\\) for example, it suffices to find one single counter example that do not fulfill the definition, in this case, \\(\\textbf{Existence of Additive Inverse}\\) is not fulfilled, as there does not exist any element in the natural number system that has an additive inverse, i.e. pick a natural number, say number 1, the additive inverse is \\(-1\\) but \\(-1\\) is not in \\(\\mathbb{N}\\) . There is a particular field called \\(\\F_2 = \\{0,1\\}\\) . Where \\(0\\) is the additive identity and \\(1\\) is the multiplicative identity. Notation of Fields Following the book Linear Algebra Done Right , we will also claim the following: Notation \\(\\F\\) will stand for either \\(\\R\\) or \\(\\mathbb{C}\\) throughout. Summary of Fields Summary We can think of Field as a \"space\" (read: Real Numbers) where operations such as addition and multiplication are well defined (read: makes sense). Elements residing in a Field has to obey some rules. Elements in a Field are called scalars (keep a mental note here the distinction of a scalar and later, vector ). https://en.wikipedia.org/wiki/Field_(mathematics) \u21a9 https://en.wikipedia.org/wiki/Closure_(mathematics) ; Well defined means closure for addition and multiplication is satisfied. \u21a9","title":"Fields"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/fields/#table-of-contents","text":"Learning Objectives Field Definition (Field) Examples of Fields Notation of Fields Summary of Fields Learning Objectives Definition of a Field","title":"Table of Contents"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/fields/#field","text":"Info The treatment of the idea (definition) of a field is stated first. As we venture into the vector spaces, we can connect back with the idea of a field.","title":"Field"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/fields/#definition-field","text":"Definition A field 1 is an ordered quintuple, \\((\\F,+,0;\\times,1)\\) , where \\(\\F\\) is a set, \\(+\\colon \\F\\times \\F \\to \\F\\) and \\(\\times\\colon \\F \\times \\F\\to \\F\\) are well defined binary operations 2 such that: \\(\\textbf{Well Defined}\\) : For all \\(a, b \\in \\F\\) , we have \\(a + b \\in \\F\\) and \\(a \\times b \\in \\F\\) . \\(\\textbf{Commutative Law for Addition}\\) : For all \\(a,b \\in \\F\\) , \\(a+b = b+a\\) . \\(\\textbf{Associative Law for Addition}\\) : For all \\(a,b,c \\in \\F\\) , \\((a+b)+c = a+(b+c)\\) . \\(\\textbf{Existence of the Additive Identity}\\) : There exists \\(\\mathbf{0} \\in \\F\\) such that \\(\\mathbf{0}+a=a+\\mathbf{0}=a\\) for all \\(a\\in \\F\\) . In other words, an additive identity for the set \\(\\F\\) is any element \\(e\\) such that for any element \\(x \\in \\F\\) , we have \\(e + x = x = x + e\\) . In familiar fields like the Real Numbers \\(\\R\\) , the additive identity is \\(\\mathbf{0}\\) . \\(\\textbf{Existence of Additive Inverse}\\) : For every \\(a \\in \\F\\) there exists \\(b\\in \\F\\) such that \\(a+b=b+a=0\\) . We call \\(b\\) the additive inverse and denote \\(b\\) by \\(-a\\) . \\(\\textbf{Commutative Law for Multiplication}\\) : For all \\(a,b \\in \\F\\) , \\(ab = ba\\) . \\(\\textbf{Associative Law for Multiplication}\\) : For all \\(a,b,c \\in \\F\\) , \\((ab)c = a(bc)\\) \\(\\textbf{Existence of the Multiplicative Identity}\\) : There exists \\(\\mathbf{1}\\in \\F\\) such that \\(\\mathbf{1} \\times a = a\\times \\mathbf{1} = a\\) for all \\(a\\in \\F\\) . \\(\\textbf{Existence of Multiplicative Inverse}\\) : For every \\(a\\in \\F\\) , \\(a\\neq 0\\) , there exists \\(b\\in \\F\\) such that \\(a\\times b = b\\times a = 1\\) . We call \\(b\\) the multiplicative inverse of \\(a\\) and denote \\(b\\) to be \\(a^{-1}\\) . \\(\\textbf{Distributive Law}\\) : \\(\\times\\) distributes over \\(+\\) on the left: for all \\(a,b,c\\in \\F\\) , \\(a\\times(b+c) = (a\\times b)+(a\\times c)\\) . \\(\\times\\) distributes over \\(+\\) on the right: for all \\(a,b,c\\in \\F\\) , \\((b+c)\\times a = (b\\times a)+(c\\times a)\\) .","title":"Definition (Field)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/fields/#examples-of-fields","text":"Example For the number system, \\(\\mathbb{Q}, \\mathbb{R}, \\mathbb{C}\\) are all fields while \\(\\mathbb{N}, \\mathbb{Z}\\) are not fields. One can easily verify that \\(\\mathbb{R}\\) is a field by the definition above. To show that a set is not a field, \\(\\mathbb{N}\\) for example, it suffices to find one single counter example that do not fulfill the definition, in this case, \\(\\textbf{Existence of Additive Inverse}\\) is not fulfilled, as there does not exist any element in the natural number system that has an additive inverse, i.e. pick a natural number, say number 1, the additive inverse is \\(-1\\) but \\(-1\\) is not in \\(\\mathbb{N}\\) . There is a particular field called \\(\\F_2 = \\{0,1\\}\\) . Where \\(0\\) is the additive identity and \\(1\\) is the multiplicative identity.","title":"Examples of Fields"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/fields/#notation-of-fields","text":"Following the book Linear Algebra Done Right , we will also claim the following: Notation \\(\\F\\) will stand for either \\(\\R\\) or \\(\\mathbb{C}\\) throughout.","title":"Notation of Fields"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/fields/#summary-of-fields","text":"Summary We can think of Field as a \"space\" (read: Real Numbers) where operations such as addition and multiplication are well defined (read: makes sense). Elements residing in a Field has to obey some rules. Elements in a Field are called scalars (keep a mental note here the distinction of a scalar and later, vector ). https://en.wikipedia.org/wiki/Field_(mathematics) \u21a9 https://en.wikipedia.org/wiki/Closure_(mathematics) ; Well defined means closure for addition and multiplication is satisfied. \u21a9","title":"Summary of Fields"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/lines_and_planes/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\n}{\\mathbf{n}} \\newcommand{\\r}{\\mathbf{r}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}}\\] Readings Dr Choo Yan Min's treatment of lines and planes are good. https://tutorial.math.lamar.edu/classes/calciii/eqnsofplanes.aspx https://www.tuitionkenneth.com/h2-maths-parametric-scalar-product-cartesian Plane Representation The treatment below concerns planes embedded in three dimensions, specially in \\(\\R^3\\) . Therefore, these planes are necessarily a 2d-subspace. Determination by contained points and lines In a Euclidean space of any number of dimensions, a plane is uniquely determined by any of the following: * Three non-collinear points (points not on a single line). * A line and a point not on that line. * Two distinct but intersecting lines. * Two distinct but parallel lines. Properties of 2D-Planes The following statements hold in three-dimensional Euclidean space but not in higher dimensions, though they have higher-dimensional analogues: * Two distinct planes are either parallel or they intersect in a line. * A line is either parallel to a plane, intersects it at a single point, or is contained in the plane. * Two distinct lines perpendicular to the same plane must be parallel to each other. * Two distinct planes perpendicular to the same line must be parallel to each other. Plane's Equations Point\u2013normal form and general form of the equation of a plane In a manner analogous to the way lines in a two-dimensional space are described using a point-slope form for their equations, planes in a three dimensional space have a natural description using a point in the plane and a vector orthogonal to it (the normal vector) to indicate its \"inclination\". Specifically, let \\(\\r_0\\) be the position vector of some point \\(P_0 = (x_0, y_0, z_0)\\) , and let \\(\\n = (a, b, c)\\) be a nonzero vector. The plane determined by the point \\(P_0\\) and the vector \\(\\n\\) consists of those points \\(P\\) , with position vector \\(\\r\\) , such that the vector drawn from \\(P_0\\) to \\(P\\) is perpendicular to \\(\\n\\) . Recalling that two vectors are perpendicular if and only if their dot product is zero, it follows that the desired plane can be described as the set of all points \\(\\r\\) such that: \\[\\n \\cdot (\\r - \\r_0) = \\0\\] The dot here means a dot product Expanded this becomes \\[a (x-x_0)+ b(y-y_0)+ c(z-z_0)=0\\] which is the point\u2013normal form of the equation of a plane. This is just a linear equation: \\[ax + by + cz + d = 0\\] where \\[d = -(ax_0 + by_0 + cz_0)\\] which is the expanded form of \\(-\\n \\cdot \\r_0\\) . In mathematics it is a common convention to express the normal as a unit vector, but the above argument holds for a normal vector of any non-zero length. Conversely, it is easily shown that if \\(a,b,c\\) and \\(d\\) are constants and \\(a,b,c\\) are not all zero, then the graph of the equation \\[ax + by + cz + d = 0\\] is a plane having the vector \\[\\n = (a,b,c)\\] as a normal. This familiar equation for a plane is called the general form of the equation of the plane. Thus for example a regression equation of the form \\(y = d + ax + cz\\) with \\(b=-1\\) establishes a best-fit plane in three-dimensional space when there are two explanatory variables. Intuition (Hongnan) The idea is given a 2D-plane embedded in a 3-D space, then we start off by assuming there exists a point \\(P_0 = (x_0, y_0, z_0)\\) on the plane; furthermore, we define a vector \\(\\n = (a, b, c)\\) such that this vector is orthogonal (perpendicular) to the plane - we call this vector a normal vector . Next, assume \\(P = (x, y, z)\\) be any point on the plane , and let us define the position vector of \\(P_0\\) and \\(P\\) to be \\(\\r_0\\) and \\(\\r\\) respectively. From a mathematical standpoint, we are fixing the point \\(P_0\\) so that for any point \\(P\\) , the vector formed by the difference of these two position vectors \\(\\r_0\\) and \\(\\r\\) will always lie in the plane . This is important, because now what we do next on this \\(\\r - \\r_0\\) will generalize for the whole plane. By now, from the visual diagram in here , one should realize that given a fixed point \\(P_0\\) and any point \\(P\\) , their difference in vectors \\(\\r - \\r_0\\) always lie on the plane, and is also necessarily orthogonal to the normal vector \\(\\n\\) . Thus, we can have by the orthogonal vectors has dot product \\(\\0\\) to get: \\[ \\n \\cdot (\\r - \\r_0) = \\0 \\implies \\n \\cdot \\r = \\n \\cdot \\r_0 \\] This is a legit equation for the plane, and holds for any vectors lying on the plane . Why so? Because recall (even geometrically) that all vectors on the plane must be orthogonal/perpendicular to the normal vector , and therefore to check the validity of the equation, we just need to check if ANY POINT \\(P\\) on the plane, and substitute its positional vector \\(\\r_0\\) into the equation \\(\\n \\cdot (\\r - \\r_0)\\) , must this equation be \\(\\0\\) ? The answer is yes, because \\(\\r - \\r_0\\) is always a vector on the plane, and hence orthogonal to \\(\\n\\) . Normal Vector need not touch the Vectors on the plane If one is confused what is the meaning of the \\(\\r - \\r_0\\) , say if this equals \\(\\r - \\r_0 = (2, 3, 4)\\) and the normal is \\(\\n = (2, -8, 5)\\) , then even though the vector \\(\\r - \\r_0\\) lies on the plane (which means the vector is not a position vector and does not start from the origin), that is okay because if one recalls what a vector is, we can \"simply move the \\(\\r - \\r_0\\) to make it start from the origin\", and this vector will now be \"position vector\", but still perpendicular to \\(\\n\\) whether it touches it or not. Describing a plane with a point and two vectors lying on it Alternatively, a plane may be described parametrically as the set of all points of the form \\[\\r = \\r_0 + s\\v + t\\w\\] where \\(s\\) and \\(t\\) range over all real numbers, \\(\\v\\) and \\(\\w\\) are given linearly independent defining the plane, and \\(\\r_0\\) is the vector representing the position of an arbitrary (but fixed) point on the plane. The vectors \\(\\v\\) and \\(\\w\\) can be visualized as vectors starting at \\(\\r_0\\) and pointing in different directions along the plane. The vectors \\(\\v\\) and \\(\\w\\) can be perpendicular, but cannot be parallel. Note: In Linear Algebra, most mentions of planes are associated with vector spaces (subspaces), and hence contains the origin. Therefore, we often describe the plane as the set of points spanned by two linearly independent vectors. \\[\\r = s\\v + t\\w\\] notice that we do not specify \\(\\r_0\\) here since we have the zero vector. Vector Equation of a Plane From the previous section, the Vector Equation of a plane is: \\[ \\n \\cdot (\\r - \\r_0) = \\0 \\iff \\n \\cdot \\r = \\n \\cdot \\r_0 \\iff \\n \\cdot \\r = d \\] where \\(d = \\n \\cdot \\r_0\\) . Fig; Vector and Cartesian Equation; Courtesy of https://www.tuitionkenneth.com/h2-maths-parametric-scalar-product-cartesian. Cartesian Equation of Plane From the previous section, the Cartesian Equation of a plane is: \\[ ax + by + cz + d = 0 \\iff ax + by + cd = d \\] where \\(d\\) is a constant \\(-(ax_0 + by_0 + cz_0)\\) and hence we are less pedantic about the sign in the equation above. Parametric Equation of a Plane The Parametric Equation of a plane is: \\[ \\r = \\r_0 + s\\v + t\\w \\] Fig; Parametric Equation; Courtesy of https://www.tuitionkenneth.com/h2-maths-parametric-scalar-product-cartesian. How to plot a plane in Python import matplotlib.pyplot as plt import numpy as np from mpl_toolkits.mplot3d import Axes3D import scipy as sp import scipy.linalg Let's say you want to plot the column space of a matrix \\[\\A = \\begin{bmatrix} 3 & -1 \\\\ 2 & 4 \\\\ -1 & 1 \\end{bmatrix}\\] where the column space of \\(\\A\\) is just the span of the columns: \\[ \\text{col}(\\A)=\\text{span}\\left\\{\\left[ \\matrix{3\\cr 2\\cr -1}\\right],\\ \\left[\\matrix{-1\\cr 4\\cr 1}\\right]\\right\\} \\] then it follows that since the two column vectors are linearly independent, then the span or rather the column space of \\(\\A\\) is the set of points that make up a plane: \\[\\text{col}(\\A) = \\text{plane} = \\{s\\left[\\matrix{3\\cr 2\\cr -1}\\right] + t\\left[\\matrix{-1\\cr 4\\cr 1}\\right] | s, t \\in \\R \\}\\] Then, to plot it, we can express the X, Y and Z components as follows: \\[X = 3s - t \\quad Y = 2s + 4t \\quad Z = -s + t\\] fig = plt . figure ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = '3d' ) s = np . linspace ( - 2 , 2 , 20 ) t = np . linspace ( - 2 , 2 , 20 ) S , T = np . meshgrid ( s , t ) X = 3 * S - T Y = 2 * S + 4 * T Z = - S + T ax . plot_wireframe ( X , Y , Z , linewidth = .5 , color = 'r' ) <mpl_toolkits.mplot3d.art3d.Line3DCollection at 0x277463733d0>","title":"Lines and Planes"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/lines_and_planes/#readings","text":"Dr Choo Yan Min's treatment of lines and planes are good. https://tutorial.math.lamar.edu/classes/calciii/eqnsofplanes.aspx https://www.tuitionkenneth.com/h2-maths-parametric-scalar-product-cartesian","title":"Readings"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/lines_and_planes/#plane-representation","text":"The treatment below concerns planes embedded in three dimensions, specially in \\(\\R^3\\) . Therefore, these planes are necessarily a 2d-subspace.","title":"Plane Representation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/lines_and_planes/#determination-by-contained-points-and-lines","text":"In a Euclidean space of any number of dimensions, a plane is uniquely determined by any of the following: * Three non-collinear points (points not on a single line). * A line and a point not on that line. * Two distinct but intersecting lines. * Two distinct but parallel lines.","title":"Determination by contained points and lines"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/lines_and_planes/#properties-of-2d-planes","text":"The following statements hold in three-dimensional Euclidean space but not in higher dimensions, though they have higher-dimensional analogues: * Two distinct planes are either parallel or they intersect in a line. * A line is either parallel to a plane, intersects it at a single point, or is contained in the plane. * Two distinct lines perpendicular to the same plane must be parallel to each other. * Two distinct planes perpendicular to the same line must be parallel to each other.","title":"Properties of 2D-Planes"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/lines_and_planes/#planes-equations","text":"","title":"Plane's Equations"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/lines_and_planes/#pointnormal-form-and-general-form-of-the-equation-of-a-plane","text":"In a manner analogous to the way lines in a two-dimensional space are described using a point-slope form for their equations, planes in a three dimensional space have a natural description using a point in the plane and a vector orthogonal to it (the normal vector) to indicate its \"inclination\". Specifically, let \\(\\r_0\\) be the position vector of some point \\(P_0 = (x_0, y_0, z_0)\\) , and let \\(\\n = (a, b, c)\\) be a nonzero vector. The plane determined by the point \\(P_0\\) and the vector \\(\\n\\) consists of those points \\(P\\) , with position vector \\(\\r\\) , such that the vector drawn from \\(P_0\\) to \\(P\\) is perpendicular to \\(\\n\\) . Recalling that two vectors are perpendicular if and only if their dot product is zero, it follows that the desired plane can be described as the set of all points \\(\\r\\) such that: \\[\\n \\cdot (\\r - \\r_0) = \\0\\] The dot here means a dot product Expanded this becomes \\[a (x-x_0)+ b(y-y_0)+ c(z-z_0)=0\\] which is the point\u2013normal form of the equation of a plane. This is just a linear equation: \\[ax + by + cz + d = 0\\] where \\[d = -(ax_0 + by_0 + cz_0)\\] which is the expanded form of \\(-\\n \\cdot \\r_0\\) . In mathematics it is a common convention to express the normal as a unit vector, but the above argument holds for a normal vector of any non-zero length. Conversely, it is easily shown that if \\(a,b,c\\) and \\(d\\) are constants and \\(a,b,c\\) are not all zero, then the graph of the equation \\[ax + by + cz + d = 0\\] is a plane having the vector \\[\\n = (a,b,c)\\] as a normal. This familiar equation for a plane is called the general form of the equation of the plane. Thus for example a regression equation of the form \\(y = d + ax + cz\\) with \\(b=-1\\) establishes a best-fit plane in three-dimensional space when there are two explanatory variables.","title":"Point\u2013normal form and general form of the equation of a plane"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/lines_and_planes/#intuition-hongnan","text":"The idea is given a 2D-plane embedded in a 3-D space, then we start off by assuming there exists a point \\(P_0 = (x_0, y_0, z_0)\\) on the plane; furthermore, we define a vector \\(\\n = (a, b, c)\\) such that this vector is orthogonal (perpendicular) to the plane - we call this vector a normal vector . Next, assume \\(P = (x, y, z)\\) be any point on the plane , and let us define the position vector of \\(P_0\\) and \\(P\\) to be \\(\\r_0\\) and \\(\\r\\) respectively. From a mathematical standpoint, we are fixing the point \\(P_0\\) so that for any point \\(P\\) , the vector formed by the difference of these two position vectors \\(\\r_0\\) and \\(\\r\\) will always lie in the plane . This is important, because now what we do next on this \\(\\r - \\r_0\\) will generalize for the whole plane. By now, from the visual diagram in here , one should realize that given a fixed point \\(P_0\\) and any point \\(P\\) , their difference in vectors \\(\\r - \\r_0\\) always lie on the plane, and is also necessarily orthogonal to the normal vector \\(\\n\\) . Thus, we can have by the orthogonal vectors has dot product \\(\\0\\) to get: \\[ \\n \\cdot (\\r - \\r_0) = \\0 \\implies \\n \\cdot \\r = \\n \\cdot \\r_0 \\] This is a legit equation for the plane, and holds for any vectors lying on the plane . Why so? Because recall (even geometrically) that all vectors on the plane must be orthogonal/perpendicular to the normal vector , and therefore to check the validity of the equation, we just need to check if ANY POINT \\(P\\) on the plane, and substitute its positional vector \\(\\r_0\\) into the equation \\(\\n \\cdot (\\r - \\r_0)\\) , must this equation be \\(\\0\\) ? The answer is yes, because \\(\\r - \\r_0\\) is always a vector on the plane, and hence orthogonal to \\(\\n\\) .","title":"Intuition (Hongnan)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/lines_and_planes/#normal-vector-need-not-touch-the-vectors-on-the-plane","text":"If one is confused what is the meaning of the \\(\\r - \\r_0\\) , say if this equals \\(\\r - \\r_0 = (2, 3, 4)\\) and the normal is \\(\\n = (2, -8, 5)\\) , then even though the vector \\(\\r - \\r_0\\) lies on the plane (which means the vector is not a position vector and does not start from the origin), that is okay because if one recalls what a vector is, we can \"simply move the \\(\\r - \\r_0\\) to make it start from the origin\", and this vector will now be \"position vector\", but still perpendicular to \\(\\n\\) whether it touches it or not.","title":"Normal Vector need not touch the Vectors on the plane"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/lines_and_planes/#describing-a-plane-with-a-point-and-two-vectors-lying-on-it","text":"Alternatively, a plane may be described parametrically as the set of all points of the form \\[\\r = \\r_0 + s\\v + t\\w\\] where \\(s\\) and \\(t\\) range over all real numbers, \\(\\v\\) and \\(\\w\\) are given linearly independent defining the plane, and \\(\\r_0\\) is the vector representing the position of an arbitrary (but fixed) point on the plane. The vectors \\(\\v\\) and \\(\\w\\) can be visualized as vectors starting at \\(\\r_0\\) and pointing in different directions along the plane. The vectors \\(\\v\\) and \\(\\w\\) can be perpendicular, but cannot be parallel. Note: In Linear Algebra, most mentions of planes are associated with vector spaces (subspaces), and hence contains the origin. Therefore, we often describe the plane as the set of points spanned by two linearly independent vectors. \\[\\r = s\\v + t\\w\\] notice that we do not specify \\(\\r_0\\) here since we have the zero vector.","title":"Describing a plane with a point and two vectors lying on it"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/lines_and_planes/#vector-equation-of-a-plane","text":"From the previous section, the Vector Equation of a plane is: \\[ \\n \\cdot (\\r - \\r_0) = \\0 \\iff \\n \\cdot \\r = \\n \\cdot \\r_0 \\iff \\n \\cdot \\r = d \\] where \\(d = \\n \\cdot \\r_0\\) . Fig; Vector and Cartesian Equation; Courtesy of https://www.tuitionkenneth.com/h2-maths-parametric-scalar-product-cartesian.","title":"Vector Equation of a Plane"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/lines_and_planes/#cartesian-equation-of-plane","text":"From the previous section, the Cartesian Equation of a plane is: \\[ ax + by + cz + d = 0 \\iff ax + by + cd = d \\] where \\(d\\) is a constant \\(-(ax_0 + by_0 + cz_0)\\) and hence we are less pedantic about the sign in the equation above.","title":"Cartesian Equation of Plane"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/lines_and_planes/#parametric-equation-of-a-plane","text":"The Parametric Equation of a plane is: \\[ \\r = \\r_0 + s\\v + t\\w \\] Fig; Parametric Equation; Courtesy of https://www.tuitionkenneth.com/h2-maths-parametric-scalar-product-cartesian.","title":"Parametric Equation of a Plane"},{"location":"reighns_ml_journey/mathematics/linear_algebra/01_preliminaries/lines_and_planes/#how-to-plot-a-plane-in-python","text":"import matplotlib.pyplot as plt import numpy as np from mpl_toolkits.mplot3d import Axes3D import scipy as sp import scipy.linalg Let's say you want to plot the column space of a matrix \\[\\A = \\begin{bmatrix} 3 & -1 \\\\ 2 & 4 \\\\ -1 & 1 \\end{bmatrix}\\] where the column space of \\(\\A\\) is just the span of the columns: \\[ \\text{col}(\\A)=\\text{span}\\left\\{\\left[ \\matrix{3\\cr 2\\cr -1}\\right],\\ \\left[\\matrix{-1\\cr 4\\cr 1}\\right]\\right\\} \\] then it follows that since the two column vectors are linearly independent, then the span or rather the column space of \\(\\A\\) is the set of points that make up a plane: \\[\\text{col}(\\A) = \\text{plane} = \\{s\\left[\\matrix{3\\cr 2\\cr -1}\\right] + t\\left[\\matrix{-1\\cr 4\\cr 1}\\right] | s, t \\in \\R \\}\\] Then, to plot it, we can express the X, Y and Z components as follows: \\[X = 3s - t \\quad Y = 2s + 4t \\quad Z = -s + t\\] fig = plt . figure ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = '3d' ) s = np . linspace ( - 2 , 2 , 20 ) t = np . linspace ( - 2 , 2 , 20 ) S , T = np . meshgrid ( s , t ) X = 3 * S - T Y = 2 * S + 4 * T Z = - S + T ax . plot_wireframe ( X , Y , Z , linewidth = .5 , color = 'r' ) <mpl_toolkits.mplot3d.art3d.Line3DCollection at 0x277463733d0>","title":"How to plot a plane in Python"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\] The following notes use reference from Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. , Sheldon Axler: Linear Algebra Done Right, 2015. and Wikipedia for intuitions, examples, formal definitions and theorems. Since I am at the introductory chapters, I will breeze through them until vector spaces. Table of Contents Learning Objectives Vectors Geometric Definition (Vectors) Vector is Invariant under Coordinates Algebraic Definition (Vectors) Equality of Vectors Vector Orientation Example of Column and Row Vectors Transposed Vector Definition (Transposed Vector) Vector Addition and Subtraction Algebraic Definition Geometric Definition Vector Addition is Commutative Vector-Scalar Multiplication Algebraic Definition Geometric Definition Vector-Scalar Multiplication is Invariant under Rotation Vector-Scalar Multiplication is Commutative Norm of a Vector Exercises Learning Objectives Definition of a Vector Vector Operations with both Algebraic and Geometric understanding. Vectors Geometric Definition (Vectors) Definition A vector can be interpretated as an geometric object (line) that are determined by magnitude and direction . Example (Vector vs Coordinate) One thing to note is that a vector is different from a coordinate/point : Consider the following diagram 2.3, the three coordinates (circles) are distinct, but the three vectors (lines) are the same, that is because all 3 vectors can be described by \"move from the start 1 unit to the right, and 2 units down\" (read: all 3 vectors have the same magnitude and direction and can be represented by the vector \\([1 -2]\\) ). When the vector is in its standard position (the black vector), the head of the vector \\([1 -2]\\) overlaps with the coordinate \\([1 -2]\\) . - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 25) Fig 2.3: 3 of the same vectors with different starting coordinates; By Hongnan G. Vector is Invariant under Coordinates The geometric interpretation is important and it deserves a spot of its own, we often say that a vector is invariant under coordinates 1 . A given vector is the same vector, regardless of how we identify its coordinates with respect to a particular basis. The vector is pointing in a certain direction, with a certain length, in space. If you \"moved space around the vector\" but left the vector alone, its coordinates would change, but it would still be the same vector. That's just another way of looking at expressing a vector in a different basis. At this stage, going deep into basis will be too much, but just think of basis of our point of reference, and in our case, we are using the origin as our point of reference. Algebraic Definition (Vectors) Warning The algebraic definition of vectors vary from different texts, though the idea is organically the same. We will pick one and stick to it! Definition For a field \\(\\F\\) and a positive integer \\(n\\) , a vector \\(\\v\\) with \\(n\\) entries \\(v_1, v_2, \\cdots, v_n\\) , each \\(v_i\\) belonging to \\(\\F\\) , is called an \\(n\\) -vector over \\(\\F\\) . In particular, \\(\\v\\) is ordered and can be represented mathematically as: \\[\\v = \\{(v_1, v_2, \\cdots, v_n) ~|~ v_i \\in \\F\\}\\] The set of \\(n\\) -vectors over \\(\\F\\) is denoted \\(\\F^n\\) . We will deal with this more in vector spaces, just keep a mental note here. Equality of Vectors Definition By definition of the geometrical interpretation of vectors, two vectors are equal if and only if they have the same magnitude in the same direction , which is why even though figure 2.3's 3 vectors look visually different, but are actually the same vector. By definition of the algebraical interpretation of vectors, two vectors \\(\\v_1\\) and \\(\\v_2\\) are equal if and only if each elements of \\(\\v_1\\) is equal to \\(\\v_2\\) . Vector Orientation A column vector \\(\\v \\in \\R^n\\) is defined as: \\[\\v = \\begin{bmatrix}v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\\\ \\end{bmatrix}\\] and a row vector \\(\\v \\in \\R^n\\) : \\[ \\v = \\begin{bmatrix} v_1 & v_2 & \\cdots & v_n \\end{bmatrix} \\] Info By convention, a vector \\(\\v\\) is a column vector unless stated otherwise. Example of Column and Row Vectors The author from Linear Algebra: Theory, Intuition, Code gave some examples in python, I've added my own comments below. import numpy as np # array, no orientation v = np . array ([ 1 , 2 , 3 ]) print ( f \"v: { v } \" ) print ( f \"v shape: { v . shape } \" ) # col. vector, note that the shape is (3, 1), means a 3 by 1 vector col_v = np . array ([[ 1 ], [ 2 ], [ 3 ]]) print ( f \"col_v: \\n { col_v } \" ) print ( f \"col_v shape: { col_v . shape } \" ) # row vector, note that the shape is (1, 3), means a 1 by 3 vector row_v = np . array ([[ 1 , 2 , 3 ]]) print ( f \"row_v: { row_v } \" ) print ( f \"row_v shape: { row_v . shape } \" ) v: [1 2 3] v shape: (3,) col_v: [[1] [2] [3]] col_v shape: (3, 1) row_v: [[1 2 3]] row_v shape: (1, 3) Transposed Vector Definition (Transposed Vector) Definition By definition, the transpose of a row vector \\(\\v\\) is defined as: \\[\\begin{bmatrix} v_1 \\; v_2 \\; \\dots \\; v_n \\end{bmatrix}^{\\rm T} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix}\\] We can also tranpose a column vector to get the row vector. Worth mentioning that for any \\(\\v \\in \\R^n\\) , \\(\\v^\\top = (\\v^\\top)^\\top\\) . Vector Addition and Subtraction Algebraic Definition (Vector Addition and Subtraction) We will go through the algebra definition first as it is easier to understand. Definition For any vector \\(\\mathbf{a}, \\mathbf{b} \\in \\R^n\\) , the vector addition and subtraction can be defined as follows: \\[\\mathbf{a} \\pm \\mathbf{b} = \\begin{bmatrix} a_1 \\pm b_1 \\; a_2 \\pm b_2 \\; \\dots \\; a_n \\pm b_n \\end{bmatrix}^{\\rm T}\\] Geometric Definition (Vector Addition and Subtraction) The geometry intuition is best done with examples, with some reference from Linear Algebra: Theory, Intuition, Code . Consider the vector \\[ \\u = \\begin{bmatrix} 4 & 7 \\end{bmatrix}^\\top, \\v = \\begin{bmatrix} 8 & 4 \\end{bmatrix}^\\top \\] corresponding to \\(\\u\\) and \\(\\v\\) in the diagram respectively. Vector Addition On the left of figure 2.5: To add two vectors \\(\\u\\) and \\(\\v\\) , we first draw out vector \\(\\u\\) and \\(\\v\\) using \\(0\\) as the origin point. Then, the first way is to just look at one of the vector, say \\(\\u\\) , and adding \\(\\v\\) just means at the head of the vector \\(\\u\\) , move \\(8\\) units to the right on the x-axis, and \\(4\\) units upwards on the y-axis to reach \\(\\u+\\v = \\begin{bmatrix} 12 & 11 \\end{bmatrix}^\\top\\) . Another way is to put the start (tail) of vector \\(\\v\\) at the end (head) of vector \\(\\u\\) . But in the diagram, the head of \\(\\u\\) does not \"directly connect to\" the tail of \\(\\v\\) . This is where we revisit our definition of vectors interpreted geometrically . Remember that vectors are defined by their direction and magnitude, so if one moves vector \\(\\v\\) from \\(\\begin{bmatrix} 4 & 7 \\end{bmatrix}^\\top\\) to exactly where the head of \\(\\u\\) is, then this is the head-to-tail method detailed in the previous paragraph. Note that to be exact, we shifted the blue vector \\(\\v\\) up to the head of \\(\\u\\) , as shown in the diagram's legend. We can do this because we are not actually changing the direction and the magnitude of the vector \\(\\v\\) . Vector Subtraction There are two ways to look at subtraction. We first distinct to the readers the red vector is \\(\\u\\) and blue vector is \\(\\v\\) , both starting from the origin. First way: we know that \\(\\u - \\v = \\u + (-\\v)\\) and thus we can translate the subtraction problem to addition by multiplying one of the vector, here we multiply \\(\\v\\) by \\(-1\\) . Note that \\(-1 \\cdot \\v = \\begin{bmatrix} -8 & -4 \\end{bmatrix}^\\top\\) . And then we can use back vector addition. Note that we should bear in mind that we can \"move\" the vectors freely so that the head-to-tail rules can be applied. This method corresponds to \"bottom left side of the diagram\". Second way: The second way to think about vector subtraction is to keep both vectors in their standard position, and draw the line that goes from the head of the subtracted vector (the one with the minus sign) to the head of the other vector (the one without the minus sign) (This method corresponds to \"upper right side of the diagram\"). That resulting vector is the difference. It\u2019s not in standard position, but that doesn\u2019t matter. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 32) Info Something worth noting is \\(\\u - \\v = -(\\v - \\u)\\) . Geometrically, this means that \\(\\u - \\v\\) flips \\(\\v - \\u\\) 180 degrees. Fig 2.52: Vector Addition and Subtraction; Courtesy of Macro Analyst . Vector Addition is Commutative Info Although we have not formally define a vector space over a field , we can chime in now and say that if a set of vectors \\(V\\) are defined over a field \\(\\F\\) , then all vectors in \\(V\\) are commutative by definition of a Field . Therefore, the vector addition example can be done from \\(\\b\\) to \\(\\a\\) instead of \\(\\a\\) to \\(\\b\\) . The power of defining objects over a field is that any vectors over this \\(\\F\\) must obey all the rules/laws above, and commutative is one of them. Vector-Scalar Multiplication Algebraic Definition (Vector-Scalar Multiplication) We go through the algebra definition first as it is easier to understand. Definition For any vector \\(\\v \\in \\R^n\\) and scalar \\(\\lambda \\in \\R\\) , the vector expression \\(\\lambda \\v\\) , \\[\\lambda \\v= \\begin{bmatrix} \\lambda v_1 \\; \\lambda v_2 \\; \\dots \\; \\lambda v_n \\end{bmatrix}^{\\rm T}\\] is called the Vector-Scalar Multiplication . Geometrical Definition (Vector-Scalar Multiplication) Positive Scaling The easiest part is to scale a vector positively. For example, a vector \\(\\begin{bmatrix}1 & 2 \\end{bmatrix}^{\\rm T}\\) when scaled with a scalar \\(\\lambda = 3\\) gives \\(3\\begin{bmatrix}1 & 2 \\end{bmatrix}^{\\rm T} = \\begin{bmatrix}3 & 6\\end{bmatrix}^{\\rm T}\\) , and the diagram below illustrates the relationship. Notice that the orientation of the vector did not change, in other words, the magnitude of the scaled vector changed by a factor of \\(3\\) , but the direction did not change. Negative Scaling The more confusing part is to scale a vector negatively. For example, a vector \\(\\begin{bmatrix}1 & 2 \\end{bmatrix}^{\\rm T}\\) when scaled with a scalar \\(\\lambda = -1\\) gives \\(-1\\begin{bmatrix}1 & 2 \\end{bmatrix}^{\\rm T} = \\begin{bmatrix}-1 & 2\\end{bmatrix}^{\\rm T}\\) , diagram 2.6 below illustrates the relationship. Note that even though the negatively scaled vector will point to the opposite direction, the \"orientation\" of the scaled vector did not change. Imagine \\(\\begin{bmatrix}1 & 2 \\end{bmatrix}^{\\rm T}\\) is extended infinitely long both sides, then all scaling of this vector will still be on this line . Fig 2.6: Vector-Scalar Multiplication; By Hongnan G. Key Properties (Vector-Scalar Multiplication is Invariant under Rotation) Vector-Scalar Multiplication Invariance Vector-scalar multiplication is conceptually and computationally simple, but do not underestimate its importance: Stretching a vector without rotating it is fundamental to many applications in linear algebra, including eigendecomposition. Sometimes, the simple things (in mathematics and in life) are the most powerful. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 36) Vector-Scalar Multiplication is Commutative Info Similar to the commutative property in vector addition, vector-scalar multiplication is commutative as well. Therefore, the vector-scalar multiplication \\(\\lambda \\v = \\v \\lambda\\) . Norm (Magnitude) of a Vector Definition (Norm of a Vector) Definition The length or the magnitude of a vector \\(\\v \\in \\R^n\\) with elements \\(v_1, v_2, \\cdots, v_n\\) is defined as: \\[\\|\\v\\| = \\sqrt{v_1^2 + v_2^2 + \\cdots + v_n^2}\\] Exercise (pp. 41 of Linear Algebra: Theory, Intuition, Code, 2021.) Create a 2D vector v, 10 scalars that are drawn at random from a normal (Gaussian) distribution, and plot all 10 scalar-vector multiplications on top of each other. What do you notice? You'll notice that all scaled versions of the vector form a line. import numpy as np import matplotlib.pyplot as plt # 2d col vector v = np . array ([ 1 , 2 ]) # plot it plt . plot ([ 0 , v [ 0 ]], [ 0 , v [ 1 ]]); import matplotlib.font_manager as font_manager from numpy.random import default_rng rng = default_rng () fig , ax = plt . subplots ( figsize = ( 9 , 9 )) # and then plot scaled versions on top legends = [] for i in range ( 100 ): # random scalar s = rng . standard_normal ( 1 )[ 0 ] # scaled vector sv = s * v plt . plot ([ 0 , sv [ 0 ]], [ 0 , sv [ 1 ]]) legends . append ( f \" { i + 1 } th vector\" ) font = font_manager . FontProperties ( family = \"Comic Sans MS\" , weight = \"bold\" , style = \"normal\" , size = 10 ) # only show first 10 legends! plt . legend ( legends [ 0 : 10 ], loc = \"upper left\" , prop = font ) plt . grid ( \"on\" ) plt . axis ( \"square\" ) plt . axis ([ - 6 , 6 , - 6 , 6 ]) plt . show (); What does it mean for a vector to remain invariant under coordinate transformation? \u21a9","title":"Vector Operations"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#table-of-contents","text":"Learning Objectives Vectors Geometric Definition (Vectors) Vector is Invariant under Coordinates Algebraic Definition (Vectors) Equality of Vectors Vector Orientation Example of Column and Row Vectors Transposed Vector Definition (Transposed Vector) Vector Addition and Subtraction Algebraic Definition Geometric Definition Vector Addition is Commutative Vector-Scalar Multiplication Algebraic Definition Geometric Definition Vector-Scalar Multiplication is Invariant under Rotation Vector-Scalar Multiplication is Commutative Norm of a Vector Exercises Learning Objectives Definition of a Vector Vector Operations with both Algebraic and Geometric understanding.","title":"Table of Contents"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#vectors","text":"","title":"Vectors"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#geometric-definition-vectors","text":"Definition A vector can be interpretated as an geometric object (line) that are determined by magnitude and direction . Example (Vector vs Coordinate) One thing to note is that a vector is different from a coordinate/point : Consider the following diagram 2.3, the three coordinates (circles) are distinct, but the three vectors (lines) are the same, that is because all 3 vectors can be described by \"move from the start 1 unit to the right, and 2 units down\" (read: all 3 vectors have the same magnitude and direction and can be represented by the vector \\([1 -2]\\) ). When the vector is in its standard position (the black vector), the head of the vector \\([1 -2]\\) overlaps with the coordinate \\([1 -2]\\) . - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 25) Fig 2.3: 3 of the same vectors with different starting coordinates; By Hongnan G.","title":"Geometric Definition (Vectors)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#vector-is-invariant-under-coordinates","text":"The geometric interpretation is important and it deserves a spot of its own, we often say that a vector is invariant under coordinates 1 . A given vector is the same vector, regardless of how we identify its coordinates with respect to a particular basis. The vector is pointing in a certain direction, with a certain length, in space. If you \"moved space around the vector\" but left the vector alone, its coordinates would change, but it would still be the same vector. That's just another way of looking at expressing a vector in a different basis. At this stage, going deep into basis will be too much, but just think of basis of our point of reference, and in our case, we are using the origin as our point of reference.","title":"Vector is Invariant under Coordinates"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#algebraic-definition-vectors","text":"Warning The algebraic definition of vectors vary from different texts, though the idea is organically the same. We will pick one and stick to it! Definition For a field \\(\\F\\) and a positive integer \\(n\\) , a vector \\(\\v\\) with \\(n\\) entries \\(v_1, v_2, \\cdots, v_n\\) , each \\(v_i\\) belonging to \\(\\F\\) , is called an \\(n\\) -vector over \\(\\F\\) . In particular, \\(\\v\\) is ordered and can be represented mathematically as: \\[\\v = \\{(v_1, v_2, \\cdots, v_n) ~|~ v_i \\in \\F\\}\\] The set of \\(n\\) -vectors over \\(\\F\\) is denoted \\(\\F^n\\) . We will deal with this more in vector spaces, just keep a mental note here.","title":"Algebraic Definition (Vectors)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#equality-of-vectors","text":"Definition By definition of the geometrical interpretation of vectors, two vectors are equal if and only if they have the same magnitude in the same direction , which is why even though figure 2.3's 3 vectors look visually different, but are actually the same vector. By definition of the algebraical interpretation of vectors, two vectors \\(\\v_1\\) and \\(\\v_2\\) are equal if and only if each elements of \\(\\v_1\\) is equal to \\(\\v_2\\) .","title":"Equality of Vectors"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#vector-orientation","text":"A column vector \\(\\v \\in \\R^n\\) is defined as: \\[\\v = \\begin{bmatrix}v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\\\ \\end{bmatrix}\\] and a row vector \\(\\v \\in \\R^n\\) : \\[ \\v = \\begin{bmatrix} v_1 & v_2 & \\cdots & v_n \\end{bmatrix} \\] Info By convention, a vector \\(\\v\\) is a column vector unless stated otherwise.","title":"Vector Orientation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#example-of-column-and-row-vectors","text":"The author from Linear Algebra: Theory, Intuition, Code gave some examples in python, I've added my own comments below. import numpy as np # array, no orientation v = np . array ([ 1 , 2 , 3 ]) print ( f \"v: { v } \" ) print ( f \"v shape: { v . shape } \" ) # col. vector, note that the shape is (3, 1), means a 3 by 1 vector col_v = np . array ([[ 1 ], [ 2 ], [ 3 ]]) print ( f \"col_v: \\n { col_v } \" ) print ( f \"col_v shape: { col_v . shape } \" ) # row vector, note that the shape is (1, 3), means a 1 by 3 vector row_v = np . array ([[ 1 , 2 , 3 ]]) print ( f \"row_v: { row_v } \" ) print ( f \"row_v shape: { row_v . shape } \" ) v: [1 2 3] v shape: (3,) col_v: [[1] [2] [3]] col_v shape: (3, 1) row_v: [[1 2 3]] row_v shape: (1, 3)","title":"Example of Column and Row Vectors"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#transposed-vector","text":"","title":"Transposed Vector"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#definition-transposed-vector","text":"Definition By definition, the transpose of a row vector \\(\\v\\) is defined as: \\[\\begin{bmatrix} v_1 \\; v_2 \\; \\dots \\; v_n \\end{bmatrix}^{\\rm T} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix}\\] We can also tranpose a column vector to get the row vector. Worth mentioning that for any \\(\\v \\in \\R^n\\) , \\(\\v^\\top = (\\v^\\top)^\\top\\) .","title":"Definition (Transposed Vector)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#vector-addition-and-subtraction","text":"","title":"Vector Addition and Subtraction"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#algebraic-definition-vector-addition-and-subtraction","text":"We will go through the algebra definition first as it is easier to understand. Definition For any vector \\(\\mathbf{a}, \\mathbf{b} \\in \\R^n\\) , the vector addition and subtraction can be defined as follows: \\[\\mathbf{a} \\pm \\mathbf{b} = \\begin{bmatrix} a_1 \\pm b_1 \\; a_2 \\pm b_2 \\; \\dots \\; a_n \\pm b_n \\end{bmatrix}^{\\rm T}\\]","title":"Algebraic Definition (Vector Addition and Subtraction)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#geometric-definition-vector-addition-and-subtraction","text":"The geometry intuition is best done with examples, with some reference from Linear Algebra: Theory, Intuition, Code . Consider the vector \\[ \\u = \\begin{bmatrix} 4 & 7 \\end{bmatrix}^\\top, \\v = \\begin{bmatrix} 8 & 4 \\end{bmatrix}^\\top \\] corresponding to \\(\\u\\) and \\(\\v\\) in the diagram respectively. Vector Addition On the left of figure 2.5: To add two vectors \\(\\u\\) and \\(\\v\\) , we first draw out vector \\(\\u\\) and \\(\\v\\) using \\(0\\) as the origin point. Then, the first way is to just look at one of the vector, say \\(\\u\\) , and adding \\(\\v\\) just means at the head of the vector \\(\\u\\) , move \\(8\\) units to the right on the x-axis, and \\(4\\) units upwards on the y-axis to reach \\(\\u+\\v = \\begin{bmatrix} 12 & 11 \\end{bmatrix}^\\top\\) . Another way is to put the start (tail) of vector \\(\\v\\) at the end (head) of vector \\(\\u\\) . But in the diagram, the head of \\(\\u\\) does not \"directly connect to\" the tail of \\(\\v\\) . This is where we revisit our definition of vectors interpreted geometrically . Remember that vectors are defined by their direction and magnitude, so if one moves vector \\(\\v\\) from \\(\\begin{bmatrix} 4 & 7 \\end{bmatrix}^\\top\\) to exactly where the head of \\(\\u\\) is, then this is the head-to-tail method detailed in the previous paragraph. Note that to be exact, we shifted the blue vector \\(\\v\\) up to the head of \\(\\u\\) , as shown in the diagram's legend. We can do this because we are not actually changing the direction and the magnitude of the vector \\(\\v\\) . Vector Subtraction There are two ways to look at subtraction. We first distinct to the readers the red vector is \\(\\u\\) and blue vector is \\(\\v\\) , both starting from the origin. First way: we know that \\(\\u - \\v = \\u + (-\\v)\\) and thus we can translate the subtraction problem to addition by multiplying one of the vector, here we multiply \\(\\v\\) by \\(-1\\) . Note that \\(-1 \\cdot \\v = \\begin{bmatrix} -8 & -4 \\end{bmatrix}^\\top\\) . And then we can use back vector addition. Note that we should bear in mind that we can \"move\" the vectors freely so that the head-to-tail rules can be applied. This method corresponds to \"bottom left side of the diagram\". Second way: The second way to think about vector subtraction is to keep both vectors in their standard position, and draw the line that goes from the head of the subtracted vector (the one with the minus sign) to the head of the other vector (the one without the minus sign) (This method corresponds to \"upper right side of the diagram\"). That resulting vector is the difference. It\u2019s not in standard position, but that doesn\u2019t matter. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 32) Info Something worth noting is \\(\\u - \\v = -(\\v - \\u)\\) . Geometrically, this means that \\(\\u - \\v\\) flips \\(\\v - \\u\\) 180 degrees. Fig 2.52: Vector Addition and Subtraction; Courtesy of Macro Analyst .","title":"Geometric Definition (Vector Addition and Subtraction)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#vector-addition-is-commutative","text":"Info Although we have not formally define a vector space over a field , we can chime in now and say that if a set of vectors \\(V\\) are defined over a field \\(\\F\\) , then all vectors in \\(V\\) are commutative by definition of a Field . Therefore, the vector addition example can be done from \\(\\b\\) to \\(\\a\\) instead of \\(\\a\\) to \\(\\b\\) . The power of defining objects over a field is that any vectors over this \\(\\F\\) must obey all the rules/laws above, and commutative is one of them.","title":"Vector Addition is Commutative"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#vector-scalar-multiplication","text":"","title":"Vector-Scalar Multiplication"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#algebraic-definition-vector-scalar-multiplication","text":"We go through the algebra definition first as it is easier to understand. Definition For any vector \\(\\v \\in \\R^n\\) and scalar \\(\\lambda \\in \\R\\) , the vector expression \\(\\lambda \\v\\) , \\[\\lambda \\v= \\begin{bmatrix} \\lambda v_1 \\; \\lambda v_2 \\; \\dots \\; \\lambda v_n \\end{bmatrix}^{\\rm T}\\] is called the Vector-Scalar Multiplication .","title":"Algebraic Definition (Vector-Scalar Multiplication)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#geometrical-definition-vector-scalar-multiplication","text":"","title":"Geometrical Definition (Vector-Scalar Multiplication)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#positive-scaling","text":"The easiest part is to scale a vector positively. For example, a vector \\(\\begin{bmatrix}1 & 2 \\end{bmatrix}^{\\rm T}\\) when scaled with a scalar \\(\\lambda = 3\\) gives \\(3\\begin{bmatrix}1 & 2 \\end{bmatrix}^{\\rm T} = \\begin{bmatrix}3 & 6\\end{bmatrix}^{\\rm T}\\) , and the diagram below illustrates the relationship. Notice that the orientation of the vector did not change, in other words, the magnitude of the scaled vector changed by a factor of \\(3\\) , but the direction did not change.","title":"Positive Scaling"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#negative-scaling","text":"The more confusing part is to scale a vector negatively. For example, a vector \\(\\begin{bmatrix}1 & 2 \\end{bmatrix}^{\\rm T}\\) when scaled with a scalar \\(\\lambda = -1\\) gives \\(-1\\begin{bmatrix}1 & 2 \\end{bmatrix}^{\\rm T} = \\begin{bmatrix}-1 & 2\\end{bmatrix}^{\\rm T}\\) , diagram 2.6 below illustrates the relationship. Note that even though the negatively scaled vector will point to the opposite direction, the \"orientation\" of the scaled vector did not change. Imagine \\(\\begin{bmatrix}1 & 2 \\end{bmatrix}^{\\rm T}\\) is extended infinitely long both sides, then all scaling of this vector will still be on this line . Fig 2.6: Vector-Scalar Multiplication; By Hongnan G.","title":"Negative Scaling"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#key-properties-vector-scalar-multiplication-is-invariant-under-rotation","text":"Vector-Scalar Multiplication Invariance Vector-scalar multiplication is conceptually and computationally simple, but do not underestimate its importance: Stretching a vector without rotating it is fundamental to many applications in linear algebra, including eigendecomposition. Sometimes, the simple things (in mathematics and in life) are the most powerful. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 36)","title":"Key Properties (Vector-Scalar Multiplication is Invariant under Rotation)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#vector-scalar-multiplication-is-commutative","text":"Info Similar to the commutative property in vector addition, vector-scalar multiplication is commutative as well. Therefore, the vector-scalar multiplication \\(\\lambda \\v = \\v \\lambda\\) .","title":"Vector-Scalar Multiplication is Commutative"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#norm-magnitude-of-a-vector","text":"","title":"Norm (Magnitude) of a Vector"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#definition-norm-of-a-vector","text":"Definition The length or the magnitude of a vector \\(\\v \\in \\R^n\\) with elements \\(v_1, v_2, \\cdots, v_n\\) is defined as: \\[\\|\\v\\| = \\sqrt{v_1^2 + v_2^2 + \\cdots + v_n^2}\\]","title":"Definition (Norm of a Vector)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/#exercise-pp-41-of-linear-algebra-theory-intuition-code-2021","text":"Create a 2D vector v, 10 scalars that are drawn at random from a normal (Gaussian) distribution, and plot all 10 scalar-vector multiplications on top of each other. What do you notice? You'll notice that all scaled versions of the vector form a line. import numpy as np import matplotlib.pyplot as plt # 2d col vector v = np . array ([ 1 , 2 ]) # plot it plt . plot ([ 0 , v [ 0 ]], [ 0 , v [ 1 ]]); import matplotlib.font_manager as font_manager from numpy.random import default_rng rng = default_rng () fig , ax = plt . subplots ( figsize = ( 9 , 9 )) # and then plot scaled versions on top legends = [] for i in range ( 100 ): # random scalar s = rng . standard_normal ( 1 )[ 0 ] # scaled vector sv = s * v plt . plot ([ 0 , sv [ 0 ]], [ 0 , sv [ 1 ]]) legends . append ( f \" { i + 1 } th vector\" ) font = font_manager . FontProperties ( family = \"Comic Sans MS\" , weight = \"bold\" , style = \"normal\" , size = 10 ) # only show first 10 legends! plt . legend ( legends [ 0 : 10 ], loc = \"upper left\" , prop = font ) plt . grid ( \"on\" ) plt . axis ( \"square\" ) plt . axis ([ - 6 , 6 , - 6 , 6 ]) plt . show (); What does it mean for a vector to remain invariant under coordinate transformation? \u21a9","title":"Exercise (pp. 41 of Linear Algebra: Theory, Intuition, Code, 2021.)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}}\\] Table of Contents Table of Contents Vector Multiplications Dot Product Algebraic Definition (Dot Product) Example of Dot Product Dot Product (Geometric definition) Scalar projections Sign of the DOT Product is determined by the Angle in between the two vectors Intuition Properties of Dot Product Application to the law of cosines Proof Cauchy-Schwarz Inequality Definition (Cauchy-Schwarz Inequality) Proof of Algebraic and Geometric Equivalence of DOT Product Learning Objectives Definition of a Vector Multiplications Vector Multiplications This section introduces one of the most important idea in Linear Algebra, the Dot Product . Since Wikipedia 1 has a wholesome introduction, we will be copying over some definitions from it. Dot Product Algebraic Definition (Dot Product) Definition The dot product of two vectors \\(\\color{red}{\\a = \\begin{bmatrix} a_1 \\; a_2 \\; \\dots \\; a_n \\end{bmatrix}^{\\rm T}}\\) and \\(\\color{blue}{\\b = \\begin{bmatrix} b_1 & b_2 & \\dots & b_n \\end{bmatrix}^{\\rm T}}\\) is defined as: \\[\\mathbf{\\color{red}\\a}\\cdot\\mathbf{\\color{blue}\\b}=\\sum_{i=1}^n {\\color{red}a}_i{\\color{blue}b}_i={\\color{red}a}_1{\\color{blue}b}_1+{\\color{red}a}_2{\\color{blue}b}_2+\\cdots+{\\color{red}a}_n{\\color{blue}b}_n\\] where \\(\\sum\\) denotes summation and \\(n\\) is the dimension of the vector space. Since vector spaces have not been introduced, we just think of it as the \\(\\R^n\\) dimensional space. Example of Dot Product Example For instance, in 3-dimensional space, the dot product of column vectors \\(\\begin{bmatrix}1 & 3 & -5\\end{bmatrix}^{\\rm T}\\) and \\(\\begin{bmatrix}4 & -2 & -2\\end{bmatrix}^{\\rm T}\\) \\[ \\begin{align} \\ [{\\color{red}1, 3, -5}] \\cdot [{\\color{blue}4, -2, -1}] &= ({\\color{red}1} \\times {\\color{blue}4}) + ({\\color{red}3}\\times{\\color{blue}-2}) + ({\\color{red}-5}\\times{\\color{blue}-1}) \\\\ &= 4 - 6 + 5 \\\\ &= 3 \\end{align} \\] Vector as Matrices We are a little ahead in terms of the definition of Matrices, but for people familiar with it, or have worked with numpy before, we know that we can interpret a row vector of dimension \\(n\\) as a matrix of dimension \\(1 \\times n\\) . Similarly, we can interpret a column vector of dimension \\(n\\) as a matrix of dimension \\(n \\times 1\\) . With this interpretation, we can perform a so called \"matrix multiplication\" of the row vector and column vector. The result is the dot product. We will go in details when we get to it. If vectors are treated like row matrices, the dot product can also be written as a matrix multiplication. \\[\\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} = \\mathbf{\\color{red}a}^\\mathsf T \\mathbf{\\color{blue}b}\\] Expressing the above example in this way, a 1 \u00d7 3 matrix row vector is multiplied by a 3 \u00d7 1 matrix column vector to get a 1 \u00d7 1 matrix that is identified with its unique entry: $$ \\begin{bmatrix} \\color{red}1 & \\color{red}3 & \\color{red}-5 \\end{bmatrix} \\begin{bmatrix} \\color{blue}4 \\ \\color{blue}-2 \\ \\color{blue}-1 \\end{bmatrix} = \\color{purple}3 $$ Dot Product (Geometric definition) Definition In Euclidean space , a Euclidean vector is a geometric object that possesses both a magnitude and a direction. A vector can be pictured as an arrow. Its magnitude is its length, and its direction is the direction to which the arrow points. The magnitude of a vector a is denoted by \\(\\left\\| \\mathbf{a} \\right\\|\\) . The dot product of two Euclidean vectors a and b is defined by \\[\\mathbf{a}\\cdot\\mathbf{b}=\\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta ,\\] where \\(\\theta\\) is the angle between \\(\\a\\) and \\(\\b\\) . Fig 3.11: Diagram of Scalar Projection and Dot Product; By Hongnan G. Scalar projections TODO: To motivate the geometric interpretation, we should see the example on scalar projections. Sign of the DOT Product is determined by the Angle in between the two vectors Refactor Geometric Formula The geometric definition can be re-written as follows: \\[\\begin{equation} \\label{eq1} \\begin{split} \\mathbf{a}\\cdot\\mathbf{b} &=\\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta \\implies \\cos(\\theta) = \\frac{\\a^\\top \\b}{\\|\\a\\| \\|\\b\\|} \\implies \\theta = \\cos^{-1}\\left(\\frac{\\a^\\top \\b}{\\|\\a\\| \\|\\b\\|}\\right) \\end{split} \\end{equation}\\] which essentially means that one can find the angle between two known vectors in any dimensional space. Mike X Cohen explains in Linear Algebra: Theory, Intuition, Code, 2021. (pp. 51-52) how the sign of the dot product is determined solely by the angle between the two vectors. By definition , \\(\\mathbf{a }\\cdot\\mathbf{b} = \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta\\) , we know that the sign (positive or negative) of the dot product \\(\\a \\cdot \\b\\) is solely determined by \\(\\cos \\theta\\) since \\(\\|\\a\\| \\|\\b\\|\\) is always positive. Case 1 ( \\(0< \\theta < 90\\) ): This implies that \\(\\cos \\theta > 0 \\implies \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta > 0 \\implies \\mathbf{a}\\cdot\\mathbf{b} > 0\\) . Case 2 ( \\(90 < \\theta < 180\\) ): This implies that \\(\\cos \\theta < 0 \\implies \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta < 0 \\implies \\mathbf{a}\\cdot\\mathbf{b} < 0\\) . Case 3 ( \\(\\theta = 90\\) ): This is an important property, for now, we just need to know that since \\(\\cos \\theta = 0\\) , then \\(\\a \\cdot \\b = \\0\\) . These two vectors are orthogonal. Case 4 ( \\(\\theta = 0\\) or \\(\\theta = 180\\) ): This implies that \\(\\cos \\theta = 1 \\implies \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta = \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\) . We say these two vectors are collinear. Consequence of Case 4 A simple consequence of case 4 is that if a vector \\(\\a\\) dot product with itself, then by case 4, we have \\(\\a \\cdot \\a = \\|\\a\\|^2 \\implies \\|\\a\\| = \\sqrt{\\a \\cdot \\a}\\) which is the formula of the Euclidean length of the vector. Fig 3.2: Sign of Dot Product and Angle between two vectors; By Hongnan G. Intuition https://flexbooks.ck12.org/cbook/ck-12-college-precalculus/section/9.6/primary/lesson/scalar-and-vector-projections-c-precalc/ https://www.quora.com/What-are-the-geometrical-meanings-of-a-dot-product-and-cross-product-of-a-vector https://math.stackexchange.com/questions/805954/what-does-the-dot-product-of-two-vectors-represent Properties of Dot Product Properties of Dot Product The dot product 2 fulfills the following properties if a , b , and c are real vectors and \\(\\lambda\\) is a scalar . Commutative : \\(\\mathbf{a} \\cdot \\mathbf{b} = \\mathbf{b} \\cdot \\mathbf{a} ,\\) which follows from the definition ( \u03b8 is the angle between a and b ): \\(\\mathbf{a} \\cdot \\mathbf{b} = \\left\\| \\mathbf{a} \\right\\| \\left\\| \\mathbf{b} \\right\\| \\cos \\theta = \\left\\| \\mathbf{b} \\right\\| \\left\\| \\mathbf{a} \\right\\| \\cos \\theta = \\mathbf{b} \\cdot \\mathbf{a} .\\) Distributive over vector addition: \\(\\mathbf{a} \\cdot (\\mathbf{b} + \\mathbf{c}) = \\mathbf{a} \\cdot \\mathbf{b} + \\mathbf{a} \\cdot \\mathbf{c} .\\) Bilinear : \\(\\mathbf{a} \\cdot ( \\lambda \\mathbf{b} + \\mathbf{c} ) = \\lambda ( \\mathbf{a} \\cdot \\mathbf{b} ) + ( \\mathbf{a} \\cdot \\mathbf{c} ) .\\) Scalar multiplication : \\(( \\lambda_1 \\mathbf{a} ) \\cdot ( \\lambda_2 \\mathbf{b} ) = \\lambda_1 \\lambda_2 ( \\mathbf{a} \\cdot \\mathbf{b} ) .\\) Not associative : This is because the dot product between a scalar ( a \u22c5 b ) and a vector ( c ) is not defined, which means that the expressions involved in the associative property, ( a \u22c5 b ) \u22c5 c or a \u22c5 ( b \u22c5 c ) are both ill-defined. Note however that the previously mentioned scalar multiplication property is sometimes called the \"associative law for scalar and dot product\" or one can say that \"the dot product is associative with respect to scalar multiplication\" because \\(\\lambda (\\a \\cdot \\b) = (\\lambda \\a) \\cdot \\b = \\a \\cdot (\\lambda \\b)\\) . Orthogonal : Two non-zero vectors a and b are orthogonal if and only if \\(\\a \\cdot \\b = \\0\\) . No cancellation : Unlike multiplication of ordinary numbers, where if \\(ab=ac\\) then b always equals c unless a is zero, the dot product does not obey the cancellation law . Product Rule : If a and b are (vector-valued) differentiable functions , then the derivative, denoted by a prime ' of \\(\\a \\cdot \\b\\) is given by the rule \\((\\a \\cdot \\b)' = \\a' \\cdot \\b + \\a \\cdot \\b'\\) . Application to the law of cosines A triangle with lines a, b and c is presented in figure 3.31, a and b are separated by angle \u03b8 , then the law of cosine states that \\[\\Vert c \\Vert^2 = \\Vert a \\Vert^2 + \\Vert b \\Vert^2 - 2ab\\cos(\\theta)\\] Proof The proof is from Wikipedia[^law_of_cosine_vector_proof]. Denote \\[\\overrightarrow{CB}=\\vec{a}, \\ \\overrightarrow{CA}=\\vec{b}, \\ \\overrightarrow{AB}=\\vec{c}\\] Therefore, \\[\\vec{c} = \\vec{a}-\\vec{b}\\] Taking the dot product of each side with itself: \\[\\vec{c}\\cdot\\vec{c} = (\\vec{a}-\\vec{b})\\cdot(\\vec{a}-\\vec{b})$$ $$\\Vert\\vec{c}\\Vert^2 = \\Vert\\vec{a}\\Vert^2 + \\Vert\\vec{b}\\Vert^2 - 2\\,\\vec{a}\\cdot\\vec{b}\\] Using the identity (see [[Dot product]]) \\[\\vec{u}\\cdot\\vec{v} = \\Vert\\vec{u}\\Vert\\,\\Vert\\vec{v}\\Vert \\cos\\angle(\\vec{u}, \\ \\vec{v})\\] leads to \\[\\Vert\\vec{c}\\Vert^2 = \\Vert\\vec{a}\\Vert^2 + {\\Vert\\vec{b}\\Vert}^2 - 2\\,\\Vert\\vec{a}\\Vert\\!\\;\\Vert\\vec{b}\\Vert \\cos\\angle(\\vec{a}, \\ \\vec{b})\\] The result follows. In short, the proof is presented below: \\[\\begin{align} \\mathbf{\\color{orange}c} \\cdot \\mathbf{\\color{orange}c} & = ( \\mathbf{\\color{red}a} - \\mathbf{\\color{blue}b}) \\cdot ( \\mathbf{\\color{red}a} - \\mathbf{\\color{blue}b} ) \\\\ & = \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{red}a} - \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} - \\mathbf{\\color{blue}b} \\cdot \\mathbf{\\color{red}a} + \\mathbf{\\color{blue}b} \\cdot \\mathbf{\\color{blue}b} \\\\ & = \\mathbf{\\color{red}a}^2 - \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} - \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} + \\mathbf{\\color{blue}b}^2 \\\\ & = \\mathbf{\\color{red}a}^2 - 2 \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} + \\mathbf{\\color{blue}b}^2 \\\\ \\mathbf{\\color{orange}c}^2 & = \\mathbf{\\color{red}a}^2 + \\mathbf{\\color{blue}b}^2 - 2 \\mathbf{\\color{red}a} \\mathbf{\\color{blue}b} \\cos \\mathbf{\\color{purple}\\theta} \\\\ \\end{align}\\] which is the law of cosines . Fig 3.31; Law of Cosine; Cauchy-Schwarz Inequality Definition (Cauchy-Schwarz Inequality) Definition Let two vectors \\(\\v\\) and \\(\\w\\) be in a field \\(\\F^n\\) , then the inequality \\[|\\v^\\top \\w| \\leq \\Vert \\v \\Vert \\Vert \\w \\Vert\\] holds. This inequality provides an upper bound for the dot product between two vectors; in other words, the absolute value of the dot product between two vectors cannot be larger than the product of the norms of the individual vectors. Note that the inequality can become an equality if and only if both vectors are the zero vector \\(\\0\\) or if one vector (either one) is scaled by the other vector \\(\\v = \\lambda \\w\\) . - Mike X Cohen, Linear Algebra: Theory, Intuition, Code If you wonder why when \\(\\v = \\lambda \\w\\) implies equality, it is apparent if you do a substitution as such \\[|\\v^\\top \\w| = |\\lambda \\w^\\top \\w| = \\lambda |\\w^\\top \\w| = \\lambda \\|\\w\\|^2 = \\lambda \\|\\w\\| \\|\\w\\| = \\|\\v\\| \\|\\w\\|\\] where we used the fact that \\(\\w^\\top \\w = \\|\\w\\|^2\\) by definition. The author decided to include this inequality here because this theorem is always used in many proofs. He then shows a use case in the Geometric Interpretation of the Dot Product. Proof of Algebraic and Geometric Equivalence of DOT Product Read here and also page 54-56 of Mike's book. https://en.wikipedia.org/wiki/Dot_product \u21a9 https://en.wikipedia.org/wiki/Dot_product \u21a9","title":"Dot Product"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#table-of-contents","text":"Table of Contents Vector Multiplications Dot Product Algebraic Definition (Dot Product) Example of Dot Product Dot Product (Geometric definition) Scalar projections Sign of the DOT Product is determined by the Angle in between the two vectors Intuition Properties of Dot Product Application to the law of cosines Proof Cauchy-Schwarz Inequality Definition (Cauchy-Schwarz Inequality) Proof of Algebraic and Geometric Equivalence of DOT Product Learning Objectives Definition of a Vector Multiplications","title":"Table of Contents"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#vector-multiplications","text":"This section introduces one of the most important idea in Linear Algebra, the Dot Product . Since Wikipedia 1 has a wholesome introduction, we will be copying over some definitions from it.","title":"Vector Multiplications"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#dot-product","text":"","title":"Dot Product"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#algebraic-definition-dot-product","text":"Definition The dot product of two vectors \\(\\color{red}{\\a = \\begin{bmatrix} a_1 \\; a_2 \\; \\dots \\; a_n \\end{bmatrix}^{\\rm T}}\\) and \\(\\color{blue}{\\b = \\begin{bmatrix} b_1 & b_2 & \\dots & b_n \\end{bmatrix}^{\\rm T}}\\) is defined as: \\[\\mathbf{\\color{red}\\a}\\cdot\\mathbf{\\color{blue}\\b}=\\sum_{i=1}^n {\\color{red}a}_i{\\color{blue}b}_i={\\color{red}a}_1{\\color{blue}b}_1+{\\color{red}a}_2{\\color{blue}b}_2+\\cdots+{\\color{red}a}_n{\\color{blue}b}_n\\] where \\(\\sum\\) denotes summation and \\(n\\) is the dimension of the vector space. Since vector spaces have not been introduced, we just think of it as the \\(\\R^n\\) dimensional space.","title":"Algebraic Definition (Dot Product)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#example-of-dot-product","text":"Example For instance, in 3-dimensional space, the dot product of column vectors \\(\\begin{bmatrix}1 & 3 & -5\\end{bmatrix}^{\\rm T}\\) and \\(\\begin{bmatrix}4 & -2 & -2\\end{bmatrix}^{\\rm T}\\) \\[ \\begin{align} \\ [{\\color{red}1, 3, -5}] \\cdot [{\\color{blue}4, -2, -1}] &= ({\\color{red}1} \\times {\\color{blue}4}) + ({\\color{red}3}\\times{\\color{blue}-2}) + ({\\color{red}-5}\\times{\\color{blue}-1}) \\\\ &= 4 - 6 + 5 \\\\ &= 3 \\end{align} \\] Vector as Matrices We are a little ahead in terms of the definition of Matrices, but for people familiar with it, or have worked with numpy before, we know that we can interpret a row vector of dimension \\(n\\) as a matrix of dimension \\(1 \\times n\\) . Similarly, we can interpret a column vector of dimension \\(n\\) as a matrix of dimension \\(n \\times 1\\) . With this interpretation, we can perform a so called \"matrix multiplication\" of the row vector and column vector. The result is the dot product. We will go in details when we get to it. If vectors are treated like row matrices, the dot product can also be written as a matrix multiplication. \\[\\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} = \\mathbf{\\color{red}a}^\\mathsf T \\mathbf{\\color{blue}b}\\] Expressing the above example in this way, a 1 \u00d7 3 matrix row vector is multiplied by a 3 \u00d7 1 matrix column vector to get a 1 \u00d7 1 matrix that is identified with its unique entry: $$ \\begin{bmatrix} \\color{red}1 & \\color{red}3 & \\color{red}-5 \\end{bmatrix} \\begin{bmatrix} \\color{blue}4 \\ \\color{blue}-2 \\ \\color{blue}-1 \\end{bmatrix} = \\color{purple}3 $$","title":"Example of Dot Product"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#dot-product-geometric-definition","text":"Definition In Euclidean space , a Euclidean vector is a geometric object that possesses both a magnitude and a direction. A vector can be pictured as an arrow. Its magnitude is its length, and its direction is the direction to which the arrow points. The magnitude of a vector a is denoted by \\(\\left\\| \\mathbf{a} \\right\\|\\) . The dot product of two Euclidean vectors a and b is defined by \\[\\mathbf{a}\\cdot\\mathbf{b}=\\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta ,\\] where \\(\\theta\\) is the angle between \\(\\a\\) and \\(\\b\\) . Fig 3.11: Diagram of Scalar Projection and Dot Product; By Hongnan G.","title":"Dot Product (Geometric definition)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#scalar-projections","text":"TODO: To motivate the geometric interpretation, we should see the example on scalar projections.","title":"Scalar projections"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#sign-of-the-dot-product-is-determined-by-the-angle-in-between-the-two-vectors","text":"Refactor Geometric Formula The geometric definition can be re-written as follows: \\[\\begin{equation} \\label{eq1} \\begin{split} \\mathbf{a}\\cdot\\mathbf{b} &=\\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta \\implies \\cos(\\theta) = \\frac{\\a^\\top \\b}{\\|\\a\\| \\|\\b\\|} \\implies \\theta = \\cos^{-1}\\left(\\frac{\\a^\\top \\b}{\\|\\a\\| \\|\\b\\|}\\right) \\end{split} \\end{equation}\\] which essentially means that one can find the angle between two known vectors in any dimensional space. Mike X Cohen explains in Linear Algebra: Theory, Intuition, Code, 2021. (pp. 51-52) how the sign of the dot product is determined solely by the angle between the two vectors. By definition , \\(\\mathbf{a }\\cdot\\mathbf{b} = \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta\\) , we know that the sign (positive or negative) of the dot product \\(\\a \\cdot \\b\\) is solely determined by \\(\\cos \\theta\\) since \\(\\|\\a\\| \\|\\b\\|\\) is always positive. Case 1 ( \\(0< \\theta < 90\\) ): This implies that \\(\\cos \\theta > 0 \\implies \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta > 0 \\implies \\mathbf{a}\\cdot\\mathbf{b} > 0\\) . Case 2 ( \\(90 < \\theta < 180\\) ): This implies that \\(\\cos \\theta < 0 \\implies \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta < 0 \\implies \\mathbf{a}\\cdot\\mathbf{b} < 0\\) . Case 3 ( \\(\\theta = 90\\) ): This is an important property, for now, we just need to know that since \\(\\cos \\theta = 0\\) , then \\(\\a \\cdot \\b = \\0\\) . These two vectors are orthogonal. Case 4 ( \\(\\theta = 0\\) or \\(\\theta = 180\\) ): This implies that \\(\\cos \\theta = 1 \\implies \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta = \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\) . We say these two vectors are collinear. Consequence of Case 4 A simple consequence of case 4 is that if a vector \\(\\a\\) dot product with itself, then by case 4, we have \\(\\a \\cdot \\a = \\|\\a\\|^2 \\implies \\|\\a\\| = \\sqrt{\\a \\cdot \\a}\\) which is the formula of the Euclidean length of the vector. Fig 3.2: Sign of Dot Product and Angle between two vectors; By Hongnan G.","title":"Sign of the DOT Product is determined by the Angle in between the two vectors"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#intuition","text":"https://flexbooks.ck12.org/cbook/ck-12-college-precalculus/section/9.6/primary/lesson/scalar-and-vector-projections-c-precalc/ https://www.quora.com/What-are-the-geometrical-meanings-of-a-dot-product-and-cross-product-of-a-vector https://math.stackexchange.com/questions/805954/what-does-the-dot-product-of-two-vectors-represent","title":"Intuition"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#properties-of-dot-product","text":"Properties of Dot Product The dot product 2 fulfills the following properties if a , b , and c are real vectors and \\(\\lambda\\) is a scalar . Commutative : \\(\\mathbf{a} \\cdot \\mathbf{b} = \\mathbf{b} \\cdot \\mathbf{a} ,\\) which follows from the definition ( \u03b8 is the angle between a and b ): \\(\\mathbf{a} \\cdot \\mathbf{b} = \\left\\| \\mathbf{a} \\right\\| \\left\\| \\mathbf{b} \\right\\| \\cos \\theta = \\left\\| \\mathbf{b} \\right\\| \\left\\| \\mathbf{a} \\right\\| \\cos \\theta = \\mathbf{b} \\cdot \\mathbf{a} .\\) Distributive over vector addition: \\(\\mathbf{a} \\cdot (\\mathbf{b} + \\mathbf{c}) = \\mathbf{a} \\cdot \\mathbf{b} + \\mathbf{a} \\cdot \\mathbf{c} .\\) Bilinear : \\(\\mathbf{a} \\cdot ( \\lambda \\mathbf{b} + \\mathbf{c} ) = \\lambda ( \\mathbf{a} \\cdot \\mathbf{b} ) + ( \\mathbf{a} \\cdot \\mathbf{c} ) .\\) Scalar multiplication : \\(( \\lambda_1 \\mathbf{a} ) \\cdot ( \\lambda_2 \\mathbf{b} ) = \\lambda_1 \\lambda_2 ( \\mathbf{a} \\cdot \\mathbf{b} ) .\\) Not associative : This is because the dot product between a scalar ( a \u22c5 b ) and a vector ( c ) is not defined, which means that the expressions involved in the associative property, ( a \u22c5 b ) \u22c5 c or a \u22c5 ( b \u22c5 c ) are both ill-defined. Note however that the previously mentioned scalar multiplication property is sometimes called the \"associative law for scalar and dot product\" or one can say that \"the dot product is associative with respect to scalar multiplication\" because \\(\\lambda (\\a \\cdot \\b) = (\\lambda \\a) \\cdot \\b = \\a \\cdot (\\lambda \\b)\\) . Orthogonal : Two non-zero vectors a and b are orthogonal if and only if \\(\\a \\cdot \\b = \\0\\) . No cancellation : Unlike multiplication of ordinary numbers, where if \\(ab=ac\\) then b always equals c unless a is zero, the dot product does not obey the cancellation law . Product Rule : If a and b are (vector-valued) differentiable functions , then the derivative, denoted by a prime ' of \\(\\a \\cdot \\b\\) is given by the rule \\((\\a \\cdot \\b)' = \\a' \\cdot \\b + \\a \\cdot \\b'\\) .","title":"Properties of Dot Product"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#application-to-the-law-of-cosines","text":"A triangle with lines a, b and c is presented in figure 3.31, a and b are separated by angle \u03b8 , then the law of cosine states that \\[\\Vert c \\Vert^2 = \\Vert a \\Vert^2 + \\Vert b \\Vert^2 - 2ab\\cos(\\theta)\\]","title":"Application to the law of cosines"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#proof","text":"The proof is from Wikipedia[^law_of_cosine_vector_proof]. Denote \\[\\overrightarrow{CB}=\\vec{a}, \\ \\overrightarrow{CA}=\\vec{b}, \\ \\overrightarrow{AB}=\\vec{c}\\] Therefore, \\[\\vec{c} = \\vec{a}-\\vec{b}\\] Taking the dot product of each side with itself: \\[\\vec{c}\\cdot\\vec{c} = (\\vec{a}-\\vec{b})\\cdot(\\vec{a}-\\vec{b})$$ $$\\Vert\\vec{c}\\Vert^2 = \\Vert\\vec{a}\\Vert^2 + \\Vert\\vec{b}\\Vert^2 - 2\\,\\vec{a}\\cdot\\vec{b}\\] Using the identity (see [[Dot product]]) \\[\\vec{u}\\cdot\\vec{v} = \\Vert\\vec{u}\\Vert\\,\\Vert\\vec{v}\\Vert \\cos\\angle(\\vec{u}, \\ \\vec{v})\\] leads to \\[\\Vert\\vec{c}\\Vert^2 = \\Vert\\vec{a}\\Vert^2 + {\\Vert\\vec{b}\\Vert}^2 - 2\\,\\Vert\\vec{a}\\Vert\\!\\;\\Vert\\vec{b}\\Vert \\cos\\angle(\\vec{a}, \\ \\vec{b})\\] The result follows. In short, the proof is presented below: \\[\\begin{align} \\mathbf{\\color{orange}c} \\cdot \\mathbf{\\color{orange}c} & = ( \\mathbf{\\color{red}a} - \\mathbf{\\color{blue}b}) \\cdot ( \\mathbf{\\color{red}a} - \\mathbf{\\color{blue}b} ) \\\\ & = \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{red}a} - \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} - \\mathbf{\\color{blue}b} \\cdot \\mathbf{\\color{red}a} + \\mathbf{\\color{blue}b} \\cdot \\mathbf{\\color{blue}b} \\\\ & = \\mathbf{\\color{red}a}^2 - \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} - \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} + \\mathbf{\\color{blue}b}^2 \\\\ & = \\mathbf{\\color{red}a}^2 - 2 \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} + \\mathbf{\\color{blue}b}^2 \\\\ \\mathbf{\\color{orange}c}^2 & = \\mathbf{\\color{red}a}^2 + \\mathbf{\\color{blue}b}^2 - 2 \\mathbf{\\color{red}a} \\mathbf{\\color{blue}b} \\cos \\mathbf{\\color{purple}\\theta} \\\\ \\end{align}\\] which is the law of cosines . Fig 3.31; Law of Cosine;","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#cauchy-schwarz-inequality","text":"","title":"Cauchy-Schwarz Inequality"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#definition-cauchy-schwarz-inequality","text":"Definition Let two vectors \\(\\v\\) and \\(\\w\\) be in a field \\(\\F^n\\) , then the inequality \\[|\\v^\\top \\w| \\leq \\Vert \\v \\Vert \\Vert \\w \\Vert\\] holds. This inequality provides an upper bound for the dot product between two vectors; in other words, the absolute value of the dot product between two vectors cannot be larger than the product of the norms of the individual vectors. Note that the inequality can become an equality if and only if both vectors are the zero vector \\(\\0\\) or if one vector (either one) is scaled by the other vector \\(\\v = \\lambda \\w\\) . - Mike X Cohen, Linear Algebra: Theory, Intuition, Code If you wonder why when \\(\\v = \\lambda \\w\\) implies equality, it is apparent if you do a substitution as such \\[|\\v^\\top \\w| = |\\lambda \\w^\\top \\w| = \\lambda |\\w^\\top \\w| = \\lambda \\|\\w\\|^2 = \\lambda \\|\\w\\| \\|\\w\\| = \\|\\v\\| \\|\\w\\|\\] where we used the fact that \\(\\w^\\top \\w = \\|\\w\\|^2\\) by definition. The author decided to include this inequality here because this theorem is always used in many proofs. He then shows a use case in the Geometric Interpretation of the Dot Product.","title":"Definition (Cauchy-Schwarz Inequality)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/#proof-of-algebraic-and-geometric-equivalence-of-dot-product","text":"Read here and also page 54-56 of Mike's book. https://en.wikipedia.org/wiki/Dot_product \u21a9 https://en.wikipedia.org/wiki/Dot_product \u21a9","title":"Proof of Algebraic and Geometric Equivalence of DOT Product"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_exercises/","text":"Table of Contents Exercise 1: Linear Combination Exercise 2: Dot Product and Average Exercise 3: Dot Product and Weighted Average Exercise 1: Linear Combination Given a set of weights and vectors, write a python function that outputs the linear combination of the vectors with the respective weights. The code to the solution is presented below, it is important to realize that the number of elements in the weights vector should be the same as the number of vectors. import numpy as np from typing import List , Union # as col vector v1 = np . asarray ([ 1 , 2 , 3 , 4 , 5 ]) . reshape ( - 1 , 1 ) v2 = np . asarray ([ 2 , 4 , 6 , 8 , 10 ]) . reshape ( - 1 , 1 ) v3 = np . asarray ([ 3 , 6 , 9 , 12 , 15 ]) . reshape ( - 1 , 1 ) weights = [ 10 , 20 , 30 ] def linear_combination_vectors ( weights : List [ float ], * args : np . ndarray ) -> np . ndarray : \"\"\"Computes the linear combination of vectors. Args: weights (List[float]): The set of weights corresponding to each vector. *args (np.ndarray): The set of vectors. Returns: linear_weighted_sum (np.ndarray): The linear combination of vectors. Examples: >>> v1 = np.asarray([1, 2, 3, 4, 5]).reshape(-1, 1) >>> v2 = np.asarray([2, 4, 6, 8, 10]).reshape(-1, 1) >>> v3 = np.asarray([3, 6, 9, 12, 15]).reshape(-1, 1) >>> weights = [10, 20, 30] >>> linear_combination_vectors([10, 20, 30], v1, v2, v3) \"\"\" linear_weighted_sum = np . zeros ( shape = args [ 0 ] . shape ) for weight , vec in zip ( weights , args ): linear_weighted_sum += weight * vec return linear_weighted_sum linear_combination_vectors ( weights , v1 , v2 , v3 ) array([[140.], [280.], [420.], [560.], [700.]]) Exercise 2: Dot Product and Average Develop a method to use the dot product to compute the average of a set of numbers in a vector. Since we want to compute the average of all elements in a vector \\(\\v \\in \\R^n\\) , we can first see the formula of average to be: \\( \\(\\bar{\\v} = \\frac{v_1 + v_2 + ... + v_n}{n}\\) \\) To make use of dot product, we can define \\(\\1\\) and perform \\(\\v^\\top \\cdot \\1\\) which returns the sum of all elements in \\(\\v\\) by the definition of dot product. Lastly, divide this answer by the total number of elements. def dot_product ( v1 : np . ndarray , v2 : np . ndarray ) -> float : \"\"\"Computes the dot product of two vectors. We assume both vectors are flattened, i.e. they are 1D arrays. Args: v1 (np.ndarray): The first vector. v2 (np.ndarray): The second vector. Returns: dot_product_v1_v2 (float): The dot product of two vectors. Examples: >>> v1 = np.asarray([1, 2, 3, 4, 5]) >>> v2 = np.asarray([2, 4, 6, 8, 10]) >>> dot_product(v1, v2) \"\"\" v1 , v2 = np . asarray ( v1 ) . flatten (), np . asarray ( v2 ) . flatten () dot_product_v1_v2 = 0 for element_1 , element_2 in zip ( v1 , v2 ): dot_product_v1_v2 += element_1 * element_2 # same as np.dot but does not take into the orientation of vectors assert dot_product_v1_v2 == np . dot ( v1 . T , v2 ) return dot_product_v1_v2 def average_set ( vec : Union [ np . ndarray , set ]) -> float : \"\"\"Average a set of numbers using dot product. Given a set of numbers {v1, v2, ..., vn}, the average is defined as: avg = (v1 + v2 + ... + vn) / n To use the dot product, we can convert the set to a col/row vector (array) `vec` and perform the dot product with the vector of ones to get `sum(set)`. Lastly, we divide by the number of elements in the set. Args: vec (Union[np.ndarray, set]): A set of numbers. Returns: average (float): The average of the set. \"\"\" if isinstance ( vec , set ): vec = np . asarray ( list ( vec )) . flatten () ones = np . ones ( shape = vec . shape ) total_sum = dot_product ( vec , ones ) average = total_sum / vec . shape [ 0 ] return average # as col vector v = np . asarray ([ 1 , 2 , 3 , 4 , 5 ]) v_set = { 1 , 2 , 3 , 4 , 5 } average = average_set ( v_set ) print ( f \"average of all vectors in v_set is { average } \" ) assert average == np . mean ( v ) average of all vectors in v_set is 3.0 Exercise 3: Dot Product and Weighted Average What if some numbers were more important than other numbers? Modify your answer to the previous question to devise a method to use the dot product to compute a weighted mean of a set of numbers. We assume weighted mean to be normalized such that the weights of all the vectors must sum up to 1. # as col vector v1 = np . asarray ([ 1 , 2 , 3 , 4 , 5 ]) . reshape ( - 1 , 1 ) shape_v1 = v1 . shape num_elements = shape_v1 [ 0 ] random_weights = np . random . rand ( * shape_v1 ) normalized_random_weights = random_weights / num_elements total_sum = dot_product ( v1 , normalized_random_weights ) weighted_average = total_sum / v1 . shape [ 0 ] print ( f \"weighted average is { weighted_average } \" ) weighted average is 0.4017198249010809","title":"Exercises"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_exercises/#table-of-contents","text":"Exercise 1: Linear Combination Exercise 2: Dot Product and Average Exercise 3: Dot Product and Weighted Average","title":"Table of Contents"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_exercises/#exercise-1-linear-combination","text":"Given a set of weights and vectors, write a python function that outputs the linear combination of the vectors with the respective weights. The code to the solution is presented below, it is important to realize that the number of elements in the weights vector should be the same as the number of vectors. import numpy as np from typing import List , Union # as col vector v1 = np . asarray ([ 1 , 2 , 3 , 4 , 5 ]) . reshape ( - 1 , 1 ) v2 = np . asarray ([ 2 , 4 , 6 , 8 , 10 ]) . reshape ( - 1 , 1 ) v3 = np . asarray ([ 3 , 6 , 9 , 12 , 15 ]) . reshape ( - 1 , 1 ) weights = [ 10 , 20 , 30 ] def linear_combination_vectors ( weights : List [ float ], * args : np . ndarray ) -> np . ndarray : \"\"\"Computes the linear combination of vectors. Args: weights (List[float]): The set of weights corresponding to each vector. *args (np.ndarray): The set of vectors. Returns: linear_weighted_sum (np.ndarray): The linear combination of vectors. Examples: >>> v1 = np.asarray([1, 2, 3, 4, 5]).reshape(-1, 1) >>> v2 = np.asarray([2, 4, 6, 8, 10]).reshape(-1, 1) >>> v3 = np.asarray([3, 6, 9, 12, 15]).reshape(-1, 1) >>> weights = [10, 20, 30] >>> linear_combination_vectors([10, 20, 30], v1, v2, v3) \"\"\" linear_weighted_sum = np . zeros ( shape = args [ 0 ] . shape ) for weight , vec in zip ( weights , args ): linear_weighted_sum += weight * vec return linear_weighted_sum linear_combination_vectors ( weights , v1 , v2 , v3 ) array([[140.], [280.], [420.], [560.], [700.]])","title":"Exercise 1: Linear Combination"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_exercises/#exercise-2-dot-product-and-average","text":"Develop a method to use the dot product to compute the average of a set of numbers in a vector. Since we want to compute the average of all elements in a vector \\(\\v \\in \\R^n\\) , we can first see the formula of average to be: \\( \\(\\bar{\\v} = \\frac{v_1 + v_2 + ... + v_n}{n}\\) \\) To make use of dot product, we can define \\(\\1\\) and perform \\(\\v^\\top \\cdot \\1\\) which returns the sum of all elements in \\(\\v\\) by the definition of dot product. Lastly, divide this answer by the total number of elements. def dot_product ( v1 : np . ndarray , v2 : np . ndarray ) -> float : \"\"\"Computes the dot product of two vectors. We assume both vectors are flattened, i.e. they are 1D arrays. Args: v1 (np.ndarray): The first vector. v2 (np.ndarray): The second vector. Returns: dot_product_v1_v2 (float): The dot product of two vectors. Examples: >>> v1 = np.asarray([1, 2, 3, 4, 5]) >>> v2 = np.asarray([2, 4, 6, 8, 10]) >>> dot_product(v1, v2) \"\"\" v1 , v2 = np . asarray ( v1 ) . flatten (), np . asarray ( v2 ) . flatten () dot_product_v1_v2 = 0 for element_1 , element_2 in zip ( v1 , v2 ): dot_product_v1_v2 += element_1 * element_2 # same as np.dot but does not take into the orientation of vectors assert dot_product_v1_v2 == np . dot ( v1 . T , v2 ) return dot_product_v1_v2 def average_set ( vec : Union [ np . ndarray , set ]) -> float : \"\"\"Average a set of numbers using dot product. Given a set of numbers {v1, v2, ..., vn}, the average is defined as: avg = (v1 + v2 + ... + vn) / n To use the dot product, we can convert the set to a col/row vector (array) `vec` and perform the dot product with the vector of ones to get `sum(set)`. Lastly, we divide by the number of elements in the set. Args: vec (Union[np.ndarray, set]): A set of numbers. Returns: average (float): The average of the set. \"\"\" if isinstance ( vec , set ): vec = np . asarray ( list ( vec )) . flatten () ones = np . ones ( shape = vec . shape ) total_sum = dot_product ( vec , ones ) average = total_sum / vec . shape [ 0 ] return average # as col vector v = np . asarray ([ 1 , 2 , 3 , 4 , 5 ]) v_set = { 1 , 2 , 3 , 4 , 5 } average = average_set ( v_set ) print ( f \"average of all vectors in v_set is { average } \" ) assert average == np . mean ( v ) average of all vectors in v_set is 3.0","title":"Exercise 2: Dot Product and Average"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_exercises/#exercise-3-dot-product-and-weighted-average","text":"What if some numbers were more important than other numbers? Modify your answer to the previous question to devise a method to use the dot product to compute a weighted mean of a set of numbers. We assume weighted mean to be normalized such that the weights of all the vectors must sum up to 1. # as col vector v1 = np . asarray ([ 1 , 2 , 3 , 4 , 5 ]) . reshape ( - 1 , 1 ) shape_v1 = v1 . shape num_elements = shape_v1 [ 0 ] random_weights = np . random . rand ( * shape_v1 ) normalized_random_weights = random_weights / num_elements total_sum = dot_product ( v1 , normalized_random_weights ) weighted_average = total_sum / v1 . shape [ 0 ] print ( f \"weighted average is { weighted_average } \" ) weighted average is 0.4017198249010809","title":"Exercise 3: Dot Product and Weighted Average"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_linear_combination/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\p}{\\mathbf{p}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\E}{\\mathbf{E}} \\newcommand{\\P}{\\mathbf{P}}\\] DO MY OWN EXAMPLES, AND USE EXAMPLES FROM WIKI EASIER ADD THE LINEAR COMB PYTHON CODE BACK TO HERE INSTEAD OF DOT PROD The below work are from https://github.com/MacroAnalyst/Linear_Algebra_With_Python. Algebraic Definition (Linear Combination) Definition extracted from Wikipedia 1 . Let \\(V\\) be a vector space over the field \\(\\F\\) . As usual, we call elements of \\(V\\) vectors and call elements of \\(\\F\\) scalars. If \\(\\v_1, ... , \\v_n\\) are vectors and \\(a_1, ..., a_n\\) are scalars, then the linear combination of those vectors with those scalars as coefficients is \\[ a_1\\v_1 + a_2\\v_2 + ... + a_n\\v_n \\] Note that by definition, a linear combination involves only finitely many vectors (except as described in Generalizations below). However, the set S that the vectors are taken from (if one is mentioned) can still be infinite; each individual linear combination will only involve finitely many vectors. Also, there is no reason that n cannot be zero; in that case, we declare by convention that the result of the linear combination is the zero vector in \\(V\\) . import matplotlib.pyplot as plt import numpy as np from mpl_toolkits.mplot3d import Axes3D import sympy as sy sy . init_printing () Visualization of Linear Combination in \\(\\mathbb{R}^2\\) Consider two vectors \\(u\\) and \\(v\\) in \\(\\mathbb{R}^2\\) , they are independent of each other, i.e. not pointing to the same or opposite direction. Therefore any vector in the \\(\\mathbb{R}^2\\) can be represented by a linear combination of \\(u\\) and \\(v\\) . For instance, this is a linear combination and essentially a linear system. \\[ c_1 \\left[ \\begin{matrix} 4\\\\ 2 \\end{matrix} \\right]+ c_2 \\left[ \\begin{matrix} -2\\\\ 2 \\end{matrix} \\right] = \\left[ \\begin{matrix} 2\\\\ 10 \\end{matrix} \\right] \\] Solve the system in SymPy: A = sy . Matrix ([[ 4 , - 2 , 2 ], [ 2 , 2 , 10 ]]) A . rref () \\(\\displaystyle \\left( \\left[\\begin{matrix}1 & 0 & 2\\\\0 & 1 & 3\\end{matrix}\\right], \\ \\left( 0, \\ 1\\right)\\right)\\) The solution is \\((c_1, c_2)^T = (2, 3)^T\\) , which means the addition of \\(2\\) times of \\(\\left[ \\begin{matrix} 4\\\\ 2 \\end{matrix} \\right]\\) and \\(3\\) times of \\(\\left[ \\begin{matrix} -2\\\\ 2 \\end{matrix} \\right]\\) equals \\(\\left[ \\begin{matrix} 2\\\\ 10 \\end{matrix} \\right]\\) . Besides plotting the vector addition, we would like to plot the coordinates of basis that spanned by \\(u\\) and \\(v\\) . We will explain further in later chapter. Calculate the slope of vectors, i.e. \\(\\frac{y}{x}\\) $$ s_1 =\\frac{y}{x} = \\frac{2}{4}=.5\\ s_2 =\\frac{y}{x}= \\frac{2}{-2}=.-1 $$ The basis can be constructed as: $$ y_1 = a+.5x\\ y_2 = b-x $$ where \\(a\\) and \\(b\\) will be set as constants with regular intervals, such as \\((2.5, 5, 7.5, 10)\\) . The coordinates of basis are pink web-style grids, each line segment is a unit (like \\(1\\) in Cartesian coordinate system) in the 'new' coordinates. fig , ax = plt . subplots ( figsize = ( 8 , 8 )) vec = np . array ([[[ 0 , 0 , 4 , 2 ]], [[ 0 , 0 , - 2 , 2 ]], [[ 0 , 0 , 2 , 10 ]], [[ 0 , 0 , 8 , 4 ]], [[ 0 , 0 , - 6 , 6 ]]]) colors = [ 'b' , 'b' , 'r' , 'b' , 'b' ] for i in range ( vec . shape [ 0 ]): X , Y , U , V = zip ( * vec [ i ,:,:]) ax . quiver ( X , Y , U , V , angles = 'xy' , scale_units = 'xy' , color = colors [ i ], scale = 1 , alpha = .6 ) ax . text ( x = vec [ i , 0 , 2 ], y = vec [ i , 0 , 3 ], s = '( %.0d , %.0d )' % ( vec [ i , 0 , 2 ], vec [ i , 0 , 3 ]), fontsize = 16 ) points12 = np . array ([[ 8 , 4 ],[ 2 , 10 ]]) ax . plot ( points12 [:, 0 ], points12 [:, 1 ], c = 'b' , lw = 3.5 , alpha = 0.5 , ls = '--' ) points34 = np . array ([[ - 6 , 6 ],[ 2 , 10 ]]) ax . plot ( points34 [:, 0 ], points34 [:, 1 ], c = 'b' , lw = 3.5 , alpha = 0.5 , ls = '--' ) ax . set_xlim ([ - 10 , 10 ]) ax . set_ylim ([ 0 , 10.5 ]) ax . set_xlabel ( 'x-axis' , fontsize = 16 ) ax . set_ylabel ( 'y-axis' , fontsize = 16 ) ax . grid () ######################################Basis######################################## a = np . arange ( - 11 , 20 , 1 ) x = np . arange ( - 11 , 20 , 1 ) for i in a : y1 = i + .5 * x ax . plot ( x , y1 , ls = '--' , color = 'pink' , lw = 2 ) y2 = i - x ax . plot ( x , y2 , ls = '--' , color = 'pink' , lw = 2 ) ax . set_title ( 'Linear Combination of Two Vectors in $\\mathbf {R} ^2$' , size = 22 , x = 0.5 , y = 1.01 ) plt . show () Linear Combination Visualization in 3D We can also show that any vectors in \\(\\mathbb{R}^3\\) can be a linear combination of a standard basis in Cartesian coordinate system. Here is the function for plotting 3D linear combination from standard basis, we just feed the scalar multiplier . def linearCombo ( a , b , c ): '''This function is for visualizing linear combination of standard basis in 3D. Function syntax: linearCombo(a, b, c), where a, b, c are the scalar multiplier, also the elements of the vector. ''' fig = plt . figure ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( 111 , projection = '3d' ) ######################## Standard basis and Scalar Multiplid Vectors######################### vec = np . array ([[[ 0 , 0 , 0 , 1 , 0 , 0 ]], # e1 [[ 0 , 0 , 0 , 0 , 1 , 0 ]], # e2 [[ 0 , 0 , 0 , 0 , 0 , 1 ]], # e3 [[ 0 , 0 , 0 , a , 0 , 0 ]], # a* e1 [[ 0 , 0 , 0 , 0 , b , 0 ]], # b* e2 [[ 0 , 0 , 0 , 0 , 0 , c ]], # c* e3 [[ 0 , 0 , 0 , a , b , c ]]]) # ae1 + be2 + ce3 colors = [ 'b' , 'b' , 'b' , 'r' , 'r' , 'r' , 'g' ] for i in range ( vec . shape [ 0 ]): X , Y , Z , U , V , W = zip ( * vec [ i ,:,:]) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = colors [ i ] , arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 , alpha = .6 ) #################################Plot Rectangle Boxes############################## dlines = np . array ([[[ a , 0 , 0 ],[ a , b , 0 ]], [[ 0 , b , 0 ],[ a , b , 0 ]], [[ 0 , 0 , c ],[ a , b , c ]], [[ 0 , 0 , c ],[ a , 0 , c ]], [[ a , 0 , c ],[ a , b , c ]], [[ 0 , 0 , c ],[ 0 , b , c ]], [[ 0 , b , c ],[ a , b , c ]], [[ a , 0 , 0 ],[ a , 0 , c ]], [[ 0 , b , 0 ],[ 0 , b , c ]], [[ a , b , 0 ],[ a , b , c ]]]) colors = [ 'k' , 'k' , 'g' , 'k' , 'k' , 'k' , 'k' , 'k' , 'k' ] for i in range ( dlines . shape [ 0 ]): ax . plot ( dlines [ i ,:, 0 ], dlines [ i ,:, 1 ], dlines [ i ,:, 2 ], lw = 3 , ls = '--' , color = 'black' , alpha = 0.5 ) #################################Annotation######################################## ax . text ( x = a , y = b , z = c , s = ' $(%0.d, %0.d, %.0d )$' % ( a , b , c ), size = 18 ) ax . text ( x = a , y = 0 , z = 0 , s = ' $%0.d e_1 = (%0.d, 0, 0)$' % ( a , a ), size = 15 ) ax . text ( x = 0 , y = b , z = 0 , s = ' $%0.d e_2 = (0, %0.d, 0)$' % ( b , b ), size = 15 ) ax . text ( x = 0 , y = 0 , z = c , s = ' $%0.d e_3 = (0, 0, %0.d)$' % ( c , c ), size = 15 ) #################################Axis Setting###################################### ax . grid () ax . set_xlim ([ 0 , a + 1 ]) ax . set_ylim ([ 0 , b + 1 ]) ax . set_zlim ([ 0 , c + 1 ]) ax . set_xlabel ( 'x-axis' , size = 18 ) ax . set_ylabel ( 'y-axis' , size = 18 ) ax . set_zlabel ( 'z-axis' , size = 18 ) ax . set_title ( 'Vector $(%0.d, %0.d, %.0d )$ Visualization' % ( a , b , c ), size = 20 ) ax . view_init ( elev = 20. , azim = 15 ) if __name__ == '__main__' : a = 7 b = 4 c = 9 linearCombo ( a , b , c ) linearCombo ( 3 , 5 , 6 ) # Try again Linear Combination of Inconsistent System Inconsistent system means no unique solution exists. It might sound weird to treat a solution of an inconsistent system as a linear combination, but it is essential a trace of line. One Free Variable Case We have seen how inconsistent systems can be solved in the earlier lectures. Now we will investigate what solution means from the perspective of linear combination. Consider a system \\[ \\left[ \\begin{matrix} 1 & 1 & 2\\\\ -2 &0 & 1\\\\ 1& 1 & 2 \\end{matrix} \\right] \\left[ \\begin{matrix} c_1\\\\c_2\\\\c_3 \\end{matrix} \\right] = \\left[ \\begin{matrix} 1\\\\-3\\\\1 \\end{matrix} \\right] \\] Solve in SymPy: A = sy . Matrix ([[ 1 , 1 , 2 , 1 ],[ - 2 , 0 , 1 , - 3 ],[ 1 , 1 , 2 , 1 ]]) A . rref () \\(\\displaystyle \\left( \\left[\\begin{matrix}1 & 0 & - \\frac{1}{2} & \\frac{3}{2}\\\\0 & 1 & \\frac{5}{2} & - \\frac{1}{2}\\\\0 & 0 & 0 & 0\\end{matrix}\\right], \\ \\left( 0, \\ 1\\right)\\right)\\) The solution is not unique due to a free variable: \\[ c_1 - \\frac{1}{2}c_3 =\\frac{3}{2}\\\\ c_2 + \\frac{5}{2}c_3 = -\\frac{1}{2}\\\\ c_3 = free \\] Let \\(c_3 = t\\) , the system can be parameterized: \\[ \\left[ \\begin{matrix} c_1\\\\c_2\\\\c_3 \\end{matrix} \\right] = \\left[ \\begin{matrix} \\frac{3}{2}+\\frac{1}{2}t\\\\ -\\frac{1}{2}-\\frac{5}{2}t\\\\ t \\end{matrix} \\right] \\] The solution is a line of infinite length, to visualize it, we set the range of \\(t\\in (-1, 1)\\) , the solution looks like: fig = plt . figure ( figsize = ( 8 , 8 )) ax = fig . add_subplot ( projection = '3d' ) t = np . linspace ( - 1 , 1 , 10 ) c1 = 3 / 2 + t / 2 c2 = - 1 / 2 - 5 / 2 * t ax . plot ( c1 , c2 , t , lw = 5 ) ax . set_xlabel ( 'x-axis' , size = 18 ) ax . set_ylabel ( 'y-axis' , size = 18 ) ax . set_zlabel ( 'z-axis' , size = 18 ) ax . set_title ( 'Solution of A Linear System with One Free Variable' , size = 18 ) plt . show () Two Free Variables Case Now consider the linear system: $$ \\left[ \\begin{matrix} 1 & -3 & -2\\ 0 &0 & 0 \\ 0& 0 & 0 \\end{matrix} \\right] \\left[ \\begin{matrix} x_1\\ x_2\\ x_3 \\end{matrix} \\right] = \\left[ \\begin{matrix} 0\\0\\0 \\end{matrix} \\right] $$ The augmented matrix is $$ \\left[ \\begin{matrix} 1 & -3 & -2 & 0\\ 0 &0 & 0 & 0\\ 0& 0 & 0 & 0 \\end{matrix} \\right] $$ We have two free variables $$ \\begin{align} x_1 &= 3x_2+2x_3\\ x_2 &= free\\ x_3 &= free \\end{align} $$ Rewrite the solution \\[ \\left[ \\begin{matrix} x_1\\\\ x_2\\\\ x_3 \\end{matrix} \\right] = \\left[ \\begin{matrix} 3x_2+2x_3\\\\ x_2\\\\ x_3 \\end{matrix} \\right] = \\left[\\begin{array}{c} 3 x_{2} \\\\ x_{2} \\\\ 0 \\end{array}\\right]+\\left[\\begin{array}{c} 2 x_{3} \\\\ 0 \\\\ x_{3} \\end{array}\\right]= x_{2}\\left[\\begin{array}{l} 3 \\\\ 1 \\\\ 0 \\end{array}\\right]+x_{3}\\left[\\begin{array}{l} 2 \\\\ 0 \\\\ 1 \\end{array}\\right] \\] The solution is a plain spanned by two vectors \\((3, 1, 0)^T\\) and \\((2, 0, 1)^T\\) . Let's draw the plane and spanning vectors. We also plot another vector \\(v = (2,2,1)\\) which is not a linear combination of \\((3, 1, 0)^T\\) and \\((2, 0, 1)^T\\) . As you pan around the view angle (in JupyterLab use %matplotlib widge ), it is apparent that \\(v\\) is not in the same plane of basis vectors. fig = plt . figure ( figsize = ( 8 , 8 )) ax = fig . add_subplot ( projection = '3d' ) x2 = np . linspace ( - 2 , 2 , 10 ) x3 = np . linspace ( - 2 , 2 , 10 ) X2 , X3 = np . meshgrid ( x2 , x3 ) X1 = 3 * X2 + 2 * X3 ax . plot_wireframe ( X1 , X2 , X3 , linewidth = 1.5 , color = 'k' , alpha = .6 ) vec = np . array ([[[ 0 , 0 , 0 , 3 , 1 , 0 ]], [[ 0 , 0 , 0 , 2 , 0 , 1 ]], [[ 0 , 0 , 0 , 5 , 1 , 1 ]], [[ 0 , 0 , 0 , 2 , 2 , 1 ]]]) colors = [ 'r' , 'b' , 'g' , 'purple' ] for i in range ( vec . shape [ 0 ]): X , Y , Z , U , V , W = zip ( * vec [ i ,:,:]) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = colors [ i ], arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 , alpha = .6 ) ################################Dashed Line################################ point12 = np . array ([[ 2 , 0 , 1 ],[ 5 , 1 , 1 ]]) ax . plot ( point12 [:, 0 ], point12 [:, 1 ], point12 [:, 2 ], lw = 3 , ls = '--' , color = 'black' , alpha = 0.5 ) point34 = np . array ([[ 3 , 1 , 0 ], [ 5 , 1 , 1 ]]) ax . plot ( point34 [:, 0 ], point34 [:, 1 ], point34 [:, 2 ], lw = 3 , ls = '--' , color = 'black' , alpha = 0.5 ) #################################Texts####################################### ax . text ( x = 3 , y = 1 , z = 0 , s = '$(3, 1, 0)$' , color = 'red' , size = 16 ) ax . text ( x = 2 , y = 0 , z = 1 , s = '$(2, 0, 1)$' , color = 'blue' , size = 16 ) ax . text ( x = 5 , y = 1 , z = 1 , s = '$(5, 1, 1)$' , color = 'green' , size = 16 ) ax . text ( x = 2 , y = 2 , z = 1 , s = '$v$' , color = 'purple' , size = 16 ) ax . set_xlabel ( 'x-axis' , size = 18 ) ax . set_ylabel ( 'y-axis' , size = 18 ) ax . set_zlabel ( 'z-axis' , size = 18 ) ax . view_init ( elev =- 29 , azim = 130 ) Linear Combination of Polynomial In a more general sense, a function or a polynomial can also be a linear combination of other functions or polynomials. Now consider a polynomial \\(p(x)=4 x^{3}+5 x^{2}-2 x+7\\) , determine if it is a linear combination of three polynomials below: \\[ p_{1}(x)=x^{3}+2 x^{2}-x+1 \\] \\[ p_{2}(x)=2 x^{3}+x^{2}-x+1 \\] \\[ p_{3}(x)=x^{3}-x^{2}-x-4 \\] which means that we need to figure out if the equation below holds \\[ c_{1}\\left(x^{3}+2 x^{2}-x+1\\right)+c_{2}\\left(2 x^{3}+x^{2}-x+1\\right)+c_{3}\\left(x^{3}-x^{2}-x-4\\right)=4 x^{3}+5 x^{2}-2 x+7 \\] Rearrange and collect terms $$ \\left(c_{1}+2 c_{2}+c_{3}\\right) x^{3}+\\left(2 c_{1}+c_{2}-c_{3}\\right) x^{2}+\\left(-c_{1}-c_{2}-c_{3}\\right) x+\\left(c_{1}+c_{2}-4 c_{3}\\right)=4 x^{3}+5 x^{2}-2 x+7 $$ Equate the coefficients and extract the augmented matrix $$ \\begin{aligned} &c_{1}+2 c_{2}+c_{3}=4\\ &2 c_{1}+c_{2}-c_{3}=5\\ &-c_{1}-c_{2}-c_{3}=-2\\ &c_{1}+c_{2}-4 c_{3}=7\\ &\\left[\\begin{array}{cccc} 1 & 2 & 1 & 3 \\ 2 & 1 & -1 & 5 \\ -1 & -1 & -1 & -2 \\ 1 & 1 & -4 & 7 \\end{array}\\right] \\end{aligned} $$ Before solving, we notice that the system has 4 equations, but 3 unknowns, this case is called over-determined . A = sy . Matrix ([[ 1 , 2 , 1 , 4 ],[ 2 , 1 , - 1 , 5 ],[ - 1 , - 1 , - 1 , - 2 ],[ 1 , 1 , - 4 , 7 ]]) A . rref () \\(\\displaystyle \\left( \\left[\\begin{matrix}1 & 0 & 0 & 1\\\\0 & 1 & 0 & 2\\\\0 & 0 & 1 & -1\\\\0 & 0 & 0 & 0\\end{matrix}\\right], \\ \\left( 0, \\ 1, \\ 2\\right)\\right)\\) We get the answer \\((c_1, c_2, c_3)^T = (1, 2, -1)^T\\) , plug in back to equation $$ \\left(x^{3}+2 x^{2}-x+1\\right)+2\\left(2 x^{3}+x^{2}-x+1\\right)-\\left(x^{3}-x^{2}-x-4\\right)=4 x^{3}+5 x^{2}-2 x+7 $$ Indeed we have just established a linear combination between these polynomials. https://en.wikipedia.org/wiki/Linear_combination#:~:text=In%20mathematics%2C%20a%20linear%20combination,a%20and%20b%20are%20constants). \u21a9","title":"Linear Combination"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_linear_combination/#do-my-own-examples-and-use-examples-from-wiki-easier","text":"","title":"DO MY OWN EXAMPLES, AND USE EXAMPLES FROM WIKI EASIER"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_linear_combination/#add-the-linear-comb-python-code-back-to-here-instead-of-dot-prod","text":"","title":"ADD THE LINEAR COMB PYTHON CODE BACK TO HERE INSTEAD OF DOT PROD"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_linear_combination/#the-below-work-are-from-httpsgithubcommacroanalystlinear_algebra_with_python","text":"","title":"The below work are from https://github.com/MacroAnalyst/Linear_Algebra_With_Python."},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_linear_combination/#algebraic-definition-linear-combination","text":"Definition extracted from Wikipedia 1 . Let \\(V\\) be a vector space over the field \\(\\F\\) . As usual, we call elements of \\(V\\) vectors and call elements of \\(\\F\\) scalars. If \\(\\v_1, ... , \\v_n\\) are vectors and \\(a_1, ..., a_n\\) are scalars, then the linear combination of those vectors with those scalars as coefficients is \\[ a_1\\v_1 + a_2\\v_2 + ... + a_n\\v_n \\] Note that by definition, a linear combination involves only finitely many vectors (except as described in Generalizations below). However, the set S that the vectors are taken from (if one is mentioned) can still be infinite; each individual linear combination will only involve finitely many vectors. Also, there is no reason that n cannot be zero; in that case, we declare by convention that the result of the linear combination is the zero vector in \\(V\\) . import matplotlib.pyplot as plt import numpy as np from mpl_toolkits.mplot3d import Axes3D import sympy as sy sy . init_printing ()","title":"Algebraic Definition (Linear Combination)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_linear_combination/#visualization-of-linear-combination-in-mathbbr2","text":"Consider two vectors \\(u\\) and \\(v\\) in \\(\\mathbb{R}^2\\) , they are independent of each other, i.e. not pointing to the same or opposite direction. Therefore any vector in the \\(\\mathbb{R}^2\\) can be represented by a linear combination of \\(u\\) and \\(v\\) . For instance, this is a linear combination and essentially a linear system. \\[ c_1 \\left[ \\begin{matrix} 4\\\\ 2 \\end{matrix} \\right]+ c_2 \\left[ \\begin{matrix} -2\\\\ 2 \\end{matrix} \\right] = \\left[ \\begin{matrix} 2\\\\ 10 \\end{matrix} \\right] \\] Solve the system in SymPy: A = sy . Matrix ([[ 4 , - 2 , 2 ], [ 2 , 2 , 10 ]]) A . rref () \\(\\displaystyle \\left( \\left[\\begin{matrix}1 & 0 & 2\\\\0 & 1 & 3\\end{matrix}\\right], \\ \\left( 0, \\ 1\\right)\\right)\\) The solution is \\((c_1, c_2)^T = (2, 3)^T\\) , which means the addition of \\(2\\) times of \\(\\left[ \\begin{matrix} 4\\\\ 2 \\end{matrix} \\right]\\) and \\(3\\) times of \\(\\left[ \\begin{matrix} -2\\\\ 2 \\end{matrix} \\right]\\) equals \\(\\left[ \\begin{matrix} 2\\\\ 10 \\end{matrix} \\right]\\) . Besides plotting the vector addition, we would like to plot the coordinates of basis that spanned by \\(u\\) and \\(v\\) . We will explain further in later chapter. Calculate the slope of vectors, i.e. \\(\\frac{y}{x}\\) $$ s_1 =\\frac{y}{x} = \\frac{2}{4}=.5\\ s_2 =\\frac{y}{x}= \\frac{2}{-2}=.-1 $$ The basis can be constructed as: $$ y_1 = a+.5x\\ y_2 = b-x $$ where \\(a\\) and \\(b\\) will be set as constants with regular intervals, such as \\((2.5, 5, 7.5, 10)\\) . The coordinates of basis are pink web-style grids, each line segment is a unit (like \\(1\\) in Cartesian coordinate system) in the 'new' coordinates. fig , ax = plt . subplots ( figsize = ( 8 , 8 )) vec = np . array ([[[ 0 , 0 , 4 , 2 ]], [[ 0 , 0 , - 2 , 2 ]], [[ 0 , 0 , 2 , 10 ]], [[ 0 , 0 , 8 , 4 ]], [[ 0 , 0 , - 6 , 6 ]]]) colors = [ 'b' , 'b' , 'r' , 'b' , 'b' ] for i in range ( vec . shape [ 0 ]): X , Y , U , V = zip ( * vec [ i ,:,:]) ax . quiver ( X , Y , U , V , angles = 'xy' , scale_units = 'xy' , color = colors [ i ], scale = 1 , alpha = .6 ) ax . text ( x = vec [ i , 0 , 2 ], y = vec [ i , 0 , 3 ], s = '( %.0d , %.0d )' % ( vec [ i , 0 , 2 ], vec [ i , 0 , 3 ]), fontsize = 16 ) points12 = np . array ([[ 8 , 4 ],[ 2 , 10 ]]) ax . plot ( points12 [:, 0 ], points12 [:, 1 ], c = 'b' , lw = 3.5 , alpha = 0.5 , ls = '--' ) points34 = np . array ([[ - 6 , 6 ],[ 2 , 10 ]]) ax . plot ( points34 [:, 0 ], points34 [:, 1 ], c = 'b' , lw = 3.5 , alpha = 0.5 , ls = '--' ) ax . set_xlim ([ - 10 , 10 ]) ax . set_ylim ([ 0 , 10.5 ]) ax . set_xlabel ( 'x-axis' , fontsize = 16 ) ax . set_ylabel ( 'y-axis' , fontsize = 16 ) ax . grid () ######################################Basis######################################## a = np . arange ( - 11 , 20 , 1 ) x = np . arange ( - 11 , 20 , 1 ) for i in a : y1 = i + .5 * x ax . plot ( x , y1 , ls = '--' , color = 'pink' , lw = 2 ) y2 = i - x ax . plot ( x , y2 , ls = '--' , color = 'pink' , lw = 2 ) ax . set_title ( 'Linear Combination of Two Vectors in $\\mathbf {R} ^2$' , size = 22 , x = 0.5 , y = 1.01 ) plt . show ()","title":" Visualization of Linear Combination in \\(\\mathbb{R}^2\\) "},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_linear_combination/#linear-combination-visualization-in-3d","text":"We can also show that any vectors in \\(\\mathbb{R}^3\\) can be a linear combination of a standard basis in Cartesian coordinate system. Here is the function for plotting 3D linear combination from standard basis, we just feed the scalar multiplier . def linearCombo ( a , b , c ): '''This function is for visualizing linear combination of standard basis in 3D. Function syntax: linearCombo(a, b, c), where a, b, c are the scalar multiplier, also the elements of the vector. ''' fig = plt . figure ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( 111 , projection = '3d' ) ######################## Standard basis and Scalar Multiplid Vectors######################### vec = np . array ([[[ 0 , 0 , 0 , 1 , 0 , 0 ]], # e1 [[ 0 , 0 , 0 , 0 , 1 , 0 ]], # e2 [[ 0 , 0 , 0 , 0 , 0 , 1 ]], # e3 [[ 0 , 0 , 0 , a , 0 , 0 ]], # a* e1 [[ 0 , 0 , 0 , 0 , b , 0 ]], # b* e2 [[ 0 , 0 , 0 , 0 , 0 , c ]], # c* e3 [[ 0 , 0 , 0 , a , b , c ]]]) # ae1 + be2 + ce3 colors = [ 'b' , 'b' , 'b' , 'r' , 'r' , 'r' , 'g' ] for i in range ( vec . shape [ 0 ]): X , Y , Z , U , V , W = zip ( * vec [ i ,:,:]) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = colors [ i ] , arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 , alpha = .6 ) #################################Plot Rectangle Boxes############################## dlines = np . array ([[[ a , 0 , 0 ],[ a , b , 0 ]], [[ 0 , b , 0 ],[ a , b , 0 ]], [[ 0 , 0 , c ],[ a , b , c ]], [[ 0 , 0 , c ],[ a , 0 , c ]], [[ a , 0 , c ],[ a , b , c ]], [[ 0 , 0 , c ],[ 0 , b , c ]], [[ 0 , b , c ],[ a , b , c ]], [[ a , 0 , 0 ],[ a , 0 , c ]], [[ 0 , b , 0 ],[ 0 , b , c ]], [[ a , b , 0 ],[ a , b , c ]]]) colors = [ 'k' , 'k' , 'g' , 'k' , 'k' , 'k' , 'k' , 'k' , 'k' ] for i in range ( dlines . shape [ 0 ]): ax . plot ( dlines [ i ,:, 0 ], dlines [ i ,:, 1 ], dlines [ i ,:, 2 ], lw = 3 , ls = '--' , color = 'black' , alpha = 0.5 ) #################################Annotation######################################## ax . text ( x = a , y = b , z = c , s = ' $(%0.d, %0.d, %.0d )$' % ( a , b , c ), size = 18 ) ax . text ( x = a , y = 0 , z = 0 , s = ' $%0.d e_1 = (%0.d, 0, 0)$' % ( a , a ), size = 15 ) ax . text ( x = 0 , y = b , z = 0 , s = ' $%0.d e_2 = (0, %0.d, 0)$' % ( b , b ), size = 15 ) ax . text ( x = 0 , y = 0 , z = c , s = ' $%0.d e_3 = (0, 0, %0.d)$' % ( c , c ), size = 15 ) #################################Axis Setting###################################### ax . grid () ax . set_xlim ([ 0 , a + 1 ]) ax . set_ylim ([ 0 , b + 1 ]) ax . set_zlim ([ 0 , c + 1 ]) ax . set_xlabel ( 'x-axis' , size = 18 ) ax . set_ylabel ( 'y-axis' , size = 18 ) ax . set_zlabel ( 'z-axis' , size = 18 ) ax . set_title ( 'Vector $(%0.d, %0.d, %.0d )$ Visualization' % ( a , b , c ), size = 20 ) ax . view_init ( elev = 20. , azim = 15 ) if __name__ == '__main__' : a = 7 b = 4 c = 9 linearCombo ( a , b , c ) linearCombo ( 3 , 5 , 6 ) # Try again","title":" Linear Combination Visualization in 3D"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_linear_combination/#linear-combination-of-inconsistent-system","text":"Inconsistent system means no unique solution exists. It might sound weird to treat a solution of an inconsistent system as a linear combination, but it is essential a trace of line.","title":" Linear Combination of Inconsistent System"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_linear_combination/#one-free-variable-case","text":"We have seen how inconsistent systems can be solved in the earlier lectures. Now we will investigate what solution means from the perspective of linear combination. Consider a system \\[ \\left[ \\begin{matrix} 1 & 1 & 2\\\\ -2 &0 & 1\\\\ 1& 1 & 2 \\end{matrix} \\right] \\left[ \\begin{matrix} c_1\\\\c_2\\\\c_3 \\end{matrix} \\right] = \\left[ \\begin{matrix} 1\\\\-3\\\\1 \\end{matrix} \\right] \\] Solve in SymPy: A = sy . Matrix ([[ 1 , 1 , 2 , 1 ],[ - 2 , 0 , 1 , - 3 ],[ 1 , 1 , 2 , 1 ]]) A . rref () \\(\\displaystyle \\left( \\left[\\begin{matrix}1 & 0 & - \\frac{1}{2} & \\frac{3}{2}\\\\0 & 1 & \\frac{5}{2} & - \\frac{1}{2}\\\\0 & 0 & 0 & 0\\end{matrix}\\right], \\ \\left( 0, \\ 1\\right)\\right)\\) The solution is not unique due to a free variable: \\[ c_1 - \\frac{1}{2}c_3 =\\frac{3}{2}\\\\ c_2 + \\frac{5}{2}c_3 = -\\frac{1}{2}\\\\ c_3 = free \\] Let \\(c_3 = t\\) , the system can be parameterized: \\[ \\left[ \\begin{matrix} c_1\\\\c_2\\\\c_3 \\end{matrix} \\right] = \\left[ \\begin{matrix} \\frac{3}{2}+\\frac{1}{2}t\\\\ -\\frac{1}{2}-\\frac{5}{2}t\\\\ t \\end{matrix} \\right] \\] The solution is a line of infinite length, to visualize it, we set the range of \\(t\\in (-1, 1)\\) , the solution looks like: fig = plt . figure ( figsize = ( 8 , 8 )) ax = fig . add_subplot ( projection = '3d' ) t = np . linspace ( - 1 , 1 , 10 ) c1 = 3 / 2 + t / 2 c2 = - 1 / 2 - 5 / 2 * t ax . plot ( c1 , c2 , t , lw = 5 ) ax . set_xlabel ( 'x-axis' , size = 18 ) ax . set_ylabel ( 'y-axis' , size = 18 ) ax . set_zlabel ( 'z-axis' , size = 18 ) ax . set_title ( 'Solution of A Linear System with One Free Variable' , size = 18 ) plt . show ()","title":" One Free Variable Case"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_linear_combination/#two-free-variables-case","text":"Now consider the linear system: $$ \\left[ \\begin{matrix} 1 & -3 & -2\\ 0 &0 & 0 \\ 0& 0 & 0 \\end{matrix} \\right] \\left[ \\begin{matrix} x_1\\ x_2\\ x_3 \\end{matrix} \\right] = \\left[ \\begin{matrix} 0\\0\\0 \\end{matrix} \\right] $$ The augmented matrix is $$ \\left[ \\begin{matrix} 1 & -3 & -2 & 0\\ 0 &0 & 0 & 0\\ 0& 0 & 0 & 0 \\end{matrix} \\right] $$ We have two free variables $$ \\begin{align} x_1 &= 3x_2+2x_3\\ x_2 &= free\\ x_3 &= free \\end{align} $$ Rewrite the solution \\[ \\left[ \\begin{matrix} x_1\\\\ x_2\\\\ x_3 \\end{matrix} \\right] = \\left[ \\begin{matrix} 3x_2+2x_3\\\\ x_2\\\\ x_3 \\end{matrix} \\right] = \\left[\\begin{array}{c} 3 x_{2} \\\\ x_{2} \\\\ 0 \\end{array}\\right]+\\left[\\begin{array}{c} 2 x_{3} \\\\ 0 \\\\ x_{3} \\end{array}\\right]= x_{2}\\left[\\begin{array}{l} 3 \\\\ 1 \\\\ 0 \\end{array}\\right]+x_{3}\\left[\\begin{array}{l} 2 \\\\ 0 \\\\ 1 \\end{array}\\right] \\] The solution is a plain spanned by two vectors \\((3, 1, 0)^T\\) and \\((2, 0, 1)^T\\) . Let's draw the plane and spanning vectors. We also plot another vector \\(v = (2,2,1)\\) which is not a linear combination of \\((3, 1, 0)^T\\) and \\((2, 0, 1)^T\\) . As you pan around the view angle (in JupyterLab use %matplotlib widge ), it is apparent that \\(v\\) is not in the same plane of basis vectors. fig = plt . figure ( figsize = ( 8 , 8 )) ax = fig . add_subplot ( projection = '3d' ) x2 = np . linspace ( - 2 , 2 , 10 ) x3 = np . linspace ( - 2 , 2 , 10 ) X2 , X3 = np . meshgrid ( x2 , x3 ) X1 = 3 * X2 + 2 * X3 ax . plot_wireframe ( X1 , X2 , X3 , linewidth = 1.5 , color = 'k' , alpha = .6 ) vec = np . array ([[[ 0 , 0 , 0 , 3 , 1 , 0 ]], [[ 0 , 0 , 0 , 2 , 0 , 1 ]], [[ 0 , 0 , 0 , 5 , 1 , 1 ]], [[ 0 , 0 , 0 , 2 , 2 , 1 ]]]) colors = [ 'r' , 'b' , 'g' , 'purple' ] for i in range ( vec . shape [ 0 ]): X , Y , Z , U , V , W = zip ( * vec [ i ,:,:]) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = colors [ i ], arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 , alpha = .6 ) ################################Dashed Line################################ point12 = np . array ([[ 2 , 0 , 1 ],[ 5 , 1 , 1 ]]) ax . plot ( point12 [:, 0 ], point12 [:, 1 ], point12 [:, 2 ], lw = 3 , ls = '--' , color = 'black' , alpha = 0.5 ) point34 = np . array ([[ 3 , 1 , 0 ], [ 5 , 1 , 1 ]]) ax . plot ( point34 [:, 0 ], point34 [:, 1 ], point34 [:, 2 ], lw = 3 , ls = '--' , color = 'black' , alpha = 0.5 ) #################################Texts####################################### ax . text ( x = 3 , y = 1 , z = 0 , s = '$(3, 1, 0)$' , color = 'red' , size = 16 ) ax . text ( x = 2 , y = 0 , z = 1 , s = '$(2, 0, 1)$' , color = 'blue' , size = 16 ) ax . text ( x = 5 , y = 1 , z = 1 , s = '$(5, 1, 1)$' , color = 'green' , size = 16 ) ax . text ( x = 2 , y = 2 , z = 1 , s = '$v$' , color = 'purple' , size = 16 ) ax . set_xlabel ( 'x-axis' , size = 18 ) ax . set_ylabel ( 'y-axis' , size = 18 ) ax . set_zlabel ( 'z-axis' , size = 18 ) ax . view_init ( elev =- 29 , azim = 130 )","title":" Two Free Variables Case"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_linear_combination/#linear-combination-of-polynomial","text":"In a more general sense, a function or a polynomial can also be a linear combination of other functions or polynomials. Now consider a polynomial \\(p(x)=4 x^{3}+5 x^{2}-2 x+7\\) , determine if it is a linear combination of three polynomials below: \\[ p_{1}(x)=x^{3}+2 x^{2}-x+1 \\] \\[ p_{2}(x)=2 x^{3}+x^{2}-x+1 \\] \\[ p_{3}(x)=x^{3}-x^{2}-x-4 \\] which means that we need to figure out if the equation below holds \\[ c_{1}\\left(x^{3}+2 x^{2}-x+1\\right)+c_{2}\\left(2 x^{3}+x^{2}-x+1\\right)+c_{3}\\left(x^{3}-x^{2}-x-4\\right)=4 x^{3}+5 x^{2}-2 x+7 \\] Rearrange and collect terms $$ \\left(c_{1}+2 c_{2}+c_{3}\\right) x^{3}+\\left(2 c_{1}+c_{2}-c_{3}\\right) x^{2}+\\left(-c_{1}-c_{2}-c_{3}\\right) x+\\left(c_{1}+c_{2}-4 c_{3}\\right)=4 x^{3}+5 x^{2}-2 x+7 $$ Equate the coefficients and extract the augmented matrix $$ \\begin{aligned} &c_{1}+2 c_{2}+c_{3}=4\\ &2 c_{1}+c_{2}-c_{3}=5\\ &-c_{1}-c_{2}-c_{3}=-2\\ &c_{1}+c_{2}-4 c_{3}=7\\ &\\left[\\begin{array}{cccc} 1 & 2 & 1 & 3 \\ 2 & 1 & -1 & 5 \\ -1 & -1 & -1 & -2 \\ 1 & 1 & -4 & 7 \\end{array}\\right] \\end{aligned} $$ Before solving, we notice that the system has 4 equations, but 3 unknowns, this case is called over-determined . A = sy . Matrix ([[ 1 , 2 , 1 , 4 ],[ 2 , 1 , - 1 , 5 ],[ - 1 , - 1 , - 1 , - 2 ],[ 1 , 1 , - 4 , 7 ]]) A . rref () \\(\\displaystyle \\left( \\left[\\begin{matrix}1 & 0 & 0 & 1\\\\0 & 1 & 0 & 2\\\\0 & 0 & 1 & -1\\\\0 & 0 & 0 & 0\\end{matrix}\\right], \\ \\left( 0, \\ 1, \\ 2\\right)\\right)\\) We get the answer \\((c_1, c_2, c_3)^T = (1, 2, -1)^T\\) , plug in back to equation $$ \\left(x^{3}+2 x^{2}-x+1\\right)+2\\left(2 x^{3}+x^{2}-x+1\\right)-\\left(x^{3}-x^{2}-x-4\\right)=4 x^{3}+5 x^{2}-2 x+7 $$ Indeed we have just established a linear combination between these polynomials. https://en.wikipedia.org/wiki/Linear_combination#:~:text=In%20mathematics%2C%20a%20linear%20combination,a%20and%20b%20are%20constants). \u21a9","title":"Linear Combination of Polynomial"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_outer_product/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\p}{\\mathbf{p}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\E}{\\mathbf{E}} \\newcommand{\\P}{\\mathbf{P}}\\] Algebraic Definition (Outer Product) Given two vectors of size \\(m \\times 1\\) and \\(n \\times 1\\) respectively \\[ \\mathbf{u} = \\begin{bmatrix} u_1 \\\\ u_2 \\\\ \\vdots \\\\ u_m \\end{bmatrix}, \\quad \\mathbf{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix} \\] their outer product, denoted \\(\\mathbf{u} \\otimes \\mathbf{v}\\) is defined as the \\(m \\times n\\) matrix \\(\\mathbf{A}\\) obtained by multiplying each element of \\(\\mathbf{u}\\) by each element of \\(\\v\\) . \\[ \\mathbf{u} \\otimes \\mathbf{v} = \\mathbf{A} = \\begin{bmatrix} u_1v_1 & u_1v_2 & \\dots & u_1v_n \\\\ u_2v_1 & u_2v_2 & \\dots & u_2v_n \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ u_mv_1 & u_mv_2 & \\dots & u_mv_n \\end{bmatrix} \\] Or in index notation: \\[(\\mathbf{u} \\otimes \\mathbf{v})_{ij} = u_i v_j\\] Denoting the dot product by \\(\\cdot\\) , if given an \\(n \\times 1\\) vector \\(\\w\\) then \\[ (\\mathbf{u} \\otimes \\mathbf{v}) \\mathbf{w} = (\\mathbf{v} \\cdot \\mathbf{w}) \\mathbf{u} \\] If given a \\(1 \\times m\\) vector \\(\\x\\) then \\[ \\mathbf{x} (\\mathbf{u} \\otimes \\mathbf{v}) = (\\mathbf{x} \\cdot \\mathbf{u}) \\mathbf{v}^{\\operatorname{T}} \\] If \\(\\u\\) and \\(\\v\\) are vectors of the same dimension, then \\(\\det (\\mathbf{u} \\otimes\\mathbf{v}) = 0\\) . The outer product \\(\\mathbf{u} \\otimes \\mathbf{v}\\) is equivalent to a matrix multiplication \\(\\mathbf{u} \\mathbf{v}^{\\operatorname{T}}\\) provided that \\(\\mathbf{u}\\) is represented as a \\(m \\times 1\\) column vector and \\(\\mathbf{v}\\) as a \\(n \\times 1\\) column vector (which makes \\(\\mathbf{v}^{\\operatorname{T}}\\) a row vector). For instance, if \\(m = 4\\) and \\(n = 3,\\) then \\[ \\mathbf{u} \\otimes \\mathbf{v} = \\mathbf{u}\\mathbf{v}^\\textsf{T} = \\begin{bmatrix}u_1 \\\\ u_2 \\\\ u_3 \\\\ u_4\\end{bmatrix} \\begin{bmatrix}v_1 & v_2 & v_3\\end{bmatrix} = \\begin{bmatrix} u_1 v_1 & u_1 v_2 & u_1 v_3 \\\\ u_2 v_1 & u_2 v_2 & u_2 v_3 \\\\ u_3 v_1 & u_3 v_2 & u_3 v_3 \\\\ u_4 v_1 & u_4 v_2 & u_4 v_3 \\end{bmatrix}. \\] Column Wise Interpretation Especially from the matrix example in the previous section, one can see that the following holds: \\[ \\mathbf{u} \\otimes \\mathbf{v} = \\mathbf{u}\\mathbf{v}^\\textsf{T} = \\begin{bmatrix}u_1 \\\\ u_2 \\\\ u_3 \\\\ u_4\\end{bmatrix} \\begin{bmatrix}v_1 & v_2 & v_3\\end{bmatrix} = \\begin{bmatrix} u_1 v_1 & u_1 v_2 & u_1 v_3 \\\\ u_2 v_1 & u_2 v_2 & u_2 v_3 \\\\ u_3 v_1 & u_3 v_2 & u_3 v_3 \\\\ u_4 v_1 & u_4 v_2 & u_4 v_3 \\end{bmatrix} = \\begin{bmatrix} v_1 \\u & v_2 \\u & v_3 \\u \\end{bmatrix} \\] What this means is that in our example our column vector is \\(\\u\\) . Then when we do an outer product of \\(\\u\\) on \\(\\v\\) , then notice each of the resultant matrix's columns is a scaled version of the column vector \\(\\u\\) , scaled none other by the elements of the row vector \\(\\v\\) itself. Row Wise Interpretation Especially from the matrix example in the previous section, one can see that the following holds: \\[ \\mathbf{u} \\otimes \\mathbf{v} = \\mathbf{u}\\mathbf{v}^\\textsf{T} = \\begin{bmatrix}u_1 \\\\ u_2 \\\\ u_3 \\\\ u_4\\end{bmatrix} \\begin{bmatrix}v_1 & v_2 & v_3\\end{bmatrix} = \\begin{bmatrix} u_1 v_1 & u_1 v_2 & u_1 v_3 \\\\ u_2 v_1 & u_2 v_2 & u_2 v_3 \\\\ u_3 v_1 & u_3 v_2 & u_3 v_3 \\\\ u_4 v_1 & u_4 v_2 & u_4 v_3 \\end{bmatrix} = \\begin{bmatrix} u_1 \\v \\\\ u_2 \\v \\\\ u_3 \\v \\end{bmatrix} \\] What this means is that in our example our row vector is \\(\\v\\) . Then when we do an outer product of \\(\\u\\) on \\(\\v\\) , then notice each of the resultant matrix's rows is a scaled version of the row vector \\(\\v\\) , scaled none other by the elements of the row vector \\(\\u\\) itself. Transpose Property \\(\\u\\v^\\top\\) and \\(\\v\\u^\\top\\) . What can you deduce from this? Actually if you do an example, you will notice that the resulting matrices are the same with rows and columns swapped. That is, \\[(\\u\\v^\\top)^\\top = \\v\\u^\\top\\] The author Mike said that this is an important property later. Applications of Outer Product Put a mental note that Outer Product has areas of applications in Machine Learning.","title":"Outer Product"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_outer_product/#algebraic-definition-outer-product","text":"Given two vectors of size \\(m \\times 1\\) and \\(n \\times 1\\) respectively \\[ \\mathbf{u} = \\begin{bmatrix} u_1 \\\\ u_2 \\\\ \\vdots \\\\ u_m \\end{bmatrix}, \\quad \\mathbf{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix} \\] their outer product, denoted \\(\\mathbf{u} \\otimes \\mathbf{v}\\) is defined as the \\(m \\times n\\) matrix \\(\\mathbf{A}\\) obtained by multiplying each element of \\(\\mathbf{u}\\) by each element of \\(\\v\\) . \\[ \\mathbf{u} \\otimes \\mathbf{v} = \\mathbf{A} = \\begin{bmatrix} u_1v_1 & u_1v_2 & \\dots & u_1v_n \\\\ u_2v_1 & u_2v_2 & \\dots & u_2v_n \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ u_mv_1 & u_mv_2 & \\dots & u_mv_n \\end{bmatrix} \\] Or in index notation: \\[(\\mathbf{u} \\otimes \\mathbf{v})_{ij} = u_i v_j\\] Denoting the dot product by \\(\\cdot\\) , if given an \\(n \\times 1\\) vector \\(\\w\\) then \\[ (\\mathbf{u} \\otimes \\mathbf{v}) \\mathbf{w} = (\\mathbf{v} \\cdot \\mathbf{w}) \\mathbf{u} \\] If given a \\(1 \\times m\\) vector \\(\\x\\) then \\[ \\mathbf{x} (\\mathbf{u} \\otimes \\mathbf{v}) = (\\mathbf{x} \\cdot \\mathbf{u}) \\mathbf{v}^{\\operatorname{T}} \\] If \\(\\u\\) and \\(\\v\\) are vectors of the same dimension, then \\(\\det (\\mathbf{u} \\otimes\\mathbf{v}) = 0\\) . The outer product \\(\\mathbf{u} \\otimes \\mathbf{v}\\) is equivalent to a matrix multiplication \\(\\mathbf{u} \\mathbf{v}^{\\operatorname{T}}\\) provided that \\(\\mathbf{u}\\) is represented as a \\(m \\times 1\\) column vector and \\(\\mathbf{v}\\) as a \\(n \\times 1\\) column vector (which makes \\(\\mathbf{v}^{\\operatorname{T}}\\) a row vector). For instance, if \\(m = 4\\) and \\(n = 3,\\) then \\[ \\mathbf{u} \\otimes \\mathbf{v} = \\mathbf{u}\\mathbf{v}^\\textsf{T} = \\begin{bmatrix}u_1 \\\\ u_2 \\\\ u_3 \\\\ u_4\\end{bmatrix} \\begin{bmatrix}v_1 & v_2 & v_3\\end{bmatrix} = \\begin{bmatrix} u_1 v_1 & u_1 v_2 & u_1 v_3 \\\\ u_2 v_1 & u_2 v_2 & u_2 v_3 \\\\ u_3 v_1 & u_3 v_2 & u_3 v_3 \\\\ u_4 v_1 & u_4 v_2 & u_4 v_3 \\end{bmatrix}. \\]","title":"Algebraic Definition (Outer Product)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_outer_product/#column-wise-interpretation","text":"Especially from the matrix example in the previous section, one can see that the following holds: \\[ \\mathbf{u} \\otimes \\mathbf{v} = \\mathbf{u}\\mathbf{v}^\\textsf{T} = \\begin{bmatrix}u_1 \\\\ u_2 \\\\ u_3 \\\\ u_4\\end{bmatrix} \\begin{bmatrix}v_1 & v_2 & v_3\\end{bmatrix} = \\begin{bmatrix} u_1 v_1 & u_1 v_2 & u_1 v_3 \\\\ u_2 v_1 & u_2 v_2 & u_2 v_3 \\\\ u_3 v_1 & u_3 v_2 & u_3 v_3 \\\\ u_4 v_1 & u_4 v_2 & u_4 v_3 \\end{bmatrix} = \\begin{bmatrix} v_1 \\u & v_2 \\u & v_3 \\u \\end{bmatrix} \\] What this means is that in our example our column vector is \\(\\u\\) . Then when we do an outer product of \\(\\u\\) on \\(\\v\\) , then notice each of the resultant matrix's columns is a scaled version of the column vector \\(\\u\\) , scaled none other by the elements of the row vector \\(\\v\\) itself.","title":"Column Wise Interpretation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_outer_product/#row-wise-interpretation","text":"Especially from the matrix example in the previous section, one can see that the following holds: \\[ \\mathbf{u} \\otimes \\mathbf{v} = \\mathbf{u}\\mathbf{v}^\\textsf{T} = \\begin{bmatrix}u_1 \\\\ u_2 \\\\ u_3 \\\\ u_4\\end{bmatrix} \\begin{bmatrix}v_1 & v_2 & v_3\\end{bmatrix} = \\begin{bmatrix} u_1 v_1 & u_1 v_2 & u_1 v_3 \\\\ u_2 v_1 & u_2 v_2 & u_2 v_3 \\\\ u_3 v_1 & u_3 v_2 & u_3 v_3 \\\\ u_4 v_1 & u_4 v_2 & u_4 v_3 \\end{bmatrix} = \\begin{bmatrix} u_1 \\v \\\\ u_2 \\v \\\\ u_3 \\v \\end{bmatrix} \\] What this means is that in our example our row vector is \\(\\v\\) . Then when we do an outer product of \\(\\u\\) on \\(\\v\\) , then notice each of the resultant matrix's rows is a scaled version of the row vector \\(\\v\\) , scaled none other by the elements of the row vector \\(\\u\\) itself.","title":"Row Wise Interpretation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_outer_product/#transpose-property","text":"\\(\\u\\v^\\top\\) and \\(\\v\\u^\\top\\) . What can you deduce from this? Actually if you do an example, you will notice that the resulting matrices are the same with rows and columns swapped. That is, \\[(\\u\\v^\\top)^\\top = \\v\\u^\\top\\] The author Mike said that this is an important property later.","title":"Transpose Property"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_outer_product/#applications-of-outer-product","text":"Put a mental note that Outer Product has areas of applications in Machine Learning.","title":"Applications of Outer Product"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_unit_vector/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}}\\] Table of Contents Unit Vector Geometric Interpretation of Unit Vector Algebraic Interpretation of Unit Vector Unit Vector Though not apparent now, unit vectors are important in linear algebra and have widespread applications. Geometric Interpretation of Unit Vector Consider the vector \\(\\v = [3, 4]\\) which has a norm of \\(\\|\\v_1\\| = \\sqrt{3^2 + 4^2} = 5\\) . We want to find a vector \\(\\u\\) that is in the same direction of \\(\\v\\) (assume all has starting coordinates at origin), but has norm of \\(1\\) . Geometrically, we know that we just need to divide the vector \\(\\v\\) by \\(5\\) (a.k.a the norm of the vector itself) to get a vector that has norm \\(1\\) and also lies in the same direction. But how to recover the exact vector \\(\\u\\) with its coordinates? We have learnt about Vector-Scalar Multiplication and visually, we need to multiply the vector \\(\\v\\) by \\(\\frac{1}{5}\\) to get the vector \\(\\u = [0.6, 0.8]\\) . Thus, given a vector \\(\\v\\) , we know that if we divide it by the length of itself, we can recover back a vector \\(\\u = \\frac{1}{\\|\\v\\|}\\v\\) such that \\(\\|\\u\\| = 1\\) . Fig 3.5: Unit Vectors; By Hongnan G. Algebraic Interpretation of Unit Vector Given a vector \\(\\v\\) , can we find a vector \\(\\u\\) such that: - \\(\\|\\u\\| = 1\\) - \\(\\u\\) is in the same direction as \\(\\v\\) . We need to fulfill the above two conditions, and since we know that \\(\\u\\) must be in the same direction as \\(\\v\\) , then \\(\\u = \\lambda \\v\\) by definition. Thus, our problem is reduced to finding a vector \\(\\u = \\lambda \\v\\) such that \\(\\|\\u\\| = 1\\) . And since \\(\\v\\) is known, it suffices for us to find \\(\\lambda\\) only. We also know that \\(\\|\\u\\|\\) must be \\(1\\) , as a result, let us take the norm of both sides to get \\[\\|\\u\\| = \\|\\lambda \\v\\| \\implies \\|\\u\\| = \\lambda \\|\\v\\| \\implies \\lambda = \\dfrac{\\|\\u\\|}{\\|\\v\\|}\\] Substituting back, we have \\[\\u = \\lambda \\v = \\dfrac{\\|\\u\\|}{\\|\\v\\|} \\v = \\dfrac{1}{\\|\\v\\|} \\v\\]","title":"Unit Vector"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_unit_vector/#table-of-contents","text":"Unit Vector Geometric Interpretation of Unit Vector Algebraic Interpretation of Unit Vector","title":"Table of Contents"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_unit_vector/#unit-vector","text":"Though not apparent now, unit vectors are important in linear algebra and have widespread applications.","title":"Unit Vector"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_unit_vector/#geometric-interpretation-of-unit-vector","text":"Consider the vector \\(\\v = [3, 4]\\) which has a norm of \\(\\|\\v_1\\| = \\sqrt{3^2 + 4^2} = 5\\) . We want to find a vector \\(\\u\\) that is in the same direction of \\(\\v\\) (assume all has starting coordinates at origin), but has norm of \\(1\\) . Geometrically, we know that we just need to divide the vector \\(\\v\\) by \\(5\\) (a.k.a the norm of the vector itself) to get a vector that has norm \\(1\\) and also lies in the same direction. But how to recover the exact vector \\(\\u\\) with its coordinates? We have learnt about Vector-Scalar Multiplication and visually, we need to multiply the vector \\(\\v\\) by \\(\\frac{1}{5}\\) to get the vector \\(\\u = [0.6, 0.8]\\) . Thus, given a vector \\(\\v\\) , we know that if we divide it by the length of itself, we can recover back a vector \\(\\u = \\frac{1}{\\|\\v\\|}\\v\\) such that \\(\\|\\u\\| = 1\\) . Fig 3.5: Unit Vectors; By Hongnan G.","title":"Geometric Interpretation of Unit Vector"},{"location":"reighns_ml_journey/mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_unit_vector/#algebraic-interpretation-of-unit-vector","text":"Given a vector \\(\\v\\) , can we find a vector \\(\\u\\) such that: - \\(\\|\\u\\| = 1\\) - \\(\\u\\) is in the same direction as \\(\\v\\) . We need to fulfill the above two conditions, and since we know that \\(\\u\\) must be in the same direction as \\(\\v\\) , then \\(\\u = \\lambda \\v\\) by definition. Thus, our problem is reduced to finding a vector \\(\\u = \\lambda \\v\\) such that \\(\\|\\u\\| = 1\\) . And since \\(\\v\\) is known, it suffices for us to find \\(\\lambda\\) only. We also know that \\(\\|\\u\\|\\) must be \\(1\\) , as a result, let us take the norm of both sides to get \\[\\|\\u\\| = \\|\\lambda \\v\\| \\implies \\|\\u\\| = \\lambda \\|\\v\\| \\implies \\lambda = \\dfrac{\\|\\u\\|}{\\|\\v\\|}\\] Substituting back, we have \\[\\u = \\lambda \\v = \\dfrac{\\|\\u\\|}{\\|\\v\\|} \\v = \\dfrac{1}{\\|\\v\\|} \\v\\]","title":"Algebraic Interpretation of Unit Vector"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\e}{\\mathbf{e}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}}\\] Basis Disclaimer Algebraic Definition (Basis) Minimal Generating Set Geometric Definition (Basis) Examples (Basis) Examples (Standard Basis) Visualize Standard Basis in 2D Space Visualize Non-Standard Basis in 2D Space Visualize Standard Basis in 3D Space Visualize Non-Standard Basis in 3D Space Theorem (Criterion for Basis and Unique Representation of Basis) Proof Theorem (All Basis has the same length) Dimensions Definition (Dimension) Notation (Dimension) Intuition (Dimension) Example (Dimension) Theorem (Dimension of a Subspace) Proof Basis and Dimension Theorems and Applications Theorem (Spanning Set contains Basis) Proof Theorem (Every Subspace has a Basis) Proof Theorem (Linear Independent Sets can be extended to a Basis) Proof Theorem (Equivalent Basis Definition) Proof Useful Summary Applications of Basis Efficient Space Storage Basis Disclaimer I believe learning linear algebra needs some geometrical intuition, after looking around, I finally chanced upon this GitHub repo with nice python code to plot basis vectors. We will use his code below to visualize basis vectors in this section. Please visit his repo here 1 . Algebraic Definition (Basis) A basis \\(\\B\\) of a vector space \\(V\\) over a field \\(\\F\\) 2 is a linearly independent subset of \\(V\\) that spans \\(V\\) . This means that a subset \\(\\B\\) of \\(V\\) is a basis if it satisfies the two following conditions: the linear independence property: The set of vectors \\(\\b_1, \\b_2, ..., \\b_n \\in V\\) is linearly independent if and only if the only solution to the equation \\(a_1\\mathbf{v}_1 + a_2\\mathbf{v}_2 + \\cdots + a_m\\mathbf{v}_n = \\mathbf{0}\\) is the trivial solution, the zero vector; and the spanning property: Define \\(\\B = \\{\\b_1, \\b_2, ..., \\b_m\\}\\) in \\(V\\) , and the linear combination of all the vectors \\(\\b_1, \\b_2, \\cdots, \\b_n\\) make up the main vector space \\(V\\) ; i.e. \\(\\textbf{span}(B) = V\\) . Minimal Generating Set We won't go through the formal definition, but rather a motivating example from Math Stack Exchange 3 . You can think about it as the idea from linear algebra of a basis for a space compared to a set of vectors which span the space. A basis is a set of linearly independent elements, where removing one of the elements would result in it being unable to generate every element in that space. In other words, you can think of a minimal generating set as a basis for the group, which has no redundant elements while a generating set may have redundant elements. For example, to generate \\(\\mathbb R^3\\) we have a basis \\(\\begin{bmatrix}1\\\\0\\\\0\\end{bmatrix}, \\begin{bmatrix}0\\\\1\\\\0\\end{bmatrix}, \\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix}\\) (a minimal generating set), but this space is still generated by the set of vectors \\(\\begin{bmatrix}1\\\\0\\\\0\\end{bmatrix}, \\begin{bmatrix}0\\\\1\\\\0\\end{bmatrix}, \\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix}, \\begin{bmatrix}0\\\\0\\\\3\\end{bmatrix}\\) (a generating set). Geometric Definition (Basis) Note Geometric understanding of basis is best understood with examples! Examples (Basis) Examples (Standard Basis) Every space \\(\\R^n\\) has a standard basis . \\[\\e = \\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1}\\end{bmatrix} \\right\\}\\] is the standard basis for the \\(\\R^2\\) space; and for \\(\\R^3\\) : \\[\\e = \\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1} \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{0} \\\\ \\color{red}1 \\end{bmatrix} \\right\\}\\] and we usually denote \\[\\e_1 = \\begin{bmatrix} \\color{red}1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} \\quad \\e_2 = \\begin{bmatrix} \\color{red}0 \\\\ 1 \\\\ \\vdots \\\\0 \\end{bmatrix} \\quad \\e_n = \\begin{bmatrix} \\color{red}0 \\\\ 0 \\\\ \\vdots \\\\ 1 \\end{bmatrix}\\] and so on. Visualize Standard Basis in 2D Space Consider a vector \\(\\v = \\begin{bmatrix}\\color{red}3 \\\\ \\color{red}6\\end{bmatrix}\\) . We can construct this vector using our standard basis \\(\\e_1, \\e_2\\) as \\(3\\e_1 + 6\\e_2\\) , as shown below. import matplotlib.pyplot as plt import numpy as np fig , ax = plt . subplots ( figsize = ( 10 , 10 )) arrows = np . array ( [ [[ 0 , 0 , 1 , 0 ]], [[ 0 , 0 , 0 , 1 ]], [[ 0 , 0 , 3 , 0 ]], [[ 0 , 0 , 0 , 6 ]], [[ 0 , 0 , 3 , 6 ]], ] ) colors = [ \"r\" , \"b\" , \"r\" , \"b\" , \"g\" ] for i in range ( arrows . shape [ 0 ]): X , Y , U , V = zip ( * arrows [ i , :, :]) ax . arrow ( X [ 0 ], Y [ 0 ], U [ 0 ], V [ 0 ], color = colors [ i ], width = 0.03 , length_includes_head = True , head_width = 0.2 , # default: 3*width head_length = 0.3 , overhang = 0.4 , ) ############################Dashed################################## line1 = np . array ([[ 3 , 0 ], [ 3 , 6 ]]) ax . plot ( line1 [:, 0 ], line1 [:, 1 ], ls = \"--\" , lw = 3 , color = \"black\" , alpha = 0.5 ) line2 = np . array ([[ 0 , 6 ], [ 3 , 6 ]]) ax . plot ( line2 [:, 0 ], line2 [:, 1 ], ls = \"--\" , lw = 3 , color = \"black\" , alpha = 0.5 ) ############################Text##################################### ax . text ( 0 , 1 , \"$e_2$\" , size = 15 ) ax . text ( 1 , 0 , \"$e_1$\" , size = 15 ) ax . text ( 0 , 6 , \"$6e_2$\" , size = 15 ) ax . text ( 3 , 0 , \"$3e_1$\" , size = 15 ) ax . text ( 3 , 6 , \"$3e_1+6e_2$\" , size = 15 ) ###########################Grid Setting############################## # Major ticks every 20, minor ticks every 5 major_ticks = np . arange ( 0 , 10 , 2 ) minor_ticks = np . arange ( 0 , 10 , 0.5 ) ax . set_xticks ( major_ticks ) ax . set_xticks ( minor_ticks , minor = True ) ax . set_yticks ( major_ticks ) ax . set_yticks ( minor_ticks , minor = True ) ax . grid ( which = \"both\" ) ax . grid ( which = \"minor\" , alpha = 0.2 ) ax . grid ( which = \"major\" , alpha = 0.5 ) ####################################################################### ax . set_xlabel ( \"x-axis\" , size = 18 ) ax . set_ylabel ( \"y-axis\" , size = 18 ) ax . axis ([ - 1 , 10 , - 1 , 10 ]) ax . grid () plt . show () Visualize Non-Standard Basis in 2D Space We can also construct the same vector using different basis. Next, consider \\(\\v_1 = \\begin{bmatrix}2 \\\\ 1 \\end{bmatrix}\\) and \\(\\v_2 = \\begin{bmatrix}-1 \\\\ 2 \\end{bmatrix}\\) . We can verify indeed this is a basis for \\(\\mathbb{R}^2\\) . But the main point is that we can have the vector constructed by \\(2.4\\v_1 + 3.6\\v_2\\) . fig , ax = plt . subplots ( figsize = ( 10 , 10 )) v1 = np . array ([ 2 , 1 ]) v2 = np . array ([ - 1 , 2 ]) v1m2 = 2.4 * v1 v2m3 = 3.6 * v2 arrows = np . array ( [ [[ 0 , 0 , v1 [ 0 ], v1 [ 1 ]]], [[ 0 , 0 , v2 [ 0 ], v2 [ 1 ]]], [[ 0 , 0 , 2.4 * v1 [ 0 ], 2.4 * v1 [ 1 ]]], [[ 0 , 0 , 3.6 * v2 [ 0 ], 3.6 * v2 [ 1 ]]], [[ 0 , 0 , ( v1m2 + v2m3 )[ 0 ], ( v1m2 + v2m3 )[ 1 ]]], ] ) colors = [ \"r\" , \"b\" , \"r\" , \"b\" , \"g\" ] for i in range ( arrows . shape [ 0 ]): X , Y , U , V = zip ( * arrows [ i , :, :]) ax . arrow ( X [ 0 ], Y [ 0 ], U [ 0 ], V [ 0 ], color = colors [ i ], width = 0.03 , length_includes_head = True , head_width = 0.2 , # default: 3*width head_length = 0.3 , overhang = 0.4 , ) # ############################ Dashed ################################## point1 = [ v2m3 [ 0 ], v2m3 [ 1 ]] point2 = [ v2m3 [ 0 ] + v1m2 [ 0 ], v2m3 [ 1 ] + v1m2 [ 1 ]] line = np . array ([ point1 , point2 ]) ax . plot ( line [:, 0 ], line [:, 1 ], ls = \"--\" , lw = 3 , color = \"black\" , alpha = 0.5 ) point1 = [ v1m2 [ 0 ], v1m2 [ 1 ]] point2 = [ v2m3 [ 0 ] + v1m2 [ 0 ], v2m3 [ 1 ] + v1m2 [ 1 ]] line = np . array ([ point1 , point2 ]) ax . plot ( line [:, 0 ], line [:, 1 ], ls = \"--\" , lw = 3 , color = \"black\" , alpha = 0.5 ) ############################Text##################################### ax . text ( 2 , 1 , \"$v_1$\" , size = 15 ) ax . text ( - 1 , 2 , \"$v_2$\" , size = 15 ) ax . text ( v1m2 [ 0 ], v1m2 [ 1 ], \"$2.4v_1$\" , size = 15 ) ax . text ( v2m3 [ 0 ], v2m3 [ 1 ], \"$3.6v_2$\" , size = 15 ) ax . text ( v1m2 [ 0 ] + v2m3 [ 0 ], v1m2 [ 1 ] + v2m3 [ 1 ], \"$2.4v_1+3.6v_2$\" , size = 15 ) ############################## Grid ############################### t = np . linspace ( - 6 , 6 ) for k in range ( - 6 , 7 ): x = 2 * k - t y = k + 2 * t ax . plot ( x , y , ls = \"--\" , color = \"red\" , alpha = 0.3 ) for k in range ( - 6 , 7 ): x = - k + 2 * t y = 2 * k + t ax . plot ( x , y , ls = \"--\" , color = \"red\" , alpha = 0.3 ) ####################################################################### ax . set_xlabel ( \"x-axis\" , size = 18 ) ax . set_ylabel ( \"y-axis\" , size = 18 ) ax . axis ([ - 6 , 6 , 0 , 10 ]) # np.linalg.norm(v1m2+v2m3) is intercept plt . show () Visualize Standard Basis in 3D Space The following shows geometrically, how standard basis in \\(\\R^3\\) constructs a vector \\(\\begin{bmatrix}2 \\\\ 3 \\\\ 4 \\end{bmatrix}\\) . import utils utils . linearCombo ( 2 , 3 , 4 ) Visualize Non-Standard Basis in 3D Space Next we show the linear combination of a non-standard basis, \\((2,1,0), (0,3,1), (0,0,3)\\) . a , b , c = 2 , 3 , 4 vec1 = np . array ([ 2 , 1 , 0 ]) vec2 = np . array ([ 0 , 3 , 1 ]) vec3 = np . array ([ 1 , 2 , 3 ]) utils . linearComboNonStd ( 2 , 3 , 4 , vec1 , vec2 , vec3 ) Theorem (Criterion for Basis and Unique Representation of Basis) Here we state another way of checking if a set \\(\\B \\subseteq V\\) is a basis of \\(V\\) . One can ignore the third condition (out of scope!). Let \\(\\B = \\{\\b_1, \\cdots,\\b_n\\}\\) and in particular \\(\\b_i \\neq \\0\\) . Let \\(\\B\\) be a finite subset of a vector space \\(V\\) over a field \\(\\F\\) . Then the following are equivalent. i) \\(\\B\\) is a basis of \\(V\\) \\(\\iff\\) ii) Unique expression condition: Every vector \\(\\v \\in V\\) can be expressed as \\[\\v = a_1\\b_1+ \\cdots +a_n\\b_n\\] for some scalars \\(a_i \\in \\F\\) and such expression of \\(\\v\\) is unique. That means whenever \\(\\v = b_1\\b_1+ \\cdots + b_n\\b_n\\) for some scalars \\(b_i \\in \\F\\) , we have \\(a_i = b_i\\) . \\(\\iff\\) iii) \\(V\\) has the following direct sum decomposition: \\[V = \\text{Span}\\{\\b_1\\} \\oplus ... \\oplus \\text{Span}\\{\\b_n\\} = \\F \\b_1 \\oplus ... \\oplus \\F\\b_n\\] Proof To prove three equivalent statements, we can simply do a round-cycle proof: \\(1 \\implies 2 \\implies 3 \\implies 1\\) will complete all \\(\\iff\\) proofs. \\((1) \\implies (2)\\) \\(B = \\{\\mathbf{v_{1}, \\cdots, v_{n}}\\}\\) finite subset of \\(V\\) . Suppose \\(\\B\\) is basis of \\(V\\) . Then pick any \\(\\v \\in V\\) and suppose we can write \\(\\v\\) in two ways. \\[\\begin{eqnarray} \\v = a_{1}\\v_1 + \\cdots a_{n}\\mathbf{v_{n}} \\\\ \\v = a_{1}^{'}\\v_1 + \\cdots a_{n}^{'}\\mathbf{v_{n}} \\end{eqnarray}\\] Equations. (1) and (2) imply \\((a_{1} - a_{1}^{'}) \\v_{1} + \\cdots (a_{n} - a_{n}^{'})\\v_{n} = 0\\) and since \\(\\B\\) is L.I set, it only has trivial solutions. Hence \\(a_{1} - a_{1}^{'} = 0\\) \\(\\forall i\\) implying \\(a_{i} = a_{i}^{'}\\) . Hence \\(\\v\\) has unique way of expressing. \\((2) \\implies (3)\\) Show first that \\(V = \\text{span}(\\{\\v_1\\}) + \\cdots \\text{span}(\\{\\mathbf{v_{n}}\\})\\) . \\(\\text{span}(\\{\\v_1\\}) + \\cdots \\text{span}(\\{\\mathbf{v_{n}}\\}) \\subseteq V\\) is obvious. We show \\(V \\subseteq \\text{span}(\\{\\v_1\\}) + \\cdots \\text{span}(\\{\\mathbf{v_{n}}\\})\\) . Let \\(\\v \\in V\\) , by hypothesis, \\[\\v = a_{1}\\v_1 + \\cdots a_{n}\\mathbf{v_{n}} \\in \\text{span}(\\{\\v_1\\})+ \\cdots + \\text{span}(\\{\\mathbf{v_{n}}\\})\\] Hence: \\[V = \\text{span}(\\{\\v_1\\})+ \\cdots + \\text{span}(\\{\\mathbf{v_{n}}\\})\\] Now we show it is direct sum. Denote \\(W_{i} = \\text{span}(\\{\\mathbf{v_{i}}\\})\\) . Suppose not, \\(\\exists x \\in \\sum\\limits_{i=1}^{k-1}W_{i} \\cap W_{k}\\) for some \\(2 \\le k \\le n\\) and \\(x \\neq 0\\) . Then $ x = \\mathbf{w_{1} + \\cdots + w_{k-1}}$ for some \\(\\mathbf{w_{i}} \\in W_{i}\\) and \\(x = -\\mathbf{w_{k}}\\) for some \\(-\\mathbf{w_{k}} \\in W_{k}\\) . But since \\(x\\) is uniquely expressed. \\begin{eqnarray} x & = & \\w_1+\\w_2+...+\\w_{k-1} \\ x & = & -\\w_k \\end{eqnarray} implying that \\[0 =\\w_1+\\w_2+...+\\w_k\\] By uniqueness \\(0 = 0 + 0 \\cdots + 0\\) , but that would means \\(\\w_1=\\w_2=...= \\w_k =0\\) , implying \\(x = 0\\) , a contradiction. \\((3) \\implies (1)\\) Want to show \\(B\\) is a basis of \\(V\\) . By hypothesis, \\begin{eqnarray} V & = & \\text{span}({\\v_{1}}) + \\cdots + \\text{span}({\\v_{n}})\\nonumber\\ & = & \\text{span}({\\v_{1}} \\cup {\\v_{2}} \\cup \\cdots \\cup {\\v_{n}}) \\nonumber \\ & = & \\text{span}({\\v_{1}, \\v_{2}, \\cdots, \\v_{n}})\\nonumber \\end{eqnarray} Now we show \\(B\\) is L.I. That is \\(a_{1}\\v_{1} + \\cdots + a_{n}\\v_{n}\\) has trivial solution. Suppose not, say \\(a_{k} \\ne 0\\) , and such that \\(\\v_{k} = b_{1}\\v_{1} + \\cdots b_{k-1}\\v_{k-1} + \\cdots + b_{n}\\v_{n}\\) where \\(b : = \\frac{-a_{i}}{a_{k}}\\) . This is contradiction as \\(\\v_{k} \\in W_{k}\\) and \\(b_{1}\\v_{1} \\cdots b_{n}\\v_{n} \\in \\sum\\limits_{i \\ne k} W_{i}\\) . Thus \\(\\v_{k} \\in \\sum\\limits_{i \\ne k}W_{i}\\cap W_{k}\\) and \\(\\v_{k} \\ne 0\\) is our assumption. This contradicts direct sum. Hence \\(\\B\\) is LI. Theorem (All Basis has the same length) This theorem states that all basis of a vector space \\(V\\) has the same length. This theorem is important to faciliate the definition of Dimension. Dimensions We have encountered the term Dimension at the start of Vector Spaces . Now, we give it a formal definition. Definition (Dimension) If a vector space \\(V\\) has a basis \\(\\B\\) with cardinality \\[|B| = n < \\infty\\] then we say that \\(V\\) is finite dimensional and define the dimension \\[\\text{dim}_{\\F}V = |B|\\] Otherwise, \\(V\\) is called infinite dimensional. Note that we implicitly assumed that all basis \\(\\B\\) has the same cardinality, which we showed as a theorem previously. Notation (Dimension) We denote the dimension of a finite vector space \\(V\\) to be \\[\\dim(V)\\] Intuition (Dimension) One may wonder why the definition of Dimension depends on the basis . Why can't we just define the dimension of a vector space \\(V\\) over a field \\(\\F^n\\) to be just the length of the element \\(\\v \\in V\\) , which is just \\(n\\) . This is a reasonable assumption, and both turns out to be equivalent. That is, the length of any element \\(\\v \\in V\\) over a field \\(\\F^n\\) is the same as the number of basis \\(\\B\\) that a vector space \\(V\\) has. We can easily think of it geometrically. Consider the 2d space \\(\\R^2\\) , we know that any element in \\(\\R^2\\) must have 2 elements and in our earlier definition, the dimension of such a space is 2. Now we understood basis, and know that we need 2 linearly independent vectors to make up the 2d space. Same logic applies to the 3d space \\(\\R^3\\) . Example (Dimension) R2 and R3 Dimensions i) Besides \\(\\{\\mathbf{0}\\}\\) and \\(\\mathbb{R}^2\\) , all subspaces of \\(\\mathbb{R}^2\\) are lines through the origin and they are of dimension \\(1\\) . (Basis of the subspaces has only one vector) ii) Besides \\(\\{\\mathbf{0}\\}\\) and \\(\\mathbb{R}^3\\) , all subspaces of \\(\\mathbb{R}^3\\) are either lines through the origin and they are of dimension \\(1\\) or planes containing the origin, which are of dimension \\(2\\) . (Basis of the subspaces has only one vector or two vectors) Theorem (Dimension of a Subspace) If \\(V\\) is a finite dimensional vector space and \\(U\\) is a subspace of \\(V\\) , then \\(\\dim(U) \\leq \\dim(V)\\) . Proof This should not even come as a surprise after the previous example. It also makes sense geometrically as a subspace \\(U\\) , is also a subset of \\(V\\) , and hence cannot \"be larger\" than its \"parent\". Prove it and check pp.45 of linear algebra done right. Basis and Dimension Theorems and Applications Theorem (Spanning Set contains Basis) A spanning set \\(S\\) (note we do not know if this is a basis or not yet) in vector space \\(V\\) necessarily contains the basis \\(\\B\\) . Proof First, intuitively we already know that the set \\(S\\) spans \\(V\\) and we acknowledge that a set \\(S\\) spanning the vector space \\(V\\) can be a linearly dependent set (refer to example (different sets can span the same vector space)). Therefore, we just need to \"remove\" the linearly dependent vectors in the set \\(S\\) so that the remaining set \\(\\B \\subseteq S\\) is both linearly independent and spans V , consequently, \\(\\B\\) is a basis of \\(V\\) . Theorem (Every Subspace has a Basis) Every finite subspace \\(V\\) has a basis \\(\\B\\) . Proof Every finite subspace can be represented by a span of a set of vectors. By Theorem (Spanning Set contains Basis) , this spanning set has a basis. Theorem (Linear Independent Sets can be extended to a Basis) Let \\(B\\) be a Linearly Independent subset of a vector space \\(V\\) over a field \\(\\F\\) . Then exactly one of the following two cases is true. i) \\(B\\) spans \\(V\\) and hence \\(B\\) is a basis of \\(V\\) . ii) Let \\(\\v \\in V \\setminus \\text{Span}(B)\\) and hence \\(\\v \\not \\in B\\) . Then \\(B \\cup \\{\\v\\}\\) is an Linearly Independent subset of \\(V\\) . iii) In particular, if \\(V\\) is of finite dimension \\(n\\) , then one can find \\(n - |B|\\) vectors \\(\\mathbf{v_{|B|+1},...,v_n}\\) in \\(V \\setminus \\text{Span}(B)\\) such that \\(B \\coprod \\{\\mathbf{v_{|B|+1},...,v_n} \\}\\) is a basis of \\(V\\) . Proof Since \\(B\\) is L.I subset of \\(V\\) , then \\(B\\) either spans \\(V\\) or do not span \\(V\\) . If it spans \\(V\\) , then \\(B\\) is a basis, which is point i). If its doesn't span \\(V\\) , take an element \\(\\w \\in V \\setminus \\text{span}(B)\\) , \\(\\w \\notin B\\) and \\(\\mathbf{w} \\notin \\text{span}(B)\\) . Then it means \\(\\mathbf{w}\\) is not a linear combination of any elements in \\(B\\) . Hence, \\(B \\cup \\{\\w\\}\\) is a L.I set as no elements in \\(B \\cup\\{\\w\\}\\) can be expressed as a LC of each other. Note if \\(B = \\{\\v_{1}, \\v_{2}, \\cdots \\v_{r}\\}, ~ B\\cup \\{\\w\\} = \\{\\v_{1}, \\cdots \\v_{r}, \\w\\}\\) . $ \\v_{i} \\ne \\w$. For point 3, this means if \\(B\\) is LI in \\(V\\) , then \\(B\\) can only have 2 cases. If Case 1 occurs, we are done as $ n - |B| = n- n = 0$, we do not need any more vectors in \\(V \\setminus \\text{span}(B)\\) to union with \\(B\\) . If Case 2 occurs, Then let \\(|B| = r\\) . then \\(\\exists \\mathbf{w_{r+1}} \\in V \\setminus \\text{span}(B)\\) s.t \\(B \\cup \\{\\mathbf{w_{r+1}}\\}\\) is L.I set. Applying the two cases to \\(B \\cup \\{\\mathbf{w_{r+1}}\\}\\) , we will have \\(B \\cup \\{\\mathbf{w_{r+1}}\\}\\) be a basis or \\(B \\cup \\{\\mathbf{w_{r+1}, w_{r+2}}\\}\\) is another L.I set. Since the dimension of \\(V\\) is \\(n\\) . Then applying this expansion inductively, \\(B \\cup \\{\\mathbf{w_{r+1}, \\cdots w_{n}}\\}\\) will eventually form a basis for \\(V\\) . If for a contradiction the case 2 continues after \\(\\mathbf{w_{n}}\\) then it contradicts the fact that a set with more than \\(n\\) vectors cannot be L.I. Theorem (Equivalent Basis Definition) Let \\(B\\) be a subset of a vector space \\(V\\) of finite dimension \\(\\text{dim}_{\\F}V = n \\geq 1\\) . Then the following are equivalent. i) \\(B\\) is a basis of \\(V\\) . ii) \\(B\\) is \\(L.I\\) and \\(|B| = n\\) . iii) \\(B\\) spans \\(V\\) and \\(|B| = n\\) . Proof We prove \\(i \\Leftrightarrow ii\\) and \\(i \\Leftrightarrow iii\\) . Now \\(i \\Rightarrow ii\\) and \\(i \\Rightarrow iii\\) are by definition. iii \\(\\Rightarrow\\) i Since \\(V = \\text{Span}(B)\\) , there exists a subset \\(B_1\\) of \\(B\\) such that \\(B_1\\) is a basis of \\(V\\) . But by our hypothesis, we have \\(|B| = n\\) . Since \\(B_1\\) is basis of \\(V\\) , we must have \\(|B_1| =\\) dimension of \\(V\\) which is \\(n\\) . And hence \\(|B_1| = |B|\\) . Since, \\(B_1 \\subseteq B\\) , and \\(|B_1| = |B|\\) , we must have \\(B_1 = B\\) as a set. Hence \\(B\\) is a basis of \\(V\\) . Alternatively, suppose \\(B\\) is not a basis of \\(V\\) . \\(B\\) is not linearly independent. Take a vector \\(\\v\\) in \\(B\\) which is a linear combination of other vectors in \\(B\\) . Then we know that \\(B - \\v\\) still spans \\(V\\) . But \\(|B-\\v| = n-1\\) by our hypothesis. And it is a contradiction since it is a subset of \\(V\\) with less than \\(n\\) vectors, hence it cannot span \\(V\\) . It is a contradiction. ii \\(\\Rightarrow\\) i Suppose that \\(B\\) is not a basis of \\(V\\) . Then \\(B\\) does not span \\(V\\) . Pick a vector \\(\\v\\) in \\(V\\) but not in Span \\((B)\\) (there exists such a vector because we say that \\(B\\) does not span \\(V\\) ) and \\(B \\cup \\{\\v\\}\\) is still a linearly independent set given that \\(B\\) is a linearly independent set. Hence it is a contradiction because \\(|B \\cup \\{\\v\\}| = n+1\\) has more vectors than even the basis set, hence it cannot be linearly independent. Useful Summary Let \\(V\\) be a vector space which has a basis \\(B\\) with \\(k\\) vectors. Then any subset \\(W\\) of \\(V\\) with more than \\(k\\) vectors is always linearly dependent. So it means if any subset \\(W\\) of \\(V\\) is linearly independent, then \\(W\\) will have less or equals to \\(k\\) vectors, in which directly translates to the dimension of \\(W\\) is less or equals to the dimension of \\(V\\) . Any subset \\(W\\) of \\(V\\) with less than \\(k\\) vectors cannot span \\(V\\) . So for any subset \\(W\\) of \\(V\\) which spans \\(V\\) , then it will have more or equals to \\(k\\) vectors. In particular, let \\(W = \\{\\w_1,...,\\w_k\\}\\) be a set of vectors in \\(V = \\mathbb{R}^n\\) . If \\(k < n\\) , then \\(S\\) cannot span \\(\\mathbb{R}^n\\) . Suppose that \\(C\\) is another basis of \\(V\\) , then \\(|B|=|C|\\) . Applications of Basis Efficient Space Storage Storing data efficiently in this era is very important. Let's give a superfluous example: Let \\(\\A\\) be a \\(3 \\times 100\\) matrix where there are 3 features and 100 samples; and if we know that the columns of the matrix has a basis \\(\\B\\) , say \\[\\B = \\left\\{\\begin{bmatrix}1 \\\\ 0 \\\\ 0\\end{bmatrix} ,\\quad \\begin{bmatrix}0 \\\\ 0 \\\\ 1 \\end{bmatrix} ,\\quad \\begin{bmatrix} 0 \\\\ 0 \\\\ 1\\end{bmatrix}\\right\\}\\] But we know that all 100 columns of \\(\\A\\) can be reconstructed using the basis vectors; i.e. for each column \\(\\a_i\\) of \\(\\A\\) , there exists constants \\(\\lambda_i\\) such that \\[\\a_i = \\lambda_1 \\B_1 + \\lambda_2 \\B_2 + \\lambda_3 \\B_3\\] As a result, we can effectively store the 3 basis vectors (9 elements and note that the 3 basis vectors can be taken from the columns of \\(\\A\\) ); the remaining 7 columns we just need \\(7 \\times 3 = 21\\) constants so that we can recover the columns using linear combination of the basis vectors. In total, we reduced the space from \\(3 \\times 100 = 300\\) elements to \\(3 \\times 3 + 7 \\times 3 = 30\\) elements, effectively 70 percent decrease. Macro Analyst Linear Algebra \u21a9 Such as the real numbers \\(\\R\\) or the complex numbers \\(\\mathbb{C}\\) . \u21a9 https://math.stackexchange.com/questions/3089880/minimal-generating-set \u21a9","title":"Basis and Dimension"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#basis","text":"","title":"Basis"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#disclaimer","text":"I believe learning linear algebra needs some geometrical intuition, after looking around, I finally chanced upon this GitHub repo with nice python code to plot basis vectors. We will use his code below to visualize basis vectors in this section. Please visit his repo here 1 .","title":"Disclaimer"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#algebraic-definition-basis","text":"A basis \\(\\B\\) of a vector space \\(V\\) over a field \\(\\F\\) 2 is a linearly independent subset of \\(V\\) that spans \\(V\\) . This means that a subset \\(\\B\\) of \\(V\\) is a basis if it satisfies the two following conditions: the linear independence property: The set of vectors \\(\\b_1, \\b_2, ..., \\b_n \\in V\\) is linearly independent if and only if the only solution to the equation \\(a_1\\mathbf{v}_1 + a_2\\mathbf{v}_2 + \\cdots + a_m\\mathbf{v}_n = \\mathbf{0}\\) is the trivial solution, the zero vector; and the spanning property: Define \\(\\B = \\{\\b_1, \\b_2, ..., \\b_m\\}\\) in \\(V\\) , and the linear combination of all the vectors \\(\\b_1, \\b_2, \\cdots, \\b_n\\) make up the main vector space \\(V\\) ; i.e. \\(\\textbf{span}(B) = V\\) .","title":"Algebraic Definition (Basis)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#minimal-generating-set","text":"We won't go through the formal definition, but rather a motivating example from Math Stack Exchange 3 . You can think about it as the idea from linear algebra of a basis for a space compared to a set of vectors which span the space. A basis is a set of linearly independent elements, where removing one of the elements would result in it being unable to generate every element in that space. In other words, you can think of a minimal generating set as a basis for the group, which has no redundant elements while a generating set may have redundant elements. For example, to generate \\(\\mathbb R^3\\) we have a basis \\(\\begin{bmatrix}1\\\\0\\\\0\\end{bmatrix}, \\begin{bmatrix}0\\\\1\\\\0\\end{bmatrix}, \\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix}\\) (a minimal generating set), but this space is still generated by the set of vectors \\(\\begin{bmatrix}1\\\\0\\\\0\\end{bmatrix}, \\begin{bmatrix}0\\\\1\\\\0\\end{bmatrix}, \\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix}, \\begin{bmatrix}0\\\\0\\\\3\\end{bmatrix}\\) (a generating set).","title":"Minimal Generating Set"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#geometric-definition-basis","text":"Note Geometric understanding of basis is best understood with examples!","title":"Geometric Definition (Basis)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#examples-basis","text":"","title":"Examples (Basis)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#examples-standard-basis","text":"Every space \\(\\R^n\\) has a standard basis . \\[\\e = \\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1}\\end{bmatrix} \\right\\}\\] is the standard basis for the \\(\\R^2\\) space; and for \\(\\R^3\\) : \\[\\e = \\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1} \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{0} \\\\ \\color{red}1 \\end{bmatrix} \\right\\}\\] and we usually denote \\[\\e_1 = \\begin{bmatrix} \\color{red}1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} \\quad \\e_2 = \\begin{bmatrix} \\color{red}0 \\\\ 1 \\\\ \\vdots \\\\0 \\end{bmatrix} \\quad \\e_n = \\begin{bmatrix} \\color{red}0 \\\\ 0 \\\\ \\vdots \\\\ 1 \\end{bmatrix}\\] and so on.","title":"Examples (Standard Basis)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#visualize-standard-basis-in-2d-space","text":"Consider a vector \\(\\v = \\begin{bmatrix}\\color{red}3 \\\\ \\color{red}6\\end{bmatrix}\\) . We can construct this vector using our standard basis \\(\\e_1, \\e_2\\) as \\(3\\e_1 + 6\\e_2\\) , as shown below. import matplotlib.pyplot as plt import numpy as np fig , ax = plt . subplots ( figsize = ( 10 , 10 )) arrows = np . array ( [ [[ 0 , 0 , 1 , 0 ]], [[ 0 , 0 , 0 , 1 ]], [[ 0 , 0 , 3 , 0 ]], [[ 0 , 0 , 0 , 6 ]], [[ 0 , 0 , 3 , 6 ]], ] ) colors = [ \"r\" , \"b\" , \"r\" , \"b\" , \"g\" ] for i in range ( arrows . shape [ 0 ]): X , Y , U , V = zip ( * arrows [ i , :, :]) ax . arrow ( X [ 0 ], Y [ 0 ], U [ 0 ], V [ 0 ], color = colors [ i ], width = 0.03 , length_includes_head = True , head_width = 0.2 , # default: 3*width head_length = 0.3 , overhang = 0.4 , ) ############################Dashed################################## line1 = np . array ([[ 3 , 0 ], [ 3 , 6 ]]) ax . plot ( line1 [:, 0 ], line1 [:, 1 ], ls = \"--\" , lw = 3 , color = \"black\" , alpha = 0.5 ) line2 = np . array ([[ 0 , 6 ], [ 3 , 6 ]]) ax . plot ( line2 [:, 0 ], line2 [:, 1 ], ls = \"--\" , lw = 3 , color = \"black\" , alpha = 0.5 ) ############################Text##################################### ax . text ( 0 , 1 , \"$e_2$\" , size = 15 ) ax . text ( 1 , 0 , \"$e_1$\" , size = 15 ) ax . text ( 0 , 6 , \"$6e_2$\" , size = 15 ) ax . text ( 3 , 0 , \"$3e_1$\" , size = 15 ) ax . text ( 3 , 6 , \"$3e_1+6e_2$\" , size = 15 ) ###########################Grid Setting############################## # Major ticks every 20, minor ticks every 5 major_ticks = np . arange ( 0 , 10 , 2 ) minor_ticks = np . arange ( 0 , 10 , 0.5 ) ax . set_xticks ( major_ticks ) ax . set_xticks ( minor_ticks , minor = True ) ax . set_yticks ( major_ticks ) ax . set_yticks ( minor_ticks , minor = True ) ax . grid ( which = \"both\" ) ax . grid ( which = \"minor\" , alpha = 0.2 ) ax . grid ( which = \"major\" , alpha = 0.5 ) ####################################################################### ax . set_xlabel ( \"x-axis\" , size = 18 ) ax . set_ylabel ( \"y-axis\" , size = 18 ) ax . axis ([ - 1 , 10 , - 1 , 10 ]) ax . grid () plt . show ()","title":"Visualize Standard Basis in 2D Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#visualize-non-standard-basis-in-2d-space","text":"We can also construct the same vector using different basis. Next, consider \\(\\v_1 = \\begin{bmatrix}2 \\\\ 1 \\end{bmatrix}\\) and \\(\\v_2 = \\begin{bmatrix}-1 \\\\ 2 \\end{bmatrix}\\) . We can verify indeed this is a basis for \\(\\mathbb{R}^2\\) . But the main point is that we can have the vector constructed by \\(2.4\\v_1 + 3.6\\v_2\\) . fig , ax = plt . subplots ( figsize = ( 10 , 10 )) v1 = np . array ([ 2 , 1 ]) v2 = np . array ([ - 1 , 2 ]) v1m2 = 2.4 * v1 v2m3 = 3.6 * v2 arrows = np . array ( [ [[ 0 , 0 , v1 [ 0 ], v1 [ 1 ]]], [[ 0 , 0 , v2 [ 0 ], v2 [ 1 ]]], [[ 0 , 0 , 2.4 * v1 [ 0 ], 2.4 * v1 [ 1 ]]], [[ 0 , 0 , 3.6 * v2 [ 0 ], 3.6 * v2 [ 1 ]]], [[ 0 , 0 , ( v1m2 + v2m3 )[ 0 ], ( v1m2 + v2m3 )[ 1 ]]], ] ) colors = [ \"r\" , \"b\" , \"r\" , \"b\" , \"g\" ] for i in range ( arrows . shape [ 0 ]): X , Y , U , V = zip ( * arrows [ i , :, :]) ax . arrow ( X [ 0 ], Y [ 0 ], U [ 0 ], V [ 0 ], color = colors [ i ], width = 0.03 , length_includes_head = True , head_width = 0.2 , # default: 3*width head_length = 0.3 , overhang = 0.4 , ) # ############################ Dashed ################################## point1 = [ v2m3 [ 0 ], v2m3 [ 1 ]] point2 = [ v2m3 [ 0 ] + v1m2 [ 0 ], v2m3 [ 1 ] + v1m2 [ 1 ]] line = np . array ([ point1 , point2 ]) ax . plot ( line [:, 0 ], line [:, 1 ], ls = \"--\" , lw = 3 , color = \"black\" , alpha = 0.5 ) point1 = [ v1m2 [ 0 ], v1m2 [ 1 ]] point2 = [ v2m3 [ 0 ] + v1m2 [ 0 ], v2m3 [ 1 ] + v1m2 [ 1 ]] line = np . array ([ point1 , point2 ]) ax . plot ( line [:, 0 ], line [:, 1 ], ls = \"--\" , lw = 3 , color = \"black\" , alpha = 0.5 ) ############################Text##################################### ax . text ( 2 , 1 , \"$v_1$\" , size = 15 ) ax . text ( - 1 , 2 , \"$v_2$\" , size = 15 ) ax . text ( v1m2 [ 0 ], v1m2 [ 1 ], \"$2.4v_1$\" , size = 15 ) ax . text ( v2m3 [ 0 ], v2m3 [ 1 ], \"$3.6v_2$\" , size = 15 ) ax . text ( v1m2 [ 0 ] + v2m3 [ 0 ], v1m2 [ 1 ] + v2m3 [ 1 ], \"$2.4v_1+3.6v_2$\" , size = 15 ) ############################## Grid ############################### t = np . linspace ( - 6 , 6 ) for k in range ( - 6 , 7 ): x = 2 * k - t y = k + 2 * t ax . plot ( x , y , ls = \"--\" , color = \"red\" , alpha = 0.3 ) for k in range ( - 6 , 7 ): x = - k + 2 * t y = 2 * k + t ax . plot ( x , y , ls = \"--\" , color = \"red\" , alpha = 0.3 ) ####################################################################### ax . set_xlabel ( \"x-axis\" , size = 18 ) ax . set_ylabel ( \"y-axis\" , size = 18 ) ax . axis ([ - 6 , 6 , 0 , 10 ]) # np.linalg.norm(v1m2+v2m3) is intercept plt . show ()","title":"Visualize Non-Standard Basis in 2D Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#visualize-standard-basis-in-3d-space","text":"The following shows geometrically, how standard basis in \\(\\R^3\\) constructs a vector \\(\\begin{bmatrix}2 \\\\ 3 \\\\ 4 \\end{bmatrix}\\) . import utils utils . linearCombo ( 2 , 3 , 4 )","title":"Visualize Standard Basis in 3D Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#visualize-non-standard-basis-in-3d-space","text":"Next we show the linear combination of a non-standard basis, \\((2,1,0), (0,3,1), (0,0,3)\\) . a , b , c = 2 , 3 , 4 vec1 = np . array ([ 2 , 1 , 0 ]) vec2 = np . array ([ 0 , 3 , 1 ]) vec3 = np . array ([ 1 , 2 , 3 ]) utils . linearComboNonStd ( 2 , 3 , 4 , vec1 , vec2 , vec3 )","title":"Visualize Non-Standard Basis in 3D Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#theorem-criterion-for-basis-and-unique-representation-of-basis","text":"Here we state another way of checking if a set \\(\\B \\subseteq V\\) is a basis of \\(V\\) . One can ignore the third condition (out of scope!). Let \\(\\B = \\{\\b_1, \\cdots,\\b_n\\}\\) and in particular \\(\\b_i \\neq \\0\\) . Let \\(\\B\\) be a finite subset of a vector space \\(V\\) over a field \\(\\F\\) . Then the following are equivalent. i) \\(\\B\\) is a basis of \\(V\\) \\(\\iff\\) ii) Unique expression condition: Every vector \\(\\v \\in V\\) can be expressed as \\[\\v = a_1\\b_1+ \\cdots +a_n\\b_n\\] for some scalars \\(a_i \\in \\F\\) and such expression of \\(\\v\\) is unique. That means whenever \\(\\v = b_1\\b_1+ \\cdots + b_n\\b_n\\) for some scalars \\(b_i \\in \\F\\) , we have \\(a_i = b_i\\) . \\(\\iff\\) iii) \\(V\\) has the following direct sum decomposition: \\[V = \\text{Span}\\{\\b_1\\} \\oplus ... \\oplus \\text{Span}\\{\\b_n\\} = \\F \\b_1 \\oplus ... \\oplus \\F\\b_n\\]","title":"Theorem (Criterion for Basis and Unique Representation of Basis)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#proof","text":"To prove three equivalent statements, we can simply do a round-cycle proof: \\(1 \\implies 2 \\implies 3 \\implies 1\\) will complete all \\(\\iff\\) proofs. \\((1) \\implies (2)\\) \\(B = \\{\\mathbf{v_{1}, \\cdots, v_{n}}\\}\\) finite subset of \\(V\\) . Suppose \\(\\B\\) is basis of \\(V\\) . Then pick any \\(\\v \\in V\\) and suppose we can write \\(\\v\\) in two ways. \\[\\begin{eqnarray} \\v = a_{1}\\v_1 + \\cdots a_{n}\\mathbf{v_{n}} \\\\ \\v = a_{1}^{'}\\v_1 + \\cdots a_{n}^{'}\\mathbf{v_{n}} \\end{eqnarray}\\] Equations. (1) and (2) imply \\((a_{1} - a_{1}^{'}) \\v_{1} + \\cdots (a_{n} - a_{n}^{'})\\v_{n} = 0\\) and since \\(\\B\\) is L.I set, it only has trivial solutions. Hence \\(a_{1} - a_{1}^{'} = 0\\) \\(\\forall i\\) implying \\(a_{i} = a_{i}^{'}\\) . Hence \\(\\v\\) has unique way of expressing. \\((2) \\implies (3)\\) Show first that \\(V = \\text{span}(\\{\\v_1\\}) + \\cdots \\text{span}(\\{\\mathbf{v_{n}}\\})\\) . \\(\\text{span}(\\{\\v_1\\}) + \\cdots \\text{span}(\\{\\mathbf{v_{n}}\\}) \\subseteq V\\) is obvious. We show \\(V \\subseteq \\text{span}(\\{\\v_1\\}) + \\cdots \\text{span}(\\{\\mathbf{v_{n}}\\})\\) . Let \\(\\v \\in V\\) , by hypothesis, \\[\\v = a_{1}\\v_1 + \\cdots a_{n}\\mathbf{v_{n}} \\in \\text{span}(\\{\\v_1\\})+ \\cdots + \\text{span}(\\{\\mathbf{v_{n}}\\})\\] Hence: \\[V = \\text{span}(\\{\\v_1\\})+ \\cdots + \\text{span}(\\{\\mathbf{v_{n}}\\})\\] Now we show it is direct sum. Denote \\(W_{i} = \\text{span}(\\{\\mathbf{v_{i}}\\})\\) . Suppose not, \\(\\exists x \\in \\sum\\limits_{i=1}^{k-1}W_{i} \\cap W_{k}\\) for some \\(2 \\le k \\le n\\) and \\(x \\neq 0\\) . Then $ x = \\mathbf{w_{1} + \\cdots + w_{k-1}}$ for some \\(\\mathbf{w_{i}} \\in W_{i}\\) and \\(x = -\\mathbf{w_{k}}\\) for some \\(-\\mathbf{w_{k}} \\in W_{k}\\) . But since \\(x\\) is uniquely expressed. \\begin{eqnarray} x & = & \\w_1+\\w_2+...+\\w_{k-1} \\ x & = & -\\w_k \\end{eqnarray} implying that \\[0 =\\w_1+\\w_2+...+\\w_k\\] By uniqueness \\(0 = 0 + 0 \\cdots + 0\\) , but that would means \\(\\w_1=\\w_2=...= \\w_k =0\\) , implying \\(x = 0\\) , a contradiction. \\((3) \\implies (1)\\) Want to show \\(B\\) is a basis of \\(V\\) . By hypothesis, \\begin{eqnarray} V & = & \\text{span}({\\v_{1}}) + \\cdots + \\text{span}({\\v_{n}})\\nonumber\\ & = & \\text{span}({\\v_{1}} \\cup {\\v_{2}} \\cup \\cdots \\cup {\\v_{n}}) \\nonumber \\ & = & \\text{span}({\\v_{1}, \\v_{2}, \\cdots, \\v_{n}})\\nonumber \\end{eqnarray} Now we show \\(B\\) is L.I. That is \\(a_{1}\\v_{1} + \\cdots + a_{n}\\v_{n}\\) has trivial solution. Suppose not, say \\(a_{k} \\ne 0\\) , and such that \\(\\v_{k} = b_{1}\\v_{1} + \\cdots b_{k-1}\\v_{k-1} + \\cdots + b_{n}\\v_{n}\\) where \\(b : = \\frac{-a_{i}}{a_{k}}\\) . This is contradiction as \\(\\v_{k} \\in W_{k}\\) and \\(b_{1}\\v_{1} \\cdots b_{n}\\v_{n} \\in \\sum\\limits_{i \\ne k} W_{i}\\) . Thus \\(\\v_{k} \\in \\sum\\limits_{i \\ne k}W_{i}\\cap W_{k}\\) and \\(\\v_{k} \\ne 0\\) is our assumption. This contradicts direct sum. Hence \\(\\B\\) is LI.","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#theorem-all-basis-has-the-same-length","text":"This theorem states that all basis of a vector space \\(V\\) has the same length. This theorem is important to faciliate the definition of Dimension.","title":"Theorem (All Basis has the same length)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#dimensions","text":"We have encountered the term Dimension at the start of Vector Spaces . Now, we give it a formal definition.","title":"Dimensions"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#definition-dimension","text":"If a vector space \\(V\\) has a basis \\(\\B\\) with cardinality \\[|B| = n < \\infty\\] then we say that \\(V\\) is finite dimensional and define the dimension \\[\\text{dim}_{\\F}V = |B|\\] Otherwise, \\(V\\) is called infinite dimensional. Note that we implicitly assumed that all basis \\(\\B\\) has the same cardinality, which we showed as a theorem previously.","title":"Definition (Dimension)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#notation-dimension","text":"We denote the dimension of a finite vector space \\(V\\) to be \\[\\dim(V)\\]","title":"Notation (Dimension)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#intuition-dimension","text":"One may wonder why the definition of Dimension depends on the basis . Why can't we just define the dimension of a vector space \\(V\\) over a field \\(\\F^n\\) to be just the length of the element \\(\\v \\in V\\) , which is just \\(n\\) . This is a reasonable assumption, and both turns out to be equivalent. That is, the length of any element \\(\\v \\in V\\) over a field \\(\\F^n\\) is the same as the number of basis \\(\\B\\) that a vector space \\(V\\) has. We can easily think of it geometrically. Consider the 2d space \\(\\R^2\\) , we know that any element in \\(\\R^2\\) must have 2 elements and in our earlier definition, the dimension of such a space is 2. Now we understood basis, and know that we need 2 linearly independent vectors to make up the 2d space. Same logic applies to the 3d space \\(\\R^3\\) .","title":"Intuition (Dimension)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#example-dimension","text":"R2 and R3 Dimensions i) Besides \\(\\{\\mathbf{0}\\}\\) and \\(\\mathbb{R}^2\\) , all subspaces of \\(\\mathbb{R}^2\\) are lines through the origin and they are of dimension \\(1\\) . (Basis of the subspaces has only one vector) ii) Besides \\(\\{\\mathbf{0}\\}\\) and \\(\\mathbb{R}^3\\) , all subspaces of \\(\\mathbb{R}^3\\) are either lines through the origin and they are of dimension \\(1\\) or planes containing the origin, which are of dimension \\(2\\) . (Basis of the subspaces has only one vector or two vectors)","title":"Example (Dimension)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#theorem-dimension-of-a-subspace","text":"If \\(V\\) is a finite dimensional vector space and \\(U\\) is a subspace of \\(V\\) , then \\(\\dim(U) \\leq \\dim(V)\\) .","title":"Theorem (Dimension of a Subspace)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#proof_1","text":"This should not even come as a surprise after the previous example. It also makes sense geometrically as a subspace \\(U\\) , is also a subset of \\(V\\) , and hence cannot \"be larger\" than its \"parent\". Prove it and check pp.45 of linear algebra done right.","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#basis-and-dimension-theorems-and-applications","text":"","title":"Basis and Dimension Theorems and Applications"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#theorem-spanning-set-contains-basis","text":"A spanning set \\(S\\) (note we do not know if this is a basis or not yet) in vector space \\(V\\) necessarily contains the basis \\(\\B\\) .","title":"Theorem (Spanning Set contains Basis)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#proof_2","text":"First, intuitively we already know that the set \\(S\\) spans \\(V\\) and we acknowledge that a set \\(S\\) spanning the vector space \\(V\\) can be a linearly dependent set (refer to example (different sets can span the same vector space)). Therefore, we just need to \"remove\" the linearly dependent vectors in the set \\(S\\) so that the remaining set \\(\\B \\subseteq S\\) is both linearly independent and spans V , consequently, \\(\\B\\) is a basis of \\(V\\) .","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#theorem-every-subspace-has-a-basis","text":"Every finite subspace \\(V\\) has a basis \\(\\B\\) .","title":"Theorem (Every Subspace has a Basis)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#proof_3","text":"Every finite subspace can be represented by a span of a set of vectors. By Theorem (Spanning Set contains Basis) , this spanning set has a basis.","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#theorem-linear-independent-sets-can-be-extended-to-a-basis","text":"Let \\(B\\) be a Linearly Independent subset of a vector space \\(V\\) over a field \\(\\F\\) . Then exactly one of the following two cases is true. i) \\(B\\) spans \\(V\\) and hence \\(B\\) is a basis of \\(V\\) . ii) Let \\(\\v \\in V \\setminus \\text{Span}(B)\\) and hence \\(\\v \\not \\in B\\) . Then \\(B \\cup \\{\\v\\}\\) is an Linearly Independent subset of \\(V\\) . iii) In particular, if \\(V\\) is of finite dimension \\(n\\) , then one can find \\(n - |B|\\) vectors \\(\\mathbf{v_{|B|+1},...,v_n}\\) in \\(V \\setminus \\text{Span}(B)\\) such that \\(B \\coprod \\{\\mathbf{v_{|B|+1},...,v_n} \\}\\) is a basis of \\(V\\) .","title":"Theorem (Linear Independent Sets can be extended to a Basis)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#proof_4","text":"Since \\(B\\) is L.I subset of \\(V\\) , then \\(B\\) either spans \\(V\\) or do not span \\(V\\) . If it spans \\(V\\) , then \\(B\\) is a basis, which is point i). If its doesn't span \\(V\\) , take an element \\(\\w \\in V \\setminus \\text{span}(B)\\) , \\(\\w \\notin B\\) and \\(\\mathbf{w} \\notin \\text{span}(B)\\) . Then it means \\(\\mathbf{w}\\) is not a linear combination of any elements in \\(B\\) . Hence, \\(B \\cup \\{\\w\\}\\) is a L.I set as no elements in \\(B \\cup\\{\\w\\}\\) can be expressed as a LC of each other. Note if \\(B = \\{\\v_{1}, \\v_{2}, \\cdots \\v_{r}\\}, ~ B\\cup \\{\\w\\} = \\{\\v_{1}, \\cdots \\v_{r}, \\w\\}\\) . $ \\v_{i} \\ne \\w$. For point 3, this means if \\(B\\) is LI in \\(V\\) , then \\(B\\) can only have 2 cases. If Case 1 occurs, we are done as $ n - |B| = n- n = 0$, we do not need any more vectors in \\(V \\setminus \\text{span}(B)\\) to union with \\(B\\) . If Case 2 occurs, Then let \\(|B| = r\\) . then \\(\\exists \\mathbf{w_{r+1}} \\in V \\setminus \\text{span}(B)\\) s.t \\(B \\cup \\{\\mathbf{w_{r+1}}\\}\\) is L.I set. Applying the two cases to \\(B \\cup \\{\\mathbf{w_{r+1}}\\}\\) , we will have \\(B \\cup \\{\\mathbf{w_{r+1}}\\}\\) be a basis or \\(B \\cup \\{\\mathbf{w_{r+1}, w_{r+2}}\\}\\) is another L.I set. Since the dimension of \\(V\\) is \\(n\\) . Then applying this expansion inductively, \\(B \\cup \\{\\mathbf{w_{r+1}, \\cdots w_{n}}\\}\\) will eventually form a basis for \\(V\\) . If for a contradiction the case 2 continues after \\(\\mathbf{w_{n}}\\) then it contradicts the fact that a set with more than \\(n\\) vectors cannot be L.I.","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#theorem-equivalent-basis-definition","text":"Let \\(B\\) be a subset of a vector space \\(V\\) of finite dimension \\(\\text{dim}_{\\F}V = n \\geq 1\\) . Then the following are equivalent. i) \\(B\\) is a basis of \\(V\\) . ii) \\(B\\) is \\(L.I\\) and \\(|B| = n\\) . iii) \\(B\\) spans \\(V\\) and \\(|B| = n\\) .","title":"Theorem (Equivalent Basis Definition)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#proof_5","text":"We prove \\(i \\Leftrightarrow ii\\) and \\(i \\Leftrightarrow iii\\) . Now \\(i \\Rightarrow ii\\) and \\(i \\Rightarrow iii\\) are by definition. iii \\(\\Rightarrow\\) i Since \\(V = \\text{Span}(B)\\) , there exists a subset \\(B_1\\) of \\(B\\) such that \\(B_1\\) is a basis of \\(V\\) . But by our hypothesis, we have \\(|B| = n\\) . Since \\(B_1\\) is basis of \\(V\\) , we must have \\(|B_1| =\\) dimension of \\(V\\) which is \\(n\\) . And hence \\(|B_1| = |B|\\) . Since, \\(B_1 \\subseteq B\\) , and \\(|B_1| = |B|\\) , we must have \\(B_1 = B\\) as a set. Hence \\(B\\) is a basis of \\(V\\) . Alternatively, suppose \\(B\\) is not a basis of \\(V\\) . \\(B\\) is not linearly independent. Take a vector \\(\\v\\) in \\(B\\) which is a linear combination of other vectors in \\(B\\) . Then we know that \\(B - \\v\\) still spans \\(V\\) . But \\(|B-\\v| = n-1\\) by our hypothesis. And it is a contradiction since it is a subset of \\(V\\) with less than \\(n\\) vectors, hence it cannot span \\(V\\) . It is a contradiction. ii \\(\\Rightarrow\\) i Suppose that \\(B\\) is not a basis of \\(V\\) . Then \\(B\\) does not span \\(V\\) . Pick a vector \\(\\v\\) in \\(V\\) but not in Span \\((B)\\) (there exists such a vector because we say that \\(B\\) does not span \\(V\\) ) and \\(B \\cup \\{\\v\\}\\) is still a linearly independent set given that \\(B\\) is a linearly independent set. Hence it is a contradiction because \\(|B \\cup \\{\\v\\}| = n+1\\) has more vectors than even the basis set, hence it cannot be linearly independent.","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#useful-summary","text":"Let \\(V\\) be a vector space which has a basis \\(B\\) with \\(k\\) vectors. Then any subset \\(W\\) of \\(V\\) with more than \\(k\\) vectors is always linearly dependent. So it means if any subset \\(W\\) of \\(V\\) is linearly independent, then \\(W\\) will have less or equals to \\(k\\) vectors, in which directly translates to the dimension of \\(W\\) is less or equals to the dimension of \\(V\\) . Any subset \\(W\\) of \\(V\\) with less than \\(k\\) vectors cannot span \\(V\\) . So for any subset \\(W\\) of \\(V\\) which spans \\(V\\) , then it will have more or equals to \\(k\\) vectors. In particular, let \\(W = \\{\\w_1,...,\\w_k\\}\\) be a set of vectors in \\(V = \\mathbb{R}^n\\) . If \\(k < n\\) , then \\(S\\) cannot span \\(\\mathbb{R}^n\\) . Suppose that \\(C\\) is another basis of \\(V\\) , then \\(|B|=|C|\\) .","title":"Useful Summary"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#applications-of-basis","text":"","title":"Applications of Basis"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/#efficient-space-storage","text":"Storing data efficiently in this era is very important. Let's give a superfluous example: Let \\(\\A\\) be a \\(3 \\times 100\\) matrix where there are 3 features and 100 samples; and if we know that the columns of the matrix has a basis \\(\\B\\) , say \\[\\B = \\left\\{\\begin{bmatrix}1 \\\\ 0 \\\\ 0\\end{bmatrix} ,\\quad \\begin{bmatrix}0 \\\\ 0 \\\\ 1 \\end{bmatrix} ,\\quad \\begin{bmatrix} 0 \\\\ 0 \\\\ 1\\end{bmatrix}\\right\\}\\] But we know that all 100 columns of \\(\\A\\) can be reconstructed using the basis vectors; i.e. for each column \\(\\a_i\\) of \\(\\A\\) , there exists constants \\(\\lambda_i\\) such that \\[\\a_i = \\lambda_1 \\B_1 + \\lambda_2 \\B_2 + \\lambda_3 \\B_3\\] As a result, we can effectively store the 3 basis vectors (9 elements and note that the 3 basis vectors can be taken from the columns of \\(\\A\\) ); the remaining 7 columns we just need \\(7 \\times 3 = 21\\) constants so that we can recover the columns using linear combination of the basis vectors. In total, we reduced the space from \\(3 \\times 100 = 300\\) elements to \\(3 \\times 3 + 7 \\times 3 = 30\\) elements, effectively 70 percent decrease. Macro Analyst Linear Algebra \u21a9 Such as the real numbers \\(\\R\\) or the complex numbers \\(\\mathbb{C}\\) . \u21a9 https://math.stackexchange.com/questions/3089880/minimal-generating-set \u21a9","title":"Efficient Space Storage"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}}\\] Linear Independence Algebraic Definition (Linear Dependence) Example (Linear Dependence in \\(\\mathbb R^2\\) ) Example (Linear Independence in \\(\\mathbb R^3\\) ) Algebraic Definition (Linear Independence) Equivalent Algebraic Definition (Linear Independence) Theorem (Linear Combination Implies Linear Dependence) Proof Theorem (The zero vector and linear independence) Proof Theorem (Union of linearly independent vectors) Intuition (Linear (In)Dependence) Theorem (Uniqueness of Representation) Theorem (The Span of Linearly Dependent Vectors is Identical V2) Theorem (Inheritance of Linear Independence) Theorem (Length of Linear Independent Set \\(\\leq\\) Length of Spanning Set) Example (Usage of Theorem) Corollary (Length of Linear Indepedent Set and Spanning Set) Proof Example Geometric Definition (Linear Independence) How to determine if a set is Linearly Independent (Non-Matrix Algorithmic Way) Linkedin Summary Linear Independence References Linear Independence Algebraic Definition (Linear Dependence) Definition Let \\(V\\) be a vector space over a field \\(\\F\\) . The set of vectors \\(\\v_1, \\v_2, ..., \\v_m \\in V\\) is linearly dependent if and only if one of the vectors \\(\\v_i\\) , where \\(i \\in [1, m]\\) , is the zero vector or that at least one of \\(\\v_i\\) is a linear combination of the rest of the vectors (i.e. \\(\\v_i = \\sum_{j \\neq i}\\alpha_j\\v_j\\) ). More formally 1 , a sequence of vectors \\(\\mathbf{v}_1, \\mathbf{v}_2, \\dots, \\mathbf{v}_m\\) from a vector space \\(V\\) is said to be linearly dependent , if there exist scalars \\(a_1, a_2, \\dots, a_m\\) , not all zero, such that \\(a_1\\mathbf{v}_1 + a_2\\mathbf{v}_2 + \\cdots + a_m\\mathbf{v}_m = \\mathbf{0}\\) , where \\(\\mathbf{0}\\) denotes the zero vector. This implies that at least one of the scalars is nonzero, say \\(a_1\\neq 0\\) , and the above equation can be written as \\[\\mathbf{v}_1 = \\frac{-a_2}{a_1}\\mathbf{v}_2 + \\cdots + \\frac{-a_m}{a_1} \\mathbf{v}_m, a_i \\in \\F, a_1 \\neq 0\\] Example (Linear Dependence in \\(\\mathbb R^2\\) ) Example Consider column vectors \\[\\v_1 = \\begin{bmatrix}1 \\\\ 2 \\end{bmatrix},\\quad \\v_2 = \\begin{bmatrix}3 \\\\ 6 \\end{bmatrix},\\quad \\v_3 = \\begin{bmatrix}-6 \\\\ -12 \\end{bmatrix}\\] in the ambient \\(\\R^2\\) space. They are linearly dependent because the vector \\[\\v_2 = \\begin{bmatrix}3 \\\\ 6 \\end{bmatrix} = 3\\v_1 + 0\\v_3\\] and note that we are using \\(\\v_2\\) as an example here, you can also say that \\(\\v_1\\) is a linear combination of the other 2 vectors; but so long there is at least one such vector in the set, then this set is linearly dependent . Note I put a coefficient \\(0\\) in front of \\(\\v_3\\) to indicate that the scalars are not all zero but can have some zeros. Fig; Linear Dependent Vectors; By Hongnan G. import matplotlib.pyplot as plt import numpy as np # Courtesy of https://github.com/MacroAnalyst/Linear_Algebra_With_Python fig , ax = plt . subplots ( figsize = ( 8 , 8 )) #######################Arrows####################### arrows = np . array ([[[ 0 , 0 , 1 , 2 ]], [[ 0 , 0 , 3 , 6 ]], [[ 0 , 0 , - 6 , - 12 ]]]) colors = [ \"r\" , \"b\" , \"g\" ] for i in range ( arrows . shape [ 0 ]): X , Y , U , V = zip ( * arrows [ i , :, :]) ax . arrow ( X [ 0 ], Y [ 0 ], U [ 0 ], V [ 0 ], color = colors [ i ], width = 0.18 , length_includes_head = True , head_width = 0.3 , # default: 3*width head_length = 0.6 , overhang = 0.4 , zorder =- i , ) ax . scatter ( 0 , 0 , ec = \"red\" , fc = \"black\" , zorder = 5 ) ax . text ( 1.5 , 2 , \"$(1, 2)$\" ) ax . text ( 3.5 , 6 , \"$(3, 6)$\" ) ax . text ( - 9 , - 12 , \"$(-9, -12)$\" ) ax . grid ( True ) ax . set_title ( \"Linear Dependence Visualization ((1,2), (3, 6), (-9, -12))\" ) # axis([xmin, xmax, ymin, ymax]) ax . axis ([ - 12 , 10 , - 20 , 10 ]) ax . set_xlabel ( \"x-axis\" , size = 18 ) ax . set_ylabel ( \"y-axis\" , size = 18 ) plt . savefig ( \"linear_dependence.svg\" , format = \"svg\" , dpi = 600 ) plt . show () Example (Linear Independence in \\(\\mathbb R^3\\) ) Courtesy of MacroAnalyst's Linear Algebra with Python . Example Next, we visualize linear independence in \\(\\mathbb{R}^3\\) with vectors \\((1,-2,1)^T\\) , \\((2,1,2)^T\\) , \\((-1,2,3)^T\\) . Pan around the image (either by setting ax.view_init or using JupyterLab widget), we can see that the green vector is not in the plane spanned by red and blue vector, thus they are linearly independent. # %matplotlib notebook, use this only when you are in Jupyter Notebook, it doesn't work in Jupyterlab import matplotlib.pyplot as plt import numpy as np # %matplotlib notebook, use this only when you are in Jupyter Notebook, it doesn't work in Jupyterlab fig = plt . figure ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = '3d' ) s = np . linspace ( - 1 , 1 , 10 ) t = np . linspace ( - 1 , 1 , 10 ) S , T = np . meshgrid ( s , t ) X = S + 2 * T Y = - 2 * S + T Z = S + 2 * T ax . plot_wireframe ( X , Y , Z , linewidth = 1.5 , color = 'k' , alpha = .6 ) vec = np . array ([[[ 0 , 0 , 0 , 1 , - 2 , 1 ]], [[ 0 , 0 , 0 , 2 , 1 , 2 ]], [[ 0 , 0 , 0 , - 1 , 2 , 3 ]]]) colors = [ 'r' , 'b' , 'g' ] for i in range ( vec . shape [ 0 ]): X , Y , Z , U , V , W = zip ( * vec [ i ,:,:]) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = colors [ i ], arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 , alpha = .6 ) ax . set_title ( 'Linear Independence Visualization' ) ax . set_xlabel ( 'x-axis' , size = 18 ) ax . set_ylabel ( 'y-axis' , size = 18 ) ax . set_zlabel ( 'z-axis' , size = 18 ) ax . view_init ( elev = 60. , azim = 0 ) plt . show () Algebraic Definition (Linear Independence) Definition Let \\(V\\) be a vector space over a field \\(\\F\\) . The set of vectors \\(\\v_1, \\v_2, ..., \\v_m \\in V\\) is linearly independent if and only if the only solution to the equation \\(a_1\\mathbf{v}_1 + a_2\\mathbf{v}_2 + \\cdots + a_m\\mathbf{v}_m = \\mathbf{0}\\) is the trivial solution, the zero vector \\(\\0\\) . Equivalent Algebraic Definition (Linear Independence) Equivalent Linear Independence Definition Let \\(V\\) be a vector space over a field \\(\\F\\) . Let the set of vectors \\(S = \\v_1, \\v_2, ..., \\v_m \\in V\\) ; Then \\(S\\) is linearly independent if and only if i) the only solution to the equation \\(a_1\\mathbf{v}_1 + a_2\\mathbf{v}_2 + \\cdots + a_m\\mathbf{v}_m = \\mathbf{0}\\) is the trivial solution, the zero vector \\(\\0\\) ; iif ii) \\(S\\) is called a linearly dependent set and \\(\\mathbf{\\v_1,\\v_2,...,\\v_m}\\) are said to be linearly dependent iff \\(a_1\\mathbf{v}_1 + a_2\\mathbf{v}_2 + \\cdots + a_m\\mathbf{v}_m = \\mathbf{0}\\) has non - trivial solutions. That is there exists real numbers \\(a_1,a_2,...,a_m\\) not all of them are zero, such that \\(a_1\\v_1+a_2\\v_2+...+a_m\\v_m=0\\) ; iif iii) The set \\(S\\) is a linearly independent set if every non empty finite subset of \\(S\\) is linearly independent. The set \\(S\\) is a linearly dependent set if at least one non empty finite subset of \\(S\\) is linearly dependent. Theorem (Linear Combination Implies Linear Dependence) This is a very useful, and often better understood theorem! Theorem i) Let \\(S = \\{\\mathbf{v_1,v_2,...,v_m}\\}\\) be a finite subset of a vector space \\(V\\) over a field \\(\\F\\) where \\(m \\geq 2\\) , then \\(S\\) is linearly dependent if and only if at least one vector \\(\\mathbf{v_i} \\in S\\) can be written as a linear combination of other vectors in \\(S\\) . This means that there are scalars \\(a_1,a_2,...a_{i-1},a_{i+1},...,a_m \\in \\F\\) (scalars vanishing allowed) such that \\[\\mathbf{v_i} = a_1\\v_1+...+a_{i-1}\\mathbf{v_{i-1}}+a_{i+1}\\mathbf{v_{i+1}}+...+a_m\\v_m\\] ii) It follows that the contrapositive of this theorem: \\(S\\) is linearly independent if and only if no vector in \\(S\\) can be written as a linear combination of other vectors in \\(S\\) . Proof Proof We will just prove part i). \\(\\implies\\) \\(S = \\{\\mathbf{v_{1}, \\cdots , v_{m}}\\}\\) is finite \\(\\implies\\) \\(|S| = n < \\infty\\) , \\(S \\subseteq V\\) . If S is LD, then \\(a_{1}\\v_1 + a_{2}\\v_2 + \\cdots + a_{m}\\mathbf{v_{m}} = 0\\) has non trivial solutions. This means not all \\(a_{i} = 0\\) . Suppose \\(a_{k} \\ne 0\\) , thus one can write in this way: \\[ \\begin{eqnarray} a_{k}\\mathbf{v_m} & = & -a_{1}\\v_1 - a_{2}\\v_2 \\cdots -a_{m-1}\\mathbf{v_{m-1}} - \\cdots -a_{m}\\mathbf{v_{m}} \\nonumber \\\\ \\mathbf{v_m} & = & \\frac{-a_{1}}{a_{k}}\\v_1 - \\cdots - \\frac{a_{m-1}}{a_{k}}\\mathbf{v_{m-1}} - \\frac{a_{m}}{a_{k}}\\mathbf{v_{m}} \\nonumber \\\\ & = & b_{1}\\v_1 + \\cdots + b_{m-1}\\mathbf{v_{m-1}} + \\cdots + b_{m}\\mathbf{v_{m}} \\nonumber \\end{eqnarray} \\] where \\(b_{i} = \\frac{-a_{1}}{a_{k}}\\) . \\(\\Leftarrow\\) If \\(\\exists \\mathbf{v_m} = a_{1}\\v_1 + \\cdots + a_{m-1}\\mathbf{v_{m-1}} + \\cdots a_{m}\\mathbf{v_{m}}\\) , Then \\(a_{1}\\v_1 + \\cdots + a_{m-1}\\mathbf{v_{m-1}} + \\cdots a_{m}\\mathbf{v_{m}} = 0\\) will have non-trivial solution. Note \\((-1)\\mathbf{v_m} = a_{1}\\v_1 - \\cdots - a_{m-1}\\mathbf{v_{m-1}} - \\cdots - a_{m}\\mathbf{v_{m}}\\) . Then set \\(a_{k} = -1\\) , we have \\[a_{1}\\v_1 + \\cdots + (-1)\\mathbf{v_{k}} + \\cdots a_{m}\\mathbf{v_{m}} = a_1\\v_1+ \\cdots -a_{1}\\v_1 - a_2\\v_2 \\cdots - a_{m}\\mathbf{v_{m}} + \\cdots a_{m}\\mathbf{v_{m}} = 0\\] Hence, \\((a_{1}, \\cdots a_{m-1},-1, a_{k+1}, \\cdots a_{m})\\) is non trivial solution. Thus \\(\\v_1, \\cdots \\mathbf{v_{m}}\\) is LD. Theorem (The zero vector and linear independence) Theorem (The zero vector and linear independence) Note that \\(\\{\\mathbf{0}\\}\\) is a linearly dependent set, which means that if \\(\\mathbf{0} \\in S\\) , then \\(S\\) is a linearly dependent set. Proof Proof Write \\(c \\cdot \\mathbf{0} = 0\\) . Then one can easily see this equation has solutions other than \\(c = 0\\) . Since by killing power of zero, we can have the variable \\(c\\) to be any number. Hence by definition, \\(\\{\\mathbf{0}\\}\\) is a linearly dependent set. If \\(\\mathbf{0} \\in S\\) , then \\(\\mathbf{0}\\) can be expressed as a linear combination of any other vectors in the set by setting coefficients to be \\(0\\) . Hence it is considered a redundant vector and therefore causing \\(S\\) to be a linearly dependent set. Theorem (Union of linearly independent vectors) Theorem (Union of linearly independent vectors) Let \\(\\mathbf{v_1, v_2,...,v_k}\\) be LI vectors in \\(\\mathbb{R}^n\\) . If \\(\\mathbf{v_{k+1}}\\) is a vector in \\(\\mathbb{R}^n\\) and it is not a linearly combination of \\(\\mathbf{v_1,v_2,...,v_k}\\) , then \\(\\mathbf{v_1,...,v_k,v_{k+1}}\\) are linearly independent. Intuition (Linear (In)Dependence) Consider a xy cartesian plane, we have the x axis, where we can visualize as walking left or right (east or west), and the y axis, walking forward and backwards (north or south). We claim that the set of vectors \\[ S = \\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1} \\end{bmatrix} \\right\\} \\] is linearly independent, as neither vector can be represented by the other in any way. But if we add one more vector \\[ S_1 = \\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1} \\end{bmatrix}, \\begin{bmatrix} \\color{red}1 \\\\ \\color{red}{1} \\end{bmatrix} \\right\\}\\] then we say this set is linearly dependent because the vector \\([1, 1]\\) can be linearly combined by the other two, and is thus redundant. But why the weird definition? Why does having a non-trivial solution to the equation means linear dependence ? A good intuition from the post in mathstackexchange 2 : Intuition Your basic intuition is quite right --- a set of vectors are linearly independent if they don't affect each other (which, as it stands, is a somewhat ambiguous statement, hence the formal definition). Perhaps it would be helpful to start with just two vectors, say the standard vectors $$ \\begin{pmatrix} 1\\ 0 \\end{pmatrix} \\hspace{20pt}\\text{and}\\hspace{20pt} \\begin{pmatrix} 0\\ 1 \\end{pmatrix} $$ which are linearly independent in \\(\\mathbb{R}^{2}\\) (two-dimensional coordinate space). Natural intuition would be to think that these two are linearly independent because there is no scalar that you can multiply one by to get the other. That is, for \\(\\alpha \\in \\mathbb{R}\\) , the equation $$ \\alpha\\begin{pmatrix} 1\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0\\ 1 \\end{pmatrix} $$ has no solutions. This is a good rule for any set of two vectors, and is in fact equivalent to the formal definition for if there were scalars \\(\\alpha_{1}, \\alpha_{2} \\in \\mathbb{R}\\) such that $$ \\alpha_{1}\\begin{pmatrix} 1\\ 0 \\end{pmatrix} + \\alpha_{2}\\begin{pmatrix} 0\\ 1 \\end{pmatrix} = 0 $$ (which is just the formal definition), then we could rearrange it to get $$ -\\frac{\\alpha_{1}}{\\alpha_{2}}\\begin{pmatrix} 1\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0\\ 1 \\end{pmatrix}. $$ This is clearly false! The formal definition for an arbitrary number of vectors is an extension of this idea. We pick \\(0\\) to be the right hand side for convenience, since every vector space must have the zero vector (by definition), so that if some vectors affect each other in some way, they must be able to be combined some way to give you the zero vector. In fact, if a set of vectors are linearly independent, then the only vector that they agree on is the zero vector, and it can only be obtained by multiplying each vector by zero (and summing them up). Here I chime in a bit: consider \\((0, 1), (1, 0), (1, 1)\\) in \\(\\R^2\\) , then we know \\((0, 1) + (1, 0) = (1, 1)\\) where \\((1, 1)\\) is a linear combination of the former two vectors; and since \\((0, 1) + (1, 0) = (1, 1)\\) , then \\(((0, 1) + (1, 0)) - (1, 1) = (0, 0)\\) , the zero vector, this must be true for every vector that can be expressed as a linear combination of the rest. If they can be combined in some way to give you the zero vector, then you can just rearrange them (like above) and find one of the vectors as a linear combination of the others, which would clearly imply that it is not independent of the others. To make this more clear, let \\(\\{v_{1}, v_{2}, \\ldots, v_{n}\\}\\) be a set of vectors, and suppose there exists non-zero scalars \\(\\alpha_{i} \\in \\mathbb{R}\\) such that $$ \\alpha_{1}v_{1} + \\alpha_{2}v_{2} + \\ldots + \\alpha_{n}v_{n} = 0. $$ Then you can just rearrange this to get, for example, the equation $$ \\frac{-\\alpha_{1}}{\\alpha_{n}}v_{1} + \\frac{-\\alpha_{2}}{\\alpha_{n}}v_{2} + \\ldots + \\frac{-\\alpha_{n-1}}{\\alpha_{n}}v_{n-1} = v_{n}. $$ Then \\(v_{n}\\) depends on the other vectors, so the set is not linearly independent ! Thus, the only way that you can get a set of linearly independent vectors to all give you the zero vector, is that all must be multiplied by zero, else you can rearrange the equation to show that one of the vectors depends on the others, which would be a contradiction. This is why the definition is the way it is. As a note for your third point, the definition wants \\(\\alpha_{i} = 0\\) for all \\(i = 1, \\ldots, n\\) . That is, every coefficient has to be zero, not just one of them. Machine Learning Though a bit too early, but we often represent the variable/feature space of the dataset using the Design Matrix and each column (or row) represents the encoded information of the variables. If there are many redundant vectors inside the Design Matrix, this means that we are having additional information that we do not need (which may hurt performance). PCA can also help to reduce the dimensionality too. Theorem (Uniqueness of Representation) Theorem (Uniqueness of Representation) From the above, we can deduce something less apparent from linear independence, that is, for the same \\(\\v \\in V\\) , and the same set of vectors \\(\\v_1, \\v_2, ..., \\v_m \\in V\\) , there is only one unique representation of \\(\\v \\in V\\) using the set of vectors. For example, if we consider a simple example where \\(\\v = a_1 \\v_1 + a_2 \\v_2\\) and \\(\\v = b_1 \\v_1 + b_2 \\v_2\\) , where \\(a_1, a_2, b_1, b_2\\) are assumed to be distinct scalars in \\(\\F\\) , then subtracting both results in \\[\\0 = (a_1-b_1)\\v_1 + (a_2-b_2)\\v_2 \\implies a_i-b_i = 0\\] because we note that the equation can only have the trivial solution \\(\\0\\) . This results in a contradiction as we stated that \\(a_i, b_i\\) are distinct. So conclusion, if a set of vectors are linearly independent in \\(V\\) , then any vectors in \\(\\v \\in V\\) can only have a unique representation in \\(V\\) . Using the example in Intuition (Linear (In)Dependence) , we know that \\(S\\) is a linearly independent set, and imagine we take a vector \\((1, 1)\\) , can we actually find another way to represent \\((1, 1)\\) using this exact set of vectors? In other words, using \\((1, 0), (0, 1)\\) as the \"base vectors\", we must move 1 unit to the right and 1 unit up to reach \\((1, 1)\\) , can we move in any other way to get to \\((1, 1)\\) ? The answer is no. Theorem (The Span of Linearly Dependent Vectors is Identical V2) Branching from the Theorem (Linear Dependence Span equals each other) in the Chapter Span and taken from Sheldon Axler: Linear Algebra Done Right, pp. 35 : Theorem (The Span of Linearly Dependent Vectors is Identical V2) Let \\(\\v_1,...,\\v_m\\) be linearly dependent vectors in a vector space \\(V\\) . Then there exists \\(j \\in \\{1,2,\\cdots,m\\}\\) such that the following holds: \\(\\v_j \\in \\textbf{span}(\\v_1,\\cdots,\\v_{j-1})\\) ; if the \\(j\\) -th term is removed from the linearly dependent set, then $\\textbf{span}(\\v_1, \\cdots, \\v_{j-1}, \\v_{j+1}, \\cdots \\v_m) = \\textbf{span}(\\v_1, \\cdots, \\v_{j-1},\\v_j, \\v_{j+1}, \\cdots \\v_m) $. Theorem (Inheritance of Linear Independence) Theorem (Inheritance of Linear Independence) Let \\(S_1 \\subseteq S_2\\) , if the smaller set \\(S_1\\) is linearly dependent then so is the larger set \\(S_2\\) . \\(S_2\\) is linearly dependent follows from part iii) of Equivalent Definition of Linear independence . Now the contrapositive of this is if the larger set \\(S_2\\) is linearly independent then so is \\(S_1\\) being linearly independent. Theorem (Length of Linear Independent Set \\(\\leq\\) Length of Spanning Set) Theorem Taken from Sheldon Axler: Linear Algebra Done Right, pp. 35: In a finite-dimensional vector space, the length of every linearly independent set of vectors is less than or equal to the length of every spanning set of vectors. Example (Usage of Theorem) Example 1: Usage of Theorem to show a set of vectors cannot be linear independent Show that the set of vectors \\(\\{(1,2,3), (4,5,8), (9,6,7), (-3,2,8)\\}\\) is not linearly independent in \\(\\R^3\\) . Solution: We know that the set of vectors (basis) \\(\\{(1,0,0), (0,1,0), (0,0,1)\\}\\) spans \\(\\R^3\\) . And hence, if the set of vectors in question is linearly indepedent, then its cardinality cannot exceed 3. Example 2: Usage of Theorem to show a set of vectors cannot span the vector space Show that the set of vectors \\(\\{(1,2,3,5), (4, 5, 8, 3), (9, 6, 7, 1)\\}\\) does not span \\(\\R^4\\) . Solution: We know that the set of vectors (basis) \\(\\{(1,0,0,0), (0,1,0,0), (0,0,1,0), (0,0,0,1)\\}\\) is linearly independent in \\(\\R^4\\) . From theorem, we know the length (cardinality) of the set of linearly independent vectors is 4, and in the question, the set of vectors has only cardinality 3, and hence, it cannot span \\(\\R^4\\) . Corollary (Length of Linear Indepedent Set and Spanning Set) Corollary As a corollary of the Theorem (Inheritance of Linear Independence) above: Let \\(S = \\{\\mathbf{u_1,u_2, \\cdots, u_k}\\} \\subseteq \\mathbb{R}^{n}\\) . If \\(k >n\\) , then \\(S\\) is linearly dependent. Proof Proof Let \\(\\mathbf{u_i} = (a_{{i1}},a_{{i2}},...,a_{{in}})\\) for \\(i=1,2,...,k\\) . Then we write \\[c_1\\u_1+c_2\\u_2+...+c_k\\u_k=0\\] and check if it has the trivial solution only or has non trivial solutions. \\(\\begin{cases} a_{11}c_1+a_{21}c_2+...+a_{k1}c_k = 0\\\\ a_{12}c_1+a_{22}c_2+...+a_{k2}c_k = 0\\\\ ~~~~~~~~~~~\\vdots\\\\ a_{1n}c_1+a_{2n}c_2+...+a_{kn}c_k = 0 \\end{cases}\\) This system has \\(k\\) unknowns and \\(n\\) equations. By our previous results, since \\(k > n\\) , the system must have non trivial solution. Hence \\(S\\) is linearly dependent. Example Example In \\(\\mathbb{R}^{2}\\) , a set of three or more vectors must be linearly dependent; In \\(\\mathbb{R}^{3}\\) , a set of four or more vectors must be linearly dependent. Fig; Note that the first figure shows a set of dependent vectors; the second figure shows a set of independent vectors; and the third figure shows a set of dependent vectors; By Hongnan G. The above image illustrates that in \\(\\R^2\\) space, if a set of vectors has cardinality more than the dimension of its ambient space (read: 2), then it must be linearly dependent . Intuition In the example above, our ambient space is \\(\\R^2\\) , the author Mike provided a good intuition here on why a set of vectors whose cardinality is more than its ambient space cannot be linearly independent. Assume a contradiction, that they are linearly independent, then these 3 vectors span a 3d-subspace, which cannot happen if all 3 vectors are in 2d-subspace. To visualize it, imagine drawing 3 vectors on a 2d-plane (a piece of paper), then can you ever construct a cube (3d-space) from these 3 vectors? No. Geometric Definition (Linear Independence) We go through the Geometric Definition after the previous theorem. From Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 90) , a set of vectors independent if the subspace dimensions spanned by the set of vectors is equal to the number of vectors in the set. Recall that up till now, the subspace dimension simply means the \"number of axes\" in the subspace. This can be understood with the following example: For example, a set with one vector spans a line (assuming it is not the zeros vector) and is always an independent set (1 vector, 1 dimension); a linearly independent set of two vectors spans a plane (2 vectors, 2 dimensions); an independent set with three vectors spans a 3D space (3 vectors, 3 dimensions). For more info, read Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 90-92) . How to determine if a set is Linearly Independent (Non-Matrix Algorithmic Way) pp. 95-96 Mike's book. Linkedin Summary Today marks day 9 of round 1, continuing my journey in #linearalgebra, following the book \"Linear Algebra, Theory, Intuition and Code\", I went through the definition and some examples of what constitutes a linear in(dependent) set . In short, for a vector space V over a field F^n, a subset S = {v_1, v_2, ..., v_m} of V is a linearly independent set if a_1v_1 + a_2v_2 + ... + a_m_vm = 0 has only the trivial solution. This definition might seem a bit weird at first sight, we can break down and see what it really means. We can understand this definition better from its contraposition: if subset S of V is linearly dependent, then it must have at least one non-trivial solution; consider this solution to be (a_1, a_2, ..., a_m) = (1, 2, 0, ..., 0), this implies that v_1 = -2v_2. Though not a proof, we now know that if at least one vector can be represented by a linear combination of the other vectors in the set, then this set is linearly dependent . So another way to word the linear independence definition is that no vector in S can be represented as a linear combination of the other vectors in S. An immediate consequence of this definition is that an linearly independent set must have an unique representation in the vector space spanned by this set. Suppose not (a contradiction), then there exists a_i, b_i's such that a_1v_1 + ... a_mv_m = 0 and b_1v_1 + ... + b_mv_m = 0, where a_i and b_i's are not all the same. This implies (a_1-b_1)v_1 + ... + (a_m-b_m)v_m = 0 has a non-trivial solution since there exists at least one pair of a_i != b_i. Geometrically, one can see the below image, 3 vectors in a 2d-plane is necessarily linearly dependent, you can also verify that to get (10, 10) can be made up by (0, 10) + (10, 0), or 1*(10, 10), which has two representations. Linear Independence References https://www.machinelearningmindset.com/linear-independence-of-vectors/ https://math.stackexchange.com/questions/2779918/intuition-for-formal-definition-of-linear-independence https://medium.com/swlh/how-to-understand-linear-independence-linear-algebra-8bab1d918509 Linear Independence Wikipedia \u21a9 https://math.stackexchange.com/questions/2779918/intuition-for-formal-definition-of-linear-independence \u21a9","title":"Linear Independence"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#linear-independence","text":"","title":"Linear Independence"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#algebraic-definition-linear-dependence","text":"Definition Let \\(V\\) be a vector space over a field \\(\\F\\) . The set of vectors \\(\\v_1, \\v_2, ..., \\v_m \\in V\\) is linearly dependent if and only if one of the vectors \\(\\v_i\\) , where \\(i \\in [1, m]\\) , is the zero vector or that at least one of \\(\\v_i\\) is a linear combination of the rest of the vectors (i.e. \\(\\v_i = \\sum_{j \\neq i}\\alpha_j\\v_j\\) ). More formally 1 , a sequence of vectors \\(\\mathbf{v}_1, \\mathbf{v}_2, \\dots, \\mathbf{v}_m\\) from a vector space \\(V\\) is said to be linearly dependent , if there exist scalars \\(a_1, a_2, \\dots, a_m\\) , not all zero, such that \\(a_1\\mathbf{v}_1 + a_2\\mathbf{v}_2 + \\cdots + a_m\\mathbf{v}_m = \\mathbf{0}\\) , where \\(\\mathbf{0}\\) denotes the zero vector. This implies that at least one of the scalars is nonzero, say \\(a_1\\neq 0\\) , and the above equation can be written as \\[\\mathbf{v}_1 = \\frac{-a_2}{a_1}\\mathbf{v}_2 + \\cdots + \\frac{-a_m}{a_1} \\mathbf{v}_m, a_i \\in \\F, a_1 \\neq 0\\]","title":"Algebraic Definition (Linear Dependence)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#example-linear-dependence-in-mathbb-r2","text":"Example Consider column vectors \\[\\v_1 = \\begin{bmatrix}1 \\\\ 2 \\end{bmatrix},\\quad \\v_2 = \\begin{bmatrix}3 \\\\ 6 \\end{bmatrix},\\quad \\v_3 = \\begin{bmatrix}-6 \\\\ -12 \\end{bmatrix}\\] in the ambient \\(\\R^2\\) space. They are linearly dependent because the vector \\[\\v_2 = \\begin{bmatrix}3 \\\\ 6 \\end{bmatrix} = 3\\v_1 + 0\\v_3\\] and note that we are using \\(\\v_2\\) as an example here, you can also say that \\(\\v_1\\) is a linear combination of the other 2 vectors; but so long there is at least one such vector in the set, then this set is linearly dependent . Note I put a coefficient \\(0\\) in front of \\(\\v_3\\) to indicate that the scalars are not all zero but can have some zeros. Fig; Linear Dependent Vectors; By Hongnan G. import matplotlib.pyplot as plt import numpy as np # Courtesy of https://github.com/MacroAnalyst/Linear_Algebra_With_Python fig , ax = plt . subplots ( figsize = ( 8 , 8 )) #######################Arrows####################### arrows = np . array ([[[ 0 , 0 , 1 , 2 ]], [[ 0 , 0 , 3 , 6 ]], [[ 0 , 0 , - 6 , - 12 ]]]) colors = [ \"r\" , \"b\" , \"g\" ] for i in range ( arrows . shape [ 0 ]): X , Y , U , V = zip ( * arrows [ i , :, :]) ax . arrow ( X [ 0 ], Y [ 0 ], U [ 0 ], V [ 0 ], color = colors [ i ], width = 0.18 , length_includes_head = True , head_width = 0.3 , # default: 3*width head_length = 0.6 , overhang = 0.4 , zorder =- i , ) ax . scatter ( 0 , 0 , ec = \"red\" , fc = \"black\" , zorder = 5 ) ax . text ( 1.5 , 2 , \"$(1, 2)$\" ) ax . text ( 3.5 , 6 , \"$(3, 6)$\" ) ax . text ( - 9 , - 12 , \"$(-9, -12)$\" ) ax . grid ( True ) ax . set_title ( \"Linear Dependence Visualization ((1,2), (3, 6), (-9, -12))\" ) # axis([xmin, xmax, ymin, ymax]) ax . axis ([ - 12 , 10 , - 20 , 10 ]) ax . set_xlabel ( \"x-axis\" , size = 18 ) ax . set_ylabel ( \"y-axis\" , size = 18 ) plt . savefig ( \"linear_dependence.svg\" , format = \"svg\" , dpi = 600 ) plt . show ()","title":"Example (Linear Dependence in \\(\\mathbb R^2\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#example-linear-independence-in-mathbb-r3","text":"Courtesy of MacroAnalyst's Linear Algebra with Python . Example Next, we visualize linear independence in \\(\\mathbb{R}^3\\) with vectors \\((1,-2,1)^T\\) , \\((2,1,2)^T\\) , \\((-1,2,3)^T\\) . Pan around the image (either by setting ax.view_init or using JupyterLab widget), we can see that the green vector is not in the plane spanned by red and blue vector, thus they are linearly independent. # %matplotlib notebook, use this only when you are in Jupyter Notebook, it doesn't work in Jupyterlab import matplotlib.pyplot as plt import numpy as np # %matplotlib notebook, use this only when you are in Jupyter Notebook, it doesn't work in Jupyterlab fig = plt . figure ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = '3d' ) s = np . linspace ( - 1 , 1 , 10 ) t = np . linspace ( - 1 , 1 , 10 ) S , T = np . meshgrid ( s , t ) X = S + 2 * T Y = - 2 * S + T Z = S + 2 * T ax . plot_wireframe ( X , Y , Z , linewidth = 1.5 , color = 'k' , alpha = .6 ) vec = np . array ([[[ 0 , 0 , 0 , 1 , - 2 , 1 ]], [[ 0 , 0 , 0 , 2 , 1 , 2 ]], [[ 0 , 0 , 0 , - 1 , 2 , 3 ]]]) colors = [ 'r' , 'b' , 'g' ] for i in range ( vec . shape [ 0 ]): X , Y , Z , U , V , W = zip ( * vec [ i ,:,:]) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = colors [ i ], arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 , alpha = .6 ) ax . set_title ( 'Linear Independence Visualization' ) ax . set_xlabel ( 'x-axis' , size = 18 ) ax . set_ylabel ( 'y-axis' , size = 18 ) ax . set_zlabel ( 'z-axis' , size = 18 ) ax . view_init ( elev = 60. , azim = 0 ) plt . show ()","title":"Example (Linear Independence in \\(\\mathbb R^3\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#algebraic-definition-linear-independence","text":"Definition Let \\(V\\) be a vector space over a field \\(\\F\\) . The set of vectors \\(\\v_1, \\v_2, ..., \\v_m \\in V\\) is linearly independent if and only if the only solution to the equation \\(a_1\\mathbf{v}_1 + a_2\\mathbf{v}_2 + \\cdots + a_m\\mathbf{v}_m = \\mathbf{0}\\) is the trivial solution, the zero vector \\(\\0\\) .","title":"Algebraic Definition (Linear Independence)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#equivalent-algebraic-definition-linear-independence","text":"Equivalent Linear Independence Definition Let \\(V\\) be a vector space over a field \\(\\F\\) . Let the set of vectors \\(S = \\v_1, \\v_2, ..., \\v_m \\in V\\) ; Then \\(S\\) is linearly independent if and only if i) the only solution to the equation \\(a_1\\mathbf{v}_1 + a_2\\mathbf{v}_2 + \\cdots + a_m\\mathbf{v}_m = \\mathbf{0}\\) is the trivial solution, the zero vector \\(\\0\\) ; iif ii) \\(S\\) is called a linearly dependent set and \\(\\mathbf{\\v_1,\\v_2,...,\\v_m}\\) are said to be linearly dependent iff \\(a_1\\mathbf{v}_1 + a_2\\mathbf{v}_2 + \\cdots + a_m\\mathbf{v}_m = \\mathbf{0}\\) has non - trivial solutions. That is there exists real numbers \\(a_1,a_2,...,a_m\\) not all of them are zero, such that \\(a_1\\v_1+a_2\\v_2+...+a_m\\v_m=0\\) ; iif iii) The set \\(S\\) is a linearly independent set if every non empty finite subset of \\(S\\) is linearly independent. The set \\(S\\) is a linearly dependent set if at least one non empty finite subset of \\(S\\) is linearly dependent.","title":"Equivalent Algebraic Definition (Linear Independence)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#theorem-linear-combination-implies-linear-dependence","text":"This is a very useful, and often better understood theorem! Theorem i) Let \\(S = \\{\\mathbf{v_1,v_2,...,v_m}\\}\\) be a finite subset of a vector space \\(V\\) over a field \\(\\F\\) where \\(m \\geq 2\\) , then \\(S\\) is linearly dependent if and only if at least one vector \\(\\mathbf{v_i} \\in S\\) can be written as a linear combination of other vectors in \\(S\\) . This means that there are scalars \\(a_1,a_2,...a_{i-1},a_{i+1},...,a_m \\in \\F\\) (scalars vanishing allowed) such that \\[\\mathbf{v_i} = a_1\\v_1+...+a_{i-1}\\mathbf{v_{i-1}}+a_{i+1}\\mathbf{v_{i+1}}+...+a_m\\v_m\\] ii) It follows that the contrapositive of this theorem: \\(S\\) is linearly independent if and only if no vector in \\(S\\) can be written as a linear combination of other vectors in \\(S\\) .","title":"Theorem (Linear Combination Implies Linear Dependence)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#proof","text":"Proof We will just prove part i). \\(\\implies\\) \\(S = \\{\\mathbf{v_{1}, \\cdots , v_{m}}\\}\\) is finite \\(\\implies\\) \\(|S| = n < \\infty\\) , \\(S \\subseteq V\\) . If S is LD, then \\(a_{1}\\v_1 + a_{2}\\v_2 + \\cdots + a_{m}\\mathbf{v_{m}} = 0\\) has non trivial solutions. This means not all \\(a_{i} = 0\\) . Suppose \\(a_{k} \\ne 0\\) , thus one can write in this way: \\[ \\begin{eqnarray} a_{k}\\mathbf{v_m} & = & -a_{1}\\v_1 - a_{2}\\v_2 \\cdots -a_{m-1}\\mathbf{v_{m-1}} - \\cdots -a_{m}\\mathbf{v_{m}} \\nonumber \\\\ \\mathbf{v_m} & = & \\frac{-a_{1}}{a_{k}}\\v_1 - \\cdots - \\frac{a_{m-1}}{a_{k}}\\mathbf{v_{m-1}} - \\frac{a_{m}}{a_{k}}\\mathbf{v_{m}} \\nonumber \\\\ & = & b_{1}\\v_1 + \\cdots + b_{m-1}\\mathbf{v_{m-1}} + \\cdots + b_{m}\\mathbf{v_{m}} \\nonumber \\end{eqnarray} \\] where \\(b_{i} = \\frac{-a_{1}}{a_{k}}\\) . \\(\\Leftarrow\\) If \\(\\exists \\mathbf{v_m} = a_{1}\\v_1 + \\cdots + a_{m-1}\\mathbf{v_{m-1}} + \\cdots a_{m}\\mathbf{v_{m}}\\) , Then \\(a_{1}\\v_1 + \\cdots + a_{m-1}\\mathbf{v_{m-1}} + \\cdots a_{m}\\mathbf{v_{m}} = 0\\) will have non-trivial solution. Note \\((-1)\\mathbf{v_m} = a_{1}\\v_1 - \\cdots - a_{m-1}\\mathbf{v_{m-1}} - \\cdots - a_{m}\\mathbf{v_{m}}\\) . Then set \\(a_{k} = -1\\) , we have \\[a_{1}\\v_1 + \\cdots + (-1)\\mathbf{v_{k}} + \\cdots a_{m}\\mathbf{v_{m}} = a_1\\v_1+ \\cdots -a_{1}\\v_1 - a_2\\v_2 \\cdots - a_{m}\\mathbf{v_{m}} + \\cdots a_{m}\\mathbf{v_{m}} = 0\\] Hence, \\((a_{1}, \\cdots a_{m-1},-1, a_{k+1}, \\cdots a_{m})\\) is non trivial solution. Thus \\(\\v_1, \\cdots \\mathbf{v_{m}}\\) is LD.","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#theorem-the-zero-vector-and-linear-independence","text":"Theorem (The zero vector and linear independence) Note that \\(\\{\\mathbf{0}\\}\\) is a linearly dependent set, which means that if \\(\\mathbf{0} \\in S\\) , then \\(S\\) is a linearly dependent set.","title":"Theorem (The zero vector and linear independence)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#proof_1","text":"Proof Write \\(c \\cdot \\mathbf{0} = 0\\) . Then one can easily see this equation has solutions other than \\(c = 0\\) . Since by killing power of zero, we can have the variable \\(c\\) to be any number. Hence by definition, \\(\\{\\mathbf{0}\\}\\) is a linearly dependent set. If \\(\\mathbf{0} \\in S\\) , then \\(\\mathbf{0}\\) can be expressed as a linear combination of any other vectors in the set by setting coefficients to be \\(0\\) . Hence it is considered a redundant vector and therefore causing \\(S\\) to be a linearly dependent set.","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#theorem-union-of-linearly-independent-vectors","text":"Theorem (Union of linearly independent vectors) Let \\(\\mathbf{v_1, v_2,...,v_k}\\) be LI vectors in \\(\\mathbb{R}^n\\) . If \\(\\mathbf{v_{k+1}}\\) is a vector in \\(\\mathbb{R}^n\\) and it is not a linearly combination of \\(\\mathbf{v_1,v_2,...,v_k}\\) , then \\(\\mathbf{v_1,...,v_k,v_{k+1}}\\) are linearly independent.","title":"Theorem (Union of linearly independent vectors)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#intuition-linear-independence","text":"Consider a xy cartesian plane, we have the x axis, where we can visualize as walking left or right (east or west), and the y axis, walking forward and backwards (north or south). We claim that the set of vectors \\[ S = \\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1} \\end{bmatrix} \\right\\} \\] is linearly independent, as neither vector can be represented by the other in any way. But if we add one more vector \\[ S_1 = \\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1} \\end{bmatrix}, \\begin{bmatrix} \\color{red}1 \\\\ \\color{red}{1} \\end{bmatrix} \\right\\}\\] then we say this set is linearly dependent because the vector \\([1, 1]\\) can be linearly combined by the other two, and is thus redundant. But why the weird definition? Why does having a non-trivial solution to the equation means linear dependence ? A good intuition from the post in mathstackexchange 2 : Intuition Your basic intuition is quite right --- a set of vectors are linearly independent if they don't affect each other (which, as it stands, is a somewhat ambiguous statement, hence the formal definition). Perhaps it would be helpful to start with just two vectors, say the standard vectors $$ \\begin{pmatrix} 1\\ 0 \\end{pmatrix} \\hspace{20pt}\\text{and}\\hspace{20pt} \\begin{pmatrix} 0\\ 1 \\end{pmatrix} $$ which are linearly independent in \\(\\mathbb{R}^{2}\\) (two-dimensional coordinate space). Natural intuition would be to think that these two are linearly independent because there is no scalar that you can multiply one by to get the other. That is, for \\(\\alpha \\in \\mathbb{R}\\) , the equation $$ \\alpha\\begin{pmatrix} 1\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0\\ 1 \\end{pmatrix} $$ has no solutions. This is a good rule for any set of two vectors, and is in fact equivalent to the formal definition for if there were scalars \\(\\alpha_{1}, \\alpha_{2} \\in \\mathbb{R}\\) such that $$ \\alpha_{1}\\begin{pmatrix} 1\\ 0 \\end{pmatrix} + \\alpha_{2}\\begin{pmatrix} 0\\ 1 \\end{pmatrix} = 0 $$ (which is just the formal definition), then we could rearrange it to get $$ -\\frac{\\alpha_{1}}{\\alpha_{2}}\\begin{pmatrix} 1\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0\\ 1 \\end{pmatrix}. $$ This is clearly false! The formal definition for an arbitrary number of vectors is an extension of this idea. We pick \\(0\\) to be the right hand side for convenience, since every vector space must have the zero vector (by definition), so that if some vectors affect each other in some way, they must be able to be combined some way to give you the zero vector. In fact, if a set of vectors are linearly independent, then the only vector that they agree on is the zero vector, and it can only be obtained by multiplying each vector by zero (and summing them up). Here I chime in a bit: consider \\((0, 1), (1, 0), (1, 1)\\) in \\(\\R^2\\) , then we know \\((0, 1) + (1, 0) = (1, 1)\\) where \\((1, 1)\\) is a linear combination of the former two vectors; and since \\((0, 1) + (1, 0) = (1, 1)\\) , then \\(((0, 1) + (1, 0)) - (1, 1) = (0, 0)\\) , the zero vector, this must be true for every vector that can be expressed as a linear combination of the rest. If they can be combined in some way to give you the zero vector, then you can just rearrange them (like above) and find one of the vectors as a linear combination of the others, which would clearly imply that it is not independent of the others. To make this more clear, let \\(\\{v_{1}, v_{2}, \\ldots, v_{n}\\}\\) be a set of vectors, and suppose there exists non-zero scalars \\(\\alpha_{i} \\in \\mathbb{R}\\) such that $$ \\alpha_{1}v_{1} + \\alpha_{2}v_{2} + \\ldots + \\alpha_{n}v_{n} = 0. $$ Then you can just rearrange this to get, for example, the equation $$ \\frac{-\\alpha_{1}}{\\alpha_{n}}v_{1} + \\frac{-\\alpha_{2}}{\\alpha_{n}}v_{2} + \\ldots + \\frac{-\\alpha_{n-1}}{\\alpha_{n}}v_{n-1} = v_{n}. $$ Then \\(v_{n}\\) depends on the other vectors, so the set is not linearly independent ! Thus, the only way that you can get a set of linearly independent vectors to all give you the zero vector, is that all must be multiplied by zero, else you can rearrange the equation to show that one of the vectors depends on the others, which would be a contradiction. This is why the definition is the way it is. As a note for your third point, the definition wants \\(\\alpha_{i} = 0\\) for all \\(i = 1, \\ldots, n\\) . That is, every coefficient has to be zero, not just one of them. Machine Learning Though a bit too early, but we often represent the variable/feature space of the dataset using the Design Matrix and each column (or row) represents the encoded information of the variables. If there are many redundant vectors inside the Design Matrix, this means that we are having additional information that we do not need (which may hurt performance). PCA can also help to reduce the dimensionality too.","title":"Intuition (Linear (In)Dependence)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#theorem-uniqueness-of-representation","text":"Theorem (Uniqueness of Representation) From the above, we can deduce something less apparent from linear independence, that is, for the same \\(\\v \\in V\\) , and the same set of vectors \\(\\v_1, \\v_2, ..., \\v_m \\in V\\) , there is only one unique representation of \\(\\v \\in V\\) using the set of vectors. For example, if we consider a simple example where \\(\\v = a_1 \\v_1 + a_2 \\v_2\\) and \\(\\v = b_1 \\v_1 + b_2 \\v_2\\) , where \\(a_1, a_2, b_1, b_2\\) are assumed to be distinct scalars in \\(\\F\\) , then subtracting both results in \\[\\0 = (a_1-b_1)\\v_1 + (a_2-b_2)\\v_2 \\implies a_i-b_i = 0\\] because we note that the equation can only have the trivial solution \\(\\0\\) . This results in a contradiction as we stated that \\(a_i, b_i\\) are distinct. So conclusion, if a set of vectors are linearly independent in \\(V\\) , then any vectors in \\(\\v \\in V\\) can only have a unique representation in \\(V\\) . Using the example in Intuition (Linear (In)Dependence) , we know that \\(S\\) is a linearly independent set, and imagine we take a vector \\((1, 1)\\) , can we actually find another way to represent \\((1, 1)\\) using this exact set of vectors? In other words, using \\((1, 0), (0, 1)\\) as the \"base vectors\", we must move 1 unit to the right and 1 unit up to reach \\((1, 1)\\) , can we move in any other way to get to \\((1, 1)\\) ? The answer is no.","title":"Theorem (Uniqueness of Representation)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#theorem-the-span-of-linearly-dependent-vectors-is-identical-v2","text":"Branching from the Theorem (Linear Dependence Span equals each other) in the Chapter Span and taken from Sheldon Axler: Linear Algebra Done Right, pp. 35 : Theorem (The Span of Linearly Dependent Vectors is Identical V2) Let \\(\\v_1,...,\\v_m\\) be linearly dependent vectors in a vector space \\(V\\) . Then there exists \\(j \\in \\{1,2,\\cdots,m\\}\\) such that the following holds: \\(\\v_j \\in \\textbf{span}(\\v_1,\\cdots,\\v_{j-1})\\) ; if the \\(j\\) -th term is removed from the linearly dependent set, then $\\textbf{span}(\\v_1, \\cdots, \\v_{j-1}, \\v_{j+1}, \\cdots \\v_m) = \\textbf{span}(\\v_1, \\cdots, \\v_{j-1},\\v_j, \\v_{j+1}, \\cdots \\v_m) $.","title":"Theorem (The Span of Linearly Dependent Vectors is Identical V2)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#theorem-inheritance-of-linear-independence","text":"Theorem (Inheritance of Linear Independence) Let \\(S_1 \\subseteq S_2\\) , if the smaller set \\(S_1\\) is linearly dependent then so is the larger set \\(S_2\\) . \\(S_2\\) is linearly dependent follows from part iii) of Equivalent Definition of Linear independence . Now the contrapositive of this is if the larger set \\(S_2\\) is linearly independent then so is \\(S_1\\) being linearly independent.","title":"Theorem (Inheritance of Linear Independence)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#theorem-length-of-linear-independent-set-leq-length-of-spanning-set","text":"Theorem Taken from Sheldon Axler: Linear Algebra Done Right, pp. 35: In a finite-dimensional vector space, the length of every linearly independent set of vectors is less than or equal to the length of every spanning set of vectors.","title":"Theorem (Length of Linear Independent Set \\(\\leq\\) Length of Spanning Set)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#example-usage-of-theorem","text":"Example 1: Usage of Theorem to show a set of vectors cannot be linear independent Show that the set of vectors \\(\\{(1,2,3), (4,5,8), (9,6,7), (-3,2,8)\\}\\) is not linearly independent in \\(\\R^3\\) . Solution: We know that the set of vectors (basis) \\(\\{(1,0,0), (0,1,0), (0,0,1)\\}\\) spans \\(\\R^3\\) . And hence, if the set of vectors in question is linearly indepedent, then its cardinality cannot exceed 3. Example 2: Usage of Theorem to show a set of vectors cannot span the vector space Show that the set of vectors \\(\\{(1,2,3,5), (4, 5, 8, 3), (9, 6, 7, 1)\\}\\) does not span \\(\\R^4\\) . Solution: We know that the set of vectors (basis) \\(\\{(1,0,0,0), (0,1,0,0), (0,0,1,0), (0,0,0,1)\\}\\) is linearly independent in \\(\\R^4\\) . From theorem, we know the length (cardinality) of the set of linearly independent vectors is 4, and in the question, the set of vectors has only cardinality 3, and hence, it cannot span \\(\\R^4\\) .","title":"Example (Usage of Theorem)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#corollary-length-of-linear-indepedent-set-and-spanning-set","text":"Corollary As a corollary of the Theorem (Inheritance of Linear Independence) above: Let \\(S = \\{\\mathbf{u_1,u_2, \\cdots, u_k}\\} \\subseteq \\mathbb{R}^{n}\\) . If \\(k >n\\) , then \\(S\\) is linearly dependent.","title":"Corollary (Length of Linear Indepedent Set and Spanning Set)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#proof_2","text":"Proof Let \\(\\mathbf{u_i} = (a_{{i1}},a_{{i2}},...,a_{{in}})\\) for \\(i=1,2,...,k\\) . Then we write \\[c_1\\u_1+c_2\\u_2+...+c_k\\u_k=0\\] and check if it has the trivial solution only or has non trivial solutions. \\(\\begin{cases} a_{11}c_1+a_{21}c_2+...+a_{k1}c_k = 0\\\\ a_{12}c_1+a_{22}c_2+...+a_{k2}c_k = 0\\\\ ~~~~~~~~~~~\\vdots\\\\ a_{1n}c_1+a_{2n}c_2+...+a_{kn}c_k = 0 \\end{cases}\\) This system has \\(k\\) unknowns and \\(n\\) equations. By our previous results, since \\(k > n\\) , the system must have non trivial solution. Hence \\(S\\) is linearly dependent.","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#example","text":"Example In \\(\\mathbb{R}^{2}\\) , a set of three or more vectors must be linearly dependent; In \\(\\mathbb{R}^{3}\\) , a set of four or more vectors must be linearly dependent. Fig; Note that the first figure shows a set of dependent vectors; the second figure shows a set of independent vectors; and the third figure shows a set of dependent vectors; By Hongnan G. The above image illustrates that in \\(\\R^2\\) space, if a set of vectors has cardinality more than the dimension of its ambient space (read: 2), then it must be linearly dependent . Intuition In the example above, our ambient space is \\(\\R^2\\) , the author Mike provided a good intuition here on why a set of vectors whose cardinality is more than its ambient space cannot be linearly independent. Assume a contradiction, that they are linearly independent, then these 3 vectors span a 3d-subspace, which cannot happen if all 3 vectors are in 2d-subspace. To visualize it, imagine drawing 3 vectors on a 2d-plane (a piece of paper), then can you ever construct a cube (3d-space) from these 3 vectors? No.","title":"Example"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#geometric-definition-linear-independence","text":"We go through the Geometric Definition after the previous theorem. From Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 90) , a set of vectors independent if the subspace dimensions spanned by the set of vectors is equal to the number of vectors in the set. Recall that up till now, the subspace dimension simply means the \"number of axes\" in the subspace. This can be understood with the following example: For example, a set with one vector spans a line (assuming it is not the zeros vector) and is always an independent set (1 vector, 1 dimension); a linearly independent set of two vectors spans a plane (2 vectors, 2 dimensions); an independent set with three vectors spans a 3D space (3 vectors, 3 dimensions). For more info, read Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 90-92) .","title":"Geometric Definition (Linear Independence)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#how-to-determine-if-a-set-is-linearly-independent-non-matrix-algorithmic-way","text":"pp. 95-96 Mike's book.","title":"How to determine if a set is Linearly Independent (Non-Matrix Algorithmic Way)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#linkedin-summary","text":"Today marks day 9 of round 1, continuing my journey in #linearalgebra, following the book \"Linear Algebra, Theory, Intuition and Code\", I went through the definition and some examples of what constitutes a linear in(dependent) set . In short, for a vector space V over a field F^n, a subset S = {v_1, v_2, ..., v_m} of V is a linearly independent set if a_1v_1 + a_2v_2 + ... + a_m_vm = 0 has only the trivial solution. This definition might seem a bit weird at first sight, we can break down and see what it really means. We can understand this definition better from its contraposition: if subset S of V is linearly dependent, then it must have at least one non-trivial solution; consider this solution to be (a_1, a_2, ..., a_m) = (1, 2, 0, ..., 0), this implies that v_1 = -2v_2. Though not a proof, we now know that if at least one vector can be represented by a linear combination of the other vectors in the set, then this set is linearly dependent . So another way to word the linear independence definition is that no vector in S can be represented as a linear combination of the other vectors in S. An immediate consequence of this definition is that an linearly independent set must have an unique representation in the vector space spanned by this set. Suppose not (a contradiction), then there exists a_i, b_i's such that a_1v_1 + ... a_mv_m = 0 and b_1v_1 + ... + b_mv_m = 0, where a_i and b_i's are not all the same. This implies (a_1-b_1)v_1 + ... + (a_m-b_m)v_m = 0 has a non-trivial solution since there exists at least one pair of a_i != b_i. Geometrically, one can see the below image, 3 vectors in a 2d-plane is necessarily linearly dependent, you can also verify that to get (10, 10) can be made up by (0, 10) + (10, 0), or 1*(10, 10), which has two representations.","title":"Linkedin Summary"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/#linear-independence-references","text":"https://www.machinelearningmindset.com/linear-independence-of-vectors/ https://math.stackexchange.com/questions/2779918/intuition-for-formal-definition-of-linear-independence https://medium.com/swlh/how-to-understand-linear-independence-linear-algebra-8bab1d918509 Linear Independence Wikipedia \u21a9 https://math.stackexchange.com/questions/2779918/intuition-for-formal-definition-of-linear-independence \u21a9","title":"Linear Independence References"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}}\\] Span Algebraic Definition (Span) Geometrical Definition (Span) Spanned By Span Membership (Examples) Theorem (Span is a subspace) Theorem (Span is a subspace and is the smallest subspace of V) Example (Different Sets can span the same Vector Space) Proof Theorem (Linear Dependence Span equals each other) Examples (Geometrical Interpretation of Span) Python (Two Linearly Independent Vectors in \\(\\mathbb R^3\\) Spans a Plane) Python (Two Linearly Dependent Vectors in \\(\\mathbb R^3\\) Spans a Line) Python (Three Linearly Inependent Vectors in \\(\\mathbb R^3\\) Spans the whole Ambient Space) Span Algebraic Definition (Span) Algebraic Definition (Span) Let \\(S \\subseteq V\\) be a non-empty subset of the vector space \\(V\\) . To be more explicit, define \\(S = \\{\\v_1, \\v_2, ..., \\v_m\\}\\) to be a subset in \\(V\\) , then the linear combination of all the vectors \\(\\v_1, \\v_2, ..., \\v_m\\) is called the span of \\(\\v_1, \\v_2, ..., \\v_m\\) , which we denote as follows: \\[\\text{span}(S) = \\text{span}(\\v_1, \\v_2,...,\\v_m) := \\{\\lambda_1\\v_1 + \\lambda_2\\v_2 + ... + \\lambda_m\\v_m : \\lambda_i \\in \\F, \\v_i \\in S\\}\\] Geometrical Definition (Span) Span is a really similar concept as subspace, and they are easy to confuse. A subspace is the region of ambient space that can be reached by any linear combination of a set of vectors. And then those vectors span that subspace. You can think about the difference using grammar: a subspace is a noun and span is a verb. A set of vectors spans, and the result of their spanning is a subspace. For example, the subspace defined as all of \\(\\R^2\\) can be created by the span of the vectors \\([0, 1]\\) and \\([1, 0]\\) . Another good example is the vector \\([0,1]\\) spans a 1D subspace that is embedded inside \\(\\R^2\\) (not \\(\\R^1\\) since the vector has 2 elements). Then the vector \\([1, 2]\\) also spans 1D subspace but it is a difference 1D subspace from that spanned by \\([0,1]\\) . - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 86) Spanned By If \\(W\\) is a vector subspace of \\(V\\) and \\(W = \\text{Span}(S)\\) , we say that \\(S\\) is a spanning set (or generating set) of \\(W\\) and \\(W\\) is spanned or generated by \\(S\\) . Important The intuition is that if a vector space \\(W\\) is spanned by a set of vectors \\(S\\) , then this means for every vector \\(\\w_i \\in W\\) , there exists scalars \\(\\lambda_i \\in \\F\\) , such that \\(\\w_i = \\lambda_1 \\w_1 + \\lambda_2 \\w_2 + \\cdots + \\lambda_m \\w_m\\) . In laymen terms, this set of vectors \\(S\\) can build up every single element in \\(W\\) . Span Membership (Examples) Example The author mentioned a commonly used terms in linear algebra, which is to check if one vector \\(\\v\\) is \"in the span\" of a set of vectors. This is illustrated clearly with the example provided below: \\[ \\v= \\begin{bmatrix} \\color{red}6 \\\\ \\color{red}3 \\\\ \\color{red}{0} \\end{bmatrix} ,\\quad \\w= \\begin{bmatrix} \\color{red}2 \\\\ \\color{red}3 \\\\ \\color{red}{-5} \\end{bmatrix} \\] and the set \\[ S = \\left\\{\\begin{bmatrix} \\color{red}2 \\\\ \\color{red}4 \\\\ \\color{red}{0} \\end{bmatrix}, \\begin{bmatrix} \\color{red}4 \\\\ \\color{red}{-1}\\\\ \\color{red}{0} \\end{bmatrix} \\right\\}\\] Then the question is whether \\(\\v\\) and \\(\\w\\) are in the span of \\(S\\) . In simple words, can the linear combination of the vectors \\(\\begin{bmatrix} \\color{red}2 \\\\ \\color{red}4 \\\\ \\color{red}{0} \\end{bmatrix}\\) and \\(\\begin{bmatrix} \\color{red}4 \\\\ \\color{red}{-1}\\\\ \\color{red}{0} \\end{bmatrix}\\) form \\(\\v\\) or \\(\\w\\) ? Well the answer for \\(\\v\\) is easy (purposely made easy), we just add them up and get \\(\\v\\) , and in this case, we say \\(\\v\\) is in the \\(\\text{span}(S)\\) . But for \\(\\w\\) , we can quickly conclude that \\(\\w \\not \\in \\text{span}(S)\\) because the third component of the span of \\(S\\) is still \\(0\\) , and thus no linear combination can ever form to \\(\\w\\) 's third component, \\(-5\\) . Theorem (Span is a subspace) Theorem (Span is a subspace) Let \\(V\\) be a vector space over a field \\(\\F\\) . Let \\(S \\subseteq V\\) be a subset of \\(V\\) . Then Span \\((S)\\) of \\(V\\) is a vector subspace of \\(V\\) . An immediate consequence of this definition is that span(S) must be a subspace of V. Why? Recall that to be a subspace, closure under vector addition and vector-scalar multiplication must be satisfied; this follows because the definition of span(S) is the linear combination of all vectors in S, and hence any vector addition or vector-scalar multiplication is a member of the linear combination. Note We will prove this together in the next theorem. Theorem (Span is a subspace and is the smallest subspace of V) Theorem (Span is a subspace and is the smallest subspace of V) Let \\(V\\) be a vector space over a field \\(\\F\\) . Let \\(S \\subseteq V\\) be a subset of \\(V\\) . Then \\(\\text{span}(S)\\) of \\(V\\) is a vector subspace of \\(V\\) . In particular, \\(\\text{span}(S)\\) is the smallest vector subspace of \\(V\\) containing the set \\(S\\) (or containing all the vectors in \\(S\\) ). Example (Different Sets can span the same Vector Space) Different Sets can span the same Vector Space Before we go through the proof, it is important to understand some possible confusions. One might be confused over the notion of smallest . We can motivate it with an example: \\[ S = \\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1} \\end{bmatrix} \\right\\}\\] spans the whole \\(\\R^2\\) space, although we have yet to learn any algorithmic way of checking whether a set spans a particular vector space, this is an obvious enough example (hopefully one can see that the linear combination of these two vectors can reach the whole ambient space \\(\\R^2\\) ). This is because the linear combination of vectors in \\(S\\) can form any vectors in the 2 dimensional space . Then consider \\[ S_1 = \\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1} \\end{bmatrix}, \\begin{bmatrix} \\color{red}1 \\\\ \\color{red}{1} \\end{bmatrix} \\right\\}\\] which also spans the whole \\(\\R^2\\) space as well. Both \\(S\\) and \\(S_1\\) are subsets of \\(\\R^2\\) and are subspaces themselves (by inspection). However, the cardinality or the len of \\(S\\) is 2 and \\(S_1\\) is 3. Since both sets span the \\(\\R^2\\) space, why do we say that the span is the smallest subspace of \\(V\\) when \\(S_1\\) has more \"elements\"? The confusion is that the theorem states that the span of a set of vectors in \\(V\\) is the smallest subspace of \\(V\\) which contains this set of vectors , not span of ANY set of vectors in \\(V\\) is the smallest subspace of \\(V\\) . Therefore, \\(S\\) is the smallest subspace of \\(V\\) which contains the two vectors \\(\\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1} \\end{bmatrix} \\right\\}\\) and \\(S_1\\) is the smallest subspace of \\(V\\) which contains the three vectors \\(\\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1} \\end{bmatrix}, \\begin{bmatrix} \\color{red}1 \\\\ \\color{red}{1} \\end{bmatrix} \\right\\}\\) . An extract from StackExchange : Written in words that theorem states, that any subspace \\(W\\) , that exists and contains \\(v_1,\u2026,v_n\\) , also contains \\(\\text{span}(v_1,\u2026,v_k)\\) . Hence \\(W\\) is larger (or equal) to \\(\\text{span}(v_1,\u2026,v_k)\\) , since it contains \\(\\text{span}(v_1,\u2026,v_k)\\) and could contain some more elements. And since any other subspace \\(W\\) is larger (or equal) it follows that \\(\\text{span}(v_1,\u2026,v_k)\\) the smallest subspace. That is like saying: Any number in \\(\u2115\u222a\\{0\\}\\) is larger (or equal) to \\(0\\) , hence \\(0\\) is the smallest number in \\(\u2115\u222a\\{0\\}\\) . Or even closer to the original problem: Any subset \\(M\u2282(\u2115\u222a\\{0\\})\\) with \\(0\u2208M\\) is larger or equal to \\(\\{0\\}\\) , hence \\(\\{0\\}\\) has to be the smallest subset of \\(\u2115\u222a\\{0\\}\\) that contains \\(0\\) . Proof Proof We first show that \\(\\text{span}(S)\\) is a vector subspace of \\(V\\) . And then we show that if \\(\\text{span}(S)\\) is a vector subspace of \\(V\\) containing \\(S\\) , then if \\(T\\) is another vector subspace of \\(V\\) containing \\(S\\) , we must have \\(\\text{span}(S) \\subseteq T\\) . \\(\\text{span}(S)\\) is a subspace : It suffices to check for the conditions S2 and S3 of subspaces . To show S2, we need to show that for any \\(\\v, \\w \\in \\text{span}(S)\\) , \\(\\v + \\w \\in \\text{span}(S)\\) . We also note that for both \\(\\v\\) and \\(\\w\\) , they can be expressed as linear combination of the set of vectors in \\(S\\) , (i.e. \\(\\v = a_1 \\v_1 + a_2 \\v2 + ... + a_m \\v_m\\) , \\(\\w = \\b_1 \\v_1 + \\b_2 \\v_2 + ... + \\b_m \\v_m\\) for some \\(a_i, b_i \\in \\F\\) ) Then adding them up we yield: \\[\\begin{align} \\v + \\w &= (a_1 \\v_1 + a_2 \\v2 + ... + a_m \\v_m) + (\\b_1 \\v_1 + \\b_2 \\v_2 + ... + \\b_m \\v_m) \\label{eq1}\\tag{1} \\\\ &= (a_1 + b_1)\\v_1 + (a_2 + b_2)\\v_2 + ... + (a_m + b_m)\\v_m \\label{eq2}\\tag{2} \\end{align}\\] Equation (\\ref{eq2}) shows us that it is still a linear combination of the set of vectors in \\(S\\) , and hence also in \\(\\text{span}(S)\\) , which is closed under addition. For S3, the same logic applies (can you show it?). \\(\\text{span}(S)\\) is the smallest subspace that contains \\(S\\) : Let \\(T\\) be any subspace of \\(V\\) that contains the set \\(S\\) . In order to show \\(\\text{span}(S) \\subseteq T\\) , we will use a proving method by showing that for all elements \\(\\v \\in \\text{span}(S)\\) , \\(\\v\\) is in \\(T\\) as well. We start off by picking any element \\(\\v \\in \\text{span}(S)\\) , (note that \\(\\v\\) may not be in \\(S\\) , but it definitely must be in \\(\\text{span}(S)\\) ! Do not get confused here!), for this \\(\\v\\) , it can be expressed as the linear combination of the vectors of \\(S\\) , \\(\\v =\\lambda_1\\v_1 + \\lambda_2\\v_2 + ... + \\lambda_m\\v_m\\) , then \\(\\v \\in T\\) as well since \\(T\\) contains the set \\(S\\) , and also is a subspace , thus closed under scalar multiplication and vector addition. Theorem (Linear Dependence Span equals each other) Theorem (Linear Dependence Span equals each other) Let \\(\\u_1,...,\\u_k\\) be vectors in \\(\\mathbb{R}^n\\) . If \\(\\u_k\\) is a linear combination of \\(\\mathbf{u_1,...,u_{k-1}}\\) , then \\[\\text{Span}\\{\\mathbf{u_1,...,u_{k-1}}\\} = \\text{Span}\\{\\mathbf{u_1,...,u_{k-1},u_k}\\}\\] This should be an obvious fact by using the same example in the Theorem (Span is a subspace and is the smallest subspace of \\(V\\) ) . Examples (Geometrical Interpretation of Span) Geometrical Interpretation of Span The \\(xz\\) -plane in \\(\\R^3\\) can be parameterized by the equations \\[x = t_1, \\;\\;\\; y = 0, \\;\\;\\; z = t_2.\\] As a subspace, the \\(xz\\) -plane is spanned by the vectors (1, 0, 0) and (0, 0, 1). Every vector in the \\(xz\\) -plane can be written as a linear combination of these two: \\[(t_1, 0, t_2) = t_1(1,0,0) + t_2(0,0,1)\\] Geometrically, this corresponds to the fact that every point on the \\(xz\\) -plane can be reached from the origin by first moving some distance in the direction of (1, 0, 0) and then moving some distance in the direction of (0, 0, 1). Python (Two Linearly Independent Vectors in \\(\\mathbb R^3\\) Spans a Plane) The below three examples are referenced from Macro Analyst's notes here 1 . The example below assumes the ambient space \\(\\R^3\\) and assumes that the term 2 linearly independent vectors just simply mean that these two vectors are not multiple of each other. We know that in earlier chapter that two linearly indepedent vectors in \\(\\R^3\\) space forms a subspace that is a plane. In fact, we can also say that two linearly independent vectors span a plane in \\(\\R^3\\) . We can verify below visually using python, with courtesy of MacroAnalyst's Linear Algebra with Python . Firstly, let's say we have two vectors: \\((3, 9, 2)\\) , \\((1,7,5)\\) which are linearly independent . The author made use of matrix multiplication in his code to demonstrate span. For more general span, a basic fact of matrix multiplication can assist us in demonstrating: \\[ AB = A[b_1\\ b_2\\ b_3,...,b_p]=[Ab_1\\ Ab_2\\ Ab_3,...,Ab_p] \\] where \\(A\\) is the spanning set of vectors, \\(b_k\\) is vector of weights for linear combination. We can generate a random matrix \\(B\\) to form various linear combinations to visually verify if they are all contained in the spanned plane. We define $$ A=\\left[\\begin{array}{rr} 3 & 1 \\ 9 & 7 \\ 2 & 5 \\end{array}\\right]\\qquad b_i\\sim N(\\mathbb{0}, 1) $$ In other words, the columns of \\(\\A\\) are the set of vectors \\[ S = \\left\\{\\begin{bmatrix} \\color{red}3 \\\\ \\color{red}9 \\\\ \\color{red}2 \\end{bmatrix}, \\begin{bmatrix} \\color{red}1 \\\\ \\color{red}7 \\\\ \\color{red}5 \\end{bmatrix} \\right\\}\\] and we want to generate say, 300 random linear combinations of this set of vectors and show visually that all these linear combinations are IN THE PLANE SPANNED BY THE SET OF VECTORS . Technically, there are infinite number of linear combinations, but we just show 300 for good illustration. Note that these 300 random linear combination are stored in the matrix \\(\\B\\) . import numpy as np import matplotlib.pyplot as plt from typing import List , Union , Tuple # The plane spanned by {[1,0,1], [0,1,1]} A = np . array ([[ 1 , 0 , 1 ], [ 0 , 1 , 1 ]]) . T B = 10 * np . random . randn ( 2 , 3000 ) # i = 300, i.e. 300 random weight vectors vecs = A @ B s = np . linspace ( - 10 , 10 , 10 ) t = np . linspace ( - 10 , 10 , 10 ) S , T = np . meshgrid ( s , t ) X = S Y = T Z = S + T fig , ax = plt . subplots ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = \"3d\" ) ax . plot_wireframe ( X , Y , Z , linewidth = 1.5 , color = \"k\" , alpha = 0.6 ) ax . scatter ( 0 , 0 , 0 , s = 200 , ec = \"red\" , fc = \"black\" ) colors = np . random . rand ( vecs . shape [ 1 ], 3 ) for i in range ( vecs . shape [ 1 ]): vec = np . array ([[ 0 , 0 , 0 , vecs [ 0 , i ], vecs [ 1 , i ], vecs [ 2 , i ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , color = colors [ i ], normalize = False , arrow_length_ratio = 0.07 , pivot = \"tail\" , linestyles = \"solid\" , linewidths = 2 , alpha = 0.9 , ) ax . view_init ( elev =- 156 , azim =- 56 ) fig . savefig ( \"span_plane.svg\" , format = \"svg\" , dpi = 600 ) plt . show () import numpy as np import matplotlib.pyplot as plt from typing import List , Union , Tuple # The plane spanned by {[3,9,2], [1,7,5]} A = np . array ([[ 3 , 9 , 2 ], [ 1 , 7 , 5 ]]) . T B = 10 * np . random . randn ( 2 , 3000 ) # i = 300, i.e. 300 random weight vectors vecs = A @ B s = np . linspace ( - 10 , 10 , 10 ) t = np . linspace ( - 10 , 10 , 10 ) S , T = np . meshgrid ( s , t ) X = 3 * S + T Y = 9 * S + 7 * T Z = 2 * S + 5 * T fig , ax = plt . subplots ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = \"3d\" ) ax . plot_wireframe ( X , Y , Z , linewidth = 1.5 , color = \"k\" , alpha = 0.6 ) ax . scatter ( 0 , 0 , 0 , s = 200 , ec = \"red\" , fc = \"black\" ) colors = np . random . rand ( vecs . shape [ 1 ], 3 ) for i in range ( vecs . shape [ 1 ]): vec = np . array ([[ 0 , 0 , 0 , vecs [ 0 , i ], vecs [ 1 , i ], vecs [ 2 , i ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , color = colors [ i ], normalize = False , arrow_length_ratio = 0.07 , pivot = \"tail\" , linestyles = \"solid\" , linewidths = 2 , alpha = 0.9 , ) ax . view_init ( elev =- 156 , azim =- 56 ) plt . show () Python (Two Linearly Dependent Vectors in \\(\\mathbb R^3\\) Spans a Line) What if the two vectors are not linear independent? Then the following example will convince you that two linearly dependent vectors span a line in \\(\\R^3\\) space. Note that this is equivalent to \"one vector\" in \\(\\R^3\\) spans a line. # Although spanned by 2 vectors, but actually reduces to 1 vector. # So it is a line. A = np . array ([[ 3 , 9 , 2 ], [ 6 , 18 , 4 ]]) . T B = 10 * np . random . randn ( 2 , 3000 ) # i = 300, i.e. 300 random weight vectors vecs = A @ B s = np . linspace ( - 10 , 10 , 10 ) t = np . linspace ( - 10 , 10 , 10 ) S , T = np . meshgrid ( s , t ) X = 3 * S + 6 * T Y = 9 * S + 18 * T Z = 2 * S + 4 * T fig , ax = plt . subplots ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = \"3d\" ) ax . plot_wireframe ( X , Y , Z , linewidth = 1.5 , color = \"k\" , alpha = 0.6 ) ax . scatter ( 0 , 0 , 0 , s = 200 , ec = \"red\" , fc = \"black\" ) colors = np . random . rand ( vecs . shape [ 1 ], 3 ) for i in range ( vecs . shape [ 1 ]): vec = np . array ([[ 0 , 0 , 0 , vecs [ 0 , i ], vecs [ 1 , i ], vecs [ 2 , i ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , color = colors [ i ], normalize = False , arrow_length_ratio = 0.07 , pivot = \"tail\" , linestyles = \"solid\" , linewidths = 2 , alpha = 0.9 , ) ax . view_init ( elev =- 156 , azim =- 56 ) fig . savefig ( \"span_line.svg\" , format = \"svg\" , dpi = 600 ) plt . show () Python (Three Linearly Inependent Vectors in \\(\\mathbb R^3\\) Spans the whole Ambient Space) Reproduce the code above, but we have three vectors: \\((1,0,1)\\) , \\((1,1,0)\\) , \\((0,1,1)\\) . Again we create a random coefficent matrix to form different linear combinations. A = np . array ([[ 1 , 0 , 1 ], [ 1 , 1 , 0 ], [ 0 , 1 , 1 ]]) . T B = 5 * np . random . randn ( 3 , 300 ) vecs = A @ B s = np . linspace ( - 10 , 10 , 10 ) t = np . linspace ( - 10 , 10 , 10 ) S , T = np . meshgrid ( s , t ) X = S + T Y = T Z = S fig , ax = plt . subplots ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = \"3d\" ) ax . plot_wireframe ( X , Y , Z , linewidth = 1.5 , color = \"k\" , alpha = 0.6 ) ax . scatter ( 0 , 0 , 0 , s = 200 , ec = \"red\" , fc = \"black\" ) colors = np . random . rand ( vecs . shape [ 1 ], 3 ) for i in range ( vecs . shape [ 1 ]): vec = np . array ([[ 0 , 0 , 0 , vecs [ 0 , i ], vecs [ 1 , i ], vecs [ 2 , i ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , color = colors [ i ], normalize = False , arrow_length_ratio = 0.07 , pivot = \"tail\" , linestyles = \"solid\" , linewidths = 2 , alpha = 0.9 , ) ax . view_init ( elev = 21 , azim =- 110 ) fig . savefig ( \"span_ambient_space.svg\" , format = \"svg\" , dpi = 600 ) plt . show () MacroAnalyst's Linear Algebra with Python . \u21a9","title":"Vector Span"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#span","text":"","title":"Span"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#algebraic-definition-span","text":"Algebraic Definition (Span) Let \\(S \\subseteq V\\) be a non-empty subset of the vector space \\(V\\) . To be more explicit, define \\(S = \\{\\v_1, \\v_2, ..., \\v_m\\}\\) to be a subset in \\(V\\) , then the linear combination of all the vectors \\(\\v_1, \\v_2, ..., \\v_m\\) is called the span of \\(\\v_1, \\v_2, ..., \\v_m\\) , which we denote as follows: \\[\\text{span}(S) = \\text{span}(\\v_1, \\v_2,...,\\v_m) := \\{\\lambda_1\\v_1 + \\lambda_2\\v_2 + ... + \\lambda_m\\v_m : \\lambda_i \\in \\F, \\v_i \\in S\\}\\]","title":"Algebraic Definition (Span)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#geometrical-definition-span","text":"Span is a really similar concept as subspace, and they are easy to confuse. A subspace is the region of ambient space that can be reached by any linear combination of a set of vectors. And then those vectors span that subspace. You can think about the difference using grammar: a subspace is a noun and span is a verb. A set of vectors spans, and the result of their spanning is a subspace. For example, the subspace defined as all of \\(\\R^2\\) can be created by the span of the vectors \\([0, 1]\\) and \\([1, 0]\\) . Another good example is the vector \\([0,1]\\) spans a 1D subspace that is embedded inside \\(\\R^2\\) (not \\(\\R^1\\) since the vector has 2 elements). Then the vector \\([1, 2]\\) also spans 1D subspace but it is a difference 1D subspace from that spanned by \\([0,1]\\) . - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 86)","title":"Geometrical Definition (Span)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#spanned-by","text":"If \\(W\\) is a vector subspace of \\(V\\) and \\(W = \\text{Span}(S)\\) , we say that \\(S\\) is a spanning set (or generating set) of \\(W\\) and \\(W\\) is spanned or generated by \\(S\\) . Important The intuition is that if a vector space \\(W\\) is spanned by a set of vectors \\(S\\) , then this means for every vector \\(\\w_i \\in W\\) , there exists scalars \\(\\lambda_i \\in \\F\\) , such that \\(\\w_i = \\lambda_1 \\w_1 + \\lambda_2 \\w_2 + \\cdots + \\lambda_m \\w_m\\) . In laymen terms, this set of vectors \\(S\\) can build up every single element in \\(W\\) .","title":"Spanned By"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#span-membership-examples","text":"Example The author mentioned a commonly used terms in linear algebra, which is to check if one vector \\(\\v\\) is \"in the span\" of a set of vectors. This is illustrated clearly with the example provided below: \\[ \\v= \\begin{bmatrix} \\color{red}6 \\\\ \\color{red}3 \\\\ \\color{red}{0} \\end{bmatrix} ,\\quad \\w= \\begin{bmatrix} \\color{red}2 \\\\ \\color{red}3 \\\\ \\color{red}{-5} \\end{bmatrix} \\] and the set \\[ S = \\left\\{\\begin{bmatrix} \\color{red}2 \\\\ \\color{red}4 \\\\ \\color{red}{0} \\end{bmatrix}, \\begin{bmatrix} \\color{red}4 \\\\ \\color{red}{-1}\\\\ \\color{red}{0} \\end{bmatrix} \\right\\}\\] Then the question is whether \\(\\v\\) and \\(\\w\\) are in the span of \\(S\\) . In simple words, can the linear combination of the vectors \\(\\begin{bmatrix} \\color{red}2 \\\\ \\color{red}4 \\\\ \\color{red}{0} \\end{bmatrix}\\) and \\(\\begin{bmatrix} \\color{red}4 \\\\ \\color{red}{-1}\\\\ \\color{red}{0} \\end{bmatrix}\\) form \\(\\v\\) or \\(\\w\\) ? Well the answer for \\(\\v\\) is easy (purposely made easy), we just add them up and get \\(\\v\\) , and in this case, we say \\(\\v\\) is in the \\(\\text{span}(S)\\) . But for \\(\\w\\) , we can quickly conclude that \\(\\w \\not \\in \\text{span}(S)\\) because the third component of the span of \\(S\\) is still \\(0\\) , and thus no linear combination can ever form to \\(\\w\\) 's third component, \\(-5\\) .","title":"Span Membership (Examples)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#theorem-span-is-a-subspace","text":"Theorem (Span is a subspace) Let \\(V\\) be a vector space over a field \\(\\F\\) . Let \\(S \\subseteq V\\) be a subset of \\(V\\) . Then Span \\((S)\\) of \\(V\\) is a vector subspace of \\(V\\) . An immediate consequence of this definition is that span(S) must be a subspace of V. Why? Recall that to be a subspace, closure under vector addition and vector-scalar multiplication must be satisfied; this follows because the definition of span(S) is the linear combination of all vectors in S, and hence any vector addition or vector-scalar multiplication is a member of the linear combination. Note We will prove this together in the next theorem.","title":"Theorem (Span is a subspace)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#theorem-span-is-a-subspace-and-is-the-smallest-subspace-of-v","text":"Theorem (Span is a subspace and is the smallest subspace of V) Let \\(V\\) be a vector space over a field \\(\\F\\) . Let \\(S \\subseteq V\\) be a subset of \\(V\\) . Then \\(\\text{span}(S)\\) of \\(V\\) is a vector subspace of \\(V\\) . In particular, \\(\\text{span}(S)\\) is the smallest vector subspace of \\(V\\) containing the set \\(S\\) (or containing all the vectors in \\(S\\) ).","title":"Theorem (Span is a subspace and is the smallest subspace of V)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#example-different-sets-can-span-the-same-vector-space","text":"Different Sets can span the same Vector Space Before we go through the proof, it is important to understand some possible confusions. One might be confused over the notion of smallest . We can motivate it with an example: \\[ S = \\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1} \\end{bmatrix} \\right\\}\\] spans the whole \\(\\R^2\\) space, although we have yet to learn any algorithmic way of checking whether a set spans a particular vector space, this is an obvious enough example (hopefully one can see that the linear combination of these two vectors can reach the whole ambient space \\(\\R^2\\) ). This is because the linear combination of vectors in \\(S\\) can form any vectors in the 2 dimensional space . Then consider \\[ S_1 = \\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1} \\end{bmatrix}, \\begin{bmatrix} \\color{red}1 \\\\ \\color{red}{1} \\end{bmatrix} \\right\\}\\] which also spans the whole \\(\\R^2\\) space as well. Both \\(S\\) and \\(S_1\\) are subsets of \\(\\R^2\\) and are subspaces themselves (by inspection). However, the cardinality or the len of \\(S\\) is 2 and \\(S_1\\) is 3. Since both sets span the \\(\\R^2\\) space, why do we say that the span is the smallest subspace of \\(V\\) when \\(S_1\\) has more \"elements\"? The confusion is that the theorem states that the span of a set of vectors in \\(V\\) is the smallest subspace of \\(V\\) which contains this set of vectors , not span of ANY set of vectors in \\(V\\) is the smallest subspace of \\(V\\) . Therefore, \\(S\\) is the smallest subspace of \\(V\\) which contains the two vectors \\(\\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1} \\end{bmatrix} \\right\\}\\) and \\(S_1\\) is the smallest subspace of \\(V\\) which contains the three vectors \\(\\left\\{\\begin{bmatrix} \\color{red}1 \\\\ \\color{red}0 \\end{bmatrix}, \\begin{bmatrix} \\color{red}0 \\\\ \\color{red}{1} \\end{bmatrix}, \\begin{bmatrix} \\color{red}1 \\\\ \\color{red}{1} \\end{bmatrix} \\right\\}\\) . An extract from StackExchange : Written in words that theorem states, that any subspace \\(W\\) , that exists and contains \\(v_1,\u2026,v_n\\) , also contains \\(\\text{span}(v_1,\u2026,v_k)\\) . Hence \\(W\\) is larger (or equal) to \\(\\text{span}(v_1,\u2026,v_k)\\) , since it contains \\(\\text{span}(v_1,\u2026,v_k)\\) and could contain some more elements. And since any other subspace \\(W\\) is larger (or equal) it follows that \\(\\text{span}(v_1,\u2026,v_k)\\) the smallest subspace. That is like saying: Any number in \\(\u2115\u222a\\{0\\}\\) is larger (or equal) to \\(0\\) , hence \\(0\\) is the smallest number in \\(\u2115\u222a\\{0\\}\\) . Or even closer to the original problem: Any subset \\(M\u2282(\u2115\u222a\\{0\\})\\) with \\(0\u2208M\\) is larger or equal to \\(\\{0\\}\\) , hence \\(\\{0\\}\\) has to be the smallest subset of \\(\u2115\u222a\\{0\\}\\) that contains \\(0\\) .","title":"Example (Different Sets can span the same Vector Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#proof","text":"Proof We first show that \\(\\text{span}(S)\\) is a vector subspace of \\(V\\) . And then we show that if \\(\\text{span}(S)\\) is a vector subspace of \\(V\\) containing \\(S\\) , then if \\(T\\) is another vector subspace of \\(V\\) containing \\(S\\) , we must have \\(\\text{span}(S) \\subseteq T\\) . \\(\\text{span}(S)\\) is a subspace : It suffices to check for the conditions S2 and S3 of subspaces . To show S2, we need to show that for any \\(\\v, \\w \\in \\text{span}(S)\\) , \\(\\v + \\w \\in \\text{span}(S)\\) . We also note that for both \\(\\v\\) and \\(\\w\\) , they can be expressed as linear combination of the set of vectors in \\(S\\) , (i.e. \\(\\v = a_1 \\v_1 + a_2 \\v2 + ... + a_m \\v_m\\) , \\(\\w = \\b_1 \\v_1 + \\b_2 \\v_2 + ... + \\b_m \\v_m\\) for some \\(a_i, b_i \\in \\F\\) ) Then adding them up we yield: \\[\\begin{align} \\v + \\w &= (a_1 \\v_1 + a_2 \\v2 + ... + a_m \\v_m) + (\\b_1 \\v_1 + \\b_2 \\v_2 + ... + \\b_m \\v_m) \\label{eq1}\\tag{1} \\\\ &= (a_1 + b_1)\\v_1 + (a_2 + b_2)\\v_2 + ... + (a_m + b_m)\\v_m \\label{eq2}\\tag{2} \\end{align}\\] Equation (\\ref{eq2}) shows us that it is still a linear combination of the set of vectors in \\(S\\) , and hence also in \\(\\text{span}(S)\\) , which is closed under addition. For S3, the same logic applies (can you show it?). \\(\\text{span}(S)\\) is the smallest subspace that contains \\(S\\) : Let \\(T\\) be any subspace of \\(V\\) that contains the set \\(S\\) . In order to show \\(\\text{span}(S) \\subseteq T\\) , we will use a proving method by showing that for all elements \\(\\v \\in \\text{span}(S)\\) , \\(\\v\\) is in \\(T\\) as well. We start off by picking any element \\(\\v \\in \\text{span}(S)\\) , (note that \\(\\v\\) may not be in \\(S\\) , but it definitely must be in \\(\\text{span}(S)\\) ! Do not get confused here!), for this \\(\\v\\) , it can be expressed as the linear combination of the vectors of \\(S\\) , \\(\\v =\\lambda_1\\v_1 + \\lambda_2\\v_2 + ... + \\lambda_m\\v_m\\) , then \\(\\v \\in T\\) as well since \\(T\\) contains the set \\(S\\) , and also is a subspace , thus closed under scalar multiplication and vector addition.","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#theorem-linear-dependence-span-equals-each-other","text":"Theorem (Linear Dependence Span equals each other) Let \\(\\u_1,...,\\u_k\\) be vectors in \\(\\mathbb{R}^n\\) . If \\(\\u_k\\) is a linear combination of \\(\\mathbf{u_1,...,u_{k-1}}\\) , then \\[\\text{Span}\\{\\mathbf{u_1,...,u_{k-1}}\\} = \\text{Span}\\{\\mathbf{u_1,...,u_{k-1},u_k}\\}\\] This should be an obvious fact by using the same example in the Theorem (Span is a subspace and is the smallest subspace of \\(V\\) ) .","title":"Theorem (Linear Dependence Span equals each other)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#examples","text":"","title":"Examples"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#geometrical-interpretation-of-span","text":"Geometrical Interpretation of Span The \\(xz\\) -plane in \\(\\R^3\\) can be parameterized by the equations \\[x = t_1, \\;\\;\\; y = 0, \\;\\;\\; z = t_2.\\] As a subspace, the \\(xz\\) -plane is spanned by the vectors (1, 0, 0) and (0, 0, 1). Every vector in the \\(xz\\) -plane can be written as a linear combination of these two: \\[(t_1, 0, t_2) = t_1(1,0,0) + t_2(0,0,1)\\] Geometrically, this corresponds to the fact that every point on the \\(xz\\) -plane can be reached from the origin by first moving some distance in the direction of (1, 0, 0) and then moving some distance in the direction of (0, 0, 1).","title":"(Geometrical Interpretation of Span)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#python-two-linearly-independent-vectors-in-mathbb-r3-spans-a-plane","text":"The below three examples are referenced from Macro Analyst's notes here 1 . The example below assumes the ambient space \\(\\R^3\\) and assumes that the term 2 linearly independent vectors just simply mean that these two vectors are not multiple of each other. We know that in earlier chapter that two linearly indepedent vectors in \\(\\R^3\\) space forms a subspace that is a plane. In fact, we can also say that two linearly independent vectors span a plane in \\(\\R^3\\) . We can verify below visually using python, with courtesy of MacroAnalyst's Linear Algebra with Python . Firstly, let's say we have two vectors: \\((3, 9, 2)\\) , \\((1,7,5)\\) which are linearly independent . The author made use of matrix multiplication in his code to demonstrate span. For more general span, a basic fact of matrix multiplication can assist us in demonstrating: \\[ AB = A[b_1\\ b_2\\ b_3,...,b_p]=[Ab_1\\ Ab_2\\ Ab_3,...,Ab_p] \\] where \\(A\\) is the spanning set of vectors, \\(b_k\\) is vector of weights for linear combination. We can generate a random matrix \\(B\\) to form various linear combinations to visually verify if they are all contained in the spanned plane. We define $$ A=\\left[\\begin{array}{rr} 3 & 1 \\ 9 & 7 \\ 2 & 5 \\end{array}\\right]\\qquad b_i\\sim N(\\mathbb{0}, 1) $$ In other words, the columns of \\(\\A\\) are the set of vectors \\[ S = \\left\\{\\begin{bmatrix} \\color{red}3 \\\\ \\color{red}9 \\\\ \\color{red}2 \\end{bmatrix}, \\begin{bmatrix} \\color{red}1 \\\\ \\color{red}7 \\\\ \\color{red}5 \\end{bmatrix} \\right\\}\\] and we want to generate say, 300 random linear combinations of this set of vectors and show visually that all these linear combinations are IN THE PLANE SPANNED BY THE SET OF VECTORS . Technically, there are infinite number of linear combinations, but we just show 300 for good illustration. Note that these 300 random linear combination are stored in the matrix \\(\\B\\) . import numpy as np import matplotlib.pyplot as plt from typing import List , Union , Tuple # The plane spanned by {[1,0,1], [0,1,1]} A = np . array ([[ 1 , 0 , 1 ], [ 0 , 1 , 1 ]]) . T B = 10 * np . random . randn ( 2 , 3000 ) # i = 300, i.e. 300 random weight vectors vecs = A @ B s = np . linspace ( - 10 , 10 , 10 ) t = np . linspace ( - 10 , 10 , 10 ) S , T = np . meshgrid ( s , t ) X = S Y = T Z = S + T fig , ax = plt . subplots ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = \"3d\" ) ax . plot_wireframe ( X , Y , Z , linewidth = 1.5 , color = \"k\" , alpha = 0.6 ) ax . scatter ( 0 , 0 , 0 , s = 200 , ec = \"red\" , fc = \"black\" ) colors = np . random . rand ( vecs . shape [ 1 ], 3 ) for i in range ( vecs . shape [ 1 ]): vec = np . array ([[ 0 , 0 , 0 , vecs [ 0 , i ], vecs [ 1 , i ], vecs [ 2 , i ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , color = colors [ i ], normalize = False , arrow_length_ratio = 0.07 , pivot = \"tail\" , linestyles = \"solid\" , linewidths = 2 , alpha = 0.9 , ) ax . view_init ( elev =- 156 , azim =- 56 ) fig . savefig ( \"span_plane.svg\" , format = \"svg\" , dpi = 600 ) plt . show () import numpy as np import matplotlib.pyplot as plt from typing import List , Union , Tuple # The plane spanned by {[3,9,2], [1,7,5]} A = np . array ([[ 3 , 9 , 2 ], [ 1 , 7 , 5 ]]) . T B = 10 * np . random . randn ( 2 , 3000 ) # i = 300, i.e. 300 random weight vectors vecs = A @ B s = np . linspace ( - 10 , 10 , 10 ) t = np . linspace ( - 10 , 10 , 10 ) S , T = np . meshgrid ( s , t ) X = 3 * S + T Y = 9 * S + 7 * T Z = 2 * S + 5 * T fig , ax = plt . subplots ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = \"3d\" ) ax . plot_wireframe ( X , Y , Z , linewidth = 1.5 , color = \"k\" , alpha = 0.6 ) ax . scatter ( 0 , 0 , 0 , s = 200 , ec = \"red\" , fc = \"black\" ) colors = np . random . rand ( vecs . shape [ 1 ], 3 ) for i in range ( vecs . shape [ 1 ]): vec = np . array ([[ 0 , 0 , 0 , vecs [ 0 , i ], vecs [ 1 , i ], vecs [ 2 , i ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , color = colors [ i ], normalize = False , arrow_length_ratio = 0.07 , pivot = \"tail\" , linestyles = \"solid\" , linewidths = 2 , alpha = 0.9 , ) ax . view_init ( elev =- 156 , azim =- 56 ) plt . show ()","title":"Python (Two Linearly Independent Vectors in \\(\\mathbb R^3\\) Spans a Plane)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#python-two-linearly-dependent-vectors-in-mathbb-r3-spans-a-line","text":"What if the two vectors are not linear independent? Then the following example will convince you that two linearly dependent vectors span a line in \\(\\R^3\\) space. Note that this is equivalent to \"one vector\" in \\(\\R^3\\) spans a line. # Although spanned by 2 vectors, but actually reduces to 1 vector. # So it is a line. A = np . array ([[ 3 , 9 , 2 ], [ 6 , 18 , 4 ]]) . T B = 10 * np . random . randn ( 2 , 3000 ) # i = 300, i.e. 300 random weight vectors vecs = A @ B s = np . linspace ( - 10 , 10 , 10 ) t = np . linspace ( - 10 , 10 , 10 ) S , T = np . meshgrid ( s , t ) X = 3 * S + 6 * T Y = 9 * S + 18 * T Z = 2 * S + 4 * T fig , ax = plt . subplots ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = \"3d\" ) ax . plot_wireframe ( X , Y , Z , linewidth = 1.5 , color = \"k\" , alpha = 0.6 ) ax . scatter ( 0 , 0 , 0 , s = 200 , ec = \"red\" , fc = \"black\" ) colors = np . random . rand ( vecs . shape [ 1 ], 3 ) for i in range ( vecs . shape [ 1 ]): vec = np . array ([[ 0 , 0 , 0 , vecs [ 0 , i ], vecs [ 1 , i ], vecs [ 2 , i ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , color = colors [ i ], normalize = False , arrow_length_ratio = 0.07 , pivot = \"tail\" , linestyles = \"solid\" , linewidths = 2 , alpha = 0.9 , ) ax . view_init ( elev =- 156 , azim =- 56 ) fig . savefig ( \"span_line.svg\" , format = \"svg\" , dpi = 600 ) plt . show ()","title":"Python (Two Linearly Dependent Vectors in \\(\\mathbb R^3\\) Spans a Line)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/#python-three-linearly-inependent-vectors-in-mathbb-r3-spans-the-whole-ambient-space","text":"Reproduce the code above, but we have three vectors: \\((1,0,1)\\) , \\((1,1,0)\\) , \\((0,1,1)\\) . Again we create a random coefficent matrix to form different linear combinations. A = np . array ([[ 1 , 0 , 1 ], [ 1 , 1 , 0 ], [ 0 , 1 , 1 ]]) . T B = 5 * np . random . randn ( 3 , 300 ) vecs = A @ B s = np . linspace ( - 10 , 10 , 10 ) t = np . linspace ( - 10 , 10 , 10 ) S , T = np . meshgrid ( s , t ) X = S + T Y = T Z = S fig , ax = plt . subplots ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = \"3d\" ) ax . plot_wireframe ( X , Y , Z , linewidth = 1.5 , color = \"k\" , alpha = 0.6 ) ax . scatter ( 0 , 0 , 0 , s = 200 , ec = \"red\" , fc = \"black\" ) colors = np . random . rand ( vecs . shape [ 1 ], 3 ) for i in range ( vecs . shape [ 1 ]): vec = np . array ([[ 0 , 0 , 0 , vecs [ 0 , i ], vecs [ 1 , i ], vecs [ 2 , i ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , color = colors [ i ], normalize = False , arrow_length_ratio = 0.07 , pivot = \"tail\" , linestyles = \"solid\" , linewidths = 2 , alpha = 0.9 , ) ax . view_init ( elev = 21 , azim =- 110 ) fig . savefig ( \"span_ambient_space.svg\" , format = \"svg\" , dpi = 600 ) plt . show () MacroAnalyst's Linear Algebra with Python . \u21a9","title":"Python (Three Linearly Inependent Vectors in \\(\\mathbb R^3\\) Spans the whole Ambient Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}}\\] Vector Spaces Notations Dimensions Algebraic Definition (Dimension) Geometric Definition (Dimension) Vector Space Definition (Vector Space) Vector Space over a Field Example of Vector Spaces over a Field Subspaces Geometric Definition (Subspaces) Algebraic Definition (Subspaces) Example and Intuition of Subspaces Theorem (The Subspace Criterion) Proof Linear Combination (Definition revisited) Theorem (Closure Linear Combination implies Subspace) Vector subspaces of \\(\\mathbb{R}^2\\) Examples of Non-Subspace Visualization of Subspaces in \\(\\mathbb{R}^2\\) Vector subspaces of \\(\\mathbb{R}^3\\) Visualization of Subspaces in \\(\\mathbb{R}^3\\) Theorem (Intersection of Subspaces is a Subspace) Proof Union of Two Subspaces may not be a Subspace Ambient Space Vector Spaces Notations For this section, we will treat our field \\(\\F\\) to be the real space \\(\\R\\) ; and when we later mention vector space or vector subspace \\(V\\) , we actually mean the vector space/subspace over the field \\(\\R\\) . Dimensions Normally, dimensions are formally defined after the introduction of basis. We will give an informal treatment of dimension here to better understand the idea when mentioning this word. Algebraic Definition (Dimension) Algebraic Definition Consider a vector \\(\\v \\in \\R^n\\) , then we can represent \\[ \\v= \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix} \\in \\R^n \\] and we can naively define the dimension of the vector to be the number of elements: \\[\\text{dim}(\\v) = |\\v| = n\\] Geometric Definition (Dimension) Geometric Definition The dimensionality of a vector is the number of coordinate axes in which that vector exists. A 2D vector is a line in a 2D space (think of the typical Cartesian XY plane); a 3D vector is a line in a 3D space. Note that both a 2D vector and a 3D vector are both lines, but they exist in a different number of dimensions. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 76) Vector Space Definition (Vector Space) Definition (Vector Space) A vector space is a set \\(V\\) consisting of the following: a) a field \\(\\F\\) , where the elements in \\(\\F\\) are called scalars . b) a non empty set \\(V\\) , where the elements in \\(V\\) are called vectors (be less pedantic about the word vectors as we can treat say polynomial ring as a vector space and we can also treat a field \\(\\F\\) over itself as a vector space as well. So the word vectors here are not only the usual ones we see in \"vectors\") c) an operation of vector addition \\(\\u + \\v\\) between every pair of vectors \\(\\u, \\v \\in V\\) and d) an operation of scalar multiplication \\(\\lambda\\v\\) between every \\(\\lambda \\in \\F\\) and every vector \\(\\v \\in V\\) . Furthermore, all elements in \\(V\\) must satisfy the closure properties and the following axioms: \\(\\textbf{V(0)}: \\textbf{Closure (Well Defined)}\\) : For all \\(\\mathbf{u,v} \\in V, \\mathbf{u+v} \\in V\\) ; For all \\(\\lambda \\in \\F\\) and \\(\\v \\in V\\) , then \\(\\lambda \\v \\in V\\) ; Consequently, all linear combinations of vectors in \\(V\\) is in \\(V\\) . \\(\\textbf{V(1)}: \\textbf{Existence of the Zero Vector (Additive Identity)}\\) : There exists a vector \\(\\mathbf{0} \\in V\\) , called the zero vector, such that \\(\\mathbf{v + 0 = u = 0+v}\\) for all \\(\\v \\in V\\) . We should know it is unique. \\(\\textbf{V(2)}: \\textbf{Commutative Law for Vector Addition}\\) : For all \\(\\mathbf{u,v} \\in V\\) , \\(\\mathbf{u+v = v+u}\\) . \\(\\textbf{V(3)}: \\textbf{Associative Law for Vector Addition}\\) : For all \\(\\mathbf{u,v,w} \\in V\\) , we have \\(\\mathbf{u + (v+w)} = \\mathbf{(u+v)+w}\\) . \\(\\textbf{V(4)}: \\textbf{Existence of Additive Inverse}\\) : For every vector \\(\\v \\in V\\) , there exists a vector \\(-\\v \\in V\\) such that \\(\\mathbf{v+(-v) = 0 = (-v)+v}\\) . \\(\\textbf{V(5)}: \\textbf{Existence of the Multiplicative Identity}\\) : There exists \\(\\mathbf{1}\\in V\\) such that \\(\\mathbf{1} \\times \\v = \\v \\times \\mathbf{1} = \\v\\) for all \\(\\v \\in \\F\\) . \\(\\textbf{V(6)}: \\textbf{Associative Law for Vector-Scalar Multiplication}\\) : For all \\(a,b \\in \\F\\) and \\(\\v \\in V\\) , we have \\(a(b\\v) = (ab)\\v\\) \\(\\textbf{V(7)}: \\textbf{Distributive Law}\\) : \\(a(\\mathbf{u+v}) = a\\u + a\\v ,~~~\\forall a \\in \\F, \\mathbf{u,v} \\in V\\) \\((a+b)\\v = a\\v + b\\v,~~~\\forall a,b \\in \\F, \\v \\in V\\) . Vector Space over a Field Warning Note carefully that a vector space \\(V\\) is dependent on the field \\(\\F\\) since scalar multiplication draws \\(\\lambda\\) from \\(\\F\\) . Thus, we don't usually talk only about vector space \\(V\\) alone, instead we use the notion of Vector Space over a Field \\(\\F\\) . Example of Vector Spaces over a Field Real Vector Space We can imagine elements \\(\\v \\in V\\) as vectors/lines/points. We can take the field \\(\\F\\) to be \\(\\R\\) . Then a vector space \\(V\\) over \\(\\R\\) is called the real vector space . Subspaces Geometric Definition (Subspaces) For a better treatment of understanding subspaces geometrically, do read page 79-80 of the book Linear Algebra: Theory, Intuition, Code . Algebraic Definition (Subspaces) Algebraic Definition (Subspaces) Let \\(V\\) be a vector space over a field \\(\\F\\) . A non empty subset \\(W \\subseteq V\\) of a vector space \\(V\\) is called a subspace of \\(V\\) if \\(W\\) is itself a vector space using the same vector addition and scalar multiplication as in \\(V\\) . Consequence Let \\(W \\subset V\\) and \\(\\w \\in W\\) , we must show that \\(W\\) obeys all conditions from the definition of a vector space . For any \\(\\w \\in W\\) , we must have \\(w \\in V\\) by definition of a subset; this means that \\(V2,V3,V5,V6,V7\\) are automatically true since \\(\\w \\in W \\subset V\\) . We just need to check if it satisfies \\(V0,V1,V6\\) , namely, the two closure properties, the existence of zero vector, and the existence of the additive inverse for vector addition. We take V2 as an example, take any two elements \\(\\w_1, \\w_2 \\in W\\) , then \\(\\w_1, \\w_2 \\in V\\) , and hence obeys V2. But we cannot say for sure about V1, as there is no guarantee the subset \\(W\\) will contain the zero vector! Example and Intuition of Subspaces Example and Intuition of Subspaces Let us start with an informal treatment of a subspace . First, we say that a subspace \\(W\\) of \\(V\\) must fulfill two conditions: \\(W\\) is a subset of \\(V\\) and; \\(W\\) is a vector space itself over the field \\(\\F\\) . The classic example of a \\(3\\) -dimensional real vector space is the Euclidean space \\(\\mathbb R^3\\) where \\(\\R^3 = \\{(x,y,z)~|~x,y,z \\in \\R\\}\\) , which is the 3-dimensional space, or to be more formal, it is the vector space \\(V\\) over \\(\\R\\) , a collection of all 3-tuple vectors. Now, consider the set \\(L = \\{\\lambda(1,2,3) ~|~ \\lambda \\in \\R\\}\\) , we check that the set \\(L\\) informally satisfies our conditions to be a subspace of \\(\\R^3\\) . I emphasized the word set because of the idea of subset , that is, a vector subspace first must be a subset of the vector space . Our \\(L\\) is a subset of \\(\\R^3\\) by definition, in fact, it is the set of all lines of the form \\(\\lambda(1,2,3)\\) . Only being a subset is not sufficient to be called a subspace , we have fulfilled the idea of a sub set, but not the space part. It suffices to check if our \\(L\\) is a valid vector space over \\(\\R\\) . And to check that we can use back the definition of vector space to do so. The main point is that a single vector, \\((1,2,3)\\) scaled by any \\(\\lambda \\in \\R\\) makes up a subspace . It also happens to be the 1D-subspace which is just a line. It is also important to mention that the line must pass through the origin to be considered a subspace . Next, consider the set \\(P = \\{\\lambda_1(1,0,0) + \\lambda_2(0,0,1) ~|~ \\lambda_i \\in \\R\\}\\) . Geometrically, we have known from earlier that these two vectors form a 2D-plane and we will show later that it is the 2D-subspace, a plane. Theorem (The Subspace Criterion) From the previous section, we know that we just need to check V0, V1 and V4 to be true. This reduces our conditions for \\(W \\subset V\\) to be a subspace to be as follows: Theorem (The Subspace Criterion) Let \\(V\\) be a vector space over a field \\(\\F\\) . A subset \\(W\\) of \\(V\\) is a subspace of \\(V\\) if and only if S1) \\(\\textbf{(Containing the Zero Vector)}\\) : \\(\\0 \\in W\\) ; S2) \\(\\textbf{(Closure under Vector Addition)}\\) : \\(\\forall \\mathbf{u,w} \\in W, \\u+\\w \\in W\\) S3) \\(\\textbf{(Closure under Scalar Multiplication)}\\) : \\(\\forall \\lambda \\in \\F\\) and \\(\\w \\in W\\) , we have \\(\\lambda\\w \\in W\\) . Proof Proof \\(\\Rightarrow\\) If \\(W\\) is also a subspace , then by the definition of subspace, \\(W\\) is also a vector space, and hence \\(S1,S2,S3\\) are satisfied. \\(\\Leftarrow\\) We should be clear that for other conditions V2, V3, V5, V6 and V7 do not warrant checking since these axioms are automatically satisfied for \\(W\\) since it holds for the larger subset \\(V\\) . We need only check the following: Zero Vector: If S1 is satisfied, then the corresponding V1 is satisfied. Closure Properties: S2 and S3 both implies V0. Additive Inverse for Vector Addition : Let \\(\\w \\in W\\) , take \\(-1 \\in \\F\\) , by S3 (closure of scalar multiplication), we must have \\(-1(\\w) \\in W\\) .$ This implies V4. One thing that you notice is that by the closure of addition \\(\\mathbf{w+(-w)} = \\mathbf{0} \\in W\\) or by the closure of scalar multiplication \\(0 \\cdot \\w = \\0 \\in W\\) (note \\(0 \\in \\F\\) ). Consequently, this implies that S2 and S3 are sufficient to imply S1 . You can trace the proof by ignoring the S1. Linear Combination (Definition revisited) Definition Let \\(V\\) be a vector space over a field \\(\\F\\) . A vector \\(\\v\\) is a linear combination of vectors \\(\\mathbf{v_1,v_2,...,v_m} \\in V\\) if \\( \\(\\v = \\lambda_1\\v_1+...+\\lambda_m\\mathbf{v_m}\\) \\) for some scalars \\(\\lambda_i \\in \\F\\) . Theorem (Closure Linear Combination implies Subspace) Theorem (Closure Linear Combination implies Subspace) Let \\(V\\) be a vector space over a field \\(\\F\\) and \\(W\\subseteq V\\) a non empty subset. Then \\(W\\) is a subspace of \\(V\\) if and only if \\(W\\) is closed under linear combination, (i.e \\(\\forall \\lambda_i \\in \\F, \\forall \\mathbf{w_i} \\in W \\Rightarrow \\lambda_1\\w_1+ \\lambda_2\\w_2 \\in W\\) ). This should not come as a surprise as this is just a rebranding of Conditions to be a Subspace Theorem (Equivalent Subspace Definition) . Vector subspaces of \\(\\mathbb{R}^2\\) There are three types of vector subspaces of the vector space \\(\\mathbb{R}^2\\) . i) The origin \\(\\mathbf{0} = \\{0,0\\}\\) ii) The line through the origin : \\(L = \\{\\lambda\\v~|~\\lambda \\in \\mathbb{R}, \\v \\in \\R^2\\}\\) iii) \\(\\mathbb{R}^2\\) Examples of Non-Subspace Non-Subspace Consider the set \\(L = \\{\\lambda (0, -3) ~|~ \\lambda \\in \\R\\}\\) , why is it not a subspace of \\(\\R^2\\) ? Though one can answer that since this line does not pass through the origin, and thus does not contain the zero vector, hence not a subspace, we can take a step back and think of it geometrically: We can check whether the line is closed under addition and vector-scalar multiplication. Geometrically, it seems that any two vectors inside the set will still be in the set since adding or subtracting vectors inside is just \"line + line | line - line\", which still lies on the same line. It is easy to gloss over that if you take \\(\\v\\) and \\(-\\v\\) from the set \\(L\\) , then the sum is the zero vector, which is not inside \\(L\\) . This can be further verified by vector-scalar, we can just take \\(0 \\in \\R\\) , and claim that \\(0\\v\\) for all \\(\\v \\in L\\) is not in \\(L\\) ! Visualization of Subspaces in \\(\\mathbb{R}^2\\) Courtesy of MacroAnalyst's Linear Algebra with Python . Notice that the line \\(y = -3 + \\frac{2}{3}x\\) does not pass through the origin \\((0, 0)\\) , and hence not a subspace. Note this example (line) is the set \\(L\\) in the previous example. import matplotlib.pyplot as plt import numpy as np fig , ax = plt . subplots ( figsize = ( 10 , 10 )) ####################### Arrows ####################### x = np . arange ( - 10 , 11 , 1 ) y = 4 / 6 * x ax . plot ( x , y , lw = 4 , color = \"blue\" , label = r \"$y = \\frac {2}{3} x$, subspace of $\\mathbf {R} ^2$\" , ) y = - 3 + 4 / 6 * x ax . plot ( x , y , lw = 4 , color = \"red\" , label = r \"$y = -3+\\frac {2}{3} x$, not a subspace of $\\mathbf {R} ^2$\" , ) ax . grid ( True ) ax . set_title ( \"Visualization of Subspace in $R^2$ \" , size = 18 ) ax . scatter ( 0 , 0 , s = 100 , fc = \"black\" , ec = \"red\" ) ax . text ( - 2 , 0 , \"$(0,0)$\" , size = 18 ) ax . legend ( fontsize = 16 ) ax . axis ([ - 10 , 10 , - 10 , 10 ]) ax . set_xlabel ( \"x-axis\" , size = 18 ) ax . set_ylabel ( \"y-axis\" , size = 18 ) plt . show () Vector subspaces of \\(\\mathbb{R}^3\\) There are four types of vector subspaces of the vector space \\(\\mathbb{R}^3\\) . i) The origin \\(\\mathbf{0} = \\{0,0,0\\}\\) ii) The line \\(L\\) passing through the origin: \\(L = \\{\\lambda \\v~|~\\lambda \\in \\mathbb{R}, \\v \\in \\R^3\\}\\) iii) A plane \\(P\\) passing through the origin: \\(P = \\{(x,y,z) \\in \\mathbb{R}^3~|~ ax + by + cz = 0\\}\\) iv) \\(\\mathbb{R}^3\\) Visualization of Subspaces in \\(\\mathbb{R}^3\\) Courtesy of MacroAnalyst's Linear Algebra with Python . We have not learnt of the term span , but for now when we say a span of two vectors \\(\\u\\) and \\(\\v\\) in \\(\\R^3\\) , it means these two vectors are not multiple of each other. Consider a span of two vectors \\(u = (1,-2,1)^T\\) and \\(v=(2,1,2)^T\\) . The span of \\((u,v)\\) is a subspace of \\(\\R^3\\) , where \\(s\\) and \\(t\\) are the scalars of the vectors. We also plot a plane which is not a subspace by adding \\(2\\) to the third equation: \\(z = s + 2t + 2\\) . import matplotlib.pyplot as plt import numpy as np # %matplotlib # %matplotlib notebook, use this only if you are in Jupyter Notebook fig = plt . figure ( figsize = ( 8 , 8 )) ax = fig . add_subplot ( 111 , projection = \"3d\" ) s = np . linspace ( - 1 , 1 , 10 ) t = np . linspace ( - 1 , 1 , 10 ) S , T = np . meshgrid ( s , t ) X = S + 2 * T Y = - 2 * S + T Z = S + 2 * T ax . plot_surface ( X , Y , Z , alpha = 0.9 , cmap = plt . cm . coolwarm ) Z2 = S + 2 * T + 2 # this is not a subspace anymore ax . plot_surface ( X , Y , Z2 , alpha = 0.6 , cmap = plt . cm . jet ) ax . scatter ( 0 , 0 , 0 , s = 200 , color = \"red\" ) ax . text ( 0 , 0 , 0 , \"$(0,0,0)$\" , size = 18 , zorder = 5 ) ax . set_title ( \"Visualization of Subspace of $\\mathbb {R} ^3$\" , x = 0.5 , y = 1.1 , size = 20 ) ax . set_xlabel ( \"x-axis\" , size = 18 ) ax . set_ylabel ( \"y-axis\" , size = 18 ) ax . set_zlabel ( \"z-axis\" , size = 18 ) ax . view_init ( elev =- 29 , azim = 132 ) plt . show () Theorem (Intersection of Subspaces is a Subspace) Theorem (Intersection of Subspaces is a Subspace) Let \\(V\\) be a vector space over a field \\(\\F\\) and let \\(W_\\alpha \\subseteq V\\) ( \\(\\alpha \\in I\\) ) be vector subspaces of \\(V\\) , then the intersection \\( \\(\\cap_{\\alpha \\in I}W_\\alpha\\) \\) is again a vector subspace of \\(V\\) . Proof Proof Before we start, the intuition is simple, call \\(C = A \\cap B\\) , and to think intuitively that \\(C\\) is itself a subspace, we just take an element \\(\\mathbf{c_1}, \\mathbf{c_2} \\in C\\) and \\(\\lambda \\in \\F\\) , and ask whether these vectors obey the closure property. For a start, for any two vectors in \\(C\\) , they are closed under addition because both vectors are elements of \\(A\\) and (or) \\(B\\) . Let \\(W_1\\) and \\(W_2\\) be subspaces of a vector space \\(V\\) , then it suffices for us to just prove \\(W_1 \\cap W_2\\) is a subspace of \\(V\\) as we can use induction to prove for \\(n\\) intersections. We denote the subset \\(W_1 \\cap W_2\\) to be \\(U\\) . Closed under Vector Addition: To show that \\(U\\) has closure properties, we take any element \\(\\mathbf{u_1}, \\mathbf{u_2} \\in U\\) , any \\(\\lambda \\in \\mathbb{F}\\) and show that \\(\\mathbf{u_1} + \\mathbf{u_2} \\in U\\) and \\(\\lambda \\mathbf{u} \\in U\\) . Since \\(\\mathbf{u_1}, \\mathbf{u_2} \\in U\\) , then \\(\\mathbf{u_1}, \\mathbf{u_2} \\in W_1\\) and \\(\\mathbf{u_1}, \\mathbf{u_2} \\in W_2\\) respectively. This means that \\(\\mathbf{u_1} + \\mathbf{u_2} \\in W_1\\) and \\(\\mathbf{u_1} + \\mathbf{u_2} \\in W_2\\) since both \\(W_1\\) and \\(W_2\\) are closed under addition. Consequently, another way of saying \\(\\mathbf{u_1} + \\mathbf{u_2} \\in W_1\\) and \\(\\mathbf{u_1} + \\mathbf{u_2} \\in W_2\\) is \\(\\mathbf{u_1} + \\mathbf{u_2} \\in W_1 \\cap W_2 = U\\) , which implies that \\(U\\) is closed under vector addition. Closed under Vector-Scalar Multiplication: The same line of logic can be applied for closure under vector-scalar multiplication. We have shown that \\(W_1 \\cap W_2\\) is a subspace. Union of Two Subspaces may not be a Subspace The union of two subspaces may not be a subspace. The reason why this can happen is that all vector spaces, and hence subspaces too, must be closed under addition (and scalar multiplication). The union of two subspaces takes all the elements already in those spaces, and nothing more. In the union of subspaces \\(W_1\\) and \\(W_2\\) , there are new combinations of vectors we can add together that we couldn't before, like \\(\\w_1 + \\w_2\\) where \\(\\w_1 \\in W_1\\) and \\(\\w_2 \\in W_2\\) . For example, take \\(W_1\\) to be the \\(x\\) -axis and \\(W_2\\) the \\(y\\) -axis, both subspaces of \\(\\mathbb{R}^2\\) . Their union includes both \\((3,0)\\) and \\((0,5)\\) , whose sum, \\((3,5)\\) , is not in the union. Hence, the union is not a vector space. Ambient Space The term ambient space is used frequently in the book. We can understand it with an example: Example If you are dealing with a vector subspace \\(U\\) as a subset of \\(\\mathbb R^2\\) , the ambient space is \\(\\mathbb R^2\\) . So basically, the ambient space is the \"parent space\" of the subspace.","title":"Vector Space and Subspaces"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#vector-spaces","text":"","title":"Vector Spaces"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#notations","text":"For this section, we will treat our field \\(\\F\\) to be the real space \\(\\R\\) ; and when we later mention vector space or vector subspace \\(V\\) , we actually mean the vector space/subspace over the field \\(\\R\\) .","title":"Notations"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#dimensions","text":"Normally, dimensions are formally defined after the introduction of basis. We will give an informal treatment of dimension here to better understand the idea when mentioning this word.","title":"Dimensions"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#algebraic-definition-dimension","text":"Algebraic Definition Consider a vector \\(\\v \\in \\R^n\\) , then we can represent \\[ \\v= \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix} \\in \\R^n \\] and we can naively define the dimension of the vector to be the number of elements: \\[\\text{dim}(\\v) = |\\v| = n\\]","title":"Algebraic Definition (Dimension)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#geometric-definition-dimension","text":"Geometric Definition The dimensionality of a vector is the number of coordinate axes in which that vector exists. A 2D vector is a line in a 2D space (think of the typical Cartesian XY plane); a 3D vector is a line in a 3D space. Note that both a 2D vector and a 3D vector are both lines, but they exist in a different number of dimensions. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 76)","title":"Geometric Definition (Dimension)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#vector-space","text":"","title":"Vector Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#definition-vector-space","text":"Definition (Vector Space) A vector space is a set \\(V\\) consisting of the following: a) a field \\(\\F\\) , where the elements in \\(\\F\\) are called scalars . b) a non empty set \\(V\\) , where the elements in \\(V\\) are called vectors (be less pedantic about the word vectors as we can treat say polynomial ring as a vector space and we can also treat a field \\(\\F\\) over itself as a vector space as well. So the word vectors here are not only the usual ones we see in \"vectors\") c) an operation of vector addition \\(\\u + \\v\\) between every pair of vectors \\(\\u, \\v \\in V\\) and d) an operation of scalar multiplication \\(\\lambda\\v\\) between every \\(\\lambda \\in \\F\\) and every vector \\(\\v \\in V\\) . Furthermore, all elements in \\(V\\) must satisfy the closure properties and the following axioms: \\(\\textbf{V(0)}: \\textbf{Closure (Well Defined)}\\) : For all \\(\\mathbf{u,v} \\in V, \\mathbf{u+v} \\in V\\) ; For all \\(\\lambda \\in \\F\\) and \\(\\v \\in V\\) , then \\(\\lambda \\v \\in V\\) ; Consequently, all linear combinations of vectors in \\(V\\) is in \\(V\\) . \\(\\textbf{V(1)}: \\textbf{Existence of the Zero Vector (Additive Identity)}\\) : There exists a vector \\(\\mathbf{0} \\in V\\) , called the zero vector, such that \\(\\mathbf{v + 0 = u = 0+v}\\) for all \\(\\v \\in V\\) . We should know it is unique. \\(\\textbf{V(2)}: \\textbf{Commutative Law for Vector Addition}\\) : For all \\(\\mathbf{u,v} \\in V\\) , \\(\\mathbf{u+v = v+u}\\) . \\(\\textbf{V(3)}: \\textbf{Associative Law for Vector Addition}\\) : For all \\(\\mathbf{u,v,w} \\in V\\) , we have \\(\\mathbf{u + (v+w)} = \\mathbf{(u+v)+w}\\) . \\(\\textbf{V(4)}: \\textbf{Existence of Additive Inverse}\\) : For every vector \\(\\v \\in V\\) , there exists a vector \\(-\\v \\in V\\) such that \\(\\mathbf{v+(-v) = 0 = (-v)+v}\\) . \\(\\textbf{V(5)}: \\textbf{Existence of the Multiplicative Identity}\\) : There exists \\(\\mathbf{1}\\in V\\) such that \\(\\mathbf{1} \\times \\v = \\v \\times \\mathbf{1} = \\v\\) for all \\(\\v \\in \\F\\) . \\(\\textbf{V(6)}: \\textbf{Associative Law for Vector-Scalar Multiplication}\\) : For all \\(a,b \\in \\F\\) and \\(\\v \\in V\\) , we have \\(a(b\\v) = (ab)\\v\\) \\(\\textbf{V(7)}: \\textbf{Distributive Law}\\) : \\(a(\\mathbf{u+v}) = a\\u + a\\v ,~~~\\forall a \\in \\F, \\mathbf{u,v} \\in V\\) \\((a+b)\\v = a\\v + b\\v,~~~\\forall a,b \\in \\F, \\v \\in V\\) .","title":"Definition (Vector Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#vector-space-over-a-field","text":"Warning Note carefully that a vector space \\(V\\) is dependent on the field \\(\\F\\) since scalar multiplication draws \\(\\lambda\\) from \\(\\F\\) . Thus, we don't usually talk only about vector space \\(V\\) alone, instead we use the notion of Vector Space over a Field \\(\\F\\) .","title":"Vector Space over a Field"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#example-of-vector-spaces-over-a-field","text":"Real Vector Space We can imagine elements \\(\\v \\in V\\) as vectors/lines/points. We can take the field \\(\\F\\) to be \\(\\R\\) . Then a vector space \\(V\\) over \\(\\R\\) is called the real vector space .","title":"Example of Vector Spaces over a Field"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#subspaces","text":"","title":"Subspaces"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#geometric-definition-subspaces","text":"For a better treatment of understanding subspaces geometrically, do read page 79-80 of the book Linear Algebra: Theory, Intuition, Code .","title":"Geometric Definition (Subspaces)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#algebraic-definition-subspaces","text":"Algebraic Definition (Subspaces) Let \\(V\\) be a vector space over a field \\(\\F\\) . A non empty subset \\(W \\subseteq V\\) of a vector space \\(V\\) is called a subspace of \\(V\\) if \\(W\\) is itself a vector space using the same vector addition and scalar multiplication as in \\(V\\) . Consequence Let \\(W \\subset V\\) and \\(\\w \\in W\\) , we must show that \\(W\\) obeys all conditions from the definition of a vector space . For any \\(\\w \\in W\\) , we must have \\(w \\in V\\) by definition of a subset; this means that \\(V2,V3,V5,V6,V7\\) are automatically true since \\(\\w \\in W \\subset V\\) . We just need to check if it satisfies \\(V0,V1,V6\\) , namely, the two closure properties, the existence of zero vector, and the existence of the additive inverse for vector addition. We take V2 as an example, take any two elements \\(\\w_1, \\w_2 \\in W\\) , then \\(\\w_1, \\w_2 \\in V\\) , and hence obeys V2. But we cannot say for sure about V1, as there is no guarantee the subset \\(W\\) will contain the zero vector!","title":"Algebraic Definition (Subspaces)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#example-and-intuition-of-subspaces","text":"Example and Intuition of Subspaces Let us start with an informal treatment of a subspace . First, we say that a subspace \\(W\\) of \\(V\\) must fulfill two conditions: \\(W\\) is a subset of \\(V\\) and; \\(W\\) is a vector space itself over the field \\(\\F\\) . The classic example of a \\(3\\) -dimensional real vector space is the Euclidean space \\(\\mathbb R^3\\) where \\(\\R^3 = \\{(x,y,z)~|~x,y,z \\in \\R\\}\\) , which is the 3-dimensional space, or to be more formal, it is the vector space \\(V\\) over \\(\\R\\) , a collection of all 3-tuple vectors. Now, consider the set \\(L = \\{\\lambda(1,2,3) ~|~ \\lambda \\in \\R\\}\\) , we check that the set \\(L\\) informally satisfies our conditions to be a subspace of \\(\\R^3\\) . I emphasized the word set because of the idea of subset , that is, a vector subspace first must be a subset of the vector space . Our \\(L\\) is a subset of \\(\\R^3\\) by definition, in fact, it is the set of all lines of the form \\(\\lambda(1,2,3)\\) . Only being a subset is not sufficient to be called a subspace , we have fulfilled the idea of a sub set, but not the space part. It suffices to check if our \\(L\\) is a valid vector space over \\(\\R\\) . And to check that we can use back the definition of vector space to do so. The main point is that a single vector, \\((1,2,3)\\) scaled by any \\(\\lambda \\in \\R\\) makes up a subspace . It also happens to be the 1D-subspace which is just a line. It is also important to mention that the line must pass through the origin to be considered a subspace . Next, consider the set \\(P = \\{\\lambda_1(1,0,0) + \\lambda_2(0,0,1) ~|~ \\lambda_i \\in \\R\\}\\) . Geometrically, we have known from earlier that these two vectors form a 2D-plane and we will show later that it is the 2D-subspace, a plane.","title":"Example and Intuition of Subspaces"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#theorem-the-subspace-criterion","text":"From the previous section, we know that we just need to check V0, V1 and V4 to be true. This reduces our conditions for \\(W \\subset V\\) to be a subspace to be as follows: Theorem (The Subspace Criterion) Let \\(V\\) be a vector space over a field \\(\\F\\) . A subset \\(W\\) of \\(V\\) is a subspace of \\(V\\) if and only if S1) \\(\\textbf{(Containing the Zero Vector)}\\) : \\(\\0 \\in W\\) ; S2) \\(\\textbf{(Closure under Vector Addition)}\\) : \\(\\forall \\mathbf{u,w} \\in W, \\u+\\w \\in W\\) S3) \\(\\textbf{(Closure under Scalar Multiplication)}\\) : \\(\\forall \\lambda \\in \\F\\) and \\(\\w \\in W\\) , we have \\(\\lambda\\w \\in W\\) .","title":"Theorem (The Subspace Criterion)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#proof","text":"Proof \\(\\Rightarrow\\) If \\(W\\) is also a subspace , then by the definition of subspace, \\(W\\) is also a vector space, and hence \\(S1,S2,S3\\) are satisfied. \\(\\Leftarrow\\) We should be clear that for other conditions V2, V3, V5, V6 and V7 do not warrant checking since these axioms are automatically satisfied for \\(W\\) since it holds for the larger subset \\(V\\) . We need only check the following: Zero Vector: If S1 is satisfied, then the corresponding V1 is satisfied. Closure Properties: S2 and S3 both implies V0. Additive Inverse for Vector Addition : Let \\(\\w \\in W\\) , take \\(-1 \\in \\F\\) , by S3 (closure of scalar multiplication), we must have \\(-1(\\w) \\in W\\) .$ This implies V4. One thing that you notice is that by the closure of addition \\(\\mathbf{w+(-w)} = \\mathbf{0} \\in W\\) or by the closure of scalar multiplication \\(0 \\cdot \\w = \\0 \\in W\\) (note \\(0 \\in \\F\\) ). Consequently, this implies that S2 and S3 are sufficient to imply S1 . You can trace the proof by ignoring the S1.","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#linear-combination-definition-revisited","text":"Definition Let \\(V\\) be a vector space over a field \\(\\F\\) . A vector \\(\\v\\) is a linear combination of vectors \\(\\mathbf{v_1,v_2,...,v_m} \\in V\\) if \\( \\(\\v = \\lambda_1\\v_1+...+\\lambda_m\\mathbf{v_m}\\) \\) for some scalars \\(\\lambda_i \\in \\F\\) .","title":"Linear Combination (Definition revisited)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#theorem-closure-linear-combination-implies-subspace","text":"Theorem (Closure Linear Combination implies Subspace) Let \\(V\\) be a vector space over a field \\(\\F\\) and \\(W\\subseteq V\\) a non empty subset. Then \\(W\\) is a subspace of \\(V\\) if and only if \\(W\\) is closed under linear combination, (i.e \\(\\forall \\lambda_i \\in \\F, \\forall \\mathbf{w_i} \\in W \\Rightarrow \\lambda_1\\w_1+ \\lambda_2\\w_2 \\in W\\) ). This should not come as a surprise as this is just a rebranding of Conditions to be a Subspace Theorem (Equivalent Subspace Definition) .","title":"Theorem (Closure Linear Combination implies Subspace)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#vector-subspaces-of-mathbbr2","text":"There are three types of vector subspaces of the vector space \\(\\mathbb{R}^2\\) . i) The origin \\(\\mathbf{0} = \\{0,0\\}\\) ii) The line through the origin : \\(L = \\{\\lambda\\v~|~\\lambda \\in \\mathbb{R}, \\v \\in \\R^2\\}\\) iii) \\(\\mathbb{R}^2\\)","title":"Vector subspaces of \\(\\mathbb{R}^2\\)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#examples-of-non-subspace","text":"Non-Subspace Consider the set \\(L = \\{\\lambda (0, -3) ~|~ \\lambda \\in \\R\\}\\) , why is it not a subspace of \\(\\R^2\\) ? Though one can answer that since this line does not pass through the origin, and thus does not contain the zero vector, hence not a subspace, we can take a step back and think of it geometrically: We can check whether the line is closed under addition and vector-scalar multiplication. Geometrically, it seems that any two vectors inside the set will still be in the set since adding or subtracting vectors inside is just \"line + line | line - line\", which still lies on the same line. It is easy to gloss over that if you take \\(\\v\\) and \\(-\\v\\) from the set \\(L\\) , then the sum is the zero vector, which is not inside \\(L\\) . This can be further verified by vector-scalar, we can just take \\(0 \\in \\R\\) , and claim that \\(0\\v\\) for all \\(\\v \\in L\\) is not in \\(L\\) !","title":"Examples of Non-Subspace"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#visualization-of-subspaces-in-mathbbr2","text":"Courtesy of MacroAnalyst's Linear Algebra with Python . Notice that the line \\(y = -3 + \\frac{2}{3}x\\) does not pass through the origin \\((0, 0)\\) , and hence not a subspace. Note this example (line) is the set \\(L\\) in the previous example. import matplotlib.pyplot as plt import numpy as np fig , ax = plt . subplots ( figsize = ( 10 , 10 )) ####################### Arrows ####################### x = np . arange ( - 10 , 11 , 1 ) y = 4 / 6 * x ax . plot ( x , y , lw = 4 , color = \"blue\" , label = r \"$y = \\frac {2}{3} x$, subspace of $\\mathbf {R} ^2$\" , ) y = - 3 + 4 / 6 * x ax . plot ( x , y , lw = 4 , color = \"red\" , label = r \"$y = -3+\\frac {2}{3} x$, not a subspace of $\\mathbf {R} ^2$\" , ) ax . grid ( True ) ax . set_title ( \"Visualization of Subspace in $R^2$ \" , size = 18 ) ax . scatter ( 0 , 0 , s = 100 , fc = \"black\" , ec = \"red\" ) ax . text ( - 2 , 0 , \"$(0,0)$\" , size = 18 ) ax . legend ( fontsize = 16 ) ax . axis ([ - 10 , 10 , - 10 , 10 ]) ax . set_xlabel ( \"x-axis\" , size = 18 ) ax . set_ylabel ( \"y-axis\" , size = 18 ) plt . show ()","title":"Visualization of Subspaces in \\(\\mathbb{R}^2\\)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#vector-subspaces-of-mathbbr3","text":"There are four types of vector subspaces of the vector space \\(\\mathbb{R}^3\\) . i) The origin \\(\\mathbf{0} = \\{0,0,0\\}\\) ii) The line \\(L\\) passing through the origin: \\(L = \\{\\lambda \\v~|~\\lambda \\in \\mathbb{R}, \\v \\in \\R^3\\}\\) iii) A plane \\(P\\) passing through the origin: \\(P = \\{(x,y,z) \\in \\mathbb{R}^3~|~ ax + by + cz = 0\\}\\) iv) \\(\\mathbb{R}^3\\)","title":"Vector subspaces of \\(\\mathbb{R}^3\\)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#visualization-of-subspaces-in-mathbbr3","text":"Courtesy of MacroAnalyst's Linear Algebra with Python . We have not learnt of the term span , but for now when we say a span of two vectors \\(\\u\\) and \\(\\v\\) in \\(\\R^3\\) , it means these two vectors are not multiple of each other. Consider a span of two vectors \\(u = (1,-2,1)^T\\) and \\(v=(2,1,2)^T\\) . The span of \\((u,v)\\) is a subspace of \\(\\R^3\\) , where \\(s\\) and \\(t\\) are the scalars of the vectors. We also plot a plane which is not a subspace by adding \\(2\\) to the third equation: \\(z = s + 2t + 2\\) . import matplotlib.pyplot as plt import numpy as np # %matplotlib # %matplotlib notebook, use this only if you are in Jupyter Notebook fig = plt . figure ( figsize = ( 8 , 8 )) ax = fig . add_subplot ( 111 , projection = \"3d\" ) s = np . linspace ( - 1 , 1 , 10 ) t = np . linspace ( - 1 , 1 , 10 ) S , T = np . meshgrid ( s , t ) X = S + 2 * T Y = - 2 * S + T Z = S + 2 * T ax . plot_surface ( X , Y , Z , alpha = 0.9 , cmap = plt . cm . coolwarm ) Z2 = S + 2 * T + 2 # this is not a subspace anymore ax . plot_surface ( X , Y , Z2 , alpha = 0.6 , cmap = plt . cm . jet ) ax . scatter ( 0 , 0 , 0 , s = 200 , color = \"red\" ) ax . text ( 0 , 0 , 0 , \"$(0,0,0)$\" , size = 18 , zorder = 5 ) ax . set_title ( \"Visualization of Subspace of $\\mathbb {R} ^3$\" , x = 0.5 , y = 1.1 , size = 20 ) ax . set_xlabel ( \"x-axis\" , size = 18 ) ax . set_ylabel ( \"y-axis\" , size = 18 ) ax . set_zlabel ( \"z-axis\" , size = 18 ) ax . view_init ( elev =- 29 , azim = 132 ) plt . show ()","title":"Visualization of Subspaces in \\(\\mathbb{R}^3\\)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#theorem-intersection-of-subspaces-is-a-subspace","text":"Theorem (Intersection of Subspaces is a Subspace) Let \\(V\\) be a vector space over a field \\(\\F\\) and let \\(W_\\alpha \\subseteq V\\) ( \\(\\alpha \\in I\\) ) be vector subspaces of \\(V\\) , then the intersection \\( \\(\\cap_{\\alpha \\in I}W_\\alpha\\) \\) is again a vector subspace of \\(V\\) .","title":"Theorem (Intersection of Subspaces is a Subspace)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#proof_1","text":"Proof Before we start, the intuition is simple, call \\(C = A \\cap B\\) , and to think intuitively that \\(C\\) is itself a subspace, we just take an element \\(\\mathbf{c_1}, \\mathbf{c_2} \\in C\\) and \\(\\lambda \\in \\F\\) , and ask whether these vectors obey the closure property. For a start, for any two vectors in \\(C\\) , they are closed under addition because both vectors are elements of \\(A\\) and (or) \\(B\\) . Let \\(W_1\\) and \\(W_2\\) be subspaces of a vector space \\(V\\) , then it suffices for us to just prove \\(W_1 \\cap W_2\\) is a subspace of \\(V\\) as we can use induction to prove for \\(n\\) intersections. We denote the subset \\(W_1 \\cap W_2\\) to be \\(U\\) . Closed under Vector Addition: To show that \\(U\\) has closure properties, we take any element \\(\\mathbf{u_1}, \\mathbf{u_2} \\in U\\) , any \\(\\lambda \\in \\mathbb{F}\\) and show that \\(\\mathbf{u_1} + \\mathbf{u_2} \\in U\\) and \\(\\lambda \\mathbf{u} \\in U\\) . Since \\(\\mathbf{u_1}, \\mathbf{u_2} \\in U\\) , then \\(\\mathbf{u_1}, \\mathbf{u_2} \\in W_1\\) and \\(\\mathbf{u_1}, \\mathbf{u_2} \\in W_2\\) respectively. This means that \\(\\mathbf{u_1} + \\mathbf{u_2} \\in W_1\\) and \\(\\mathbf{u_1} + \\mathbf{u_2} \\in W_2\\) since both \\(W_1\\) and \\(W_2\\) are closed under addition. Consequently, another way of saying \\(\\mathbf{u_1} + \\mathbf{u_2} \\in W_1\\) and \\(\\mathbf{u_1} + \\mathbf{u_2} \\in W_2\\) is \\(\\mathbf{u_1} + \\mathbf{u_2} \\in W_1 \\cap W_2 = U\\) , which implies that \\(U\\) is closed under vector addition. Closed under Vector-Scalar Multiplication: The same line of logic can be applied for closure under vector-scalar multiplication. We have shown that \\(W_1 \\cap W_2\\) is a subspace.","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#union-of-two-subspaces-may-not-be-a-subspace","text":"The union of two subspaces may not be a subspace. The reason why this can happen is that all vector spaces, and hence subspaces too, must be closed under addition (and scalar multiplication). The union of two subspaces takes all the elements already in those spaces, and nothing more. In the union of subspaces \\(W_1\\) and \\(W_2\\) , there are new combinations of vectors we can add together that we couldn't before, like \\(\\w_1 + \\w_2\\) where \\(\\w_1 \\in W_1\\) and \\(\\w_2 \\in W_2\\) . For example, take \\(W_1\\) to be the \\(x\\) -axis and \\(W_2\\) the \\(y\\) -axis, both subspaces of \\(\\mathbb{R}^2\\) . Their union includes both \\((3,0)\\) and \\((0,5)\\) , whose sum, \\((3,5)\\) , is not in the union. Hence, the union is not a vector space.","title":"Union of Two Subspaces may not be a Subspace"},{"location":"reighns_ml_journey/mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/#ambient-space","text":"The term ambient space is used frequently in the book. We can understand it with an example: Example If you are dealing with a vector subspace \\(U\\) as a subset of \\(\\mathbb R^2\\) , the ambient space is \\(\\mathbb R^2\\) . So basically, the ambient space is the \"parent space\" of the subspace.","title":"Ambient Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\C}{\\mathbb{C}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\Q}{\\mathbf{Q}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\q}{\\mathbf{q}} \\newcommand{\\e}{\\mathbf{e}} \\newcommand{\\I}{\\mathbf{I}} \\] Definition (Matrix) A matrix is a rectangular array of numbers (or other mathematical objects), called the entries of the matrix. Matrices are subject to standard operations such as addition and multiplication . Most commonly, a matrix over a field \\(\\F\\) is a rectangular array of elements of \\(\\F\\) . A real matrix and a complex matrix are matrices whose entries are respectively real numbers or complex numbers . More general types of entries are discussed below . For instance, this is a real matrix: \\[\\mathbf{A} = \\begin{bmatrix} -1.3 & 0.6 \\\\ 20.4 & 5.5 \\\\ 9.7 & -6.2 \\end{bmatrix}\\] The numbers, symbols, or expressions in the matrix are called its entries or its elements . The horizontal and vertical lines of entries in a matrix are called rows and columns , respectively. Notation (Matrix) Matrices are commonly written in box brackets or parentheses : \\[\\mathbf{A} = \\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\end{bmatrix} = \\begin{pmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\end{pmatrix}=\\left(a_{ij}\\right) \\in \\mathbb{R}^{m \\times n}\\] The specifics of symbolic matrix notation vary widely, with some prevailing trends. Matrices are usually symbolized using upper-case letters (such as A in the examples above). If we say a matrix \\(\\A \\in \\F^{m \\times n}\\) , then this means: \\(\\A\\) has \\(m\\) rows and \\(n\\) columns. \\(\\A\\) is a matrix with elements drawn from the field \\(\\F\\) . Furthermore, we read the \\((i, j)\\) -th entry of the matrix \\(\\A\\) as \\(\\A_{i, j}\\) . Definition (Dimension and Size of a Matrix) As detailed in Notation (Matrix) , we usually denote the size of a matrix as \\(\\A \\in \\F^{m \\times n}\\) .","title":"Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix/#definition-matrix","text":"A matrix is a rectangular array of numbers (or other mathematical objects), called the entries of the matrix. Matrices are subject to standard operations such as addition and multiplication . Most commonly, a matrix over a field \\(\\F\\) is a rectangular array of elements of \\(\\F\\) . A real matrix and a complex matrix are matrices whose entries are respectively real numbers or complex numbers . More general types of entries are discussed below . For instance, this is a real matrix: \\[\\mathbf{A} = \\begin{bmatrix} -1.3 & 0.6 \\\\ 20.4 & 5.5 \\\\ 9.7 & -6.2 \\end{bmatrix}\\] The numbers, symbols, or expressions in the matrix are called its entries or its elements . The horizontal and vertical lines of entries in a matrix are called rows and columns , respectively.","title":"Definition (Matrix)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix/#notation-matrix","text":"Matrices are commonly written in box brackets or parentheses : \\[\\mathbf{A} = \\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\end{bmatrix} = \\begin{pmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\end{pmatrix}=\\left(a_{ij}\\right) \\in \\mathbb{R}^{m \\times n}\\] The specifics of symbolic matrix notation vary widely, with some prevailing trends. Matrices are usually symbolized using upper-case letters (such as A in the examples above). If we say a matrix \\(\\A \\in \\F^{m \\times n}\\) , then this means: \\(\\A\\) has \\(m\\) rows and \\(n\\) columns. \\(\\A\\) is a matrix with elements drawn from the field \\(\\F\\) . Furthermore, we read the \\((i, j)\\) -th entry of the matrix \\(\\A\\) as \\(\\A_{i, j}\\) .","title":"Notation (Matrix)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix/#definition-dimension-and-size-of-a-matrix","text":"As detailed in Notation (Matrix) , we usually denote the size of a matrix as \\(\\A \\in \\F^{m \\times n}\\) .","title":"Definition (Dimension and Size of a Matrix)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\C}{\\mathbb{C}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\Q}{\\mathbf{Q}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\q}{\\mathbf{q}} \\newcommand{\\e}{\\mathbf{e}} \\newcommand{\\I}{\\mathbf{I}} \\] import numpy as np import sympy as sy sy . init_printing () Matrix Types Rectangular Matrices A matrix \\(\\A \\in \\R^{m \\times n}\\) is a rectangular matrix with \\(m\\) rows and \\(n\\) columns Square Matrices A square matrix \\(\\A \\in \\R^{n \\times n}\\) is a special case of a rectangular matrix, where it has equal number of rows and columns. Main Diagonal The main diagonal of a square matrix \\(\\A\\) is the entries \\(\\A_{i, i}\\) . Diagonal and Triangular Matrix Diagonal and Triangular Matrix can appear in various matrix decompositions, and of course, eigendecomposition. Upper Triangular Matrix If all entries of A below the main diagonal are zero, A is called an upper triangular matrix . \\[ \\begin{bmatrix} a_{11} & a_{12} & a_{13} \\\\ 0 & a_{22} & a_{23} \\\\ 0 & 0 & a_{33} \\\\ \\end{bmatrix} \\] Lower Triangular Matrix If all entries of A above the main diagonal are zero, A is called an lower triangular matrix . \\[ \\begin{bmatrix} a_{11} & 0 & 0 \\\\ a_{21} & a_{22} & 0 \\\\ a_{31} & a_{32} & a_{33} \\\\ \\end{bmatrix} \\] Diagonal Matrix If all entries outside the main diagonal are zero, A is called a diagonal matrix . \\[ \\begin{bmatrix} a_{11} & 0 & 0 \\\\ 0 & a_{22} & 0 \\\\ 0 & 0 & a_{33} \\\\ \\end{bmatrix} \\] Identity Matrices (Multiplicative Identity) The identity matrix \\(\\I\\) of size n is the n -by- n matrix in which all the elements on the main diagonal are equal to 1 and all other elements are equal to 0. Note that the Identity Matrix , as its name suggest, is the identity element which maps any matrices to \\(\\1\\) . See our section on Fields for a refresher on the Multiplicative Identity . For example, \\[\\mathbf{I}_1 = \\begin{bmatrix} 1 \\end{bmatrix}, \\ \\mathbf{I}_2 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}, \\ \\ldots , \\ \\mathbf{I}_n = \\begin{bmatrix} 1 & 0 & \\cdots & 0 \\\\ 0 & 1 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & 1 \\end{bmatrix}\\] It is a square matrix of order n , and also a special kind of diagonal matrix . It is called an identity matrix because multiplication with it leaves a matrix unchanged, that is, for any matrix \\(\\A \\in \\R^{m \\times n}\\) and any vector \\(\\v\\) of the appropriate size, then we have: \\[ \\A\\I_n = \\I_m \\A = \\A \\] and \\[\\v\\I = \\v\\] Zero Matrices (Additive Identity) A matrix \\(\\A \\in \\R^{m \\times n}\\) is the zero matrix if all entries are \\(0\\) . Note that this is the additive identity and fulfills the property of additive identity. Symmetric and Skew-Symmetric Matrices Symmetric Matrix A quare matrix A that is equal to its transpose, that is: \\[ \\A = \\A^\\top \\] Visually, a symmetric matrix is a \"mirrored\" matrix where the top and bottom of its diagonals are \"flipped/mirrored\". Note that only square matrix can be symmetric. symmetric_matrix = sy . Matrix ([[ 1 , 3.14 , 2.71 ], [ 3.14 , 7 , 2 ], [ 2.71 , 2 , 0 ]]) symmetric_matrix \\(\\displaystyle \\left[\\begin{matrix}1 & 3.14 & 2.71\\\\3.14 & 7 & 2\\\\2.71 & 2 & 0\\end{matrix}\\right]\\) symmetric_matrix . T == symmetric_matrix True The author noted that symmetric matrices is very useful and has many attractive properties. He also mentioned that creating symmetric matrices from non-symmetric matrices are central to many statistics and machine learning applications, such as least-squares and eigendecomposition. For example, you might have heard of a \"covariance matrix\"; this is simply a symmetric matrix created from a rectangular data matrix. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 114) Skew-Symmetric If instead, \\(\\A\\) is equal to the negative of its transpose, that is: \\[\\A = -\\A^\\top\\] then \\(\\A\\) is a skew-symmetric matrix. skewed_symmetric_matrix = sy . Matrix ([[ 0 , - 3.14 , - 2.71 ], [ 3.14 , 0 , 2 ], [ 2.71 , - 2 , 0 ]]) skewed_symmetric_matrix \\(\\displaystyle \\left[\\begin{matrix}0 & -3.14 & -2.71\\\\3.14 & 0 & 2\\\\2.71 & -2 & 0\\end{matrix}\\right]\\) skewed_symmetric_matrix . T == - 1 * skewed_symmetric_matrix True Note to the readers that the diagonal of skewed-symmetric matrices are always zero, because by definition, the diagonal entry must fulfil: \\[\\A_{i, i} = -\\A_{i, i}\\] Dense and Sparse Matrix Dense Matrix A dense matrix is a matrix with most or all of its elements/entries being non-zero. Sparse Matrix A sparse matrix is a matrix with most or all of its elements/entries being zero. Sparse matrix is an important topic in modern numerical analysis because it is an efficient matrix. Orthogonal Matrix An orthogonal matrix is a square matrix \\(\\Q\\) with real entries whose columns and rows are orthogonal unit vectors (that is, orthonormal vectors). This means: All columns of the matrix are pairwise orthogonal, which means for any \\(\\q_i, \\q_j\\) of the columns \\(\\Q\\) , we have \\(\\q_i \\cdot \\q_j = \\0\\) Each column of the matrix has unit length and are therefore unit vectors: \\(\\Vert \\q_i \\Vert = \\1\\) . From the above, we can deduce a notation: $$ \\Q_i \\cdot \\Q_j = \\begin{cases} 1\\hspace{0.5cm} \\text{if } i=j \\ 0\\hspace{0.5cm} \\text{if } i \\neq j \\end{cases} $$ To make the notation/expression more compact, we can write that a matrix \\(\\Q\\) is orthogonal if: \\[ \\Q^\\top \\Q = \\I \\] Equivalently, we have its transpose is equal to its inverse : \\( \\(\\mathbf{A}^\\mathrm{T}=\\mathbf{A}^{-1}, \\,\\) \\) which entails \\( \\(\\mathbf{A}^\\mathrm{T} \\mathbf{A} = \\mathbf{A} \\mathbf{A}^\\mathrm{T} = \\mathbf{I}_n,\\) \\) where I is the identity matrix of size n . Importance of A transpose A This matrix is so important that it must be mentioned here even if we have not learnt some concepts. Here are the properties one should remember, with reference from Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 117) : \\(\\A^\\top\\A\\) is a square matrix, even if \\(\\A\\) is not square. Positive semidefinite- ness \\(\\A^\\top\\A\\) has real and positive eigenvalues The trace is positive (the trace is the sum of eigenvalues) The determinant is positive (the determinant is the product of the eigenvalues) The diagonal entries are all positive \\(\\A^\\top\\A\\) has Orthogonal eigenvectors . Diagonalizable as \\(Q\\Lambda Q^T\\) \\(\\A^\\top\\A\\) is full rank if \\(\\A\\) is full column rank. Rank of \\(A^TA\\) is the same as rank of \\(A\\) . \\(\\text{ker}(A^TA)=\\text{ker}(A)\\) \\(\\A^\\top\\A\\) is symmetric, even if \\(\\A\\) is not symmetric. \\(\\A^\\top\\A\\) is invertible if \\(\\A\\) is full column rank. \\(\\A^\\top\\A\\) and \\(\\A\\) have the same row space. \\(\\A^\\top\\A\\) is often called a covariance matrix 1 . https://math.stackexchange.com/questions/1896628/properties-of-the-a-transpose-a-matrix \u21a9","title":"Basic Matrix Types"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#matrix-types","text":"","title":"Matrix Types"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#rectangular-matrices","text":"A matrix \\(\\A \\in \\R^{m \\times n}\\) is a rectangular matrix with \\(m\\) rows and \\(n\\) columns","title":"Rectangular Matrices"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#square-matrices","text":"A square matrix \\(\\A \\in \\R^{n \\times n}\\) is a special case of a rectangular matrix, where it has equal number of rows and columns.","title":"Square Matrices"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#main-diagonal","text":"The main diagonal of a square matrix \\(\\A\\) is the entries \\(\\A_{i, i}\\) .","title":"Main Diagonal"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#diagonal-and-triangular-matrix","text":"Diagonal and Triangular Matrix can appear in various matrix decompositions, and of course, eigendecomposition.","title":"Diagonal and Triangular Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#upper-triangular-matrix","text":"If all entries of A below the main diagonal are zero, A is called an upper triangular matrix . \\[ \\begin{bmatrix} a_{11} & a_{12} & a_{13} \\\\ 0 & a_{22} & a_{23} \\\\ 0 & 0 & a_{33} \\\\ \\end{bmatrix} \\]","title":"Upper Triangular Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#lower-triangular-matrix","text":"If all entries of A above the main diagonal are zero, A is called an lower triangular matrix . \\[ \\begin{bmatrix} a_{11} & 0 & 0 \\\\ a_{21} & a_{22} & 0 \\\\ a_{31} & a_{32} & a_{33} \\\\ \\end{bmatrix} \\]","title":"Lower Triangular Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#diagonal-matrix","text":"If all entries outside the main diagonal are zero, A is called a diagonal matrix . \\[ \\begin{bmatrix} a_{11} & 0 & 0 \\\\ 0 & a_{22} & 0 \\\\ 0 & 0 & a_{33} \\\\ \\end{bmatrix} \\]","title":"Diagonal Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#identity-matrices-multiplicative-identity","text":"The identity matrix \\(\\I\\) of size n is the n -by- n matrix in which all the elements on the main diagonal are equal to 1 and all other elements are equal to 0. Note that the Identity Matrix , as its name suggest, is the identity element which maps any matrices to \\(\\1\\) . See our section on Fields for a refresher on the Multiplicative Identity . For example, \\[\\mathbf{I}_1 = \\begin{bmatrix} 1 \\end{bmatrix}, \\ \\mathbf{I}_2 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}, \\ \\ldots , \\ \\mathbf{I}_n = \\begin{bmatrix} 1 & 0 & \\cdots & 0 \\\\ 0 & 1 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & 1 \\end{bmatrix}\\] It is a square matrix of order n , and also a special kind of diagonal matrix . It is called an identity matrix because multiplication with it leaves a matrix unchanged, that is, for any matrix \\(\\A \\in \\R^{m \\times n}\\) and any vector \\(\\v\\) of the appropriate size, then we have: \\[ \\A\\I_n = \\I_m \\A = \\A \\] and \\[\\v\\I = \\v\\]","title":"Identity Matrices (Multiplicative Identity)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#zero-matrices-additive-identity","text":"A matrix \\(\\A \\in \\R^{m \\times n}\\) is the zero matrix if all entries are \\(0\\) . Note that this is the additive identity and fulfills the property of additive identity.","title":"Zero Matrices (Additive Identity)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#symmetric-and-skew-symmetric-matrices","text":"","title":"Symmetric and Skew-Symmetric Matrices"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#symmetric-matrix","text":"A quare matrix A that is equal to its transpose, that is: \\[ \\A = \\A^\\top \\] Visually, a symmetric matrix is a \"mirrored\" matrix where the top and bottom of its diagonals are \"flipped/mirrored\". Note that only square matrix can be symmetric. symmetric_matrix = sy . Matrix ([[ 1 , 3.14 , 2.71 ], [ 3.14 , 7 , 2 ], [ 2.71 , 2 , 0 ]]) symmetric_matrix \\(\\displaystyle \\left[\\begin{matrix}1 & 3.14 & 2.71\\\\3.14 & 7 & 2\\\\2.71 & 2 & 0\\end{matrix}\\right]\\) symmetric_matrix . T == symmetric_matrix True The author noted that symmetric matrices is very useful and has many attractive properties. He also mentioned that creating symmetric matrices from non-symmetric matrices are central to many statistics and machine learning applications, such as least-squares and eigendecomposition. For example, you might have heard of a \"covariance matrix\"; this is simply a symmetric matrix created from a rectangular data matrix. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 114)","title":"Symmetric Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#skew-symmetric","text":"If instead, \\(\\A\\) is equal to the negative of its transpose, that is: \\[\\A = -\\A^\\top\\] then \\(\\A\\) is a skew-symmetric matrix. skewed_symmetric_matrix = sy . Matrix ([[ 0 , - 3.14 , - 2.71 ], [ 3.14 , 0 , 2 ], [ 2.71 , - 2 , 0 ]]) skewed_symmetric_matrix \\(\\displaystyle \\left[\\begin{matrix}0 & -3.14 & -2.71\\\\3.14 & 0 & 2\\\\2.71 & -2 & 0\\end{matrix}\\right]\\) skewed_symmetric_matrix . T == - 1 * skewed_symmetric_matrix True Note to the readers that the diagonal of skewed-symmetric matrices are always zero, because by definition, the diagonal entry must fulfil: \\[\\A_{i, i} = -\\A_{i, i}\\]","title":"Skew-Symmetric"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#dense-and-sparse-matrix","text":"","title":"Dense and Sparse Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#dense-matrix","text":"A dense matrix is a matrix with most or all of its elements/entries being non-zero.","title":"Dense Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#sparse-matrix","text":"A sparse matrix is a matrix with most or all of its elements/entries being zero. Sparse matrix is an important topic in modern numerical analysis because it is an efficient matrix.","title":"Sparse Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#orthogonal-matrix","text":"An orthogonal matrix is a square matrix \\(\\Q\\) with real entries whose columns and rows are orthogonal unit vectors (that is, orthonormal vectors). This means: All columns of the matrix are pairwise orthogonal, which means for any \\(\\q_i, \\q_j\\) of the columns \\(\\Q\\) , we have \\(\\q_i \\cdot \\q_j = \\0\\) Each column of the matrix has unit length and are therefore unit vectors: \\(\\Vert \\q_i \\Vert = \\1\\) . From the above, we can deduce a notation: $$ \\Q_i \\cdot \\Q_j = \\begin{cases} 1\\hspace{0.5cm} \\text{if } i=j \\ 0\\hspace{0.5cm} \\text{if } i \\neq j \\end{cases} $$ To make the notation/expression more compact, we can write that a matrix \\(\\Q\\) is orthogonal if: \\[ \\Q^\\top \\Q = \\I \\] Equivalently, we have its transpose is equal to its inverse : \\( \\(\\mathbf{A}^\\mathrm{T}=\\mathbf{A}^{-1}, \\,\\) \\) which entails \\( \\(\\mathbf{A}^\\mathrm{T} \\mathbf{A} = \\mathbf{A} \\mathbf{A}^\\mathrm{T} = \\mathbf{I}_n,\\) \\) where I is the identity matrix of size n .","title":"Orthogonal Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/#importance-of-a-transpose-a","text":"This matrix is so important that it must be mentioned here even if we have not learnt some concepts. Here are the properties one should remember, with reference from Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 117) : \\(\\A^\\top\\A\\) is a square matrix, even if \\(\\A\\) is not square. Positive semidefinite- ness \\(\\A^\\top\\A\\) has real and positive eigenvalues The trace is positive (the trace is the sum of eigenvalues) The determinant is positive (the determinant is the product of the eigenvalues) The diagonal entries are all positive \\(\\A^\\top\\A\\) has Orthogonal eigenvectors . Diagonalizable as \\(Q\\Lambda Q^T\\) \\(\\A^\\top\\A\\) is full rank if \\(\\A\\) is full column rank. Rank of \\(A^TA\\) is the same as rank of \\(A\\) . \\(\\text{ker}(A^TA)=\\text{ker}(A)\\) \\(\\A^\\top\\A\\) is symmetric, even if \\(\\A\\) is not symmetric. \\(\\A^\\top\\A\\) is invertible if \\(\\A\\) is full column rank. \\(\\A^\\top\\A\\) and \\(\\A\\) have the same row space. \\(\\A^\\top\\A\\) is often called a covariance matrix 1 . https://math.stackexchange.com/questions/1896628/properties-of-the-a-transpose-a-matrix \u21a9","title":"Importance of A transpose A"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\C}{\\mathbb{C}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\Q}{\\mathbf{Q}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\q}{\\mathbf{q}} \\newcommand{\\e}{\\mathbf{e}} \\newcommand{\\I}{\\mathbf{I}} \\] Matrix Operations Matrix Addition and Subraction The sum of two matrices of the same size \\(m \\times n\\) , \\(\\A\\) and \\(\\B\\) are calculated elementwise: \\[ (\\A \\pm \\B)_{i, j} = \\A_{i, j} \\pm \\B_{i, j} \\] where \\(1 \\leq i \\leq m , \\quad 1 \\leq j \\leq n\\) . Scalar-Matrix Multiplication For any scalar \\(\\lambda \\in \\F\\) , the Matrix-Scalar Multiplication \\(\\lambda \\A\\) is given by: \\[ (\\lambda \\A)_{i, j} = \\lambda \\cdot \\A_{i, j} \\] Commutative of Scalar-Matrix Multiplication Not surprisingly, the operation is commutative such that, given any scalar \\(\\lambda\\) , and any sequence of matrices \\(\\A, \\B\\) , we have: \\[ \\lambda \\A\\B = \\A\\lambda\\B = \\A\\B\\lambda \\] Matrix Operations Fulfill Field Properties In fact, matrix operations fulfill the properties of field properties. That is, for any matrix \\(\\A\\) and \\(\\B\\) of the same shape and size, we have 1 : \\(\\A+ \\B= \\B+ \\A\\) \\((\\A+\\B)+ C=\\A+(\\B+C)\\) \\(c(\\A+\\B)=c\\A+c\\B\\) \\((c+d)\\A=c\\A+c{D}\\) \\(c(d\\A)=(cd)\\A\\) \\(\\A+=\\A\\) , where \\({0}\\) is the zero matrix For any \\(\\A\\) , there exists a \\(-\\A\\) , such that $ \\A+(- \\A)=0$. Although we have not learn matrix multiplication , their properties are: $ \\A({\\B\\mathbf{C}})=({\\A\\B}) \\mathbf{C}$ \\(\\mathbf{C}({\\A\\B})=(\\mathbf{C}\\A)\\B=\\A(\\mathbf{C}\\B)\\) \\(\\A(\\B+ \\mathbf{C})={\\A\\B}+{\\A\\mathbf{C}}\\) \\((\\B+\\mathbf{C})\\A={\\B\\A}+{\\mathbf{C}\\A}\\) Matrix Tranpose Given a matrix \\(\\A \\in \\R^{m \\times n}\\) , the transpose of \\(\\A\\) is denoted \\(\\A^\\top\\) and formed by mapping the rows of \\(\\A\\) to columns and columns of \\(\\A\\) to rows, as illustrated: \\[ (\\A^\\top)_{i, j} = \\A_{j, i} \\] Theorem (A Matrixs transpose is itself) Prove that the transpose of a matrix \\(\\mathbf{A}\\) 's transpose is \\(\\mathbf{A}\\) : \\((\\mathbf{A}^\\top)^\\top = \\mathbf{A}\\) . Proof Consider a matrix \\(A_{n \\times k}\\) as follows, $$\\mathbf{A}=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1k} \\ a_{21} & a_{22} & \\cdots & a_{2k} \\ \\vdots & \\vdots & \\ddots & \\vdots \\ a_{n1} & a_{n2} & \\cdots & a_{nk} \\ \\end{bmatrix} $$ By definition of Transpose , all \\((i,j)\\) entries of \\(A\\) is mapped to \\((j,i)\\) , for example, \\(a_{1,2}\\) becomes \\(a_{2,1}\\) when transposed. Performing a transpose once more will then map all \\((j,i)\\) entries back to \\((i,j)\\) . \\(A\\) is unchanged and thus \\((\\mathbf{A}^\\top)^\\top = \\mathbf{A}\\) . Q.E.D Theorem (Sum of Transpose is Transpose of Sum) Given two matrices \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) , show that the sum of transposes is equal to the transpose of a sum: \\(\\mathbf{A}^\\top + \\mathbf{B}^\\top = (\\mathbf{A} + \\mathbf{B})^\\top\\) . Proof Say that we have two matrices \\(\\mathbf{A} \\in \\mathbb{R}^{n \\times k}\\) and \\(\\mathbf{B} \\in \\mathbb{R}^{k \\times m}\\) : \\[\\mathbf{A}=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1k} \\\\ a_{21} & a_{22} & \\cdots & a_{2k} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{n1} & a_{n2} & \\cdots & a_{nk} \\\\ \\end{bmatrix},\\quad \\mathbf{B}=\\begin{bmatrix} b_{11} & b_{12} & \\cdots & b_{1m} \\\\ b_{21} & b_{22} & \\cdots & b_{2m} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ b_{k1} & b_{k2} & \\cdots & b_{km} \\\\ \\end{bmatrix},\\quad \\mathbf{A+B}=\\begin{bmatrix} a_{11}+b_{11} & a_{12}+b_{12} & \\cdots & a_{1m}+b_{1m} \\\\ a_{21}+b_{21} & a_{22}+b_{22} & \\cdots & a_{2m}+b_{2m} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{k1}+b_{k1} & a_{k2}+b_{k2} & \\cdots & a_{km}+b_{km} \\\\ \\end{bmatrix}.\\] Then we can prove it by simply computing the LHS and RHS respectively. Without loss of generality, we pick any pair of point \\(a_{i,j} \\in \\mathbf{A}, b_{i,j} \\in \\mathbf{B}\\) and this pair of point corresponds to \\(a_{i,j}+b_{i,j} \\in \\mathbf{A}+\\mathbf{B}\\) . Note in particular that \\(a_{i,j}+b_{i,j} = (a+b)_{i,j}\\) . Then the transpose of the point \\(a_{i,j}\\) and \\(b_{i,j}\\) is \\(a_{j,i}\\) and \\(b_{j,i}\\) , which sums to \\(a_{j,i}+b_{j,i} = (a+b)_{j,i}\\) , which is the transpose of the point \\(a_{i,j}+b_{i,j} = (a+b)_{i,j}\\) . Q.E.D Shifting a Matrix When we say we shift a matrix, we really mean the following: Given a square matrix \\(\\A \\in \\R^{n \\times n}\\) , then shifting a matrix by a constant \\(\\lambda\\) is the following operation: \\[ \\widetilde{\\A} = \\A + \\lambda \\I_n \\quad \\A \\in \\R^{n \\times n}, \\lambda \\in \\R \\] Example and Motivation The author Mike gave us an example with some motivation behind, with reference to Linear Algebra: Theory, Intuition, Code, 2021. (pp. 127) , we consider the matrix: \\[ \\widetilde{A} = \\A + 0.1 \\cdot \\I_3 = \\begin{bmatrix}1 & 3 & 0 \\\\ 1 & 3 & 0 \\\\ 2 & 2 & 7 \\end{bmatrix} + 0.1 \\cdot \\I_3 = \\begin{bmatrix}1.1 & 3 & 0 \\\\ 1 & 3.1 & 0 \\\\ 2 & 2 & 7.1 \\end{bmatrix} \\] Then we observed: Diagonal Elements will be affected by shifting, but nothing else. This is obvious as off-diagonal elements of the scaled identity matrix are all zero entries. Note that row 1 and 2 of \\(\\A\\) are identical, and thus linearly dependent, but just by shifting a little, we will have distinct rows in \\(\\widetilde{A}\\) . In practice, we choose \\(\\lambda\\) to be small so that the shifted matrix is similar to the original matrix \\(\\A\\) , while still satisfying some constraints. Applications in Machine Learning The well known regularization technique is shifting a matrix in disguise. One can read it more here 2 . Diagonal We can extract the diagonal of a matrix into a vector: \\[ \\v = \\text{diag}(\\A) \\quad \\A \\in \\R^{m, n}, v_i = \\A_{i, i}, i = \\{1, 2, ..., \\min{(m, n)}\\} \\] Applications in Machine Learning The diagonal elements of a matrix can be extracted and placed into a vector. This is used, for example, in statistics: the diagonal elements of a covariance matrix contain the variance of each variable. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 129) Trace The trace of a matrix \\(\\A \\in \\R^{m \\times n}\\) is: \\[ \\text{tr}(\\A) = \\sum_{i=1}^{m}a_{i, i} \\] Applications in Machine Learning The trace operation has two applications in machine learning: It is used to compute the Frobenius norm of a matrix (a measure of the magnitude of a matrix) and it is used to measure the \"distance\" between two matrices. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 129) https://github.com/MacroAnalyst/Linear_Algebra_With_Python \u21a9 https://en.wikipedia.org/wiki/Tikhonov_regularization \u21a9","title":"Basic Matrix Operations"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#matrix-operations","text":"","title":"Matrix Operations"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#matrix-addition-and-subraction","text":"The sum of two matrices of the same size \\(m \\times n\\) , \\(\\A\\) and \\(\\B\\) are calculated elementwise: \\[ (\\A \\pm \\B)_{i, j} = \\A_{i, j} \\pm \\B_{i, j} \\] where \\(1 \\leq i \\leq m , \\quad 1 \\leq j \\leq n\\) .","title":"Matrix Addition and Subraction"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#scalar-matrix-multiplication","text":"For any scalar \\(\\lambda \\in \\F\\) , the Matrix-Scalar Multiplication \\(\\lambda \\A\\) is given by: \\[ (\\lambda \\A)_{i, j} = \\lambda \\cdot \\A_{i, j} \\]","title":"Scalar-Matrix Multiplication"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#commutative-of-scalar-matrix-multiplication","text":"Not surprisingly, the operation is commutative such that, given any scalar \\(\\lambda\\) , and any sequence of matrices \\(\\A, \\B\\) , we have: \\[ \\lambda \\A\\B = \\A\\lambda\\B = \\A\\B\\lambda \\]","title":"Commutative of Scalar-Matrix Multiplication"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#matrix-operations-fulfill-field-properties","text":"In fact, matrix operations fulfill the properties of field properties. That is, for any matrix \\(\\A\\) and \\(\\B\\) of the same shape and size, we have 1 : \\(\\A+ \\B= \\B+ \\A\\) \\((\\A+\\B)+ C=\\A+(\\B+C)\\) \\(c(\\A+\\B)=c\\A+c\\B\\) \\((c+d)\\A=c\\A+c{D}\\) \\(c(d\\A)=(cd)\\A\\) \\(\\A+=\\A\\) , where \\({0}\\) is the zero matrix For any \\(\\A\\) , there exists a \\(-\\A\\) , such that $ \\A+(- \\A)=0$. Although we have not learn matrix multiplication , their properties are: $ \\A({\\B\\mathbf{C}})=({\\A\\B}) \\mathbf{C}$ \\(\\mathbf{C}({\\A\\B})=(\\mathbf{C}\\A)\\B=\\A(\\mathbf{C}\\B)\\) \\(\\A(\\B+ \\mathbf{C})={\\A\\B}+{\\A\\mathbf{C}}\\) \\((\\B+\\mathbf{C})\\A={\\B\\A}+{\\mathbf{C}\\A}\\)","title":"Matrix Operations Fulfill Field Properties"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#matrix-tranpose","text":"Given a matrix \\(\\A \\in \\R^{m \\times n}\\) , the transpose of \\(\\A\\) is denoted \\(\\A^\\top\\) and formed by mapping the rows of \\(\\A\\) to columns and columns of \\(\\A\\) to rows, as illustrated: \\[ (\\A^\\top)_{i, j} = \\A_{j, i} \\]","title":"Matrix Tranpose"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#theorem-a-matrixs-transpose-is-itself","text":"Prove that the transpose of a matrix \\(\\mathbf{A}\\) 's transpose is \\(\\mathbf{A}\\) : \\((\\mathbf{A}^\\top)^\\top = \\mathbf{A}\\) .","title":"Theorem (A Matrixs transpose is itself)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#proof","text":"Consider a matrix \\(A_{n \\times k}\\) as follows, $$\\mathbf{A}=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1k} \\ a_{21} & a_{22} & \\cdots & a_{2k} \\ \\vdots & \\vdots & \\ddots & \\vdots \\ a_{n1} & a_{n2} & \\cdots & a_{nk} \\ \\end{bmatrix} $$ By definition of Transpose , all \\((i,j)\\) entries of \\(A\\) is mapped to \\((j,i)\\) , for example, \\(a_{1,2}\\) becomes \\(a_{2,1}\\) when transposed. Performing a transpose once more will then map all \\((j,i)\\) entries back to \\((i,j)\\) . \\(A\\) is unchanged and thus \\((\\mathbf{A}^\\top)^\\top = \\mathbf{A}\\) . Q.E.D","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#theorem-sum-of-transpose-is-transpose-of-sum","text":"Given two matrices \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) , show that the sum of transposes is equal to the transpose of a sum: \\(\\mathbf{A}^\\top + \\mathbf{B}^\\top = (\\mathbf{A} + \\mathbf{B})^\\top\\) .","title":"Theorem (Sum of Transpose is Transpose of Sum)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#proof_1","text":"Say that we have two matrices \\(\\mathbf{A} \\in \\mathbb{R}^{n \\times k}\\) and \\(\\mathbf{B} \\in \\mathbb{R}^{k \\times m}\\) : \\[\\mathbf{A}=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1k} \\\\ a_{21} & a_{22} & \\cdots & a_{2k} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{n1} & a_{n2} & \\cdots & a_{nk} \\\\ \\end{bmatrix},\\quad \\mathbf{B}=\\begin{bmatrix} b_{11} & b_{12} & \\cdots & b_{1m} \\\\ b_{21} & b_{22} & \\cdots & b_{2m} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ b_{k1} & b_{k2} & \\cdots & b_{km} \\\\ \\end{bmatrix},\\quad \\mathbf{A+B}=\\begin{bmatrix} a_{11}+b_{11} & a_{12}+b_{12} & \\cdots & a_{1m}+b_{1m} \\\\ a_{21}+b_{21} & a_{22}+b_{22} & \\cdots & a_{2m}+b_{2m} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{k1}+b_{k1} & a_{k2}+b_{k2} & \\cdots & a_{km}+b_{km} \\\\ \\end{bmatrix}.\\] Then we can prove it by simply computing the LHS and RHS respectively. Without loss of generality, we pick any pair of point \\(a_{i,j} \\in \\mathbf{A}, b_{i,j} \\in \\mathbf{B}\\) and this pair of point corresponds to \\(a_{i,j}+b_{i,j} \\in \\mathbf{A}+\\mathbf{B}\\) . Note in particular that \\(a_{i,j}+b_{i,j} = (a+b)_{i,j}\\) . Then the transpose of the point \\(a_{i,j}\\) and \\(b_{i,j}\\) is \\(a_{j,i}\\) and \\(b_{j,i}\\) , which sums to \\(a_{j,i}+b_{j,i} = (a+b)_{j,i}\\) , which is the transpose of the point \\(a_{i,j}+b_{i,j} = (a+b)_{i,j}\\) . Q.E.D","title":"Proof"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#shifting-a-matrix","text":"When we say we shift a matrix, we really mean the following: Given a square matrix \\(\\A \\in \\R^{n \\times n}\\) , then shifting a matrix by a constant \\(\\lambda\\) is the following operation: \\[ \\widetilde{\\A} = \\A + \\lambda \\I_n \\quad \\A \\in \\R^{n \\times n}, \\lambda \\in \\R \\]","title":"Shifting a Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#example-and-motivation","text":"The author Mike gave us an example with some motivation behind, with reference to Linear Algebra: Theory, Intuition, Code, 2021. (pp. 127) , we consider the matrix: \\[ \\widetilde{A} = \\A + 0.1 \\cdot \\I_3 = \\begin{bmatrix}1 & 3 & 0 \\\\ 1 & 3 & 0 \\\\ 2 & 2 & 7 \\end{bmatrix} + 0.1 \\cdot \\I_3 = \\begin{bmatrix}1.1 & 3 & 0 \\\\ 1 & 3.1 & 0 \\\\ 2 & 2 & 7.1 \\end{bmatrix} \\] Then we observed: Diagonal Elements will be affected by shifting, but nothing else. This is obvious as off-diagonal elements of the scaled identity matrix are all zero entries. Note that row 1 and 2 of \\(\\A\\) are identical, and thus linearly dependent, but just by shifting a little, we will have distinct rows in \\(\\widetilde{A}\\) . In practice, we choose \\(\\lambda\\) to be small so that the shifted matrix is similar to the original matrix \\(\\A\\) , while still satisfying some constraints.","title":"Example and Motivation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#applications-in-machine-learning","text":"The well known regularization technique is shifting a matrix in disguise. One can read it more here 2 .","title":"Applications in Machine Learning"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#diagonal","text":"We can extract the diagonal of a matrix into a vector: \\[ \\v = \\text{diag}(\\A) \\quad \\A \\in \\R^{m, n}, v_i = \\A_{i, i}, i = \\{1, 2, ..., \\min{(m, n)}\\} \\]","title":"Diagonal"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#applications-in-machine-learning_1","text":"The diagonal elements of a matrix can be extracted and placed into a vector. This is used, for example, in statistics: the diagonal elements of a covariance matrix contain the variance of each variable. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 129)","title":"Applications in Machine Learning"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#trace","text":"The trace of a matrix \\(\\A \\in \\R^{m \\times n}\\) is: \\[ \\text{tr}(\\A) = \\sum_{i=1}^{m}a_{i, i} \\]","title":"Trace"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/#applications-in-machine-learning_2","text":"The trace operation has two applications in machine learning: It is used to compute the Frobenius norm of a matrix (a measure of the magnitude of a matrix) and it is used to measure the \"distance\" between two matrices. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 129) https://github.com/MacroAnalyst/Linear_Algebra_With_Python \u21a9 https://en.wikipedia.org/wiki/Tikhonov_regularization \u21a9","title":"Applications in Machine Learning"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}}\\] Table of Contents Matrix Multiplication Validity of Matrix Multiplication Basic Formula for Matrix Multiplication Matrix-Vector Multiplication Right Multiplication (Linear Combination of Columns) Example (Right Multiplication) Example (Linear Transformation) Definition (Right Multiplication) Linear Equations (Right Multiplication) Column Space (Right Multiplication) Left Multiplication (Linear Combination of Rows) Example (Left Multiplication) The Four Interpretations of Matrix Multiplication Element Wise Matrix Multiplication Significance (Element Wise Matrix Multiplication) Outer Product Wise Matrix Multiplication Matrix Multiplication using Right Multiplication (Columns) Significance Matrix Multiplication using Right Multiplication (Rows) Significance Matrix Multiplication Properties Symmetric Matrices Matrix Multiplication (Naive) in Python References Learning Objectives Matrix Multiplication Matrix Multiplication Validity of Matrix Multiplication If you have dabbled in deep learning before, then the dreaded error shape mismatch is omnipresent . This is because matrix multiplication is only defined for matrices of a certain shape. If \\(\\A\\) is an \\(m \\times n\\) matrix and \\(\\B\\) is an \\(n \\times p\\) matrix, then \\(\\A\\B\\) is well defined because the columns of \\(\\A\\) is equals to the rows of \\(\\B\\) . If this is not true, then the \"shape is mismatched\". Consequently, if the matrix multiplication is well defined, then \\(\\C = \\A\\B\\) has shape (size) of \\(m \\times p\\) . Basic Formula for Matrix Multiplication Let us go through the most basic formula for matrix multiplication. Quoting from Wikipedia 1 : Let \\[\\A=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix},\\quad\\mathbf{B}=\\begin{bmatrix} b_{11} & b_{12} & \\cdots & b_{1p} \\\\ b_{21} & b_{22} & \\cdots & b_{2p} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ b_{n1} & b_{n2} & \\cdots & b_{np} \\\\ \\end{bmatrix}\\] then the matrix product \\(\\C = \\A\\B\\) is defined to be the \\(m \\times p\\) matrix: \\[\\mathbf{C}=\\A\\B=\\begin{bmatrix} c_{11} & c_{12} & \\cdots & c_{1p} \\\\ c_{21} & c_{22} & \\cdots & c_{2p} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ c_{m1} & c_{m2} & \\cdots & c_{mp} \\\\ \\end{bmatrix}\\] where \\(c_{ij} = a_{i1}b_{1j} + a_{i2}b_{2j} +\\cdots + a_{in}b_{nj}= \\sum_{k=1}^n a_{ik}b_{kj}\\) for \\(i = 1, \\cdots , m\\) and \\(j = 1, \\cdots , p\\) . That is, the entry \\(c_{i,j}\\) of the product is obtained by multiplying term-by-term the entries of the \\(i\\) -th row of \\(\\A\\) and the \\(j\\) -th column of \\(\\B\\) , and summing these \\(n\\) products. In other words, \\(c_{i,j}\\) is the dot product of the \\(i\\) -th row of \\(\\A\\) and the \\(j\\) -th column of \\(\\B\\) . Therefore, \\(\\C = \\A\\B\\) can also be written as \\[\\mathbf{C}=\\A\\B=\\begin{bmatrix} a_{11}b_{11} +\\cdots + a_{1n}b_{n1} & a_{11}b_{12} +\\cdots + a_{1n}b_{n2} & \\cdots & a_{11}b_{1p} +\\cdots + a_{1n}b_{np} \\\\ a_{21}b_{11} +\\cdots + a_{2n}b_{n1} & a_{21}b_{12} +\\cdots + a_{2n}b_{n2} & \\cdots & a_{21}b_{1p} +\\cdots + a_{2n}b_{np} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1}b_{11} +\\cdots + a_{mn}b_{n1} & a_{m1}b_{12} +\\cdots + a_{mn}b_{n2} & \\cdots & a_{m1}b_{1p} +\\cdots + a_{mn}b_{np} \\\\ \\end{bmatrix} \\] Thus the product \\(\\A\\B\\) is defined if and only if the number of columns in \\(\\A\\) equals the number of rows in \\(\\B\\) . Matrix-Vector Multiplication Before we go into Matrix-Matrix Multiplication, it is important to understand how Matrix-Vector Multiplication. Take a mental note on the usage of linear combination here. We will be referencing heavily from the article written by Eli Bendersky 2 . Right Multiplication (Linear Combination of Columns) Example (Right Multiplication) We motivate this with an example. Given a 3 by 3 matrix \\(A = \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix}\\) and \\(\\x = \\begin{bmatrix} a \\\\ b \\\\ c \\\\ \\end{bmatrix}\\) then \\[\\A\\x = \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix} \\begin{bmatrix} a \\\\ b \\\\ c \\\\ \\end{bmatrix} = \\begin{bmatrix} ax_1+by_1+cz_1 \\\\ ax_2+by_2+cz_2 \\\\ ax_3+by_3+cz_3 \\\\ \\end{bmatrix}\\] But notice that the above can also be written as: \\[\\A\\x = \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix} \\begin{bmatrix} a \\\\ b \\\\ c \\\\ \\end{bmatrix} = \\begin{bmatrix} ax_1+by_1+cz_1 \\\\ ax_2+by_2+cz_2 \\\\ ax_3+by_3+cz_3 \\\\ \\end{bmatrix} = \\color{red}{a}\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ \\end{bmatrix} + \\color{green}{b}\\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ \\end{bmatrix} + \\color{blue}{c}\\begin{bmatrix} z_1 \\\\ z_2 \\\\ z_3 \\\\ \\end{bmatrix}\\] This above expression is called: The matrix \\(\\A\\) acts on the vector \\(\\x\\) and the output is a linear combination of the columns of the matrix \\(\\A\\) . Example (Linear Transformation) We won't be going through the formal definition yet, but one could directly see as a consequence of the previous example. Given a 3 by 3 matrix \\(A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\\\ 3 & 6 & 9 \\\\ \\end{bmatrix}\\) and \\(\\x = \\begin{bmatrix} 1 \\\\ 2 \\\\ 4 \\\\ \\end{bmatrix}\\) then the geometric meaning of \\(\\A\\x\\) can be defined by a series of \"linear transformations\" categorized by scaling the first column of \\(\\A\\) by 1, then add the result to 2 times of the second column of \\(\\A\\) , and add the result to 4 times of the third column of \\(\\A\\) . Definition (Right Multiplication) Given a \\(m \\times n\\) matrix \\(\\A=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix}\\) and a column vector \\(\\x=\\begin{bmatrix} x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{n}\\end{bmatrix}\\) then \\[\\A\\x = \\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix}\\begin{bmatrix} x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{n}\\end{bmatrix} = \\color{red}{x_1}\\begin{bmatrix} a_{11} \\\\ a_{12} \\\\ \\vdots \\\\ a_{m1} \\\\ \\end{bmatrix} + \\color{green}{x_2}\\begin{bmatrix} a_{12} \\\\ a_{22} \\\\ \\vdots \\\\ a_{m2} \\\\ \\end{bmatrix} + \\cdots + \\color{blue}{x_n}\\begin{bmatrix} a_{1n} \\\\ a_{2n} \\\\ \\vdots \\\\ a_{mn} \\\\ \\end{bmatrix}\\] If the formula looks daunting, just remember that \\(\\A\\x\\) gives nothing but the linear combination of the columns of \\(\\A\\) with values of \\(\\x\\) as coefficients. Linear Equations (Right Multiplication) This is a very important realization that one must have, I will mention it right here first and will repeat it throughout. Given a 3 by 3 matrix \\(A = \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix}\\) and \\(\\x = \\begin{bmatrix} a \\\\ b \\\\ c \\\\ \\end{bmatrix}\\) then \\[\\A\\x = \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix} \\begin{bmatrix} a \\\\ b \\\\ c \\\\ \\end{bmatrix} = \\begin{bmatrix} ax_1+by_1+cz_1 \\\\ ax_2+by_2+cz_2 \\\\ ax_3+by_3+cz_3 \\\\ \\end{bmatrix} = \\color{red}{a}\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ \\end{bmatrix} + \\color{green}{b}\\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ \\end{bmatrix} + \\color{blue}{c}\\begin{bmatrix} z_1 \\\\ z_2 \\\\ z_3 \\\\ \\end{bmatrix}\\] In the examples above, \\(\\A\\) and \\(\\x\\) are known and we want to find the unknown \\(\\b\\) which is the product of \\(\\A\\x\\) . Now, if we know \\(\\A\\) and \\(\\b\\) and wish to find \\(\\x\\) that solves the linear equation/system \\(\\A\\x = \\b\\) instead, what can we understand from the above? Since we know \\(\\b = \\A\\x\\) is a linear combination of the columns of \\(\\A\\) with values of \\(\\x\\) as coefficients. Then if we want to solve for \\(\\x\\) , we ask ourselves what combination of the columns of \\(\\A = \\begin{bmatrix} \\x & \\y & \\z \\end{bmatrix}\\) gives rise to the vector \\(\\b\\) ? If we can find the combination \\(a, b, c\\) , we can recover \\(\\x = \\begin{bmatrix} a \\\\ b \\\\ c \\\\ \\end{bmatrix}\\) Column Space (Right Multiplication) A column space of a matrix \\(\\A\\) is just the set of linear combination of the columns of \\(\\A\\) , and is a subspace. We will go through it in more details, but for now, I want to introduce this idea first. As a consequence of the example prior, one should realize two things: \\(\\A\\x = \\b\\) may not always have a solution \\(\\x\\) . If \\(\\A\\x = \\b\\) has a solution \\(\\x\\) , then the product \\(\\b\\) must be a linear combination of the columns of \\(\\A\\) . This has important consequences later on. For now, just know that if \\(\\A\\x = \\b\\) has a solution, then \\(\\b\\) resides in the column space of \\(\\A\\) . Left Multiplication (Linear Combination of Rows) This part is also necessary to better understand matrix multiplication later. Example (Left Multiplication) We motivate this with an example. Given a 3 by 3 matrix \\(A = \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix}\\) and \\(\\x = \\begin{bmatrix} a & b & c \\end{bmatrix}\\) then \\[\\x\\A = \\begin{bmatrix} a & b & c \\end{bmatrix} \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix} = \\begin{bmatrix} ax_1+bx_2+cx_3 & ay_1+by_2+cy_3 & az_1+bz_2+cz_3 \\end{bmatrix}\\] But notice that the above can also be written as: \\[\\x\\A = \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix} = \\begin{bmatrix} ax_1+bx_2+cx_3 & ay_1+by_2+cy_3 & az_1+bz_2+cz_3 \\end{bmatrix} = \\color{red}{a}\\begin{bmatrix} x_1 & y_1 & z_1 \\end{bmatrix} + \\color{green}{b}\\begin{bmatrix} x_2 & y_2 & z_2 \\end{bmatrix} + \\color{blue}{c}\\begin{bmatrix} x_3 & y_3 & z_3 \\end{bmatrix}\\] Notice that now \\(\\x\\A\\) is just a linear combination of the rows of \\(\\A\\) . The Four Interpretations of Matrix Multiplication Element Wise Matrix Multiplication We have mentioned in the previous section. Here we repeat again for the sake of modularity. Let \\[\\A=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix},\\quad\\mathbf{B}=\\begin{bmatrix} b_{11} & b_{12} & \\cdots & b_{1p} \\\\ b_{21} & b_{22} & \\cdots & b_{2p} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ b_{n1} & b_{n2} & \\cdots & b_{np} \\\\ \\end{bmatrix}\\] then the matrix product \\(\\C = \\A\\B\\) is defined to be the \\(m \\times p\\) matrix: \\[\\mathbf{C}=\\A\\B=\\begin{bmatrix} c_{11} & c_{12} & \\cdots & c_{1p} \\\\ c_{21} & c_{22} & \\cdots & c_{2p} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ c_{m1} & c_{m2} & \\cdots & c_{mp} \\\\ \\end{bmatrix}\\] where \\(c_{ij} = a_{i1}b_{1j} + a_{i2}b_{2j} +\\cdots + a_{in}b_{nj}= \\sum_{k=1}^n a_{ik}b_{kj}\\) for \\(i = 1, \\cdots , m\\) and \\(j = 1, \\cdots , p\\) . That is, the entry \\(c_{i,j}\\) of the product is obtained by multiplying term-by-term the entries of the \\(i\\) -th row of \\(\\A\\) and the \\(j\\) -th column of \\(\\B\\) , and summing these \\(n\\) products. In other words, \\(c_{i,j}\\) is the dot product of the \\(i\\) -th row of \\(\\A\\) and the \\(j\\) -th column of \\(\\B\\) . Therefore, \\(\\C = \\A\\B\\) can also be written as \\[\\mathbf{C}=\\A\\B=\\begin{bmatrix} a_{11}b_{11} +\\cdots + a_{1n}b_{n1} & a_{11}b_{12} +\\cdots + a_{1n}b_{n2} & \\cdots & a_{11}b_{1p} +\\cdots + a_{1n}b_{np} \\\\ a_{21}b_{11} +\\cdots + a_{2n}b_{n1} & a_{21}b_{12} +\\cdots + a_{2n}b_{n2} & \\cdots & a_{21}b_{1p} +\\cdots + a_{2n}b_{np} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1}b_{11} +\\cdots + a_{mn}b_{n1} & a_{m1}b_{12} +\\cdots + a_{mn}b_{n2} & \\cdots & a_{m1}b_{1p} +\\cdots + a_{mn}b_{np} \\\\ \\end{bmatrix} \\] Thus the product \\(\\A\\B\\) is defined if and only if the number of columns in \\(\\A\\) equals the number of rows in \\(\\B\\) . Significance (Element Wise Matrix Multiplication) From Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 144) , he mentioned the following: The diagonal of \\(\\C\\) contains dot products between row \\(i\\) and column \\(j\\) of \\(\\A\\) and \\(\\B\\) respectively, this is relevant in data covariance matrices. The lower triangle of \\(\\C\\) contains dot products between row \\(i\\) in \\(\\A\\) and column \\(j\\) in \\(\\B\\) where \\(i > j\\) . The upper triangle of \\(\\C\\) contains dot products between row \\(i\\) in \\(\\A\\) and column \\(j\\) in \\(\\B\\) where \\(i < j\\) . Both are important in matrix decompositions, such as QR decomposition and generalized eigendecomposition . Outer Product Wise Matrix Multiplication To simplify notation, we denote: \\( \\(\\A = \\begin{bmatrix} \\a_1 & \\a_2 \\cdots & \\a_n \\end{bmatrix}, \\quad \\B = \\begin{bmatrix} \\b_1^\\top \\\\ \\b_2^\\top \\\\ \\cdots \\\\ \\b_n^\\top \\end{bmatrix}\\) \\) as shorthand where \\(\\a_i\\) is the \\(i\\) -th column of \\(\\A\\) and \\(\\b_j^\\top\\) is the \\(j\\) -th row of \\(\\B\\) . Then \\[\\A\\B = \\a_1\\b_1^\\top + \\a_2\\b_2^\\top + \\cdots + \\a_n\\b_n^\\top\\] Notice that in each of the \\(\\a_i\\b_i^\\top\\) , the columns form a dependent set (the same can be said of the rows). However, the sum of these singular matrices\u2014the product matrix\u2014has columns that form a linearly independent set. Each of these matrices is rank-1 (to be defined later). This forms the basis for the Singular Value Decomposition. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 145) Matrix Multiplication using Right Multiplication (Columns) Using back the notation in the Element Wise Matrix Multiplication , we can define \\[\\A\\B = \\A \\begin{bmatrix} \\b_1 & \\b_2 & \\cdots & \\b_p \\end{bmatrix} = \\begin{bmatrix} \\A\\b_1 & \\A\\b_2 & \\cdots & \\A\\b_p \\end{bmatrix}\\] where \\(\\b_i\\) is the column \\(i\\) of the matrix \\(\\B\\) . This means that each column of the matrix \\(\\C = \\A\\B\\) is defined by \\(\\A\\b_i\\) , and recall in the section \"Matrix-Vector Right Multiplication\", \\(\\A\\b_i\\) means a linear combination of the columns of \\(\\A\\) with weight coefficients in \\(\\b_i\\) . They say a picture is worth a thousand words. The below images are taken from Eli Bendersky's website here . Matrix Multiplication, Column Perspective; Courtesy of Eli Bendersky Significance The column perspective of matrix multiplication is useful in statistics, when the columns of the left matrix contain a set of regressors (a simplified model of the data), and the right matrix contains coefficients. The coefficients encode the importance of each regressor, and the goal of statistical model-fitting is to find the best coefficients such that the weighted combination of regressors matches the data. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 146) Matrix Multiplication using Left Multiplication (Rows) Using back the notation in the Element Wise Matrix Multiplication , we can define \\[\\A\\B = \\begin{bmatrix}\\a_1 \\\\ \\a_2 \\\\ \\vdots \\\\ \\a_m \\end{bmatrix}\\B = \\begin{bmatrix}\\a_1\\B \\\\ \\a_2\\B \\\\ \\vdots \\\\ \\a_m\\B \\end{bmatrix}\\] where \\(\\a_i\\) is the row \\(i\\) of the matrix \\(\\A\\) . This means that each row of the matrix \\(\\C = \\A\\B\\) is defined by \\(\\a_i\\B\\) , and recall in the section \"Matrix-Vector Left Multiplication\", \\(\\a_i\\B\\) means a linear combination of the row of \\(\\B\\) with weight coefficients in \\(\\a_i\\) . This becomes apparent when we come to the chapter of Row-Echolon Form . They say a picture is worth a thousand words. The below images are taken from Eli Bendersky's website here . Matrix Multiplication, Row Perspective; Courtesy of Eli Bendersky Significance The row perspective is useful, for example in principal components analysis, where the rows of the right matrix contain data (observations in rows and features in columns) and the rows of the left matrix contain weights for combining the features. Then the weighted sum of data creates the principal component scores. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 147) Matrix Multiplication Properties Read Wikipedia . To fill in when free as it is relatively light. Symmetric Matrices Matrix Multiplication (Naive) in Python For a Divide-and-conquer method, see here 3 . import os import random import numpy as np import torch def seed_all ( seed : int = 19921930 ) -> None : \"\"\"Seed all random number generators.\"\"\" print ( f \"Using Seed Number { seed } \" ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator # set fixed value for python built-in pseudo-random generator random . seed ( seed ) torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False torch . backends . cudnn . enabled = False seed_all () Using Seed Number 19921930 import torch import numpy as np from typing import Tuple , List A = np . random . randint ( 0 , 10 , size = ( 3 , 2 )) B = np . random . randint ( 0 , 10 , size = ( 2 , 2 )) Pseudo Code Let us run through the matrix multiplication between two simple matrices \\(\\A\\) and \\(\\B\\) . We define their product \\(\\C = \\A\\B\\) to be a matrix of shape \\((3, 2)\\) . Take first row of \\(\\A\\) and first column of \\(\\B\\) , compute the dot product of both and assign the value to the first entry of \\(\\C\\) (i.e. \\(\\C_{1, 1}\\) ). Take first row of \\(\\A\\) and second column of \\(\\B\\) , compute the dot product of both and assign the value to the first entry of \\(\\C\\) (i.e. \\(\\C_{1, 2}\\) ). Take second row of \\(\\A\\) and first column of \\(\\B\\) , compute the dot product of both and assign the value to the first entry of \\(\\C\\) (i.e. \\(\\C_{2, 1}\\) ). Take second row of \\(\\A\\) and second column of \\(\\B\\) , compute the dot product of both and assign the value to the first entry of \\(\\C\\) (i.e. \\(\\C_{2, 2}\\) ). Take third row of \\(\\A\\) and first column of \\(\\B\\) , compute the dot product of both and assign the value to the first entry of \\(\\C\\) (i.e. \\(\\C_{3, 1}\\) ). Take third row of \\(\\A\\) and second column of \\(\\B\\) , compute the dot product of both and assign the value to the first entry of \\(\\C\\) (i.e. \\(\\C_{3, 2}\\) ). We have seen the above in laymen english. We can easily convert the above to pseudo-code, but first we need to recognize that the above method is the \"Element-wise\" method, where the outer loop is rows of \\(\\A\\) , and the inner loop is columns of \\(\\B\\) . Input: matrices \\(\\A\\) and \\(\\B\\) of size \\((m, n)\\) and \\((n, p)\\) respectively. Initialize matrix \\(\\C\\) to be the product of \\(\\A\\B\\) with the correct shape. For row i from 1 to m: For col j from 1 to p: compute dot product of row i of A and col j of B: dot assign the dot product to entry \\(C_{i, j}\\) return \\(\\C\\) We have removed a layer of abstraction above, and that is the computation of the dot product, in which we have coded up previously. If there is no abstraction, then: Input: matrices \\(\\A\\) and \\(\\B\\) of size \\((m, n)\\) and \\((n, p)\\) respectively. Initialize matrix \\(\\C\\) to be the product of \\(\\A\\B\\) with the correct shape. For row i from 1 to m: Initialize summation = 0 For col j from 1 to p: for k from 1 to n: summation += dot product of row i of A and col j of B assign the dot product summation to entry \\(C_{i, j}\\) return \\(\\C\\) Python Code def linear_combination_vectors ( weights : List [ float ], * args : np . ndarray ) -> np . ndarray : \"\"\"Computes the linear combination of vectors. Args: weights (List[float]): The set of weights corresponding to each vector. Returns: linear_weighted_sum (np.ndarray): The linear combination of vectors. Examples: >>> v1 = np.asarray([1, 2, 3, 4, 5]).reshape(-1, 1) >>> v2 = np.asarray([2, 4, 6, 8, 10]).reshape(-1, 1) >>> v3 = np.asarray([3, 6, 9, 12, 15]).reshape(-1, 1) >>> weights = [10, 20, 30] >>> linear_combination_vectors([10, 20, 30], v1, v2, v3) \"\"\" linear_weighted_sum = np . zeros ( shape = args [ 0 ] . shape ) for weight , vec in zip ( weights , args ): linear_weighted_sum += weight * vec return linear_weighted_sum def dot_product ( v1 : np . ndarray , v2 : np . ndarray ) -> float : \"\"\"Computes the dot product of two vectors. We assume both vectors are flattened, i.e. they are 1D arrays. Args: v1 (np.ndarray): The first vector. v2 (np.ndarray): The second vector. Returns: dot_product_v1_v2 (float): The dot product of two vectors. Examples: >>> v1 = np.asarray([1, 2, 3, 4, 5]) >>> v2 = np.asarray([2, 4, 6, 8, 10]) >>> dot_product(v1, v2) \"\"\" v1 , v2 = np . asarray ( v1 ) . flatten (), np . asarray ( v2 ) . flatten () dot_product_v1_v2 = 0 for element_1 , element_2 in zip ( v1 , v2 ): dot_product_v1_v2 += element_1 * element_2 # same as np.dot but does not take into the orientation of vectors assert dot_product_v1_v2 == np . dot ( v1 . T , v2 ) return dot_product_v1_v2 def get_matmul_shape ( A : np . ndarray , B : np . ndarray ) -> Tuple [ int , int , int ]: \"\"\"Check if the shape of the matrices A and B are compatible for matrix multiplication. If A and B are of size (m, n) and (n, p), respectively, then the shape of the resulting matrix is (m, p). Args: A (np.ndarray): The first matrix. B (np.ndarray): The second matrix. Raises: ValueError: Raises a ValueError if the shape of the matrices A and B are not compatible for matrix multiplication. Returns: (Tuple[int, int, int]): (m, n, p) where (m, n) is the shape of A and (n, p) is the shape of B. \"\"\" if A . shape [ 1 ] != B . shape [ 0 ]: raise ValueError ( f \"The number of columns of A must be equal to the number of rows of B, but got { A . shape [ 1 ] } and { B . shape [ 0 ] } respectively.\" ) return ( A . shape [ 0 ], A . shape [ 1 ], B . shape [ 1 ]) def np_matmul_naive ( A : np . ndarray , B : np . ndarray ) -> np . ndarray : \"\"\"Computes the matrix multiplication of two matrices. Args: A (np.ndarray): The first matrix. B (np.ndarray): The second matrix. Returns: matmul (np.ndarray): The matrix multiplication of two matrices. \"\"\" num_rows_A , common_index , num_cols_B = check_matmul_shape ( A , B ) matmul = np . zeros ( shape = ( num_rows_A , num_cols_B )) # 1st loop: loops through first matrix A for i in range ( num_rows_A ): summation = 0 # 2nd loop: loops through second matrix B for j in range ( num_cols_B ): # 3rd loop: computes dot prod for k in range ( common_index ): summation += A [ i , k ] * B [ k , j ] matmul [ i , j ] = summation return matmul def np_matmul_element_wise ( A : np . ndarray , B : np . ndarray ) -> np . ndarray : \"\"\"Computes the matrix multiplication of two matrices using element wise method. Args: A (np.ndarray): The first matrix. B (np.ndarray): The second matrix. Returns: matmul (np.ndarray): The matrix multiplication of two matrices. \"\"\" num_rows_A , _ , num_cols_B = check_matmul_shape ( A , B ) matmul = np . zeros ( shape = ( num_rows_A , num_cols_B )) # 1st loop: loops through first matrix A for row_i in range ( num_rows_A ): # 2nd loop: loops through second matrix B for col_j in range ( num_cols_B ): # computes dot product of row i with column j of B and # assign the result to the element of the matrix matmul at row i and column j. matmul [ row_i , col_j ] = dot_product ( A [ row_i , :], B [:, col_j ]) return matmul def np_matmul_column_wise ( A : np . ndarray , B : np . ndarray ) -> np . ndarray : \"\"\"Computes the matrix multiplication of two matrices using column wise method. Recall the section on Matrix Multiplication using Right Multiplication. Column i of C is represented by: Ab_i Args: A (np.ndarray): The first matrix. B (np.ndarray): The second matrix. Returns: matmul (np.ndarray): The matrix multiplication of two matrices. \"\"\" num_rows_A , _ , num_cols_B = check_matmul_shape ( A , B ) matmul = np . zeros ( shape = ( num_rows_A , num_cols_B )) # we just need to populate the columns of C for col_i in range ( matmul . shape [ 1 ]): # b_i col_i_B = B [:, col_i ] # Ab_i linear_comb_A_on_col_i_B = linear_combination_vectors ( col_i_B , * A . T ) # C_i = Ab_i matmul [:, col_i ] = linear_comb_A_on_col_i_B return matmul # assert the function output is similar to numpy's A @ B np . allclose ( np_matmul_element_wise ( A , B ), np_matmul_column_wise ( A , B ), A @ B ) True Time Complexity The time complexity can be easily found in the pseudo-code. Input: matrices \\(\\A\\) and \\(\\B\\) of size \\((m, n)\\) and \\((n, p)\\) respectively. Initialize matrix \\(\\C\\) to be the product of \\(\\A\\B\\) with the correct shape. For row i from 1 to m: Initialize summation = 0 For col j from 1 to p: for k from 1 to n: summation += dot product of row i of A and col j of B assign the dot product summation to entry \\(C_{i, j}\\) return \\(\\C\\) In rough terms, the first outer loop has \\(m\\) operations, the second loop has \\(p\\) operations and last loop has \\(n\\) operations; we further assume each operation is \\(\\mathcal{O}(1)\\) and thus we have a total of \\(m \\times n \\times p\\) loops (operations), so the time complexity is \\( \\(\\mathcal{O}(mnp) \\approx \\mathcal{O}(n^3)\\) \\) if \\(m \\approx n \\approx p\\) . References https://eli.thegreenplace.net/2015/visualizing-matrix-multiplication-as-a-linear-combination/ https://math.stackexchange.com/questions/192835/fastest-and-intuitive-ways-to-look-at-matrix-multiplication https://math.stackexchange.com/questions/24456/matrix-multiplication-interpreting-and-understanding-the-process https://en.wikipedia.org/wiki/Matrix_multiplication \u21a9 https://eli.thegreenplace.net/2015/visualizing-matrix-multiplication-as-a-linear-combination/ \u21a9 solvay_strassen_algorithm \u21a9","title":"Matrix Multiplication"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#table-of-contents","text":"Matrix Multiplication Validity of Matrix Multiplication Basic Formula for Matrix Multiplication Matrix-Vector Multiplication Right Multiplication (Linear Combination of Columns) Example (Right Multiplication) Example (Linear Transformation) Definition (Right Multiplication) Linear Equations (Right Multiplication) Column Space (Right Multiplication) Left Multiplication (Linear Combination of Rows) Example (Left Multiplication) The Four Interpretations of Matrix Multiplication Element Wise Matrix Multiplication Significance (Element Wise Matrix Multiplication) Outer Product Wise Matrix Multiplication Matrix Multiplication using Right Multiplication (Columns) Significance Matrix Multiplication using Right Multiplication (Rows) Significance Matrix Multiplication Properties Symmetric Matrices Matrix Multiplication (Naive) in Python References Learning Objectives Matrix Multiplication","title":"Table of Contents"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#matrix-multiplication","text":"","title":"Matrix Multiplication"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#validity-of-matrix-multiplication","text":"If you have dabbled in deep learning before, then the dreaded error shape mismatch is omnipresent . This is because matrix multiplication is only defined for matrices of a certain shape. If \\(\\A\\) is an \\(m \\times n\\) matrix and \\(\\B\\) is an \\(n \\times p\\) matrix, then \\(\\A\\B\\) is well defined because the columns of \\(\\A\\) is equals to the rows of \\(\\B\\) . If this is not true, then the \"shape is mismatched\". Consequently, if the matrix multiplication is well defined, then \\(\\C = \\A\\B\\) has shape (size) of \\(m \\times p\\) .","title":"Validity of Matrix Multiplication"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#basic-formula-for-matrix-multiplication","text":"Let us go through the most basic formula for matrix multiplication. Quoting from Wikipedia 1 : Let \\[\\A=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix},\\quad\\mathbf{B}=\\begin{bmatrix} b_{11} & b_{12} & \\cdots & b_{1p} \\\\ b_{21} & b_{22} & \\cdots & b_{2p} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ b_{n1} & b_{n2} & \\cdots & b_{np} \\\\ \\end{bmatrix}\\] then the matrix product \\(\\C = \\A\\B\\) is defined to be the \\(m \\times p\\) matrix: \\[\\mathbf{C}=\\A\\B=\\begin{bmatrix} c_{11} & c_{12} & \\cdots & c_{1p} \\\\ c_{21} & c_{22} & \\cdots & c_{2p} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ c_{m1} & c_{m2} & \\cdots & c_{mp} \\\\ \\end{bmatrix}\\] where \\(c_{ij} = a_{i1}b_{1j} + a_{i2}b_{2j} +\\cdots + a_{in}b_{nj}= \\sum_{k=1}^n a_{ik}b_{kj}\\) for \\(i = 1, \\cdots , m\\) and \\(j = 1, \\cdots , p\\) . That is, the entry \\(c_{i,j}\\) of the product is obtained by multiplying term-by-term the entries of the \\(i\\) -th row of \\(\\A\\) and the \\(j\\) -th column of \\(\\B\\) , and summing these \\(n\\) products. In other words, \\(c_{i,j}\\) is the dot product of the \\(i\\) -th row of \\(\\A\\) and the \\(j\\) -th column of \\(\\B\\) . Therefore, \\(\\C = \\A\\B\\) can also be written as \\[\\mathbf{C}=\\A\\B=\\begin{bmatrix} a_{11}b_{11} +\\cdots + a_{1n}b_{n1} & a_{11}b_{12} +\\cdots + a_{1n}b_{n2} & \\cdots & a_{11}b_{1p} +\\cdots + a_{1n}b_{np} \\\\ a_{21}b_{11} +\\cdots + a_{2n}b_{n1} & a_{21}b_{12} +\\cdots + a_{2n}b_{n2} & \\cdots & a_{21}b_{1p} +\\cdots + a_{2n}b_{np} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1}b_{11} +\\cdots + a_{mn}b_{n1} & a_{m1}b_{12} +\\cdots + a_{mn}b_{n2} & \\cdots & a_{m1}b_{1p} +\\cdots + a_{mn}b_{np} \\\\ \\end{bmatrix} \\] Thus the product \\(\\A\\B\\) is defined if and only if the number of columns in \\(\\A\\) equals the number of rows in \\(\\B\\) .","title":"Basic Formula for Matrix Multiplication"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#matrix-vector-multiplication","text":"Before we go into Matrix-Matrix Multiplication, it is important to understand how Matrix-Vector Multiplication. Take a mental note on the usage of linear combination here. We will be referencing heavily from the article written by Eli Bendersky 2 .","title":"Matrix-Vector Multiplication"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#right-multiplication-linear-combination-of-columns","text":"","title":"Right Multiplication (Linear Combination of Columns)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#example-right-multiplication","text":"We motivate this with an example. Given a 3 by 3 matrix \\(A = \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix}\\) and \\(\\x = \\begin{bmatrix} a \\\\ b \\\\ c \\\\ \\end{bmatrix}\\) then \\[\\A\\x = \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix} \\begin{bmatrix} a \\\\ b \\\\ c \\\\ \\end{bmatrix} = \\begin{bmatrix} ax_1+by_1+cz_1 \\\\ ax_2+by_2+cz_2 \\\\ ax_3+by_3+cz_3 \\\\ \\end{bmatrix}\\] But notice that the above can also be written as: \\[\\A\\x = \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix} \\begin{bmatrix} a \\\\ b \\\\ c \\\\ \\end{bmatrix} = \\begin{bmatrix} ax_1+by_1+cz_1 \\\\ ax_2+by_2+cz_2 \\\\ ax_3+by_3+cz_3 \\\\ \\end{bmatrix} = \\color{red}{a}\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ \\end{bmatrix} + \\color{green}{b}\\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ \\end{bmatrix} + \\color{blue}{c}\\begin{bmatrix} z_1 \\\\ z_2 \\\\ z_3 \\\\ \\end{bmatrix}\\] This above expression is called: The matrix \\(\\A\\) acts on the vector \\(\\x\\) and the output is a linear combination of the columns of the matrix \\(\\A\\) .","title":"Example (Right Multiplication)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#example-linear-transformation","text":"We won't be going through the formal definition yet, but one could directly see as a consequence of the previous example. Given a 3 by 3 matrix \\(A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 6 \\\\ 3 & 6 & 9 \\\\ \\end{bmatrix}\\) and \\(\\x = \\begin{bmatrix} 1 \\\\ 2 \\\\ 4 \\\\ \\end{bmatrix}\\) then the geometric meaning of \\(\\A\\x\\) can be defined by a series of \"linear transformations\" categorized by scaling the first column of \\(\\A\\) by 1, then add the result to 2 times of the second column of \\(\\A\\) , and add the result to 4 times of the third column of \\(\\A\\) .","title":"Example (Linear Transformation)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#definition-right-multiplication","text":"Given a \\(m \\times n\\) matrix \\(\\A=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix}\\) and a column vector \\(\\x=\\begin{bmatrix} x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{n}\\end{bmatrix}\\) then \\[\\A\\x = \\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix}\\begin{bmatrix} x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{n}\\end{bmatrix} = \\color{red}{x_1}\\begin{bmatrix} a_{11} \\\\ a_{12} \\\\ \\vdots \\\\ a_{m1} \\\\ \\end{bmatrix} + \\color{green}{x_2}\\begin{bmatrix} a_{12} \\\\ a_{22} \\\\ \\vdots \\\\ a_{m2} \\\\ \\end{bmatrix} + \\cdots + \\color{blue}{x_n}\\begin{bmatrix} a_{1n} \\\\ a_{2n} \\\\ \\vdots \\\\ a_{mn} \\\\ \\end{bmatrix}\\] If the formula looks daunting, just remember that \\(\\A\\x\\) gives nothing but the linear combination of the columns of \\(\\A\\) with values of \\(\\x\\) as coefficients.","title":"Definition (Right Multiplication)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#linear-equations-right-multiplication","text":"This is a very important realization that one must have, I will mention it right here first and will repeat it throughout. Given a 3 by 3 matrix \\(A = \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix}\\) and \\(\\x = \\begin{bmatrix} a \\\\ b \\\\ c \\\\ \\end{bmatrix}\\) then \\[\\A\\x = \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix} \\begin{bmatrix} a \\\\ b \\\\ c \\\\ \\end{bmatrix} = \\begin{bmatrix} ax_1+by_1+cz_1 \\\\ ax_2+by_2+cz_2 \\\\ ax_3+by_3+cz_3 \\\\ \\end{bmatrix} = \\color{red}{a}\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ \\end{bmatrix} + \\color{green}{b}\\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ \\end{bmatrix} + \\color{blue}{c}\\begin{bmatrix} z_1 \\\\ z_2 \\\\ z_3 \\\\ \\end{bmatrix}\\] In the examples above, \\(\\A\\) and \\(\\x\\) are known and we want to find the unknown \\(\\b\\) which is the product of \\(\\A\\x\\) . Now, if we know \\(\\A\\) and \\(\\b\\) and wish to find \\(\\x\\) that solves the linear equation/system \\(\\A\\x = \\b\\) instead, what can we understand from the above? Since we know \\(\\b = \\A\\x\\) is a linear combination of the columns of \\(\\A\\) with values of \\(\\x\\) as coefficients. Then if we want to solve for \\(\\x\\) , we ask ourselves what combination of the columns of \\(\\A = \\begin{bmatrix} \\x & \\y & \\z \\end{bmatrix}\\) gives rise to the vector \\(\\b\\) ? If we can find the combination \\(a, b, c\\) , we can recover \\(\\x = \\begin{bmatrix} a \\\\ b \\\\ c \\\\ \\end{bmatrix}\\)","title":"Linear Equations (Right Multiplication)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#column-space-right-multiplication","text":"A column space of a matrix \\(\\A\\) is just the set of linear combination of the columns of \\(\\A\\) , and is a subspace. We will go through it in more details, but for now, I want to introduce this idea first. As a consequence of the example prior, one should realize two things: \\(\\A\\x = \\b\\) may not always have a solution \\(\\x\\) . If \\(\\A\\x = \\b\\) has a solution \\(\\x\\) , then the product \\(\\b\\) must be a linear combination of the columns of \\(\\A\\) . This has important consequences later on. For now, just know that if \\(\\A\\x = \\b\\) has a solution, then \\(\\b\\) resides in the column space of \\(\\A\\) .","title":"Column Space (Right Multiplication)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#left-multiplication-linear-combination-of-rows","text":"This part is also necessary to better understand matrix multiplication later.","title":"Left Multiplication (Linear Combination of Rows)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#example-left-multiplication","text":"We motivate this with an example. Given a 3 by 3 matrix \\(A = \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix}\\) and \\(\\x = \\begin{bmatrix} a & b & c \\end{bmatrix}\\) then \\[\\x\\A = \\begin{bmatrix} a & b & c \\end{bmatrix} \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix} = \\begin{bmatrix} ax_1+bx_2+cx_3 & ay_1+by_2+cy_3 & az_1+bz_2+cz_3 \\end{bmatrix}\\] But notice that the above can also be written as: \\[\\x\\A = \\begin{bmatrix} x_1 & y_1 & z_1 \\\\ x_2 & y_2 & z_2 \\\\ x_3 & y_3 & z_3 \\\\ \\end{bmatrix} = \\begin{bmatrix} ax_1+bx_2+cx_3 & ay_1+by_2+cy_3 & az_1+bz_2+cz_3 \\end{bmatrix} = \\color{red}{a}\\begin{bmatrix} x_1 & y_1 & z_1 \\end{bmatrix} + \\color{green}{b}\\begin{bmatrix} x_2 & y_2 & z_2 \\end{bmatrix} + \\color{blue}{c}\\begin{bmatrix} x_3 & y_3 & z_3 \\end{bmatrix}\\] Notice that now \\(\\x\\A\\) is just a linear combination of the rows of \\(\\A\\) .","title":"Example (Left Multiplication)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#the-four-interpretations-of-matrix-multiplication","text":"","title":"The Four Interpretations of Matrix Multiplication"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#element-wise-matrix-multiplication","text":"We have mentioned in the previous section. Here we repeat again for the sake of modularity. Let \\[\\A=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix},\\quad\\mathbf{B}=\\begin{bmatrix} b_{11} & b_{12} & \\cdots & b_{1p} \\\\ b_{21} & b_{22} & \\cdots & b_{2p} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ b_{n1} & b_{n2} & \\cdots & b_{np} \\\\ \\end{bmatrix}\\] then the matrix product \\(\\C = \\A\\B\\) is defined to be the \\(m \\times p\\) matrix: \\[\\mathbf{C}=\\A\\B=\\begin{bmatrix} c_{11} & c_{12} & \\cdots & c_{1p} \\\\ c_{21} & c_{22} & \\cdots & c_{2p} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ c_{m1} & c_{m2} & \\cdots & c_{mp} \\\\ \\end{bmatrix}\\] where \\(c_{ij} = a_{i1}b_{1j} + a_{i2}b_{2j} +\\cdots + a_{in}b_{nj}= \\sum_{k=1}^n a_{ik}b_{kj}\\) for \\(i = 1, \\cdots , m\\) and \\(j = 1, \\cdots , p\\) . That is, the entry \\(c_{i,j}\\) of the product is obtained by multiplying term-by-term the entries of the \\(i\\) -th row of \\(\\A\\) and the \\(j\\) -th column of \\(\\B\\) , and summing these \\(n\\) products. In other words, \\(c_{i,j}\\) is the dot product of the \\(i\\) -th row of \\(\\A\\) and the \\(j\\) -th column of \\(\\B\\) . Therefore, \\(\\C = \\A\\B\\) can also be written as \\[\\mathbf{C}=\\A\\B=\\begin{bmatrix} a_{11}b_{11} +\\cdots + a_{1n}b_{n1} & a_{11}b_{12} +\\cdots + a_{1n}b_{n2} & \\cdots & a_{11}b_{1p} +\\cdots + a_{1n}b_{np} \\\\ a_{21}b_{11} +\\cdots + a_{2n}b_{n1} & a_{21}b_{12} +\\cdots + a_{2n}b_{n2} & \\cdots & a_{21}b_{1p} +\\cdots + a_{2n}b_{np} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1}b_{11} +\\cdots + a_{mn}b_{n1} & a_{m1}b_{12} +\\cdots + a_{mn}b_{n2} & \\cdots & a_{m1}b_{1p} +\\cdots + a_{mn}b_{np} \\\\ \\end{bmatrix} \\] Thus the product \\(\\A\\B\\) is defined if and only if the number of columns in \\(\\A\\) equals the number of rows in \\(\\B\\) .","title":"Element Wise Matrix Multiplication"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#significance-element-wise-matrix-multiplication","text":"From Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 144) , he mentioned the following: The diagonal of \\(\\C\\) contains dot products between row \\(i\\) and column \\(j\\) of \\(\\A\\) and \\(\\B\\) respectively, this is relevant in data covariance matrices. The lower triangle of \\(\\C\\) contains dot products between row \\(i\\) in \\(\\A\\) and column \\(j\\) in \\(\\B\\) where \\(i > j\\) . The upper triangle of \\(\\C\\) contains dot products between row \\(i\\) in \\(\\A\\) and column \\(j\\) in \\(\\B\\) where \\(i < j\\) . Both are important in matrix decompositions, such as QR decomposition and generalized eigendecomposition .","title":"Significance (Element Wise Matrix Multiplication)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#outer-product-wise-matrix-multiplication","text":"To simplify notation, we denote: \\( \\(\\A = \\begin{bmatrix} \\a_1 & \\a_2 \\cdots & \\a_n \\end{bmatrix}, \\quad \\B = \\begin{bmatrix} \\b_1^\\top \\\\ \\b_2^\\top \\\\ \\cdots \\\\ \\b_n^\\top \\end{bmatrix}\\) \\) as shorthand where \\(\\a_i\\) is the \\(i\\) -th column of \\(\\A\\) and \\(\\b_j^\\top\\) is the \\(j\\) -th row of \\(\\B\\) . Then \\[\\A\\B = \\a_1\\b_1^\\top + \\a_2\\b_2^\\top + \\cdots + \\a_n\\b_n^\\top\\] Notice that in each of the \\(\\a_i\\b_i^\\top\\) , the columns form a dependent set (the same can be said of the rows). However, the sum of these singular matrices\u2014the product matrix\u2014has columns that form a linearly independent set. Each of these matrices is rank-1 (to be defined later). This forms the basis for the Singular Value Decomposition. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 145)","title":"Outer Product Wise Matrix Multiplication"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#matrix-multiplication-using-right-multiplication-columns","text":"Using back the notation in the Element Wise Matrix Multiplication , we can define \\[\\A\\B = \\A \\begin{bmatrix} \\b_1 & \\b_2 & \\cdots & \\b_p \\end{bmatrix} = \\begin{bmatrix} \\A\\b_1 & \\A\\b_2 & \\cdots & \\A\\b_p \\end{bmatrix}\\] where \\(\\b_i\\) is the column \\(i\\) of the matrix \\(\\B\\) . This means that each column of the matrix \\(\\C = \\A\\B\\) is defined by \\(\\A\\b_i\\) , and recall in the section \"Matrix-Vector Right Multiplication\", \\(\\A\\b_i\\) means a linear combination of the columns of \\(\\A\\) with weight coefficients in \\(\\b_i\\) . They say a picture is worth a thousand words. The below images are taken from Eli Bendersky's website here . Matrix Multiplication, Column Perspective; Courtesy of Eli Bendersky","title":"Matrix Multiplication using Right Multiplication (Columns)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#significance","text":"The column perspective of matrix multiplication is useful in statistics, when the columns of the left matrix contain a set of regressors (a simplified model of the data), and the right matrix contains coefficients. The coefficients encode the importance of each regressor, and the goal of statistical model-fitting is to find the best coefficients such that the weighted combination of regressors matches the data. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 146)","title":"Significance"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#matrix-multiplication-using-left-multiplication-rows","text":"Using back the notation in the Element Wise Matrix Multiplication , we can define \\[\\A\\B = \\begin{bmatrix}\\a_1 \\\\ \\a_2 \\\\ \\vdots \\\\ \\a_m \\end{bmatrix}\\B = \\begin{bmatrix}\\a_1\\B \\\\ \\a_2\\B \\\\ \\vdots \\\\ \\a_m\\B \\end{bmatrix}\\] where \\(\\a_i\\) is the row \\(i\\) of the matrix \\(\\A\\) . This means that each row of the matrix \\(\\C = \\A\\B\\) is defined by \\(\\a_i\\B\\) , and recall in the section \"Matrix-Vector Left Multiplication\", \\(\\a_i\\B\\) means a linear combination of the row of \\(\\B\\) with weight coefficients in \\(\\a_i\\) . This becomes apparent when we come to the chapter of Row-Echolon Form . They say a picture is worth a thousand words. The below images are taken from Eli Bendersky's website here . Matrix Multiplication, Row Perspective; Courtesy of Eli Bendersky","title":"Matrix Multiplication using Left Multiplication (Rows)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#significance_1","text":"The row perspective is useful, for example in principal components analysis, where the rows of the right matrix contain data (observations in rows and features in columns) and the rows of the left matrix contain weights for combining the features. Then the weighted sum of data creates the principal component scores. - Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 147)","title":"Significance"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#matrix-multiplication-properties","text":"Read Wikipedia . To fill in when free as it is relatively light.","title":"Matrix Multiplication Properties"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#symmetric-matrices","text":"","title":"Symmetric Matrices"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#matrix-multiplication-naive-in-python","text":"For a Divide-and-conquer method, see here 3 . import os import random import numpy as np import torch def seed_all ( seed : int = 19921930 ) -> None : \"\"\"Seed all random number generators.\"\"\" print ( f \"Using Seed Number { seed } \" ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator # set fixed value for python built-in pseudo-random generator random . seed ( seed ) torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False torch . backends . cudnn . enabled = False seed_all () Using Seed Number 19921930 import torch import numpy as np from typing import Tuple , List A = np . random . randint ( 0 , 10 , size = ( 3 , 2 )) B = np . random . randint ( 0 , 10 , size = ( 2 , 2 ))","title":"Matrix Multiplication (Naive) in Python"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#pseudo-code","text":"Let us run through the matrix multiplication between two simple matrices \\(\\A\\) and \\(\\B\\) . We define their product \\(\\C = \\A\\B\\) to be a matrix of shape \\((3, 2)\\) . Take first row of \\(\\A\\) and first column of \\(\\B\\) , compute the dot product of both and assign the value to the first entry of \\(\\C\\) (i.e. \\(\\C_{1, 1}\\) ). Take first row of \\(\\A\\) and second column of \\(\\B\\) , compute the dot product of both and assign the value to the first entry of \\(\\C\\) (i.e. \\(\\C_{1, 2}\\) ). Take second row of \\(\\A\\) and first column of \\(\\B\\) , compute the dot product of both and assign the value to the first entry of \\(\\C\\) (i.e. \\(\\C_{2, 1}\\) ). Take second row of \\(\\A\\) and second column of \\(\\B\\) , compute the dot product of both and assign the value to the first entry of \\(\\C\\) (i.e. \\(\\C_{2, 2}\\) ). Take third row of \\(\\A\\) and first column of \\(\\B\\) , compute the dot product of both and assign the value to the first entry of \\(\\C\\) (i.e. \\(\\C_{3, 1}\\) ). Take third row of \\(\\A\\) and second column of \\(\\B\\) , compute the dot product of both and assign the value to the first entry of \\(\\C\\) (i.e. \\(\\C_{3, 2}\\) ). We have seen the above in laymen english. We can easily convert the above to pseudo-code, but first we need to recognize that the above method is the \"Element-wise\" method, where the outer loop is rows of \\(\\A\\) , and the inner loop is columns of \\(\\B\\) . Input: matrices \\(\\A\\) and \\(\\B\\) of size \\((m, n)\\) and \\((n, p)\\) respectively. Initialize matrix \\(\\C\\) to be the product of \\(\\A\\B\\) with the correct shape. For row i from 1 to m: For col j from 1 to p: compute dot product of row i of A and col j of B: dot assign the dot product to entry \\(C_{i, j}\\) return \\(\\C\\) We have removed a layer of abstraction above, and that is the computation of the dot product, in which we have coded up previously. If there is no abstraction, then: Input: matrices \\(\\A\\) and \\(\\B\\) of size \\((m, n)\\) and \\((n, p)\\) respectively. Initialize matrix \\(\\C\\) to be the product of \\(\\A\\B\\) with the correct shape. For row i from 1 to m: Initialize summation = 0 For col j from 1 to p: for k from 1 to n: summation += dot product of row i of A and col j of B assign the dot product summation to entry \\(C_{i, j}\\) return \\(\\C\\)","title":"Pseudo Code"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#python-code","text":"def linear_combination_vectors ( weights : List [ float ], * args : np . ndarray ) -> np . ndarray : \"\"\"Computes the linear combination of vectors. Args: weights (List[float]): The set of weights corresponding to each vector. Returns: linear_weighted_sum (np.ndarray): The linear combination of vectors. Examples: >>> v1 = np.asarray([1, 2, 3, 4, 5]).reshape(-1, 1) >>> v2 = np.asarray([2, 4, 6, 8, 10]).reshape(-1, 1) >>> v3 = np.asarray([3, 6, 9, 12, 15]).reshape(-1, 1) >>> weights = [10, 20, 30] >>> linear_combination_vectors([10, 20, 30], v1, v2, v3) \"\"\" linear_weighted_sum = np . zeros ( shape = args [ 0 ] . shape ) for weight , vec in zip ( weights , args ): linear_weighted_sum += weight * vec return linear_weighted_sum def dot_product ( v1 : np . ndarray , v2 : np . ndarray ) -> float : \"\"\"Computes the dot product of two vectors. We assume both vectors are flattened, i.e. they are 1D arrays. Args: v1 (np.ndarray): The first vector. v2 (np.ndarray): The second vector. Returns: dot_product_v1_v2 (float): The dot product of two vectors. Examples: >>> v1 = np.asarray([1, 2, 3, 4, 5]) >>> v2 = np.asarray([2, 4, 6, 8, 10]) >>> dot_product(v1, v2) \"\"\" v1 , v2 = np . asarray ( v1 ) . flatten (), np . asarray ( v2 ) . flatten () dot_product_v1_v2 = 0 for element_1 , element_2 in zip ( v1 , v2 ): dot_product_v1_v2 += element_1 * element_2 # same as np.dot but does not take into the orientation of vectors assert dot_product_v1_v2 == np . dot ( v1 . T , v2 ) return dot_product_v1_v2 def get_matmul_shape ( A : np . ndarray , B : np . ndarray ) -> Tuple [ int , int , int ]: \"\"\"Check if the shape of the matrices A and B are compatible for matrix multiplication. If A and B are of size (m, n) and (n, p), respectively, then the shape of the resulting matrix is (m, p). Args: A (np.ndarray): The first matrix. B (np.ndarray): The second matrix. Raises: ValueError: Raises a ValueError if the shape of the matrices A and B are not compatible for matrix multiplication. Returns: (Tuple[int, int, int]): (m, n, p) where (m, n) is the shape of A and (n, p) is the shape of B. \"\"\" if A . shape [ 1 ] != B . shape [ 0 ]: raise ValueError ( f \"The number of columns of A must be equal to the number of rows of B, but got { A . shape [ 1 ] } and { B . shape [ 0 ] } respectively.\" ) return ( A . shape [ 0 ], A . shape [ 1 ], B . shape [ 1 ]) def np_matmul_naive ( A : np . ndarray , B : np . ndarray ) -> np . ndarray : \"\"\"Computes the matrix multiplication of two matrices. Args: A (np.ndarray): The first matrix. B (np.ndarray): The second matrix. Returns: matmul (np.ndarray): The matrix multiplication of two matrices. \"\"\" num_rows_A , common_index , num_cols_B = check_matmul_shape ( A , B ) matmul = np . zeros ( shape = ( num_rows_A , num_cols_B )) # 1st loop: loops through first matrix A for i in range ( num_rows_A ): summation = 0 # 2nd loop: loops through second matrix B for j in range ( num_cols_B ): # 3rd loop: computes dot prod for k in range ( common_index ): summation += A [ i , k ] * B [ k , j ] matmul [ i , j ] = summation return matmul def np_matmul_element_wise ( A : np . ndarray , B : np . ndarray ) -> np . ndarray : \"\"\"Computes the matrix multiplication of two matrices using element wise method. Args: A (np.ndarray): The first matrix. B (np.ndarray): The second matrix. Returns: matmul (np.ndarray): The matrix multiplication of two matrices. \"\"\" num_rows_A , _ , num_cols_B = check_matmul_shape ( A , B ) matmul = np . zeros ( shape = ( num_rows_A , num_cols_B )) # 1st loop: loops through first matrix A for row_i in range ( num_rows_A ): # 2nd loop: loops through second matrix B for col_j in range ( num_cols_B ): # computes dot product of row i with column j of B and # assign the result to the element of the matrix matmul at row i and column j. matmul [ row_i , col_j ] = dot_product ( A [ row_i , :], B [:, col_j ]) return matmul def np_matmul_column_wise ( A : np . ndarray , B : np . ndarray ) -> np . ndarray : \"\"\"Computes the matrix multiplication of two matrices using column wise method. Recall the section on Matrix Multiplication using Right Multiplication. Column i of C is represented by: Ab_i Args: A (np.ndarray): The first matrix. B (np.ndarray): The second matrix. Returns: matmul (np.ndarray): The matrix multiplication of two matrices. \"\"\" num_rows_A , _ , num_cols_B = check_matmul_shape ( A , B ) matmul = np . zeros ( shape = ( num_rows_A , num_cols_B )) # we just need to populate the columns of C for col_i in range ( matmul . shape [ 1 ]): # b_i col_i_B = B [:, col_i ] # Ab_i linear_comb_A_on_col_i_B = linear_combination_vectors ( col_i_B , * A . T ) # C_i = Ab_i matmul [:, col_i ] = linear_comb_A_on_col_i_B return matmul # assert the function output is similar to numpy's A @ B np . allclose ( np_matmul_element_wise ( A , B ), np_matmul_column_wise ( A , B ), A @ B ) True","title":"Python Code"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#time-complexity","text":"The time complexity can be easily found in the pseudo-code. Input: matrices \\(\\A\\) and \\(\\B\\) of size \\((m, n)\\) and \\((n, p)\\) respectively. Initialize matrix \\(\\C\\) to be the product of \\(\\A\\B\\) with the correct shape. For row i from 1 to m: Initialize summation = 0 For col j from 1 to p: for k from 1 to n: summation += dot product of row i of A and col j of B assign the dot product summation to entry \\(C_{i, j}\\) return \\(\\C\\) In rough terms, the first outer loop has \\(m\\) operations, the second loop has \\(p\\) operations and last loop has \\(n\\) operations; we further assume each operation is \\(\\mathcal{O}(1)\\) and thus we have a total of \\(m \\times n \\times p\\) loops (operations), so the time complexity is \\( \\(\\mathcal{O}(mnp) \\approx \\mathcal{O}(n^3)\\) \\) if \\(m \\approx n \\approx p\\) .","title":"Time Complexity"},{"location":"reighns_ml_journey/mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/#references","text":"https://eli.thegreenplace.net/2015/visualizing-matrix-multiplication-as-a-linear-combination/ https://math.stackexchange.com/questions/192835/fastest-and-intuitive-ways-to-look-at-matrix-multiplication https://math.stackexchange.com/questions/24456/matrix-multiplication-interpreting-and-understanding-the-process https://en.wikipedia.org/wiki/Matrix_multiplication \u21a9 https://eli.thegreenplace.net/2015/visualizing-matrix-multiplication-as-a-linear-combination/ \u21a9 solvay_strassen_algorithm \u21a9","title":"References"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\r}{\\mathbf{r}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\] Preamble Both Professor Mike and Gilbert started off with this statement: The entirety and gist of the matrix space can be summarized as answering two key questions: Given a matrix \\(\\A \\in \\F^{m \\times n}\\) and vector \\(\\b \\in \\F^{m}\\) and \\(\\0 \\in \\F^{m}\\) , then can we find a vector \\(\\x \\in \\F^{n}\\) such that \\( \\(\\A\\x = \\b\\) \\) \\( \\(\\A\\x = \\0\\) \\) From the matrix-multiplication section, we can easily re-interpret the question as: \\(\\A\\x=\\b\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\b\\) ? \\(\\A\\x=\\0\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\0\\) assuming \\(\\x \\neq \\0\\) . Column Space Motivation We often frame our Machine Learning problems into a linear system of equations of the form \\(\\A\\x=\\b\\) . Not every linear system of equation is easily solvable, and has a solution \\(\\x\\) exists if and only if \\(\\b\\) belongs to the column space of \\(\\A\\) . Why so? Recall in the section linear algebra and matrix multiplication the following (if you forgot go read up): A column space of a matrix \\(\\A\\) is just the set of linear combination of the columns of \\(\\A\\) , and is a subspace. We will go through it in more details, but for now, I want to introduce this idea first. As a consequence of the example prior, one should realize three things: \\(\\A\\x\\) is a combination of the columns of the matrix \\(\\A\\) . \\(\\A\\x = \\b\\) may not always have a solution \\(\\x\\) . If \\(\\A\\x = \\b\\) has a solution \\(\\x\\) , then the product \\(\\b\\) must be a linear combination of the columns of \\(\\A\\) . This has important consequences later on. For now, just know that if \\(\\A\\x = \\b\\) has a solution, then \\(\\b\\) resides in the column space of \\(\\A\\) . Algebraic Definition (Column Space) Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, with column vectors \\(\\a_1, \\a_2, \\cdots, \\a_n\\) . Note that a linear combination of these vectors is any vector of the form \\[c_1 \\mathbf{a}_1 + c_2 \\mathbf{a}_2 + \\cdots + c_n \\mathbf{a}_n\\] where \\(c_i\\) are scalars; Then the set of all possible linear combinations of \\(\\a_1, \\a_2, \\cdots, \\a_n\\) is called the column space of \\(\\A\\) ; In other words, the column space of \\(\\A\\) is the linear span of the vectors \\(\\a_1, \\a_2, \\cdots, \\a_n\\) . And as noted in the right multiplication method in the section matrix-vector multiplication , any linear combination of the column vectors of a matrix \\(\\A\\) can be written as the product of \\(\\A\\) with a column vector where the column vectors hold the coefficients of the linear combination: \\[ \\begin{array} {rcl} \\A \\begin{bmatrix} c_1 \\\\ \\vdots \\\\ c_n \\end{bmatrix} & = & \\begin{bmatrix} a_{11} & \\cdots & a_{1n} \\\\ \\vdots & \\ddots & \\vdots \\\\ a_{m1} & \\cdots & a_{mn} \\end{bmatrix} \\begin{bmatrix} c_1 \\\\ \\vdots \\\\ c_n \\end{bmatrix} = \\begin{bmatrix} c_1 a_{11} + \\cdots + c_{n} a_{1n} \\\\ \\vdots \\\\ c_{1} a_{m1} + \\cdots + c_{n} a_{mn} \\end{bmatrix} = c_1 \\begin{bmatrix} a_{11} \\\\ \\vdots \\\\ a_{m1} \\end{bmatrix} + \\cdots + c_n \\begin{bmatrix} a_{1n} \\\\ \\vdots \\\\ a_{mn} \\end{bmatrix} \\\\ & = & c_1 \\mathbf{v}_1 + \\cdots + c_n \\mathbf{v}_n \\end{array} \\] Therefore, the column space of \\(\\A\\) consists of all possible products \\(\\A\\x\\) for \\(\\x \\in \\F^n\\) . This is the same as the image or range of the corresponding matrix transformation in which we will learn more on in the linear transformation chapter. Notation (Column Space) The column space of a matrix is denoted as \\(C(\\A)\\) , which is the space spanned by all columns of the matrix \\(\\A\\) . Note that the column space \\(C(\\A)\\) resides in the \\(\\F^{m}\\) space. Example (Column Space) If \\(A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 2 & 0 \\end{bmatrix}\\) , then the column vectors are \\(\\a_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix} \\quad \\a_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0\\end{bmatrix}\\) . A linear combination of \\(\\a_1, \\a_2\\) is any vector of the form \\[c_1 \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix} + c_2 \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} c_1 \\\\ c_2 \\\\ 2c_1 \\end{bmatrix}\\] The set of all such vectors is the column space of \\(\\A\\) and in this case, the column space is precisely the set of vectors \\((x, y, z) \\in \\R^3\\) satisfying the equation \\(z=2x\\) using Cartesian coordinates, this set is a plane through the origin in three-dimensional space. Column Space and Basis Note that the columns of the matrix \\(\\A\\) spans the column space, but may not form a basis since there is no guarantee that the columns are linearly independent. However, recall the theorem that elementary row elimination/reduction does not affect the dependency of the column vectors , therefore, we still can use row reduction to find a basis for the column space. Dimension and Rank The dimension of the column space is called the rank of the matrix. Thus, if the rank of the matrix \\(\\A\\) is \\(r = n\\) , then the column space spans all of \\(\\F^{n}\\) and is a basis of \\(\\F^{n}\\) , else it is a \\(r\\) -dimensional subspace embedded in \\(\\F^{n}\\) . Theorem (Column Space of \\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\) ) \\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\) have the same column space. Proof (Column Space of \\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\) ) We first write \\(\\B = \\A\\A^\\top\\) and use the method that if \\(M \\subseteq N\\) and \\(N \\subseteq M\\) , then \\(N=M\\) to prove this. We first show that \\(C(\\B) \\subseteq C(\\A)\\) . The column space \\(C(\\A) = \\text{span}(\\a_1, \\a_2, ..., \\a_n) \\in \\F^{m}\\) and \\(C(\\B) = \\text{span}(\\b_1, \\b_2, ..., \\b_m)\\) . We note that by the right matrix multiplication , each column of \\(\\B = \\A\\A^\\top\\) is a linear combination of the columns of the left matrix \\(\\A\\) . That is to say, we can represent each column in \\(\\B\\) as \\(\\b_i = \\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_n \\a_n\\) . Consequently, by definition, any column from \\(\\B\\) is an element of \\(\\text{span}(\\a_1, ..., \\a_n)\\) , and hence in the column space \\(C(\\A)\\) . Thus, for any element in \\(C(\\B)\\) , this element must be in \\(C(\\A)\\) , and thus \\(C(\\B) \\subseteq C(\\A)\\) . We then show that \\(C(\\A) \\subseteq C(\\B)\\) . Take any element from \\(C(\\A)\\) , and recall that \\(C(\\B) = \\text{span}(\\b_1, \\b_2, ..., \\b_m) = c_1 \\b_1 + c_2 \\b_2 + \\cdots + c_m \\b_m = c_1 (\\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_m \\a_m) + c_2 (\\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_m \\a_m) + ... + c_2 (\\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_m \\a_m) = d_1\\a_1 + d_2\\a_2 + ... + d_m \\a_m\\) for some \\(d_i \\in \\F\\) . Then any element taken from the column space of \\(\\A\\) is a linear combination of \\(\\a_1, ..., \\a_m\\) ... What can we tell? We cannot tell anything since if \\(n > m\\) , then it may be the case that an element from \\(C(\\A)\\) may not cover. The \"Augment-Rank\" Algorithm to determine membership of Column Space Given a set of vectors \\(S = \\{\\v_1, \\v_2, ..., \\v_n\\}\\) , and a vector \\(\\w\\) , deduce if \\(\\w \\in \\textbf{span}(S)\\) . Assume \\(\\v_i \\in \\R^{m}\\) and \\(\\w \\in \\R^{m}\\) . Construct a matrix \\(\\mathbf{S} = \\begin{bmatrix} \\v_1 & \\v_2 & \\cdots & \\v_m \\end{bmatrix}_{m \\times n}\\) where \\(\\mathbf{S} \\in \\R^{m \\times n}\\) . Compute the rank of \\(\\mathbf{S}\\) and call it \\(s_1\\) . Horizontally concatenate \\(\\mathbf{S}\\) and \\(\\w\\) to get \\(\\mathbf{S}_w = \\mathbf{S} \\cup \\w\\) . Compute rank of \\(\\mathbf{S}_w\\) to be \\(s_2\\) . Then: If \\(s_1 = s_2\\) , this means that column space of \\(\\mathbf{S}\\) equals to the column space of \\(\\mathbf{S}_w\\) , and thus \\(\\w\\) did not alter the column space of \\(\\mathbf{S}\\) , which means \\(\\w\\) must be part of the column space of \\(\\mathbf{S}\\) , and thus in the span of \\(S\\) . If \\(s_2 > s_1\\) , then \\(\\w \\not\\in S\\) because if it is, the column space of \\(\\mathbf{S}_w\\) should not change. We can easily use this algorithm to check if a vector \\(\\w\\) is in the column space of a matrix \\(\\A\\) by setting \\(S\\) to be the set that contains all the columns of \\(\\A\\) . Geometric Intuition Mike mentioned on Linear Algebra: Theory, Intuition, Code, 2021. (pp. 211) that we can think of the above cases geometrically. In the first case where \\(s_1 = s_2\\) , the rank is the same, this means the vector \\(\\w\\) is in the column space of \\(\\A\\) . This makes sense because when we add the new vector to the set, and yet the rank (dimension) did not change, this coincides with the idea of vector \\(\\w\\) sitting somewhere in the column space of \\(\\A\\) , and hence no new geometric directions are obatined by including this vector . In the second case where \\(s_2 > s_1\\) however, if v is outside the column space, then it points off in some other geometric dimension that is not spanned by the column space; hence, B has one extra geometric dimension not contained in A, and thus the rank is one higher. In the image below, we denote \\(C(\\A)\\) as the 1d-subspace in red, then vector \\(\\v\\) is apparently lying in the 1d-subspace, and hence a member of \\(C(\\A)\\) , then \\(\\w\\) , is slightly pointing to a different direction, and hence not in the column space of \\(\\A\\) . Fig; Column Space of A; By Hongnan G. Corollary If \\(\\A\\) is now a full ranked square matrix \\(m \\times m\\) , which means rank of \\(\\A\\) is \\(m\\) , then any vector \\(\\w \\in \\R^{m}\\) will be in the column space of \\(\\A\\) since the column space of \\(\\A\\) is actually a basis of the ambient subspace \\(\\F^{m}\\) . Theorem (Row Operations preserves Column Space) Row operations will not change the dependence of the columns of a matrix. Visualizing Column Space Courtesy of Macro Analyst's linear algebra with python . import matplotlib.pyplot as plt import numpy as np from mpl_toolkits.mplot3d import Axes3D import scipy as sp import scipy.linalg import sympy as sy sy . init_printing () Consider two matrix with \\[\\A = \\begin{bmatrix}1 & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\end{bmatrix} ,\\quad \\B = \\begin{bmatrix}3 & -1 \\\\ 2 & 4 \\\\ -1 & 1 \\end{bmatrix}\\] Then the column space \\(C(\\A)\\) is a 2d-plane given by \\[\\text{plane}(C(\\A)) = \\0 + s\\left[\\matrix{1\\cr 0\\cr 0}\\right] + t\\left[\\matrix{0\\cr 1\\cr 0}\\right]\\] and the column space \\(C(\\B)\\) is a 2d-plane given by \\[\\text{plane}(C(\\B)) = \\0 + s\\left[\\matrix{3\\cr 2\\cr -1}\\right] + t\\left[\\matrix{-1\\cr 4\\cr 1}\\right]\\] fig = plt . figure ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = '3d' ) s = np . linspace ( - 2 , 2 , 20 ) t = np . linspace ( - 2 , 2 , 20 ) S , T = np . meshgrid ( s , t ) X = 3 * S - T Y = 2 * S + 4 * T Z = - S + T ax . plot_wireframe ( X , Y , Z , linewidth = .5 , color = 'r' ) s = np . linspace ( - 10 , 10 , 20 ) t = np . linspace ( - 10 , 10 , 20 ) S , T = np . meshgrid ( s , t ) X = S Y = T Z = np . zeros ( S . shape ) ax . plot_wireframe ( X , Y , Z , linewidth = .5 , color = 'k' ) ax . view_init ( elev = 14 , azim = 58 ) Row Space Algebraic Definition (Row Space) Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, with row vectors \\(\\a_1, \\a_2, \\cdots, \\a_m\\) . Note that a linear combination of these vectors is any vector of the form \\[c_1 \\mathbf{a}_1 + c_2 \\mathbf{a}_2 + \\cdots + c_m \\mathbf{a}_m\\] where \\(c_i\\) are scalars; Then the set of all possible linear combinations of \\(\\a_1, \\a_2, \\cdots, \\a_m\\) is called the row space of \\(\\A\\) ; In other words, the column space of \\(\\A\\) is the linear span of the vectors \\(\\a_1, \\a_2, \\cdots, \\a_m\\) . Note in particular that the row space \\(R(\\A)\\) resides in the \\(\\F^{n}\\) space. Notation (Row Space) The row space of a matrix is denoted as \\(R(\\A)\\) , which is the space spanned by all rows of the matrix \\(\\A\\) . Row Space and Basis Note that elementary row operations do not affect the row space, consequently, row reduction can be used to find a basis for the row space. Dimension and Rank The dimension of the row space is called the rank of the matrix. Thus, if the rank of the matrix \\(\\A\\) is \\(r = m\\) , then the column space spans all of \\(\\F^{m}\\) and is a basis of \\(\\F^{m}\\) , else it is a \\(r\\) -dimensional subspace embedded in \\(\\F^{m}\\) . Theorem (Row space of \\(\\mathbf{A}\\) is the Column space of \\(\\mathbf{A}^\\top\\) ) Given a matrix \\(\\A \\in \\F^{m \\times n}\\) , the rows of \\(\\A\\) is the columns of \\(\\A^\\top\\) , and hence the theorem follows. Theorem (Row Space of \\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\) ) \\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\) have the same row space. Applications in Machine Learning The author Mike mentioned in Linear Algebra: Theory, Intuition, Code, 2021. (pp. 214) that \\(R(\\A) = R(\\A^\\top\\A)\\) is an example of dimensionality reduction where both matrices have the same row space, but \\(\\A^\\top\\A\\) might be a much smaller matrix and hence computationally more efficient. (Right) Null Space (Kernel) Motivation To fill in. Algebraic Definition (Null Space) Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, with column vectors \\(\\a_1, \\a_2, \\cdots, \\a_n\\) . Note that a linear combination of these vectors is any vector of the form \\[c_1 \\mathbf{a}_1 + c_2 \\mathbf{a}_2 + \\cdots + c_n \\mathbf{a}_n\\] where \\(c_i\\) are scalars; Then the nullspace of \\(\\A\\) is the set: \\[ N(\\A) = \\{\\v \\in \\F^{n} ~|~ \\A\\v = \\0\\} \\] Note that the trivial solution \\(\\0\\) is always a solution to the nullspace. Note that if there exists a non-trivial \\(\\v\\) such that \\(\\A\\v = \\0\\) , then for any \\(\\lambda \\in F\\) , we also have \\(\\A(\\lambda\\v) = \\0\\) . Note in particular that the column space \\(N(\\A)\\) resides in the \\(\\F^{n}\\) space. Notation (Null Space) The null space of a matrix is denoted as \\(N(\\A)\\) . What does Null Space tell you? Now one important consequence is that, if there exists a non-trivial solution to the matrix \\(\\A\\x = \\0\\) , then what does it mean? Recall the right multiplication of columns for matrix-vector multiplication : It means that the linear combination of the columns of \\(\\A\\) can form the zero vector \\(\\0\\) . In particular, this linear combination is NON-TRIVIAL! Then the matrix \\(\\A\\) is formed by columns that are linearly dependent, and hence not full rank! We can formalize it as a theorem below. Theorem (Full Ranked Matrix has an Empty Nullspace) A matrix \\(\\A \\in \\F^{m \\times n}\\) is full rank if and only if the nullspace \\(N(\\A)\\) has only the trivial solution. Geometric Intuition (Null Space) Left (Null Space) Algebraic Definition (Left Null Space) Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, then the left nullspace of \\(\\A\\) is actually the nullspace of its transpose: \\[ N(\\A^\\top) = \\{\\v \\in \\F^{m} ~|~ \\A^\\top\\v = \\0\\} \\] and if we take transpose to both sides of \\(\\A^\\top\\v = \\0\\) to be \\(\\left(\\A^\\top\\v \\right)^\\top = \\0^\\top\\) ; it follows we have \\(\\v^\\top\\A = \\0^\\top\\) , where the row vector \\(\\v^\\top\\) is on the left of \\(\\A\\) . Note in particular that the column space \\(N(\\A)\\) resides in the \\(\\F^{m}\\) space. Theorem (The Nullspace and Left Nullspace of a Symmetric Matrix is Equal) Given a symmetric matrix \\(\\A\\) , we know that \\(\\A^\\top = \\A\\) , and thus \\(N(\\A) = N(\\A^\\top)\\) . Orthogonal Subspaces Row and Null Space are Orthogonal and Complements each other The row space and the null space of a matrix \\(\\A \\in \\F^{m \\times n}\\) are orthogonal complements . Proof (Row Space is Orthogonal to Null Space) Orthogonal Subspace We first show that both subspaces are orthogonal. Note that the null space of a matrix \\(\\A \\in F^{m \\times n}\\) is the set of all vectors \\(\\x\\) such that \\(\\A\\x = \\0\\) . We can also write \\(\\A\\x = \\0\\) as \\[ \\A\\x = \\begin{bmatrix} \\r_1 \\cdot \\x \\\\ \\r_2 \\cdot \\x \\\\ \\vdots \\\\ \\r_m \\cdot \\x \\end{bmatrix} \\] where \\(\\cdot\\) is the dot product and \\(\\r_i\\) the row vector \\(i\\) of \\(\\A\\) . Then one can easily see that \\(\\A\\x = \\0\\) if and only if every \\(\\r_i \\cdot \\x = 0\\) . Then it immediately follows that every \\(\\r_i\\) is orthogonal to \\(\\x\\) , and consequently, the nullspace and row space of \\(\\A\\) forms an orthogonal subspace . To see this, take any vector \\(\\r \\in R(\\A)\\) , and represent this \\(\\r = \\lambda_1 \\r_1 + ... + \\lambda_m \\r_m\\) , then \\[ \\begin{aligned} \\r \\cdot \\x &= (\\lambda_1 \\r_1 + ... + \\lambda_m \\r_m) \\cdot \\x \\\\ &= \\lambda_1 \\r_1 \\cdot \\x + ... + \\lambda_m \\r_m \\cdot \\x \\\\ &= \\0 + ... + \\0 \\\\ &= \\0 \\end{aligned} \\] Orthogonal Complements Reference 1 : We have proven that the row space \\(\\newcommand{\\R}{\\mathrm{R}} \\R(A)\\) and null space \\(\\newcommand{\\N}{\\mathrm{N}} \\N(A)\\) are orthogonal to each other; that is, \\(\\newcommand{\\r}{\\vec r} \\newcommand{\\n}{\\vec n} \\forall\\r\\in\\R(A)\\ \\forall\\n\\in\\N(A): \\r\\perp\\n\\) . Next, we show that they are complements of each other: \\[\\R(A)\\cap\\N(A)=\\left\\{\\vec0\\right\\}\\] Both of these criteria must be met for two subspaces to be orthogonal complements. Proof : Suppose we take an element \\(\\v \\in \\mathrm{R}(\\A) \\cap \\N(A)\\) , this means that \\(\\newcommand{\\v}{\\vec v} \\v\\in\\N(A)\\) and \\(\\v\\in\\R(A)\\) . Recall that if \\(\\n\\in\\N(A)\\) then \\( \\(\\n\\cdot\\r=0\\) \\) where \\(\\r\\in\\R(A)\\) . Now the element we took from their intersection \\(\\v\\) has this property: \\[\\v\\cdot\\v=0=\\left\\|\\v\\right\\|^2\\] We can two ways from here, one is we know \\[\\v \\cdot \\v = \\begin{bmatrix} v_1^2 \\\\ v_2^2 \\\\ \\vdots \\\\ \\v_m^2 \\end{bmatrix}\\] and thus for this to be zero, then \\(v_i^2 = 0 \\implies v_i = 0 \\forall i\\) , hence \\(\\v\\) is the zero vector. Otherwise, since \\(\\left\\|\\v\\right\\|=0\\) , the vector \\(\\v\\) must be the zero vector. In any case, any vector \\(\\v\\) in both \\(\\R(A)\\) and \\(\\N(A)\\) must equal \\(\\vec0\\) . Therefore \\(\\R(A)\\cap\\N(A)=\\left\\{\\vec0\\right\\}\\) , and so by definition \\(\\R(A)\\) and \\(\\N(A)\\) are complementary subspaces as well as orthogonal. \\(\\blacksquare\\) Applications of Column and Null Space in Machine Learning Read Linear Algebra: Theory, Intuition, Code, 2021. (pp. 230-231) . The Four Fundamental Subspaces The Dimensionalities of Matrix Spaces References ML Wiki 2 https://math.stackexchange.com/questions/1448326/how-would-one-prove-that-the-row-space-and-null-space-are-orthogonal-compliments# \u21a9 http://mlwiki.org/index.php/Four_Fundamental_Subspaces \u21a9","title":"(old)05.0x linear algebra matrix theory matrix spaces"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#preamble","text":"Both Professor Mike and Gilbert started off with this statement: The entirety and gist of the matrix space can be summarized as answering two key questions: Given a matrix \\(\\A \\in \\F^{m \\times n}\\) and vector \\(\\b \\in \\F^{m}\\) and \\(\\0 \\in \\F^{m}\\) , then can we find a vector \\(\\x \\in \\F^{n}\\) such that \\( \\(\\A\\x = \\b\\) \\) \\( \\(\\A\\x = \\0\\) \\) From the matrix-multiplication section, we can easily re-interpret the question as: \\(\\A\\x=\\b\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\b\\) ? \\(\\A\\x=\\0\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\0\\) assuming \\(\\x \\neq \\0\\) .","title":"Preamble"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#column-space","text":"","title":"Column Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#motivation","text":"We often frame our Machine Learning problems into a linear system of equations of the form \\(\\A\\x=\\b\\) . Not every linear system of equation is easily solvable, and has a solution \\(\\x\\) exists if and only if \\(\\b\\) belongs to the column space of \\(\\A\\) . Why so? Recall in the section linear algebra and matrix multiplication the following (if you forgot go read up): A column space of a matrix \\(\\A\\) is just the set of linear combination of the columns of \\(\\A\\) , and is a subspace. We will go through it in more details, but for now, I want to introduce this idea first. As a consequence of the example prior, one should realize three things: \\(\\A\\x\\) is a combination of the columns of the matrix \\(\\A\\) . \\(\\A\\x = \\b\\) may not always have a solution \\(\\x\\) . If \\(\\A\\x = \\b\\) has a solution \\(\\x\\) , then the product \\(\\b\\) must be a linear combination of the columns of \\(\\A\\) . This has important consequences later on. For now, just know that if \\(\\A\\x = \\b\\) has a solution, then \\(\\b\\) resides in the column space of \\(\\A\\) .","title":"Motivation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#algebraic-definition-column-space","text":"Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, with column vectors \\(\\a_1, \\a_2, \\cdots, \\a_n\\) . Note that a linear combination of these vectors is any vector of the form \\[c_1 \\mathbf{a}_1 + c_2 \\mathbf{a}_2 + \\cdots + c_n \\mathbf{a}_n\\] where \\(c_i\\) are scalars; Then the set of all possible linear combinations of \\(\\a_1, \\a_2, \\cdots, \\a_n\\) is called the column space of \\(\\A\\) ; In other words, the column space of \\(\\A\\) is the linear span of the vectors \\(\\a_1, \\a_2, \\cdots, \\a_n\\) . And as noted in the right multiplication method in the section matrix-vector multiplication , any linear combination of the column vectors of a matrix \\(\\A\\) can be written as the product of \\(\\A\\) with a column vector where the column vectors hold the coefficients of the linear combination: \\[ \\begin{array} {rcl} \\A \\begin{bmatrix} c_1 \\\\ \\vdots \\\\ c_n \\end{bmatrix} & = & \\begin{bmatrix} a_{11} & \\cdots & a_{1n} \\\\ \\vdots & \\ddots & \\vdots \\\\ a_{m1} & \\cdots & a_{mn} \\end{bmatrix} \\begin{bmatrix} c_1 \\\\ \\vdots \\\\ c_n \\end{bmatrix} = \\begin{bmatrix} c_1 a_{11} + \\cdots + c_{n} a_{1n} \\\\ \\vdots \\\\ c_{1} a_{m1} + \\cdots + c_{n} a_{mn} \\end{bmatrix} = c_1 \\begin{bmatrix} a_{11} \\\\ \\vdots \\\\ a_{m1} \\end{bmatrix} + \\cdots + c_n \\begin{bmatrix} a_{1n} \\\\ \\vdots \\\\ a_{mn} \\end{bmatrix} \\\\ & = & c_1 \\mathbf{v}_1 + \\cdots + c_n \\mathbf{v}_n \\end{array} \\] Therefore, the column space of \\(\\A\\) consists of all possible products \\(\\A\\x\\) for \\(\\x \\in \\F^n\\) . This is the same as the image or range of the corresponding matrix transformation in which we will learn more on in the linear transformation chapter.","title":"Algebraic Definition (Column Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#notation-column-space","text":"The column space of a matrix is denoted as \\(C(\\A)\\) , which is the space spanned by all columns of the matrix \\(\\A\\) . Note that the column space \\(C(\\A)\\) resides in the \\(\\F^{m}\\) space.","title":"Notation (Column Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#example-column-space","text":"If \\(A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 2 & 0 \\end{bmatrix}\\) , then the column vectors are \\(\\a_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix} \\quad \\a_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0\\end{bmatrix}\\) . A linear combination of \\(\\a_1, \\a_2\\) is any vector of the form \\[c_1 \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix} + c_2 \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} c_1 \\\\ c_2 \\\\ 2c_1 \\end{bmatrix}\\] The set of all such vectors is the column space of \\(\\A\\) and in this case, the column space is precisely the set of vectors \\((x, y, z) \\in \\R^3\\) satisfying the equation \\(z=2x\\) using Cartesian coordinates, this set is a plane through the origin in three-dimensional space.","title":"Example (Column Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#column-space-and-basis","text":"Note that the columns of the matrix \\(\\A\\) spans the column space, but may not form a basis since there is no guarantee that the columns are linearly independent. However, recall the theorem that elementary row elimination/reduction does not affect the dependency of the column vectors , therefore, we still can use row reduction to find a basis for the column space.","title":"Column Space and Basis"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#dimension-and-rank","text":"The dimension of the column space is called the rank of the matrix. Thus, if the rank of the matrix \\(\\A\\) is \\(r = n\\) , then the column space spans all of \\(\\F^{n}\\) and is a basis of \\(\\F^{n}\\) , else it is a \\(r\\) -dimensional subspace embedded in \\(\\F^{n}\\) .","title":"Dimension and Rank"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#theorem-column-space-of-mathbfa-and-mathbfamathbfatop","text":"\\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\) have the same column space.","title":"Theorem (Column Space of \\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#proof-column-space-of-mathbfa-and-mathbfamathbfatop","text":"We first write \\(\\B = \\A\\A^\\top\\) and use the method that if \\(M \\subseteq N\\) and \\(N \\subseteq M\\) , then \\(N=M\\) to prove this. We first show that \\(C(\\B) \\subseteq C(\\A)\\) . The column space \\(C(\\A) = \\text{span}(\\a_1, \\a_2, ..., \\a_n) \\in \\F^{m}\\) and \\(C(\\B) = \\text{span}(\\b_1, \\b_2, ..., \\b_m)\\) . We note that by the right matrix multiplication , each column of \\(\\B = \\A\\A^\\top\\) is a linear combination of the columns of the left matrix \\(\\A\\) . That is to say, we can represent each column in \\(\\B\\) as \\(\\b_i = \\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_n \\a_n\\) . Consequently, by definition, any column from \\(\\B\\) is an element of \\(\\text{span}(\\a_1, ..., \\a_n)\\) , and hence in the column space \\(C(\\A)\\) . Thus, for any element in \\(C(\\B)\\) , this element must be in \\(C(\\A)\\) , and thus \\(C(\\B) \\subseteq C(\\A)\\) . We then show that \\(C(\\A) \\subseteq C(\\B)\\) . Take any element from \\(C(\\A)\\) , and recall that \\(C(\\B) = \\text{span}(\\b_1, \\b_2, ..., \\b_m) = c_1 \\b_1 + c_2 \\b_2 + \\cdots + c_m \\b_m = c_1 (\\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_m \\a_m) + c_2 (\\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_m \\a_m) + ... + c_2 (\\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_m \\a_m) = d_1\\a_1 + d_2\\a_2 + ... + d_m \\a_m\\) for some \\(d_i \\in \\F\\) . Then any element taken from the column space of \\(\\A\\) is a linear combination of \\(\\a_1, ..., \\a_m\\) ... What can we tell? We cannot tell anything since if \\(n > m\\) , then it may be the case that an element from \\(C(\\A)\\) may not cover.","title":"Proof (Column Space of \\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#the-augment-rank-algorithm-to-determine-membership-of-column-space","text":"Given a set of vectors \\(S = \\{\\v_1, \\v_2, ..., \\v_n\\}\\) , and a vector \\(\\w\\) , deduce if \\(\\w \\in \\textbf{span}(S)\\) . Assume \\(\\v_i \\in \\R^{m}\\) and \\(\\w \\in \\R^{m}\\) . Construct a matrix \\(\\mathbf{S} = \\begin{bmatrix} \\v_1 & \\v_2 & \\cdots & \\v_m \\end{bmatrix}_{m \\times n}\\) where \\(\\mathbf{S} \\in \\R^{m \\times n}\\) . Compute the rank of \\(\\mathbf{S}\\) and call it \\(s_1\\) . Horizontally concatenate \\(\\mathbf{S}\\) and \\(\\w\\) to get \\(\\mathbf{S}_w = \\mathbf{S} \\cup \\w\\) . Compute rank of \\(\\mathbf{S}_w\\) to be \\(s_2\\) . Then: If \\(s_1 = s_2\\) , this means that column space of \\(\\mathbf{S}\\) equals to the column space of \\(\\mathbf{S}_w\\) , and thus \\(\\w\\) did not alter the column space of \\(\\mathbf{S}\\) , which means \\(\\w\\) must be part of the column space of \\(\\mathbf{S}\\) , and thus in the span of \\(S\\) . If \\(s_2 > s_1\\) , then \\(\\w \\not\\in S\\) because if it is, the column space of \\(\\mathbf{S}_w\\) should not change. We can easily use this algorithm to check if a vector \\(\\w\\) is in the column space of a matrix \\(\\A\\) by setting \\(S\\) to be the set that contains all the columns of \\(\\A\\) .","title":"The \"Augment-Rank\" Algorithm to determine membership of Column Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#geometric-intuition","text":"Mike mentioned on Linear Algebra: Theory, Intuition, Code, 2021. (pp. 211) that we can think of the above cases geometrically. In the first case where \\(s_1 = s_2\\) , the rank is the same, this means the vector \\(\\w\\) is in the column space of \\(\\A\\) . This makes sense because when we add the new vector to the set, and yet the rank (dimension) did not change, this coincides with the idea of vector \\(\\w\\) sitting somewhere in the column space of \\(\\A\\) , and hence no new geometric directions are obatined by including this vector . In the second case where \\(s_2 > s_1\\) however, if v is outside the column space, then it points off in some other geometric dimension that is not spanned by the column space; hence, B has one extra geometric dimension not contained in A, and thus the rank is one higher. In the image below, we denote \\(C(\\A)\\) as the 1d-subspace in red, then vector \\(\\v\\) is apparently lying in the 1d-subspace, and hence a member of \\(C(\\A)\\) , then \\(\\w\\) , is slightly pointing to a different direction, and hence not in the column space of \\(\\A\\) . Fig; Column Space of A; By Hongnan G.","title":"Geometric Intuition"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#corollary","text":"If \\(\\A\\) is now a full ranked square matrix \\(m \\times m\\) , which means rank of \\(\\A\\) is \\(m\\) , then any vector \\(\\w \\in \\R^{m}\\) will be in the column space of \\(\\A\\) since the column space of \\(\\A\\) is actually a basis of the ambient subspace \\(\\F^{m}\\) .","title":"Corollary"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#theorem-row-operations-preserves-column-space","text":"Row operations will not change the dependence of the columns of a matrix.","title":"Theorem (Row Operations preserves Column Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#visualizing-column-space","text":"Courtesy of Macro Analyst's linear algebra with python . import matplotlib.pyplot as plt import numpy as np from mpl_toolkits.mplot3d import Axes3D import scipy as sp import scipy.linalg import sympy as sy sy . init_printing () Consider two matrix with \\[\\A = \\begin{bmatrix}1 & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\end{bmatrix} ,\\quad \\B = \\begin{bmatrix}3 & -1 \\\\ 2 & 4 \\\\ -1 & 1 \\end{bmatrix}\\] Then the column space \\(C(\\A)\\) is a 2d-plane given by \\[\\text{plane}(C(\\A)) = \\0 + s\\left[\\matrix{1\\cr 0\\cr 0}\\right] + t\\left[\\matrix{0\\cr 1\\cr 0}\\right]\\] and the column space \\(C(\\B)\\) is a 2d-plane given by \\[\\text{plane}(C(\\B)) = \\0 + s\\left[\\matrix{3\\cr 2\\cr -1}\\right] + t\\left[\\matrix{-1\\cr 4\\cr 1}\\right]\\] fig = plt . figure ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = '3d' ) s = np . linspace ( - 2 , 2 , 20 ) t = np . linspace ( - 2 , 2 , 20 ) S , T = np . meshgrid ( s , t ) X = 3 * S - T Y = 2 * S + 4 * T Z = - S + T ax . plot_wireframe ( X , Y , Z , linewidth = .5 , color = 'r' ) s = np . linspace ( - 10 , 10 , 20 ) t = np . linspace ( - 10 , 10 , 20 ) S , T = np . meshgrid ( s , t ) X = S Y = T Z = np . zeros ( S . shape ) ax . plot_wireframe ( X , Y , Z , linewidth = .5 , color = 'k' ) ax . view_init ( elev = 14 , azim = 58 )","title":"Visualizing Column Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#row-space","text":"","title":"Row Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#algebraic-definition-row-space","text":"Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, with row vectors \\(\\a_1, \\a_2, \\cdots, \\a_m\\) . Note that a linear combination of these vectors is any vector of the form \\[c_1 \\mathbf{a}_1 + c_2 \\mathbf{a}_2 + \\cdots + c_m \\mathbf{a}_m\\] where \\(c_i\\) are scalars; Then the set of all possible linear combinations of \\(\\a_1, \\a_2, \\cdots, \\a_m\\) is called the row space of \\(\\A\\) ; In other words, the column space of \\(\\A\\) is the linear span of the vectors \\(\\a_1, \\a_2, \\cdots, \\a_m\\) . Note in particular that the row space \\(R(\\A)\\) resides in the \\(\\F^{n}\\) space.","title":"Algebraic Definition (Row Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#notation-row-space","text":"The row space of a matrix is denoted as \\(R(\\A)\\) , which is the space spanned by all rows of the matrix \\(\\A\\) .","title":"Notation (Row Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#row-space-and-basis","text":"Note that elementary row operations do not affect the row space, consequently, row reduction can be used to find a basis for the row space.","title":"Row Space and Basis"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#dimension-and-rank_1","text":"The dimension of the row space is called the rank of the matrix. Thus, if the rank of the matrix \\(\\A\\) is \\(r = m\\) , then the column space spans all of \\(\\F^{m}\\) and is a basis of \\(\\F^{m}\\) , else it is a \\(r\\) -dimensional subspace embedded in \\(\\F^{m}\\) .","title":"Dimension and Rank"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#theorem-row-space-of-mathbfa-is-the-column-space-of-mathbfatop","text":"Given a matrix \\(\\A \\in \\F^{m \\times n}\\) , the rows of \\(\\A\\) is the columns of \\(\\A^\\top\\) , and hence the theorem follows.","title":"Theorem (Row space of \\(\\mathbf{A}\\) is the Column space of \\(\\mathbf{A}^\\top\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#theorem-row-space-of-mathbfa-and-mathbfamathbfatop","text":"\\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\) have the same row space.","title":"Theorem (Row Space of \\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#applications-in-machine-learning","text":"The author Mike mentioned in Linear Algebra: Theory, Intuition, Code, 2021. (pp. 214) that \\(R(\\A) = R(\\A^\\top\\A)\\) is an example of dimensionality reduction where both matrices have the same row space, but \\(\\A^\\top\\A\\) might be a much smaller matrix and hence computationally more efficient.","title":"Applications in Machine Learning"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#right-null-space-kernel","text":"","title":"(Right) Null Space (Kernel)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#motivation_1","text":"To fill in.","title":"Motivation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#algebraic-definition-null-space","text":"Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, with column vectors \\(\\a_1, \\a_2, \\cdots, \\a_n\\) . Note that a linear combination of these vectors is any vector of the form \\[c_1 \\mathbf{a}_1 + c_2 \\mathbf{a}_2 + \\cdots + c_n \\mathbf{a}_n\\] where \\(c_i\\) are scalars; Then the nullspace of \\(\\A\\) is the set: \\[ N(\\A) = \\{\\v \\in \\F^{n} ~|~ \\A\\v = \\0\\} \\] Note that the trivial solution \\(\\0\\) is always a solution to the nullspace. Note that if there exists a non-trivial \\(\\v\\) such that \\(\\A\\v = \\0\\) , then for any \\(\\lambda \\in F\\) , we also have \\(\\A(\\lambda\\v) = \\0\\) . Note in particular that the column space \\(N(\\A)\\) resides in the \\(\\F^{n}\\) space.","title":"Algebraic Definition (Null Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#notation-null-space","text":"The null space of a matrix is denoted as \\(N(\\A)\\) .","title":"Notation (Null Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#what-does-null-space-tell-you","text":"Now one important consequence is that, if there exists a non-trivial solution to the matrix \\(\\A\\x = \\0\\) , then what does it mean? Recall the right multiplication of columns for matrix-vector multiplication : It means that the linear combination of the columns of \\(\\A\\) can form the zero vector \\(\\0\\) . In particular, this linear combination is NON-TRIVIAL! Then the matrix \\(\\A\\) is formed by columns that are linearly dependent, and hence not full rank! We can formalize it as a theorem below.","title":"What does Null Space tell you?"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#theorem-full-ranked-matrix-has-an-empty-nullspace","text":"A matrix \\(\\A \\in \\F^{m \\times n}\\) is full rank if and only if the nullspace \\(N(\\A)\\) has only the trivial solution.","title":"Theorem (Full Ranked Matrix has an Empty Nullspace)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#geometric-intuition-null-space","text":"","title":"Geometric Intuition (Null Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#left-null-space","text":"","title":"Left (Null Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#algebraic-definition-left-null-space","text":"Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, then the left nullspace of \\(\\A\\) is actually the nullspace of its transpose: \\[ N(\\A^\\top) = \\{\\v \\in \\F^{m} ~|~ \\A^\\top\\v = \\0\\} \\] and if we take transpose to both sides of \\(\\A^\\top\\v = \\0\\) to be \\(\\left(\\A^\\top\\v \\right)^\\top = \\0^\\top\\) ; it follows we have \\(\\v^\\top\\A = \\0^\\top\\) , where the row vector \\(\\v^\\top\\) is on the left of \\(\\A\\) . Note in particular that the column space \\(N(\\A)\\) resides in the \\(\\F^{m}\\) space.","title":"Algebraic Definition (Left Null Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#theorem-the-nullspace-and-left-nullspace-of-a-symmetric-matrix-is-equal","text":"Given a symmetric matrix \\(\\A\\) , we know that \\(\\A^\\top = \\A\\) , and thus \\(N(\\A) = N(\\A^\\top)\\) .","title":"Theorem (The Nullspace and Left Nullspace of a Symmetric Matrix is Equal)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#orthogonal-subspaces","text":"","title":"Orthogonal Subspaces"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#row-and-null-space-are-orthogonal-and-complements-each-other","text":"The row space and the null space of a matrix \\(\\A \\in \\F^{m \\times n}\\) are orthogonal complements .","title":"Row and Null Space are Orthogonal and Complements each other"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#proof-row-space-is-orthogonal-to-null-space","text":"","title":"Proof (Row Space is Orthogonal to Null Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#orthogonal-subspace","text":"We first show that both subspaces are orthogonal. Note that the null space of a matrix \\(\\A \\in F^{m \\times n}\\) is the set of all vectors \\(\\x\\) such that \\(\\A\\x = \\0\\) . We can also write \\(\\A\\x = \\0\\) as \\[ \\A\\x = \\begin{bmatrix} \\r_1 \\cdot \\x \\\\ \\r_2 \\cdot \\x \\\\ \\vdots \\\\ \\r_m \\cdot \\x \\end{bmatrix} \\] where \\(\\cdot\\) is the dot product and \\(\\r_i\\) the row vector \\(i\\) of \\(\\A\\) . Then one can easily see that \\(\\A\\x = \\0\\) if and only if every \\(\\r_i \\cdot \\x = 0\\) . Then it immediately follows that every \\(\\r_i\\) is orthogonal to \\(\\x\\) , and consequently, the nullspace and row space of \\(\\A\\) forms an orthogonal subspace . To see this, take any vector \\(\\r \\in R(\\A)\\) , and represent this \\(\\r = \\lambda_1 \\r_1 + ... + \\lambda_m \\r_m\\) , then \\[ \\begin{aligned} \\r \\cdot \\x &= (\\lambda_1 \\r_1 + ... + \\lambda_m \\r_m) \\cdot \\x \\\\ &= \\lambda_1 \\r_1 \\cdot \\x + ... + \\lambda_m \\r_m \\cdot \\x \\\\ &= \\0 + ... + \\0 \\\\ &= \\0 \\end{aligned} \\]","title":"Orthogonal Subspace"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#orthogonal-complements","text":"Reference 1 : We have proven that the row space \\(\\newcommand{\\R}{\\mathrm{R}} \\R(A)\\) and null space \\(\\newcommand{\\N}{\\mathrm{N}} \\N(A)\\) are orthogonal to each other; that is, \\(\\newcommand{\\r}{\\vec r} \\newcommand{\\n}{\\vec n} \\forall\\r\\in\\R(A)\\ \\forall\\n\\in\\N(A): \\r\\perp\\n\\) . Next, we show that they are complements of each other: \\[\\R(A)\\cap\\N(A)=\\left\\{\\vec0\\right\\}\\] Both of these criteria must be met for two subspaces to be orthogonal complements. Proof : Suppose we take an element \\(\\v \\in \\mathrm{R}(\\A) \\cap \\N(A)\\) , this means that \\(\\newcommand{\\v}{\\vec v} \\v\\in\\N(A)\\) and \\(\\v\\in\\R(A)\\) . Recall that if \\(\\n\\in\\N(A)\\) then \\( \\(\\n\\cdot\\r=0\\) \\) where \\(\\r\\in\\R(A)\\) . Now the element we took from their intersection \\(\\v\\) has this property: \\[\\v\\cdot\\v=0=\\left\\|\\v\\right\\|^2\\] We can two ways from here, one is we know \\[\\v \\cdot \\v = \\begin{bmatrix} v_1^2 \\\\ v_2^2 \\\\ \\vdots \\\\ \\v_m^2 \\end{bmatrix}\\] and thus for this to be zero, then \\(v_i^2 = 0 \\implies v_i = 0 \\forall i\\) , hence \\(\\v\\) is the zero vector. Otherwise, since \\(\\left\\|\\v\\right\\|=0\\) , the vector \\(\\v\\) must be the zero vector. In any case, any vector \\(\\v\\) in both \\(\\R(A)\\) and \\(\\N(A)\\) must equal \\(\\vec0\\) . Therefore \\(\\R(A)\\cap\\N(A)=\\left\\{\\vec0\\right\\}\\) , and so by definition \\(\\R(A)\\) and \\(\\N(A)\\) are complementary subspaces as well as orthogonal. \\(\\blacksquare\\)","title":"Orthogonal Complements"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#applications-of-column-and-null-space-in-machine-learning","text":"Read Linear Algebra: Theory, Intuition, Code, 2021. (pp. 230-231) .","title":"Applications of Column and Null Space in Machine Learning"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#the-four-fundamental-subspaces","text":"","title":"The Four Fundamental Subspaces"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#the-dimensionalities-of-matrix-spaces","text":"","title":"The Dimensionalities of Matrix Spaces"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/%28old%2905.0x_linear_algebra_matrix_theory_matrix_spaces/#references","text":"ML Wiki 2 https://math.stackexchange.com/questions/1448326/how-would-one-prove-that-the-row-space-and-null-space-are-orthogonal-compliments# \u21a9 http://mlwiki.org/index.php/Four_Fundamental_Subspaces \u21a9","title":"References"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand\\aug{\\fboxsep=-\\fboxrule\\!\\!\\!\\fbox{\\strut}\\!\\!\\!} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\d}{\\mathbf{d}} \\newcommand{\\p}{\\mathbf{p}} \\newcommand{\\r}{\\mathbf{r}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\E}{\\mathbf{E}} \\newcommand{\\P}{\\mathbf{P}}\\] General Form of Linear Equations Algebraic Definition (System of Linear Equations) A general system of \\(m\\) linear equations with \\(n\\) unknowns can be written as: \\[ \\begin{align} a_{11} x_1 + a_{12} x_2 + \\cdots + a_{1n} x_n &= b_1 \\\\ a_{21} x_1 + a_{22} x_2 + \\cdots + a_{2n} x_n &= b_2 \\\\ & \\ \\ \\vdots\\\\ a_{m1} x_1 + a_{m2} x_2 + \\cdots + a_{mn} x_n &= b_m, \\end{align} \\] where \\(x_1, x_2,\\ldots,x_n\\) are the unknowns, \\(a_{11},a_{12},\\ldots,a_{mn}\\) are the coefficients of the system, and \\(b_1,b_2,\\ldots,b_m\\) are the constant terms. Matrix Definition (System of Linear Equations) The vector equation is equivalent to a matrix equation of the form \\(\\A\\x = \\b\\) , where \\(\\A \\in \\F^{m \\times n}\\) , \\(\\x\\) a column vector in \\(\\F^n\\) and \\(\\b\\) a column vector in \\(\\F^m\\) . \\[ \\A = \\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\end{bmatrix},\\quad \\mathbf{x}= \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix},\\quad \\mathbf{b}= \\begin{bmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{bmatrix} \\] Vector Definition (System of Linear Equations) Recall in the chapter on Matrix Multiplication, we note that \\(\\A\\x = \\b\\) is a right multiplication of a matrix \\(\\A\\) on the vector \\(\\b\\) , and thus \\(\\b\\) can be represented as the linear combination of columns of \\(\\A\\) with \\(x_i\\) as coefficients . \\[ \\b = x_1 \\a_1 + x_2 \\a_2 + ... + x_n \\a_n \\implies \\begin{bmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{bmatrix} = x_1 \\begin{bmatrix} a_{11} \\\\ a_{21} \\\\ \\vdots \\\\ a_{m1} \\end{bmatrix} + x_2 \\begin{bmatrix} a_{12} \\\\ a_{22} \\\\ \\vdots \\\\ a_{m2} \\end{bmatrix} + ... + x_n \\begin{bmatrix} a_{1n} \\\\ a_{2n} \\\\ \\vdots \\\\ a_{mn} \\end{bmatrix} \\] Definition (Homogeneous System of Equations) A system of equations is called homogeneous if each equation in the system is equal to \\(0\\) . A homogeneous system has the form: \\[ \\begin{align} a_{11} x_1 + a_{12} x_2 + \\cdots + a_{1n} x_n &= 0 \\\\ a_{21} x_1 + a_{22} x_2 + \\cdots + a_{2n} x_n &= 0 \\\\ & \\ \\ \\vdots\\\\ a_{m1} x_1 + a_{m2} x_2 + \\cdots + a_{mn} x_n &= 0, \\end{align} \\] where \\(x_1, x_2,\\ldots,x_n\\) are the unknowns, \\(a_{11},a_{12},\\ldots,a_{mn}\\) are the coefficients of the system. Note that this definition can be similarly translated in terms of Matrix and Vector definitions. Definition (Inconsistent and Consistent Systems) Consistent : A system of linear equations are called consistent if there exists at least one solution. Inconsistent : A system of linear equations are called inconsistent if there exists no solution. Elementary Row Operations Elementarty row operations provide us a way to find out if a system of linear equations is consistent or not . Definition (Elementary Row Operations) In order to enable us to convert a system of linear equations to an equivalent system, we define the following elementary row operations : Row Permutation: Interchange any two rows of a matrix: \\(\\r_i \\iff \\r_j\\) Row Multiply: Replace any row of a matrix with a non-zero scalar multiple of itself: \\(\\r_i \\to \\lambda\\r_i\\) Row Addition: Replace any row of a matrix with the sum of itself and a non-zero scalar multiple of any other row: \\(\\r_i \\to \\r_i + \\lambda \\r_j\\) . \\(\\r_i\\) refers to row \\(i\\) of the matrix. Definition (Elementary Column Operations) By replacing the word row to column , we recover the definition of elementary column operations . Theorem (Elementary Row Operations Preserve Solution Set of Linear Systems) This theorem will be proven again later in the context of matrices. Here, I highly recommend reading the proof (without the context of matrices) from A First Course in Linear Algebra by Ken Kuttler where he showed that these 3 operations will not change the solution set of the original system of linear equations. Gauss Elimination Definition (Augmented Matrix of a System of Linear Equations) We usually combine \\(\\A\\x = \\b\\) into one system (matrix) for ease of computing elementary row operations, after all, row operations are always applied to the whole system . Given the general form of the linear equations, the augmented matrix of the system of equations is: \\[ [\\A ~|~ \\b] = \\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} & b_1 \\\\ a_{21} & a_{22} & \\cdots & a_{2n} & b_2 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} & b_m \\end{bmatrix} \\] Theorem (Solving Augmented Matrix Solves the System of Linear Equations) We established that row operations on a system of linear equations preserve the orginal solution set, therefore we can apply row operations on the augmented matrix to solve the solution. Definition (Row Echolon Form) Given a matrix \\(\\A \\in \\F^{m \\times n}\\) and \\(\\b \\in \\F^{m}\\) , then we say the augmented matrix \\([\\A ~|~ \\b]\\) is in its row echolon form if: Any rows that are all zeros must be at the bottom of the matrix, that is to say, all zero row vectors are grouped at the bottom. The leading coefficient (also called the pivot) of a non-zero row is always strictly to the right of the leading coefficient of the row above it. All entries in a column below a pivot are zeros. Some textbooks require the leading coefficient to be 1. Definition (Reduced Row Echolon Form) Given a matrix \\(\\A \\in \\F^{m \\times n}\\) and \\(\\b \\in \\F^{m}\\) , then we say the augmented matrix \\([\\A ~|~ \\b]\\) is in its reduced row echolon form if: Any rows that are all zeros must be at the bottom of the matrix, that is to say, all zero row vectors are grouped at the bottom. The leading coefficient (also called the pivot) of a non-zero row is always strictly to the right of the leading coefficient of the row above it. All entries in a column below a pivot are zeros. The leading coefficient to be 1. All entries in a column above and below a leading entry are zero. Definition (Pivot Position and Pivot Column) Pivot Position: A pivot position in a matrix is the location of a leading entry in the row-echelon form of a matrix. Pivot Column: A pivot column is a column that contains a pivot position. Algorithm (Gaussian and Gaussian-Jordan Elimination) Entirely taken from A First Course in Linear Algebra by Ken Kuttler . This algorithm provides a method for using row operations to take a matrix to its reduced row-echelon form. We begin with the matrix in its original form. Starting from the left, find the first nonzero column. This is the first pivot column, and the position at the top of this column is the first pivot position. Switch rows if necessary to place a nonzero number in the first pivot position. Use row operations to make the entries below the first pivot position (in the first pivot column) equal to zero. Ignoring the row containing the first pivot position, repeat steps 1 and 2 with the remaining rows. Repeat the process until there are no more rows to modify. Divide each nonzero row by the value of the leading entry, so that the leading entry becomes 1 . The matrix will then be in row-echelon form. The following step will carry the matrix from row-echelon form to reduced row-echelon form. Moving from right to left, use row operations to create zeros in the entries of the pivot columns which are above the pivot positions. The result will be a matrix in reduced row-echelon form. Definition (Types of Solutions) Modified from A First Course in Linear Algebra by Ken Kuttler . Definition (No Solution) In the case where the system of equations has no solution, the row-echelon form of the augmented matrix will have a row of the form: \\[ \\left[\\begin{array}{@{}ccc|c@{}} 0 & 0 & \\cdots & b_i \\\\ \\end{array}\\right] \\] That is to say, there exists a row with entirely zeros in \\(\\A\\) but the corresponding output \\(\\b_i \\neq 0\\) . Definition (One Unique Solution) We use a small example as follows: \\[ \\left[\\begin{array}{@{}ccc|c@{}} 1 & 0 & 0 & b_1 \\\\ 0 & 1 & 0 & b_2 \\\\ 0 & 0 & 1 & b_3 \\\\ \\end{array}\\right] \\] This system has unique solution as every column of the coefficient matrix is a pivot column. Definition (Infinitely Many Solutions) We use a small example as follows. In the case where the system of equations has infinitely many solutions, the solution contains parameters. There will be columns of the coefficient matrix which are not pivot columns. The following are examples of augmented matrices in reduced row-echelon form for systems of equations with infinitely many solutions. \\[ \\left[\\begin{array}{@{}ccc|c@{}} 1 & 0 & 0 & b_1 \\\\ 0 & 1 & 0 & b_2 \\\\ 0 & 0 & 0 & 0 \\\\ \\end{array}\\right] \\] Uniqueness of Reduced Row-Echolon Form Definition (Basis Variable) Assume a augmented matrix system \\([\\A ~|~ \\b]\\) in rref , then the variables (unknowns) \\(x_i\\) is a basic variable if \\([\\A ~|~ \\b]\\) has a leading 1 in column number \\(i\\) , in this case, column \\(i\\) is also a pivot column . Definition (Free Variable) If the variable \\(x_i\\) is not basis , then it is free . Definition (Free Column) A free column is a column that does not contains a pivot position. Example (Basic and Free Variable) This is best understood from an example taken from A First Course in Linear Algebra by Ken Kuttler . Consider the system: \\[ \\begin{align} x + 2y - z + w = 3 \\\\ x + y - z + w = 1 \\\\ x + 3y - z + w = 5 \\end{align} \\] we know that the augmented matrix is: \\[ \\left[\\begin{array}{@{}cccc|c@{}} 1 & 2 & -1 & 1 & 3 \\\\ 0 & 1 & 0 & 0 & 2 \\\\ 0 & 0 & 0 & 0 & 0\\\\ \\end{array}\\right] \\] Solution We always look out for the row with 1 variable to one solution (if it exists). In this case, it is \\(y = 2\\) . The perks of rref allows us to do this easily. In the first row, it has \\(x + 2y - z + w = 3 \\implies x + 4 - z + w = 3 \\implies x = -1 + z - w\\) . Since the solution of \\(x\\) depends on \\(z\\) and \\(w\\) , we call \\(z\\) and \\(w\\) the free variable and parameters as \\(z\\) and \\(w\\) can actually take on any value. Set \\(z = s\\) Set \\(w = t\\) So the solution set can be described as: \\[ \\begin{bmatrix} x \\\\ y \\\\ z \\\\ w \\end{bmatrix} = \\begin{bmatrix} -1 + s - t \\\\ 2 \\\\ s \\\\ t \\end{bmatrix} \\] and has infinitely number of solutions . Here, the free variables are the parameters \\(z = s\\) and \\(w = t\\) , and basic variables . Sorting out the confusion (Basic and Free Variables) From the example above, we can clearly see that free variables allow us to assign any values to them. The above example seems obvious, but it isn't that much if we have: \\[ \\left[\\begin{array}{@{}cccc|c@{}} 1 & 2 & 0 & -2 & 0 \\\\ 0 & 0 & 1 & 2 & 0 \\\\ 0 & 0 & 0 & 0 & 0\\\\ \\end{array}\\right] \\] which translates to: \\[ \\begin{aligned} x_1 + 2x_2 + 0x_3 - 2x_4 = 0 \\\\ 0 x_1 + 0x_2 + x_3 + 2x_4 = 0 \\end{aligned} \\] By definition \\(x_2\\) and \\(x_4\\) are free variables, and if you ever wonder why \\(x_4\\) is free (even though it is by definition), then you did not understand the basics. Consider simply: \\[ \\begin{aligned} x + y = 0 \\\\ 2x + 2y = 0 \\end{aligned} \\] then it is obvious that this system reduces to only solving \\(x + y = 0\\) , in which if you do RREF , the free variable is \\(y\\) . If you plot out the solution set, this is just a straight line \\(x + y = 0\\) that passes through the origin. Then if you write it as \\(x = -y\\) , then this means \\(x\\) depends on \\(y\\) , in which \\(y\\) can be any point on the line. Similarly, if we ignore the definition of free variable, we can also write \\(y = -x\\) and recover our favourite high school equation of a line where \\(y\\) depends on \\(x\\) and \\(x\\) being independent is allowed to take on any values. But matrix theory now gives us a systematic way to approach things, we just need to know that if our unknowns is more than the equations, we are usually bound to have free variables. Word of Caution (Basic and Free Variables) Note that since normal Gaussian Elimination REF is not unique, there can be different free and basic variables for different REF . But you will see that RREF guarantees uniqueness. Proposition (Basic and Free Variables) If \\(x_i\\) is a basic variable of a homogeneous system of linear equations, then any solution of the system with \\(x_j=0\\) for all those free variables \\(x_j\\) with \\(j>i\\) must also have \\(x_i=0\\) . This is best understood by the previous example, note that we can denote: \\[ x = x_1, y = x_2, z = x_3, w = x_4 \\] and see that the free variables below \\(x_1\\) cannot have \\(x_1 \\neq 0\\) inside. Lemma (Solutions and the Reduced Row-Echelon Form of a Matrix) Let \\(\\A\\) and \\(\\B\\) be two distinct augmented matrices for two homogeneous systems of \\(m\\) equations in \\(n\\) variables, such that \\(A\\) and \\(B\\) are each in reduced row-echelon. Then, the two systems do not have exactly the same solutions. Definition (Row Equivalence) Two matrices \\(\\A\\) and \\(\\B\\) are row equivalent if one matrix can be obtained from the other matrix by a finite sequence of elementary row operations . Note that if \\(\\A\\) can be obtained by applying a sequence of elementary row operations on \\(\\B\\) , then it follows that we just need to apply the sequence in reverse for \\(\\B\\) to get to \\(\\A\\) . Theorem (Every Matrix is row equivalent to its RREF) Every matrix \\(\\A \\in \\F^{m \\times n}\\) is row equivalent to its RREF . Theorem (Row Equivalent Augmented Matrices have the same solution set) Given \\([\\A ~|~ \\b]\\) and \\([\\C ~|~ \\d]\\) , if both are row equivalent to each other, then the two linear systems have the same solution sets. Theorem (RREF is Unique) Every matrix \\(\\A\\) has a RREF and it is unique. To prove it one should use Lemma (Solutions and the Reduced Row-Echelon Form of a Matrix) and Theorem (Row Equivalent Augmented Matrices have the same solution set) . See A First Course in Linear Algebra by Ken Kuttler . Rank and Homogeneous Systems The section talks about matrix rank in homogeneous systems. I felt it is better mentioned again in matrix theory. So do visit there. Elementary Matrices Permutation Matrix Row Exchange: $$ \\begin{align} x_1- 2x_2+x_3&=0\\ 2x_2-8x_3&=8\\ -4x_1+5x_2+9x_3&=-9 \\end{align} $$ vs \\[ \\begin{align} 2x_2-8x_3&=8\\\\ x_1- 2x_2+x_3&=0\\\\ -4x_1+5x_2+9x_3&=-9 \\end{align} \\] has no difference, we just swapped row 1 and 2. We can do the same in matrix for conveince. Also, given \\[ \\P = \\begin{bmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 1 \\\\ \\end{bmatrix} ,\\quad \\A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\\\ \\end{bmatrix} \\] then \\[\\P\\A = \\begin{bmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 1 \\\\ \\end{bmatrix} \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\\\ \\end{bmatrix} = \\begin{bmatrix} 4 & 5 & 6 \\\\ 1 & 2 & 3 \\\\ 7 & 8 & 9 \\\\ \\end{bmatrix}\\] and notice that row 1 and 2 are swapped by the left multiplication of the permutation matrix \\(\\P\\) . Why did it worked? Recall now \\[\\P\\A = \\begin{bmatrix}\\ \\p_1 \\\\ \\p_2 \\\\ \\p_3 \\end{bmatrix}\\A = \\begin{bmatrix}\\p_1\\A \\\\ \\p_2\\A \\\\ \\p_3\\A \\end{bmatrix}\\] We just look at the first row of \\(\\P\\A\\) given by \\(\\p_1\\A\\) which maps to the first row of \\(\\P\\A\\) . \\[\\p_1\\A = 0 \\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix} + 1 \\begin{bmatrix} 4 & 5 & 6 \\end{bmatrix} + 0 \\begin{bmatrix} 7 & 8 & 9 \\end{bmatrix} = \\begin{bmatrix} 4 & 5 & 6 \\end{bmatrix}\\] Then the rest is the same logic: \\[\\p_2\\A = 1 \\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix} + 0 \\begin{bmatrix} 4 & 5 & 6 \\end{bmatrix} + 0 \\begin{bmatrix} 7 & 8 & 9 \\end{bmatrix} = \\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix}\\] \\[\\p_3\\A = 0 \\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix} + 0 \\begin{bmatrix} 4 & 5 & 6 \\end{bmatrix} + 1 \\begin{bmatrix} 7 & 8 & 9 \\end{bmatrix} = \\begin{bmatrix} 7 & 8 & 9 \\end{bmatrix}\\] We now see why through Matrix Multiplication (Left row wise) that the Permutation Matrix works the way it is! References A First Course in Linear Algebra by Ken Kuttler https://math.stackexchange.com/questions/1634411/why-adding-or-subtracting-linear-equations-finds-their-intersection-point","title":"System of Linear Equations"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#general-form-of-linear-equations","text":"","title":"General Form of Linear Equations"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#algebraic-definition-system-of-linear-equations","text":"A general system of \\(m\\) linear equations with \\(n\\) unknowns can be written as: \\[ \\begin{align} a_{11} x_1 + a_{12} x_2 + \\cdots + a_{1n} x_n &= b_1 \\\\ a_{21} x_1 + a_{22} x_2 + \\cdots + a_{2n} x_n &= b_2 \\\\ & \\ \\ \\vdots\\\\ a_{m1} x_1 + a_{m2} x_2 + \\cdots + a_{mn} x_n &= b_m, \\end{align} \\] where \\(x_1, x_2,\\ldots,x_n\\) are the unknowns, \\(a_{11},a_{12},\\ldots,a_{mn}\\) are the coefficients of the system, and \\(b_1,b_2,\\ldots,b_m\\) are the constant terms.","title":"Algebraic Definition (System of Linear Equations)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#matrix-definition-system-of-linear-equations","text":"The vector equation is equivalent to a matrix equation of the form \\(\\A\\x = \\b\\) , where \\(\\A \\in \\F^{m \\times n}\\) , \\(\\x\\) a column vector in \\(\\F^n\\) and \\(\\b\\) a column vector in \\(\\F^m\\) . \\[ \\A = \\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\end{bmatrix},\\quad \\mathbf{x}= \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix},\\quad \\mathbf{b}= \\begin{bmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{bmatrix} \\]","title":"Matrix Definition (System of Linear Equations)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#vector-definition-system-of-linear-equations","text":"Recall in the chapter on Matrix Multiplication, we note that \\(\\A\\x = \\b\\) is a right multiplication of a matrix \\(\\A\\) on the vector \\(\\b\\) , and thus \\(\\b\\) can be represented as the linear combination of columns of \\(\\A\\) with \\(x_i\\) as coefficients . \\[ \\b = x_1 \\a_1 + x_2 \\a_2 + ... + x_n \\a_n \\implies \\begin{bmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{bmatrix} = x_1 \\begin{bmatrix} a_{11} \\\\ a_{21} \\\\ \\vdots \\\\ a_{m1} \\end{bmatrix} + x_2 \\begin{bmatrix} a_{12} \\\\ a_{22} \\\\ \\vdots \\\\ a_{m2} \\end{bmatrix} + ... + x_n \\begin{bmatrix} a_{1n} \\\\ a_{2n} \\\\ \\vdots \\\\ a_{mn} \\end{bmatrix} \\]","title":"Vector Definition (System of Linear Equations)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-homogeneous-system-of-equations","text":"A system of equations is called homogeneous if each equation in the system is equal to \\(0\\) . A homogeneous system has the form: \\[ \\begin{align} a_{11} x_1 + a_{12} x_2 + \\cdots + a_{1n} x_n &= 0 \\\\ a_{21} x_1 + a_{22} x_2 + \\cdots + a_{2n} x_n &= 0 \\\\ & \\ \\ \\vdots\\\\ a_{m1} x_1 + a_{m2} x_2 + \\cdots + a_{mn} x_n &= 0, \\end{align} \\] where \\(x_1, x_2,\\ldots,x_n\\) are the unknowns, \\(a_{11},a_{12},\\ldots,a_{mn}\\) are the coefficients of the system. Note that this definition can be similarly translated in terms of Matrix and Vector definitions.","title":"Definition (Homogeneous System of Equations)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-inconsistent-and-consistent-systems","text":"Consistent : A system of linear equations are called consistent if there exists at least one solution. Inconsistent : A system of linear equations are called inconsistent if there exists no solution.","title":"Definition (Inconsistent and Consistent Systems)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#elementary-row-operations","text":"Elementarty row operations provide us a way to find out if a system of linear equations is consistent or not .","title":"Elementary Row Operations"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-elementary-row-operations","text":"In order to enable us to convert a system of linear equations to an equivalent system, we define the following elementary row operations : Row Permutation: Interchange any two rows of a matrix: \\(\\r_i \\iff \\r_j\\) Row Multiply: Replace any row of a matrix with a non-zero scalar multiple of itself: \\(\\r_i \\to \\lambda\\r_i\\) Row Addition: Replace any row of a matrix with the sum of itself and a non-zero scalar multiple of any other row: \\(\\r_i \\to \\r_i + \\lambda \\r_j\\) . \\(\\r_i\\) refers to row \\(i\\) of the matrix.","title":"Definition (Elementary Row Operations)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-elementary-column-operations","text":"By replacing the word row to column , we recover the definition of elementary column operations .","title":"Definition (Elementary Column Operations)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#theorem-elementary-row-operations-preserve-solution-set-of-linear-systems","text":"This theorem will be proven again later in the context of matrices. Here, I highly recommend reading the proof (without the context of matrices) from A First Course in Linear Algebra by Ken Kuttler where he showed that these 3 operations will not change the solution set of the original system of linear equations.","title":"Theorem (Elementary Row Operations Preserve Solution Set of Linear Systems)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#gauss-elimination","text":"","title":"Gauss Elimination"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-augmented-matrix-of-a-system-of-linear-equations","text":"We usually combine \\(\\A\\x = \\b\\) into one system (matrix) for ease of computing elementary row operations, after all, row operations are always applied to the whole system . Given the general form of the linear equations, the augmented matrix of the system of equations is: \\[ [\\A ~|~ \\b] = \\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} & b_1 \\\\ a_{21} & a_{22} & \\cdots & a_{2n} & b_2 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} & b_m \\end{bmatrix} \\]","title":"Definition (Augmented Matrix of a System of Linear Equations)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#theorem-solving-augmented-matrix-solves-the-system-of-linear-equations","text":"We established that row operations on a system of linear equations preserve the orginal solution set, therefore we can apply row operations on the augmented matrix to solve the solution.","title":"Theorem (Solving Augmented Matrix Solves the System of Linear Equations)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-row-echolon-form","text":"Given a matrix \\(\\A \\in \\F^{m \\times n}\\) and \\(\\b \\in \\F^{m}\\) , then we say the augmented matrix \\([\\A ~|~ \\b]\\) is in its row echolon form if: Any rows that are all zeros must be at the bottom of the matrix, that is to say, all zero row vectors are grouped at the bottom. The leading coefficient (also called the pivot) of a non-zero row is always strictly to the right of the leading coefficient of the row above it. All entries in a column below a pivot are zeros. Some textbooks require the leading coefficient to be 1.","title":"Definition (Row Echolon Form)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-reduced-row-echolon-form","text":"Given a matrix \\(\\A \\in \\F^{m \\times n}\\) and \\(\\b \\in \\F^{m}\\) , then we say the augmented matrix \\([\\A ~|~ \\b]\\) is in its reduced row echolon form if: Any rows that are all zeros must be at the bottom of the matrix, that is to say, all zero row vectors are grouped at the bottom. The leading coefficient (also called the pivot) of a non-zero row is always strictly to the right of the leading coefficient of the row above it. All entries in a column below a pivot are zeros. The leading coefficient to be 1. All entries in a column above and below a leading entry are zero.","title":"Definition (Reduced Row Echolon Form)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-pivot-position-and-pivot-column","text":"Pivot Position: A pivot position in a matrix is the location of a leading entry in the row-echelon form of a matrix. Pivot Column: A pivot column is a column that contains a pivot position.","title":"Definition (Pivot Position and Pivot Column)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#algorithm-gaussian-and-gaussian-jordan-elimination","text":"Entirely taken from A First Course in Linear Algebra by Ken Kuttler . This algorithm provides a method for using row operations to take a matrix to its reduced row-echelon form. We begin with the matrix in its original form. Starting from the left, find the first nonzero column. This is the first pivot column, and the position at the top of this column is the first pivot position. Switch rows if necessary to place a nonzero number in the first pivot position. Use row operations to make the entries below the first pivot position (in the first pivot column) equal to zero. Ignoring the row containing the first pivot position, repeat steps 1 and 2 with the remaining rows. Repeat the process until there are no more rows to modify. Divide each nonzero row by the value of the leading entry, so that the leading entry becomes 1 . The matrix will then be in row-echelon form. The following step will carry the matrix from row-echelon form to reduced row-echelon form. Moving from right to left, use row operations to create zeros in the entries of the pivot columns which are above the pivot positions. The result will be a matrix in reduced row-echelon form.","title":"Algorithm (Gaussian and Gaussian-Jordan Elimination)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-types-of-solutions","text":"Modified from A First Course in Linear Algebra by Ken Kuttler .","title":"Definition (Types of Solutions)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-no-solution","text":"In the case where the system of equations has no solution, the row-echelon form of the augmented matrix will have a row of the form: \\[ \\left[\\begin{array}{@{}ccc|c@{}} 0 & 0 & \\cdots & b_i \\\\ \\end{array}\\right] \\] That is to say, there exists a row with entirely zeros in \\(\\A\\) but the corresponding output \\(\\b_i \\neq 0\\) .","title":"Definition (No Solution)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-one-unique-solution","text":"We use a small example as follows: \\[ \\left[\\begin{array}{@{}ccc|c@{}} 1 & 0 & 0 & b_1 \\\\ 0 & 1 & 0 & b_2 \\\\ 0 & 0 & 1 & b_3 \\\\ \\end{array}\\right] \\] This system has unique solution as every column of the coefficient matrix is a pivot column.","title":"Definition (One Unique Solution)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-infinitely-many-solutions","text":"We use a small example as follows. In the case where the system of equations has infinitely many solutions, the solution contains parameters. There will be columns of the coefficient matrix which are not pivot columns. The following are examples of augmented matrices in reduced row-echelon form for systems of equations with infinitely many solutions. \\[ \\left[\\begin{array}{@{}ccc|c@{}} 1 & 0 & 0 & b_1 \\\\ 0 & 1 & 0 & b_2 \\\\ 0 & 0 & 0 & 0 \\\\ \\end{array}\\right] \\]","title":"Definition (Infinitely Many Solutions)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#uniqueness-of-reduced-row-echolon-form","text":"","title":"Uniqueness of Reduced Row-Echolon Form"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-basis-variable","text":"Assume a augmented matrix system \\([\\A ~|~ \\b]\\) in rref , then the variables (unknowns) \\(x_i\\) is a basic variable if \\([\\A ~|~ \\b]\\) has a leading 1 in column number \\(i\\) , in this case, column \\(i\\) is also a pivot column .","title":"Definition (Basis Variable)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-free-variable","text":"If the variable \\(x_i\\) is not basis , then it is free .","title":"Definition (Free Variable)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-free-column","text":"A free column is a column that does not contains a pivot position.","title":"Definition (Free Column)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#example-basic-and-free-variable","text":"This is best understood from an example taken from A First Course in Linear Algebra by Ken Kuttler . Consider the system: \\[ \\begin{align} x + 2y - z + w = 3 \\\\ x + y - z + w = 1 \\\\ x + 3y - z + w = 5 \\end{align} \\] we know that the augmented matrix is: \\[ \\left[\\begin{array}{@{}cccc|c@{}} 1 & 2 & -1 & 1 & 3 \\\\ 0 & 1 & 0 & 0 & 2 \\\\ 0 & 0 & 0 & 0 & 0\\\\ \\end{array}\\right] \\] Solution We always look out for the row with 1 variable to one solution (if it exists). In this case, it is \\(y = 2\\) . The perks of rref allows us to do this easily. In the first row, it has \\(x + 2y - z + w = 3 \\implies x + 4 - z + w = 3 \\implies x = -1 + z - w\\) . Since the solution of \\(x\\) depends on \\(z\\) and \\(w\\) , we call \\(z\\) and \\(w\\) the free variable and parameters as \\(z\\) and \\(w\\) can actually take on any value. Set \\(z = s\\) Set \\(w = t\\) So the solution set can be described as: \\[ \\begin{bmatrix} x \\\\ y \\\\ z \\\\ w \\end{bmatrix} = \\begin{bmatrix} -1 + s - t \\\\ 2 \\\\ s \\\\ t \\end{bmatrix} \\] and has infinitely number of solutions . Here, the free variables are the parameters \\(z = s\\) and \\(w = t\\) , and basic variables .","title":"Example (Basic and Free Variable)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#sorting-out-the-confusion-basic-and-free-variables","text":"From the example above, we can clearly see that free variables allow us to assign any values to them. The above example seems obvious, but it isn't that much if we have: \\[ \\left[\\begin{array}{@{}cccc|c@{}} 1 & 2 & 0 & -2 & 0 \\\\ 0 & 0 & 1 & 2 & 0 \\\\ 0 & 0 & 0 & 0 & 0\\\\ \\end{array}\\right] \\] which translates to: \\[ \\begin{aligned} x_1 + 2x_2 + 0x_3 - 2x_4 = 0 \\\\ 0 x_1 + 0x_2 + x_3 + 2x_4 = 0 \\end{aligned} \\] By definition \\(x_2\\) and \\(x_4\\) are free variables, and if you ever wonder why \\(x_4\\) is free (even though it is by definition), then you did not understand the basics. Consider simply: \\[ \\begin{aligned} x + y = 0 \\\\ 2x + 2y = 0 \\end{aligned} \\] then it is obvious that this system reduces to only solving \\(x + y = 0\\) , in which if you do RREF , the free variable is \\(y\\) . If you plot out the solution set, this is just a straight line \\(x + y = 0\\) that passes through the origin. Then if you write it as \\(x = -y\\) , then this means \\(x\\) depends on \\(y\\) , in which \\(y\\) can be any point on the line. Similarly, if we ignore the definition of free variable, we can also write \\(y = -x\\) and recover our favourite high school equation of a line where \\(y\\) depends on \\(x\\) and \\(x\\) being independent is allowed to take on any values. But matrix theory now gives us a systematic way to approach things, we just need to know that if our unknowns is more than the equations, we are usually bound to have free variables.","title":"Sorting out the confusion (Basic and Free Variables)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#word-of-caution-basic-and-free-variables","text":"Note that since normal Gaussian Elimination REF is not unique, there can be different free and basic variables for different REF . But you will see that RREF guarantees uniqueness.","title":"Word of Caution (Basic and Free Variables)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#proposition-basic-and-free-variables","text":"If \\(x_i\\) is a basic variable of a homogeneous system of linear equations, then any solution of the system with \\(x_j=0\\) for all those free variables \\(x_j\\) with \\(j>i\\) must also have \\(x_i=0\\) . This is best understood by the previous example, note that we can denote: \\[ x = x_1, y = x_2, z = x_3, w = x_4 \\] and see that the free variables below \\(x_1\\) cannot have \\(x_1 \\neq 0\\) inside.","title":"Proposition (Basic and Free Variables)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#lemma-solutions-and-the-reduced-row-echelon-form-of-a-matrix","text":"Let \\(\\A\\) and \\(\\B\\) be two distinct augmented matrices for two homogeneous systems of \\(m\\) equations in \\(n\\) variables, such that \\(A\\) and \\(B\\) are each in reduced row-echelon. Then, the two systems do not have exactly the same solutions.","title":"Lemma (Solutions and the Reduced Row-Echelon Form of a Matrix)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#definition-row-equivalence","text":"Two matrices \\(\\A\\) and \\(\\B\\) are row equivalent if one matrix can be obtained from the other matrix by a finite sequence of elementary row operations . Note that if \\(\\A\\) can be obtained by applying a sequence of elementary row operations on \\(\\B\\) , then it follows that we just need to apply the sequence in reverse for \\(\\B\\) to get to \\(\\A\\) .","title":"Definition (Row Equivalence)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#theorem-every-matrix-is-row-equivalent-to-its-rref","text":"Every matrix \\(\\A \\in \\F^{m \\times n}\\) is row equivalent to its RREF .","title":"Theorem (Every Matrix is row equivalent to its RREF)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#theorem-row-equivalent-augmented-matrices-have-the-same-solution-set","text":"Given \\([\\A ~|~ \\b]\\) and \\([\\C ~|~ \\d]\\) , if both are row equivalent to each other, then the two linear systems have the same solution sets.","title":"Theorem (Row Equivalent Augmented Matrices have the same solution set)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#theorem-rref-is-unique","text":"Every matrix \\(\\A\\) has a RREF and it is unique. To prove it one should use Lemma (Solutions and the Reduced Row-Echelon Form of a Matrix) and Theorem (Row Equivalent Augmented Matrices have the same solution set) . See A First Course in Linear Algebra by Ken Kuttler .","title":"Theorem (RREF is Unique)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#rank-and-homogeneous-systems","text":"The section talks about matrix rank in homogeneous systems. I felt it is better mentioned again in matrix theory. So do visit there.","title":"Rank and Homogeneous Systems"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#elementary-matrices","text":"","title":"Elementary Matrices"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#permutation-matrix","text":"Row Exchange: $$ \\begin{align} x_1- 2x_2+x_3&=0\\ 2x_2-8x_3&=8\\ -4x_1+5x_2+9x_3&=-9 \\end{align} $$ vs \\[ \\begin{align} 2x_2-8x_3&=8\\\\ x_1- 2x_2+x_3&=0\\\\ -4x_1+5x_2+9x_3&=-9 \\end{align} \\] has no difference, we just swapped row 1 and 2. We can do the same in matrix for conveince. Also, given \\[ \\P = \\begin{bmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 1 \\\\ \\end{bmatrix} ,\\quad \\A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\\\ \\end{bmatrix} \\] then \\[\\P\\A = \\begin{bmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 1 \\\\ \\end{bmatrix} \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\\\ \\end{bmatrix} = \\begin{bmatrix} 4 & 5 & 6 \\\\ 1 & 2 & 3 \\\\ 7 & 8 & 9 \\\\ \\end{bmatrix}\\] and notice that row 1 and 2 are swapped by the left multiplication of the permutation matrix \\(\\P\\) . Why did it worked? Recall now \\[\\P\\A = \\begin{bmatrix}\\ \\p_1 \\\\ \\p_2 \\\\ \\p_3 \\end{bmatrix}\\A = \\begin{bmatrix}\\p_1\\A \\\\ \\p_2\\A \\\\ \\p_3\\A \\end{bmatrix}\\] We just look at the first row of \\(\\P\\A\\) given by \\(\\p_1\\A\\) which maps to the first row of \\(\\P\\A\\) . \\[\\p_1\\A = 0 \\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix} + 1 \\begin{bmatrix} 4 & 5 & 6 \\end{bmatrix} + 0 \\begin{bmatrix} 7 & 8 & 9 \\end{bmatrix} = \\begin{bmatrix} 4 & 5 & 6 \\end{bmatrix}\\] Then the rest is the same logic: \\[\\p_2\\A = 1 \\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix} + 0 \\begin{bmatrix} 4 & 5 & 6 \\end{bmatrix} + 0 \\begin{bmatrix} 7 & 8 & 9 \\end{bmatrix} = \\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix}\\] \\[\\p_3\\A = 0 \\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix} + 0 \\begin{bmatrix} 4 & 5 & 6 \\end{bmatrix} + 1 \\begin{bmatrix} 7 & 8 & 9 \\end{bmatrix} = \\begin{bmatrix} 7 & 8 & 9 \\end{bmatrix}\\] We now see why through Matrix Multiplication (Left row wise) that the Permutation Matrix works the way it is!","title":"Permutation Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/#references","text":"A First Course in Linear Algebra by Ken Kuttler https://math.stackexchange.com/questions/1634411/why-adding-or-subtracting-linear-equations-finds-their-intersection-point","title":"References"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.02_linear_algebra_row_reduction_preserves_rank/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\e}{\\mathbf{e}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\E}{\\mathbf{E}}\\] Preamble This theorem is important enough to derserve a page of its own. One should note that the column space of a matrix \\(\\A\\) is just the subspace spanned by its columns and row space is just the subspace spanned by its rows. We will give a formal treatment in the next section. For now, we will prove 2 key theorems. Here we prove that row elimination do not alter the linear (in)dependence of the rows and column space. One needs to first realize that any row operation on \\(\\A\\) is equivalent to applying an left multiplcation of elementary matrix \\(\\E\\) on \\(\\A\\) . Row Operations Preserves Row Space and Linear In(Depedence) Given a matrix \\(\\A \\in \\F^{m \\times n}\\) , if one applies row elimination and row operations to the matrix \\(\\A\\) , show that it does not change the row space of \\(\\A\\) , and also preserves the linear (in)dependence of the rows of \\(\\A\\) , that is equivalent to saying that row elimination/operations do not change the dimension of the row space of \\(\\A\\) . We prove this theorem first as it is relatively easier to see and visualize 1 . We first show that row elimination/operations on \\(\\A\\) preserve the row space. That is, if we represent rows of \\(\\A\\) as \\(\\v_1, \\v_2, ..., \\v_m\\) , then it suffices to prove that a row operation \\(\\E\\A\\) preserves the row space: \\[\\textbf{span}(\\v_1, \\v_2, ..., \\v_m) = \\textbf{span}(\\e_1, \\e_2, ..., \\e_m)\\] where \\(\\v_i\\) is the row \\(i\\) of \\(\\A\\) and \\(\\e_i\\) row \\(i\\) of \\(\\E\\) . Let \\(\\v_1,\\ldots,\\v_,\\) denote the rows of \\(A\\) , and let \\(V\\) be the row-space of \\(A\\) . In other words, $$ V=\\text{span}\\,{\\v_1,\\ldots,\\v_m}. $$ Firstly, the easiest type of elementary operations is permutation of rows, which amount to permuting some \\(\\v_j\\) and \\(\\v_k\\) above; such operation will not change the span of \\(\\v_1,\\ldots,\\v_m\\) . Secondly, multiplying a row with a non-zero constant does not change the row space; that is if we multiply any row of \\(\\A\\) by \\(\\lambda\\) , then: \\[\\textbf{span}(\\v_1, \\ldots, \\v_i ,\\v_m) = \\textbf{span}(\\v_1, \\ldots, \\lambda_k\\v_k, \\v_m)\\] Lastly, the row operation amounts to of replacing \\(\\v_k\\) with \\(\\v_k+\\lambda \\v_j\\) . In this case, we can write \\[ \\alpha_1\\v_1+\\cdots+\\alpha_n\\v_m=\\alpha_1\\v_1+\\cdots+\\alpha_{k-1}\\v_{k-1}+\\alpha_k(\\v_k+\\lambda \\v_j)+\\alpha_{k+1}\\v_{k+1}+\\cdots (\\alpha_j-\\alpha_k\\lambda)\\v_j+\\cdots+\\alpha_n\\v_m \\] So every linear combination of \\(\\v_1,\\ldots,\\v_m\\) is also a linear combination of \\(\\v_1,\\ldots,\\v_m\\) with $v_k$ replaced by \\(\\v_k+\\lambda \\v_j\\) . In summary, after doing any elementary operation to \\(v_1,\\ldots,v_n\\) , the span doesn't change. It follows directly that if \\(A\\) and \\(B\\) are row equivalent, since the rows of \\(B\\) can be obtained by elementary operations from the rows of \\(A\\) , the spans of their rows are equal. If \\(A\\) is invertible, then it is row equivalent to \\(I\\) , and so its row space is \\(F^n\\) . Conversely, if the row space of \\(A\\) is \\(F^n\\) , then by writing each of \\(v_1,\\ldots,v_n\\) in terms of the canonical basis, we get a recipe to go from \\(I\\) to \\(A\\) by elementary operations, and so \\(A\\) is invertible. To show that the row operations also preserve the linear (in)depedence, we just need to prove that the dimension of the column space of \\(\\A\\) before and after row operations is the same. Row Operations Preserve Column Space 1 The most important fact is that elementary row operations are realized as multiplication (on the left) by an invertible matrix. So the proof below just suffices to prove that if we have a matrix \\(\\A \\in \\F^{m \\times n}\\) , and if we apply a row operation on \\(\\A\\) as \\(\\E\\A = \\B\\) , then we need a lemma in between to show that if given a matrix \\(\\A\\) , and we do a row operation on \\(\\A\\) as \\(\\E\\A\\) where \\(\\E\\) is naturally invertible, then we suffice to show for the same column indices, \\(a_{i_1},a_{i_2},\\dots,a_{i_k}\\) are linearly independent if and only if \\(b_{i_1},b_{i_2},\\dots,b_{i_k}\\) are linearly independent. This proof is just proving that the same set of linearly independent (or dependent) columns of \\(\\A\\) coincides with the same set (indexed) columns of \\(\\B\\) . Once you know this fact, you can proceed as follows. Suppose \\(A\\) and \\(B\\) are \\(m\\times n\\) and there exists an invertible \\(m\\times m\\) matrix \\(F\\) such that \\(A=FB\\) . Denote by \\(a_1,a_2,\\dots,a_n\\) and \\(b_1,b_2,\\dots,b_n\\) the columns of \\(A\\) and \\(B\\) respectively. Consider indices \\(i_1,i_2,\\dots,i_k\\) such that \\(1\\le i_1<i_2<\\dots<i_k\\le n\\) . Then the columns \\(a_{i_1},a_{i_2},\\dots,a_{i_k}\\) are linearly independent if and only if \\(b_{i_1},b_{i_2},\\dots,b_{i_k}\\) are linearly independent. It's sufficient to prove one implication, because \\(B=F^{-1}A\\) . So, suppose the columns \\(a_{i_1},a_{i_2},\\dots,a_{i_k}\\) are linearly independent and that \\[ \\alpha_1b_{i_1}+\\alpha_2b_{i_2}+\\dots+\\alpha_kb_{i_k}=0 \\] Then we can multiply both sides by \\(F\\) and get \\[ \\alpha_1Fb_{i_1}+\\alpha_2Fb_{i_2}+\\dots+\\alpha_kFb_{i_k}=0 \\] Since \\(Fb_i=a_i\\) , by definition of matrix product, we obtain \\[ \\alpha_1a_{i_1}+\\alpha_2a_{i_2}+\\dots+\\alpha_ka_{i_k}=0 \\] so \\(\\alpha_1=\\alpha_2=\\dots=\\alpha_k=0\\) . In a similar way, we see that a column \\(a_i\\) of \\(A\\) is a linear combination of the columns \\(a_{i_1},a_{i_2},\\dots,a_{i_k}\\) if and only if \\(b_i\\) is a linear combination of \\(b_{i_1},b_{i_2},\\dots,b_{i_k}\\) , with the same coefficients . As a consequence, \\(a_{i_1},a_{i_2},\\dots,a_{i_k}\\) is a basis of the column space of \\(A\\) if and only if \\(b_{i_1},b_{i_2},\\dots,b_{i_k}\\) is a basis of the column space of \\(B\\) . In particular, the column space of \\(A\\) has the same dimension as the column space of \\(B\\) . Therefore \\(A\\) and \\(B\\) have the same column rank (the dimension is the maximum number of linearly independent columns, of course, because the columns are, by definition, generators of the column space). This has other important consequences. When you find a row echelon form \\(U\\) for \\(A\\) , it's easy to see that the pivot columns of \\(U\\) form a basis of the column space of \\(U\\) . Therefore, the columns of \\(A\\) corresponding to the pivot columns form a basis of the column space of \\(A\\) . This provides an algorithm for extracting a basis from the columns of \\(A\\) . Not only this. If \\(U\\) is the reduced row echelon form, we see that a nonpivot column is the linear combination of the pivot columns with lower column index and the coefficients in the nonpivot column are exactly those needed to write it as a linear combination. Thus the same coefficients can be used to express the columns of \\(A\\) corresponding to nonpivot columns as linear combination of the already found basis for the column space of \\(A\\) . Thus the reduced row echelon form of \\(A\\) is unique, because its entries only depend on the linear relations between the columns of \\(A\\) . Elementary row operations also preserve the row rank (dimension of the row space or maximum number of linearly independent rows). This is easier, because the row space is unchanged by elementary row operations. This is obvious if the operation is swapping two rows. If the operation is multiplying a row by a nonzero constant, then the original row is a multiple of the new row, and conversely. If the operation is of the form \\(r_i+kr_j\\) , then \\(r_i=(r_i+kr_j)-kr_j\\) , and conversely. Summary Row Operations do not change null space and row space. For null space \\(\\A\\x = \\0\\) , row eliminations also do not change the set of solutions rank of matrix \\(\\A\\) is the number of pivots after elimination Yes, the Gaussian elimination does not preserve the column space (it does preserve the row space though). However, each time you perform an elementary operation, you basically multiply your original matrix by an invertible matrix. In the language of linear transformations, you act by an isomorphisms (linear invertible operators) and the isomorphisms keep linearly independent columns linearly independent and linearly dependent columns to be linearly dependent. Note that the columns with pivots are linearly independent, and all other columns in the row reduced echelon form can be represented as linear combinations of columns with pivots. Hence the conclusion. Consider matrix \\(\\A = \\begin{bmatrix} \\a_1 \\\\ \\a_2 \\\\ \\vdots \\\\ \\a_m \\end{bmatrix}\\) where \\(\\a_i\\) is the row of \\(\\A\\) . Then one might need to think intuitively why row reduction such as Gaussian Elimination will tell us the number of linearly independent rows by counting all the non-zero rows? First, a toy example, assume that out of \\(m\\) rows, there exist \\(m-2\\) linearly independent rows \\(\\a_1, \\cdots, \\a_{m-2}\\) and the two linearly dependent rows are \\[\\a_{m-1} = \\a_1 + \\cdots + \\a_{m-2} \\quad \\a_m = \\a_1 + \\cdots + \\a_{m-1}\\] We can work out how row operations can kill (zero) out these linearly dependent rows. Firstly, if we kill \\(\\a_{m-1}\\) first by doing the row operation of \\(\\a_{m-1} - (\\a_1 + \\cdots + \\a_{m-2})\\) . Then, \\(\\a_{m}\\) will still be killed even though \\(\\a_{m-1}\\) is reduced to the zero vector because we already know \\(\\a_{m-1} = \\a_1 + \\cdots + \\a_{m-2}\\) and thus \\(\\a_m - \\left[(\\a_1 + \\cdots + a_{m-2}) + (\\a_1 + \\cdots + \\a_{m-2})\\right]\\) . How do we ensure that no other (linearly independent) rows are zeroed out? Suppose any other linearly independent rows can be zeroed out by other rows in \\(\\A\\) , then a contradiction occurred since they are linearly independent. https://math.stackexchange.com/questions/2078943/row-operations-do-not-change-the-dependency-relationships-among-columns https://math.stackexchange.com/questions/354362/why-do-elementary-row-operations-preserve-linear-dependence-between-matrix-colum?rq=1 https://math.stackexchange.com/questions/3760618/how-prove-that-the-elementary-operations-dont-change-the-rank-of-a-matrix https://math.stackexchange.com/questions/3760618/how-prove-that-the-elementary-operations-dont-change-the-rank-of-a-matrix \u21a9 \u21a9","title":"Row Reduction Preserves Rank"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.02_linear_algebra_row_reduction_preserves_rank/#preamble","text":"This theorem is important enough to derserve a page of its own. One should note that the column space of a matrix \\(\\A\\) is just the subspace spanned by its columns and row space is just the subspace spanned by its rows. We will give a formal treatment in the next section. For now, we will prove 2 key theorems. Here we prove that row elimination do not alter the linear (in)dependence of the rows and column space. One needs to first realize that any row operation on \\(\\A\\) is equivalent to applying an left multiplcation of elementary matrix \\(\\E\\) on \\(\\A\\) .","title":"Preamble"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.02_linear_algebra_row_reduction_preserves_rank/#row-operations-preserves-row-space-and-linear-indepedence","text":"Given a matrix \\(\\A \\in \\F^{m \\times n}\\) , if one applies row elimination and row operations to the matrix \\(\\A\\) , show that it does not change the row space of \\(\\A\\) , and also preserves the linear (in)dependence of the rows of \\(\\A\\) , that is equivalent to saying that row elimination/operations do not change the dimension of the row space of \\(\\A\\) . We prove this theorem first as it is relatively easier to see and visualize 1 . We first show that row elimination/operations on \\(\\A\\) preserve the row space. That is, if we represent rows of \\(\\A\\) as \\(\\v_1, \\v_2, ..., \\v_m\\) , then it suffices to prove that a row operation \\(\\E\\A\\) preserves the row space: \\[\\textbf{span}(\\v_1, \\v_2, ..., \\v_m) = \\textbf{span}(\\e_1, \\e_2, ..., \\e_m)\\] where \\(\\v_i\\) is the row \\(i\\) of \\(\\A\\) and \\(\\e_i\\) row \\(i\\) of \\(\\E\\) . Let \\(\\v_1,\\ldots,\\v_,\\) denote the rows of \\(A\\) , and let \\(V\\) be the row-space of \\(A\\) . In other words, $$ V=\\text{span}\\,{\\v_1,\\ldots,\\v_m}. $$ Firstly, the easiest type of elementary operations is permutation of rows, which amount to permuting some \\(\\v_j\\) and \\(\\v_k\\) above; such operation will not change the span of \\(\\v_1,\\ldots,\\v_m\\) . Secondly, multiplying a row with a non-zero constant does not change the row space; that is if we multiply any row of \\(\\A\\) by \\(\\lambda\\) , then: \\[\\textbf{span}(\\v_1, \\ldots, \\v_i ,\\v_m) = \\textbf{span}(\\v_1, \\ldots, \\lambda_k\\v_k, \\v_m)\\] Lastly, the row operation amounts to of replacing \\(\\v_k\\) with \\(\\v_k+\\lambda \\v_j\\) . In this case, we can write \\[ \\alpha_1\\v_1+\\cdots+\\alpha_n\\v_m=\\alpha_1\\v_1+\\cdots+\\alpha_{k-1}\\v_{k-1}+\\alpha_k(\\v_k+\\lambda \\v_j)+\\alpha_{k+1}\\v_{k+1}+\\cdots (\\alpha_j-\\alpha_k\\lambda)\\v_j+\\cdots+\\alpha_n\\v_m \\] So every linear combination of \\(\\v_1,\\ldots,\\v_m\\) is also a linear combination of \\(\\v_1,\\ldots,\\v_m\\) with $v_k$ replaced by \\(\\v_k+\\lambda \\v_j\\) . In summary, after doing any elementary operation to \\(v_1,\\ldots,v_n\\) , the span doesn't change. It follows directly that if \\(A\\) and \\(B\\) are row equivalent, since the rows of \\(B\\) can be obtained by elementary operations from the rows of \\(A\\) , the spans of their rows are equal. If \\(A\\) is invertible, then it is row equivalent to \\(I\\) , and so its row space is \\(F^n\\) . Conversely, if the row space of \\(A\\) is \\(F^n\\) , then by writing each of \\(v_1,\\ldots,v_n\\) in terms of the canonical basis, we get a recipe to go from \\(I\\) to \\(A\\) by elementary operations, and so \\(A\\) is invertible. To show that the row operations also preserve the linear (in)depedence, we just need to prove that the dimension of the column space of \\(\\A\\) before and after row operations is the same.","title":"Row Operations Preserves Row Space and Linear In(Depedence)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.02_linear_algebra_row_reduction_preserves_rank/#row-operations-preserve-column-space1","text":"The most important fact is that elementary row operations are realized as multiplication (on the left) by an invertible matrix. So the proof below just suffices to prove that if we have a matrix \\(\\A \\in \\F^{m \\times n}\\) , and if we apply a row operation on \\(\\A\\) as \\(\\E\\A = \\B\\) , then we need a lemma in between to show that if given a matrix \\(\\A\\) , and we do a row operation on \\(\\A\\) as \\(\\E\\A\\) where \\(\\E\\) is naturally invertible, then we suffice to show for the same column indices, \\(a_{i_1},a_{i_2},\\dots,a_{i_k}\\) are linearly independent if and only if \\(b_{i_1},b_{i_2},\\dots,b_{i_k}\\) are linearly independent. This proof is just proving that the same set of linearly independent (or dependent) columns of \\(\\A\\) coincides with the same set (indexed) columns of \\(\\B\\) . Once you know this fact, you can proceed as follows. Suppose \\(A\\) and \\(B\\) are \\(m\\times n\\) and there exists an invertible \\(m\\times m\\) matrix \\(F\\) such that \\(A=FB\\) . Denote by \\(a_1,a_2,\\dots,a_n\\) and \\(b_1,b_2,\\dots,b_n\\) the columns of \\(A\\) and \\(B\\) respectively. Consider indices \\(i_1,i_2,\\dots,i_k\\) such that \\(1\\le i_1<i_2<\\dots<i_k\\le n\\) . Then the columns \\(a_{i_1},a_{i_2},\\dots,a_{i_k}\\) are linearly independent if and only if \\(b_{i_1},b_{i_2},\\dots,b_{i_k}\\) are linearly independent. It's sufficient to prove one implication, because \\(B=F^{-1}A\\) . So, suppose the columns \\(a_{i_1},a_{i_2},\\dots,a_{i_k}\\) are linearly independent and that \\[ \\alpha_1b_{i_1}+\\alpha_2b_{i_2}+\\dots+\\alpha_kb_{i_k}=0 \\] Then we can multiply both sides by \\(F\\) and get \\[ \\alpha_1Fb_{i_1}+\\alpha_2Fb_{i_2}+\\dots+\\alpha_kFb_{i_k}=0 \\] Since \\(Fb_i=a_i\\) , by definition of matrix product, we obtain \\[ \\alpha_1a_{i_1}+\\alpha_2a_{i_2}+\\dots+\\alpha_ka_{i_k}=0 \\] so \\(\\alpha_1=\\alpha_2=\\dots=\\alpha_k=0\\) . In a similar way, we see that a column \\(a_i\\) of \\(A\\) is a linear combination of the columns \\(a_{i_1},a_{i_2},\\dots,a_{i_k}\\) if and only if \\(b_i\\) is a linear combination of \\(b_{i_1},b_{i_2},\\dots,b_{i_k}\\) , with the same coefficients . As a consequence, \\(a_{i_1},a_{i_2},\\dots,a_{i_k}\\) is a basis of the column space of \\(A\\) if and only if \\(b_{i_1},b_{i_2},\\dots,b_{i_k}\\) is a basis of the column space of \\(B\\) . In particular, the column space of \\(A\\) has the same dimension as the column space of \\(B\\) . Therefore \\(A\\) and \\(B\\) have the same column rank (the dimension is the maximum number of linearly independent columns, of course, because the columns are, by definition, generators of the column space). This has other important consequences. When you find a row echelon form \\(U\\) for \\(A\\) , it's easy to see that the pivot columns of \\(U\\) form a basis of the column space of \\(U\\) . Therefore, the columns of \\(A\\) corresponding to the pivot columns form a basis of the column space of \\(A\\) . This provides an algorithm for extracting a basis from the columns of \\(A\\) . Not only this. If \\(U\\) is the reduced row echelon form, we see that a nonpivot column is the linear combination of the pivot columns with lower column index and the coefficients in the nonpivot column are exactly those needed to write it as a linear combination. Thus the same coefficients can be used to express the columns of \\(A\\) corresponding to nonpivot columns as linear combination of the already found basis for the column space of \\(A\\) . Thus the reduced row echelon form of \\(A\\) is unique, because its entries only depend on the linear relations between the columns of \\(A\\) . Elementary row operations also preserve the row rank (dimension of the row space or maximum number of linearly independent rows). This is easier, because the row space is unchanged by elementary row operations. This is obvious if the operation is swapping two rows. If the operation is multiplying a row by a nonzero constant, then the original row is a multiple of the new row, and conversely. If the operation is of the form \\(r_i+kr_j\\) , then \\(r_i=(r_i+kr_j)-kr_j\\) , and conversely.","title":"Row Operations Preserve Column Space1"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.02_linear_algebra_row_reduction_preserves_rank/#summary","text":"Row Operations do not change null space and row space. For null space \\(\\A\\x = \\0\\) , row eliminations also do not change the set of solutions rank of matrix \\(\\A\\) is the number of pivots after elimination Yes, the Gaussian elimination does not preserve the column space (it does preserve the row space though). However, each time you perform an elementary operation, you basically multiply your original matrix by an invertible matrix. In the language of linear transformations, you act by an isomorphisms (linear invertible operators) and the isomorphisms keep linearly independent columns linearly independent and linearly dependent columns to be linearly dependent. Note that the columns with pivots are linearly independent, and all other columns in the row reduced echelon form can be represented as linear combinations of columns with pivots. Hence the conclusion. Consider matrix \\(\\A = \\begin{bmatrix} \\a_1 \\\\ \\a_2 \\\\ \\vdots \\\\ \\a_m \\end{bmatrix}\\) where \\(\\a_i\\) is the row of \\(\\A\\) . Then one might need to think intuitively why row reduction such as Gaussian Elimination will tell us the number of linearly independent rows by counting all the non-zero rows? First, a toy example, assume that out of \\(m\\) rows, there exist \\(m-2\\) linearly independent rows \\(\\a_1, \\cdots, \\a_{m-2}\\) and the two linearly dependent rows are \\[\\a_{m-1} = \\a_1 + \\cdots + \\a_{m-2} \\quad \\a_m = \\a_1 + \\cdots + \\a_{m-1}\\] We can work out how row operations can kill (zero) out these linearly dependent rows. Firstly, if we kill \\(\\a_{m-1}\\) first by doing the row operation of \\(\\a_{m-1} - (\\a_1 + \\cdots + \\a_{m-2})\\) . Then, \\(\\a_{m}\\) will still be killed even though \\(\\a_{m-1}\\) is reduced to the zero vector because we already know \\(\\a_{m-1} = \\a_1 + \\cdots + \\a_{m-2}\\) and thus \\(\\a_m - \\left[(\\a_1 + \\cdots + a_{m-2}) + (\\a_1 + \\cdots + \\a_{m-2})\\right]\\) . How do we ensure that no other (linearly independent) rows are zeroed out? Suppose any other linearly independent rows can be zeroed out by other rows in \\(\\A\\) , then a contradiction occurred since they are linearly independent. https://math.stackexchange.com/questions/2078943/row-operations-do-not-change-the-dependency-relationships-among-columns https://math.stackexchange.com/questions/354362/why-do-elementary-row-operations-preserve-linear-dependence-between-matrix-colum?rq=1 https://math.stackexchange.com/questions/3760618/how-prove-that-the-elementary-operations-dont-change-the-rank-of-a-matrix https://math.stackexchange.com/questions/3760618/how-prove-that-the-elementary-operations-dont-change-the-rank-of-a-matrix \u21a9 \u21a9","title":"Summary"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\r}{\\mathbf{r}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\] Preamble Both Professor Mike and Gilbert started off with this statement: The entirety and gist of the matrix space can be summarized as answering two key questions: Given a matrix \\(\\A \\in \\F^{m \\times n}\\) and vector \\(\\b \\in \\F^{m}\\) and \\(\\0 \\in \\F^{m}\\) , then can we find a vector \\(\\x \\in \\F^{n}\\) such that \\(\\A\\x = \\b\\) \\(\\A\\x = \\0\\) From the matrix-multiplication section, we can easily re-interpret the question as: \\(\\A\\x=\\b\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\b\\) ? \\(\\A\\x=\\0\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\0\\) assuming \\(\\x \\neq \\0\\) . Row Space Algebraic Definition (Row Space) Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, with row vectors \\(\\r_1, \\r_2, \\cdots, \\r_m\\) . Note that a linear combination of these vectors is any vector of the form \\[c_1 \\r_1 + c_2 \\r_2 + \\cdots + c_m \\r_m\\] where \\(c_i\\) are scalars; Then the set of all possible linear combinations of \\(\\r_1, \\r_2, \\cdots, \\r_m\\) is called the row space of \\(\\A\\) ; In other words, the row space of \\(\\A\\) is the linear span of the vectors \\(\\r_1, \\r_2, \\cdots, \\r_m\\) . Notation (Row Space) The row space of a matrix is denoted as \\(R(\\A)\\) , which is the space spanned by all rows of the matrix \\(\\A\\) . Note in particular that the row space \\(R(\\A)\\) resides in the \\(\\F^{n}\\) space. Algebraic Definition (Row Rank) The row rank of \\(\\A\\) is the dimension of the row space of \\(\\A\\) . Definition (Full Row Rank) A matrix \\(\\A \\in \\F^{m \\times n}\\) is full row rank if and only if \\(\\rank(A) = m\\) . The row space spans all of \\(\\F^{m}\\) and is a basis of \\(\\F^{m}\\) , else it is a \\(r\\) -dimensional subspace embedded in \\(\\F^{m}\\) . Theorem (Row Reduction Preserves Row Space) This theorem has been proved in the section 05.02_linear_algebra_row_elimination_preserves_row_column_spaces_dependency . Theorem (Basis For Row Space) The proof is detailed in pp.127-128 of A modern introduction to linear algebra henry ricardo . Algorithm (Basis For Row Space) Note that elementary row operations do not affect the row space by our previous theorem, consequently, row reduction can be used to find a basis for the row space. The pseudo-algorithm can be detailed below: Calculate RREF of the matrix \\(\\A\\) . The pivot rows (non-zero) rows form a basis of the row space of \\(\\A\\) . Theorem (Counting Row Rank) As a consequence from the previous algorithm, the non-zero rows of RREF of \\(\\A\\) is the row rank of \\(\\A\\) . Theorem (Row Space of \\(\\mathbf{A}\\) and \\(\\mathbf{A}^\\top\\mathbf{A}\\) ) \\(\\mathbf{A}\\) and \\(\\mathbf{A}^\\top\\mathbf{A}\\) have the same row space. Applications in Machine Learning The author Mike mentioned in Linear Algebra: Theory, Intuition, Code, 2021. (pp. 214) that \\(R(\\A) = R(\\A^\\top\\A)\\) is an example of dimensionality reduction where both matrices have the same row space, but \\(\\A^\\top\\A\\) might be a much smaller matrix and hence computationally more efficient.","title":"Row Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/#preamble","text":"Both Professor Mike and Gilbert started off with this statement: The entirety and gist of the matrix space can be summarized as answering two key questions: Given a matrix \\(\\A \\in \\F^{m \\times n}\\) and vector \\(\\b \\in \\F^{m}\\) and \\(\\0 \\in \\F^{m}\\) , then can we find a vector \\(\\x \\in \\F^{n}\\) such that \\(\\A\\x = \\b\\) \\(\\A\\x = \\0\\) From the matrix-multiplication section, we can easily re-interpret the question as: \\(\\A\\x=\\b\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\b\\) ? \\(\\A\\x=\\0\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\0\\) assuming \\(\\x \\neq \\0\\) .","title":"Preamble"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/#row-space","text":"","title":"Row Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/#algebraic-definition-row-space","text":"Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, with row vectors \\(\\r_1, \\r_2, \\cdots, \\r_m\\) . Note that a linear combination of these vectors is any vector of the form \\[c_1 \\r_1 + c_2 \\r_2 + \\cdots + c_m \\r_m\\] where \\(c_i\\) are scalars; Then the set of all possible linear combinations of \\(\\r_1, \\r_2, \\cdots, \\r_m\\) is called the row space of \\(\\A\\) ; In other words, the row space of \\(\\A\\) is the linear span of the vectors \\(\\r_1, \\r_2, \\cdots, \\r_m\\) .","title":"Algebraic Definition (Row Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/#notation-row-space","text":"The row space of a matrix is denoted as \\(R(\\A)\\) , which is the space spanned by all rows of the matrix \\(\\A\\) . Note in particular that the row space \\(R(\\A)\\) resides in the \\(\\F^{n}\\) space.","title":"Notation (Row Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/#algebraic-definition-row-rank","text":"The row rank of \\(\\A\\) is the dimension of the row space of \\(\\A\\) .","title":"Algebraic Definition (Row Rank)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/#definition-full-row-rank","text":"A matrix \\(\\A \\in \\F^{m \\times n}\\) is full row rank if and only if \\(\\rank(A) = m\\) . The row space spans all of \\(\\F^{m}\\) and is a basis of \\(\\F^{m}\\) , else it is a \\(r\\) -dimensional subspace embedded in \\(\\F^{m}\\) .","title":"Definition (Full Row Rank)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/#theorem-row-reduction-preserves-row-space","text":"This theorem has been proved in the section 05.02_linear_algebra_row_elimination_preserves_row_column_spaces_dependency .","title":"Theorem (Row Reduction Preserves Row Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/#theorem-basis-for-row-space","text":"The proof is detailed in pp.127-128 of A modern introduction to linear algebra henry ricardo .","title":"Theorem (Basis For Row Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/#algorithm-basis-for-row-space","text":"Note that elementary row operations do not affect the row space by our previous theorem, consequently, row reduction can be used to find a basis for the row space. The pseudo-algorithm can be detailed below: Calculate RREF of the matrix \\(\\A\\) . The pivot rows (non-zero) rows form a basis of the row space of \\(\\A\\) .","title":"Algorithm (Basis For Row Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/#theorem-counting-row-rank","text":"As a consequence from the previous algorithm, the non-zero rows of RREF of \\(\\A\\) is the row rank of \\(\\A\\) .","title":"Theorem (Counting Row Rank)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/#theorem-row-space-of-mathbfa-and-mathbfatopmathbfa","text":"\\(\\mathbf{A}\\) and \\(\\mathbf{A}^\\top\\mathbf{A}\\) have the same row space.","title":"Theorem (Row Space of \\(\\mathbf{A}\\) and \\(\\mathbf{A}^\\top\\mathbf{A}\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/#applications-in-machine-learning","text":"The author Mike mentioned in Linear Algebra: Theory, Intuition, Code, 2021. (pp. 214) that \\(R(\\A) = R(\\A^\\top\\A)\\) is an example of dimensionality reduction where both matrices have the same row space, but \\(\\A^\\top\\A\\) might be a much smaller matrix and hence computationally more efficient.","title":"Applications in Machine Learning"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\] Preamble Both Professor Mike and Gilbert started off with this statement: The entirety and gist of the matrix space can be summarized as answering two key questions: Given a matrix \\(\\A \\in \\F^{m \\times n}\\) and vector \\(\\b \\in \\F^{m}\\) and \\(\\0 \\in \\F^{m}\\) , then can we find a vector \\(\\x \\in \\F^{n}\\) such that \\( \\(\\A\\x = \\b\\) \\) \\( \\(\\A\\x = \\0\\) \\) From the matrix-multiplication section, we can easily re-interpret the question as: \\(\\A\\x=\\b\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\b\\) ? \\(\\A\\x=\\0\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\0\\) assuming \\(\\x \\neq \\0\\) . Column Space Motivation We often frame our Machine Learning problems into a linear system of equations of the form \\(\\A\\x=\\b\\) . Not every linear system of equation is easily solvable, and has a solution \\(\\x\\) exists if and only if \\(\\b\\) belongs to the column space of \\(\\A\\) . Why so? Recall in the section linear algebra and matrix multiplication the following (if you forgot go read up): A column space of a matrix \\(\\A\\) is just the set of linear combination of the columns of \\(\\A\\) , and is a subspace. We will go through it in more details, but for now, I want to introduce this idea first. As a consequence of the example prior, one should realize three things: \\(\\A\\x\\) is a combination of the columns of the matrix \\(\\A\\) . \\(\\A\\x = \\b\\) may not always have a solution \\(\\x\\) . If \\(\\A\\x = \\b\\) has a solution \\(\\x\\) , then the product \\(\\b\\) must be a linear combination of the columns of \\(\\A\\) . This has important consequences later on. For now, just know that if \\(\\A\\x = \\b\\) has a solution, then \\(\\b\\) resides in the column space of \\(\\A\\) . Algebraic Definition (Column Space) Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, with column vectors \\(\\c_1, \\c_2, \\cdots, \\c_n\\) . Note that a linear combination of these vectors is any vector of the form \\[\\lambda_1 \\mathbf{c}_1 + \\lambda_2 \\mathbf{c}_2 + \\cdots + \\lambda_n \\mathbf{a}_n\\] where \\(\\lambda_i\\) are scalars; Then the set of all possible linear combinations of \\(\\c_1, \\c_2, \\cdots, \\c_n\\) is called the column space of \\(\\A\\) ; In other words, the column space of \\(\\A\\) is the linear span of the vectors \\(\\c_1, \\c_2, \\cdots, \\c_n\\) . And as noted in the right multiplication method in the section matrix-vector multiplication , any linear combination of the column vectors of a matrix \\(\\A\\) can be written as the product of \\(\\A\\) with a column vector where the column vectors hold the coefficients of the linear combination: \\[ \\begin{array} {rcl} \\A \\begin{bmatrix} c_1 \\\\ \\vdots \\\\ c_n \\end{bmatrix} & = & \\begin{bmatrix} a_{11} & \\cdots & a_{1n} \\\\ \\vdots & \\ddots & \\vdots \\\\ a_{m1} & \\cdots & a_{mn} \\end{bmatrix} \\begin{bmatrix} c_1 \\\\ \\vdots \\\\ c_n \\end{bmatrix} = \\begin{bmatrix} c_1 a_{11} + \\cdots + c_{n} a_{1n} \\\\ \\vdots \\\\ c_{1} a_{m1} + \\cdots + c_{n} a_{mn} \\end{bmatrix} = c_1 \\begin{bmatrix} a_{11} \\\\ \\vdots \\\\ a_{m1} \\end{bmatrix} + \\cdots + c_n \\begin{bmatrix} a_{1n} \\\\ \\vdots \\\\ a_{mn} \\end{bmatrix} \\\\ & = & c_1 \\mathbf{v}_1 + \\cdots + c_n \\mathbf{v}_n \\end{array} \\] Therefore, the column space of \\(\\A\\) consists of all possible products \\(\\A\\x\\) for \\(\\x \\in \\F^n\\) . This is the same as the image or range of the corresponding matrix transformation in which we will learn more on in the linear transformation chapter. Notation (Column Space) The column space of a matrix is denoted as \\(C(\\A)\\) , which is the space spanned by all columns of the matrix \\(\\A\\) . Note that the column space \\(C(\\A)\\) resides in the \\(\\F^{m}\\) space. Example (Column Space) If \\(A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 2 & 0 \\end{bmatrix}\\) , then the column vectors are \\(\\a_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix} \\quad \\a_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0\\end{bmatrix}\\) . A linear combination of \\(\\a_1, \\a_2\\) is any vector of the form \\[c_1 \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix} + c_2 \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} c_1 \\\\ c_2 \\\\ 2c_1 \\end{bmatrix}\\] The set of all such vectors is the column space of \\(\\A\\) and in this case, the column space is precisely the set of vectors \\((x, y, z) \\in \\R^3\\) satisfying the equation \\(z=2x\\) using Cartesian coordinates, this set is a plane through the origin in three-dimensional space. Theorem (Solvable Solutions) A system of \\(m\\) linear equations in \\(n\\) unknowns \\(\\A\\x = \\b\\) has a solution if and only if the vector \\(\\b\\) can be expressed as a linear combination of the columns of \\(\\A\\) . In other words, the system is solvable if and only if \\(\\b \\in \\textbf{Col Space}(\\A)\\) . Proof can be found in pp.125-126 A modern introduction to linear algebra by Henry Ricardo . Algebraic Definition (Column Rank) The column rank of \\(\\A\\) is the dimension of the column space of \\(\\A\\) . In other words, the column rank of \\(\\A\\) corresponds to the largest number vectors that can form a linearly indepedent set in the columns of \\(\\A\\) . This interpretation follows because the definition of dimension of a column space means given a vector space \\(V\\) which is our column space spanned by the columns of \\(\\A\\) , the dimension of the column space is the cardinality of the basis \\(\\B\\) of \\(V\\) ; and note that any basis \\(\\B\\) of \\(V\\) (our column space) is a linearly independent set which also spans \\(V\\) . So both definition is equivalent. Full Column Rank A matrix \\(\\A \\in \\F^{m \\times n}\\) is full column rank if and only if \\(\\rank(A) = n\\) . Thus, if the rank of the matrix \\(\\A\\) is \\(r = n\\) , then the column space spans all of \\(\\F^{n}\\) and is a basis of \\(\\F^{n}\\) , else it is a \\(r\\) -dimensional subspace embedded in \\(\\F^{n}\\) . Lemma (Row Operations preserves Linear Dependency of Column Space) Row operations apparently change the column space but the important part is that it preserves the column rank of a matrix. We first start off by proving the lemma to show that the columns of two row equivalent matrices satisfy the same linear dependence relations and subsequently use this to determine a basis for the column space. If an \\(m \\times n\\) matrix \\(\\A\\) with columns \\(\\a_1, \\a_2, ..., \\a_n\\) is row equivalent to matrix \\(\\B\\) with columns \\(\\b_1, \\b_2, ..., \\b_n\\) then \\[ c_1\\a_1 + c_2\\a_2 + ... + \\c_n\\a_n = \\0 \\] if and only if \\[ c_1\\b_1 + c_2\\b_2 + ... + \\c_n\\b_n = \\0 \\] Proof (Row Operations preserves Linear Dependency of Column Space) Suppose \\(\\A\\) and \\(\\B\\) are row equivalent matrices. Then we know that both have the same solution space (i.e. \\(\\A\\x=\\0\\) iff \\(\\B\\x=\\0\\) ). Denote a vector \\(\\c = \\begin{bmatrix}c_1 \\\\ c_2 \\\\ \\vdots \\\\ c_n \\end{bmatrix}\\) then we see that \\(\\A\\c=\\0\\) iff \\(\\B\\c=\\0\\) and so we see that \\[ c_1\\a_1 + c_2\\a_2 + ... + \\c_n\\a_n = \\0 \\] if and only if \\[ c_1\\b_1 + c_2\\b_2 + ... + \\c_n\\b_n = \\0 \\] Corollary (Row Operations preserves Order Linear Dependency of Column Space) As a corollary to the lemma, we note that for two row equivalent matrices \\(\\A\\) and \\(\\B\\) , the same set of linearly (in)dependen columns in \\(\\A\\) corresponds to the same set of linearly (in)dependent columns in \\(\\B\\) . Theorem (Basis For Column Space) If \\(\\A\\) is an \\(m \\times n\\) matrix and the pivots of \\(rref(\\A)\\) occur in columns \\(i_1, i_2, \\ldots, i_k\\) where \\(\\{i_1, i_2, \\ldots, i_k\\} \\subseteq \\{1, 2, \\ldots, n\\}\\) , then columns \\(i_1, i_2, \\ldots, i_k\\) of \\(\\A\\) form a basis for the column space of \\(\\A\\) . The proof is detailed in pp.130 of A modern introduction to linear algebra henry ricardo . Algorithm (Basis For Column Space) Calculate RREF of the matrix \\(\\A\\) . The pivot rows (non-zero) columns form a basis of the column space of \\(\\A\\) . Theorem (Column Space of \\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\) ) \\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\) have the same column space. Proof (Column Space of \\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\) ) We first write \\(\\B = \\A\\A^\\top\\) and use the method that if \\(M \\subseteq N\\) and \\(N \\subseteq M\\) , then \\(N=M\\) to prove this. We first show that \\(C(\\B) \\subseteq C(\\A)\\) . The column space \\(C(\\A) = \\text{span}(\\a_1, \\a_2, ..., \\a_n) \\in \\F^{m}\\) and \\(C(\\B) = \\text{span}(\\b_1, \\b_2, ..., \\b_m)\\) . We note that by the right matrix multiplication , each column of \\(\\B = \\A\\A^\\top\\) is a linear combination of the columns of the left matrix \\(\\A\\) . That is to say, we can represent each column in \\(\\B\\) as \\(\\b_i = \\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_n \\a_n\\) . Consequently, by definition, any column from \\(\\B\\) is an element of \\(\\text{span}(\\a_1, ..., \\a_n)\\) , and hence in the column space \\(C(\\A)\\) . Thus, for any element in \\(C(\\B)\\) , this element must be in \\(C(\\A)\\) , and thus \\(C(\\B) \\subseteq C(\\A)\\) . We then show that \\(C(\\A) \\subseteq C(\\B)\\) . Take any element from \\(C(\\A)\\) , and recall that \\(C(\\B) = \\text{span}(\\b_1, \\b_2, ..., \\b_m) = c_1 \\b_1 + c_2 \\b_2 + \\cdots + c_m \\b_m = c_1 (\\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_m \\a_m) + c_2 (\\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_m \\a_m) + ... + c_2 (\\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_m \\a_m) = d_1\\a_1 + d_2\\a_2 + ... + d_m \\a_m\\) for some \\(d_i \\in \\F\\) . Then any element taken from the column space of \\(\\A\\) is a linear combination of \\(\\a_1, ..., \\a_m\\) ... What can we tell? We cannot tell anything since if \\(n > m\\) , then it may be the case that an element from \\(C(\\A)\\) may not cover. The \"Augment-Rank\" Algorithm to determine membership of Column Space Given a set of vectors \\(S = \\{\\v_1, \\v_2, ..., \\v_n\\}\\) , and a vector \\(\\w\\) , deduce if \\(\\w \\in \\textbf{span}(S)\\) . Assume \\(\\v_i \\in \\R^{m}\\) and \\(\\w \\in \\R^{m}\\) . Construct a matrix \\(\\mathbf{S} = \\begin{bmatrix} \\v_1 & \\v_2 & \\cdots & \\v_m \\end{bmatrix}_{m \\times n}\\) where \\(\\mathbf{S} \\in \\R^{m \\times n}\\) . Compute the rank of \\(\\mathbf{S}\\) and call it \\(s_1\\) . Horizontally concatenate \\(\\mathbf{S}\\) and \\(\\w\\) to get \\(\\mathbf{S}_w = \\mathbf{S} \\cup \\w\\) . Compute rank of \\(\\mathbf{S}_w\\) to be \\(s_2\\) . Then: If \\(s_1 = s_2\\) , this means that column space of \\(\\mathbf{S}\\) equals to the column space of \\(\\mathbf{S}_w\\) , and thus \\(\\w\\) did not alter the column space of \\(\\mathbf{S}\\) , which means \\(\\w\\) must be part of the column space of \\(\\mathbf{S}\\) , and thus in the span of \\(S\\) . If \\(s_2 > s_1\\) , then \\(\\w \\not\\in S\\) because if it is, the column space of \\(\\mathbf{S}_w\\) should not change. We can easily use this algorithm to check if a vector \\(\\w\\) is in the column space of a matrix \\(\\A\\) by setting \\(S\\) to be the set that contains all the columns of \\(\\A\\) . Geometric Intuition Mike mentioned on Linear Algebra: Theory, Intuition, Code, 2021. (pp. 211) that we can think of the above cases geometrically. In the first case where \\(s_1 = s_2\\) , the rank is the same, this means the vector \\(\\w\\) is in the column space of \\(\\A\\) . This makes sense because when we add the new vector to the set, and yet the rank (dimension) did not change, this coincides with the idea of vector \\(\\w\\) sitting somewhere in the column space of \\(\\A\\) , and hence no new geometric directions are obatined by including this vector . In the second case where \\(s_2 > s_1\\) however, if v is outside the column space, then it points off in some other geometric dimension that is not spanned by the column space; hence, B has one extra geometric dimension not contained in A, and thus the rank is one higher. In the image below, we denote \\(C(\\A)\\) as the 1d-subspace in red, then vector \\(\\v\\) is apparently lying in the 1d-subspace, and hence a member of \\(C(\\A)\\) , then \\(\\w\\) , is slightly pointing to a different direction, and hence not in the column space of \\(\\A\\) . Fig; Column Space of A; By Hongnan G. Corollary If \\(\\A\\) is now a full ranked square matrix \\(m \\times m\\) , which means rank of \\(\\A\\) is \\(m\\) , then any vector \\(\\w \\in \\R^{m}\\) will be in the column space of \\(\\A\\) since the column space of \\(\\A\\) is actually a basis of the ambient subspace \\(\\F^{m}\\) . Visualizing Column Space Courtesy of Macro Analyst's linear algebra with python . import matplotlib.pyplot as plt import numpy as np from mpl_toolkits.mplot3d import Axes3D import scipy as sp import scipy.linalg import sympy as sy sy . init_printing () Consider two matrix with \\[\\A = \\begin{bmatrix}1 & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\end{bmatrix} ,\\quad \\B = \\begin{bmatrix}3 & -1 \\\\ 2 & 4 \\\\ -1 & 1 \\end{bmatrix}\\] Then the column space \\(C(\\A)\\) is a 2d-plane given by \\[\\text{plane}(C(\\A)) = \\0 + s\\left[\\matrix{1\\cr 0\\cr 0}\\right] + t\\left[\\matrix{0\\cr 1\\cr 0}\\right]\\] and the column space \\(C(\\B)\\) is a 2d-plane given by \\[\\text{plane}(C(\\B)) = \\0 + s\\left[\\matrix{3\\cr 2\\cr -1}\\right] + t\\left[\\matrix{-1\\cr 4\\cr 1}\\right]\\] fig = plt . figure ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = '3d' ) s = np . linspace ( - 2 , 2 , 20 ) t = np . linspace ( - 2 , 2 , 20 ) S , T = np . meshgrid ( s , t ) X = 3 * S - T Y = 2 * S + 4 * T Z = - S + T ax . plot_wireframe ( X , Y , Z , linewidth = .5 , color = 'r' ) s = np . linspace ( - 10 , 10 , 20 ) t = np . linspace ( - 10 , 10 , 20 ) S , T = np . meshgrid ( s , t ) X = S Y = T Z = np . zeros ( S . shape ) ax . plot_wireframe ( X , Y , Z , linewidth = .5 , color = 'k' ) ax . view_init ( elev = 14 , azim = 58 )","title":"Column Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#preamble","text":"Both Professor Mike and Gilbert started off with this statement: The entirety and gist of the matrix space can be summarized as answering two key questions: Given a matrix \\(\\A \\in \\F^{m \\times n}\\) and vector \\(\\b \\in \\F^{m}\\) and \\(\\0 \\in \\F^{m}\\) , then can we find a vector \\(\\x \\in \\F^{n}\\) such that \\( \\(\\A\\x = \\b\\) \\) \\( \\(\\A\\x = \\0\\) \\) From the matrix-multiplication section, we can easily re-interpret the question as: \\(\\A\\x=\\b\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\b\\) ? \\(\\A\\x=\\0\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\0\\) assuming \\(\\x \\neq \\0\\) .","title":"Preamble"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#column-space","text":"","title":"Column Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#motivation","text":"We often frame our Machine Learning problems into a linear system of equations of the form \\(\\A\\x=\\b\\) . Not every linear system of equation is easily solvable, and has a solution \\(\\x\\) exists if and only if \\(\\b\\) belongs to the column space of \\(\\A\\) . Why so? Recall in the section linear algebra and matrix multiplication the following (if you forgot go read up): A column space of a matrix \\(\\A\\) is just the set of linear combination of the columns of \\(\\A\\) , and is a subspace. We will go through it in more details, but for now, I want to introduce this idea first. As a consequence of the example prior, one should realize three things: \\(\\A\\x\\) is a combination of the columns of the matrix \\(\\A\\) . \\(\\A\\x = \\b\\) may not always have a solution \\(\\x\\) . If \\(\\A\\x = \\b\\) has a solution \\(\\x\\) , then the product \\(\\b\\) must be a linear combination of the columns of \\(\\A\\) . This has important consequences later on. For now, just know that if \\(\\A\\x = \\b\\) has a solution, then \\(\\b\\) resides in the column space of \\(\\A\\) .","title":"Motivation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#algebraic-definition-column-space","text":"Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, with column vectors \\(\\c_1, \\c_2, \\cdots, \\c_n\\) . Note that a linear combination of these vectors is any vector of the form \\[\\lambda_1 \\mathbf{c}_1 + \\lambda_2 \\mathbf{c}_2 + \\cdots + \\lambda_n \\mathbf{a}_n\\] where \\(\\lambda_i\\) are scalars; Then the set of all possible linear combinations of \\(\\c_1, \\c_2, \\cdots, \\c_n\\) is called the column space of \\(\\A\\) ; In other words, the column space of \\(\\A\\) is the linear span of the vectors \\(\\c_1, \\c_2, \\cdots, \\c_n\\) . And as noted in the right multiplication method in the section matrix-vector multiplication , any linear combination of the column vectors of a matrix \\(\\A\\) can be written as the product of \\(\\A\\) with a column vector where the column vectors hold the coefficients of the linear combination: \\[ \\begin{array} {rcl} \\A \\begin{bmatrix} c_1 \\\\ \\vdots \\\\ c_n \\end{bmatrix} & = & \\begin{bmatrix} a_{11} & \\cdots & a_{1n} \\\\ \\vdots & \\ddots & \\vdots \\\\ a_{m1} & \\cdots & a_{mn} \\end{bmatrix} \\begin{bmatrix} c_1 \\\\ \\vdots \\\\ c_n \\end{bmatrix} = \\begin{bmatrix} c_1 a_{11} + \\cdots + c_{n} a_{1n} \\\\ \\vdots \\\\ c_{1} a_{m1} + \\cdots + c_{n} a_{mn} \\end{bmatrix} = c_1 \\begin{bmatrix} a_{11} \\\\ \\vdots \\\\ a_{m1} \\end{bmatrix} + \\cdots + c_n \\begin{bmatrix} a_{1n} \\\\ \\vdots \\\\ a_{mn} \\end{bmatrix} \\\\ & = & c_1 \\mathbf{v}_1 + \\cdots + c_n \\mathbf{v}_n \\end{array} \\] Therefore, the column space of \\(\\A\\) consists of all possible products \\(\\A\\x\\) for \\(\\x \\in \\F^n\\) . This is the same as the image or range of the corresponding matrix transformation in which we will learn more on in the linear transformation chapter.","title":"Algebraic Definition (Column Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#notation-column-space","text":"The column space of a matrix is denoted as \\(C(\\A)\\) , which is the space spanned by all columns of the matrix \\(\\A\\) . Note that the column space \\(C(\\A)\\) resides in the \\(\\F^{m}\\) space.","title":"Notation (Column Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#example-column-space","text":"If \\(A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 2 & 0 \\end{bmatrix}\\) , then the column vectors are \\(\\a_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix} \\quad \\a_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0\\end{bmatrix}\\) . A linear combination of \\(\\a_1, \\a_2\\) is any vector of the form \\[c_1 \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix} + c_2 \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} c_1 \\\\ c_2 \\\\ 2c_1 \\end{bmatrix}\\] The set of all such vectors is the column space of \\(\\A\\) and in this case, the column space is precisely the set of vectors \\((x, y, z) \\in \\R^3\\) satisfying the equation \\(z=2x\\) using Cartesian coordinates, this set is a plane through the origin in three-dimensional space.","title":"Example (Column Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#theorem-solvable-solutions","text":"A system of \\(m\\) linear equations in \\(n\\) unknowns \\(\\A\\x = \\b\\) has a solution if and only if the vector \\(\\b\\) can be expressed as a linear combination of the columns of \\(\\A\\) . In other words, the system is solvable if and only if \\(\\b \\in \\textbf{Col Space}(\\A)\\) . Proof can be found in pp.125-126 A modern introduction to linear algebra by Henry Ricardo .","title":"Theorem (Solvable Solutions)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#algebraic-definition-column-rank","text":"The column rank of \\(\\A\\) is the dimension of the column space of \\(\\A\\) . In other words, the column rank of \\(\\A\\) corresponds to the largest number vectors that can form a linearly indepedent set in the columns of \\(\\A\\) . This interpretation follows because the definition of dimension of a column space means given a vector space \\(V\\) which is our column space spanned by the columns of \\(\\A\\) , the dimension of the column space is the cardinality of the basis \\(\\B\\) of \\(V\\) ; and note that any basis \\(\\B\\) of \\(V\\) (our column space) is a linearly independent set which also spans \\(V\\) . So both definition is equivalent.","title":"Algebraic Definition (Column Rank)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#full-column-rank","text":"A matrix \\(\\A \\in \\F^{m \\times n}\\) is full column rank if and only if \\(\\rank(A) = n\\) . Thus, if the rank of the matrix \\(\\A\\) is \\(r = n\\) , then the column space spans all of \\(\\F^{n}\\) and is a basis of \\(\\F^{n}\\) , else it is a \\(r\\) -dimensional subspace embedded in \\(\\F^{n}\\) .","title":"Full Column Rank"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#lemma-row-operations-preserves-linear-dependency-of-column-space","text":"Row operations apparently change the column space but the important part is that it preserves the column rank of a matrix. We first start off by proving the lemma to show that the columns of two row equivalent matrices satisfy the same linear dependence relations and subsequently use this to determine a basis for the column space. If an \\(m \\times n\\) matrix \\(\\A\\) with columns \\(\\a_1, \\a_2, ..., \\a_n\\) is row equivalent to matrix \\(\\B\\) with columns \\(\\b_1, \\b_2, ..., \\b_n\\) then \\[ c_1\\a_1 + c_2\\a_2 + ... + \\c_n\\a_n = \\0 \\] if and only if \\[ c_1\\b_1 + c_2\\b_2 + ... + \\c_n\\b_n = \\0 \\]","title":"Lemma (Row Operations preserves Linear Dependency of Column Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#proof-row-operations-preserves-linear-dependency-of-column-space","text":"Suppose \\(\\A\\) and \\(\\B\\) are row equivalent matrices. Then we know that both have the same solution space (i.e. \\(\\A\\x=\\0\\) iff \\(\\B\\x=\\0\\) ). Denote a vector \\(\\c = \\begin{bmatrix}c_1 \\\\ c_2 \\\\ \\vdots \\\\ c_n \\end{bmatrix}\\) then we see that \\(\\A\\c=\\0\\) iff \\(\\B\\c=\\0\\) and so we see that \\[ c_1\\a_1 + c_2\\a_2 + ... + \\c_n\\a_n = \\0 \\] if and only if \\[ c_1\\b_1 + c_2\\b_2 + ... + \\c_n\\b_n = \\0 \\]","title":"Proof (Row Operations preserves Linear Dependency of Column Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#corollary-row-operations-preserves-order-linear-dependency-of-column-space","text":"As a corollary to the lemma, we note that for two row equivalent matrices \\(\\A\\) and \\(\\B\\) , the same set of linearly (in)dependen columns in \\(\\A\\) corresponds to the same set of linearly (in)dependent columns in \\(\\B\\) .","title":"Corollary (Row Operations preserves Order Linear Dependency of Column Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#theorem-basis-for-column-space","text":"If \\(\\A\\) is an \\(m \\times n\\) matrix and the pivots of \\(rref(\\A)\\) occur in columns \\(i_1, i_2, \\ldots, i_k\\) where \\(\\{i_1, i_2, \\ldots, i_k\\} \\subseteq \\{1, 2, \\ldots, n\\}\\) , then columns \\(i_1, i_2, \\ldots, i_k\\) of \\(\\A\\) form a basis for the column space of \\(\\A\\) . The proof is detailed in pp.130 of A modern introduction to linear algebra henry ricardo .","title":"Theorem (Basis For Column Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#algorithm-basis-for-column-space","text":"Calculate RREF of the matrix \\(\\A\\) . The pivot rows (non-zero) columns form a basis of the column space of \\(\\A\\) .","title":"Algorithm (Basis For Column Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#theorem-column-space-of-mathbfa-and-mathbfamathbfatop","text":"\\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\) have the same column space.","title":"Theorem (Column Space of \\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#proof-column-space-of-mathbfa-and-mathbfamathbfatop","text":"We first write \\(\\B = \\A\\A^\\top\\) and use the method that if \\(M \\subseteq N\\) and \\(N \\subseteq M\\) , then \\(N=M\\) to prove this. We first show that \\(C(\\B) \\subseteq C(\\A)\\) . The column space \\(C(\\A) = \\text{span}(\\a_1, \\a_2, ..., \\a_n) \\in \\F^{m}\\) and \\(C(\\B) = \\text{span}(\\b_1, \\b_2, ..., \\b_m)\\) . We note that by the right matrix multiplication , each column of \\(\\B = \\A\\A^\\top\\) is a linear combination of the columns of the left matrix \\(\\A\\) . That is to say, we can represent each column in \\(\\B\\) as \\(\\b_i = \\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_n \\a_n\\) . Consequently, by definition, any column from \\(\\B\\) is an element of \\(\\text{span}(\\a_1, ..., \\a_n)\\) , and hence in the column space \\(C(\\A)\\) . Thus, for any element in \\(C(\\B)\\) , this element must be in \\(C(\\A)\\) , and thus \\(C(\\B) \\subseteq C(\\A)\\) . We then show that \\(C(\\A) \\subseteq C(\\B)\\) . Take any element from \\(C(\\A)\\) , and recall that \\(C(\\B) = \\text{span}(\\b_1, \\b_2, ..., \\b_m) = c_1 \\b_1 + c_2 \\b_2 + \\cdots + c_m \\b_m = c_1 (\\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_m \\a_m) + c_2 (\\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_m \\a_m) + ... + c_2 (\\lambda_1 \\a_1 + \\lambda_2 \\a_2 + \\cdots + \\lambda_m \\a_m) = d_1\\a_1 + d_2\\a_2 + ... + d_m \\a_m\\) for some \\(d_i \\in \\F\\) . Then any element taken from the column space of \\(\\A\\) is a linear combination of \\(\\a_1, ..., \\a_m\\) ... What can we tell? We cannot tell anything since if \\(n > m\\) , then it may be the case that an element from \\(C(\\A)\\) may not cover.","title":"Proof (Column Space of \\(\\mathbf{A}\\) and \\(\\mathbf{A}\\mathbf{A}^\\top\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#the-augment-rank-algorithm-to-determine-membership-of-column-space","text":"Given a set of vectors \\(S = \\{\\v_1, \\v_2, ..., \\v_n\\}\\) , and a vector \\(\\w\\) , deduce if \\(\\w \\in \\textbf{span}(S)\\) . Assume \\(\\v_i \\in \\R^{m}\\) and \\(\\w \\in \\R^{m}\\) . Construct a matrix \\(\\mathbf{S} = \\begin{bmatrix} \\v_1 & \\v_2 & \\cdots & \\v_m \\end{bmatrix}_{m \\times n}\\) where \\(\\mathbf{S} \\in \\R^{m \\times n}\\) . Compute the rank of \\(\\mathbf{S}\\) and call it \\(s_1\\) . Horizontally concatenate \\(\\mathbf{S}\\) and \\(\\w\\) to get \\(\\mathbf{S}_w = \\mathbf{S} \\cup \\w\\) . Compute rank of \\(\\mathbf{S}_w\\) to be \\(s_2\\) . Then: If \\(s_1 = s_2\\) , this means that column space of \\(\\mathbf{S}\\) equals to the column space of \\(\\mathbf{S}_w\\) , and thus \\(\\w\\) did not alter the column space of \\(\\mathbf{S}\\) , which means \\(\\w\\) must be part of the column space of \\(\\mathbf{S}\\) , and thus in the span of \\(S\\) . If \\(s_2 > s_1\\) , then \\(\\w \\not\\in S\\) because if it is, the column space of \\(\\mathbf{S}_w\\) should not change. We can easily use this algorithm to check if a vector \\(\\w\\) is in the column space of a matrix \\(\\A\\) by setting \\(S\\) to be the set that contains all the columns of \\(\\A\\) .","title":"The \"Augment-Rank\" Algorithm to determine membership of Column Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#geometric-intuition","text":"Mike mentioned on Linear Algebra: Theory, Intuition, Code, 2021. (pp. 211) that we can think of the above cases geometrically. In the first case where \\(s_1 = s_2\\) , the rank is the same, this means the vector \\(\\w\\) is in the column space of \\(\\A\\) . This makes sense because when we add the new vector to the set, and yet the rank (dimension) did not change, this coincides with the idea of vector \\(\\w\\) sitting somewhere in the column space of \\(\\A\\) , and hence no new geometric directions are obatined by including this vector . In the second case where \\(s_2 > s_1\\) however, if v is outside the column space, then it points off in some other geometric dimension that is not spanned by the column space; hence, B has one extra geometric dimension not contained in A, and thus the rank is one higher. In the image below, we denote \\(C(\\A)\\) as the 1d-subspace in red, then vector \\(\\v\\) is apparently lying in the 1d-subspace, and hence a member of \\(C(\\A)\\) , then \\(\\w\\) , is slightly pointing to a different direction, and hence not in the column space of \\(\\A\\) . Fig; Column Space of A; By Hongnan G.","title":"Geometric Intuition"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#corollary","text":"If \\(\\A\\) is now a full ranked square matrix \\(m \\times m\\) , which means rank of \\(\\A\\) is \\(m\\) , then any vector \\(\\w \\in \\R^{m}\\) will be in the column space of \\(\\A\\) since the column space of \\(\\A\\) is actually a basis of the ambient subspace \\(\\F^{m}\\) .","title":"Corollary"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/#visualizing-column-space","text":"Courtesy of Macro Analyst's linear algebra with python . import matplotlib.pyplot as plt import numpy as np from mpl_toolkits.mplot3d import Axes3D import scipy as sp import scipy.linalg import sympy as sy sy . init_printing () Consider two matrix with \\[\\A = \\begin{bmatrix}1 & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\end{bmatrix} ,\\quad \\B = \\begin{bmatrix}3 & -1 \\\\ 2 & 4 \\\\ -1 & 1 \\end{bmatrix}\\] Then the column space \\(C(\\A)\\) is a 2d-plane given by \\[\\text{plane}(C(\\A)) = \\0 + s\\left[\\matrix{1\\cr 0\\cr 0}\\right] + t\\left[\\matrix{0\\cr 1\\cr 0}\\right]\\] and the column space \\(C(\\B)\\) is a 2d-plane given by \\[\\text{plane}(C(\\B)) = \\0 + s\\left[\\matrix{3\\cr 2\\cr -1}\\right] + t\\left[\\matrix{-1\\cr 4\\cr 1}\\right]\\] fig = plt . figure ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( projection = '3d' ) s = np . linspace ( - 2 , 2 , 20 ) t = np . linspace ( - 2 , 2 , 20 ) S , T = np . meshgrid ( s , t ) X = 3 * S - T Y = 2 * S + 4 * T Z = - S + T ax . plot_wireframe ( X , Y , Z , linewidth = .5 , color = 'r' ) s = np . linspace ( - 10 , 10 , 20 ) t = np . linspace ( - 10 , 10 , 20 ) S , T = np . meshgrid ( s , t ) X = S Y = T Z = np . zeros ( S . shape ) ax . plot_wireframe ( X , Y , Z , linewidth = .5 , color = 'k' ) ax . view_init ( elev = 14 , azim = 58 )","title":"Visualizing Column Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.05_linear_algebra_matrix_theory_matrix_spaces_right_nullspace/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\] Preamble Both Professor Mike and Gilbert started off with this statement: The entirety and gist of the matrix space can be summarized as answering two key questions: Given a matrix \\(\\A \\in \\F^{m \\times n}\\) and vector \\(\\b \\in \\F^{m}\\) and \\(\\0 \\in \\F^{m}\\) , then can we find a vector \\(\\x \\in \\F^{n}\\) such that \\( \\(\\A\\x = \\b\\) \\) \\( \\(\\A\\x = \\0\\) \\) From the matrix-multiplication section, we can easily re-interpret the question as: \\(\\A\\x=\\b\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\b\\) ? \\(\\A\\x=\\0\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\0\\) assuming \\(\\x \\neq \\0\\) . (Right) Null Space (Kernel) Motivation To fill in. Algebraic Definition (Null Space) Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, then the nullspace of \\(\\A\\) is the set: \\[ N(\\A) = \\{\\v \\in \\F^{n} ~|~ \\A\\v = \\0\\} \\] Note that the trivial solution \\(\\0\\) is always a solution to the nullspace. Note that if there exists a non-trivial \\(\\v\\) such that \\(\\A\\v = \\0\\) , then for any \\(\\lambda \\in F\\) , we also have \\(\\A(\\lambda\\v) = \\0\\) . Matrix Definition (Null Space) Consider a linear map represented as a \\(m \\times n\\) matrix \\(\\A\\) with coefficients in a field \\(\\F\\) , that is operating on column vectors \\(\\x\\) with \\(n\\) components over \\(\\F\\) . The kernel of this linear map is the set of solutions to the equation \\(\\A\\x=\\0\\) where \\(\\0\\) is understood as the zero vector. The dimension of the kernel of \\(\\A\\) is called the nullity of \\(\\A\\) . In set builder notations, we recover the algebraic definition : \\[ N(\\A) = \\{\\v \\in \\F^{n} ~|~ \\A\\v = \\0\\} \\] The matrix equation is equivalent to a homogeneous system of linear equations: \\[ \\A\\x=\\mathbf{0} \\;\\;\\Leftrightarrow\\;\\; \\begin{alignat}{7} a_{11} x_1 &&\\; + \\;&& a_{12} x_2 &&\\; + \\;\\cdots\\; + \\;&& a_{1n} x_n &&\\; = \\;&&& 0 \\\\ a_{21} x_1 &&\\; + \\;&& a_{22} x_2 &&\\; + \\;\\cdots\\; + \\;&& a_{2n} x_n &&\\; = \\;&&& 0 \\\\ && && && && &&\\vdots\\ \\;&&& \\\\ a_{m1} x_1 &&\\; + \\;&& a_{m2} x_2 &&\\; + \\;\\cdots\\; + \\;&& a_{mn} x_n &&\\; = \\;&&& 0\\text{.} \\\\ \\end{alignat} \\] Thus the kernel of \\(\\A\\) is the same as the solution set to the above homogeneous equations. Notation (Null Space) The null space of a matrix is denoted as \\(N(\\A)\\) . Note in particular that the column space \\(N(\\A)\\) resides in the \\(\\F^{n}\\) space. What does Null Space tell you? Now one important consequence is that, if there exists a non-trivial solution to the matrix \\(\\A\\x = \\0\\) , then what does it mean? Recall the right multiplication of columns for matrix-vector multiplication : It means that the linear combination of the columns of \\(\\A\\) can form the zero vector \\(\\0\\) . In particular, this linear combination is NON-TRIVIAL! Then the matrix \\(\\A\\) is formed by columns that are linearly dependent, and hence not full rank! We can formalize it as a theorem below. Theorem (Full Ranked Matrix has an Empty Nullspace) A matrix \\(\\A \\in \\F^{m \\times n}\\) is full rank if and only if the nullspace \\(N(\\A)\\) has only the trivial solution. Theorem (Basis For Right Null Space) To be filled in. Geometric Intuition (Null Space) import matplotlib.pyplot as plt import numpy as np from mpl_toolkits.mplot3d import Axes3D import sympy as sy sy . init_printing () A = sy . Matrix ([[ 5 , 8 , 2 ], [ 10 , 16 , 4 ], [ 3 , 4 , 1 ]]); A \\(\\displaystyle \\left[\\begin{matrix}5 & 8 & 2\\\\10 & 16 & 4\\\\3 & 4 & 1\\end{matrix}\\right]\\) A . rref () \\(\\displaystyle \\left( \\left[\\begin{matrix}1 & 0 & 0\\\\0 & 1 & \\frac{1}{4}\\\\0 & 0 & 0\\end{matrix}\\right], \\ \\left( 0, \\ 1\\right)\\right)\\)","title":"Right Nullspace (Kernel)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.05_linear_algebra_matrix_theory_matrix_spaces_right_nullspace/#preamble","text":"Both Professor Mike and Gilbert started off with this statement: The entirety and gist of the matrix space can be summarized as answering two key questions: Given a matrix \\(\\A \\in \\F^{m \\times n}\\) and vector \\(\\b \\in \\F^{m}\\) and \\(\\0 \\in \\F^{m}\\) , then can we find a vector \\(\\x \\in \\F^{n}\\) such that \\( \\(\\A\\x = \\b\\) \\) \\( \\(\\A\\x = \\0\\) \\) From the matrix-multiplication section, we can easily re-interpret the question as: \\(\\A\\x=\\b\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\b\\) ? \\(\\A\\x=\\0\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\0\\) assuming \\(\\x \\neq \\0\\) .","title":"Preamble"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.05_linear_algebra_matrix_theory_matrix_spaces_right_nullspace/#right-null-space-kernel","text":"","title":"(Right) Null Space (Kernel)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.05_linear_algebra_matrix_theory_matrix_spaces_right_nullspace/#motivation","text":"To fill in.","title":"Motivation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.05_linear_algebra_matrix_theory_matrix_spaces_right_nullspace/#algebraic-definition-null-space","text":"Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, then the nullspace of \\(\\A\\) is the set: \\[ N(\\A) = \\{\\v \\in \\F^{n} ~|~ \\A\\v = \\0\\} \\] Note that the trivial solution \\(\\0\\) is always a solution to the nullspace. Note that if there exists a non-trivial \\(\\v\\) such that \\(\\A\\v = \\0\\) , then for any \\(\\lambda \\in F\\) , we also have \\(\\A(\\lambda\\v) = \\0\\) .","title":"Algebraic Definition (Null Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.05_linear_algebra_matrix_theory_matrix_spaces_right_nullspace/#matrix-definition-null-space","text":"Consider a linear map represented as a \\(m \\times n\\) matrix \\(\\A\\) with coefficients in a field \\(\\F\\) , that is operating on column vectors \\(\\x\\) with \\(n\\) components over \\(\\F\\) . The kernel of this linear map is the set of solutions to the equation \\(\\A\\x=\\0\\) where \\(\\0\\) is understood as the zero vector. The dimension of the kernel of \\(\\A\\) is called the nullity of \\(\\A\\) . In set builder notations, we recover the algebraic definition : \\[ N(\\A) = \\{\\v \\in \\F^{n} ~|~ \\A\\v = \\0\\} \\] The matrix equation is equivalent to a homogeneous system of linear equations: \\[ \\A\\x=\\mathbf{0} \\;\\;\\Leftrightarrow\\;\\; \\begin{alignat}{7} a_{11} x_1 &&\\; + \\;&& a_{12} x_2 &&\\; + \\;\\cdots\\; + \\;&& a_{1n} x_n &&\\; = \\;&&& 0 \\\\ a_{21} x_1 &&\\; + \\;&& a_{22} x_2 &&\\; + \\;\\cdots\\; + \\;&& a_{2n} x_n &&\\; = \\;&&& 0 \\\\ && && && && &&\\vdots\\ \\;&&& \\\\ a_{m1} x_1 &&\\; + \\;&& a_{m2} x_2 &&\\; + \\;\\cdots\\; + \\;&& a_{mn} x_n &&\\; = \\;&&& 0\\text{.} \\\\ \\end{alignat} \\] Thus the kernel of \\(\\A\\) is the same as the solution set to the above homogeneous equations.","title":"Matrix Definition (Null Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.05_linear_algebra_matrix_theory_matrix_spaces_right_nullspace/#notation-null-space","text":"The null space of a matrix is denoted as \\(N(\\A)\\) . Note in particular that the column space \\(N(\\A)\\) resides in the \\(\\F^{n}\\) space.","title":"Notation (Null Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.05_linear_algebra_matrix_theory_matrix_spaces_right_nullspace/#what-does-null-space-tell-you","text":"Now one important consequence is that, if there exists a non-trivial solution to the matrix \\(\\A\\x = \\0\\) , then what does it mean? Recall the right multiplication of columns for matrix-vector multiplication : It means that the linear combination of the columns of \\(\\A\\) can form the zero vector \\(\\0\\) . In particular, this linear combination is NON-TRIVIAL! Then the matrix \\(\\A\\) is formed by columns that are linearly dependent, and hence not full rank! We can formalize it as a theorem below.","title":"What does Null Space tell you?"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.05_linear_algebra_matrix_theory_matrix_spaces_right_nullspace/#theorem-full-ranked-matrix-has-an-empty-nullspace","text":"A matrix \\(\\A \\in \\F^{m \\times n}\\) is full rank if and only if the nullspace \\(N(\\A)\\) has only the trivial solution.","title":"Theorem (Full Ranked Matrix has an Empty Nullspace)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.05_linear_algebra_matrix_theory_matrix_spaces_right_nullspace/#theorem-basis-for-right-null-space","text":"To be filled in.","title":"Theorem (Basis For Right Null Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.05_linear_algebra_matrix_theory_matrix_spaces_right_nullspace/#geometric-intuition-null-space","text":"import matplotlib.pyplot as plt import numpy as np from mpl_toolkits.mplot3d import Axes3D import sympy as sy sy . init_printing () A = sy . Matrix ([[ 5 , 8 , 2 ], [ 10 , 16 , 4 ], [ 3 , 4 , 1 ]]); A \\(\\displaystyle \\left[\\begin{matrix}5 & 8 & 2\\\\10 & 16 & 4\\\\3 & 4 & 1\\end{matrix}\\right]\\) A . rref () \\(\\displaystyle \\left( \\left[\\begin{matrix}1 & 0 & 0\\\\0 & 1 & \\frac{1}{4}\\\\0 & 0 & 0\\end{matrix}\\right], \\ \\left( 0, \\ 1\\right)\\right)\\)","title":"Geometric Intuition (Null Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.06_linear_algebra_matrix_theory_matrix_spaces_left_nullspace/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\] Preamble Both Professor Mike and Gilbert started off with this statement: The entirety and gist of the matrix space can be summarized as answering two key questions: Given a matrix \\(\\A \\in \\F^{m \\times n}\\) and vector \\(\\b \\in \\F^{m}\\) and \\(\\0 \\in \\F^{m}\\) , then can we find a vector \\(\\x \\in \\F^{n}\\) such that \\( \\(\\A\\x = \\b\\) \\) \\( \\(\\A\\x = \\0\\) \\) From the matrix-multiplication section, we can easily re-interpret the question as: \\(\\A\\x=\\b\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\b\\) ? \\(\\A\\x=\\0\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\0\\) assuming \\(\\x \\neq \\0\\) . Left (Null Space) Algebraic Definition (Left Null Space) Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, then the left nullspace of \\(\\A\\) is actually the nullspace of its transpose: \\[ N(\\A^\\top) = \\{\\v \\in \\F^{m} ~|~ \\A^\\top\\v = \\0\\} \\] and if we take transpose to both sides of \\(\\A^\\top\\v = \\0\\) to be \\(\\left(\\A^\\top\\v \\right)^\\top = \\0^\\top\\) ; it follows we have \\(\\v^\\top\\A = \\0^\\top\\) , where the row vector \\(\\v^\\top\\) is on the left of \\(\\A\\) . Note in particular that the column space \\(N(\\A)\\) resides in the \\(\\F^{m}\\) space. Theorem (The Nullspace and Left Nullspace of a Symmetric Matrix is Equal) Given a symmetric matrix \\(\\A\\) , we know that \\(\\A^\\top = \\A\\) , and thus \\(N(\\A) = N(\\A^\\top)\\) .","title":"Left Nullspace"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.06_linear_algebra_matrix_theory_matrix_spaces_left_nullspace/#preamble","text":"Both Professor Mike and Gilbert started off with this statement: The entirety and gist of the matrix space can be summarized as answering two key questions: Given a matrix \\(\\A \\in \\F^{m \\times n}\\) and vector \\(\\b \\in \\F^{m}\\) and \\(\\0 \\in \\F^{m}\\) , then can we find a vector \\(\\x \\in \\F^{n}\\) such that \\( \\(\\A\\x = \\b\\) \\) \\( \\(\\A\\x = \\0\\) \\) From the matrix-multiplication section, we can easily re-interpret the question as: \\(\\A\\x=\\b\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\b\\) ? \\(\\A\\x=\\0\\) is equivalent to asking can we find linear combination of columns of \\(\\A\\) such that the sum is \\(\\0\\) assuming \\(\\x \\neq \\0\\) .","title":"Preamble"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.06_linear_algebra_matrix_theory_matrix_spaces_left_nullspace/#left-null-space","text":"","title":"Left (Null Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.06_linear_algebra_matrix_theory_matrix_spaces_left_nullspace/#algebraic-definition-left-null-space","text":"Let \\(\\F\\) be a field of scalars and let \\(\\A\\) a \\(m \\times n\\) matrix, then the left nullspace of \\(\\A\\) is actually the nullspace of its transpose: \\[ N(\\A^\\top) = \\{\\v \\in \\F^{m} ~|~ \\A^\\top\\v = \\0\\} \\] and if we take transpose to both sides of \\(\\A^\\top\\v = \\0\\) to be \\(\\left(\\A^\\top\\v \\right)^\\top = \\0^\\top\\) ; it follows we have \\(\\v^\\top\\A = \\0^\\top\\) , where the row vector \\(\\v^\\top\\) is on the left of \\(\\A\\) . Note in particular that the column space \\(N(\\A)\\) resides in the \\(\\F^{m}\\) space.","title":"Algebraic Definition (Left Null Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.06_linear_algebra_matrix_theory_matrix_spaces_left_nullspace/#theorem-the-nullspace-and-left-nullspace-of-a-symmetric-matrix-is-equal","text":"Given a symmetric matrix \\(\\A\\) , we know that \\(\\A^\\top = \\A\\) , and thus \\(N(\\A) = N(\\A^\\top)\\) .","title":"Theorem (The Nullspace and Left Nullspace of a Symmetric Matrix is Equal)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\C}{\\mathbf{C}}\\] Matrix Rank We will understand matrix rank in a naive manner first, we will go through it more formally in the next few sections. Algebraic Definition (Rank) 1 In linear algebra , the rank of a matrix \\(\\A\\) is the dimension of the vector space generated (or spanned ) by its columns. This corresponds to the maximal number of linearly independent columns of \\(\\A\\) . This, in turn, is identical to the dimension of the vector space spanned by its rows. Rank is thus a measure of the \\\" nondegenerateness \\\" of the system of linear equations and linear transformation encoded by \\(\\A\\) . There are multiple equivalent definitions of rank. A matrix\\'s rank is one of its most fundamental characteristics. Notation (Rank) The rank of a matrix \\(\\A\\) is commonly denoted by \\(\\rank(A)\\) . Algebraic Definition (Column Rank) The column rank of \\(\\A\\) is the dimension of the column space of \\(\\A\\) . In other words, the column rank of \\(\\A\\) corresponds to the largest number vectors that can form a linearly indepedent set in the columns of \\(\\A\\) . This interpretation follows because the definition of dimension of a column space means given a vector space \\(V\\) which is our column space spanned by the columns of \\(\\A\\) , the dimension of the column space is the cardinality of the basis \\(\\B\\) of \\(V\\) ; and note that any basis \\(\\B\\) of \\(V\\) (our column space) is a linearly independent set which also spans \\(V\\) . So both definition is equivalent. Full Column Rank A matrix \\(\\A \\in \\F^{m \\times n}\\) is full column rank if and only if \\(\\rank(A) = n\\) . Algebraic Definition (Row Rank) The row rank of \\(\\A\\) is the dimension of the row space of \\(\\A\\) . Full Row Rank A matrix \\(\\A \\in \\F^{m \\times n}\\) is full column rank if and only if \\(\\rank(A) = m\\) . Definition (Full Rank) We will soon show that the column and row rank of a matrix \\(\\A \\in \\F^{m \\times n}\\) is the same, and for a matrix to be termed full rank , it means that: \\[\\rank(\\A) = \\min{(m, n)}\\] This makes sense because if we know that for a matrix say shape \\((3, 6)\\) to have equal rank on both columns and rows, then the max rank a matrix can have for this example is \\(3\\) . Definition (Reduced Rank) If a matrix \\(\\A \\in \\F^{m \\times n}\\) is not full rank, then we call it reduced rank, or rank deficient. Geometric Definition (Rank) TBD Example (Computing Rank by Inspection) The matrix \\[\\A = \\begin{bmatrix}1&0&1\\\\-2&-3&1\\\\3&3&0\\end{bmatrix}\\] has column rank 2 since the first two columns are linearly independent , so the rank is at least 2, but since the third is a linear combination of the first two (the second subtracted from the first), the three columns are linearly dependent so the column rank is 2. The matrix \\[\\A=\\begin{bmatrix}1&1&0&2\\\\-1&-1&0&-2\\end{bmatrix}\\] has row rank 1 since row 2 is a multiple of row 1, and thus of the 2 rows, the number of linearly independent rows is 1. We will soon see that column and row rank are equivalent. Theorem (Column Rank is Row Rank) The first important theorem states that for any matrix \\(\\A \\in \\F^{m \\times n}\\) , the row rank is equivalent to the column rank . There are many proofs, we will use what is the easiest using Gaussian Elimination. For other proofs, see here 2 . Proof (Column Rank is Row Rank) Recall that row operations preserve both the column and row space of a matrix \\(\\A\\) . Thus row reduction performed on \\(\\A\\) will reveal the number of pivots. First, we assert that row reduction reveals us a basis of the row space of \\(\\A\\) by just taking the non-zero rows. Consequently, the dimension of the row space is also obtained by counting the number of pivots (non-zero rows). We thus get the row rank of the matrix \\(\\A\\) . But recall that we are counting the pivot columns to get the dimension of the row space. One immediately recalls that row reduction also preserves the linear dependency of the column space , in Theorem (Basis For Column Space) , we also deduced that the number of pivots columns corresponds to the dimension of the column space. Consequently, the dimension of the row space and column space is the same, and so is their rank. Computing Rank Naive Count If the matrix \\(\\A \\in \\F^{m \\times n}\\) is small, then eyeballing like how I did in the previous example will work. Pivots in RREF This is mentioned in Theorem (Column Rank is Row Rank) . SVD Later chapter Properties of Rank Assume \\(\\A \\in \\F^{m \\times p}\\) and \\(\\B \\in \\F^{p \\times n}\\) . Rank and Scalar Multiplication Given a matrix \\(\\A\\) , and a scalar \\(\\lambda\\) : \\[\\rank(A) = \\rank(\\lambda\\A) ,\\quad \\lambda \\neq 0\\] Geometrically, this makes sense because scaling all the columns or rows by a scalar does not change the columns or rows linear dependency. Algebraically, it is easy to see that given a set of vectors \\(\\{\\v_1, \\v_2, ..., \\v_m\\}\\) , then \\(\\lambda\\{\\v_1, \\v_2, ..., \\v_m\\}\\) does not change the linear dependency. One should recall \\[\\text{span}(\\{\\v_1, \\v_2, ..., \\v_m\\}) = \\text{span}(\\lambda\\{\\v_1, \\v_2, ..., \\v_m\\})\\] Subadditivity This property states that: \\(\\rank(\\A + \\B) \\leq \\rank(\\A) + \\rank(\\B)\\) . Rank of AB is Minimum of A or B This theorem states that: \\[ \\rank(\\A\\B) \\leq \\min{(\\rank(\\A), \\rank(\\B))} \\] Proof (Rank of AB is Minimum of A or B) Let \\(\\mathbf{C} = \\A\\B\\) to of size \\(m \\times n\\) . Then we note that: \\[ \\mathbf{C} = \\A\\begin{bmatrix}\\b_1 & \\b_2 & \\cdots & \\b_n\\end{bmatrix} \\] which implies \\[ \\mathbf{C}_i = \\A\\b_i \\] indicating that column \\(i\\) of \\(\\mathbf{C}\\) is \\(\\A\\b_i\\) . Further recall in the section on matrix multiplication that \\(\\A\\b_i\\) is the linear combination of columns of \\(\\A\\) with coefficients from \\(\\b_i\\) . Consequently, we can say that each and every column of \\(\\mathbf{C}\\) is a linear combination of columns of \\(\\A\\) , implying that the column space of \\(\\mathbf{C}\\) is a subset of the column space of \\(\\A\\) (i.e. take any column \\(\\mathbf{C}_i\\) of \\(\\mathbf{C}\\) , we show that this column is in the column space of \\(\\A\\) .) Therefore, we conclude \\[\\textbf{col}(\\mathbf{C}) \\subseteq \\textbf{col}({\\A}) \\implies \\rank(\\mathbf{C}) \\leq \\rank(\\A)\\] Without loss of generality, the same can be done for matrix \\(\\B\\) by looking at the row space of \\(\\B\\) and \\(\\mathbf{C}\\) . Equivalence of Ranks on \\(\\mathbf{A}, \\mathbf{A}^\\top, \\mathbf{A}^\\top\\mathbf{A}, \\mathbf{A}\\mathbf{A}^\\top\\) Firstly, \\(\\A\\) and \\(\\A^\\top\\) have the same rank because we can use the theorem which states the column and row rank of any matrix is the same. Rank of Random Matrices This is a refreshing topic from Mike X Cohen's Linear Algebra: Theory, Intuition, Code, 2021. (pp. 193) . In summary, if you fill up a matrix \\(\\A \\in \\F^{m \\times n}\\) with elements randomly drawn from various distributions (i.e Gaussian/Uniform etc), then this random matrix is almost always guaranteed to be full rank . The intuition is simple, consider the real space \\(\\R\\) , we are drawing elements from the continuous real space with decimal points, and assume you are creating a 3 by 2 matrix. The probability for the 3 rows or 2 columns to be linearly independent is close to 0. Python Implementation We first create full ranked matrices. import numpy as np A = np . random . standard_normal ( size = ( 3 , 6 )) # draw from standard normal with mu = 0 and sigma = 1 np . linalg . matrix_rank ( A ) == 3 True Then to create rank deficient matrices of a fixed rank, it is more challenging because we know that populating a matrix with random values from a distribution means the matrix is full rank. However, we can use the theorem that states Rank of AB is Minimum of A or B to do so. # let's say we want to create a 3x6 matrix but we only want its rank to be 2 # we know from theorem that rank(AB) <= min(rank(A), rank(B)) # we thus ensure both A and B has rank 2 (the one we want here) but we must make sure the other shape of the matrix A and B is more than 2, # which is guaranteed in the code below. reduced_rank = 2 reduced_rank_matrix_shape = ( 3 , 6 ) A = np . random . standard_normal ( size = ( reduced_rank_matrix_shape [ 0 ], reduced_rank )) B = np . random . standard_normal ( size = ( reduced_rank , reduced_rank_matrix_shape [ 1 ])) C = A @B # shape (3, 6) np . linalg . matrix_rank ( C ) 2 How to turn Rank-Deficient Matrices to Full Rank? (Machine Learning) In machine learning, we often want to work with full rank matrices. Given a rank-deficient matrix \\(\\A \\in \\F^{m \\times n}\\) , we can shift the matrix by \\(\\lambda\\) to make it full rank. Read more from Mike X Cohen's Linear Algebra: Theory, Intuition, Code, 2021. (pp. 195) . Using Rank to check if a vector in Span Given a set of vectors \\(S = \\{\\v_1, \\v_2, ..., \\v_n\\}\\) , and a vector \\(\\w\\) , deduce if \\(\\w \\in \\textbf{span}(S)\\) . Assume \\(\\v_i \\in \\R^{m}\\) and \\(\\w \\in \\R^{m}\\) . Construct a matrix \\(\\mathbf{S} = \\begin{bmatrix} \\v_1 & \\v_2 & \\cdots & \\v_m \\end{bmatrix}_{m \\times n}\\) where \\(\\mathbf{S} \\in \\R^{m \\times n}\\) . Compute the rank of \\(\\mathbf{S}\\) and call it \\(s_1\\) . Horizontally concatenate \\(\\mathbf{S}\\) and \\(\\w\\) to get \\(\\mathbf{S}_w = \\mathbf{S} \\cup \\w\\) . Compute rank of \\(\\mathbf{S}_w\\) to be \\(s_2\\) . Then: If \\(s_1 = s_2\\) , this means that column space of \\(\\mathbf{S}\\) equals to the column space of \\(\\mathbf{S}_w\\) , and thus \\(\\w\\) did not alter the column space of \\(\\mathbf{S}\\) , which means \\(\\w\\) must be part of the column space of \\(\\mathbf{S}\\) , and thus in the span of \\(S\\) . If \\(s_2 > s_1\\) , then \\(\\w \\not\\in S\\) because if it is, the column space of \\(\\mathbf{S}_w\\) should not change. https://en.wikipedia.org/wiki/Rank_(linear_algebra) \u21a9 https://math.stackexchange.com/questions/332908/looking-for-an-intuitive-explanation-why-the-row-rank-is-equal-to-the-column-ran \u21a9","title":"Matrix Rank"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#matrix-rank","text":"We will understand matrix rank in a naive manner first, we will go through it more formally in the next few sections.","title":"Matrix Rank"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#algebraic-definition-rank1","text":"In linear algebra , the rank of a matrix \\(\\A\\) is the dimension of the vector space generated (or spanned ) by its columns. This corresponds to the maximal number of linearly independent columns of \\(\\A\\) . This, in turn, is identical to the dimension of the vector space spanned by its rows. Rank is thus a measure of the \\\" nondegenerateness \\\" of the system of linear equations and linear transformation encoded by \\(\\A\\) . There are multiple equivalent definitions of rank. A matrix\\'s rank is one of its most fundamental characteristics.","title":"Algebraic Definition (Rank)1"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#notation-rank","text":"The rank of a matrix \\(\\A\\) is commonly denoted by \\(\\rank(A)\\) .","title":"Notation (Rank)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#algebraic-definition-column-rank","text":"The column rank of \\(\\A\\) is the dimension of the column space of \\(\\A\\) . In other words, the column rank of \\(\\A\\) corresponds to the largest number vectors that can form a linearly indepedent set in the columns of \\(\\A\\) . This interpretation follows because the definition of dimension of a column space means given a vector space \\(V\\) which is our column space spanned by the columns of \\(\\A\\) , the dimension of the column space is the cardinality of the basis \\(\\B\\) of \\(V\\) ; and note that any basis \\(\\B\\) of \\(V\\) (our column space) is a linearly independent set which also spans \\(V\\) . So both definition is equivalent.","title":"Algebraic Definition (Column Rank)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#full-column-rank","text":"A matrix \\(\\A \\in \\F^{m \\times n}\\) is full column rank if and only if \\(\\rank(A) = n\\) .","title":"Full Column Rank"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#algebraic-definition-row-rank","text":"The row rank of \\(\\A\\) is the dimension of the row space of \\(\\A\\) .","title":"Algebraic Definition (Row Rank)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#full-row-rank","text":"A matrix \\(\\A \\in \\F^{m \\times n}\\) is full column rank if and only if \\(\\rank(A) = m\\) .","title":"Full Row Rank"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#definition-full-rank","text":"We will soon show that the column and row rank of a matrix \\(\\A \\in \\F^{m \\times n}\\) is the same, and for a matrix to be termed full rank , it means that: \\[\\rank(\\A) = \\min{(m, n)}\\] This makes sense because if we know that for a matrix say shape \\((3, 6)\\) to have equal rank on both columns and rows, then the max rank a matrix can have for this example is \\(3\\) .","title":"Definition (Full Rank)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#definition-reduced-rank","text":"If a matrix \\(\\A \\in \\F^{m \\times n}\\) is not full rank, then we call it reduced rank, or rank deficient.","title":"Definition (Reduced Rank)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#geometric-definition-rank","text":"TBD","title":"Geometric Definition (Rank)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#example-computing-rank-by-inspection","text":"The matrix \\[\\A = \\begin{bmatrix}1&0&1\\\\-2&-3&1\\\\3&3&0\\end{bmatrix}\\] has column rank 2 since the first two columns are linearly independent , so the rank is at least 2, but since the third is a linear combination of the first two (the second subtracted from the first), the three columns are linearly dependent so the column rank is 2. The matrix \\[\\A=\\begin{bmatrix}1&1&0&2\\\\-1&-1&0&-2\\end{bmatrix}\\] has row rank 1 since row 2 is a multiple of row 1, and thus of the 2 rows, the number of linearly independent rows is 1. We will soon see that column and row rank are equivalent.","title":"Example (Computing Rank by Inspection)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#theorem-column-rank-is-row-rank","text":"The first important theorem states that for any matrix \\(\\A \\in \\F^{m \\times n}\\) , the row rank is equivalent to the column rank . There are many proofs, we will use what is the easiest using Gaussian Elimination. For other proofs, see here 2 .","title":"Theorem (Column Rank is Row Rank)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#proof-column-rank-is-row-rank","text":"Recall that row operations preserve both the column and row space of a matrix \\(\\A\\) . Thus row reduction performed on \\(\\A\\) will reveal the number of pivots. First, we assert that row reduction reveals us a basis of the row space of \\(\\A\\) by just taking the non-zero rows. Consequently, the dimension of the row space is also obtained by counting the number of pivots (non-zero rows). We thus get the row rank of the matrix \\(\\A\\) . But recall that we are counting the pivot columns to get the dimension of the row space. One immediately recalls that row reduction also preserves the linear dependency of the column space , in Theorem (Basis For Column Space) , we also deduced that the number of pivots columns corresponds to the dimension of the column space. Consequently, the dimension of the row space and column space is the same, and so is their rank.","title":"Proof (Column Rank is Row Rank)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#computing-rank","text":"","title":"Computing Rank"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#naive-count","text":"If the matrix \\(\\A \\in \\F^{m \\times n}\\) is small, then eyeballing like how I did in the previous example will work.","title":"Naive Count"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#pivots-in-rref","text":"This is mentioned in Theorem (Column Rank is Row Rank) .","title":"Pivots in RREF"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#svd","text":"Later chapter","title":"SVD"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#properties-of-rank","text":"Assume \\(\\A \\in \\F^{m \\times p}\\) and \\(\\B \\in \\F^{p \\times n}\\) .","title":"Properties of Rank"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#rank-and-scalar-multiplication","text":"Given a matrix \\(\\A\\) , and a scalar \\(\\lambda\\) : \\[\\rank(A) = \\rank(\\lambda\\A) ,\\quad \\lambda \\neq 0\\] Geometrically, this makes sense because scaling all the columns or rows by a scalar does not change the columns or rows linear dependency. Algebraically, it is easy to see that given a set of vectors \\(\\{\\v_1, \\v_2, ..., \\v_m\\}\\) , then \\(\\lambda\\{\\v_1, \\v_2, ..., \\v_m\\}\\) does not change the linear dependency. One should recall \\[\\text{span}(\\{\\v_1, \\v_2, ..., \\v_m\\}) = \\text{span}(\\lambda\\{\\v_1, \\v_2, ..., \\v_m\\})\\]","title":"Rank and Scalar Multiplication"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#subadditivity","text":"This property states that: \\(\\rank(\\A + \\B) \\leq \\rank(\\A) + \\rank(\\B)\\) .","title":"Subadditivity"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#rank-of-ab-is-minimum-of-a-or-b","text":"This theorem states that: \\[ \\rank(\\A\\B) \\leq \\min{(\\rank(\\A), \\rank(\\B))} \\]","title":"Rank of AB is Minimum of A or B"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#proof-rank-of-ab-is-minimum-of-a-or-b","text":"Let \\(\\mathbf{C} = \\A\\B\\) to of size \\(m \\times n\\) . Then we note that: \\[ \\mathbf{C} = \\A\\begin{bmatrix}\\b_1 & \\b_2 & \\cdots & \\b_n\\end{bmatrix} \\] which implies \\[ \\mathbf{C}_i = \\A\\b_i \\] indicating that column \\(i\\) of \\(\\mathbf{C}\\) is \\(\\A\\b_i\\) . Further recall in the section on matrix multiplication that \\(\\A\\b_i\\) is the linear combination of columns of \\(\\A\\) with coefficients from \\(\\b_i\\) . Consequently, we can say that each and every column of \\(\\mathbf{C}\\) is a linear combination of columns of \\(\\A\\) , implying that the column space of \\(\\mathbf{C}\\) is a subset of the column space of \\(\\A\\) (i.e. take any column \\(\\mathbf{C}_i\\) of \\(\\mathbf{C}\\) , we show that this column is in the column space of \\(\\A\\) .) Therefore, we conclude \\[\\textbf{col}(\\mathbf{C}) \\subseteq \\textbf{col}({\\A}) \\implies \\rank(\\mathbf{C}) \\leq \\rank(\\A)\\] Without loss of generality, the same can be done for matrix \\(\\B\\) by looking at the row space of \\(\\B\\) and \\(\\mathbf{C}\\) .","title":"Proof (Rank of AB is Minimum of A or B)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#equivalence-of-ranks-on-mathbfa-mathbfatop-mathbfatopmathbfa-mathbfamathbfatop","text":"Firstly, \\(\\A\\) and \\(\\A^\\top\\) have the same rank because we can use the theorem which states the column and row rank of any matrix is the same.","title":"Equivalence of Ranks on \\(\\mathbf{A}, \\mathbf{A}^\\top, \\mathbf{A}^\\top\\mathbf{A}, \\mathbf{A}\\mathbf{A}^\\top\\)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#rank-of-random-matrices","text":"This is a refreshing topic from Mike X Cohen's Linear Algebra: Theory, Intuition, Code, 2021. (pp. 193) . In summary, if you fill up a matrix \\(\\A \\in \\F^{m \\times n}\\) with elements randomly drawn from various distributions (i.e Gaussian/Uniform etc), then this random matrix is almost always guaranteed to be full rank . The intuition is simple, consider the real space \\(\\R\\) , we are drawing elements from the continuous real space with decimal points, and assume you are creating a 3 by 2 matrix. The probability for the 3 rows or 2 columns to be linearly independent is close to 0.","title":"Rank of Random Matrices"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#python-implementation","text":"We first create full ranked matrices. import numpy as np A = np . random . standard_normal ( size = ( 3 , 6 )) # draw from standard normal with mu = 0 and sigma = 1 np . linalg . matrix_rank ( A ) == 3 True Then to create rank deficient matrices of a fixed rank, it is more challenging because we know that populating a matrix with random values from a distribution means the matrix is full rank. However, we can use the theorem that states Rank of AB is Minimum of A or B to do so. # let's say we want to create a 3x6 matrix but we only want its rank to be 2 # we know from theorem that rank(AB) <= min(rank(A), rank(B)) # we thus ensure both A and B has rank 2 (the one we want here) but we must make sure the other shape of the matrix A and B is more than 2, # which is guaranteed in the code below. reduced_rank = 2 reduced_rank_matrix_shape = ( 3 , 6 ) A = np . random . standard_normal ( size = ( reduced_rank_matrix_shape [ 0 ], reduced_rank )) B = np . random . standard_normal ( size = ( reduced_rank , reduced_rank_matrix_shape [ 1 ])) C = A @B # shape (3, 6) np . linalg . matrix_rank ( C ) 2","title":"Python Implementation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#how-to-turn-rank-deficient-matrices-to-full-rank-machine-learning","text":"In machine learning, we often want to work with full rank matrices. Given a rank-deficient matrix \\(\\A \\in \\F^{m \\times n}\\) , we can shift the matrix by \\(\\lambda\\) to make it full rank. Read more from Mike X Cohen's Linear Algebra: Theory, Intuition, Code, 2021. (pp. 195) .","title":"How to turn Rank-Deficient Matrices to Full Rank? (Machine Learning)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/#using-rank-to-check-if-a-vector-in-span","text":"Given a set of vectors \\(S = \\{\\v_1, \\v_2, ..., \\v_n\\}\\) , and a vector \\(\\w\\) , deduce if \\(\\w \\in \\textbf{span}(S)\\) . Assume \\(\\v_i \\in \\R^{m}\\) and \\(\\w \\in \\R^{m}\\) . Construct a matrix \\(\\mathbf{S} = \\begin{bmatrix} \\v_1 & \\v_2 & \\cdots & \\v_m \\end{bmatrix}_{m \\times n}\\) where \\(\\mathbf{S} \\in \\R^{m \\times n}\\) . Compute the rank of \\(\\mathbf{S}\\) and call it \\(s_1\\) . Horizontally concatenate \\(\\mathbf{S}\\) and \\(\\w\\) to get \\(\\mathbf{S}_w = \\mathbf{S} \\cup \\w\\) . Compute rank of \\(\\mathbf{S}_w\\) to be \\(s_2\\) . Then: If \\(s_1 = s_2\\) , this means that column space of \\(\\mathbf{S}\\) equals to the column space of \\(\\mathbf{S}_w\\) , and thus \\(\\w\\) did not alter the column space of \\(\\mathbf{S}\\) , which means \\(\\w\\) must be part of the column space of \\(\\mathbf{S}\\) , and thus in the span of \\(S\\) . If \\(s_2 > s_1\\) , then \\(\\w \\not\\in S\\) because if it is, the column space of \\(\\mathbf{S}_w\\) should not change. https://en.wikipedia.org/wiki/Rank_(linear_algebra) \u21a9 https://math.stackexchange.com/questions/332908/looking-for-an-intuitive-explanation-why-the-row-rank-is-equal-to-the-column-ran \u21a9","title":"Using Rank to check if a vector in Span"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.08_linear_algebra_matrix_theory_matrix_spaces_summary/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\nullity}{\\textbf{nullity}} \\newcommand{\\C}{\\mathbf{C}}\\] The Four Fundamental Subspaces Summary We highlight some important theorems here. This is a summary of what we should know. Theorem (Row-Reduced Matrix has the same 4 Subspace Dimension as the Original Matrix) This at its core is the foundation of many matrix theories. The beauty is that given any matrix \\(\\A\\) , then its RREF matrix \\(\\mathbf{R}\\) 's 4 fundamental subspaces has the same dimension. Theorem (Row space of \\(\\mathbf{A}\\) is the Column space of \\(\\mathbf{A}^\\top\\) ) Given a matrix \\(\\A \\in \\F^{m \\times n}\\) , the rows of \\(\\A\\) is the columns of \\(\\A^\\top\\) , and hence the theorem follows. Theorem (Row rank of \\(\\mathbf{A}\\) is Column rank of \\(\\mathbf{A}\\) ) The row rank of a matrix \\(\\A\\) is equals to the column rank of \\(\\A\\) . pp 131; of A modern introduction to linear algebra henry ricardo Corollary (Transpose has the same Rank) Let \\(\\A \\in \\F^{m \\times n}\\) , then \\(\\rank(\\A) = \\rank(\\B)\\) . Theorem (Rank-Nullity Theorem) Given any matrix \\(\\A \\in \\F^{m \\times n}\\) , the Rank-Nullity Theorem states: \\[ \\rank(\\A) + \\nullity(\\A) = n \\] pp 133; of A modern introduction to linear algebra henry ricardo Dimensions of Four Subspaces Given a matrix \\(\\A \\in \\F^{m \\times n}\\) , then assume the rank of the matrix is \\(r\\) : \\(\\dim(C(\\A)) = \\dim(R(\\A)) = r\\) \\(\\dim(C(\\A^\\top)) = r = \\dim(R(\\A^\\top))\\) because the dimension of row and column space of \\(\\A\\) is equal, and so is their transpose! \\(\\dim(N(\\A)) = n - r\\) by Rank-Nullity Theorem . \\(\\dim(N(\\A^\\top)) = m - r\\) because rank of \\(\\A^\\top = r\\) and by Rank-Nullity Theorem this holds. Table of Contents Firstly, recall the solution set of a homogeneous system of linear equations remains unchanged after row operations (i.e. Gaussian-Jordan). Secondly, define rank of a matrix to be the number of pivots after RREF . So \\(\\A\\x = \\0\\) becomes \\(\\U\\x = \\0\\) . Rank of a matrix is the number of pivot columns, and therefore is the dimension of the column space","title":"The Four Fundamental Subspaces (Summary)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.08_linear_algebra_matrix_theory_matrix_spaces_summary/#the-four-fundamental-subspaces-summary","text":"We highlight some important theorems here. This is a summary of what we should know.","title":"The Four Fundamental Subspaces Summary"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.08_linear_algebra_matrix_theory_matrix_spaces_summary/#theorem-row-reduced-matrix-has-the-same-4-subspace-dimension-as-the-original-matrix","text":"This at its core is the foundation of many matrix theories. The beauty is that given any matrix \\(\\A\\) , then its RREF matrix \\(\\mathbf{R}\\) 's 4 fundamental subspaces has the same dimension.","title":"Theorem (Row-Reduced Matrix has the same 4 Subspace Dimension as the Original Matrix)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.08_linear_algebra_matrix_theory_matrix_spaces_summary/#theorem-row-space-of-mathbfa-is-the-column-space-of-mathbfatop","text":"Given a matrix \\(\\A \\in \\F^{m \\times n}\\) , the rows of \\(\\A\\) is the columns of \\(\\A^\\top\\) , and hence the theorem follows.","title":"Theorem (Row space of \\(\\mathbf{A}\\) is the Column space of \\(\\mathbf{A}^\\top\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.08_linear_algebra_matrix_theory_matrix_spaces_summary/#theorem-row-rank-of-mathbfa-is-column-rank-of-mathbfa","text":"The row rank of a matrix \\(\\A\\) is equals to the column rank of \\(\\A\\) . pp 131; of A modern introduction to linear algebra henry ricardo","title":"Theorem (Row rank of \\(\\mathbf{A}\\) is Column rank of \\(\\mathbf{A}\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.08_linear_algebra_matrix_theory_matrix_spaces_summary/#corollary-transpose-has-the-same-rank","text":"Let \\(\\A \\in \\F^{m \\times n}\\) , then \\(\\rank(\\A) = \\rank(\\B)\\) .","title":"Corollary (Transpose has the same Rank)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.08_linear_algebra_matrix_theory_matrix_spaces_summary/#theorem-rank-nullity-theorem","text":"Given any matrix \\(\\A \\in \\F^{m \\times n}\\) , the Rank-Nullity Theorem states: \\[ \\rank(\\A) + \\nullity(\\A) = n \\] pp 133; of A modern introduction to linear algebra henry ricardo","title":"Theorem (Rank-Nullity Theorem)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.08_linear_algebra_matrix_theory_matrix_spaces_summary/#dimensions-of-four-subspaces","text":"Given a matrix \\(\\A \\in \\F^{m \\times n}\\) , then assume the rank of the matrix is \\(r\\) : \\(\\dim(C(\\A)) = \\dim(R(\\A)) = r\\) \\(\\dim(C(\\A^\\top)) = r = \\dim(R(\\A^\\top))\\) because the dimension of row and column space of \\(\\A\\) is equal, and so is their transpose! \\(\\dim(N(\\A)) = n - r\\) by Rank-Nullity Theorem . \\(\\dim(N(\\A^\\top)) = m - r\\) because rank of \\(\\A^\\top = r\\) and by Rank-Nullity Theorem this holds.","title":"Dimensions of Four Subspaces"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.08_linear_algebra_matrix_theory_matrix_spaces_summary/#table-of-contents","text":"Firstly, recall the solution set of a homogeneous system of linear equations remains unchanged after row operations (i.e. Gaussian-Jordan). Secondly, define rank of a matrix to be the number of pivots after RREF . So \\(\\A\\x = \\0\\) becomes \\(\\U\\x = \\0\\) . Rank of a matrix is the number of pivot columns, and therefore is the dimension of the column space","title":"Table of Contents"},{"location":"reighns_ml_journey/mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.09_linear_algebra_systems_of_linear_equations_revisited/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\nullity}{\\textbf{nullity}} \\newcommand{\\C}{\\mathbf{C}}\\] Read pp.137 onwards of Henry's book.","title":"05.09 linear algebra systems of linear equations revisited"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\e}{\\mathbf{e}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\null}{\\textbf{null}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\U}{\\mathrm{U}} \\newcommand{\\V}{\\mathrm{V}} \\newcommand{\\W}{\\mathrm{W}} \\newcommand{\\L}{\\mathcal{L}} \\] Disclaimer This chapter/section borrows and reference heavily from the book Sheldon Axler: Linear Algebra Done Right, 2015 . What is Completely Determined? In the text below, you will see the phrase completely determined . This can be confusing. A vector subspace \\(\\V\\) is completely determined by the set of basis vectors . This example illustrates that, if were to know the basis vectors \\(\\v_1, ..., \\v_n\\) , we can construct the entire vector subspace \\(\\V\\) . Linear Transformation Definition (Linear Transformation/Map) Let \\(\\V\\) and \\(\\W\\) be two vector spaces over the same field \\(\\F\\) . The mapping (function) \\(T: \\V \\to \\W\\) is called a linear transformation from vector spaces \\(\\V\\) to \\(\\W\\) with the following properties: additivity: \\(T(\\u + \\v) = T(\\u) + T(\\v)\\) for all \\(\\u, \\v \\in \\V\\) . homogeneity: \\(T\\left(\\lambda(\\v)\\right) = \\lambda(T(\\v))\\) for all \\(\\lambda \\in \\F\\) and all \\(\\v \\in \\V\\) . Notation (Linear Transformation/Map) The set of all linear maps from \\(\\V\\) to \\(\\W\\) is denoted \\(\\L(\\V, \\W)\\) . To be more explicit, this set is every possible linear transformation from the vector space \\(\\V\\) to \\(\\W\\) over \\(\\F\\) . Example (Linear Transformation/Map) The Zero Mapping Let \\(\\V\\) and \\(\\W\\) be two vector subspaces in \\(\\F\\) . Then the mapping function \\(0\\) maps any element \\(\\v \\in \\V\\) to the zero vector \\(\\0_W \\in \\W\\) where \\(\\0_{\\W}\\) is the zero (additive) element in the subspace \\(\\W\\) . \\[ \\begin{eqnarray} 0: \\V & \\rightarrow & \\W \\nonumber \\\\ \\v & \\mapsto & \\0_{\\W} \\nonumber \\end{eqnarray} \\] This is a linear transformation and called the zero linear transformation from \\(\\V\\) to \\(\\W\\) . The Identity Mapping Let \\(\\V\\) be a vector subspace in \\(\\F\\) . Then the mapping function \\(I\\) maps any element \\(\\v \\in \\V\\) to the itself \\(\\v \\in \\V\\) . \\[ \\begin{eqnarray} I: \\V & \\rightarrow & \\V \\nonumber \\\\ \\v & \\mapsto & \\v \\nonumber \\end{eqnarray} \\] This is a linear transformation and called the identity linear transformation from \\(\\V\\) to \\(\\V\\) . For more examples, read here 1 . Non-Linear Mapping The mapping \\[ \\begin{eqnarray} T : \\F^{3} & \\rightarrow & \\F^{3} \\nonumber \\\\ (x, y, z) & \\mapsto & (0, x+y+z, 1) \\nonumber \\end{eqnarray} \\] is not a linear transformations assuming \\(|\\F|\\ge 3\\) . This is because note that \\(\\0\\) vector must map to \\(\\0\\) vector, if not, it is not a linear transformation because it does not fulfill homogeneity (consider \\(\\v = \\0\\) and \\(\\lambda = 2\\) , then \\(T(2(\\0)) \\neq 2(T(\\0)\\) . Theorem (Linear Transformation Maps 0 to 0) Suppose \\(T\\) is a linear transformation from \\(\\V\\) to \\(\\W\\) , then: \\[ T(\\0_\\V) = \\0_\\W \\] This is useful for checking if a linear transformation is valid because the contrapositive says: If \\(\\0_\\V\\) does not map to \\(\\0_\\W\\) , then \\(T\\) is not a linear transformation . Theorem (Equivalent Linear Transformation Definition) Let \\[T: \\V \\rightarrow \\W\\] be a map between two vector spaces over the same field \\(\\F\\) . Then the following are equivalent. \\(T\\) is a linear transformation. For any \\(\\v_1, \\v_2 \\in \\V\\) and \\(\\lambda_1, \\lambda_2 \\in \\F\\) , we have the following: \\( \\(T(\\lambda_1\\v_1 + \\lambda_2\\v_2) = \\lambda_1 T(\\v_1) + \\lambda_2 T(\\v_2)\\) \\) Theorem (Linear Transformation/Maps are entirely determined by the basis vectors) An extremely important theorem! The existence part of the next result means that we can find a linear map that takes on whatever values we wish on the vectors in a basis. The uniqueness part of the next result means that a linear map is completely determined by its values on a basis. - Sheldon Axler: Linear Algebra Done Right, 2015. pp. 54 Let \\(\\V\\) and \\(\\W\\) be vector spaces over \\(\\F\\) . Suppose \\(\\v_1, ..., \\v_n\\) is a basis of \\(\\V\\) and \\(\\w_1, ..., \\w_n\\) be a set of arbitrary vectors in \\(\\W\\) . Then there exists an unique linear map \\(T: \\V \\to \\W\\) such that \\[ T(\\v_j) = \\w_j , \\quad \\forall j = 1, ..., n \\] This implies that if we know the basis vectors of \\(\\V\\) and Proof (Linear Transformation/Maps are entirely determined by the basis vectors) This mathematical proof is non-trivial and requires two components: We need to prove the existence of \\(T\\) , that such a linear transformation \\(T\\) exists (i.e. fulfilling the properties in the definition). We need to show uniqueness of such \\(T\\) , that is equivalent to asking: given another mapping \\(T^{'}: \\V \\to \\W\\) and assume that \\(T(\\v) = T^{'}(\\v) , \\forall i\\) , then \\(T = T^{'}\\) . Neither parts of the proof are trivial, and can be referenced here 2 . I will be more verbose in this proof to be clear to myself. Existence To show existence , we need to show that given the basis vectors \\(\\v_1, ..., \\v_n\\) of \\(\\V\\) and any set of arbitrary vectors \\(\\w_1, ..., \\w_n\\) of \\(\\W\\) , the mapping \\(T\\) indeed maps \\(\\v_j\\) to \\(\\w_j\\) where \\(j = 1, ..., n\\) , specifically, the basis vectors of \\(\\V\\) all have a mapping to the corresponding vectors in \\(\\W\\) . The implicit assumption in this part is that the map \\(T\\) is also well-defined , which we will outline below. Define and construct \\(T: \\V \\to \\W\\) where we want to map any element \\(\\v \\in \\V\\) to some \\(\\w \\in \\W\\) , define \\(\\v = c_1 \\v_1 + ... + c_n \\v_n\\) and the corresponding \\(\\w = c_1 \\w_1 + ... + c_n \\w_n\\) . \\[ T(c_1 \\v_1 + ... + c_n \\v_n) = c_1 \\w_1 + ... + c_n \\w_n \\] At this stage we are not assuming anything about \\(T\\) 's linearity, we are just constructing a linear equation in hope that this coincides with what we want (i.e. showing the existence of such \\(T\\) ). Note also \\(c\\) is arbitrary in \\(\\F\\) . The domain \\(\\V\\) is well defined because for any \\(\\v \\in \\V\\) , \\(\\v\\) can be written as \\(\\v = c_1 \\v_1 + ... + c_n \\v_n\\) and has an unique representation. Consequently, the mapping is well defined. Next, we just need to show that the additivity and homogeneity properties to complete the proof on existence. Uniqueness We can show uniqueness by: given another mapping \\(T^{'}: \\V \\to \\W\\) and assume that \\(T(\\v) = T^{'}(\\v) , \\forall i\\) , then \\(T = T^{'}\\) . Example (Linear Transformation/Maps are entirely determined by the basis vectors) https://math.stackexchange.com/questions/4114034/is-a-linear-map-uniquely-determined-on-v-or-on-a-basis-of-v Suppose I have a transformation \\(T: \\mathbb{R}^2 \\to \\mathbb{R}\\) . Pick a basis \\(B=\\{\\e_1=(1,0), \\e_2=(0,1) \\}\\) . Then \\(T\\) is completely specified by the values \\(\\w_1=T(\\e_1),\\w_2=T(\\e_2)\\) . To elaborate from the post, the OP mentioned that now he understood that once \\(T\\) is determined by \\(\\w_j\\) on \\(\\v_j\\) , then this \\(T\\) is unique on \\(\\V\\) . My understanding of determined is that we need to know both \\(\\v_1, \\v_2\\) (the basis vectors of \\(\\V = \\mathbb{R}^2\\) ) and the output \\(\\w_1 = T(\\e_1), \\w_2 = T(\\e_2)\\) . Consequently, we need to pick any vectors \\(\\w_1, \\w_2 \\in \\W\\) , say \\(\\w_1 = (1, 1), \\w_2 = (2, 0)\\) then only can we say that this particular mapping \\(T\\) is uniquely and entirely determined by \\(\\w_j\\) on \\(\\v_j\\) ? Algebraic Operations on Linear Transformation Definition (Addition and Scalar-Multiplication) Suppose \\(S, T \\in \\L(\\V, \\W)\\) and \\(\\lambda \\in \\F\\) . We define the addition \\(S + T\\) as: \\( \\((S+T)(\\v) = S(\\v) + T(\\v)\\) \\) And define the scalar-multiplication \\(\\lambda T\\) as: \\( \\(\\lambda T(\\v) = T(\\lambda\\v)\\) \\) for all \\(\\v \\in \\V\\) . In particular, both \\(S+T\\) and \\(\\lambda T\\) are in itself linear transformations . Corollary (The set of Linear Transformations is a Vector Space) \\(\\L(\\V, \\W)\\) is a vector space . Definition (Composite of Linear Transformations) Let \\(S\\) and \\(T\\) be linear transformations in \\(\\L(\\V, \\U)\\) and \\(\\L(\\U, \\W)\\) respectively: \\[ S: \\V \\to \\U \\] \\[ T: \\U \\to \\W \\] then the composite map is also a linear transformation given by: \\[ S \\circ T: \\V \\to \\W \\] where \\((S \\circ T)(\\v) = S \\circ (T(\\v)\\) . Properties of Linear Transformations Associativity Identity Distributive Properties Non-Commutative Sheldon Axler: Linear Algebra Done Right, 2015. pp. 52-53 \u21a9 Sheldon Axler: Linear Algebra Done Right, 2015. pp. 54 \u21a9","title":"Linear Transformation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#disclaimer","text":"This chapter/section borrows and reference heavily from the book Sheldon Axler: Linear Algebra Done Right, 2015 .","title":"Disclaimer"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#what-is-completely-determined","text":"In the text below, you will see the phrase completely determined . This can be confusing. A vector subspace \\(\\V\\) is completely determined by the set of basis vectors . This example illustrates that, if were to know the basis vectors \\(\\v_1, ..., \\v_n\\) , we can construct the entire vector subspace \\(\\V\\) .","title":"What is Completely Determined?"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#linear-transformation","text":"","title":"Linear Transformation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#definition-linear-transformationmap","text":"Let \\(\\V\\) and \\(\\W\\) be two vector spaces over the same field \\(\\F\\) . The mapping (function) \\(T: \\V \\to \\W\\) is called a linear transformation from vector spaces \\(\\V\\) to \\(\\W\\) with the following properties: additivity: \\(T(\\u + \\v) = T(\\u) + T(\\v)\\) for all \\(\\u, \\v \\in \\V\\) . homogeneity: \\(T\\left(\\lambda(\\v)\\right) = \\lambda(T(\\v))\\) for all \\(\\lambda \\in \\F\\) and all \\(\\v \\in \\V\\) .","title":"Definition (Linear Transformation/Map)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#notation-linear-transformationmap","text":"The set of all linear maps from \\(\\V\\) to \\(\\W\\) is denoted \\(\\L(\\V, \\W)\\) . To be more explicit, this set is every possible linear transformation from the vector space \\(\\V\\) to \\(\\W\\) over \\(\\F\\) .","title":"Notation (Linear Transformation/Map)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#example-linear-transformationmap","text":"","title":"Example (Linear Transformation/Map)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#the-zero-mapping","text":"Let \\(\\V\\) and \\(\\W\\) be two vector subspaces in \\(\\F\\) . Then the mapping function \\(0\\) maps any element \\(\\v \\in \\V\\) to the zero vector \\(\\0_W \\in \\W\\) where \\(\\0_{\\W}\\) is the zero (additive) element in the subspace \\(\\W\\) . \\[ \\begin{eqnarray} 0: \\V & \\rightarrow & \\W \\nonumber \\\\ \\v & \\mapsto & \\0_{\\W} \\nonumber \\end{eqnarray} \\] This is a linear transformation and called the zero linear transformation from \\(\\V\\) to \\(\\W\\) .","title":"The Zero Mapping"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#the-identity-mapping","text":"Let \\(\\V\\) be a vector subspace in \\(\\F\\) . Then the mapping function \\(I\\) maps any element \\(\\v \\in \\V\\) to the itself \\(\\v \\in \\V\\) . \\[ \\begin{eqnarray} I: \\V & \\rightarrow & \\V \\nonumber \\\\ \\v & \\mapsto & \\v \\nonumber \\end{eqnarray} \\] This is a linear transformation and called the identity linear transformation from \\(\\V\\) to \\(\\V\\) . For more examples, read here 1 .","title":"The Identity Mapping"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#non-linear-mapping","text":"The mapping \\[ \\begin{eqnarray} T : \\F^{3} & \\rightarrow & \\F^{3} \\nonumber \\\\ (x, y, z) & \\mapsto & (0, x+y+z, 1) \\nonumber \\end{eqnarray} \\] is not a linear transformations assuming \\(|\\F|\\ge 3\\) . This is because note that \\(\\0\\) vector must map to \\(\\0\\) vector, if not, it is not a linear transformation because it does not fulfill homogeneity (consider \\(\\v = \\0\\) and \\(\\lambda = 2\\) , then \\(T(2(\\0)) \\neq 2(T(\\0)\\) .","title":"Non-Linear Mapping"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#theorem-linear-transformation-maps-0-to-0","text":"Suppose \\(T\\) is a linear transformation from \\(\\V\\) to \\(\\W\\) , then: \\[ T(\\0_\\V) = \\0_\\W \\] This is useful for checking if a linear transformation is valid because the contrapositive says: If \\(\\0_\\V\\) does not map to \\(\\0_\\W\\) , then \\(T\\) is not a linear transformation .","title":"Theorem (Linear Transformation Maps 0 to 0)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#theorem-equivalent-linear-transformation-definition","text":"Let \\[T: \\V \\rightarrow \\W\\] be a map between two vector spaces over the same field \\(\\F\\) . Then the following are equivalent. \\(T\\) is a linear transformation. For any \\(\\v_1, \\v_2 \\in \\V\\) and \\(\\lambda_1, \\lambda_2 \\in \\F\\) , we have the following: \\( \\(T(\\lambda_1\\v_1 + \\lambda_2\\v_2) = \\lambda_1 T(\\v_1) + \\lambda_2 T(\\v_2)\\) \\)","title":"Theorem (Equivalent Linear Transformation Definition)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#theorem-linear-transformationmaps-are-entirely-determined-by-the-basis-vectors","text":"An extremely important theorem! The existence part of the next result means that we can find a linear map that takes on whatever values we wish on the vectors in a basis. The uniqueness part of the next result means that a linear map is completely determined by its values on a basis. - Sheldon Axler: Linear Algebra Done Right, 2015. pp. 54 Let \\(\\V\\) and \\(\\W\\) be vector spaces over \\(\\F\\) . Suppose \\(\\v_1, ..., \\v_n\\) is a basis of \\(\\V\\) and \\(\\w_1, ..., \\w_n\\) be a set of arbitrary vectors in \\(\\W\\) . Then there exists an unique linear map \\(T: \\V \\to \\W\\) such that \\[ T(\\v_j) = \\w_j , \\quad \\forall j = 1, ..., n \\] This implies that if we know the basis vectors of \\(\\V\\) and","title":"Theorem (Linear Transformation/Maps are entirely determined by the basis vectors)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#proof-linear-transformationmaps-are-entirely-determined-by-the-basis-vectors","text":"This mathematical proof is non-trivial and requires two components: We need to prove the existence of \\(T\\) , that such a linear transformation \\(T\\) exists (i.e. fulfilling the properties in the definition). We need to show uniqueness of such \\(T\\) , that is equivalent to asking: given another mapping \\(T^{'}: \\V \\to \\W\\) and assume that \\(T(\\v) = T^{'}(\\v) , \\forall i\\) , then \\(T = T^{'}\\) . Neither parts of the proof are trivial, and can be referenced here 2 . I will be more verbose in this proof to be clear to myself. Existence To show existence , we need to show that given the basis vectors \\(\\v_1, ..., \\v_n\\) of \\(\\V\\) and any set of arbitrary vectors \\(\\w_1, ..., \\w_n\\) of \\(\\W\\) , the mapping \\(T\\) indeed maps \\(\\v_j\\) to \\(\\w_j\\) where \\(j = 1, ..., n\\) , specifically, the basis vectors of \\(\\V\\) all have a mapping to the corresponding vectors in \\(\\W\\) . The implicit assumption in this part is that the map \\(T\\) is also well-defined , which we will outline below. Define and construct \\(T: \\V \\to \\W\\) where we want to map any element \\(\\v \\in \\V\\) to some \\(\\w \\in \\W\\) , define \\(\\v = c_1 \\v_1 + ... + c_n \\v_n\\) and the corresponding \\(\\w = c_1 \\w_1 + ... + c_n \\w_n\\) . \\[ T(c_1 \\v_1 + ... + c_n \\v_n) = c_1 \\w_1 + ... + c_n \\w_n \\] At this stage we are not assuming anything about \\(T\\) 's linearity, we are just constructing a linear equation in hope that this coincides with what we want (i.e. showing the existence of such \\(T\\) ). Note also \\(c\\) is arbitrary in \\(\\F\\) . The domain \\(\\V\\) is well defined because for any \\(\\v \\in \\V\\) , \\(\\v\\) can be written as \\(\\v = c_1 \\v_1 + ... + c_n \\v_n\\) and has an unique representation. Consequently, the mapping is well defined. Next, we just need to show that the additivity and homogeneity properties to complete the proof on existence. Uniqueness We can show uniqueness by: given another mapping \\(T^{'}: \\V \\to \\W\\) and assume that \\(T(\\v) = T^{'}(\\v) , \\forall i\\) , then \\(T = T^{'}\\) .","title":"Proof (Linear Transformation/Maps are entirely determined by the basis vectors)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#example-linear-transformationmaps-are-entirely-determined-by-the-basis-vectors","text":"https://math.stackexchange.com/questions/4114034/is-a-linear-map-uniquely-determined-on-v-or-on-a-basis-of-v Suppose I have a transformation \\(T: \\mathbb{R}^2 \\to \\mathbb{R}\\) . Pick a basis \\(B=\\{\\e_1=(1,0), \\e_2=(0,1) \\}\\) . Then \\(T\\) is completely specified by the values \\(\\w_1=T(\\e_1),\\w_2=T(\\e_2)\\) . To elaborate from the post, the OP mentioned that now he understood that once \\(T\\) is determined by \\(\\w_j\\) on \\(\\v_j\\) , then this \\(T\\) is unique on \\(\\V\\) . My understanding of determined is that we need to know both \\(\\v_1, \\v_2\\) (the basis vectors of \\(\\V = \\mathbb{R}^2\\) ) and the output \\(\\w_1 = T(\\e_1), \\w_2 = T(\\e_2)\\) . Consequently, we need to pick any vectors \\(\\w_1, \\w_2 \\in \\W\\) , say \\(\\w_1 = (1, 1), \\w_2 = (2, 0)\\) then only can we say that this particular mapping \\(T\\) is uniquely and entirely determined by \\(\\w_j\\) on \\(\\v_j\\) ?","title":"Example (Linear Transformation/Maps are entirely determined by the basis vectors)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#algebraic-operations-on-linear-transformation","text":"","title":"Algebraic Operations on Linear Transformation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#definition-addition-and-scalar-multiplication","text":"Suppose \\(S, T \\in \\L(\\V, \\W)\\) and \\(\\lambda \\in \\F\\) . We define the addition \\(S + T\\) as: \\( \\((S+T)(\\v) = S(\\v) + T(\\v)\\) \\) And define the scalar-multiplication \\(\\lambda T\\) as: \\( \\(\\lambda T(\\v) = T(\\lambda\\v)\\) \\) for all \\(\\v \\in \\V\\) . In particular, both \\(S+T\\) and \\(\\lambda T\\) are in itself linear transformations .","title":"Definition (Addition and Scalar-Multiplication)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#corollary-the-set-of-linear-transformations-is-a-vector-space","text":"\\(\\L(\\V, \\W)\\) is a vector space .","title":"Corollary (The set of Linear Transformations is a Vector Space)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#definition-composite-of-linear-transformations","text":"Let \\(S\\) and \\(T\\) be linear transformations in \\(\\L(\\V, \\U)\\) and \\(\\L(\\U, \\W)\\) respectively: \\[ S: \\V \\to \\U \\] \\[ T: \\U \\to \\W \\] then the composite map is also a linear transformation given by: \\[ S \\circ T: \\V \\to \\W \\] where \\((S \\circ T)(\\v) = S \\circ (T(\\v)\\) .","title":"Definition (Composite of Linear Transformations)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/#properties-of-linear-transformations","text":"Associativity Identity Distributive Properties Non-Commutative Sheldon Axler: Linear Algebra Done Right, 2015. pp. 52-53 \u21a9 Sheldon Axler: Linear Algebra Done Right, 2015. pp. 54 \u21a9","title":"Properties of Linear Transformations"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.02_linear_algebra_linear_transformations_nullspace/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\e}{\\mathbf{e}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\null}{\\textbf{null}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\U}{\\mathrm{U}} \\newcommand{\\V}{\\mathrm{V}} \\newcommand{\\W}{\\mathrm{W}} \\newcommand{\\L}{\\mathcal{L}} \\] Null Space Definition (Nullspace of \\(T\\) ) For any \\(T: \\V \\to \\W \\in L(\\V, \\W)\\) , the nullspace of \\(T\\) denoted as \\(\\null(T)\\) is the subset of vectors in \\(\\V\\) that are mapped to the zero vector \\(\\0_\\W\\) by \\(T\\) . \\[ \\null(T) = \\{\\v \\in \\V ~|~ T(\\v) = \\0_\\W\\} \\] Definition (Nullspace of \\(T\\) is nullspace of \\(\\A\\) ) As per title. Example (Nullspace of Differentiation) Let \\(T \\in \\L(\\F[\\z], \\F[\\z])\\) be the differentiation map \\(T(f(\\z)) = f^{'}(\\z)\\) . Then the nullspace of \\(T\\) is: \\[ \\null(T) = \\{f \\in \\F[\\z] ~|~ f(\\z) \\text{ is constant}\\} \\] which is apparent because the only way a function's derivative is zero is if the function is a constant. Theorem (Nullspace is a Subspace) Given any \\(T: \\V \\to \\W\\) in \\(\\L(\\V, \\W)\\) , the nullspace of \\(T\\) is a subspace of \\(\\V\\) . We have already seen that in matrix theory. Definition (Injective) Many of us are familiar with what is an injective map , for those who aren't, here is the definition: A function or mapping \\(f: X \\to Y\\) is injective if and only if \\(T(x) = T(y) \\implies x = y\\) . Note the contrapositive applies here as well: If \\(x \\neq y \\implies T(x) \\neq T(y)\\) then \\(f\\) is not njective . Theorem (Nullspace and Injectivity) Let \\(T \\in \\L(\\V, \\W)\\) , then \\(T\\) is injective if and only if the \\(\\null(T) = \\{\\0\\}\\) . In matrix terminology: Let \\(T_{\\A} \\in \\L(\\V, \\W)\\) , then \\(T_{\\A}\\) is injective if and only if the \\(\\null(T_{\\A}) = \\{\\0\\}\\) if and only if the nullity of \\(\\A\\) is zero (i.e. dimension of the nullspace of the matrix \\(\\A\\) is zero). Intuition (Nullspace and Injectivity) Proving this theorem alone shows you understand the algebraic logic, but we can go one step further and try to get more intuition of what this theorem means. Well, for one, we know that \\(\\null(T) = \\0\\) means that the matrix \\(\\A\\) associated with this \\(T\\) is full-rank, that is to say, \\(\\A\\x = \\0\\) has only the trivial solution. We can immediately have a corollary. Corollary (Nullspace and Injectivity implies Full-Rank) If \\(T\\) is an injective map, then the matrix associated with \\(T\\) is full-rank. Example (Injective Maps) Let \\(T: \\F[\\z] \\to \\F[\\z]\\) be the differentiation map. Note \\(T(f(\\z)) = f^{'}(\\z)\\) . The differentiation map \\(f(\\z) \\mapsto f^{'}(\\z)\\) is not injective because if you take \\(T(f(\\z)) = T(g(\\z))\\) , we must recover \\(f(\\z) = g(\\z)\\) , but in fact this is not true. Set \\(g(\\z) = f(\\z) + c\\) where \\(c \\neq 0 \\in \\F\\) is a constant, then \\(f(\\z) \\neq g(\\z)\\) by construction and hence not injective.","title":"Nullspace"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.02_linear_algebra_linear_transformations_nullspace/#null-space","text":"","title":"Null Space"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.02_linear_algebra_linear_transformations_nullspace/#definition-nullspace-of-t","text":"For any \\(T: \\V \\to \\W \\in L(\\V, \\W)\\) , the nullspace of \\(T\\) denoted as \\(\\null(T)\\) is the subset of vectors in \\(\\V\\) that are mapped to the zero vector \\(\\0_\\W\\) by \\(T\\) . \\[ \\null(T) = \\{\\v \\in \\V ~|~ T(\\v) = \\0_\\W\\} \\]","title":"Definition (Nullspace of \\(T\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.02_linear_algebra_linear_transformations_nullspace/#definition-nullspace-of-t-is-nullspace-of-a","text":"As per title.","title":"Definition (Nullspace of \\(T\\) is nullspace of \\(\\A\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.02_linear_algebra_linear_transformations_nullspace/#example-nullspace-of-differentiation","text":"Let \\(T \\in \\L(\\F[\\z], \\F[\\z])\\) be the differentiation map \\(T(f(\\z)) = f^{'}(\\z)\\) . Then the nullspace of \\(T\\) is: \\[ \\null(T) = \\{f \\in \\F[\\z] ~|~ f(\\z) \\text{ is constant}\\} \\] which is apparent because the only way a function's derivative is zero is if the function is a constant.","title":"Example (Nullspace of Differentiation)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.02_linear_algebra_linear_transformations_nullspace/#theorem-nullspace-is-a-subspace","text":"Given any \\(T: \\V \\to \\W\\) in \\(\\L(\\V, \\W)\\) , the nullspace of \\(T\\) is a subspace of \\(\\V\\) . We have already seen that in matrix theory.","title":"Theorem (Nullspace is a Subspace)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.02_linear_algebra_linear_transformations_nullspace/#definition-injective","text":"Many of us are familiar with what is an injective map , for those who aren't, here is the definition: A function or mapping \\(f: X \\to Y\\) is injective if and only if \\(T(x) = T(y) \\implies x = y\\) . Note the contrapositive applies here as well: If \\(x \\neq y \\implies T(x) \\neq T(y)\\) then \\(f\\) is not njective .","title":"Definition (Injective)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.02_linear_algebra_linear_transformations_nullspace/#theorem-nullspace-and-injectivity","text":"Let \\(T \\in \\L(\\V, \\W)\\) , then \\(T\\) is injective if and only if the \\(\\null(T) = \\{\\0\\}\\) . In matrix terminology: Let \\(T_{\\A} \\in \\L(\\V, \\W)\\) , then \\(T_{\\A}\\) is injective if and only if the \\(\\null(T_{\\A}) = \\{\\0\\}\\) if and only if the nullity of \\(\\A\\) is zero (i.e. dimension of the nullspace of the matrix \\(\\A\\) is zero).","title":"Theorem (Nullspace and Injectivity)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.02_linear_algebra_linear_transformations_nullspace/#intuition-nullspace-and-injectivity","text":"Proving this theorem alone shows you understand the algebraic logic, but we can go one step further and try to get more intuition of what this theorem means. Well, for one, we know that \\(\\null(T) = \\0\\) means that the matrix \\(\\A\\) associated with this \\(T\\) is full-rank, that is to say, \\(\\A\\x = \\0\\) has only the trivial solution. We can immediately have a corollary.","title":"Intuition (Nullspace and Injectivity)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.02_linear_algebra_linear_transformations_nullspace/#corollary-nullspace-and-injectivity-implies-full-rank","text":"If \\(T\\) is an injective map, then the matrix associated with \\(T\\) is full-rank.","title":"Corollary (Nullspace and Injectivity implies Full-Rank)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.02_linear_algebra_linear_transformations_nullspace/#example-injective-maps","text":"Let \\(T: \\F[\\z] \\to \\F[\\z]\\) be the differentiation map. Note \\(T(f(\\z)) = f^{'}(\\z)\\) . The differentiation map \\(f(\\z) \\mapsto f^{'}(\\z)\\) is not injective because if you take \\(T(f(\\z)) = T(g(\\z))\\) , we must recover \\(f(\\z) = g(\\z)\\) , but in fact this is not true. Set \\(g(\\z) = f(\\z) + c\\) where \\(c \\neq 0 \\in \\F\\) is a constant, then \\(f(\\z) \\neq g(\\z)\\) by construction and hence not injective.","title":"Example (Injective Maps)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.03_linear_algebra_linear_transformations_ranges/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\e}{\\mathbf{e}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\null}{\\textbf{null}} \\newcommand{\\range}{\\textbf{range}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\U}{\\mathrm{U}} \\newcommand{\\V}{\\mathrm{V}} \\newcommand{\\W}{\\mathrm{W}} \\newcommand{\\L}{\\mathcal{L}} \\] Range Definition (Range of \\(T\\) ) For any \\(T: \\V \\to \\W \\in L(\\V, \\W)\\) , the range of \\(T\\) denoted as \\(\\range(T)\\) is the subset of vectors in \\(\\W\\) that are in the image of \\(T\\) , more concretely: \\[ \\range(T) = \\{T(\\v) ~|~ \\v \\in \\V\\} = \\{\\w \\in \\W ~|~ \\exists \\v \\in \\V \\text{ s.t. } T(\\v) = \\w\\} \\] Definition (Range of T is column space of A) Example (Range of Differentiation) Let \\(T \\in \\L(\\F[\\z], \\F[\\z])\\) be the differentiation map \\(T(f(\\z)) = f^{'}(\\z)\\) . Then the range of \\(T\\) is: \\[ \\range(T) = \\F[\\z] \\] since for every polynomial \\(q \\in \\F[\\z]\\) , there exists a \\(p \\in \\F[\\z]\\) such that \\(p^{'} = q\\) . Theorem (Range is a Subspace) Given any \\(T: \\V \\to \\W\\) in \\(\\L(\\V, \\W)\\) , the range of \\(T\\) is a subspace of \\(\\W\\) . We have already seen that in matrix theory. Definition (Surjective) Many of us are familiar with what is an surjective map , for those who aren't, here is the definition: A function or mapping \\(f: X \\to Y\\) is surjective if and only if \\(f\\) is a function that maps an element \\(x \\in X\\) to every element \\(y \\in Y\\) . In other words, for every \\(y \\in Y\\) , there exists an \\(x \\in X\\) such that \\(f(x) = y\\) . Theorem (Range and Surjectivity) Let \\(T: \\V \\to \\W \\in \\L(\\V, \\W)\\) , then \\(T\\) is surjective if and only if the \\(\\range(T) = \\W\\) . In matrix terminology: Let \\(T_{\\A} \\in \\L(\\V, \\W)\\) , then \\(T_{\\A}\\) is surjective if and only if the rank of \\(\\A\\) is \\(m\\) .","title":"Range"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.03_linear_algebra_linear_transformations_ranges/#range","text":"","title":"Range"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.03_linear_algebra_linear_transformations_ranges/#definition-range-of-t","text":"For any \\(T: \\V \\to \\W \\in L(\\V, \\W)\\) , the range of \\(T\\) denoted as \\(\\range(T)\\) is the subset of vectors in \\(\\W\\) that are in the image of \\(T\\) , more concretely: \\[ \\range(T) = \\{T(\\v) ~|~ \\v \\in \\V\\} = \\{\\w \\in \\W ~|~ \\exists \\v \\in \\V \\text{ s.t. } T(\\v) = \\w\\} \\]","title":"Definition (Range of \\(T\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.03_linear_algebra_linear_transformations_ranges/#definition-range-of-t-is-column-space-of-a","text":"","title":"Definition (Range of T is column space of A)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.03_linear_algebra_linear_transformations_ranges/#example-range-of-differentiation","text":"Let \\(T \\in \\L(\\F[\\z], \\F[\\z])\\) be the differentiation map \\(T(f(\\z)) = f^{'}(\\z)\\) . Then the range of \\(T\\) is: \\[ \\range(T) = \\F[\\z] \\] since for every polynomial \\(q \\in \\F[\\z]\\) , there exists a \\(p \\in \\F[\\z]\\) such that \\(p^{'} = q\\) .","title":"Example (Range of Differentiation)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.03_linear_algebra_linear_transformations_ranges/#theorem-range-is-a-subspace","text":"Given any \\(T: \\V \\to \\W\\) in \\(\\L(\\V, \\W)\\) , the range of \\(T\\) is a subspace of \\(\\W\\) . We have already seen that in matrix theory.","title":"Theorem (Range is a Subspace)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.03_linear_algebra_linear_transformations_ranges/#definition-surjective","text":"Many of us are familiar with what is an surjective map , for those who aren't, here is the definition: A function or mapping \\(f: X \\to Y\\) is surjective if and only if \\(f\\) is a function that maps an element \\(x \\in X\\) to every element \\(y \\in Y\\) . In other words, for every \\(y \\in Y\\) , there exists an \\(x \\in X\\) such that \\(f(x) = y\\) .","title":"Definition (Surjective)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.03_linear_algebra_linear_transformations_ranges/#theorem-range-and-surjectivity","text":"Let \\(T: \\V \\to \\W \\in \\L(\\V, \\W)\\) , then \\(T\\) is surjective if and only if the \\(\\range(T) = \\W\\) . In matrix terminology: Let \\(T_{\\A} \\in \\L(\\V, \\W)\\) , then \\(T_{\\A}\\) is surjective if and only if the rank of \\(\\A\\) is \\(m\\) .","title":"Theorem (Range and Surjectivity)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.04_linear_algebra_linear_transformations_homomorphism/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\e}{\\mathbf{e}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\null}{\\textbf{null}} \\newcommand{\\range}{\\textbf{range}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\U}{\\mathrm{U}} \\newcommand{\\V}{\\mathrm{V}} \\newcommand{\\W}{\\mathrm{W}} \\newcommand{\\L}{\\mathcal{L}} \\] Homomorphisms Definition (Homomorphisms) Extracted from here , we have the following definition: Linear maps between vector spaces are called vector space homomorphisms , and instead of \\(\\L(\\V, \\W)\\) , we see the following notation: \\[ \\text{Hom}_{\\F}(\\V, \\W) = \\{T: \\V \\to \\W ~|~ T \\text{ is a linear map}\\} \\] Definition (Isomorphism and Bijective Linear Map) A homomorphism \\(T: \\V \\to \\W\\) is an isomorphism if and only if \\(T\\) is a bijective map , that is, \\(T\\) is both injective and surjective . Definition (Monomorphism and Bijective Linear Map) A homomorphism \\(T: \\V \\to \\W\\) is an monomorphism if and only if \\(T\\) is an injective map . Definition (Epimorphism and Bijective Linear Map) A homomorphism \\(T: \\V \\to \\W\\) is an epimorphism if and only if \\(T\\) is an surjective map . Definition (Endomorphism and Bijective Linear Map) A homomorphism \\(T: \\V \\to \\W\\) is an endomorphism if and only if \\(\\V = \\W\\) . Definition (Automorphism and Bijective Linear Map) A homomorphism \\(T: \\V \\to \\W\\) is an automorphism if and only if \\(\\V = \\W\\) and \\(T\\) is bijective .","title":"Homomorphism"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.04_linear_algebra_linear_transformations_homomorphism/#homomorphisms","text":"","title":"Homomorphisms"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.04_linear_algebra_linear_transformations_homomorphism/#definition-homomorphisms","text":"Extracted from here , we have the following definition: Linear maps between vector spaces are called vector space homomorphisms , and instead of \\(\\L(\\V, \\W)\\) , we see the following notation: \\[ \\text{Hom}_{\\F}(\\V, \\W) = \\{T: \\V \\to \\W ~|~ T \\text{ is a linear map}\\} \\]","title":"Definition (Homomorphisms)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.04_linear_algebra_linear_transformations_homomorphism/#definition-isomorphism-and-bijective-linear-map","text":"A homomorphism \\(T: \\V \\to \\W\\) is an isomorphism if and only if \\(T\\) is a bijective map , that is, \\(T\\) is both injective and surjective .","title":"Definition (Isomorphism and Bijective Linear Map)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.04_linear_algebra_linear_transformations_homomorphism/#definition-monomorphism-and-bijective-linear-map","text":"A homomorphism \\(T: \\V \\to \\W\\) is an monomorphism if and only if \\(T\\) is an injective map .","title":"Definition (Monomorphism and Bijective Linear Map)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.04_linear_algebra_linear_transformations_homomorphism/#definition-epimorphism-and-bijective-linear-map","text":"A homomorphism \\(T: \\V \\to \\W\\) is an epimorphism if and only if \\(T\\) is an surjective map .","title":"Definition (Epimorphism and Bijective Linear Map)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.04_linear_algebra_linear_transformations_homomorphism/#definition-endomorphism-and-bijective-linear-map","text":"A homomorphism \\(T: \\V \\to \\W\\) is an endomorphism if and only if \\(\\V = \\W\\) .","title":"Definition (Endomorphism and Bijective Linear Map)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.04_linear_algebra_linear_transformations_homomorphism/#definition-automorphism-and-bijective-linear-map","text":"A homomorphism \\(T: \\V \\to \\W\\) is an automorphism if and only if \\(\\V = \\W\\) and \\(T\\) is bijective .","title":"Definition (Automorphism and Bijective Linear Map)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.05_linear_algebra_linear_transformations_fundamental_theorem/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\e}{\\mathbf{e}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\null}{\\textbf{null}} \\newcommand{\\range}{\\textbf{range}} \\newcommand{\\dim}{\\textbf{dim}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\U}{\\mathrm{U}} \\newcommand{\\V}{\\mathrm{V}} \\newcommand{\\W}{\\mathrm{W}} \\newcommand{\\L}{\\mathcal{L}} \\] The Fundamental Theorem of Linear Transformation/Maps Definition (Nullity-Rank Theorem revisited) Let \\(T: \\V \\to \\W\\) be a linear transformation between vector spaces over a field \\(\\F\\) where we assume \\(\\V\\) is finite-dimensional and \\(\\range(T)\\) is finite as a consequence. Then \\[ \\dim_{\\F}(\\V) = \\dim\\left[\\null(T)\\right] + \\dim\\left[\\range(T)\\right] \\] In particular, if \\(\\A \\in M_{m \\times n}(\\F)\\) then the theorem recovers the nullity-rank theorem : \\[ \\text{nullity}(\\A) + \\text{rank}(\\A) = n \\] where \\(n\\) is the number of columns of \\(\\A\\) . Corollary (A map to a smaller dimensional space is not injective) A simple corollary 1 is that no linear map from a finite-dimensional vector space to a \"smaller\" vector space can be injective, where smaller means dimension. Suppose \\(\\V\\) and \\(\\W\\) are finite-dimensional vector spaces such that \\(\\dim(\\V) > \\dim(\\W)\\) , then no linear map from \\(\\V\\) to \\(\\W\\) is injective . Corollary (A map to a smaller dimensional space is not injective) A simple corollary 2 shows that no linear map from a finite-dimensional vector space to a \"bigger\" vector space can be surjective, where \"bigger\" is measured by dimension. Suppose \\(\\V\\) and \\(\\W\\) are finite-dimensional vector spaces such that \\(\\dim(\\V) < \\dim(\\W)\\) , then no linear map from \\(\\V\\) to \\(\\W\\) is surjective . Homogeneous System of Linear Equations Quite important, revisit pp.66-67 of Linear Algebra done right. Inhomogeneous system of linear equations Sheldon Axler: Linear Algebra Done Right, 2015; pp.64 \u21a9 Sheldon Axler: Linear Algebra Done Right, 2015; pp.64 \u21a9","title":"Fundamental Theorem"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.05_linear_algebra_linear_transformations_fundamental_theorem/#the-fundamental-theorem-of-linear-transformationmaps","text":"","title":"The Fundamental Theorem of Linear Transformation/Maps"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.05_linear_algebra_linear_transformations_fundamental_theorem/#definition-nullity-rank-theorem-revisited","text":"Let \\(T: \\V \\to \\W\\) be a linear transformation between vector spaces over a field \\(\\F\\) where we assume \\(\\V\\) is finite-dimensional and \\(\\range(T)\\) is finite as a consequence. Then \\[ \\dim_{\\F}(\\V) = \\dim\\left[\\null(T)\\right] + \\dim\\left[\\range(T)\\right] \\] In particular, if \\(\\A \\in M_{m \\times n}(\\F)\\) then the theorem recovers the nullity-rank theorem : \\[ \\text{nullity}(\\A) + \\text{rank}(\\A) = n \\] where \\(n\\) is the number of columns of \\(\\A\\) .","title":"Definition (Nullity-Rank Theorem revisited)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.05_linear_algebra_linear_transformations_fundamental_theorem/#corollary-a-map-to-a-smaller-dimensional-space-is-not-injective","text":"A simple corollary 1 is that no linear map from a finite-dimensional vector space to a \"smaller\" vector space can be injective, where smaller means dimension. Suppose \\(\\V\\) and \\(\\W\\) are finite-dimensional vector spaces such that \\(\\dim(\\V) > \\dim(\\W)\\) , then no linear map from \\(\\V\\) to \\(\\W\\) is injective .","title":"Corollary (A map to a smaller dimensional space is not injective)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.05_linear_algebra_linear_transformations_fundamental_theorem/#corollary-a-map-to-a-smaller-dimensional-space-is-not-injective_1","text":"A simple corollary 2 shows that no linear map from a finite-dimensional vector space to a \"bigger\" vector space can be surjective, where \"bigger\" is measured by dimension. Suppose \\(\\V\\) and \\(\\W\\) are finite-dimensional vector spaces such that \\(\\dim(\\V) < \\dim(\\W)\\) , then no linear map from \\(\\V\\) to \\(\\W\\) is surjective .","title":"Corollary (A map to a smaller dimensional space is not injective)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.05_linear_algebra_linear_transformations_fundamental_theorem/#homogeneous-system-of-linear-equations","text":"Quite important, revisit pp.66-67 of Linear Algebra done right.","title":"Homogeneous System of Linear Equations"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.05_linear_algebra_linear_transformations_fundamental_theorem/#inhomogeneous-system-of-linear-equations","text":"Sheldon Axler: Linear Algebra Done Right, 2015; pp.64 \u21a9 Sheldon Axler: Linear Algebra Done Right, 2015; pp.64 \u21a9","title":"Inhomogeneous system of linear equations"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.06_linear_algebra_linear_transformations_matrix/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\e}{\\mathbf{e}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\null}{\\textbf{null}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\U}{\\mathrm{U}} \\newcommand{\\V}{\\mathrm{V}} \\newcommand{\\W}{\\mathrm{W}} \\newcommand{\\L}{\\mathcal{L}} \\] Matrix and Linear Transformations This is a big topic and has its own spot in this chapter. We let \\[ \\A=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix} \\] Definition (Matrix is a Linear Transformation Naive) Let \\(\\A = (\\a_{ij}) \\in \\F^{m \\times n}\\) be an \\(m \\times n\\) matrix with entries in a field \\(\\F\\) . Let us first define the matrix-vector multiplication \\(\\A\\x = \\b\\) where \\(\\x \\in \\F^{n}\\) and \\(\\b \\in \\F^{m}\\) , and specifically, let \\(\\F^n\\) and \\(\\F^m\\) be our vector spaces \\(\\V\\) and \\(\\W\\) respectively. Define the map \\[T_{\\A}: \\F_{c}^{n} \\rightarrow F_{c}^{m}\\] \\[\\x = \\begin{bmatrix} x_{1}\\\\ x_{2}\\\\ x_{3}\\\\ \\vdots\\\\ x_{n} \\end{bmatrix} \\mapsto \\A\\x \\] Then \\(T_{\\A}\\) is a linear transformation (associated with the matrix \\(\\A\\) ) where we are mapping (sending) the vector \\(\\x\\) from \\(n\\) dimensional space to the vector \\(\\b = \\A\\x\\) in the \\(m\\) dimensional space . Important for readers: \\(T_{\\A}(\\x) = \\A\\x\\) . Proof (Matrix is a Linear Transformation) This definition deserves a proof, simply, because one should really internalize this and not gloss it over. Recall carefully that matrix operations such as: \\(\\A(\\x_1 + \\x_2) = \\A\\x_1 \\A\\x_2\\) \\(\\lambda(\\A\\x) = \\A(\\lambda(\\x))\\) are well-defined . With this, this directly carries over to our linear transformation , for any vectors \\(\\x_1, \\x_2 \\in \\F^n\\) and any \\(\\lambda \\in \\F\\) : additivity: \\(T_{\\A}(\\x_1 + \\x_2) = T_{\\A}(\\x_1) + T_{\\A}(\\x_2)\\) for all \\(\\x_1, \\x_2 \\in \\V=\\F^n\\) . homogeneity: \\(T_{\\A}\\left(\\lambda(\\x)\\right) = \\lambda(T_{\\A}(\\x))\\) for all \\(\\lambda \\in \\F\\) and all \\(\\x \\in \\V=\\F^n\\) . Definition (Matrix is a Linear Transformation Proper) The proper definition of matrix being a linear transformation is given below. Note that we will see that every linear transformation \\(T: \\V \\to \\W\\) can be defined and encoded by a matrix \\(\\A\\) , and conversely, every matrix also defines such a linear transformation . Let \\(T \\in \\L(\\V, \\W)\\) where \\(\\V\\) and \\(\\W\\) are finite-dimensional vector spaces, in particular, they are \\(n\\) and \\(m\\) dimensional respectively.. Since every vector space has a basis, we can define \\(\\v_1, ..., \\v_n\\) and \\(\\w_1, ..., \\w_m\\) to be the basis of \\(\\V\\) and \\(\\W\\) respectively . More concretely, every vector \\(\\v \\in \\V\\) is uniquely determined by the coefficients \\(c_1, ..., c_n \\in \\F\\) , that is, any vector \\(\\v\\) in the vector space \\(\\V\\) can be uniquely determined by the linear combination below: \\[ \\v = c_1 \\v_1 + ... + c_n \\v_n , \\quad \\forall \\v \\in \\V \\] If \\(T: \\V \\to \\W\\) is a linear transformation , then it follows that: \\[ T(c_1 \\v_1 + ... + c_n \\v_n) = c_1 T(\\v_1) + ... + c_nT(\\v_n) \\] by additivity . This implies that the mapping \\(T\\) is entirely determined by the vectors \\(T(\\v_1), ..., T(\\v_n)\\) . Now, we turn out attention to the basis vectors of \\(\\W\\) . We see that we can represent each vector \\(T(\\v_j)\\) as: \\[ T(\\v_j) = a_{1j} \\w_1 + ... + a_{mj}\\w_m \\] where \\(a_{ij}\\) is unique scalars in \\(\\F\\) as well. Thus the mapping \\(T\\) is also entirely determined by the values \\(a_{ij}\\) where \\(i\\) is from \\(1\\) to \\(m\\) . Last but not least, we define the matrix \\(\\A\\) associated with the mapping \\(T\\) with respect to these bases is the \\(m \\times n\\) matrix \\(T_{\\A}\\) whose entries \\(a_{ij}\\) are defined as: \\[ T(\\v_j) = a_{1j}\\w_1 + ... + a_{mj}\\w_m \\] As a consequence, the \\(j\\) -th column of \\(\\A\\) contains the coefficients of the \\(j\\) -th basis vector \\(\\v_j\\) where each element of \\(\\v_j\\) are the coefficients of the vector \\(\\w_j = T(\\v_j)\\) . \\[ \\A=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix} \\] This is a mouthful, so we understand it better with examples. Examples (Matrix is a Linear Transformation Proper) Standard Basis Linear Transformation Let \\(T \\in \\L(\\F^2, \\F^3)\\) be defined by: \\[ T(x, y) = (x+3y, 2x+5y, 7x+9y) \\] Then the \\(T_{\\A}\\) with respect to the standard bases in \\(\\F^2\\) and \\(\\F^3\\) is: Let \\(\\v_1 = [1, 0], \\quad \\v_2 = [0, 1]\\) be the basis of \\(\\F^2\\) and we see that \\[ \\w_1 = T(\\v_1) = (1, 2, 7), \\quad \\w_2 = T(\\v_2) = (3, 5, 9) \\] Construct the matrix \\[ \\A = \\begin{bmatrix} 1 & 3 \\\\ 2 & 5 \\\\ 7 & 9 \\end{bmatrix} \\] Example (Rotational Matrix) Define the following setup: 2 dimensional real space: \\(\\R^2\\) Define our domain and co-domain to be the same 2d-space (i.e. \\(\\V = \\W = \\R^2\\) ) Define basis vectors from \\(\\V\\) to be the standard basis \\(\\e_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\) and \\(\\e_2 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\) Now let me tell you first that a rotation 90 degrees anti-clockwise is a valid linear transformation and you can draw it to see geometrically that this rotation maps our basis vector \\(\\e_1\\) and \\(\\e_2\\) to \\(T(\\e_1) = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\) and \\(T(\\e_2) = \\begin{bmatrix} -1 \\\\ 0 \\end{bmatrix}\\) (you can check visually). Then the theorem of linear transformation tells us that if we know the set of basis vectors from the domain \\(\\V\\) , and correspondingly the mapping of these basis vectors (i.e in this case \\(T(\\e_1)\\) and \\(T(\\e_2)\\) ), we can then say that our mapping (rotational) is entirely determined and uniquely defined in \\(\\V\\) by \\(\\W\\) . In laymen, given any vector \\(\\v \\in \\V\\) , we can now fully determine where \\(\\v\\) is going to go to in \\(\\W\\) (in this case the same space) via the rotational mapping \\(T\\) . Note that the mapping \\(T\\) can also be in terms of matrix \\(\\A = \\begin{bmatrix}T(\\e_1) & T(\\e_2) \\end{bmatrix} = \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}\\) Thus, by the theorem of linear transformation, if we take an arbitrary vector say \\(\\v = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}\\) , then visually you know the 90 degrees rotation will go to \\(T(\\v) = \\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}\\) , but using algebra we can assert this is true by \\(T(\\v) = 1 \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} + 2 \\begin{bmatrix} -1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}\\) Lastly, recall the matrix-vector multiplication \\(\\A\\v = \\b\\) , then \\(\\A\\v = \\b\\) is the linear transformation where \\(\\A\\) is the rotational mapping in which the columns are \\(T(\\e_i)\\) , and \\(\\v\\) is any vector in the domain. Now we have a algebraic formula to denote the mapping. The Four Fundamental Subspaces Revisited We can now frame our Four (Favourite) Fundamental Subspaces in the lingo of linear transformation . TBD write this after section 3.B in LADR. Nullspace: The kernel of \\(T_{\\A}\\) equals the null space (or kernel) of \\(A\\) $$ \\text{Ker}(T_{A}) = \\text{Ker}(A) = \\text{Null}(A) = {\\x \\in F_{c}^{n} ~|~ A\\x = 0} \\subseteq F_{c}^{n}$$ The range (or image) of \\(T_{A}\\) equals the range of \\(A\\) : \\[R(T_{A}) = T_{A}(F_{c}^{n}) = R(A) : \\{A\\x ~|~ \\x \\in F_{c}^{n}\\} \\subseteq F_{c}^{m}\\] Note in particular, the Range of \\(A\\) is just the Column Space of \\(A\\) , that is if \\(A = (\\a_1,...,\\a_n)\\) , then \\( \\(\\text{Range}(A) = \\text{Span}\\{\\a_1,...,\\a_n\\}\\) \\) References https://math.stackexchange.com/questions/4376735/what-is-meant-by-the-linear-mapping-t-is-entirely-and-uniquely-determined-on/4376761#4376761 https://math.stackexchange.com/questions/4114034/is-a-linear-map-uniquely-determined-on-v-or-on-a-basis-of-v","title":"Linear Transformation and Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.06_linear_algebra_linear_transformations_matrix/#matrix-and-linear-transformations","text":"This is a big topic and has its own spot in this chapter. We let \\[ \\A=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix} \\]","title":"Matrix and Linear Transformations"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.06_linear_algebra_linear_transformations_matrix/#definition-matrix-is-a-linear-transformation-naive","text":"Let \\(\\A = (\\a_{ij}) \\in \\F^{m \\times n}\\) be an \\(m \\times n\\) matrix with entries in a field \\(\\F\\) . Let us first define the matrix-vector multiplication \\(\\A\\x = \\b\\) where \\(\\x \\in \\F^{n}\\) and \\(\\b \\in \\F^{m}\\) , and specifically, let \\(\\F^n\\) and \\(\\F^m\\) be our vector spaces \\(\\V\\) and \\(\\W\\) respectively. Define the map \\[T_{\\A}: \\F_{c}^{n} \\rightarrow F_{c}^{m}\\] \\[\\x = \\begin{bmatrix} x_{1}\\\\ x_{2}\\\\ x_{3}\\\\ \\vdots\\\\ x_{n} \\end{bmatrix} \\mapsto \\A\\x \\] Then \\(T_{\\A}\\) is a linear transformation (associated with the matrix \\(\\A\\) ) where we are mapping (sending) the vector \\(\\x\\) from \\(n\\) dimensional space to the vector \\(\\b = \\A\\x\\) in the \\(m\\) dimensional space . Important for readers: \\(T_{\\A}(\\x) = \\A\\x\\) .","title":"Definition (Matrix is a Linear Transformation Naive)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.06_linear_algebra_linear_transformations_matrix/#proof-matrix-is-a-linear-transformation","text":"This definition deserves a proof, simply, because one should really internalize this and not gloss it over. Recall carefully that matrix operations such as: \\(\\A(\\x_1 + \\x_2) = \\A\\x_1 \\A\\x_2\\) \\(\\lambda(\\A\\x) = \\A(\\lambda(\\x))\\) are well-defined . With this, this directly carries over to our linear transformation , for any vectors \\(\\x_1, \\x_2 \\in \\F^n\\) and any \\(\\lambda \\in \\F\\) : additivity: \\(T_{\\A}(\\x_1 + \\x_2) = T_{\\A}(\\x_1) + T_{\\A}(\\x_2)\\) for all \\(\\x_1, \\x_2 \\in \\V=\\F^n\\) . homogeneity: \\(T_{\\A}\\left(\\lambda(\\x)\\right) = \\lambda(T_{\\A}(\\x))\\) for all \\(\\lambda \\in \\F\\) and all \\(\\x \\in \\V=\\F^n\\) .","title":"Proof (Matrix is a Linear Transformation)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.06_linear_algebra_linear_transformations_matrix/#definition-matrix-is-a-linear-transformation-proper","text":"The proper definition of matrix being a linear transformation is given below. Note that we will see that every linear transformation \\(T: \\V \\to \\W\\) can be defined and encoded by a matrix \\(\\A\\) , and conversely, every matrix also defines such a linear transformation . Let \\(T \\in \\L(\\V, \\W)\\) where \\(\\V\\) and \\(\\W\\) are finite-dimensional vector spaces, in particular, they are \\(n\\) and \\(m\\) dimensional respectively.. Since every vector space has a basis, we can define \\(\\v_1, ..., \\v_n\\) and \\(\\w_1, ..., \\w_m\\) to be the basis of \\(\\V\\) and \\(\\W\\) respectively . More concretely, every vector \\(\\v \\in \\V\\) is uniquely determined by the coefficients \\(c_1, ..., c_n \\in \\F\\) , that is, any vector \\(\\v\\) in the vector space \\(\\V\\) can be uniquely determined by the linear combination below: \\[ \\v = c_1 \\v_1 + ... + c_n \\v_n , \\quad \\forall \\v \\in \\V \\] If \\(T: \\V \\to \\W\\) is a linear transformation , then it follows that: \\[ T(c_1 \\v_1 + ... + c_n \\v_n) = c_1 T(\\v_1) + ... + c_nT(\\v_n) \\] by additivity . This implies that the mapping \\(T\\) is entirely determined by the vectors \\(T(\\v_1), ..., T(\\v_n)\\) . Now, we turn out attention to the basis vectors of \\(\\W\\) . We see that we can represent each vector \\(T(\\v_j)\\) as: \\[ T(\\v_j) = a_{1j} \\w_1 + ... + a_{mj}\\w_m \\] where \\(a_{ij}\\) is unique scalars in \\(\\F\\) as well. Thus the mapping \\(T\\) is also entirely determined by the values \\(a_{ij}\\) where \\(i\\) is from \\(1\\) to \\(m\\) . Last but not least, we define the matrix \\(\\A\\) associated with the mapping \\(T\\) with respect to these bases is the \\(m \\times n\\) matrix \\(T_{\\A}\\) whose entries \\(a_{ij}\\) are defined as: \\[ T(\\v_j) = a_{1j}\\w_1 + ... + a_{mj}\\w_m \\] As a consequence, the \\(j\\) -th column of \\(\\A\\) contains the coefficients of the \\(j\\) -th basis vector \\(\\v_j\\) where each element of \\(\\v_j\\) are the coefficients of the vector \\(\\w_j = T(\\v_j)\\) . \\[ \\A=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix} \\] This is a mouthful, so we understand it better with examples.","title":"Definition (Matrix is a Linear Transformation Proper)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.06_linear_algebra_linear_transformations_matrix/#examples-matrix-is-a-linear-transformation-proper","text":"","title":"Examples (Matrix is a Linear Transformation Proper)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.06_linear_algebra_linear_transformations_matrix/#standard-basis-linear-transformation","text":"Let \\(T \\in \\L(\\F^2, \\F^3)\\) be defined by: \\[ T(x, y) = (x+3y, 2x+5y, 7x+9y) \\] Then the \\(T_{\\A}\\) with respect to the standard bases in \\(\\F^2\\) and \\(\\F^3\\) is: Let \\(\\v_1 = [1, 0], \\quad \\v_2 = [0, 1]\\) be the basis of \\(\\F^2\\) and we see that \\[ \\w_1 = T(\\v_1) = (1, 2, 7), \\quad \\w_2 = T(\\v_2) = (3, 5, 9) \\] Construct the matrix \\[ \\A = \\begin{bmatrix} 1 & 3 \\\\ 2 & 5 \\\\ 7 & 9 \\end{bmatrix} \\]","title":"Standard Basis Linear Transformation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.06_linear_algebra_linear_transformations_matrix/#example-rotational-matrix","text":"Define the following setup: 2 dimensional real space: \\(\\R^2\\) Define our domain and co-domain to be the same 2d-space (i.e. \\(\\V = \\W = \\R^2\\) ) Define basis vectors from \\(\\V\\) to be the standard basis \\(\\e_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\) and \\(\\e_2 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\) Now let me tell you first that a rotation 90 degrees anti-clockwise is a valid linear transformation and you can draw it to see geometrically that this rotation maps our basis vector \\(\\e_1\\) and \\(\\e_2\\) to \\(T(\\e_1) = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\) and \\(T(\\e_2) = \\begin{bmatrix} -1 \\\\ 0 \\end{bmatrix}\\) (you can check visually). Then the theorem of linear transformation tells us that if we know the set of basis vectors from the domain \\(\\V\\) , and correspondingly the mapping of these basis vectors (i.e in this case \\(T(\\e_1)\\) and \\(T(\\e_2)\\) ), we can then say that our mapping (rotational) is entirely determined and uniquely defined in \\(\\V\\) by \\(\\W\\) . In laymen, given any vector \\(\\v \\in \\V\\) , we can now fully determine where \\(\\v\\) is going to go to in \\(\\W\\) (in this case the same space) via the rotational mapping \\(T\\) . Note that the mapping \\(T\\) can also be in terms of matrix \\(\\A = \\begin{bmatrix}T(\\e_1) & T(\\e_2) \\end{bmatrix} = \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}\\) Thus, by the theorem of linear transformation, if we take an arbitrary vector say \\(\\v = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}\\) , then visually you know the 90 degrees rotation will go to \\(T(\\v) = \\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}\\) , but using algebra we can assert this is true by \\(T(\\v) = 1 \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} + 2 \\begin{bmatrix} -1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}\\) Lastly, recall the matrix-vector multiplication \\(\\A\\v = \\b\\) , then \\(\\A\\v = \\b\\) is the linear transformation where \\(\\A\\) is the rotational mapping in which the columns are \\(T(\\e_i)\\) , and \\(\\v\\) is any vector in the domain. Now we have a algebraic formula to denote the mapping.","title":"Example (Rotational Matrix)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.06_linear_algebra_linear_transformations_matrix/#the-four-fundamental-subspaces-revisited","text":"We can now frame our Four (Favourite) Fundamental Subspaces in the lingo of linear transformation . TBD write this after section 3.B in LADR. Nullspace: The kernel of \\(T_{\\A}\\) equals the null space (or kernel) of \\(A\\) $$ \\text{Ker}(T_{A}) = \\text{Ker}(A) = \\text{Null}(A) = {\\x \\in F_{c}^{n} ~|~ A\\x = 0} \\subseteq F_{c}^{n}$$ The range (or image) of \\(T_{A}\\) equals the range of \\(A\\) : \\[R(T_{A}) = T_{A}(F_{c}^{n}) = R(A) : \\{A\\x ~|~ \\x \\in F_{c}^{n}\\} \\subseteq F_{c}^{m}\\] Note in particular, the Range of \\(A\\) is just the Column Space of \\(A\\) , that is if \\(A = (\\a_1,...,\\a_n)\\) , then \\( \\(\\text{Range}(A) = \\text{Span}\\{\\a_1,...,\\a_n\\}\\) \\)","title":"The Four Fundamental Subspaces Revisited"},{"location":"reighns_ml_journey/mathematics/linear_algebra/06_linear_transformation/06.06_linear_algebra_linear_transformations_matrix/#references","text":"https://math.stackexchange.com/questions/4376735/what-is-meant-by-the-linear-mapping-t-is-entirely-and-uniquely-determined-on/4376761#4376761 https://math.stackexchange.com/questions/4114034/is-a-linear-map-uniquely-determined-on-v-or-on-a-basis-of-v","title":"References"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.01_motivation/","text":"Motivation of Chapter This chapter is essential in Machine Learning context. Below is an image of the workflow of this chapter, taken from the book \"Mathematics for Machine Learning\". Fig 2.3: 3 of the same vectors with different starting coordinates; By Hongnan G.","title":"Motivation"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.01_motivation/#motivation-of-chapter","text":"This chapter is essential in Machine Learning context. Below is an image of the workflow of this chapter, taken from the book \"Mathematics for Machine Learning\". Fig 2.3: 3 of the same vectors with different starting coordinates; By Hongnan G.","title":"Motivation of Chapter"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.02_norms/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\r}{\\mathbf{r}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\] Norms 1 Algebraic Definition (Norms) Algebraic Definition (Manhattan Norm) Geometric Definition (Manhattan Norm) Algebraic Definition (Euclidean Norm) Geometric Definition (Euclidean Norm) Algebraic Definition (LP Norm) Norms: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 71-72) \u21a9","title":"Norms"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.02_norms/#norms1","text":"","title":"Norms1"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.02_norms/#algebraic-definition-norms","text":"","title":"Algebraic Definition (Norms)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.02_norms/#algebraic-definition-manhattan-norm","text":"","title":"Algebraic Definition (Manhattan Norm)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.02_norms/#geometric-definition-manhattan-norm","text":"","title":"Geometric Definition (Manhattan Norm)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.02_norms/#algebraic-definition-euclidean-norm","text":"","title":"Algebraic Definition (Euclidean Norm)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.02_norms/#geometric-definition-euclidean-norm","text":"","title":"Geometric Definition (Euclidean Norm)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.02_norms/#algebraic-definition-lp-norm","text":"Norms: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 71-72) \u21a9","title":"Algebraic Definition (LP Norm)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.03_inner_products/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\r}{\\mathbf{r}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\] Inner Products 1 Inner Products: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 72-74) \u21a9","title":"Inner Product Spaces"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.03_inner_products/#inner-products1","text":"Inner Products: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 72-74) \u21a9","title":"Inner Products1"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.04_lengths_and_distances/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\r}{\\mathbf{r}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\] Lengths and Distances 1 Lengths and Distances: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 75-76) \u21a9","title":"Lengths and Distances"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.04_lengths_and_distances/#lengths-and-distances1","text":"Lengths and Distances: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 75-76) \u21a9","title":"Lengths and Distances1"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.05_angles_and_orthogonality/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\r}{\\mathbf{r}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\rank}{\\textbf{rank}} \\] Angles and Orthogonality 1 Calculating Angles Python In Euclidean space , a Euclidean vector is a geometric object that possesses both a magnitude and a direction. A vector can be pictured as an arrow. Its magnitude is its length, and its direction is the direction to which the arrow points. The magnitude of a vector a is denoted by \\(\\left\\| \\mathbf{a} \\right\\|\\) . The dot product of two Euclidean vectors a and b is defined by \\[\\mathbf{a}\\cdot\\mathbf{b}=\\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta ,\\] where \\(\\theta\\) is the angle between \\(\\a\\) and \\(\\b\\) . And thus to find angle we can just: \\[\\theta = \\cos^{-1}\\left(\\dfrac{\\mathbf{a} \\cdot \\mathbf{b}}{\\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|}\\right)\\] Fig: Calculate Angle Between Vectors; By Hongnan G. import numpy as np import math def calculate_angle ( a , b , c ): x1 , y1 = a x2 , y2 = b x3 , y3 = c angle = math . degrees ( math . atan2 ( y3 - y2 , x3 - x2 ) - math . atan2 ( y1 - y2 , x1 - x2 ) ) return angle + 360 if angle < 0 else angle def calculate_angle_using_dot_prod ( a : np . ndarray , b : np . ndarray , c : np . ndarray , return_as_degrees : bool = True , ): \"\"\"Takes in three points and calculates the angle between them using dot product. Let angle ABC as the angle between vectors AB and BC. This function calculates the angle ABC using the dot product formula: .. math:: BA = a - b BC = c - b \\cos(angle(ABC)) = \\dfrac{(BA \\cdot BC)}{(|BA||BC|)} Args: a (np.ndarray): Point a corresponding to A. b (np.ndarray): Point b corresponding to B. c (np.ndarray): Point c corresponding to C. return_as_degrees (bool): Returns angle in degrees if True else radians. Default: True. Shape: a (np.ndarray): (2, ) b (np.ndarray): (2, ) c (np.ndarray): (2, ) Examples: >>> import numpy as np >>> a = (6, 0) >>> b = (0, 0) >>> c = (6, 6) >>> calculate_angle_using_dot_prod(a,b,c) 45.0 \"\"\" # turn the points into numpy arrays a = np . asarray ( a ) b = np . asarray ( b ) c = np . asarray ( c ) ba = a - b bc = c - b cosine_angle = np . dot ( ba , bc ) / ( np . linalg . norm ( ba ) * np . linalg . norm ( bc ) ) angle = np . arccos ( cosine_angle ) if return_as_degrees : return np . degrees ( angle ) return angle a = ( 6 , 0 ) b = ( 0 , 0 ) c = ( 6 , 6 ) print ( calculate_angle ( a , b , c )) print ( calculate_angle_using_dot_prod ( a , b , c )) 45.0 45.0 https://stackoverflow.com/questions/58953047/issue-with-finding-angle-between-3-points-in-python https://math.stackexchange.com/questions/361412/finding-the-angle-between-three-points https://stackoverflow.com/questions/14066933/direct-way-of-computing-clockwise-angle-between-2-vectors Angles and Orthogonality: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 76-78) \u21a9","title":"Angles and Orthogoanlity"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.05_angles_and_orthogonality/#angles-and-orthogonality1","text":"","title":"Angles and Orthogonality1"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.05_angles_and_orthogonality/#calculating-angles-python","text":"In Euclidean space , a Euclidean vector is a geometric object that possesses both a magnitude and a direction. A vector can be pictured as an arrow. Its magnitude is its length, and its direction is the direction to which the arrow points. The magnitude of a vector a is denoted by \\(\\left\\| \\mathbf{a} \\right\\|\\) . The dot product of two Euclidean vectors a and b is defined by \\[\\mathbf{a}\\cdot\\mathbf{b}=\\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta ,\\] where \\(\\theta\\) is the angle between \\(\\a\\) and \\(\\b\\) . And thus to find angle we can just: \\[\\theta = \\cos^{-1}\\left(\\dfrac{\\mathbf{a} \\cdot \\mathbf{b}}{\\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|}\\right)\\] Fig: Calculate Angle Between Vectors; By Hongnan G. import numpy as np import math def calculate_angle ( a , b , c ): x1 , y1 = a x2 , y2 = b x3 , y3 = c angle = math . degrees ( math . atan2 ( y3 - y2 , x3 - x2 ) - math . atan2 ( y1 - y2 , x1 - x2 ) ) return angle + 360 if angle < 0 else angle def calculate_angle_using_dot_prod ( a : np . ndarray , b : np . ndarray , c : np . ndarray , return_as_degrees : bool = True , ): \"\"\"Takes in three points and calculates the angle between them using dot product. Let angle ABC as the angle between vectors AB and BC. This function calculates the angle ABC using the dot product formula: .. math:: BA = a - b BC = c - b \\cos(angle(ABC)) = \\dfrac{(BA \\cdot BC)}{(|BA||BC|)} Args: a (np.ndarray): Point a corresponding to A. b (np.ndarray): Point b corresponding to B. c (np.ndarray): Point c corresponding to C. return_as_degrees (bool): Returns angle in degrees if True else radians. Default: True. Shape: a (np.ndarray): (2, ) b (np.ndarray): (2, ) c (np.ndarray): (2, ) Examples: >>> import numpy as np >>> a = (6, 0) >>> b = (0, 0) >>> c = (6, 6) >>> calculate_angle_using_dot_prod(a,b,c) 45.0 \"\"\" # turn the points into numpy arrays a = np . asarray ( a ) b = np . asarray ( b ) c = np . asarray ( c ) ba = a - b bc = c - b cosine_angle = np . dot ( ba , bc ) / ( np . linalg . norm ( ba ) * np . linalg . norm ( bc ) ) angle = np . arccos ( cosine_angle ) if return_as_degrees : return np . degrees ( angle ) return angle a = ( 6 , 0 ) b = ( 0 , 0 ) c = ( 6 , 6 ) print ( calculate_angle ( a , b , c )) print ( calculate_angle_using_dot_prod ( a , b , c )) 45.0 45.0 https://stackoverflow.com/questions/58953047/issue-with-finding-angle-between-3-points-in-python https://math.stackexchange.com/questions/361412/finding-the-angle-between-three-points https://stackoverflow.com/questions/14066933/direct-way-of-computing-clockwise-angle-between-2-vectors Angles and Orthogonality: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 76-78) \u21a9","title":"Calculating Angles Python"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\q}{\\mathbf{q}} \\newcommand{\\r}{\\mathbf{r}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\Q}{\\mathbf{Q}} \\newcommand{\\U}{\\mathbf{U}} \\newcommand{\\V}{\\mathbf{V}} \\newcommand{\\W}{\\mathbf{W}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\span}{\\textbf{span}} \\] Orthogonal Subspaces Definition (Orthogonal Subspaces) Note that is does not make sense to talk about the Orthogonality of one subspace. Given any two vector subspaces \\(\\V\\) and \\(\\W\\) , both necessarily have the same dimension in the sense that any elements in either subspace should have the same length, if not the dot (inner) product is not well defined, then we say that \\(\\V\\) and \\(\\W\\) are orthogonal subspaces if \\(\\v^\\top \\w = \\0\\) for all \\(\\v \\in \\V\\) and \\(\\w \\in \\W\\) . Example (Orthogonal Subspaces) The Nullspace and the Row Space are orthogonal subspaces. We will soon prove this. Theorem (Dimension implies Non-Orthogonality) This may be best explained using an example so that it sticks to memory intuitively. Consider \\(\\R^3\\) space and take 2 subspaces \\(\\V, \\W \\subseteq \\R^3\\) where both are 2D-planes (spanned by 2 linearly independent vectors) embedded in the \\(\\R^3\\) space. Then \\(\\V\\) and \\(\\W\\) can never be orthogonal to each other. The intuition is that no matter how you position 2 such 2D-planes, they can never be placed completely orthogonal to each other. This idea leads us to define another core concept, Orthogonal Complement. Once defined, you will then be able to prove why this is so. Definition (Orthogonal Subset) Let \\(\\Q \\subseteq \\V\\) be a subset in a subspace , then \\(\\Q\\) is an orthogonal subset of \\(\\V\\) if every element in \\(\\Q\\) is mutually orthogonal to each other, that is, \\(\\forall \\q_i, \\q_j \\in \\Q\\) , we have \\(\\q_i \\perp \\q_j\\) . Theorem (Orthogonal Subset is Linearly Independent) Let \\(\\V\\) be an inner product space , then any orthogonal subset of \\(\\V\\) consisting of non-zero vectors is linearly independent . Proof (Orthogonal Subset is Linearly Independent) 1 Intuitively, this must be true, just image the standard basis in \\(\\R^3\\) space, we can easily verify they are an orthogonal subset , and also have the intuition that these 3 vectors must be linearly independent. Orthogonal Complements Definition (Orthogonal Complements) Let \\(\\V \\in \\F^{D}\\) be a \\(D\\) -dimensional subspace and let \\(\\U \\subset \\V\\) be a \\(M\\) -dimensional subspace. Denote the set of vectors \\(\\{\\w_i\\}\\) to be all vectors that are orthogonal to \\(\\U\\) , then this set of vectors, denoted \\(\\U^\\perp\\) , is the orthogonal complement to \\(\\U\\) and is defined as: \\[ \\U^\\perp = \\left\\{\\w \\in \\V ~|~ \\langle \\w, \\u \\rangle = \\0 \\quad \\forall \\u \\in \\U \\right\\} \\] Theorem (Properties of Orthogonal Complements) Let \\(\\U\\) be a subset of a finite-dimensional inner product space \\(\\V\\) , then we have: Theorem (Intersection of Orthogonal Complements is Zero) \\[ \\U \\cap \\U^\\perp = \\{\\0\\} \\] The proof is relatively simple, consider a contradiction that there is some element \\(\\u\\) in the intersection of \\(\\U \\cap \\U^\\perp\\) that is not \\(\\0\\) , then \\(\\u \\in \\U\\) and \\(\\u \\in \\U^\\perp\\) , by the definition of Orthogonal Complement , we must have \\(\\u \\cdot \\u = \\0\\) , which is a contradiction since no such \\(\\u\\) can fulfill this. Theorem (Orthogonal Complement is a Subspace) If \\(\\U\\) is a non-empty subset of a finite-dimensional inner product space \\(\\V\\) , then \\(\\U^\\perp\\) is a subspace . Theorem (Element of Orthogonal Complement is Orthogonal to every Linear Combination of U) \\(\\U^\\perp = (\\span(\\U))^\\perp\\) which means a vector \\(\\u\\) belonging to the orthogonal complement of \\(\\U\\) if and only if \\(\\u\\) is orthogonal to every linear combination of vectors from \\(\\U\\) . Theorem (Othogonal Complement's Complement is Itself) \\[ (\\U^\\perp)^\\perp = \\U \\] Theorem (The Fundamental Theorem of Linear Algebra Part 2: Orthogonal Complements and The Four Fundamental Subspaces) We state straightaway that the row space and the kernel (right nullspace) are orthogonal complements, with some preliminary intuition below. More specifically, one should note that the row space of a matrix A is not only orthogonal to its nullspace, it also serves as a complement to it such that the union of them is the whole R^n space itself. I will now denote nullspace as N(A) and row space as R(A), with the associated matrix being m by n. Before the concept of orthogonality, one may take a while to realize that R(A) UNION N(A) = R^n. Even though the rank-nullity theorem tells us that their dimension of the nullspace and row space is n, it did not specifically say that the union of them is the whole Rn space (though intuitively they are if you stare at it long enough). But the main point is, with the orthogonal concept introduced, every vector in the nullspace is \"perpendicular\" to those in the row space, and that means that any vector n in N(A) is of a \"different axis/dimension\" as those in R(A), and this indicates linear independence of them. Now this means the basis vectors of N(A) and R(A) are linearly independent, and hence when unioned, they make up the whole R^n space. Row space and Null Space are Orthogonal Complements The row space and the null space of a matrix \\(\\A \\in \\F^{m \\times n}\\) are orthogonal complements . Proof (Orthogonal Subspace) We first show that both subspaces are orthogonal. Note that the null space of a matrix \\(\\A \\in F^{m \\times n}\\) is the set of all vectors \\(\\x\\) such that \\(\\A\\x = \\0\\) . We can also write \\(\\A\\x = \\0\\) as \\[ \\A\\x = \\begin{bmatrix} \\r_1 \\cdot \\x \\\\ \\r_2 \\cdot \\x \\\\ \\vdots \\\\ \\r_m \\cdot \\x \\end{bmatrix} \\] where \\(\\cdot\\) is the dot product and \\(\\r_i\\) the row vector \\(i\\) of \\(\\A\\) . Then one can easily see that \\(\\A\\x = \\0\\) if and only if every \\(\\r_i \\cdot \\x = 0\\) . Then it immediately follows that every \\(\\r_i\\) is orthogonal to \\(\\x\\) , and consequently, the nullspace and row space of \\(\\A\\) forms an orthogonal subspace . To see this, take any vector \\(\\r \\in R(\\A)\\) , and represent this \\(\\r = \\lambda_1 \\r_1 + ... + \\lambda_m \\r_m\\) , then \\[ \\begin{aligned} \\r \\cdot \\x &= (\\lambda_1 \\r_1 + ... + \\lambda_m \\r_m) \\cdot \\x \\\\ &= \\lambda_1 \\r_1 \\cdot \\x + ... + \\lambda_m \\r_m \\cdot \\x \\\\ &= \\0 + ... + \\0 \\\\ &= \\0 \\end{aligned} \\] So we have proved that if we take any element \\(\\r\\) in the row space of \\(\\A\\) , then \\(\\r\\x = \\0\\) for every \\(\\x \\in N(\\A)\\) . Since the dot product \\(\\cdot\\) is commutative, we do not need to show that for every element \\(\\x \\in N(\\A)\\) , it is orthogonal to every element in the row space of \\(\\A\\) . Proof (Orthogonal Complements) 2 We have proven that the row space \\(\\newcommand{\\R}{\\mathrm{R}} \\R(A)\\) and null space \\(\\newcommand{\\N}{\\mathrm{N}} \\N(A)\\) are orthogonal to each other; that is, \\(\\newcommand{\\r}{\\vec r} \\newcommand{\\n}{\\vec n} \\forall\\r\\in\\R(A)\\ \\forall\\n\\in\\N(A): \\r\\perp\\n\\) . Next, we show that they are complements of each other: \\[\\R(A)\\cap\\N(A)=\\left\\{\\vec0\\right\\}\\] Both of these criteria must be met for two subspaces to be orthogonal complements. Proof : Suppose we take an element \\(\\v \\in \\mathrm{R}(\\A) \\cap \\N(A)\\) , this means that \\(\\newcommand{\\v}{\\vec v} \\v\\in\\N(A)\\) and \\(\\v\\in\\R(A)\\) . Recall that if \\(\\n\\in\\N(A)\\) then \\( \\(\\n\\cdot\\r=0\\) \\) where \\(\\r\\in\\R(A)\\) . Now the element we took from their intersection \\(\\v\\) has this property: \\[\\v\\cdot\\v=0=\\left\\|\\v\\right\\|^2\\] We can use two ways from here, one is we know \\[\\v \\cdot \\v = \\begin{bmatrix} v_1^2 \\\\ v_2^2 \\\\ \\vdots \\\\ \\v_m^2 \\end{bmatrix}\\] and thus for this to be zero, then \\(v_i^2 = 0 \\implies v_i = 0 \\forall i\\) , hence \\(\\v\\) is the zero vector. Otherwise, since \\(\\left\\|\\v\\right\\|=0\\) , the vector \\(\\v\\) must be the zero vector. In any case, any vector \\(\\v\\) in both \\(\\R(A)\\) and \\(\\N(A)\\) must equal \\(\\vec0\\) . Therefore \\(\\R(A)\\cap\\N(A)=\\left\\{\\vec0\\right\\}\\) , and so by definition \\(\\R(A)\\) and \\(\\N(A)\\) are complementary subspaces as well as orthogonal. \\(\\blacksquare\\) Column space and Left Null Space are Orthogonal Complements This proof is similar with the previous one. Important Note Note that at this junction, we have to remind ourselves that given two subspaces \\(\\U\\) and \\(\\U^\\perp\\) in a vector space \\(\\V \\in \\F^n\\) , we can only tell that their intersection is zero, meaning they are disjoin, but we are not sure whether the union of them actually spans the whole \\(\\V\\) or not. Intuitively, it should, but we should soon see why in proof. Note the intuition is given earlier in The Fundamental Theorem of Linear Algebra Part 2. Theorem (Subspace and its Orthogonal Complement Forms a Disjoint Union) Let \\(\\V \\in \\F^n\\) be of \\(n\\) dimensions. Let \\(\\U\\) be a subspace of \\(\\V\\) and \\(\\U^\\perp\\) be the Orthogonal Complement of \\(\\U\\) , then we have \\[ \\U \\sqcup \\U^\\perp = \\V \\] In other words, the basis of \\(\\U\\) and \\(\\U^\\perp\\) span \\(\\V\\) . We do not use a formal proof here, instead we reason out with some geometric intuition. We should use the example of the row space and the kernel with symbols \\(R(\\A)\\) and \\(N(\\A)\\) respectively. First, the Rank-Nullity Theorem tells us that the dimensions of \\(R(\\A)\\) and \\(N(\\A)\\) is \\(n\\) . This helps because if they do not add up to \\(n\\) , then their basis certainly do not span \\(\\V\\) . Then, since Orthogonality implies that every vector is pairwise orthogonal, it means that geomtrically, both subspaces' basis vectors are all independent. You can think perpendicular means that the basis vectors all point in different axis. Thus, both subspace have pairwise linearly independent vectors. Finally, since the basis vectors of \\(R(\\A)\\) and \\(N(\\A)\\) when unioned together, are linearly independent, and the cardinality is \\(n\\) , it follows that this basis spans \\(\\V\\) . \\(\\blacksquare\\) Theorem (The Orthogonal Decomposition Theorem) 3 Let \\(\\U\\) be a subspace of a finite-dimensional inner product space \\(\\V\\) , then any vector \\(\\v \\in \\V\\) can be written uniquely in the form \\(\\v = \\u_1 + \\u_2\\) where \\(\\u_1 \\in \\U\\) and \\(\\u_2 \\in \\U^\\perp\\) . In direct sum , we have: \\[ \\V = \\U \\oplus \\U^\\perp \\] Corollary (Dimensions of Orthogonal Complements) 3 If \\(\\U\\) is a subsapce of an \\(n\\) -dimensional inner product space \\(\\V\\) , then \\(\\dim(\\U) + \\dim(\\U^\\perp) = n\\) . Proof (Dimensions of Orthogonal Complements) 3 Corollary (Dimensions of Four Fundamental Subspaces Revisited) 4 Theorem (Unique Row Space Solution to \\(\\mathbf{Ax=b}\\) ) Given any \\(\\b \\in C(\\A)\\) , there exists an unique member \\(\\r_0 \\in R(\\A)\\) such that \\(\\r_0\\) is a solution to \\(\\A\\x=\\b\\) , and this \\(\\r_0\\) is the solution (special) and no other solution can have a smaller length in the sense that \\(||\\x|| \\geq ||\\r_0||\\) for any solution \\(\\x\\) . Visualization (Row Space and Null Space Orthogonal) The plots and contents below are entirely credited to MacroAnalyst's GitHub Repo 5 . import matplotlib.pyplot as plt import numpy as np from mpl_toolkits.mplot3d import Axes3D import sympy as sy sy . init_printing () A = sy . Matrix ([[ 5 , 8 , 2 ], [ 10 , 16 , 4 ], [ 3 , 4 , 1 ]]); A \\(\\displaystyle \\left[\\begin{matrix}5 & 8 & 2\\\\10 & 16 & 4\\\\3 & 4 & 1\\end{matrix}\\right]\\) A . rref () \\(\\displaystyle \\left( \\left[\\begin{matrix}1 & 0 & 0\\\\0 & 1 & \\frac{1}{4}\\\\0 & 0 & 0\\end{matrix}\\right], \\ \\left( 0, \\ 1\\right)\\right)\\) The basis of row space of \\(A\\) is \\((1, 0, 0)\\) and \\((0, 1, .25)\\) .And the \\(\\text{Row}A\\) is \\[ \\text{Row}A= s\\left[ \\begin{matrix} 1 \\\\ 0\\\\ 0 \\end{matrix} \\right]+ t\\left[ \\begin{matrix} 0 \\\\ 1\\\\ 0.25 \\end{matrix} \\right] \\] The \\(\\text{Nul}A\\) is $$ \\left[ \\begin{matrix} x_1 \\ x_2\\ x_3 \\end{matrix} \\right]= x_3 \\left[ \\begin{matrix} 0 \\ -.25\\ 1 \\end{matrix} \\right] $$ Now we can visualize their relations geometrically. Again keep in mind that Matplotlib does not render 3D properly, so you need some imagination as well. Here is what we observe. The \\(\\text{Row}A\\) is a plane and \\(\\text{Nul}A\\) is a line which is perpendicular to the plane. It is easy to grasp the idea if you notice that in a homogeneous system \\(Ab = \\mathbf{0}\\) , it breaks down into many dot products \\[ Ab =\\left[ \\begin{matrix} A_{1i}\\cdot b \\\\ A_{2i}\\cdot b\\\\ A_{3i}\\cdot b \\end{matrix} \\right] \\] where \\(A_{1i}, A_{2i}, A_{3i}\\) are the rows of \\(A\\) . In later chapters we will prove when the dot product of two vectors equals zero, which means geometrically they are perpendicular. % matplotlib inline s = np . linspace ( - 1 , 1 , 10 ) t = np . linspace ( - 1 , 1 , 10 ) S , T = np . meshgrid ( s , t ) X = S Y = T Z = T * .25 fig = plt . figure ( figsize = ( 8 , 8 )) ax = fig . add_subplot ( 111 , projection = '3d' ) ax . plot_surface ( X , Y , Z , alpha = .9 , cmap = plt . cm . coolwarm ) x3 = np . linspace ( - 1 , 1 , 10 ) x1 = 0 * x3 x2 = - .25 * x3 ax . plot ( x1 , x2 , x3 , lw = 5 ) ax . set_xlabel ( 'x-axis' , size = 18 ) ax . set_ylabel ( 'y-axis' , size = 18 ) ax . set_zlabel ( 'z-axis' , size = 18 ) ax . axis ([ - 1 , 1 , - 1 , 1 ]) ax . text ( x = 1 , y = - 1 , z = - .25 , s = r '$Row\\ A$' , size = 17 ) ax . text ( 0 , - .25 , 1 , s = r '$Nul\\ A$' , size = 17 ) ax . view_init ( 7 , 20 ) plt . show () Orthogonal Subset is Linearly Independent: Henry Ricardo: A Modern Introduction to Linear Algebra, 2009. (pp. 477) \u21a9 Row space and Null space are Orthogonal Complements: How would one prove that the row space and null space are orthogonal compliments of each other? \u21a9 Proof (Dimensions of Orthogonal Complements): Henry Ricardo: A Modern Introduction to Linear Algebra, 2009. (pp. 524) \u21a9 \u21a9 \u21a9 (Dimensions of Four Fundamental Subspaces Revisited): Henry Ricardo: A Modern Introduction to Linear Algebra, 2009. (pp. 525) \u21a9 Row Space and Null Space Orthogonal: Row Space and Null Space Orthogonal \u21a9","title":"Orthogonal Subspace"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#orthogonal-subspaces","text":"","title":"Orthogonal Subspaces"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#definition-orthogonal-subspaces","text":"Note that is does not make sense to talk about the Orthogonality of one subspace. Given any two vector subspaces \\(\\V\\) and \\(\\W\\) , both necessarily have the same dimension in the sense that any elements in either subspace should have the same length, if not the dot (inner) product is not well defined, then we say that \\(\\V\\) and \\(\\W\\) are orthogonal subspaces if \\(\\v^\\top \\w = \\0\\) for all \\(\\v \\in \\V\\) and \\(\\w \\in \\W\\) .","title":"Definition (Orthogonal Subspaces)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#example-orthogonal-subspaces","text":"The Nullspace and the Row Space are orthogonal subspaces. We will soon prove this.","title":"Example (Orthogonal Subspaces)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#theorem-dimension-implies-non-orthogonality","text":"This may be best explained using an example so that it sticks to memory intuitively. Consider \\(\\R^3\\) space and take 2 subspaces \\(\\V, \\W \\subseteq \\R^3\\) where both are 2D-planes (spanned by 2 linearly independent vectors) embedded in the \\(\\R^3\\) space. Then \\(\\V\\) and \\(\\W\\) can never be orthogonal to each other. The intuition is that no matter how you position 2 such 2D-planes, they can never be placed completely orthogonal to each other. This idea leads us to define another core concept, Orthogonal Complement. Once defined, you will then be able to prove why this is so.","title":"Theorem (Dimension implies Non-Orthogonality)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#definition-orthogonal-subset","text":"Let \\(\\Q \\subseteq \\V\\) be a subset in a subspace , then \\(\\Q\\) is an orthogonal subset of \\(\\V\\) if every element in \\(\\Q\\) is mutually orthogonal to each other, that is, \\(\\forall \\q_i, \\q_j \\in \\Q\\) , we have \\(\\q_i \\perp \\q_j\\) .","title":"Definition (Orthogonal Subset)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#theorem-orthogonal-subset-is-linearly-independent","text":"Let \\(\\V\\) be an inner product space , then any orthogonal subset of \\(\\V\\) consisting of non-zero vectors is linearly independent .","title":"Theorem (Orthogonal Subset is Linearly Independent)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#proof-orthogonal-subset-is-linearly-independent1","text":"Intuitively, this must be true, just image the standard basis in \\(\\R^3\\) space, we can easily verify they are an orthogonal subset , and also have the intuition that these 3 vectors must be linearly independent.","title":"Proof (Orthogonal Subset is Linearly Independent)1"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#orthogonal-complements","text":"","title":"Orthogonal Complements"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#definition-orthogonal-complements","text":"Let \\(\\V \\in \\F^{D}\\) be a \\(D\\) -dimensional subspace and let \\(\\U \\subset \\V\\) be a \\(M\\) -dimensional subspace. Denote the set of vectors \\(\\{\\w_i\\}\\) to be all vectors that are orthogonal to \\(\\U\\) , then this set of vectors, denoted \\(\\U^\\perp\\) , is the orthogonal complement to \\(\\U\\) and is defined as: \\[ \\U^\\perp = \\left\\{\\w \\in \\V ~|~ \\langle \\w, \\u \\rangle = \\0 \\quad \\forall \\u \\in \\U \\right\\} \\]","title":"Definition (Orthogonal Complements)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#theorem-properties-of-orthogonal-complements","text":"Let \\(\\U\\) be a subset of a finite-dimensional inner product space \\(\\V\\) , then we have:","title":"Theorem (Properties of Orthogonal Complements)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#theorem-intersection-of-orthogonal-complements-is-zero","text":"\\[ \\U \\cap \\U^\\perp = \\{\\0\\} \\] The proof is relatively simple, consider a contradiction that there is some element \\(\\u\\) in the intersection of \\(\\U \\cap \\U^\\perp\\) that is not \\(\\0\\) , then \\(\\u \\in \\U\\) and \\(\\u \\in \\U^\\perp\\) , by the definition of Orthogonal Complement , we must have \\(\\u \\cdot \\u = \\0\\) , which is a contradiction since no such \\(\\u\\) can fulfill this.","title":"Theorem (Intersection of Orthogonal Complements is Zero)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#theorem-orthogonal-complement-is-a-subspace","text":"If \\(\\U\\) is a non-empty subset of a finite-dimensional inner product space \\(\\V\\) , then \\(\\U^\\perp\\) is a subspace .","title":"Theorem (Orthogonal Complement is a Subspace)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#theorem-element-of-orthogonal-complement-is-orthogonal-to-every-linear-combination-of-u","text":"\\(\\U^\\perp = (\\span(\\U))^\\perp\\) which means a vector \\(\\u\\) belonging to the orthogonal complement of \\(\\U\\) if and only if \\(\\u\\) is orthogonal to every linear combination of vectors from \\(\\U\\) .","title":"Theorem (Element of Orthogonal Complement is Orthogonal to every Linear Combination of U)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#theorem-othogonal-complements-complement-is-itself","text":"\\[ (\\U^\\perp)^\\perp = \\U \\]","title":"Theorem (Othogonal Complement's Complement is Itself)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#theorem-the-fundamental-theorem-of-linear-algebra-part-2-orthogonal-complements-and-the-four-fundamental-subspaces","text":"We state straightaway that the row space and the kernel (right nullspace) are orthogonal complements, with some preliminary intuition below. More specifically, one should note that the row space of a matrix A is not only orthogonal to its nullspace, it also serves as a complement to it such that the union of them is the whole R^n space itself. I will now denote nullspace as N(A) and row space as R(A), with the associated matrix being m by n. Before the concept of orthogonality, one may take a while to realize that R(A) UNION N(A) = R^n. Even though the rank-nullity theorem tells us that their dimension of the nullspace and row space is n, it did not specifically say that the union of them is the whole Rn space (though intuitively they are if you stare at it long enough). But the main point is, with the orthogonal concept introduced, every vector in the nullspace is \"perpendicular\" to those in the row space, and that means that any vector n in N(A) is of a \"different axis/dimension\" as those in R(A), and this indicates linear independence of them. Now this means the basis vectors of N(A) and R(A) are linearly independent, and hence when unioned, they make up the whole R^n space.","title":"Theorem (The Fundamental Theorem of Linear Algebra Part 2: Orthogonal Complements and The Four Fundamental Subspaces)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#row-space-and-null-space-are-orthogonal-complements","text":"The row space and the null space of a matrix \\(\\A \\in \\F^{m \\times n}\\) are orthogonal complements .","title":"Row space and Null Space are Orthogonal Complements"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#proof-orthogonal-subspace","text":"We first show that both subspaces are orthogonal. Note that the null space of a matrix \\(\\A \\in F^{m \\times n}\\) is the set of all vectors \\(\\x\\) such that \\(\\A\\x = \\0\\) . We can also write \\(\\A\\x = \\0\\) as \\[ \\A\\x = \\begin{bmatrix} \\r_1 \\cdot \\x \\\\ \\r_2 \\cdot \\x \\\\ \\vdots \\\\ \\r_m \\cdot \\x \\end{bmatrix} \\] where \\(\\cdot\\) is the dot product and \\(\\r_i\\) the row vector \\(i\\) of \\(\\A\\) . Then one can easily see that \\(\\A\\x = \\0\\) if and only if every \\(\\r_i \\cdot \\x = 0\\) . Then it immediately follows that every \\(\\r_i\\) is orthogonal to \\(\\x\\) , and consequently, the nullspace and row space of \\(\\A\\) forms an orthogonal subspace . To see this, take any vector \\(\\r \\in R(\\A)\\) , and represent this \\(\\r = \\lambda_1 \\r_1 + ... + \\lambda_m \\r_m\\) , then \\[ \\begin{aligned} \\r \\cdot \\x &= (\\lambda_1 \\r_1 + ... + \\lambda_m \\r_m) \\cdot \\x \\\\ &= \\lambda_1 \\r_1 \\cdot \\x + ... + \\lambda_m \\r_m \\cdot \\x \\\\ &= \\0 + ... + \\0 \\\\ &= \\0 \\end{aligned} \\] So we have proved that if we take any element \\(\\r\\) in the row space of \\(\\A\\) , then \\(\\r\\x = \\0\\) for every \\(\\x \\in N(\\A)\\) . Since the dot product \\(\\cdot\\) is commutative, we do not need to show that for every element \\(\\x \\in N(\\A)\\) , it is orthogonal to every element in the row space of \\(\\A\\) .","title":"Proof (Orthogonal Subspace)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#proof-orthogonal-complements2","text":"We have proven that the row space \\(\\newcommand{\\R}{\\mathrm{R}} \\R(A)\\) and null space \\(\\newcommand{\\N}{\\mathrm{N}} \\N(A)\\) are orthogonal to each other; that is, \\(\\newcommand{\\r}{\\vec r} \\newcommand{\\n}{\\vec n} \\forall\\r\\in\\R(A)\\ \\forall\\n\\in\\N(A): \\r\\perp\\n\\) . Next, we show that they are complements of each other: \\[\\R(A)\\cap\\N(A)=\\left\\{\\vec0\\right\\}\\] Both of these criteria must be met for two subspaces to be orthogonal complements. Proof : Suppose we take an element \\(\\v \\in \\mathrm{R}(\\A) \\cap \\N(A)\\) , this means that \\(\\newcommand{\\v}{\\vec v} \\v\\in\\N(A)\\) and \\(\\v\\in\\R(A)\\) . Recall that if \\(\\n\\in\\N(A)\\) then \\( \\(\\n\\cdot\\r=0\\) \\) where \\(\\r\\in\\R(A)\\) . Now the element we took from their intersection \\(\\v\\) has this property: \\[\\v\\cdot\\v=0=\\left\\|\\v\\right\\|^2\\] We can use two ways from here, one is we know \\[\\v \\cdot \\v = \\begin{bmatrix} v_1^2 \\\\ v_2^2 \\\\ \\vdots \\\\ \\v_m^2 \\end{bmatrix}\\] and thus for this to be zero, then \\(v_i^2 = 0 \\implies v_i = 0 \\forall i\\) , hence \\(\\v\\) is the zero vector. Otherwise, since \\(\\left\\|\\v\\right\\|=0\\) , the vector \\(\\v\\) must be the zero vector. In any case, any vector \\(\\v\\) in both \\(\\R(A)\\) and \\(\\N(A)\\) must equal \\(\\vec0\\) . Therefore \\(\\R(A)\\cap\\N(A)=\\left\\{\\vec0\\right\\}\\) , and so by definition \\(\\R(A)\\) and \\(\\N(A)\\) are complementary subspaces as well as orthogonal. \\(\\blacksquare\\)","title":"Proof (Orthogonal Complements)2"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#column-space-and-left-null-space-are-orthogonal-complements","text":"This proof is similar with the previous one.","title":"Column space and Left Null Space are Orthogonal Complements"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#important-note","text":"Note that at this junction, we have to remind ourselves that given two subspaces \\(\\U\\) and \\(\\U^\\perp\\) in a vector space \\(\\V \\in \\F^n\\) , we can only tell that their intersection is zero, meaning they are disjoin, but we are not sure whether the union of them actually spans the whole \\(\\V\\) or not. Intuitively, it should, but we should soon see why in proof. Note the intuition is given earlier in The Fundamental Theorem of Linear Algebra Part 2.","title":"Important Note"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#theorem-subspace-and-its-orthogonal-complement-forms-a-disjoint-union","text":"Let \\(\\V \\in \\F^n\\) be of \\(n\\) dimensions. Let \\(\\U\\) be a subspace of \\(\\V\\) and \\(\\U^\\perp\\) be the Orthogonal Complement of \\(\\U\\) , then we have \\[ \\U \\sqcup \\U^\\perp = \\V \\] In other words, the basis of \\(\\U\\) and \\(\\U^\\perp\\) span \\(\\V\\) . We do not use a formal proof here, instead we reason out with some geometric intuition. We should use the example of the row space and the kernel with symbols \\(R(\\A)\\) and \\(N(\\A)\\) respectively. First, the Rank-Nullity Theorem tells us that the dimensions of \\(R(\\A)\\) and \\(N(\\A)\\) is \\(n\\) . This helps because if they do not add up to \\(n\\) , then their basis certainly do not span \\(\\V\\) . Then, since Orthogonality implies that every vector is pairwise orthogonal, it means that geomtrically, both subspaces' basis vectors are all independent. You can think perpendicular means that the basis vectors all point in different axis. Thus, both subspace have pairwise linearly independent vectors. Finally, since the basis vectors of \\(R(\\A)\\) and \\(N(\\A)\\) when unioned together, are linearly independent, and the cardinality is \\(n\\) , it follows that this basis spans \\(\\V\\) . \\(\\blacksquare\\)","title":"Theorem (Subspace and its Orthogonal Complement Forms a Disjoint Union)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#theorem-the-orthogonal-decomposition-theorem3","text":"Let \\(\\U\\) be a subspace of a finite-dimensional inner product space \\(\\V\\) , then any vector \\(\\v \\in \\V\\) can be written uniquely in the form \\(\\v = \\u_1 + \\u_2\\) where \\(\\u_1 \\in \\U\\) and \\(\\u_2 \\in \\U^\\perp\\) . In direct sum , we have: \\[ \\V = \\U \\oplus \\U^\\perp \\]","title":"Theorem (The Orthogonal Decomposition Theorem)3"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#corollary-dimensions-of-orthogonal-complements3","text":"If \\(\\U\\) is a subsapce of an \\(n\\) -dimensional inner product space \\(\\V\\) , then \\(\\dim(\\U) + \\dim(\\U^\\perp) = n\\) .","title":"Corollary (Dimensions of Orthogonal Complements)3"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#proof-dimensions-of-orthogonal-complements3","text":"","title":"Proof (Dimensions of Orthogonal Complements)3"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#corollary-dimensions-of-four-fundamental-subspaces-revisited4","text":"","title":"Corollary (Dimensions of Four Fundamental Subspaces Revisited)4"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#theorem-unique-row-space-solution-to-mathbfaxb","text":"Given any \\(\\b \\in C(\\A)\\) , there exists an unique member \\(\\r_0 \\in R(\\A)\\) such that \\(\\r_0\\) is a solution to \\(\\A\\x=\\b\\) , and this \\(\\r_0\\) is the solution (special) and no other solution can have a smaller length in the sense that \\(||\\x|| \\geq ||\\r_0||\\) for any solution \\(\\x\\) .","title":"Theorem (Unique Row Space Solution to \\(\\mathbf{Ax=b}\\))"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/#visualization-row-space-and-null-space-orthogonal","text":"The plots and contents below are entirely credited to MacroAnalyst's GitHub Repo 5 . import matplotlib.pyplot as plt import numpy as np from mpl_toolkits.mplot3d import Axes3D import sympy as sy sy . init_printing () A = sy . Matrix ([[ 5 , 8 , 2 ], [ 10 , 16 , 4 ], [ 3 , 4 , 1 ]]); A \\(\\displaystyle \\left[\\begin{matrix}5 & 8 & 2\\\\10 & 16 & 4\\\\3 & 4 & 1\\end{matrix}\\right]\\) A . rref () \\(\\displaystyle \\left( \\left[\\begin{matrix}1 & 0 & 0\\\\0 & 1 & \\frac{1}{4}\\\\0 & 0 & 0\\end{matrix}\\right], \\ \\left( 0, \\ 1\\right)\\right)\\) The basis of row space of \\(A\\) is \\((1, 0, 0)\\) and \\((0, 1, .25)\\) .And the \\(\\text{Row}A\\) is \\[ \\text{Row}A= s\\left[ \\begin{matrix} 1 \\\\ 0\\\\ 0 \\end{matrix} \\right]+ t\\left[ \\begin{matrix} 0 \\\\ 1\\\\ 0.25 \\end{matrix} \\right] \\] The \\(\\text{Nul}A\\) is $$ \\left[ \\begin{matrix} x_1 \\ x_2\\ x_3 \\end{matrix} \\right]= x_3 \\left[ \\begin{matrix} 0 \\ -.25\\ 1 \\end{matrix} \\right] $$ Now we can visualize their relations geometrically. Again keep in mind that Matplotlib does not render 3D properly, so you need some imagination as well. Here is what we observe. The \\(\\text{Row}A\\) is a plane and \\(\\text{Nul}A\\) is a line which is perpendicular to the plane. It is easy to grasp the idea if you notice that in a homogeneous system \\(Ab = \\mathbf{0}\\) , it breaks down into many dot products \\[ Ab =\\left[ \\begin{matrix} A_{1i}\\cdot b \\\\ A_{2i}\\cdot b\\\\ A_{3i}\\cdot b \\end{matrix} \\right] \\] where \\(A_{1i}, A_{2i}, A_{3i}\\) are the rows of \\(A\\) . In later chapters we will prove when the dot product of two vectors equals zero, which means geometrically they are perpendicular. % matplotlib inline s = np . linspace ( - 1 , 1 , 10 ) t = np . linspace ( - 1 , 1 , 10 ) S , T = np . meshgrid ( s , t ) X = S Y = T Z = T * .25 fig = plt . figure ( figsize = ( 8 , 8 )) ax = fig . add_subplot ( 111 , projection = '3d' ) ax . plot_surface ( X , Y , Z , alpha = .9 , cmap = plt . cm . coolwarm ) x3 = np . linspace ( - 1 , 1 , 10 ) x1 = 0 * x3 x2 = - .25 * x3 ax . plot ( x1 , x2 , x3 , lw = 5 ) ax . set_xlabel ( 'x-axis' , size = 18 ) ax . set_ylabel ( 'y-axis' , size = 18 ) ax . set_zlabel ( 'z-axis' , size = 18 ) ax . axis ([ - 1 , 1 , - 1 , 1 ]) ax . text ( x = 1 , y = - 1 , z = - .25 , s = r '$Row\\ A$' , size = 17 ) ax . text ( 0 , - .25 , 1 , s = r '$Nul\\ A$' , size = 17 ) ax . view_init ( 7 , 20 ) plt . show () Orthogonal Subset is Linearly Independent: Henry Ricardo: A Modern Introduction to Linear Algebra, 2009. (pp. 477) \u21a9 Row space and Null space are Orthogonal Complements: How would one prove that the row space and null space are orthogonal compliments of each other? \u21a9 Proof (Dimensions of Orthogonal Complements): Henry Ricardo: A Modern Introduction to Linear Algebra, 2009. (pp. 524) \u21a9 \u21a9 \u21a9 (Dimensions of Four Fundamental Subspaces Revisited): Henry Ricardo: A Modern Introduction to Linear Algebra, 2009. (pp. 525) \u21a9 Row Space and Null Space Orthogonal: Row Space and Null Space Orthogonal \u21a9","title":"Visualization (Row Space and Null Space Orthogonal)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.07_orthogonal_projections/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\r}{\\mathbf{r}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\P}{\\mathbf{P}} \\newcommand{\\U}{\\mathbf{U}} \\newcommand{\\V}{\\mathbf{V}} \\newcommand{\\rank}{\\textbf{rank}} \\] Orthogonal Projections Most derivations are written in my Ipad. Algebraic Definition (Orthogonal Projections) Let \\(\\V\\) be the ambient vector space. A projection on a vector subspace \\(\\U \\subseteq \\V\\) is a linear mapping \\(\\pi: \\V \\to \\U\\) such that \\(\\pi^2 = \\pi\\) . If \\(\\V\\) is an inner product space , then \\(\\pi\\) can be called an orthogonal projection . Definition (Projection Matrix) We can verify that \\(\\pi\\) is indeed a linear transformaton . Recall that linear transformation can be expressed by transformation matrices . Thus we define projection matrices to be \\(\\P_\\pi\\) such that \\(\\P_\\pi^2 = \\P\\) . Derivation of Projection onto a Line \\(U\\) 1 Projection onto the x-axis In page 84, the author said if the vector \\(\\x\\) is of unit length, then projecting on the horizontal axis yields a projection vector to be \\(\\cos(\\omega)\\) . This may be confusing at first if you derive it using formula since we see that \\[ \\pi_{U}(\\x) = \\dfrac{\\b^\\top\\x}{|| \\b ||^2}\\b = \\dfrac{||\\b|| ||\\x|| \\cos(\\omega)}{||\\b||^2} \\b = \\cos(\\omega) ||\\x|| \\dfrac{\\b}{||\\b||} \\overset{||\\x|| = 1}{=} \\cos(\\omega) \\dfrac{\\b}{||\\b||} \\] where did the unit vector \\(\\hat{\\b} = \\frac{\\b}{||\\b||}\\) go? The confusion lies in two folds, one is author mentioned that this is only true when projecting onto the horizontal axis (x-axis), and secondly, the abuse of notation of vector where I misunderstood \\(\\cos(\\omega)\\) as the \"projection vector\". In fact, if we are projecting on the horizontal axis, then the basis vector \\(\\b\\) is just \\(\\begin{bmatrix}1 \\\\0 \\end{bmatrix}\\) and we have the projection vector to be actually \\[ \\pi_{U}(\\x) = \\cos(\\omega) \\dfrac{\\b}{||\\b||} = \\cos(\\omega) \\begin{bmatrix}1 \\\\0 \\end{bmatrix} = \\begin{bmatrix}\\cos(\\omega) \\\\0 \\end{bmatrix} \\] and so when mentioned loosely, we can say that the projection vector is just \\(\\cos(\\omega)\\) . Derivation of Projection onto a General Subspace \\(U\\) 2 3 The derivation using orthogonal complement provides a more intuitive understanding! Projection Onto Lower Dimensional Subspace The example here will tell you that given a vector \\(\\x \\in \\R^3\\) , it can be projected onto a lower dimensional subspace with minimal information loss since their distance is lowest. One thing to not get confused is that the projected vector is still in \\(\\R^3\\) , but it exists in a lower dimensional subspace \\(\\U \\subset \\R^3\\) embedded in \\(\\R^3\\) with 2 dimensions. Python Plot (A Visualization of Projection) Suppose we have \\(\\u = \\begin{bmatrix} 4 \\\\ 5 \\end{bmatrix}\\) , \\(\\v = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}\\) . Consider the subspace \\(\\U\\) spanned by \\(\\v\\) . We first plot the graph without the projection vector. The plots and contents (including the visualization of the decomposition) below are entirely credited to MacroAnalyst's GitHub Repo 5 . import matplotlib.pyplot as plt import matplotlib as mpl import numpy as np from mpl_toolkits.mplot3d import Axes3D import scipy as sp import scipy.linalg import scipy.spatial import sympy as sy sy . init_printing () fig , ax = plt . subplots ( figsize = ( 12 , 12 )) vects = np . array ([[ 4 , 5 ], [ 2 , 1 ]]) colr = [ \"red\" , \"blue\" ] cordt = [ \"$(4, 5)$\" , \"$(2, 1)$\" ] vec_name = [ \"$\\mathbf {u} $\" , \"$\\mathbf {v} $\" ] for i in range ( 2 ): ax . arrow ( 0 , 0 , vects [ i ][ 0 ], vects [ i ][ 1 ], color = colr [ i ], width = 0.03 , length_includes_head = True , head_width = 0.1 , # default: 3*width head_length = 0.2 , overhang = 0.4 , ) ax . text ( x = vects [ i ][ 0 ], y = vects [ i ][ 1 ], s = cordt [ i ], size = 15 ) ax . text ( x = vects [ i ][ 0 ] / 2 , y = vects [ i ][ 1 ] / 2 , s = vec_name [ i ], size = 22 ) ################################### Subspace L ############################ x = np . linspace ( 0 , 8.1 ) y = 1 / 2 * x ax . plot ( x , y , lw = 3 , color = \"red\" , alpha = 0.5 ) ax . text ( x = 6.5 , y = 3 , s = \"$L = \\operatorname{Span(\\mathbf {v} )}$\" , size = 19 ) ax . axis ([ 0 , 8 , 0 , 8 ]) ax . grid () Next, we plot the projection vector \\(\\pi_{\\U}(\\u)\\) onto \\(\\U\\) . u = np . array ([ 4 , 5 ]) v = np . array ([ 2 , 1 ]) alpha = ( u @ v ) / ( v @ v ) # the lambda coordinates print ( alpha ) proj_vec = alpha * v print ( proj_vec ) 2.6 [5.2 2.6] fig , ax = plt . subplots ( figsize = ( 12 , 12 )) vects = np . array ([[ 4 , 5 ], [ 2 , 1 ], [ 5.2 , 2.6 ]]) colr = [ \"red\" , \"blue\" , \"green\" ] cordt = [ \"$(4, 5)$\" , \"$(2, 1)$\" , \"(5.2, 2.6)\" ] vec_name = [ \"$\\mathbf {u} $\" , \"$\\mathbf {v} $\" , r \"$\\pi_{\\mathbf {U} }(\\mathbf {u} ) = \\alpha\\mathbf {v} $\" , ] for i in range ( 3 ): ax . arrow ( 0 , 0 , vects [ i ][ 0 ], vects [ i ][ 1 ], color = colr [ i ], width = 0.03 , length_includes_head = True , head_width = 0.1 , # default: 3*width head_length = 0.2 , overhang = 0.4 , zorder =- i , ) ax . text ( x = vects [ i ][ 0 ], y = vects [ i ][ 1 ], s = cordt [ i ], size = 19 ) ax . text ( x = vects [ i ][ 0 ] / 2 , y = vects [ i ][ 1 ] / 2 , s = vec_name [ i ], size = 22 ) ##################################### Components of y orthogonal to u ########################## point1 = [ 4 , 5 ] point2 = [ 5.2 , 2.6 ] line1 = np . array ([ point1 , point2 ]) ax . plot ( line1 [:, 0 ], line1 [:, 1 ], c = \"k\" , lw = 3.5 , alpha = 0.5 , ls = \"--\" ) ax . text ( 4.7 , 3.8 , \"$\\mathbf {z} $\" , size = 22 ) ################################### Subspace L ############################ x = np . linspace ( 0 , 8.1 ) y = 1 / 2 * x ax . plot ( x , y , lw = 3 , color = \"red\" , alpha = 0.5 , zorder =- 3 ) ax . text ( x = 6.5 , y = 3 , s = \"$\\mathbf {U} = \\operatorname{Span(\\mathbf {v} )}$\" , size = 19 ) ax . axis ([ 0 , 8 , 0 , 8 ]) ax . grid () #################################### Formula ################################ ax . text ( x = 1 , y = 7 , s = r \"$(\\mathbf {u} - \\alpha \\mathbf {v} )\\cdot \\mathbf {v} = 0$\" , size = 22 , color = \"b\" , ) ax . text ( x = 1 , y = 6.5 , s = r \"$\\alpha = \\frac{\\mathbf {u} \\cdot \\mathbf {v} }{\\mathbf {v} \\cdot \\mathbf {v} }$\" , size = 22 , color = \"b\" , ) ax . text ( x = 1 , y = 6 , s = r \"$\\operatorname {proj} _{\\mathbf {U} }\\mathbf {u} =\\frac{\\mathbf {u} \\cdot\\mathbf {v} }{\\mathbf {v} \\cdot\\mathbf {v} }\\mathbf {v} $\" , size = 22 , color = \"b\" , ) plt . show () Python Plot (A Visualization of Orthogonal Decomposition) To generalize the orthogonal projection in the higher dimension \\(\\mathbb{R}^n\\) , we summarize the idea into the orthogonal decomposition theorem . Let \\(W\\) be a subspace of \\(\\mathbb{R}^{n}\\) . Then each \\(\\mathbf{y}\\) in \\(\\mathbb{R}^{n}\\) can be written uniquely in the form $$ \\mathbf{y}=\\hat{\\mathbf{y}}+\\mathbf{z} $$ where \\(\\hat{\\mathbf{y}}\\) is in \\(W\\) and \\(\\mathbf{z}\\) is in \\(W^{\\perp} .\\) In fact, if \\(\\left\\{\\mathbf{u}_{1}, \\ldots, \\mathbf{u}_{p}\\right\\}\\) is any orthogonal basis of \\(W,\\) then $$ \\hat{\\mathbf{y}}=\\frac{\\mathbf{y} \\cdot \\mathbf{u} {1}}{\\mathbf{u} \\cdot \\mathbf{u} {1}} \\mathbf{u} +\\cdots+\\frac{\\mathbf{y} \\cdot \\mathbf{u} {p}}{\\mathbf{u} \\cdot \\mathbf{u} {p}} \\mathbf{u} $$ and \\(\\mathbf{z}=\\mathbf{y}-\\hat{\\mathbf{y}}\\) . In \\(\\mathbb{R}^{2}\\) , we project \\(\\mathbf{y}\\) onto subspace \\(L\\) which is spanned by \\(\\mathbf{u}\\) , here we generalize the formula for \\(\\mathbb{R}^{n}\\) , that \\(\\mathbf{y}\\) is projected onto \\(W\\) which is spanned by \\(\\left\\{\\mathbf{u}_{1}, \\ldots, \\mathbf{u}_{p}\\right\\}\\) . A Visual Example in \\(\\mathbb{R}^{3}\\) A subspace \\(W=\\operatorname{Span}\\left\\{\\mathbf{u}_{1}, \\mathbf{u}_{2}\\right\\}\\) , and a vector \\(\\mathbf{y}\\) is not in \\(W\\) , decompose \\(\\mathbf{y}\\) into \\(\\hat{\\mathbf{y}} + \\mathbf{z}\\) , and plot them. where \\[\\mathbf{u}_{1}=\\left[\\begin{array}{r} 2 \\\\ 5 \\\\ -1 \\end{array}\\right], \\mathbf{u}_{2}=\\left[\\begin{array}{r} -2 \\\\ 1 \\\\ 1 \\end{array}\\right], \\text { and } \\mathbf{y}=\\left[\\begin{array}{l} 1 \\\\ 2 \\\\ 3 \\end{array}\\right]\\] The projection onto \\(W\\) in \\(\\mathbb{R}^3\\) is \\[ \\hat{\\mathbf{y}}=\\frac{\\mathbf{y} \\cdot \\mathbf{u}_{1}}{\\mathbf{u}_{1} \\cdot \\mathbf{u}_{1}} \\mathbf{u}_{1}+\\frac{\\mathbf{y} \\cdot \\mathbf{u}_{2}}{\\mathbf{u}_{2} \\cdot \\mathbf{u}_{2}} \\mathbf{u}_{2}=\\hat{\\mathbf{y}}_{1}+\\hat{\\mathbf{y}}_{2} \\] The codes for plotting are quite redundent, however exceedingly intuitive. ######################## Subspace W ############################## s = np . linspace ( - .5 , .5 , 10 ) t = np . linspace ( - .5 , .5 , 10 ) S , T = np . meshgrid ( s , t ) X1 = 2 * S - 2 * T X2 = 5 * S + T X3 = - S + T fig = plt . figure ( figsize = ( 7 , 7 )) ax = fig . add_subplot ( projection = '3d' ) ax . plot_wireframe ( X1 , X2 , X3 , linewidth = 1.5 , alpha = .3 ) ########################### vector y ############################### y = np . array ([ 1 , 2 , 3 ]) u1 , u2 = np . array ([ 2 , 5 , - 1 ]), np . array ([ - 2 , 1 , 1 ]) vec = np . array ([[ 0 , 0 , 0 , y [ 0 ], y [ 1 ], y [ 2 ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = 'red' , alpha = .6 , arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 ) ax . text ( y [ 0 ], y [ 1 ], y [ 2 ], '$\\mathbf {y} $' , size = 15 ) ########################### vector u1 and u2 ############################### vec = np . array ([[ 0 , 0 , 0 , u1 [ 0 ], u1 [ 1 ], u1 [ 2 ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = 'red' , alpha = .6 , arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 ) vec = np . array ([[ 0 , 0 , 0 , u2 [ 0 ], u2 [ 1 ], u2 [ 2 ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = 'red' , alpha = .6 , arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 ) ax . text ( u1 [ 0 ], u1 [ 1 ], u1 [ 2 ], '$\\mathbf {u} _1$' , size = 15 ) ax . text ( u2 [ 0 ], u2 [ 1 ], u2 [ 2 ], '$\\mathbf {u} _2$' , size = 15 ) ########################### yhat ############################### alpha1 = ( y @u1 ) / ( u1 @u1 ) alpha2 = ( y @u2 ) / ( u2 @u2 ) yhat1 = alpha1 * u1 yhat2 = alpha2 * u2 yhat = yhat1 + yhat2 vec = np . array ([[ 0 , 0 , 0 , yhat1 [ 0 ], yhat1 [ 1 ], yhat1 [ 2 ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = 'blue' , alpha = .6 , arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 , zorder = 3 ) vec = np . array ([[ 0 , 0 , 0 , yhat2 [ 0 ], yhat2 [ 1 ], yhat2 [ 2 ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = 'blue' , alpha = .6 , arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 , zorder = 3 ) vec = np . array ([[ 0 , 0 , 0 , yhat [ 0 ], yhat [ 1 ], yhat [ 2 ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = 'pink' , alpha = 1 , arrow_length_ratio = .12 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 , zorder = 3 ) ax . text ( yhat1 [ 0 ], yhat1 [ 1 ], yhat1 [ 2 ], '$\\hat{\\mathbf {y} }_1$' , size = 15 ) ax . text ( yhat2 [ 0 ], yhat2 [ 1 ], yhat2 [ 2 ], '$\\hat{\\mathbf {y} }_2$' , size = 15 ) ax . text ( x = yhat [ 0 ], y = yhat [ 1 ], z = yhat [ 2 ], s = r '$\\hat{\\mathbf {y} }=\\frac{\\mathbf {y} \\cdot \\mathbf {u} _ {1} }{\\mathbf {u} _ {1} \\cdot \\mathbf {u} _ {1} } \\mathbf {u} _ {1} +\\frac{\\mathbf {y} \\cdot \\mathbf {u} _ {2} }{\\mathbf {u} _ {2} \\cdot \\mathbf {u} _ {2} } \\mathbf {u} _ {2} =\\hat{\\mathbf {y} }_ {1} +\\hat{\\mathbf {y} }_ {2} $' , size = 15 ) ########################### z ############################### z = y - yhat vec = np . array ([[ yhat [ 0 ], yhat [ 1 ], yhat [ 2 ], z [ 0 ], z [ 1 ], z [ 2 ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = 'green' , alpha = .6 , arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 ) ############################ Dashed Line #################### line1 = np . array ([ y , yhat1 ]) ax . plot ( line1 [:, 0 ], line1 [:, 1 ], line1 [:, 2 ], c = 'b' , lw = 3.5 , alpha = 0.5 , ls = '--' ) line2 = np . array ([ y , yhat2 ]) ax . plot ( line2 [:, 0 ], line2 [:, 1 ], line2 [:, 2 ], c = 'b' , lw = 2.5 , alpha = 0.5 , ls = '--' ) line3 = np . array ([ yhat , yhat2 ]) ax . plot ( line3 [:, 0 ], line3 [:, 1 ], line3 [:, 2 ], c = 'b' , lw = 2.5 , alpha = 0.5 , ls = '--' ) line4 = np . array ([ yhat , yhat1 ]) ax . plot ( line4 [:, 0 ], line4 [:, 1 ], line4 [:, 2 ], c = 'b' , lw = 2.5 , alpha = 0.5 , ls = '--' ) ############################# View Angel ax . view_init ( elev =- 6 , azim = 12 ) Derivation of Projection onto a Line: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 82-85) \u21a9 Derivation of Projection onto a General Subspace: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 85-88) \u21a9 Derivation of Projection onto a General Subspace: Khan's Academy Projection onto a General Subspace \u21a9 Projection Onto Lower Dimensional Subspace: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 87-88) \u21a9 Plotting Projections in Python: Plot Projections in Python \u21a9","title":"Orthogonal Projection"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.07_orthogonal_projections/#orthogonal-projections","text":"Most derivations are written in my Ipad.","title":"Orthogonal Projections"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.07_orthogonal_projections/#algebraic-definition-orthogonal-projections","text":"Let \\(\\V\\) be the ambient vector space. A projection on a vector subspace \\(\\U \\subseteq \\V\\) is a linear mapping \\(\\pi: \\V \\to \\U\\) such that \\(\\pi^2 = \\pi\\) . If \\(\\V\\) is an inner product space , then \\(\\pi\\) can be called an orthogonal projection .","title":"Algebraic Definition (Orthogonal Projections)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.07_orthogonal_projections/#definition-projection-matrix","text":"We can verify that \\(\\pi\\) is indeed a linear transformaton . Recall that linear transformation can be expressed by transformation matrices . Thus we define projection matrices to be \\(\\P_\\pi\\) such that \\(\\P_\\pi^2 = \\P\\) .","title":"Definition (Projection Matrix)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.07_orthogonal_projections/#derivation-of-projection-onto-a-line-u1","text":"","title":"Derivation of Projection onto a Line \\(U\\)1"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.07_orthogonal_projections/#projection-onto-the-x-axis","text":"In page 84, the author said if the vector \\(\\x\\) is of unit length, then projecting on the horizontal axis yields a projection vector to be \\(\\cos(\\omega)\\) . This may be confusing at first if you derive it using formula since we see that \\[ \\pi_{U}(\\x) = \\dfrac{\\b^\\top\\x}{|| \\b ||^2}\\b = \\dfrac{||\\b|| ||\\x|| \\cos(\\omega)}{||\\b||^2} \\b = \\cos(\\omega) ||\\x|| \\dfrac{\\b}{||\\b||} \\overset{||\\x|| = 1}{=} \\cos(\\omega) \\dfrac{\\b}{||\\b||} \\] where did the unit vector \\(\\hat{\\b} = \\frac{\\b}{||\\b||}\\) go? The confusion lies in two folds, one is author mentioned that this is only true when projecting onto the horizontal axis (x-axis), and secondly, the abuse of notation of vector where I misunderstood \\(\\cos(\\omega)\\) as the \"projection vector\". In fact, if we are projecting on the horizontal axis, then the basis vector \\(\\b\\) is just \\(\\begin{bmatrix}1 \\\\0 \\end{bmatrix}\\) and we have the projection vector to be actually \\[ \\pi_{U}(\\x) = \\cos(\\omega) \\dfrac{\\b}{||\\b||} = \\cos(\\omega) \\begin{bmatrix}1 \\\\0 \\end{bmatrix} = \\begin{bmatrix}\\cos(\\omega) \\\\0 \\end{bmatrix} \\] and so when mentioned loosely, we can say that the projection vector is just \\(\\cos(\\omega)\\) .","title":"Projection onto the x-axis"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.07_orthogonal_projections/#derivation-of-projection-onto-a-general-subspace-u23","text":"The derivation using orthogonal complement provides a more intuitive understanding!","title":"Derivation of Projection onto a General Subspace \\(U\\)23"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.07_orthogonal_projections/#projection-onto-lower-dimensional-subspace","text":"The example here will tell you that given a vector \\(\\x \\in \\R^3\\) , it can be projected onto a lower dimensional subspace with minimal information loss since their distance is lowest. One thing to not get confused is that the projected vector is still in \\(\\R^3\\) , but it exists in a lower dimensional subspace \\(\\U \\subset \\R^3\\) embedded in \\(\\R^3\\) with 2 dimensions.","title":"Projection Onto Lower Dimensional Subspace"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.07_orthogonal_projections/#python-plot-a-visualization-of-projection","text":"Suppose we have \\(\\u = \\begin{bmatrix} 4 \\\\ 5 \\end{bmatrix}\\) , \\(\\v = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}\\) . Consider the subspace \\(\\U\\) spanned by \\(\\v\\) . We first plot the graph without the projection vector. The plots and contents (including the visualization of the decomposition) below are entirely credited to MacroAnalyst's GitHub Repo 5 . import matplotlib.pyplot as plt import matplotlib as mpl import numpy as np from mpl_toolkits.mplot3d import Axes3D import scipy as sp import scipy.linalg import scipy.spatial import sympy as sy sy . init_printing () fig , ax = plt . subplots ( figsize = ( 12 , 12 )) vects = np . array ([[ 4 , 5 ], [ 2 , 1 ]]) colr = [ \"red\" , \"blue\" ] cordt = [ \"$(4, 5)$\" , \"$(2, 1)$\" ] vec_name = [ \"$\\mathbf {u} $\" , \"$\\mathbf {v} $\" ] for i in range ( 2 ): ax . arrow ( 0 , 0 , vects [ i ][ 0 ], vects [ i ][ 1 ], color = colr [ i ], width = 0.03 , length_includes_head = True , head_width = 0.1 , # default: 3*width head_length = 0.2 , overhang = 0.4 , ) ax . text ( x = vects [ i ][ 0 ], y = vects [ i ][ 1 ], s = cordt [ i ], size = 15 ) ax . text ( x = vects [ i ][ 0 ] / 2 , y = vects [ i ][ 1 ] / 2 , s = vec_name [ i ], size = 22 ) ################################### Subspace L ############################ x = np . linspace ( 0 , 8.1 ) y = 1 / 2 * x ax . plot ( x , y , lw = 3 , color = \"red\" , alpha = 0.5 ) ax . text ( x = 6.5 , y = 3 , s = \"$L = \\operatorname{Span(\\mathbf {v} )}$\" , size = 19 ) ax . axis ([ 0 , 8 , 0 , 8 ]) ax . grid () Next, we plot the projection vector \\(\\pi_{\\U}(\\u)\\) onto \\(\\U\\) . u = np . array ([ 4 , 5 ]) v = np . array ([ 2 , 1 ]) alpha = ( u @ v ) / ( v @ v ) # the lambda coordinates print ( alpha ) proj_vec = alpha * v print ( proj_vec ) 2.6 [5.2 2.6] fig , ax = plt . subplots ( figsize = ( 12 , 12 )) vects = np . array ([[ 4 , 5 ], [ 2 , 1 ], [ 5.2 , 2.6 ]]) colr = [ \"red\" , \"blue\" , \"green\" ] cordt = [ \"$(4, 5)$\" , \"$(2, 1)$\" , \"(5.2, 2.6)\" ] vec_name = [ \"$\\mathbf {u} $\" , \"$\\mathbf {v} $\" , r \"$\\pi_{\\mathbf {U} }(\\mathbf {u} ) = \\alpha\\mathbf {v} $\" , ] for i in range ( 3 ): ax . arrow ( 0 , 0 , vects [ i ][ 0 ], vects [ i ][ 1 ], color = colr [ i ], width = 0.03 , length_includes_head = True , head_width = 0.1 , # default: 3*width head_length = 0.2 , overhang = 0.4 , zorder =- i , ) ax . text ( x = vects [ i ][ 0 ], y = vects [ i ][ 1 ], s = cordt [ i ], size = 19 ) ax . text ( x = vects [ i ][ 0 ] / 2 , y = vects [ i ][ 1 ] / 2 , s = vec_name [ i ], size = 22 ) ##################################### Components of y orthogonal to u ########################## point1 = [ 4 , 5 ] point2 = [ 5.2 , 2.6 ] line1 = np . array ([ point1 , point2 ]) ax . plot ( line1 [:, 0 ], line1 [:, 1 ], c = \"k\" , lw = 3.5 , alpha = 0.5 , ls = \"--\" ) ax . text ( 4.7 , 3.8 , \"$\\mathbf {z} $\" , size = 22 ) ################################### Subspace L ############################ x = np . linspace ( 0 , 8.1 ) y = 1 / 2 * x ax . plot ( x , y , lw = 3 , color = \"red\" , alpha = 0.5 , zorder =- 3 ) ax . text ( x = 6.5 , y = 3 , s = \"$\\mathbf {U} = \\operatorname{Span(\\mathbf {v} )}$\" , size = 19 ) ax . axis ([ 0 , 8 , 0 , 8 ]) ax . grid () #################################### Formula ################################ ax . text ( x = 1 , y = 7 , s = r \"$(\\mathbf {u} - \\alpha \\mathbf {v} )\\cdot \\mathbf {v} = 0$\" , size = 22 , color = \"b\" , ) ax . text ( x = 1 , y = 6.5 , s = r \"$\\alpha = \\frac{\\mathbf {u} \\cdot \\mathbf {v} }{\\mathbf {v} \\cdot \\mathbf {v} }$\" , size = 22 , color = \"b\" , ) ax . text ( x = 1 , y = 6 , s = r \"$\\operatorname {proj} _{\\mathbf {U} }\\mathbf {u} =\\frac{\\mathbf {u} \\cdot\\mathbf {v} }{\\mathbf {v} \\cdot\\mathbf {v} }\\mathbf {v} $\" , size = 22 , color = \"b\" , ) plt . show ()","title":"Python Plot (A Visualization of Projection)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.07_orthogonal_projections/#python-plot-a-visualization-of-orthogonal-decomposition","text":"To generalize the orthogonal projection in the higher dimension \\(\\mathbb{R}^n\\) , we summarize the idea into the orthogonal decomposition theorem . Let \\(W\\) be a subspace of \\(\\mathbb{R}^{n}\\) . Then each \\(\\mathbf{y}\\) in \\(\\mathbb{R}^{n}\\) can be written uniquely in the form $$ \\mathbf{y}=\\hat{\\mathbf{y}}+\\mathbf{z} $$ where \\(\\hat{\\mathbf{y}}\\) is in \\(W\\) and \\(\\mathbf{z}\\) is in \\(W^{\\perp} .\\) In fact, if \\(\\left\\{\\mathbf{u}_{1}, \\ldots, \\mathbf{u}_{p}\\right\\}\\) is any orthogonal basis of \\(W,\\) then $$ \\hat{\\mathbf{y}}=\\frac{\\mathbf{y} \\cdot \\mathbf{u} {1}}{\\mathbf{u} \\cdot \\mathbf{u} {1}} \\mathbf{u} +\\cdots+\\frac{\\mathbf{y} \\cdot \\mathbf{u} {p}}{\\mathbf{u} \\cdot \\mathbf{u} {p}} \\mathbf{u} $$ and \\(\\mathbf{z}=\\mathbf{y}-\\hat{\\mathbf{y}}\\) . In \\(\\mathbb{R}^{2}\\) , we project \\(\\mathbf{y}\\) onto subspace \\(L\\) which is spanned by \\(\\mathbf{u}\\) , here we generalize the formula for \\(\\mathbb{R}^{n}\\) , that \\(\\mathbf{y}\\) is projected onto \\(W\\) which is spanned by \\(\\left\\{\\mathbf{u}_{1}, \\ldots, \\mathbf{u}_{p}\\right\\}\\) .","title":"Python Plot (A Visualization of Orthogonal Decomposition)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.07_orthogonal_projections/#a-visual-example-in-mathbbr3","text":"A subspace \\(W=\\operatorname{Span}\\left\\{\\mathbf{u}_{1}, \\mathbf{u}_{2}\\right\\}\\) , and a vector \\(\\mathbf{y}\\) is not in \\(W\\) , decompose \\(\\mathbf{y}\\) into \\(\\hat{\\mathbf{y}} + \\mathbf{z}\\) , and plot them. where \\[\\mathbf{u}_{1}=\\left[\\begin{array}{r} 2 \\\\ 5 \\\\ -1 \\end{array}\\right], \\mathbf{u}_{2}=\\left[\\begin{array}{r} -2 \\\\ 1 \\\\ 1 \\end{array}\\right], \\text { and } \\mathbf{y}=\\left[\\begin{array}{l} 1 \\\\ 2 \\\\ 3 \\end{array}\\right]\\] The projection onto \\(W\\) in \\(\\mathbb{R}^3\\) is \\[ \\hat{\\mathbf{y}}=\\frac{\\mathbf{y} \\cdot \\mathbf{u}_{1}}{\\mathbf{u}_{1} \\cdot \\mathbf{u}_{1}} \\mathbf{u}_{1}+\\frac{\\mathbf{y} \\cdot \\mathbf{u}_{2}}{\\mathbf{u}_{2} \\cdot \\mathbf{u}_{2}} \\mathbf{u}_{2}=\\hat{\\mathbf{y}}_{1}+\\hat{\\mathbf{y}}_{2} \\] The codes for plotting are quite redundent, however exceedingly intuitive. ######################## Subspace W ############################## s = np . linspace ( - .5 , .5 , 10 ) t = np . linspace ( - .5 , .5 , 10 ) S , T = np . meshgrid ( s , t ) X1 = 2 * S - 2 * T X2 = 5 * S + T X3 = - S + T fig = plt . figure ( figsize = ( 7 , 7 )) ax = fig . add_subplot ( projection = '3d' ) ax . plot_wireframe ( X1 , X2 , X3 , linewidth = 1.5 , alpha = .3 ) ########################### vector y ############################### y = np . array ([ 1 , 2 , 3 ]) u1 , u2 = np . array ([ 2 , 5 , - 1 ]), np . array ([ - 2 , 1 , 1 ]) vec = np . array ([[ 0 , 0 , 0 , y [ 0 ], y [ 1 ], y [ 2 ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = 'red' , alpha = .6 , arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 ) ax . text ( y [ 0 ], y [ 1 ], y [ 2 ], '$\\mathbf {y} $' , size = 15 ) ########################### vector u1 and u2 ############################### vec = np . array ([[ 0 , 0 , 0 , u1 [ 0 ], u1 [ 1 ], u1 [ 2 ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = 'red' , alpha = .6 , arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 ) vec = np . array ([[ 0 , 0 , 0 , u2 [ 0 ], u2 [ 1 ], u2 [ 2 ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = 'red' , alpha = .6 , arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 ) ax . text ( u1 [ 0 ], u1 [ 1 ], u1 [ 2 ], '$\\mathbf {u} _1$' , size = 15 ) ax . text ( u2 [ 0 ], u2 [ 1 ], u2 [ 2 ], '$\\mathbf {u} _2$' , size = 15 ) ########################### yhat ############################### alpha1 = ( y @u1 ) / ( u1 @u1 ) alpha2 = ( y @u2 ) / ( u2 @u2 ) yhat1 = alpha1 * u1 yhat2 = alpha2 * u2 yhat = yhat1 + yhat2 vec = np . array ([[ 0 , 0 , 0 , yhat1 [ 0 ], yhat1 [ 1 ], yhat1 [ 2 ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = 'blue' , alpha = .6 , arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 , zorder = 3 ) vec = np . array ([[ 0 , 0 , 0 , yhat2 [ 0 ], yhat2 [ 1 ], yhat2 [ 2 ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = 'blue' , alpha = .6 , arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 , zorder = 3 ) vec = np . array ([[ 0 , 0 , 0 , yhat [ 0 ], yhat [ 1 ], yhat [ 2 ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = 'pink' , alpha = 1 , arrow_length_ratio = .12 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 , zorder = 3 ) ax . text ( yhat1 [ 0 ], yhat1 [ 1 ], yhat1 [ 2 ], '$\\hat{\\mathbf {y} }_1$' , size = 15 ) ax . text ( yhat2 [ 0 ], yhat2 [ 1 ], yhat2 [ 2 ], '$\\hat{\\mathbf {y} }_2$' , size = 15 ) ax . text ( x = yhat [ 0 ], y = yhat [ 1 ], z = yhat [ 2 ], s = r '$\\hat{\\mathbf {y} }=\\frac{\\mathbf {y} \\cdot \\mathbf {u} _ {1} }{\\mathbf {u} _ {1} \\cdot \\mathbf {u} _ {1} } \\mathbf {u} _ {1} +\\frac{\\mathbf {y} \\cdot \\mathbf {u} _ {2} }{\\mathbf {u} _ {2} \\cdot \\mathbf {u} _ {2} } \\mathbf {u} _ {2} =\\hat{\\mathbf {y} }_ {1} +\\hat{\\mathbf {y} }_ {2} $' , size = 15 ) ########################### z ############################### z = y - yhat vec = np . array ([[ yhat [ 0 ], yhat [ 1 ], yhat [ 2 ], z [ 0 ], z [ 1 ], z [ 2 ]]]) X , Y , Z , U , V , W = zip ( * vec ) ax . quiver ( X , Y , Z , U , V , W , length = 1 , normalize = False , color = 'green' , alpha = .6 , arrow_length_ratio = .08 , pivot = 'tail' , linestyles = 'solid' , linewidths = 3 ) ############################ Dashed Line #################### line1 = np . array ([ y , yhat1 ]) ax . plot ( line1 [:, 0 ], line1 [:, 1 ], line1 [:, 2 ], c = 'b' , lw = 3.5 , alpha = 0.5 , ls = '--' ) line2 = np . array ([ y , yhat2 ]) ax . plot ( line2 [:, 0 ], line2 [:, 1 ], line2 [:, 2 ], c = 'b' , lw = 2.5 , alpha = 0.5 , ls = '--' ) line3 = np . array ([ yhat , yhat2 ]) ax . plot ( line3 [:, 0 ], line3 [:, 1 ], line3 [:, 2 ], c = 'b' , lw = 2.5 , alpha = 0.5 , ls = '--' ) line4 = np . array ([ yhat , yhat1 ]) ax . plot ( line4 [:, 0 ], line4 [:, 1 ], line4 [:, 2 ], c = 'b' , lw = 2.5 , alpha = 0.5 , ls = '--' ) ############################# View Angel ax . view_init ( elev =- 6 , azim = 12 ) Derivation of Projection onto a Line: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 82-85) \u21a9 Derivation of Projection onto a General Subspace: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 85-88) \u21a9 Derivation of Projection onto a General Subspace: Khan's Academy Projection onto a General Subspace \u21a9 Projection Onto Lower Dimensional Subspace: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 87-88) \u21a9 Plotting Projections in Python: Plot Projections in Python \u21a9","title":" A Visual Example in \\(\\mathbb{R}^{3}\\)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.08_orthogonal_matrices_and_basis/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\q}{\\mathbf{q}} \\newcommand{\\r}{\\mathbf{r}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\I}{\\mathbf{I}} \\newcommand{\\P}{\\mathbf{P}} \\newcommand{\\Q}{\\mathbf{Q}} \\newcommand{\\U}{\\mathbf{U}} \\newcommand{\\V}{\\mathbf{V}} \\newcommand{\\rank}{\\textbf{rank}} \\] Orthogonal Matrix Definition (Orthogonal Matrix) We mentioned this before in the matrix chapter. An orthogonal matrix is a square matrix \\(\\Q\\) with real entries whose columns and rows are orthogonal unit vectors (that is, orthonormal vectors). This means: All columns of the matrix are pairwise orthogonal, which means for any \\(\\q_i, \\q_j\\) of the columns \\(\\Q\\) , we have \\(\\q_i \\cdot \\q_j = \\0\\) Each column of the matrix has unit length and are therefore unit vectors: \\(\\Vert \\q_i \\Vert = \\1\\) . From the above, we can deduce a notation: \\[ \\Q_i \\cdot \\Q_j = \\begin{cases} 1\\hspace{0.5cm} \\text{if } i=j \\\\ 0\\hspace{0.5cm} \\text{if } i \\neq j \\end{cases} \\] To make the notation/expression more compact, we can write that a matrix \\(\\Q\\) is orthogonal if: \\[ \\Q^\\top \\Q = \\I \\] Theorem (Equivalence of Transpose and Inverse in Orthogonal Matrix) For any orthogonal matrix \\(\\Q\\) , we have its transpose equals to its inverse: \\[ \\Q^\\top = \\Q^{-1} \\] The proof is relatively easy since by definition \\(\\Q^\\top\\Q = \\I \\implies \\Q^\\top\\Q = \\Q^{-1}\\Q\\) . This result isn't trivial as computing inverse is significantly more difficult than computing transpose! General Form of 2 by 2 Orthogonal Matrix Given any angle \\(\\theta\\) , we can construct the 2 by 2 orthogonal matrix \\(\\Q\\) : \\[ \\Q = \\begin{bmatrix} \\cos(\\theta) & -\\sin(\\theta) \\\\ \\sin(\\theta) & \\cos(\\theta) \\end{bmatrix} \\] This is easy to see as we just need to verify the two properties: \\(-\\cos(\\theta)\\sin(\\theta) + \\sin(\\theta)\\cos(\\theta) = 0\\) ; The length of each column is unit length of \\(1\\) by the property of \\(\\sin(\\theta)^2 + \\cos(\\theta)^2 = 1\\) . Rectangular Orthogonal Matrices 1 Orthogonal and Orthonormal Basis 2 Orthogonal Basis Orthonormal Basis Rectangular Orthogonal Matrices: Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 372-373) \u21a9 Orthogonal and Orthonormal Basis: Henry Ricardo: A Modern Introduction to Linear Algebra, 2009. (pp. 477-480) \u21a9","title":"Orthogonal Matrices and Basis"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.08_orthogonal_matrices_and_basis/#orthogonal-matrix","text":"","title":"Orthogonal Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.08_orthogonal_matrices_and_basis/#definition-orthogonal-matrix","text":"We mentioned this before in the matrix chapter. An orthogonal matrix is a square matrix \\(\\Q\\) with real entries whose columns and rows are orthogonal unit vectors (that is, orthonormal vectors). This means: All columns of the matrix are pairwise orthogonal, which means for any \\(\\q_i, \\q_j\\) of the columns \\(\\Q\\) , we have \\(\\q_i \\cdot \\q_j = \\0\\) Each column of the matrix has unit length and are therefore unit vectors: \\(\\Vert \\q_i \\Vert = \\1\\) . From the above, we can deduce a notation: \\[ \\Q_i \\cdot \\Q_j = \\begin{cases} 1\\hspace{0.5cm} \\text{if } i=j \\\\ 0\\hspace{0.5cm} \\text{if } i \\neq j \\end{cases} \\] To make the notation/expression more compact, we can write that a matrix \\(\\Q\\) is orthogonal if: \\[ \\Q^\\top \\Q = \\I \\]","title":"Definition (Orthogonal Matrix)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.08_orthogonal_matrices_and_basis/#theorem-equivalence-of-transpose-and-inverse-in-orthogonal-matrix","text":"For any orthogonal matrix \\(\\Q\\) , we have its transpose equals to its inverse: \\[ \\Q^\\top = \\Q^{-1} \\] The proof is relatively easy since by definition \\(\\Q^\\top\\Q = \\I \\implies \\Q^\\top\\Q = \\Q^{-1}\\Q\\) . This result isn't trivial as computing inverse is significantly more difficult than computing transpose!","title":"Theorem (Equivalence of Transpose and Inverse in Orthogonal Matrix)"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.08_orthogonal_matrices_and_basis/#general-form-of-2-by-2-orthogonal-matrix","text":"Given any angle \\(\\theta\\) , we can construct the 2 by 2 orthogonal matrix \\(\\Q\\) : \\[ \\Q = \\begin{bmatrix} \\cos(\\theta) & -\\sin(\\theta) \\\\ \\sin(\\theta) & \\cos(\\theta) \\end{bmatrix} \\] This is easy to see as we just need to verify the two properties: \\(-\\cos(\\theta)\\sin(\\theta) + \\sin(\\theta)\\cos(\\theta) = 0\\) ; The length of each column is unit length of \\(1\\) by the property of \\(\\sin(\\theta)^2 + \\cos(\\theta)^2 = 1\\) .","title":"General Form of 2 by 2 Orthogonal Matrix"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.08_orthogonal_matrices_and_basis/#rectangular-orthogonal-matrices-1","text":"","title":"Rectangular Orthogonal Matrices 1"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.08_orthogonal_matrices_and_basis/#orthogonal-and-orthonormal-basis-2","text":"","title":"Orthogonal and Orthonormal Basis 2"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.08_orthogonal_matrices_and_basis/#orthogonal-basis","text":"","title":"Orthogonal Basis"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.08_orthogonal_matrices_and_basis/#orthonormal-basis","text":"Rectangular Orthogonal Matrices: Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 372-373) \u21a9 Orthogonal and Orthonormal Basis: Henry Ricardo: A Modern Introduction to Linear Algebra, 2009. (pp. 477-480) \u21a9","title":"Orthonormal Basis"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.09_gram_schmidt_orthogonalization/","text":"\\[ \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\r}{\\mathbf{r}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\C}{\\mathbf{C}} \\newcommand{\\P}{\\mathbf{P}} \\newcommand{\\U}{\\mathbf{U}} \\newcommand{\\V}{\\mathbf{V}} \\newcommand{\\rank}{\\textbf{rank}} \\] Gram-Schmidt The motivation of Gram-Schmidt is clear when we realize working with orthogonal/orthonormal vectors yield desirable properties. For example, a basis vector \\(\\B = \\{\\b_1, \\b_2, \\ldots, \\b_n\\}\\) of a \\(\\R^n\\) space can be transformed into a set of orthogonal vectors for easier processing. With this in mind, we go through a method to do so. Geometric Intuition (Gram-Schmidt) 1 2 We leave the heavy lifting in the two references. But the intuition can be simply derived in \\(\\R^2\\) space. Consider \\(2\\) basis vectors \\(\\{\\u, \\v\\}\\) of \\(\\R^2\\) , then fix the vector \\(\\u\\) , and find the projection of the vector \\(\\u\\) on \\(\\v\\) . Recall this is found by: \\[ \\textbf{proj}_{\\u}(\\v) = \\dfrac{\\u \\cdot \\v}{\\u \\cdot \\u} \\u \\] Then \\(\\v- \\textbf{proj}_{\\u}(\\v)\\) is guaranteed to be orthogonal to \\(\\u\\) by definition and this method holds for any \\(\\u, \\v\\) in \\(\\R^n\\) where \\(\\u \\neq \\0\\) . In \\(\\R^2\\) space, we have already turned \\(\\u, \\v\\) to \\(\\u, \\v- \\textbf{proj}_{\\u}(\\v)\\) where the latter is a set of orthogonal vectors that is also a basis of \\(\\R^2\\) . Note one should be clear by now that orthogonal vectors like these are guanranteed to be linearly independent and since the cardinality is \\(2\\) , it spans the \\(R^2\\) space. To further make them orthonormal , we further divide them by their length as a way of normalization and that is all. For higher dimensions, the process is iteratively applied. QR Decomposition Geometric Intuition of Gram-Schmidt: Henry Ricardo: A Modern Introduction to Linear Algebra, 2009. (pp. 483-485) \u21a9 Geometric Intuition of Gram-Schmidt: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 89-90) \u21a9","title":"Gram-Schmidt Orthogonalization"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.09_gram_schmidt_orthogonalization/#gram-schmidt","text":"The motivation of Gram-Schmidt is clear when we realize working with orthogonal/orthonormal vectors yield desirable properties. For example, a basis vector \\(\\B = \\{\\b_1, \\b_2, \\ldots, \\b_n\\}\\) of a \\(\\R^n\\) space can be transformed into a set of orthogonal vectors for easier processing. With this in mind, we go through a method to do so.","title":"Gram-Schmidt"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.09_gram_schmidt_orthogonalization/#geometric-intuition-gram-schmidt1-2","text":"We leave the heavy lifting in the two references. But the intuition can be simply derived in \\(\\R^2\\) space. Consider \\(2\\) basis vectors \\(\\{\\u, \\v\\}\\) of \\(\\R^2\\) , then fix the vector \\(\\u\\) , and find the projection of the vector \\(\\u\\) on \\(\\v\\) . Recall this is found by: \\[ \\textbf{proj}_{\\u}(\\v) = \\dfrac{\\u \\cdot \\v}{\\u \\cdot \\u} \\u \\] Then \\(\\v- \\textbf{proj}_{\\u}(\\v)\\) is guaranteed to be orthogonal to \\(\\u\\) by definition and this method holds for any \\(\\u, \\v\\) in \\(\\R^n\\) where \\(\\u \\neq \\0\\) . In \\(\\R^2\\) space, we have already turned \\(\\u, \\v\\) to \\(\\u, \\v- \\textbf{proj}_{\\u}(\\v)\\) where the latter is a set of orthogonal vectors that is also a basis of \\(\\R^2\\) . Note one should be clear by now that orthogonal vectors like these are guanranteed to be linearly independent and since the cardinality is \\(2\\) , it spans the \\(R^2\\) space. To further make them orthonormal , we further divide them by their length as a way of normalization and that is all. For higher dimensions, the process is iteratively applied.","title":"Geometric Intuition (Gram-Schmidt)1 2"},{"location":"reighns_ml_journey/mathematics/linear_algebra/08_analytic_geometry/08.09_gram_schmidt_orthogonalization/#qr-decomposition","text":"Geometric Intuition of Gram-Schmidt: Henry Ricardo: A Modern Introduction to Linear Algebra, 2009. (pp. 483-485) \u21a9 Geometric Intuition of Gram-Schmidt: Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 89-90) \u21a9","title":"QR Decomposition"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/day-1-binomial-distribution/","text":"66 Days of Data [04/07/2021] Day 2 This is slightly modified from the original module in Datacamp, as I find it better to put the concept of covariance later on. Quick Navigation * [Dependencies](#1) * [Configurations](#2) * [Seeding](#3) * [Loading Iris Data](#4) * [Quantitative Exploratory Data Analysis](#5) * [Descripte Analytics](#51) * [Mean](#511) * [Median](#512) * [Mode](#513) * [Range](#514) * [Population Variance](#515) * [Population Standard Deviation](#516) * [Percentiles](#517) * [Box and Whiskers Plot](#52) Dependencies # !pip install -U -q scikit-learn==0.24.2 import os import random import sys import seaborn as sns import matplotlib as mpl import matplotlib.pyplot as plt import numpy as np import pandas as pd import sklearn import torch import scipy from tqdm import tqdm from sklearn.datasets import * assert sys . version_info >= ( 3 , 5 ) assert sklearn . __version__ >= \"0.20\" Configurations % matplotlib inline sns . set ( style = \"ticks\" ) plt . style . use ( \"dark_background\" ) # mpl.rc('axes', labelsize=15) # mpl.rc('xtick', labelsize=12) # mpl.rc('ytick', labelsize=12) # Where to save the figures PROJECT_ROOT_DIR = \".\" CHAPTER_ID = \"Quantitative Exploratory Data Analysis\" IMAGES_PATH = os . path . join ( PROJECT_ROOT_DIR , \"images\" , CHAPTER_ID ) os . makedirs ( IMAGES_PATH , exist_ok = True ) def save_fig ( fig_id , tight_layout = True , fig_extension = \"png\" , resolution = 300 ): path = os . path . join ( IMAGES_PATH , fig_id + \".\" + fig_extension ) print ( \"Saving figure\" , fig_id ) if tight_layout : plt . tight_layout () plt . savefig ( path , format = fig_extension , dpi = resolution ) def ecdf ( data ): \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\" # Number of data points: n n = len ( data ) # x-data for the ECDF: x x = np . sort ( data ) # y-data for the ECDF: y y = np . arange ( start = 1 , stop = n + 1 ) / n return x , y Seeding def seed_all ( seed : int = 1930 ): \"\"\"Seed all random number generators.\"\"\" print ( \"Using Seed Number {} \" . format ( seed )) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator random . seed ( seed ) # set fixed value for python built-in pseudo-random generator torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False torch . backends . cudnn . enabled = False def seed_worker ( _worker_id ): \"\"\"Seed a worker with the given ID.\"\"\" worker_seed = torch . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) seed_all ( 42 ) In [probability](probability_theory \"wikilink\") and [statistics](statistics \"wikilink\"), a **probability mass function** is a function that gives the probability that a [discrete random variable](discrete_random_variable \"wikilink\") is exactly equal to some value.[^1] Sometimes it is also known as the discrete density function. The probability mass function is often the primary means of defining a [discrete probability distribution](discrete_probability_distribution \"wikilink\"), and such functions exist for either [scalar](Scalar_variable \"wikilink\") or [multivariate random variables](multivariate_random_variable \"wikilink\") whose [domain](Domain_of_a_function \"wikilink\") is discrete. A probability mass function differs from a [probability density function](probability_density_function \"wikilink\") (PDF) in that the latter is associated with continuous rather than discrete random variables. A PDF must be [integrated](integration_(mathematics) \"wikilink\") over an interval to yield a probability.[^2] The value of the random variable having the largest probability mass is called the [mode](mode_(statistics) \"wikilink\"). ## Introduction to Inferential Statistics ### Review of Probability Theory #### Properties of expected values and variances Let $X$ be an arbitrary random variable, and $a$ and $c$ are two constants, then we have - $\\mathbb{E}(c) = c$; - $\\mathbb{E}(aX+c) = a\\mathbb{E}(X) + c$. If $\\{a_1, a_2, ..., a_n\\}$ is a sequence of constants, and $\\{X_1, X_2, ..., X_n\\}$ is a sequence of random variables, then we have - $\\mathbb{E}\\left(\\sum\\limits_{i=1}^na_iX_i\\right) = \\sum\\limits_{i=1}^na_i\\mathbb{E}(X_i)$ As a special case that each $a_i=1$, then the equation above can be written as $\\mathbb{E}\\left(\\sum_{i=1}^nX_i\\right)=\\sum_{i=1}^n\\mathbb{E}(X_i)$. Let $X$ and $Y$ be two random variables, and $a$, $b$, and $c$ are three constants, then we have - $\\text{Var}(c) = 0$; - $\\text{Var}(aX+c) = a^2\\text{Var}(X)$; - $\\text{Var}(aX+bY+c) = a^2\\text{Var}(X) + b^2\\text{Var}(Y) + 2ab\\text{Cov}(X, Y)$. In a special case that $X$ and $Y$ are uncorrelated, the covariance between $X$ and $Y$ is zero, so the last equation can be written as $\\text{Var}(aX+bY+c) = a^2\\text{Var}(X) + b^2\\text{Var}(Y)$. Such a result can be extend to the following case - $\\text{Var}\\left(\\sum\\limits_{i=1}^na_iX_i\\right) = \\sum\\limits_{i=1}^na_i^2\\text{Var}(X_i)$, where $\\{a_1, a_2, ..., a_n\\}$ is a sequence of constants, and $\\{X_1, X_2, ..., X_n\\}$ is a sequence of **pairwise uncorrelated** random variables. #### Discrete random variables and their distributions A random variable $X$ is defined to be **discrete** if its possible outcomes are finite or countable. A few examples are given below. 1. The result of rolling a dice (discrete uniform distribution) 2. The preference of one customer for Coke or Pepsi (Bernoulli distribution) 3. Among 10 customers, the number of people who prefer Coke over Pepsi (Binomial distribution) 4. The number of patients arriving in an emergency room within a fixed time interval (Poisson distribution) Notes: For a discrete random variable $X$ with $k$ possible outcomes $x_j$, the probability mass function (PMF) is given by: \\begin{align} P(X=x_j) = p_j, \\text{ for each }j=1, 2, ..., k, \\end{align} where $p_j$ is the probability of the outcome $x_j$, and all $p_i$ must satisfy \\begin{cases} 0\\leq p_i \\leq 1 \\\\ \\sum_{j=1}^kp_j = 1 \\end{cases} Example 4: Suppose that in Singapore, $65\\%$ of customers prefer Coke, while the remaining $35\\%$ prefer Pepsi. Now we randomly survey 10 customers, among which the number of customers who prefer Coke is denoted by a discrete random variable $X$. Plot the PMF of $X$. ### [Probability Mass Function] Definition: For a discrete random variable $X$ with $k$ possible outcomes $x_j$, the probability mass function (PMF) is given by: \\begin{align} P(X=x_j) = p_X(x_j), \\text{ for each }j=1, 2, ..., k, \\end{align} where $p_X(x_j)$ is the probability of the outcome $x_j$, and all $p_X(x_i)$ must satisfy \\begin{cases} 0\\leq p_X(x_i) \\leq 1 \\\\ \\sum_{j=1}^kp_j = 1 \\end{cases} The probability mass function $f$ for outcomes $k$ and probabilities $p$ is: ### $$ pmf(k; p) = \\begin{cases} p & \\text{for }k=1 \\\\ q=(1-p) & \\text{for }k=0 \\\\ \\end{cases} $$ ### [Bernoulli Trials] **Note Bernoulli Trial is not the same Bernoulli Distribution, in terms of definition**. Definition: The performance of a fixed number of trials with fixed probability of success on each trial is known as a Bernoulli trial. Independent repeated trials of an experiment with exactly two possible outcomes are called Bernoulli trials. Call one of the outcomes \"success\" and the other outcome \"failure\". Let $p$ be the probability of success in a Bernoulli trial, and $q$ be the probability of failure. Then the probability of success and the probability of failure sum to one, since these are complementary events: \"success\" and \"failure\" are mutually exclusive and exhaustive. Thus one has the following relations: \\begin{align} p = 1 - q, \\quad \\quad q = 1 - p, \\quad \\quad p + q = 1. \\end{align} [Random variables](Random_variable \"wikilink\") describing Bernoulli trials are often encoded using the convention that 1 = \\\"success\\\", 0 = \\\"failure\\\". Closely related to a Bernoulli trial is a binomial experiment, which consists of a fixed number $n$ of [statistically independent](statistically_independent \"wikilink\") Bernoulli trials, each with a probability of success $p$, and counts the number of successes. A random variable corresponding to a binomial is denoted by $B(n,p)$, and is said to have a *[binomial distribution](binomial_distribution \"wikilink\")*. The probability of exactly $k$ successes in the experiment $B(n,p)$ is given by: $$P(k)={n \\choose k} p^k q^{n-k}$$ where ${n \\choose k}$ is a [binomial coefficient](binomial_coefficient \"wikilink\"). Bernoulli trials may also lead to [negative binomial distributions](negative_binomial_distribution \"wikilink\") (which count the number of successes in a series of repeated Bernoulli trials until a specified number of failures are seen), as well as various other distributions. When multiple Bernoulli trials are performed, each with its own probability of success, these are sometimes referred to as [Poisson trials](Poisson_trial \"wikilink\").[^3] [Example 1] tossing coins: Consider the simple experiment where a fair coin is tossed four times. Find the probability that exactly two of the tosses result in heads. [Solution]: For this experiment, let a heads be defined as a *success* and a tails as a *failure.* Because the coin is assumed to be fair, the probability of success is $p = \\tfrac{1}{2}$. Thus the probability of failure, $q$ is given by $$q = 1 - p = 1 - \\tfrac{1}{2} = \\tfrac{1}{2}$$ Using the equation above, the probability of exactly two tosses out of four total tosses resulting in a heads is given by: $$\\begin{align} P(2) &= {4 \\choose 2} p^{2} q^{4-2} \\\\ &= 6 \\times \\left(\\tfrac{1}{2}\\right)^2 \\times \\left(\\tfrac{1}{2}\\right)^2 \\\\ &= \\dfrac {3}{8}. \\end{align}$$ Example 1: Suppose that in Singapore, $65\\%$ of customers prefer Coke, while the remaining $35\\%$ prefer Pepsi. Now we randomly survey 10 customers, among which the number of customers who prefer Coke is denoted by a discrete random variable $X$. Plot the PMF of $X$. def perform_bernoulli_trials ( n , p ): \"\"\" Perform n Bernoulli trials with success probability p and return number of successes. That is to say: If I toss coin 10 times, and landed head 7 times, then success rate is 70% -> this is what I should return. But note this is binary. \"\"\" # Initialize number of successes: n_success n_success = 0 # Perform trials for i in range ( n ): # Choose random number between zero and one: random_number random_number = np . random . random ( size = 1 ) # If less than p, it's a success so add one to n_success if random_number < p : n_success += 1 return n_success # Initialize the number of defaults: n_defaults n_defaults = np . empty ( shape = 100000 ) # Compute the number of defaults for 1000 times # this is to say, every 100 loans, we find the number of defaults for i in tqdm ( range ( len ( n_defaults ))): n_defaults [ i ] = perform_bernoulli_trials ( n = 100 , p = 0.05 ) # Plot the histogram with default number of bins, density=True is normalized; label your axes _ = plt . hist ( x = n_defaults , density = True ) _ = plt . hist ( x = n_defaults , density = True , ) _ = plt . xlabel ( 'number of defaults out of 100 loans' ) _ = plt . ylabel ( 'probability' ) # save save_fig ( \"Bernoulli Trial\" ) # Show the plot plt . show () # from the plot, seems 4-8 is quite common, when I do on kaggle, bin it nicely for visuals~ len ( n_defaults ) # Compute ECDF: x, y x , y = ecdf ( n_defaults ) # Plot the ECDF with labeled axes _ = plt . plot ( x , y , marker = '.' , linestyle = 'none' ) _ = plt . xlabel ( xlabel = 'number of defaults' ) _ = plt . ylabel ( ylabel = 'percentage' ) # Show the plot plt . show () # Compute the number of 100-loan simulations with 10 or more defaults: n_lose_money default_more_than_ten_bool = np . where ( n_defaults >= 10 , True , False ) n_lose_money = np . sum ( default_more_than_ten_bool , axis = None ) # Compute and print probability of losing money print ( 'Probability of losing money =' , n_lose_money / len ( n_defaults )) # How to intepret this as bernoulli? # As we might expect, we most likely get 5/100 defaults. But we still have about a 2% chance of getting 10 or more defaults out of 100 loans. # This means given n=100, and p = 0.05 of default, we draw 100000 samples from this distribution. This is basically performing bernoulli function 100 times. n_defaults = np . random . binomial ( n = 100 , p = 0.05 , size = 1000000000 ) # Compute CDF: x, y x , y = ecdf ( n_defaults ) # Plot the CDF with axis labels _ = plt . plot ( x , y , marker = '.' , linestyle = 'none' ) _ = plt . xlabel ( xlabel = \"number of defaults\" ) _ = plt . ylabel ( ylabel = 'ECDF' ) # Show the plot plt . show () # Compute the number of 100-loan simulations with 10 or more defaults: n_lose_money default_more_than_ten_bool = np . where ( n_defaults >= 10 , True , False ) n_lose_money = np . sum ( default_more_than_ten_bool , axis = None ) # Compute and print probability of losing money print ( 'Probability of losing money =' , n_lose_money / len ( n_defaults )) ### [Bernoulli Distribution] PMF of Bernoulli Distribution: For a discrete random variable $X$ with $k$ possible outcomes $x_j$, the probability mass function (PMF) is given by: \\begin{align} P(X=x_j) = p_X(x_j), \\text{ for each }j=1, 2, ..., k, \\end{align} where $p_X(x_j)$ is the probability of the outcome $x_j$, and all $p_X(x_i)$ must satisfy \\begin{cases} 0\\leq p_X(x_i) \\leq 1 \\\\ \\sum_{j=1}^kp_j = 1 \\end{cases} In [probability theory](probability_theory \"wikilink\") and [statistics](statistics \"wikilink\"), the **Bernoulli distribution**, named after Swiss mathematician [Jacob Bernoulli](Jacob_Bernoulli \"wikilink\"),[^1] is the [discrete probability distribution](discrete_probability_distribution \"wikilink\") of a [random variable](random_variable \"wikilink\") which takes the value 1 with probability $p$ and the value 0 with probability $q = 1-p$. Less formally, it can be thought of as a model for the set of possible outcomes of any single [experiment](experiment \"wikilink\") that asks a [yes--no question](yes\u2013no_question \"wikilink\"). Such questions lead to [outcomes](outcome_(probability) \"wikilink\") that are [boolean](boolean-valued_function \"wikilink\")-valued: a single [bit](bit \"wikilink\") whose value is success/[yes](yes_and_no \"wikilink\")/[true](truth \"wikilink\")/[one](one \"wikilink\") with [probability](probability \"wikilink\") *p* and failure/no/[false](false_(logic) \"wikilink\")/[zero](zero \"wikilink\") with probability *q*. It can be used to represent a (possibly biased) [coin toss](coin_toss \"wikilink\") where 1 and 0 would represent \\\"heads\\\" and \\\"tails\\\" (or vice versa), respectively, and *p* would be the probability of the coin landing on heads or tails, respectively. In particular, unfair coins would have $p \\neq 1/2.$ The Bernoulli distribution is a special case of the [binomial distribution](binomial_distribution \"wikilink\") where a single trial is conducted (so *n* would be 1 for such a binomial distribution). It is also a special case of the **two-point distribution**, for which the possible outcomes need not be 0 and 1. ## Properties If $X$ is a random variable with this distribution, then: $$\\Pr(X=1) = p = 1 - \\Pr(X=0) = 1 - q.$$ The [probability mass function](probability_mass_function \"wikilink\") $f$ of this distribution, over possible outcomes *k*, is $$f(k;p) = \\begin{cases} p & \\text{if }k=1, \\\\ q = 1-p & \\text {if } k = 0. \\end{cases}$$[^2] This can also be expressed as $$f(k;p) = p^k (1-p)^{1-k} \\quad \\text{for } k\\in\\{0,1\\}$$ or as $$f(k;p)=pk+(1-p)(1-k) \\quad \\text{for } k\\in\\{0,1\\}.$$ The Bernoulli distribution is a special case of the [binomial distribution](binomial_distribution \"wikilink\") with $n = 1.$[^3] The [kurtosis](kurtosis \"wikilink\") goes to infinity for high and low values of $p,$ but for $p=1/2$ the two-point distributions including the Bernoulli distribution have a lower [excess kurtosis](excess_kurtosis \"wikilink\") than any other probability distribution, namely \u22122. The Bernoulli distributions for $0 \\le p \\le 1$ form an [exponential family](exponential_family \"wikilink\"). The [maximum likelihood estimator](maximum_likelihood_estimator \"wikilink\") of $p$ based on a random sample is the [sample mean](sample_mean \"wikilink\"). ## Mean The [expected value](expected_value \"wikilink\") of a Bernoulli random variable $X$ is $$\\operatorname{E}\\left(X\\right)=p$$ This is due to the fact that for a Bernoulli distributed random variable $X$ with $\\Pr(X=1)=p$ and $\\Pr(X=0)=q$ we find $$\\operatorname{E}[X] = \\Pr(X=1)\\cdot 1 + \\Pr(X=0)\\cdot 0 = p \\cdot 1 + q\\cdot 0 = p.$$[^4] ## Variance The [variance](variance \"wikilink\") of a Bernoulli distributed $X$ is $$\\operatorname{Var}[X] = pq = p(1-p)$$ We first find $$\\operatorname{E}[X^2] = \\Pr(X=1)\\cdot 1^2 + \\Pr(X=0)\\cdot 0^2 = p \\cdot 1^2 + q\\cdot 0^2 = p = \\operatorname{E}[X]$$ From this follows $$\\operatorname{Var}[X] = \\operatorname{E}[X^2]-\\operatorname{E}[X]^2 = \\operatorname{E}[X]-\\operatorname{E}[X]^2 = p-p^2 = p(1-p) = pq$$[^5] With this result it is easy to prove that, for any Bernoulli distribution, its variance will have a value inside $[0,1/4]$. ## Skewness The [skewness](skewness \"wikilink\") is $\\frac{q-p}{\\sqrt{pq}}=\\frac{1-2p}{\\sqrt{pq}}$. When we take the standardized Bernoulli distributed random variable $\\frac{X-\\operatorname{E}[X]}{\\sqrt{\\operatorname{Var}[X]}}$ we find that this random variable attains $\\frac{q}{\\sqrt{pq}}$ with probability $p$ and attains $-\\frac{p}{\\sqrt{pq}}$ with probability $q$. Thus we get $$\\begin{align} \\gamma_1 &= \\operatorname{E} \\left[\\left(\\frac{X-\\operatorname{E}[X]}{\\sqrt{\\operatorname{Var}[X]}}\\right)^3\\right] \\\\ &= p \\cdot \\left(\\frac{q}{\\sqrt{pq}}\\right)^3 + q \\cdot \\left(-\\frac{p}{\\sqrt{pq}}\\right)^3 \\\\ &= \\frac{1}{\\sqrt{pq}^3} \\left(pq^3-qp^3\\right) \\\\ &= \\frac{pq}{\\sqrt{pq}^3} (q-p) \\\\ &= \\frac{q-p}{\\sqrt{pq}} \\end{align}$$ ## Higher moments and cumulants {#higher_moments_and_cumulants} The raw moments are all equal due to the fact that $1^k=1$ and $0^k=0$. $$\\operatorname{E}[X^k] = \\Pr(X=1)\\cdot 1^k + \\Pr(X=0)\\cdot 0^k = p \\cdot 1 + q\\cdot 0 = p = \\operatorname{E}[X].$$ The central moment of order $k$ is given by $$\\mu_k =(1-p)(-p)^k +p(1-p)^k.$$ The first six central moments are $$\\begin{align} \\mu_1 &= 0, \\\\ \\mu_2 &= p(1-p), \\\\ \\mu_3 &= p(1-p)(1-2p), \\\\ \\mu_4 &= p(1-p)(1-3p(1-p)), \\\\ \\mu_5 &= p(1-p)(1-2p)(1-2p(1-p)), \\\\ \\mu_6 &= p(1-p)(1-5p(1-p)(1-p(1-p))). \\end{align}$$ The higher central moments can be expressed more compactly in terms of $\\mu_2$ and $\\mu_3$ $$\\begin{align} \\mu_4 &= \\mu_2 (1-3\\mu_2 ), \\\\ \\mu_5 &= \\mu_3 (1-2\\mu_2 ), \\\\ \\mu_6 &= \\mu_2 (1-5\\mu_2 (1-\\mu_2 )). \\end{align}$$ The first six cumulants are $$\\begin{align} \\kappa_1 &= p, \\\\ \\kappa_2 &= \\mu_2 , \\\\ \\kappa_3 &= \\mu_3 , \\\\ \\kappa_4 &= \\mu_2 (1-6\\mu_2 ), \\\\ \\kappa_5 &= \\mu_3 (1-12\\mu_2 ), \\\\ \\kappa_6 &= \\mu_2 (1-30\\mu_2 (1-4\\mu_2 )). \\end{align}$$ ### Binomial Distribution In [probability theory](probability_theory \"wikilink\") and [statistics](statistics \"wikilink\"), the **[binomial](Binomial_coefficient \"wikilink\") distribution** with parameters *n* and *p* is the [discrete probability distribution](discrete_probability_distribution \"wikilink\") of the number of successes in a sequence of *n* [independent](statistical_independence \"wikilink\") [experiments](experiment_(probability_theory) \"wikilink\"), each asking a [yes--no question](yes\u2013no_question \"wikilink\"), and each with its own [Boolean](boolean-valued_function \"wikilink\")-valued [outcome](outcome_(probability) \"wikilink\"): *success* (with probability *p*) or *failure* (with probability *q* = 1 \u2212 *p*). A single success/failure experiment is also called a [Bernoulli trial](Bernoulli_trial \"wikilink\") or Bernoulli experiment, and a sequence of outcomes is called a [Bernoulli process](Bernoulli_process \"wikilink\"); for a single trial, i.e., *n* = 1, the binomial distribution is a [Bernoulli distribution](Bernoulli_distribution \"wikilink\"). The binomial distribution is the basis for the popular [binomial test](binomial_test \"wikilink\") of [statistical significance](statistical_significance \"wikilink\"). The binomial distribution is frequently used to model the number of successes in a sample of size *n* drawn [with replacement](with_replacement \"wikilink\") from a population of size *N*. If the sampling is carried out without replacement, the draws are not independent and so the resulting distribution is a [hypergeometric distribution](hypergeometric_distribution \"wikilink\"), not a binomial one. However, for *N* much larger than *n*, the binomial distribution remains a good approximation, and is widely used. In particular, The binomial distribution is directly related to the Bernoullli distribution: it is **the sum of positive outcomes of a Bernoulli distributed random variable**. Whereas the Bernoulli distribution represented a single binary outcome and it's probability of occuring, the binomial has a parameter $n$ for the number of \"trials\". It is important to note that each trial, or event, must be independent and have the same probability of success in order to be represented with the binomial distribution. Run simulation to be close to the result. Means to say if the coin flip is TRULY a binomial distribution. Then simulating enough times will ultimately converge to what the binomial distribution will say , like say prob of 5 heads out of ten Toss is such and such ### [Binomial Distribution] PMF of Binomial Distribution: For a discrete random variable $X$ which follows the binomial distribution, with parameters $n \\in \\mathbb{N}$, $p \\in [0,1]$, representing number of trials, and the probability of success respectively. Then, the probability mass function (PMF) of $X$ is given by: \\begin{align} pmf(k;n,p) = P(X = k) = \\binom n k p^k(1-p)^{n-k} \\end{align} for $k = 0, 1, 2, ..., n$, where $$\\binom{n}{k} =\\frac{n!}{k!(n-k)!}$$ is the [binomial coefficient](binomial_coefficient \"wikilink\"), hence the name of the distribution. Take note that the probability mass function above also means the probability of getting exactly $k$ successes in $n$ independent Bernoulli trials. Interpretation: The formula can be understood as follows: *k* successes occur with probability *p*^*k*^ and *n* \u2212 *k* failures occur with probability (1 \u2212 *p*)^*n* \u2212 *k*^. However, the *k* successes can occur anywhere among the *n* trials, and there are $\\binom{n}{k}$ different ways of distributing *k* successes in a sequence of *n* trials. [Example 1] Classical Coin Toss: Consider the simple experiment where a fair coin is tossed ten times. Find the probability that exactly two of the tosses result in heads. [Solution]: We can do this using just probability (which I will not go into because I don't like probability). But if the question added a assumption, that says this experiment follows a binomial distribution, then I am very happy since we have an out-of-the-box formula to calculate such questions! To reframe the question, let us define the random variable $X$ to represent the number of heads you get (note since the question asked us about on \"tosses\" and \"heads\", it is thus natural for the random variable to be defined as such. Furthermore, there are 10 tosses, and X can take on integers 0 to 10). For this experiment, let a heads be defined as a *success* and a tails as a *failure.* Because the coin is assumed to be fair, the probability of success is $p = \\tfrac{1}{2}$. Thus the probability of failure, $q$ is given by $$q = 1 - p = 1 - \\tfrac{1}{2} = \\tfrac{1}{2}$$ Random Variable $X$ n=10 p=0.5 k=2 Using the formula defined above, the probability of exactly two tosses out of ten total tosses resulting in a heads is given by: $$\\begin{align} P(k=2) &= {10 \\choose 2} p^{2} q^{10-2} \\\\ \\end{align}$$ [reference](https://towardsdatascience.com/fun-with-the-binomial-distribution-96a5ecabf65b) ## Definitions ### Probability mass function {#probability_mass_function} ### Example Suppose a [biased coin](fair_coin \"wikilink\") comes up heads with probability 0.3 when tossed. The probability of seeing exactly 4 heads in 6 tosses is $$f(4,6,0.3) = \\binom{6}{4}0.3^4 (1-0.3)^{6-4}= 0.059535.$$ ### Cumulative distribution function {#cumulative_distribution_function} The [cumulative distribution function](cumulative_distribution_function \"wikilink\") can be expressed as: $$F(k;n,p) = \\Pr(X \\le k) = \\sum_{i=0}^{\\lfloor k \\rfloor} {n\\choose i}p^i(1-p)^{n-i},$$ where $\\lfloor k\\rfloor$ is the \\\"floor\\\" under *k*, i.e. the [greatest integer](greatest_integer \"wikilink\") less than or equal to *k*. It can also be represented in terms of the [regularized incomplete beta function](regularized_incomplete_beta_function \"wikilink\"), as follows:[^2] $$\\begin{align} F(k;n,p) & = \\Pr(X \\le k) \\\\ &= I_{1-p}(n-k, k+1) \\\\ & = (n-k) {n \\choose k} \\int_0^{1-p} t^{n-k-1} (1-t)^k \\, dt. \\end{align}$$ which is equivalent to the [cumulative distribution function](cumulative_distribution_function \"wikilink\") of the [`{{mvar|F}}`{=mediawiki}-distribution](F-distribution \"wikilink\"):[^3] $$F(k;n,p) = F_{F\\text{-distribution}}\\left(x=\\frac{1-p}{p}\\frac{k+1}{n-k};d_1=2(n-k),d_2=2(k+1)\\right).$$ Some closed-form bounds for the cumulative distribution function are given [below](#Tail_bounds \"wikilink\"). ## Properties ### Expected value and variance {#expected_value_and_variance} If *X* \\~ *B*(*n*, *p*), that is, *X* is a binomially distributed random variable, n being the total number of experiments and p the probability of each experiment yielding a successful result, then the [expected value](expected_value \"wikilink\") of *X* is:[^4] $$\\operatorname{E}[X] = np.$$ This follows from the linearity of the expected value along with the fact that `{{mvar|X}}`{=mediawiki} is the sum of `{{mvar|n}}`{=mediawiki} identical Bernoulli random variables, each with expected value `{{mvar|p}}`{=mediawiki}. In other words, if $X_1, \\ldots, X_n$ are identical (and independent) Bernoulli random variables with parameter `{{mvar|p}}`{=mediawiki}, then $X = X_1 + \\cdots + X_n$ and $$\\operatorname{E}[X] = \\operatorname{E}[X_1 + \\cdots + X_n] = \\operatorname{E}[X_1] + \\cdots + \\operatorname{E}[X_n] = p + \\cdots + p = np.$$ The [variance](variance \"wikilink\") is: $$\\operatorname{Var}(X) = np(1 - p).$$ This similarly follows from the fact that the variance of a sum of independent random variables is the sum of the variances. ### Higher moments {#higher_moments} The first 6 [central moments](central_moment \"wikilink\"), defined as $\\mu _{c}=\\operatorname {E} \\left[(X-\\operatorname {E} [X])^{c}\\right]$, are given by $$\\begin{align} \\mu_1 &= 0, \\\\ \\mu_2 &= np(1-p),\\\\ \\mu_3 &= np(1-p)(1-2p),\\\\ \\mu_4 &= np(1-p)(1+(3n-6)p(1-p)),\\\\ \\mu_5 &= np(1-p)(1-2p)(1+(10n-12)p(1-p)),\\\\ \\mu_6 &= np(1-p)(1-30p(1-p)(1-4p(1-p))+5np(1-p)(5-26p(1-p))+15n^2 p^2 (1-p)^2). \\end{align}$$ The non-central moments satisfy $$\\begin{align} \\operatorname {E}[X] &= np, \\\\ \\operatorname {E}[X^2] &= np(1-p)+n^2p^2, \\end{align}$$ and in general [^5] $$\\operatorname {E}[X^c] = \\sum_{k=0}^c \\left\\{ {c \\atop k} \\right\\} n^{\\underline{k}} p^k,$$ where $\\textstyle \\left\\{{c\\atop k}\\right\\}$ are the [Stirling numbers of the second kind](Stirling_numbers_of_the_second_kind \"wikilink\"), and $n^{\\underline{k}} = n(n-1)\\cdots(n-k+1)$ is the $k$th [falling power](Falling_and_rising_factorials \"wikilink\") of $n$. A simple bound [^6] follows by bounding the Binomial moments via the [higher Poisson moments](Poisson_distribution#Higher_moments \"wikilink\"): $$\\operatorname {E}[X^c] \\le \\left(\\frac{c}{\\log(c/(np)+1)}\\right)^c \\le (np)^c \\exp(c^2/(2np)).$$ ### Mode Usually the [mode](mode_(statistics) \"wikilink\") of a binomial *B*(*n*,\u2009*p*) distribution is equal to $\\lfloor (n+1)p\\rfloor$, where $\\lfloor\\cdot\\rfloor$ is the [floor function](floor_function \"wikilink\"). However, when (*n* + 1)*p* is an integer and *p* is neither 0 nor 1, then the distribution has two modes: (*n* + 1)*p* and (*n* + 1)*p* \u2212 1. When *p* is equal to 0 or 1, the mode will be 0 and *n* correspondingly. These cases can be summarized as follows: : ` `{=html}\\\\text{mode} = ` \\begin{cases}`\\ ` \\lfloor (n+1)\\,p\\rfloor & \\text{if }(n+1)p\\text{ is 0 or a noninteger}, \\\\`\\ ` (n+1)\\,p\\ \\text{ and }\\ (n+1)\\,p - 1 &\\text{if }(n+1)p\\in\\{1,\\dots,n\\}, \\\\`\\ ` n & \\text{if }(n+1)p = n + 1.`\\ ` \\end{cases}`` `{=html} **Proof:** Let $$f(k)=\\binom nk p^k q^{n-k}.$$ For $p=0$ only $f(0)$ has a nonzero value with $f(0)=1$. For $p=1$ we find $f(n)=1$ and $f(k)=0$ for $k\\neq n$. This proves that the mode is 0 for $p=0$ and $n$ for $p=1$. Let $0 < p < 1$. We find $$\\frac{f(k+1)}{f(k)} = \\frac{(n-k)p}{(k+1)(1-p)}$$. From this follows $$\\begin{align} k > (n+1)p-1 \\Rightarrow f(k+1) < f(k) \\\\ k = (n+1)p-1 \\Rightarrow f(k+1) = f(k) \\\\ k < (n+1)p-1 \\Rightarrow f(k+1) > f(k) \\end{align}$$ So when $(n+1)p-1$ is an integer, then $(n+1)p-1$ and $(n+1)p$ is a mode. In the case that $(n+1)p-1\\notin \\Z$, then only $\\lfloor (n+1)p-1\\rfloor+1=\\lfloor (n+1)p\\rfloor$ is a mode.[^7] ### Median In general, there is no single formula to find the [median](median \"wikilink\") for a binomial distribution, and it may even be non-unique. However several special results have been established: - If *np* is an integer, then the mean, median, and mode coincide and equal *np*.[^8][^9] - Any median *m* must lie within the interval \u230a*np*\u230b \u2264 *m* \u2264 \u2308*np*\u2309.[^10] - A median *m* cannot lie too far away from the mean: `{{nowrap||''m'' \u2212 ''np''| \u2264 min{\u2009ln 2, max{''p'', 1 \u2212 ''p''}\u2009}}`{=mediawiki}}.[^11] - The median is unique and equal to *m* = [round](Rounding \"wikilink\")(*np*) when \\|*m* \u2212 *np*\\| \u2264 min{*p*, 1 \u2212 *p*} (except for the case when *p* = `{{sfrac|1|2}}`{=mediawiki} and *n* is odd).[^12] - When *p* is a rational number (with the exception of *p* = 1/2 and *n* odd) the median is unique.[^13] - When *p* = 1/2 and *n* is odd, any number *m* in the interval `{{sfrac|1|2}}`{=mediawiki}(*n* \u2212 1) \u2264 *m* \u2264 `{{sfrac|1|2}}`{=mediawiki}(*n* + 1) is a median of the binomial distribution. If *p* = 1/2 and *n* is even, then *m* = *n*/2 is the unique median. ### Tail bounds {#tail_bounds} For *k* \u2264 *np*, upper bounds can be derived for the lower tail of the cumulative distribution function $F(k;n,p) = \\Pr(X \\le k)$, the probability that there are at most *k* successes. Since $\\Pr(X \\ge k) = F(n-k;n,1-p)$, these bounds can also be seen as bounds for the upper tail of the cumulative distribution function for *k* \u2265 *np*. [Hoeffding\\'s inequality](Hoeffding's_inequality \"wikilink\") yields the simple bound $$F(k;n,p) \\leq \\exp\\left(-2 n\\left(p-\\frac{k}{n}\\right)^2\\right), \\!$$ which is however not very tight. In particular, for *p* = 1, we have that *F*(*k*;*n*,*p*) = 0 (for fixed *k*, *n* with *k* \\ < *n*), but Hoeffding\\'s bound evaluates to a positive constant. A sharper bound can be obtained from the [Chernoff bound](Chernoff_bound \"wikilink\"):[^14] $$F(k;n,p) \\leq \\exp\\left(-nD\\left(\\frac{k}{n}\\parallel p\\right)\\right)$$ where *D*(*a* \\|\\| *p*) is the [relative entropy (or Kullback-Leibler divergence)](Kullback\u2013Leibler_divergence \"wikilink\") between an *a*-coin and a *p*-coin (i.e. between the Bernoulli(*a*) and Bernoulli(*p*) distribution): $$D(a\\parallel p)=(a)\\log\\frac{a}{p}+(1-a)\\log\\frac{1-a}{1-p}. \\!$$ Asymptotically, this bound is reasonably tight; see [^15] for details. One can also obtain *lower* bounds on the tail $F(k;n,p)$, known as anti-concentration bounds. By approximating the binomial coefficient with Stirling\\'s formula it can be shown that[^16] $$F(k;n,p) \\geq \\frac{1}{\\sqrt{8n\\tfrac{k}{n}(1-\\tfrac{k}{n})}} \\exp\\left(-nD\\left(\\frac{k}{n}\\parallel p\\right)\\right),$$ which implies the simpler but looser bound $$F(k;n,p) \\geq \\frac1{\\sqrt{2n}} \\exp\\left(-nD\\left(\\frac{k}{n}\\parallel p\\right)\\right).$$ For *p* = 1/2 and *k* \u2265 3*n*/8 for even *n*, it is possible to make the denominator constant:[^17] $$F(k;n,\\tfrac{1}{2}) \\geq \\frac{1}{15} \\exp\\left(- 16n \\left(\\frac{1}{2} -\\frac{k}{n}\\right)^2\\right). \\!$$ ## Related distributions {#related_distributions} ### Sums of binomials {#sums_of_binomials} If *X* \\~ B(*n*, *p*) and *Y* \\~ B(*m*, *p*) are independent binomial variables with the same probability *p*, then *X* + *Y* is again a binomial variable; its distribution is *Z=X+Y* \\~ B(*n+m*, *p*): $$\\begin{align} \\operatorname P(Z=k) &= \\sum_{i=0}^k\\left[\\binom{n}i p^i (1-p)^{n-i}\\right]\\left[\\binom{m}{k-i} p^{k-i} (1-p)^{m-k+i}\\right]\\\\ &= \\binom{n+m}k p^k (1-p)^{n+m-k} \\end{align}$$ However, if *X* and *Y* do not have the same probability *p*, then the variance of the sum will be [smaller than the variance of a binomial variable](Binomial_sum_variance_inequality \"wikilink\") distributed as $B(n+m, \\bar{p}).\\,$ ### Poisson binomial distribution {#poisson_binomial_distribution} The binomial distribution is a special case of the [Poisson binomial distribution](Poisson_binomial_distribution \"wikilink\"), or [general binomial distribution](general_binomial_distribution \"wikilink\"), which is the distribution of a sum of *n* independent non-identical [Bernoulli trials](Bernoulli_trials \"wikilink\") B(*p~i~*).[^18] ### Ratio of two binomial distributions {#ratio_of_two_binomial_distributions} This result was first derived by Katz and coauthors in 1978.[^19] Let *X* \\~ B(*n*,*p*~1~) and *Y* \\~ B(*m*,*p*~2~) be independent. Let *T* = (*X*/*n*)/(*Y*/*m*). Then log(*T*) is approximately normally distributed with mean log(*p*~1~/*p*~2~) and variance ((1/*p*~1~) \u2212 1)/*n* + ((1/*p*~2~) \u2212 1)/*m*. ### Conditional binomials {#conditional_binomials} If *X* \\~ B(*n*, *p*) and *Y* \\| *X* \\~ B(*X*, *q*) (the conditional distribution of *Y*, given *X*), then *Y* is a simple binomial random variable with distribution *Y* \\~ B(*n*, *pq*). For example, imagine throwing *n* balls to a basket *U~X~* and taking the balls that hit and throwing them to another basket *U~Y~*. If *p* is the probability to hit *U~X~* then *X* \\~ B(*n*, *p*) is the number of balls that hit *U~X~*. If *q* is the probability to hit *U~Y~* then the number of balls that hit *U~Y~* is *Y* \\~ B(*X*, *q*) and therefore *Y* \\~ B(*n*, *pq*). {{hidden begin|style=width:60%|ta1=center|border=1px #aaa solid|title=[Proof]}} Since $X \\sim B(n, p)$ and $Y \\sim B(X, q)$, by the [law of total probability](law_of_total_probability \"wikilink\"), $$\\begin{align} \\Pr[Y = m] &= \\sum_{k = m}^{n} \\Pr[Y = m \\mid X = k] \\Pr[X = k] \\\\[2pt] &= \\sum_{k=m}^n \\binom{n}{k} \\binom{k}{m} p^k q^m (1-p)^{n-k} (1-q)^{k-m} \\end{align}$$ Since $\\tbinom{n}{k} \\tbinom{k}{m} = \\tbinom{n}{m} \\tbinom{n-m}{k-m},$ the equation above can be expressed as $$\\Pr[Y = m] = \\sum_{k=m}^{n} \\binom{n}{m} \\binom{n-m}{k-m} p^k q^m (1-p)^{n-k} (1-q)^{k-m}$$ Factoring $p^k = p^m p^{k-m}$ and pulling all the terms that don\\'t depend on $k$ out of the sum now yields $$\\begin{align} \\Pr[Y = m] &= \\binom{n}{m} p^m q^m \\left( \\sum_{k=m}^n \\binom{n-m}{k-m} p^{k-m} (1-p)^{n-k} (1-q)^{k-m} \\right) \\\\[2pt] &= \\binom{n}{m} (pq)^m \\left( \\sum_{k=m}^n \\binom{n-m}{k-m} \\left(p(1-q)\\right)^{k-m} (1-p)^{n-k} \\right) \\end{align}$$ After substituting $i = k - m$ in the expression above, we get $$\\Pr[Y = m] = \\binom{n}{m} (pq)^m \\left( \\sum_{i=0}^{n-m} \\binom{n-m}{i} (p - pq)^i (1-p)^{n-m - i} \\right)$$ Notice that the sum (in the parentheses) above equals $(p - pq + 1 - p)^{n-m}$ by the [binomial theorem](binomial_theorem \"wikilink\"). Substituting this in finally yields $$\\begin{align} \\Pr[Y=m] &= \\binom{n}{m} (pq)^m (p - pq + 1 - p)^{n-m}\\\\[4pt] &= \\binom{n}{m} (pq)^m (1-pq)^{n-m} \\end{align}$$ and thus $Y \\sim B(n, pq)$ as desired. `{{hidden end}}`{=mediawiki} ### Bernoulli distribution {#bernoulli_distribution} The [Bernoulli distribution](Bernoulli_distribution \"wikilink\") is a special case of the binomial distribution, where *n* = 1. Symbolically, *X* \\~ B(1, *p*) has the same meaning as *X* \\~ Bernoulli(*p*). Conversely, any binomial distribution, B(*n*, *p*), is the distribution of the sum of *n* [Bernoulli trials](Bernoulli_trials \"wikilink\"), Bernoulli(*p*), each with the same probability *p*.[^20] ### Normal approximation {#normal_approximation} ![Binomial [probability mass function](probability_mass_function \"wikilink\") and normal [probability density function](probability_density_function \"wikilink\") approximation for *n* = 6 and *p* = 0.5](Binomial_Distribution.svg \"Binomial probability mass function and normal probability density function approximation for n = 6 and p = 0.5\"){width=\"250\"} If *n* is large enough, then the skew of the distribution is not too great. In this case a reasonable approximation to B(*n*, *p*) is given by the [normal distribution](normal_distribution \"wikilink\") $$\\mathcal{N}(np,\\,np(1-p)),$$ and this basic approximation can be improved in a simple way by using a suitable [continuity correction](continuity_correction \"wikilink\"). The basic approximation generally improves as *n* increases (at least 20) and is better when *p* is not near to 0 or 1.[^21] Various [rules of thumb](Rule_of_thumb \"wikilink\") may be used to decide whether *n* is large enough, and *p* is far enough from the extremes of zero or one: - One rule[^22] is that for `{{nowrap|''n'' > 5}}`{=mediawiki} the normal approximation is adequate if the absolute value of the skewness is strictly less than 1/3; that is, if $$\\frac{|1-2p|}{\\sqrt{np(1-p)}}=\\frac1{\\sqrt{n}}\\left|\\sqrt{\\frac{1-p}p}-\\sqrt{\\frac{p}{1-p}}\\,\\right| < \\frac13.$$ - A stronger rule states that the normal approximation is appropriate only if everything within 3 standard deviations of its mean is within the range of possible values; that is, only if $$\\mu\\pm3\\sigma=np\\pm3\\sqrt{np(1-p)}\\in(0,n).$$ : This 3-standard-deviation rule is equivalent to the following conditions, which also imply the first rule above. $$n>9 \\left(\\frac{1-p}{p} \\right)\\quad\\text{and}\\quad n>9\\left(\\frac{p}{1-p}\\right).$$ {{hidden begin|style=width:66%|ta1=center|border=1px #aaa solid|title=[Proof]}} The rule $np\\pm3\\sqrt{np(1-p)}\\in(0,n)$ is totally equivalent to request that $$np-3\\sqrt{np(1-p)}>0\\quad\\text{and}\\quad np+3\\sqrt{np(1-p)} 3\\sqrt{np(1-p)}\\quad\\text{and}\\quad n(1-p)>3\\sqrt{np(1-p)}.$$ Since $0 9 \\left(\\frac{1-p}p\\right) \\quad\\text{and}\\quad n>9 \\left(\\frac{p}{1-p}\\right).$$ Notice that these conditions automatically imply that $n>9$. On the other hand, apply again the square root and divide by 3, $$\\frac{\\sqrt{n}}3>\\sqrt{\\frac{1-p}p}>0 \\quad \\text{and} \\quad \\frac{\\sqrt{n}}3 > \\sqrt{\\frac{p}{1-p}}>0.$$ Subtracting the second set of inequalities from the first one yields: $$\\frac{\\sqrt{n}}3>\\sqrt{\\frac{1-p}p}-\\sqrt{\\frac{p}{1-p}}>-\\frac{\\sqrt{n}}3;$$ and so, the desired first rule is satisfied, $$\\left|\\sqrt{\\frac{1-p}p}-\\sqrt{\\frac{p}{1-p}}\\,\\right| < \\frac{\\sqrt{n}}3.$$ `{{hidden end}}`{=mediawiki} - Another commonly used rule is that both values $np$ and $n(1-p)$ must be greater than or equal to 5. However, the specific number varies from source to source, and depends on how good an approximation one wants. In particular, if one uses 9 instead of 5, the rule implies the results stated in the previous paragraphs. {{hidden begin|style=width:66%|ta1=center|border=1px #aaa solid|title=[Proof]}} Assume that both values $np$ and $n(1-p)$ are greater than 9. Since $0 < p < 1$, we easily have that $$np\\geq9>9(1-p)\\quad\\text{and}\\quad n(1-p)\\geq9>9p.$$ We only have to divide now by the respective factors $p$ and $1-p$, to deduce the alternative form of the 3-standard-deviation rule: $$n>9 \\left(\\frac{1-p}p\\right) \\quad\\text{and}\\quad n>9 \\left(\\frac{p}{1-p}\\right).$$ `{{hidden end}}`{=mediawiki} The following is an example of applying a [continuity correction](continuity_correction \"wikilink\"). Suppose one wishes to calculate Pr(*X* \u2264 8) for a binomial random variable *X*. If *Y* has a distribution given by the normal approximation, then Pr(*X* \u2264 8) is approximated by Pr(*Y* \u2264 8.5). The addition of 0.5 is the continuity correction; the uncorrected normal approximation gives considerably less accurate results. This approximation, known as [de Moivre--Laplace theorem](de_Moivre\u2013Laplace_theorem \"wikilink\"), is a huge time-saver when undertaking calculations by hand (exact calculations with large *n* are very onerous); historically, it was the first use of the normal distribution, introduced in [Abraham de Moivre](Abraham_de_Moivre \"wikilink\")\\'s book *[The Doctrine of Chances](The_Doctrine_of_Chances \"wikilink\")* in 1738. Nowadays, it can be seen as a consequence of the [central limit theorem](central_limit_theorem \"wikilink\") since B(*n*, *p*) is a sum of *n* independent, identically distributed [Bernoulli variables](Bernoulli_distribution \"wikilink\") with parameter *p*. This fact is the basis of a [hypothesis test](hypothesis_test \"wikilink\"), a \\\"proportion z-test\\\", for the value of *p* using *x/n*, the sample proportion and estimator of *p*, in a [common test statistic](common_test_statistics \"wikilink\").[^23] For example, suppose one randomly samples *n* people out of a large population and ask them whether they agree with a certain statement. The proportion of people who agree will of course depend on the sample. If groups of *n* people were sampled repeatedly and truly randomly, the proportions would follow an approximate normal distribution with mean equal to the true proportion *p* of agreement in the population and with standard deviation $\\sigma = \\sqrt{\\frac{p(1-p)}{n}}$ ### Poisson approximation {#poisson_approximation} The binomial distribution converges towards the [Poisson distribution](Poisson_distribution \"wikilink\") as the number of trials goes to infinity while the product *np* remains fixed or at least *p* tends to zero. Therefore, the Poisson distribution with parameter *\u03bb* = *np* can be used as an approximation to B(*n*, *p*) of the binomial distribution if *n* is sufficiently large and *p* is sufficiently small. According to two rules of thumb, this approximation is good if *n* \u2265 20 and *p* \u2264 0.05, or if *n* \u2265 100 and *np* \u2264 10.[^24] Concerning the accuracy of Poisson approximation, see Novak,[^25] ch. 4, and references therein. ### Limiting distributions {#limiting_distributions} - *[Poisson limit theorem](Poisson_limit_theorem \"wikilink\")*: As *n* approaches \u221e and *p* approaches 0 with the product *np* held fixed, the Binomial(*n*, *p*) distribution approaches the [Poisson distribution](Poisson_distribution \"wikilink\") with [expected value](expected_value \"wikilink\") *\u03bb = np*.[^26] - *[de Moivre--Laplace theorem](de_Moivre\u2013Laplace_theorem \"wikilink\")*: As *n* approaches \u221e while *p* remains fixed, the distribution of $$\\frac{X-np}{\\sqrt{np(1-p)}}$$ : approaches the [normal distribution](normal_distribution \"wikilink\") with expected value 0 and [variance](variance \"wikilink\") 1.`{{citation needed|date=May 2012}}`{=mediawiki} This result is sometimes loosely stated by saying that the distribution of *X* is [asymptotically normal](Asymptotic_normality \"wikilink\") with expected value *np* and [variance](variance \"wikilink\") *np*(1 \u2212 *p*). This result is a specific case of the [central limit theorem](central_limit_theorem \"wikilink\"). ### Beta distribution {#beta_distribution} The binomial distribution and beta distribution are different views of the same model of repeated Bernoulli trials. The binomial distribution is the [PMF](Probability_mass_function \"wikilink\") of `{{mvar|k}}`{=mediawiki} successes given `{{mvar|n}}`{=mediawiki} independent events each with a probability `{{mvar|p}}`{=mediawiki} of success. Mathematically, when `{{math|1=''\u03b1'' = ''k'' + 1}}`{=mediawiki} and `{{math|1=''\u03b2'' = ''n'' \u2212 ''k'' + 1}}`{=mediawiki}, the beta distribution and the binomial distribution are related by a factor of `{{math|''n'' + 1}}`{=mediawiki}: $$\\operatorname{Beta}(p;\\alpha;\\beta) = (n+1)\\operatorname{Binom}(k;n;p)$$ [Beta distributions](Beta_distribution \"wikilink\") also provide a family of [prior probability distributions](prior_distribution \"wikilink\") for binomial distributions in [Bayesian inference](Bayesian_inference \"wikilink\"):[^27] $$P(p;\\alpha,\\beta) = \\frac{p^{\\alpha-1}(1-p)^{\\beta-1}}{\\mathrm{B}(\\alpha,\\beta)}.$$ Given a uniform prior, the posterior distribution for the probability of success `{{mvar|p}}`{=mediawiki} given `{{mvar|n}}`{=mediawiki} independent events with `{{mvar|k}}`{=mediawiki} observed successes is a beta distribution.[^28] ## Statistical Inference {#statistical_inference} ### Estimation of parameters {#estimation_of_parameters} {{see also|Beta distribution#Bayesian inference}} When *n* is known, the parameter *p* can be estimated using the proportion of successes: $\\widehat{p} = \\frac{x}{n}.$ This estimator is found using [maximum likelihood estimator](maximum_likelihood_estimator \"wikilink\") and also the [method of moments](method_of_moments_(statistics) \"wikilink\"). This estimator is [unbiased](Bias_of_an_estimator \"wikilink\") and uniformly with [minimum variance](Minimum-variance_unbiased_estimator \"wikilink\"), proven using [Lehmann--Scheff\u00e9 theorem](Lehmann\u2013Scheff\u00e9_theorem \"wikilink\"), since it is based on a [minimal sufficient](minimal_sufficient \"wikilink\") and [complete](Completeness_(statistics) \"wikilink\") statistic (i.e.: *x*). It is also [consistent](Consistent_estimator \"wikilink\") both in probability and in [MSE](Mean_squared_error \"wikilink\"). A closed form [Bayes estimator](Bayes_estimator \"wikilink\") for *p* also exists when using the [Beta distribution](Beta_distribution \"wikilink\") as a [conjugate](Conjugate_prior \"wikilink\") [prior distribution](prior_distribution \"wikilink\"). When using a general $\\operatorname{Beta}(\\alpha, \\beta)$ as a prior, the [posterior mean](Bayes_estimator#Posterior_mean \"wikilink\") estimator is: $\\widehat{p_b} = \\frac{x+\\alpha}{n+\\alpha+\\beta}$. The Bayes estimator is [asymptotically efficient](Asymptotic_efficiency_(Bayes) \"wikilink\") and as the sample size approaches infinity (*n* \u2192 \u221e), it approaches the [MLE](Maximum_likelihood_estimation \"wikilink\") solution. The Bayes estimator is [biased](Bias_of_an_estimator \"wikilink\") (how much depends on the priors), [admissible](Bayes_estimator#Admissibility \"wikilink\") and [consistent](Consistent_estimator \"wikilink\") in probability. For the special case of using the [standard uniform distribution](standard_uniform_distribution \"wikilink\") as a [non-informative prior](non-informative_prior \"wikilink\") ($\\operatorname{Beta}(\\alpha=1, \\beta=1) = U(0,1)$), the posterior mean estimator becomes $\\widehat{p_b} = \\frac{x+1}{n+2}$ (a [posterior mode](Bayes_estimator#Posterior_mode \"wikilink\") should just lead to the standard estimator). This method is called the [rule of succession](rule_of_succession \"wikilink\"), which was introduced in the 18th century by [Pierre-Simon Laplace](Pierre-Simon_Laplace \"wikilink\"). When estimating *p* with very rare events and a small *n* (e.g.: if x=0), then using the standard estimator leads to $\\widehat{p} = 0,$ which sometimes is unrealistic and undesirable. In such cases there are various alternative estimators.[^29] One way is to use the Bayes estimator, leading to: $\\widehat{p_b} = \\frac{1}{n+2}$). Another method is to use the upper bound of the [confidence interval](confidence_interval \"wikilink\") obtained using the [rule of three](Rule_of_three_(statistics) \"wikilink\"): $\\widehat{p_{\\text{rule of 3}}} = \\frac{3}{n}$) ### Confidence intervals {#confidence_intervals} {{Main|Binomial proportion confidence interval}} Even for quite large values of *n*, the actual distribution of the mean is significantly nonnormal.[^30] Because of this problem several methods to estimate confidence intervals have been proposed. In the equations for confidence intervals below, the variables have the following meaning: - *n*~1~ is the number of successes out of *n*, the total number of trials - $\\widehat{p\\,} = \\frac{n_1}{n}$ is the proportion of successes - $z$ is the $1 - \\tfrac{1}{2}\\alpha$ [quantile](quantile \"wikilink\") of a [standard normal distribution](standard_normal_distribution \"wikilink\") (i.e., [probit](probit \"wikilink\")) corresponding to the target error rate $\\alpha$. For example, for a 95% confidence level the error $\\alpha$ = 0.05, so $1 - \\tfrac{1}{2}\\alpha$ = 0.975 and $z$ = 1.96. #### Wald method {#wald_method} : : $\\widehat{p\\,} \\pm z \\sqrt{ \\frac{ \\widehat{p\\,} ( 1 -\\widehat{p\\,} )}{ n } } .$ <!-- --> : A [continuity correction](continuity_correction \"wikilink\") of 0.5/*n* may be added.`{{clarify|date=July 2012}}`{=mediawiki} #### Agresti--Coull method {#agresticoull_method} [^31] : : $\\tilde{p} \\pm z \\sqrt{ \\frac{ \\tilde{p} ( 1 - \\tilde{p} )}{ n + z^2 } }$ <!-- --> : Here the estimate of *p* is modified to <!-- --> : : $\\tilde{p}= \\frac{ n_1 + \\frac{1}{2} z^2}{ n + z^2 }$ <!-- --> : This method works well for $n>10$ and $n_1\\neq 0,n$.[^32] See here for $n\\leq 10$. [^33] For $n_1 = 0,n$ use the Wilson (score) method below. #### Arcsine method {#arcsine_method} [^34] : $\\sin^2 \\left(\\arcsin \\left(\\sqrt{\\widehat{p\\,}}\\right) \\pm \\frac{z}{2\\sqrt{n}} \\right).$ #### Wilson (score) method {#wilson_score_method} {{Main|Binomial proportion confidence interval#Wilson score interval}} The notation in the formula below differs from the previous formulas in two respects:[^35] - Firstly, *z*~*x*~ has a slightly different interpretation in the formula below: it has its ordinary meaning of \\'the *x*th quantile of the standard normal distribution\\', rather than being a shorthand for \\'the (1 \u2212 *x*)-th quantile\\'. - Secondly, this formula does not use a plus-minus to define the two bounds. Instead, one may use $z = z_{\\alpha / 2}$ to get the lower bound, or use $z = z_{1 - \\alpha/2}$ to get the upper bound. For example: for a 95% confidence level the error $\\alpha$ = 0.05, so one gets the lower bound by using $z = z_{\\alpha/2} = z_{0.025} = - 1.96$, and one gets the upper bound by using $z = z_{1 - \\alpha/2} = z_{0.975} = 1.96$. : : ` `{=html}\\\\frac{ ` \\widehat{p\\,} + \\frac{z^2}{2n} + z`\\ ` \\sqrt{`\\ ` \\frac{\\widehat{p\\,}(1 - \\widehat{p\\,})}{n} +`\\ ` \\frac{z^2}{4 n^2}`\\ ` }` }{ ` 1 + \\frac{z^2}{n}` }` `{=html}[^36] #### Comparison The exact ([Clopper--Pearson](Binomial_proportion_confidence_interval#Clopper\u2013Pearson_interval \"wikilink\")) method is the most conservative.[^37] The Wald method, although commonly recommended in textbooks, is the most biased.`{{clarify|reason=what sense of bias is this|date=July 2012}}`{=mediawiki} ## Computational methods {#computational_methods} ### Generating binomial random variates {#generating_binomial_random_variates} Methods for [random number generation](random_number_generation \"wikilink\") where the [marginal distribution](marginal_distribution \"wikilink\") is a binomial distribution are well-established.[^38][^39] One way to generate random samples from a binomial distribution is to use an inversion algorithm. To do so, one must calculate the probability that `{{math|1=Pr(''X'' = ''k'')}}`{=mediawiki} for all values `{{mvar|k}}`{=mediawiki} from `{{math|0}}`{=mediawiki} through `{{mvar|n}}`{=mediawiki}. (These probabilities should sum to a value close to one, in order to encompass the entire sample space.) Then by using a [pseudorandom number generator](pseudorandom_number_generator \"wikilink\") to generate samples uniformly between 0 and 1, one can transform the calculated samples into discrete numbers by using the probabilities calculated in the first step. ## History This distribution was derived by [Jacob Bernoulli](Jacob_Bernoulli \"wikilink\"). He considered the case where *p* = *r*/(*r* + *s*) where *p* is the probability of success and *r* and *s* are positive integers. [Blaise Pascal](Blaise_Pascal \"wikilink\") had earlier considered the case where *p* = 1/2. ## See also {#see_also} {{Portal|Mathematics}} - [Logistic regression](Logistic_regression \"wikilink\") - [Multinomial distribution](Multinomial_distribution \"wikilink\") - [Negative binomial distribution](Negative_binomial_distribution \"wikilink\") - [Beta-binomial distribution](Beta-binomial_distribution \"wikilink\") - Binomial measure, an example of a [multifractal](Multifractal_system \"wikilink\") [measure](measure_(mathematics) \"wikilink\").[^40] - [Statistical mechanics](Statistical_mechanics \"wikilink\") - [Piling-up lemma](Piling-up_lemma \"wikilink\"), the resulting probability when [XOR](XOR \"wikilink\")-ing independent Boolean variables ## References {{reflist|colwidth=30em}} ## Further reading {#further_reading} - ```{=mediawiki} {{cite book |first=Werner Z. |last=Hirsch |title=Introduction to Modern Statistics |location=New York |publisher=MacMillan |year=1957 |chapter=Binomial Distribution\u2014Success or Failure, How Likely Are They? |pages=140\u2013153 |chapter-url=https://books.google.com/books?id=KostAAAAIAAJ&pg=PA140 }} ``` - ```{=mediawiki} {{cite book |first1=John |last1=Neter |first2=William |last2=Wasserman |first3=G. A. |last3=Whitmore |title=Applied Statistics |location=Boston |publisher=Allyn & Bacon |edition=Third |year=1988 |isbn=0-205-10328-6 |pages=185\u2013192 }} ``` ## External links {#external_links} {{Commons category|Binomial distributions}} - Interactive graphic: [Univariate Distribution Relationships](http://www.math.wm.edu/~leemis/chart/UDR/UDR.html) - [Binomial distribution formula calculator](http://www.fxsolver.com/browse/formulas/Binomial+distribution) - Difference of two binomial variables: [X-Y](https://math.stackexchange.com/q/1065487) or [\\|X-Y\\|](https://math.stackexchange.com/q/562119) - [Querying the binomial probability distribution in WolframAlpha](http://www.wolframalpha.com/input/?i=Prob+x+%3E+19+if+x+is+binomial+with+n+%3D+36++and+p+%3D+.6) {{-}} `{{ProbDistributions|discrete-finite}}`{=mediawiki} {{DEFAULTSORT:Binomial Distribution}} [Category:Discrete distributions](Category:Discrete_distributions \"wikilink\") [Category:Factorial and binomial topics](Category:Factorial_and_binomial_topics \"wikilink\") [Category:Conjugate prior distributions](Category:Conjugate_prior_distributions \"wikilink\") [Category:Exponential family distributions](Category:Exponential_family_distributions \"wikilink\") [2] Quantitative Exploratory Data Analysis Descriptive Statistics Mean ```numpy.mean(a, axis=None, dtype=None)``` * a: array containing numbers whose mean is required * axis: axis or axes along which the means are computed, * default is to compute the mean of the flattened array * dtype: type of data to be used in calculations # get versicolor's petal length versicolor_petal_length = df_iris . loc [ df_iris [ 'species' ] == 'versicolor' ][ 'petal length (cm)' ] . to_numpy ( dtype = np . float64 , copy = False ) # Compute the mean: mean_length_vers mean_length_vers = np . mean ( versicolor_petal_length , axis = None , dtype = np . float16 ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , mean_length_vers , 'cm' ) Median ```numpy.median(a, axis=None, out=None)``` * a: array containing numbers whose median is required * axis: axis or axes along which the median is computed * default is to compute the median of the flattened array * out: alternative output array to place the result, must have the same shape and buffer length as the expected output. # Compute the median: median_length_vers median_length_vers = np . median ( versicolor_petal_length , axis = None ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , median_length_vers , 'cm' ) Mode **The mode is the most frequently occurring number.** scipy . stats . mstats . mode ( a , axis = 0 ) * a: array containing numbers whose mode is required * axis: axis or axes along which the mode is computed * default is 0 * if None, compute the mode of the flattened array It returns (```mode: array of modal values, count: array of counts for each mode```). # Compute the mode: mode_length_vers mode_length_vers = scipy . stats . mstats . mode ( versicolor_petal_length , axis = None ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , mode_length_vers , 'cm' ) Range ```numpy.ptp(a, axis=None, out=None)``` 'ptp' stands for 'peak to peak'. * a: array containing numbers whose range is required * axis: axis or axes along which the range is computed, * default is to compute the range of the flattened array. It returns a new array with the result. # Compute the range: range_length_vers range_length_vers = np . ptp ( versicolor_petal_length , axis = None ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , range_length_vers , 'cm' ) Population Variance Variance can be calculated in python using different libraries like numpy, pandas, and statistics. numpy.var(a, axis=None, dtype=None, ddof=0) * a: array containing numbers whose variance is required * axis: axis or axes along which the variances are computed, default is to compute the mean of the flattened array * ddof : int, optional * ddof stands for delta degrees of freedom. It is the divisor used in the calculation, which is N - ddof, where N is the number of elements. * The default value of ddof is 0. **Formula** $$\\sigma^2 = \\frac{\\displaystyle\\sum_{i=1}^{n}(x_i - \\mu)^2} {n}$$ # Array of differences to mean: differences differences = versicolor_petal_length - \\ np . mean ( versicolor_petal_length , axis = None ) # Square the differences: diff_sq diff_sq = np . square ( differences ) # Compute the mean square difference: variance_explicit variance_explicit = np . sum ( np . square ( versicolor_petal_length - np . mean ( versicolor_petal_length , axis = None ))) / len ( versicolor_petal_length ) # Compute the variance using NumPy: variance_np variance_np = np . var ( versicolor_petal_length , axis = None ) # Print the results print ( variance_explicit , variance_np ) Note that the unit of variance is not the same as the dataset, for example, if we are looking at the Iris dataset's versicolor petal length, which is in cm, and its variance is 0.2164 cm squared. So it is not easy to interpret the variance and hence we can look at the standard deviation, which square roots the variance, to make it the same unit as the dataset. With standard deviation, we have 0.465188 cm. Population Standard Deviation The standard deviation is the square root of variance. numpy.std(a, axis=None, dtype=None, ddof=0) Parameters are the same as ```numpy.var()```. * a: array containing numbers whose standard deviation is required * axis: axis or axes along which the standard deviations are computed, default is to compute the mean of the flattened array * ddof : int, optional * ddof stands for delta degrees of freedom. It is the divisor used in the calculation, which is N - ddof, where N is the number of elements. * The default value of ddof is 0. **Formula** $$\\sigma = \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^{n}(x_i - \\mu)^2} {n}}$$ Because the variance is the average of the distances from the mean _squared_, the standard deviation tells us approximately, on average, the distance of numbers in a distribution from the mean of the distribution. In the **Mean** section, we see that the average petal length is of 4.26 cm, our standard deviation tells us that ***on average***, each data point in the distribution (population) is around 0.465188~ cm away from the mean. # Compute the variance: variance variance = np . var ( versicolor_petal_length , axis = None ) # Print the square root of the variance print ( np . sqrt ( variance )) # Print the standard deviation print ( np . std ( versicolor_petal_length , axis = None )) Percentile # Specify array of percentiles: percentiles percentiles = np . array ([ 2.5 , 25 , 50 , 75 , 97.5 ]) # Compute percentiles: ptiles_vers ptiles_vers = np . percentile ( a = versicolor_petal_length , q = percentiles , axis = None ) # Print the result print ( ptiles_vers ) def ecdf ( data ): \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\" # Number of data points: n n = len ( data ) # x-data for the ECDF: x x = np . sort ( data ) # y-data for the ECDF: y y = np . arange ( start = 1 , stop = n + 1 ) / n return x , y # Plot the ECDF x_vers , y_vers = ecdf ( versicolor_petal_length ) _ = plt . plot ( x_vers , y_vers , \".\" ) _ = plt . xlabel ( 'petal length (cm)' ) _ = plt . ylabel ( 'ECDF' ) # Overlay percentiles as red diamonds. _ = plt . plot ( ptiles_vers , percentiles / 100 , marker = 'D' , color = 'red' , linestyle = 'none' ) # Save the plot save_fig ( \"[Versicolor] Percentile + ECDF Plot on Petal Length\" ) # Show the plot plt . show () Skewness scipy.stats.skew(a, axis=0) For normally distributed data, the skewness should be about 0. A skewness value > 0 means that there is more weight in the left tail of the distribution. Skewness refers to the lack of symmetry in a distribution of data. [Technical note: we will be talking about skewness here only in the context of _unimodal_ distributions.] ![image.png](attachment:e5188fd8-9bb3-422f-8121-a459a129189f.png) A *positive-skewed* distribution is one whose right tail is longer or fatter than its left. Conversely, a *negative-skewed* distribution is one whose left tail is longer or fatter than its right. Symmetric distributions have no skewness! #### Skewness and measures of central tendency The mean, median, and mode are affected by skewness. When a distribution is symmetric, the mean, median, and mode are the same. > Symmetric: mean == median == mode When a distribution is negatively skewed, the mean is less than the median, which is less than the mode. > Negative skew: mean < median < mode When a distribution is positively skewed, the mean is greater than the median, which is greater than the mode. > Positive skew: mode < median < mean You\u2019ve learned numerical measures of center, spread, and outliers, but what about **measures of shape**? The histogram can give you a general idea of the shape, but two numerical measures of shape give a more precise evaluation: **skewness tells you the amount and direction of skew** (departure from horizontal symmetry), and **kurtosis tells you how tall and sharp the central peak is**, relative to a standard bell curve. Why do we care? One application is **testing for normality**: many statistics inferences require that a distribution be normal or nearly normal. A normal distribution has skewness and excess kurtosis of 0, so if your distribution is close to those values then it is probably close to normal. # Compute the range: range_length_vers skew_length_vers = scipy . stats . skew ( versicolor_petal_length , axis = None ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , skew_length_vers , 'cm' ) Indeed, our skew is negative, indicating the data is in a slightly negative skewed distribution, where the left tail is longer. A natural question that follows is how to calculate skewness? How is the value -0.588158~ quantified? _ = sns . displot ( x = versicolor_petal_length , kind = 'kde' ) _ = plt . xlabel ( xlabel = 'petal length (cm)' ) _ = sns . displot ( x = versicolor_petal_length , kind = 'hist' ) _ = plt . xlabel ( xlabel = 'petal length (cm)' ) _ = sns . displot ( x = versicolor_petal_length , kind = 'ecdf' ) _ = plt . xlabel ( xlabel = 'petal length (cm)' ) Box and Whiskers Plot Making a box plot for the petal lengths is unnecessary because the iris data set is not too large and the bee swarm plot works fine. Furthermore, A box and whisker plot\u2014also called a box plot\u2014displays the five-number summary of a set of data. The five-number summary is the minimum, first quartile, median, third quartile, and maximum. In a box plot, we draw a box from the first quartile to the third quartile. A vertical/horizontal line goes through the box at the median. The whiskers go from each quartile to the minimum or maximum. # Create box plot with Seaborn's default settings _ = sns . boxplot ( x = 'species' , y = 'petal length (cm)' , data = df_iris ) # Label the axes _ = plt . xlabel ( xlabel = 'species' ) _ = plt . ylabel ( ylabel = 'petal length (cm)' ) # Save the plot save_fig ( \"[Versicolor] Box and Whiskers Plot on Petal Length\" ) # Show the plot plt . show () To understand the graph above, let us just look at **versicolor** for consistency. In simple terms, the ECDF of this species can be interpreted as follows: what percentage of **versicolor** have a **petal length** of less than 4 cm? By eyeballing, we can tell that about $20\\%$ just by pinpointing which value on the y-axis (ECDF) corresponds to 4 cm on the x-axis (petal length).","title":"Day 1 binomial distribution"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/day-1-graphical-exploratory-data-analysis/","text":"66 Days of Data [03/07/2021] Day 1 Quick Navigation * [Dependencies](#1) * [Configurations](#2) * [Seeding](#3) * [Loading Iris Data](#4) * [Graphical Exploratory Data Analysis](#5) * [Histogram](#51) * [Bee Swarm Plot](#52) * [Empirical Cumulative Distribution Function](#53) * [ECDF vs CDF](#531) Dependencies # !pip install -U -q scikit-learn==0.24.2 import os import random import sys import seaborn as sns import matplotlib as mpl import matplotlib.pyplot as plt import numpy as np import pandas as pd import sklearn import torch from sklearn.datasets import * assert sys . version_info >= ( 3 , 5 ) assert sklearn . __version__ >= \"0.20\" Configurations np . random . seed ( 42 ) % matplotlib inline sns . set ( style = \"ticks\" ) plt . style . use ( \"dark_background\" ) # mpl.rc('axes', labelsize=15) # mpl.rc('xtick', labelsize=12) # mpl.rc('ytick', labelsize=12) # Where to save the figures PROJECT_ROOT_DIR = \".\" CHAPTER_ID = \"Graphical Exploratory Data Analysis\" IMAGES_PATH = os . path . join ( PROJECT_ROOT_DIR , \"images\" , CHAPTER_ID ) os . makedirs ( IMAGES_PATH , exist_ok = True ) def save_fig ( fig_id , tight_layout = True , fig_extension = \"png\" , resolution = 300 ): path = os . path . join ( IMAGES_PATH , fig_id + \".\" + fig_extension ) print ( \"Saving figure\" , fig_id ) if tight_layout : plt . tight_layout () plt . savefig ( path , format = fig_extension , dpi = resolution ) Seeding def seed_all ( seed : int = 1930 ): \"\"\"Seed all random number generators.\"\"\" print ( \"Using Seed Number {} \" . format ( seed )) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator random . seed ( seed ) # set fixed value for python built-in pseudo-random generator torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False torch . backends . cudnn . enabled = False def seed_worker ( _worker_id ): \"\"\"Seed a worker with the given ID.\"\"\" worker_seed = torch . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) seed_all ( 1992 ) Using Seed Number 1992 Loading Iris Data # import iris and load as dataframe iris = load_iris ( return_X_y = False , as_frame = True ) # make a copy of iris df_iris = iris . frame . copy () # change target to species and map 0,1,2 to species df_iris . columns = [ 'sepal length (cm)' , 'sepal width (cm)' , 'petal length (cm)' , 'petal width (cm)' , 'species' ] species_mapping = { 0 : 'setosa' , 1 : 'versicolor' , 2 : 'virginica' } df_iris [ 'species' ] = df_iris [ 'species' ] . map ( species_mapping ) [1] Graphical Exploratory Data Analysis Histogram - Used for continuous data while bar charts are used for categorical data. - To construct a histogram, the first step is to \"bin\" (or \"bucket\") the range of values\u2014that is, divide the entire range of values into a series of intervals\u2014and then count how many values fall into each interval. We used the square root rule to calculate the number of bins in the histogram below. It turns out that `int(n_bins)=7`. It is a nice number because if I set the x-tick step size to be 0.3, we can easily see that each interval contains how many such values. For example, we know that the `max(versicolor_petal_length)=5.1` and the `min(versicolor_petal_length)=3`. Therefore, the range is 2.1. We can divide 2.1 into 7 bins, where each interval is 0.3. This is why I chose the x-tick step size to be 0.3 earlier. From the graph, it is now easy to interpret that there are 1 count from 3-3.3, 4 counts from 3.3-3.6 and so on. You can uncomment `_ = plt.hist(x=versicolor_petal_length, bins=20, edgecolor='blue', linewidth=1.2)` below to see that when you increase the number of bins, your data representation seemingly change, which is one of the drawbacks of histograms. # get versicolor's petal length versicolor_petal_length = df_iris . loc [ df_iris [ 'species' ] == 'versicolor' ][ 'petal length (cm)' ] . to_numpy ( dtype = np . float16 , copy = False ) # Compute number of data points: n_data n_data = len ( versicolor_petal_length ) # Number of bins is the square root of number of data points: n_bins n_bins = np . sqrt ( n_data ) # Convert number of bins to integer: n_bins n_bins = int ( n_bins ) # Plot the histogram _ = plt . hist ( x = versicolor_petal_length , bins = n_bins , edgecolor = 'red' , linewidth = 1.2 ) # _ = plt.hist(x=versicolor_petal_length, bins=20, edgecolor='blue', linewidth=1.2) # Label axes _ = plt . xlabel ( 'petal length (cm)' ) _ = plt . ylabel ( 'count' ) # setting x and y ticks to show a more granular level of x and y range. # note carefully that np.arange does not include the stop value, except when my step size is in float (like the case below) _ = plt . xticks ( np . arange ( start = min ( versicolor_petal_length ), stop = max ( versicolor_petal_length ), step = 0.3 )) _ = plt . yticks ( np . arange ( start = 0 , stop = 18 , step = 2 )) # Save the plot save_fig ( \"[Versicolor] Histogram Plot on Petal Length\" ) # Show histogram plt . show () Saving figure [Versicolor] Histogram Plot on Petal Length ![png](day-1-graphical-exploratory-data-analysis_files/day-1-graphical-exploratory-data-analysis_14_1.png) We can tell that there are more data clustered in between 3.9-4.8 cm. Bee Swarm Plot An additional problem with histograms is that we are not plotting all of the data. We are sweeping the data into bins, and losing their actual values. This means that we are not on a granular level when reading off histogram plots, instead, we are grouping data in terms of bins, like from this range to that range, how many data are within the said intervals. This can lead to what we mentioned on the point above - binning bias. Bee Swarm Plot addresses this issue by plotting all data points of Iris dataset where x-axis is the species, and y-axis the petal length. This diagram below attempts to show all data points, linking back to the histogram previously, we can tell that for versicolor species, there are more data points clustered in between 4-4.75 cm (roughly the same as what we saw in histogram). # get petal species and petal length petal_species = df_iris [ 'species' ] petal_length = df_iris [ 'petal length (cm)' ] # _ = sns.swarmplot(x=petal_species, y = petal_length) same as below # note that change marker size from 5 to 3 to avoid the plot warning on marker size too big _ = sns . swarmplot ( x = 'species' , y = 'petal length (cm)' , data = df_iris , size = 3 ) # Label the axes _ = plt . xlabel ( xlabel = 'species' ) _ = plt . ylabel ( ylabel = 'petal length (cm)' ) _ = plt . xlabel ( 'petal length (cm)' ) _ = plt . ylabel ( 'count' ) # setting x and y ticks to show a more granular level of x and y range. _ = plt . yticks ( np . arange ( start = 0 , stop = max ( petal_length ) + 1 , step = 1 )) # Save the plot save_fig ( \"[Iris] Bee Swarm Plot on Petal Length\" ) # Show the plot plt . show () Saving figure [Iris] Bee Swarm Plot on Petal Length ![png](day-1-graphical-exploratory-data-analysis_files/day-1-graphical-exploratory-data-analysis_18_1.png) Empirical Cumulative Distribution Function An ECDF is an estimator of the Cumulative Distribution Function. To read it, it is similar to the idea of percentiles. To code it in python: 1. sort the data in ascending order 2. calculate the number of samples in the data 3. calculate the y-axis in a binning manner: start from 0, with increment of 1/n until it reaches 1. def ecdf ( data ): \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\" # Number of data points: n n = len ( data ) # x-data for the ECDF: x x = np . sort ( data ) # y-data for the ECDF: y y = np . arange ( start = 1 , stop = n + 1 ) / n return x , y versicolor_petal_length = df_iris . loc [ df_iris [ 'species' ] == 'versicolor' ][ 'petal length (cm)' ] . to_numpy ( dtype = np . float16 , copy = False ) setosa_petal_length = df_iris . loc [ df_iris [ 'species' ] == 'setosa' ][ 'petal length (cm)' ] . to_numpy ( dtype = np . float16 , copy = False ) virginica_petal_length = df_iris . loc [ df_iris [ 'species' ] == 'virginica' ][ 'petal length (cm)' ] . to_numpy ( dtype = np . float16 , copy = False ) # Compute ECDFs x_set , y_set = ecdf ( setosa_petal_length ) x_vers , y_vers = ecdf ( versicolor_petal_length ) x_virg , y_virg = ecdf ( virginica_petal_length ) # Plot all ECDFs on the same plot _ = plt . plot ( x_set , y_set , marker = \".\" , linestyle = 'none' ) _ = plt . plot ( x_vers , y_vers , marker = \".\" , linestyle = 'none' ) _ = plt . plot ( x_virg , y_virg , marker = \".\" , linestyle = 'none' ) # Annotate the plot plt . legend (( 'setosa' , 'versicolor' , 'virginica' ), loc = 'lower right' ) _ = plt . xlabel ( 'petal length (cm)' ) _ = plt . ylabel ( 'ECDF' ) # Save the plot save_fig ( \"[Iris] ECDF Plot on Petal Length\" ) # Display the plot plt . show () Saving figure [Iris] ECDF Plot on Petal Length ![png](day-1-graphical-exploratory-data-analysis_files/day-1-graphical-exploratory-data-analysis_22_1.png) To understand the graph above, let us just look at **versicolor** for consistency. In simple terms, the ECDF of this species can be interpreted as follows: what percentage of **versicolor** have a **petal length** of less than 4 cm? By eyeballing, we can tell that about $20\\%$ just by pinpointing which value on the y-axis (ECDF) corresponds to 4 cm on the x-axis (petal length). ECDF vs CDF Let $X$ be a random variable. - The cumulative distribution function $F(x)$ gives the $P(X \\leq x)$. - An empirical cumulative distribution function function $G(x)$ gives $P(X \\leq x)$ based on the observations in your sample. The distinction is which probability measure is used. For the empirical CDF, you use the probability measure defined by the frequency counts in an empirical sample. **Simple example (coin flip):** Let $X$ be a random variable denoting the result of a single coin flip where $X=1$ denotes heads and $X=0$ denotes tails. The CDF for a fair coin is given by: $$ F(x) = \\left\\{ \\begin{array}{ll} 0 & \\text{for } x < 0\\\\ \\frac{1}{2} & \\text{for } 0 \\leq x < 1 \\\\1 & \\text{for } 1 \\leq x \\end{array} \\right. $$ If you flipped 2 heads and 1 tail, the empirical CDF would be: $$ G(x) = \\left\\{ \\begin{array}{ll} 0 & \\text{for } x < 0\\\\ \\frac{2}{3} & \\text{for } 0 \\leq x < 1 \\\\1 & \\text{for } 1 \\leq x \\end{array} \\right. $$ The empirical CDF would reflect that in your sample, $2/3$ of your flips were heads. **Another example ($F$ is CDF for normal distribution):** Let $X$ be a normally distributed random variable with mean $0$ and standard deviation $1$. The CDF is given by: $$F(x) = \\int_{-\\infty}^x \\frac{1}{\\sqrt{2\\pi}} e^{\\frac{-x^2}{2}}$$ Let's say you had 3 IID draws and obtained the values $x_1 < x_2 < x_3$. The empirical CDF would be: $$ G(y) = \\left\\{ \\begin{array}{ll} 0 & \\text{for } y < x_1\\\\ \\frac{1}{3} & \\text{for } x_1 \\leq y < x_2 \\\\\\frac{2}{3} & \\text{for } x_2 \\leq y < x_3 \\\\1 & \\text{for } x_3 \\leq y \\end{array} \\right. $$ With enough IID draws (and certain regularity conditions are satisfied), the empirical CDF would converge on the underlying CDF of the population.","title":"Day 1 graphical exploratory data analysis"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/day-2-quantitative-exploratory-data-analysis/","text":"66 Days of Data [04/07/2021] Day 2 This is slightly modified from the original module in Datacamp, as I find it better to put the concept of covariance later on. Quick Navigation * [Dependencies](#1) * [Configurations](#2) * [Seeding](#3) * [Loading Iris Data](#4) * [Quantitative Exploratory Data Analysis](#5) * [Descripte Analytics](#51) * [Mean](#511) * [Median](#512) * [Mode](#513) * [Range](#514) * [Population Variance](#515) * [Population Standard Deviation](#516) * [Percentiles](#517) * [Box and Whiskers Plot](#52) Dependencies # !pip install -U -q scikit-learn==0.24.2 import os import random import sys import seaborn as sns import matplotlib as mpl import matplotlib.pyplot as plt import numpy as np import pandas as pd import sklearn import torch import scipy from sklearn.datasets import * assert sys . version_info >= ( 3 , 5 ) assert sklearn . __version__ >= \"0.20\" Configurations np . random . seed ( 42 ) % matplotlib inline sns . set ( style = \"ticks\" ) plt . style . use ( \"dark_background\" ) # mpl.rc('axes', labelsize=15) # mpl.rc('xtick', labelsize=12) # mpl.rc('ytick', labelsize=12) # Where to save the figures PROJECT_ROOT_DIR = \".\" CHAPTER_ID = \"Quantitative Exploratory Data Analysis\" IMAGES_PATH = os . path . join ( PROJECT_ROOT_DIR , \"images\" , CHAPTER_ID ) os . makedirs ( IMAGES_PATH , exist_ok = True ) def save_fig ( fig_id , tight_layout = True , fig_extension = \"png\" , resolution = 300 ): path = os . path . join ( IMAGES_PATH , fig_id + \".\" + fig_extension ) print ( \"Saving figure\" , fig_id ) if tight_layout : plt . tight_layout () plt . savefig ( path , format = fig_extension , dpi = resolution ) Seeding def seed_all ( seed : int = 1930 ): \"\"\"Seed all random number generators.\"\"\" print ( \"Using Seed Number {} \" . format ( seed )) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator random . seed ( seed ) # set fixed value for python built-in pseudo-random generator torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False torch . backends . cudnn . enabled = False def seed_worker ( _worker_id ): \"\"\"Seed a worker with the given ID.\"\"\" worker_seed = torch . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) seed_all ( 1992 ) Using Seed Number 1992 Loading Iris Data # import iris and load as dataframe iris = load_iris ( return_X_y = False , as_frame = True ) # make a copy of iris df_iris = iris . frame . copy () # change target to species and map 0,1,2 to species df_iris . columns = [ 'sepal length (cm)' , 'sepal width (cm)' , 'petal length (cm)' , 'petal width (cm)' , 'species' ] species_mapping = { 0 : 'setosa' , 1 : 'versicolor' , 2 : 'virginica' } df_iris [ 'species' ] = df_iris [ 'species' ] . map ( species_mapping ) [2] Quantitative Exploratory Data Analysis Descriptive Statistics Mean ```numpy.mean(a, axis=None, dtype=None)``` * a: array containing numbers whose mean is required * axis: axis or axes along which the means are computed, * default is to compute the mean of the flattened array * dtype: type of data to be used in calculations # get versicolor's petal length versicolor_petal_length = df_iris . loc [ df_iris [ 'species' ] == 'versicolor' ][ 'petal length (cm)' ] . to_numpy ( dtype = np . float64 , copy = False ) # Compute the mean: mean_length_vers mean_length_vers = np . mean ( versicolor_petal_length , axis = None , dtype = np . float16 ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , mean_length_vers , 'cm' ) Iris. versicolor: 4.26 cm Median ```numpy.median(a, axis=None, out=None)``` * a: array containing numbers whose median is required * axis: axis or axes along which the median is computed * default is to compute the median of the flattened array * out: alternative output array to place the result, must have the same shape and buffer length as the expected output. # Compute the median: median_length_vers median_length_vers = np . median ( versicolor_petal_length , axis = None ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , median_length_vers , 'cm' ) Iris. versicolor: 4.35 cm Mode **The mode is the most frequently occurring number.** scipy . stats . mstats . mode ( a , axis = 0 ) * a: array containing numbers whose mode is required * axis: axis or axes along which the mode is computed * default is 0 * if None, compute the mode of the flattened array It returns (```mode: array of modal values, count: array of counts for each mode```). # Compute the mode: mode_length_vers mode_length_vers = scipy . stats . mstats . mode ( versicolor_petal_length , axis = None ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , mode_length_vers , 'cm' ) Iris. versicolor: ModeResult(mode=array([4.5]), count=array([7.])) cm Range ```numpy.ptp(a, axis=None, out=None)``` 'ptp' stands for 'peak to peak'. * a: array containing numbers whose range is required * axis: axis or axes along which the range is computed, * default is to compute the range of the flattened array. It returns a new array with the result. # Compute the range: range_length_vers range_length_vers = np . ptp ( versicolor_petal_length , axis = None ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , range_length_vers , 'cm' ) Iris. versicolor: 2.0999999999999996 cm Population Variance Variance can be calculated in python using different libraries like numpy, pandas, and statistics. numpy.var(a, axis=None, dtype=None, ddof=0) * a: array containing numbers whose variance is required * axis: axis or axes along which the variances are computed, default is to compute the mean of the flattened array * ddof : int, optional * ddof stands for delta degrees of freedom. It is the divisor used in the calculation, which is N - ddof, where N is the number of elements. * The default value of ddof is 0. **Formula** $$\\sigma^2 = \\frac{\\displaystyle\\sum_{i=1}^{n}(x_i - \\mu)^2} {n}$$ # Array of differences to mean: differences differences = versicolor_petal_length - \\ np . mean ( versicolor_petal_length , axis = None ) # Square the differences: diff_sq diff_sq = np . square ( differences ) # Compute the mean square difference: variance_explicit variance_explicit = np . sum ( np . square ( versicolor_petal_length - np . mean ( versicolor_petal_length , axis = None ))) / len ( versicolor_petal_length ) # Compute the variance using NumPy: variance_np variance_np = np . var ( versicolor_petal_length , axis = None ) # Print the results print ( variance_explicit , variance_np ) 0.21640000000000004 0.21640000000000004 Note that the unit of variance is not the same as the dataset, for example, if we are looking at the Iris dataset's versicolor petal length, which is in cm, and its variance is 0.2164 cm squared. So it is not easy to interpret the variance and hence we can look at the standard deviation, which square roots the variance, to make it the same unit as the dataset. With standard deviation, we have 0.465188 cm. Population Standard Deviation The standard deviation is the square root of variance. numpy.std(a, axis=None, dtype=None, ddof=0) Parameters are the same as ```numpy.var()```. * a: array containing numbers whose standard deviation is required * axis: axis or axes along which the standard deviations are computed, default is to compute the mean of the flattened array * ddof : int, optional * ddof stands for delta degrees of freedom. It is the divisor used in the calculation, which is N - ddof, where N is the number of elements. * The default value of ddof is 0. **Formula** $$\\sigma = \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^{n}(x_i - \\mu)^2} {n}}$$ Because the variance is the average of the distances from the mean _squared_, the standard deviation tells us approximately, on average, the distance of numbers in a distribution from the mean of the distribution. In the **Mean** section, we see that the average petal length is of 4.26 cm, our standard deviation tells us that ***on average***, each data point in the distribution (population) is around 0.465188~ cm away from the mean. # Compute the variance: variance variance = np . var ( versicolor_petal_length , axis = None ) # Print the square root of the variance print ( np . sqrt ( variance )) # Print the standard deviation print ( np . std ( versicolor_petal_length , axis = None )) 0.4651881339845203 0.4651881339845203 Percentile # Specify array of percentiles: percentiles percentiles = np . array ([ 2.5 , 25 , 50 , 75 , 97.5 ]) # Compute percentiles: ptiles_vers ptiles_vers = np . percentile ( a = versicolor_petal_length , q = percentiles , axis = None ) # Print the result print ( ptiles_vers ) [3.3 4. 4.35 4.6 4.9775] def ecdf ( data ): \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\" # Number of data points: n n = len ( data ) # x-data for the ECDF: x x = np . sort ( data ) # y-data for the ECDF: y y = np . arange ( start = 1 , stop = n + 1 ) / n return x , y # Plot the ECDF x_vers , y_vers = ecdf ( versicolor_petal_length ) _ = plt . plot ( x_vers , y_vers , \".\" ) _ = plt . xlabel ( 'petal length (cm)' ) _ = plt . ylabel ( 'ECDF' ) # Overlay percentiles as red diamonds. _ = plt . plot ( ptiles_vers , percentiles / 100 , marker = 'D' , color = 'red' , linestyle = 'none' ) # Save the plot save_fig ( \"[Versicolor] Percentile + ECDF Plot on Petal Length\" ) # Show the plot plt . show () Saving figure [Versicolor] Percentile + ECDF Plot on Petal Length ![png](day-2-quantitative-exploratory-data-analysis_files/day-2-quantitative-exploratory-data-analysis_39_1.png) Skewness scipy.stats.skew(a, axis=0) For normally distributed data, the skewness should be about 0. A skewness value > 0 means that there is more weight in the left tail of the distribution. Skewness refers to the lack of symmetry in a distribution of data. [Technical note: we will be talking about skewness here only in the context of _unimodal_ distributions.] ![image.png](attachment:e5188fd8-9bb3-422f-8121-a459a129189f.png) A *positive-skewed* distribution is one whose right tail is longer or fatter than its left. Conversely, a *negative-skewed* distribution is one whose left tail is longer or fatter than its right. Symmetric distributions have no skewness! #### Skewness and measures of central tendency The mean, median, and mode are affected by skewness. When a distribution is symmetric, the mean, median, and mode are the same. > Symmetric: mean == median == mode When a distribution is negatively skewed, the mean is less than the median, which is less than the mode. > Negative skew: mean < median < mode When a distribution is positively skewed, the mean is greater than the median, which is greater than the mode. > Positive skew: mode < median < mean You\u2019ve learned numerical measures of center, spread, and outliers, but what about **measures of shape**? The histogram can give you a general idea of the shape, but two numerical measures of shape give a more precise evaluation: **skewness tells you the amount and direction of skew** (departure from horizontal symmetry), and **kurtosis tells you how tall and sharp the central peak is**, relative to a standard bell curve. Why do we care? One application is **testing for normality**: many statistics inferences require that a distribution be normal or nearly normal. A normal distribution has skewness and excess kurtosis of 0, so if your distribution is close to those values then it is probably close to normal. # Compute the range: range_length_vers skew_length_vers = scipy . stats . skew ( versicolor_petal_length , axis = None ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , skew_length_vers , 'cm' ) Iris. versicolor: -0.5881586743962586 cm Indeed, our skew is negative, indicating the data is in a slightly negative skewed distribution, where the left tail is longer. A natural question that follows is how to calculate skewness? How is the value -0.588158~ quantified? _ = sns . displot ( x = versicolor_petal_length , kind = 'kde' ) _ = plt . xlabel ( xlabel = 'petal length (cm)' ) _ = sns . displot ( x = versicolor_petal_length , kind = 'hist' ) _ = plt . xlabel ( xlabel = 'petal length (cm)' ) _ = sns . displot ( x = versicolor_petal_length , kind = 'ecdf' ) _ = plt . xlabel ( xlabel = 'petal length (cm)' ) ![png](day-2-quantitative-exploratory-data-analysis_files/day-2-quantitative-exploratory-data-analysis_46_0.png) ![png](day-2-quantitative-exploratory-data-analysis_files/day-2-quantitative-exploratory-data-analysis_46_1.png) ![png](day-2-quantitative-exploratory-data-analysis_files/day-2-quantitative-exploratory-data-analysis_46_2.png) Box and Whiskers Plot Making a box plot for the petal lengths is unnecessary because the iris data set is not too large and the bee swarm plot works fine. Furthermore, A box and whisker plot\u2014also called a box plot\u2014displays the five-number summary of a set of data. The five-number summary is the minimum, first quartile, median, third quartile, and maximum. In a box plot, we draw a box from the first quartile to the third quartile. A vertical/horizontal line goes through the box at the median. The whiskers go from each quartile to the minimum or maximum. # Create box plot with Seaborn's default settings _ = sns . boxplot ( x = 'species' , y = 'petal length (cm)' , data = df_iris ) # Label the axes _ = plt . xlabel ( xlabel = 'species' ) _ = plt . ylabel ( ylabel = 'petal length (cm)' ) # Save the plot save_fig ( \"[Versicolor] Box and Whiskers Plot on Petal Length\" ) # Show the plot plt . show () Saving figure [Versicolor] Box and Whiskers Plot on Petal Length ![png](day-2-quantitative-exploratory-data-analysis_files/day-2-quantitative-exploratory-data-analysis_49_1.png) To understand the graph above, let us just look at **versicolor** for consistency. In simple terms, the ECDF of this species can be interpreted as follows: what percentage of **versicolor** have a **petal length** of less than 4 cm? By eyeballing, we can tell that about $20\\%$ just by pinpointing which value on the y-axis (ECDF) corresponds to 4 cm on the x-axis (petal length).","title":"Day 2 quantitative exploratory data analysis"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/day-3-probabilistically-discrete-variables/","text":"66 Days of Data [05/07/2021] Day 3 This is slightly modified from the original module in Datacamp, as I find it better to put the concept of covariance later on. Quick Navigation * [Dependencies](#1) * [Configurations](#2) * [Seeding](#3) * [Loading Iris Data](#4) * [Stastical Inferences](#5) * [Descripte Analytics](#51) * [Mean](#511) * [Median](#512) * [Mode](#513) * [Range](#514) * [Population Variance](#515) * [Population Standard Deviation](#516) * [Percentiles](#517) * [Box and Whiskers Plot](#52) Dependencies # !pip install -U -q scikit-learn==0.24.2 import os import random import sys import seaborn as sns import matplotlib as mpl import matplotlib.pyplot as plt import numpy as np import pandas as pd import sklearn import torch import scipy from sklearn.datasets import * assert sys . version_info >= ( 3 , 5 ) assert sklearn . __version__ >= \"0.20\" Configurations np . random . seed ( 42 ) % matplotlib inline sns . set ( style = \"ticks\" ) plt . style . use ( \"dark_background\" ) # mpl.rc('axes', labelsize=15) # mpl.rc('xtick', labelsize=12) # mpl.rc('ytick', labelsize=12) # Where to save the figures PROJECT_ROOT_DIR = \".\" CHAPTER_ID = \"Quantitative Exploratory Data Analysis\" IMAGES_PATH = os . path . join ( PROJECT_ROOT_DIR , \"images\" , CHAPTER_ID ) os . makedirs ( IMAGES_PATH , exist_ok = True ) def save_fig ( fig_id , tight_layout = True , fig_extension = \"png\" , resolution = 300 ): path = os . path . join ( IMAGES_PATH , fig_id + \".\" + fig_extension ) print ( \"Saving figure\" , fig_id ) if tight_layout : plt . tight_layout () plt . savefig ( path , format = fig_extension , dpi = resolution ) Seeding def seed_all ( seed : int = 1930 ): \"\"\"Seed all random number generators.\"\"\" print ( \"Using Seed Number {} \" . format ( seed )) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator random . seed ( seed ) # set fixed value for python built-in pseudo-random generator torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False torch . backends . cudnn . enabled = False def seed_worker ( _worker_id ): \"\"\"Seed a worker with the given ID.\"\"\" worker_seed = torch . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) seed_all ( 1992 ) Using Seed Number 1992 Loading Iris Data {{short description|Any experiment with two possible random outcomes}} {{Probability fundamentals}} ![Graphs of probability *P* of **not** observing independent events each of probability *p* after *n* Bernoulli trials vs *np* for various *p*. Three examples are shown:\\ **Blue curve**: Throwing a 6-sided die 6 times gives 33.5% chance that 6 (or any other given number) never turns up; it can be observed that as *n* increases, the probability of a 1/*n*-chance event never appearing after *n* tries rapidly converges to *0*.\\ **Grey curve**: To get 50-50 chance of throwing a [Yahtzee](Yahtzee \"wikilink\") (5 cubic dice all showing the same number) requires 0.69 \u00d7 1296 \\~ 898 throws.\\ **Green curve**: Drawing a card from a deck of playing cards without jokers 100 (1.92 \u00d7 52) times with replacement gives 85.7% chance of drawing the ace of spades at least once.](Bernoulli_trial_progression.svg \"fig:Graphs of probability P of not observing independent events each of probability p after n Bernoulli trials vs np for various p. Three examples are shown: Blue curve: Throwing a 6-sided die 6 times gives 33.5% chance that 6 (or any other given number) never turns up; it can be observed that as n increases, the probability of a 1/n-chance event never appearing after n tries rapidly converges to 0. Grey curve: To get 50-50 chance of throwing a Yahtzee (5 cubic dice all showing the same number) requires 0.69 \u00d7 1296 ~ 898 throws. Green curve: Drawing a card from a deck of playing cards without jokers 100 (1.92 \u00d7 52) times with replacement gives 85.7% chance of drawing the ace of spades at least once.\"){width=\"400\"} In the theory of [probability](probability \"wikilink\") and [statistics](statistics \"wikilink\"), a **Bernoulli trial** (or **binomial trial**) is a random [experiment](Experiment_(probability_theory) \"wikilink\") with exactly two possible [outcomes](Outcome_(probability) \"wikilink\"), \\\"success\\\" and \\\"failure\\\", in which the probability of success is the same every time the experiment is conducted.[^1] It is named after [Jacob Bernoulli](Jacob_Bernoulli \"wikilink\"), a 17th-century Swiss mathematician, who analyzed them in his *[Ars Conjectandi](Ars_Conjectandi \"wikilink\")* (1713).[^2] The mathematical formalisation of the Bernoulli trial is known as the [Bernoulli process](Bernoulli_process \"wikilink\"). This article offers an elementary introduction to the concept, whereas the article on the Bernoulli process offers a more advanced treatment. Since a Bernoulli trial has only two possible outcomes, it can be framed as some \\\"yes or no\\\" question. For example: - Is the top card of a shuffled deck an ace? - Was the newborn child a girl? (See [human sex ratio](human_sex_ratio \"wikilink\").) Therefore, success and failure are merely labels for the two outcomes, and should not be construed literally. The term \\\"success\\\" in this sense consists in the result meeting specified conditions, not in any moral judgement. More generally, given any [probability space](probability_space \"wikilink\"), for any [event](Event_(probability_theory) \"wikilink\") (set of outcomes), one can define a Bernoulli trial, corresponding to whether the event occurred or not (event or [complementary event](complementary_event \"wikilink\")). Examples of Bernoulli trials include: - Flipping a coin. In this context, obverse (\\\"heads\\\") conventionally denotes success and reverse (\\\"tails\\\") denotes failure. A [fair coin](fair_coin \"wikilink\") has the probability of success 0.5 by definition. In this case there are exactly two possible outcomes. - Rolling a `{{dice}}`{=mediawiki}, where a six is \\\"success\\\" and everything else a \\\"failure\\\". In this case there are six possible outcomes, and the event is a six; the complementary event \\\"not a six\\\" corresponds to the other five possible outcomes. - In conducting a political [opinion poll](opinion_poll \"wikilink\"), choosing a voter at random to ascertain whether that voter will vote \\\"yes\\\" in an upcoming referendum. ## Definition Independent repeated trials of an experiment with exactly two possible outcomes are called Bernoulli trials. Call one of the outcomes \\\"success\\\" and the other outcome \\\"failure\\\". Let $p$ be the probability of success in a Bernoulli trial, and $q$ be the probability of failure. Then the probability of success and the probability of failure sum to one, since these are complementary events: \\\"success\\\" and \\\"failure\\\" are [mutually exclusive](mutually_exclusive \"wikilink\") and [exhaustive](Collectively_exhaustive_events \"wikilink\"). Thus one has the following relations: $$p = 1 - q, \\quad \\quad q = 1 - p, \\quad \\quad p + q = 1.$$ Alternatively, these can be stated in terms of [odds](Odds_(statistics) \"wikilink\"): given probability *p* of success and *q* of failure, the *odds for* are $p:q$ and the *odds against* are $q:p.$ These can also be expressed as numbers, by dividing, yielding the odds for, $o_f$, and the odds against, $o_a:$, $$\\begin{align} o_f &= p/q = p/(1-p) = (1-q)/q\\\\ o_a &= q/p = (1-p)/p = q/(1-q) \\end{align}$$ These are [multiplicative inverses](multiplicative_inverse \"wikilink\"), so they multiply to 1, with the following relations: $$o_f = 1/o_a, \\quad o_a = 1/o_f, \\quad o_f \\cdot o_a = 1.$$ In the case that a Bernoulli trial is representing an event from finitely many [equally likely outcomes](equally_likely_outcomes \"wikilink\"), where *S* of the outcomes are success and *F* of the outcomes are failure, the odds for are $S:F$ and the odds against are $F:S.$ This yields the following formulas for probability and odds: $$\\begin{align} p &= S/(S+F)\\\\ q &= F/(S+F)\\\\ o_f &= S/F\\\\ o_a &= F/S \\end{align}$$ Note that here the odds are computed by dividing the number of outcomes, not the probabilities, but the proportion is the same, since these ratios only differ by multiplying both terms by the same constant factor. [Random variables](Random_variable \"wikilink\") describing Bernoulli trials are often encoded using the convention that 1 = \\\"success\\\", 0 = \\\"failure\\\". Closely related to a Bernoulli trial is a binomial experiment, which consists of a fixed number $n$ of [statistically independent](statistically_independent \"wikilink\") Bernoulli trials, each with a probability of success $p$, and counts the number of successes. A random variable corresponding to a binomial is denoted by $B(n,p)$, and is said to have a *[binomial distribution](binomial_distribution \"wikilink\")*. The probability of exactly $k$ successes in the experiment $B(n,p)$ is given by: $$P(k)={n \\choose k} p^k q^{n-k}$$ where ${n \\choose k}$ is a [binomial coefficient](binomial_coefficient \"wikilink\"). Bernoulli trials may also lead to [negative binomial distributions](negative_binomial_distribution \"wikilink\") (which count the number of successes in a series of repeated Bernoulli trials until a specified number of failures are seen), as well as various other distributions. When multiple Bernoulli trials are performed, each with its own probability of success, these are sometimes referred to as [Poisson trials](Poisson_trial \"wikilink\").[^3] ## Example: tossing coins {#example_tossing_coins} Consider the simple experiment where a fair coin is tossed four times. Find the probability that exactly two of the tosses result in heads. ### Solution For this experiment, let a heads be defined as a *success* and a tails as a *failure.* Because the coin is assumed to be fair, the probability of success is $p = \\tfrac{1}{2}$. Thus the probability of failure, $q$, is given by $$q = 1 - p = 1 - \\tfrac{1}{2} = \\tfrac{1}{2}$$. Using the equation above, the probability of exactly two tosses out of four total tosses resulting in a heads is given by: $$\\begin{align} P(2) &= {4 \\choose 2} p^{2} q^{4-2} \\\\ &= 6 \\times \\left(\\tfrac{1}{2}\\right)^2 \\times \\left(\\tfrac{1}{2}\\right)^2 \\\\ &= \\dfrac {3}{8}. \\end{align}$$ ## See also {#see_also} - [Bernoulli scheme](Bernoulli_scheme \"wikilink\") - [Bernoulli sampling](Bernoulli_sampling \"wikilink\") - [Bernoulli distribution](Bernoulli_distribution \"wikilink\") - [Binomial distribution](Binomial_distribution \"wikilink\") - [Binomial coefficient](Binomial_coefficient \"wikilink\") - [Binomial proportion confidence interval](Binomial_proportion_confidence_interval \"wikilink\") - [Poisson sampling](Poisson_sampling \"wikilink\") - [Sampling design](Sampling_design \"wikilink\") - [Coin flipping](Coin_flipping \"wikilink\") - [Jacob Bernoulli](Jacob_Bernoulli \"wikilink\") - [Fisher\\'s exact test](Fisher's_exact_test \"wikilink\") - [Boschloo\\'s test](Boschloo's_test \"wikilink\") ## References {{reflist}} ## External links {#external_links} {{Commonscat}} - ```{=mediawiki} {{springer|title=Bernoulli trials|id=p/b015690}} ``` - ```{=mediawiki} {{cite web|url=http://www.math.uah.edu/stat/applets/BinomialTimelineExperiment.html|title=Simulation of n Bernoulli trials|publisher=math.uah.edu|access-date=2014-01-21}} ``` ```{=mediawiki} {{DEFAULTSORT:Bernoulli Trial}} [Category:Discrete distributions](Category:Discrete_distributions \"wikilink\") [Category:Coin flipping](Category:Coin_flipping \"wikilink\") [Category:Experiment (probability theory)](Category:Experiment_(probability_theory) \"wikilink\") [^1]: `{{cite encyclopedia | last = Papoulis | first = A. | contribution = Bernoulli Trials | title = Probability, Random Variables, and Stochastic Processes | edition = 2nd | location = New York | publisher = [[McGraw-Hill]] | pages = 57\u201363 | year = 1984}}`{=mediawiki} [^2]: James Victor Uspensky: *Introduction to Mathematical Probability*, McGraw-Hill, New York 1937, page 45 [^3]: [Rajeev Motwani](Rajeev_Motwani \"wikilink\") and P. Raghavan. Randomized Algorithms. Cambridge University Press, New York (NY), 1995, p.67-68 ```python def perform_bernoulli_trials(n, p): \"\"\" Perform n Bernoulli trials with success probability p and return number of successes. That is to say: If I toss coin 10 times, and landed head 7 times, then success rate is 70% -> this is what I should return. But note this is binary. \"\"\" # Initialize number of successes: n_success n_success = 0 # Perform trials for i in range(n): # Choose random number between zero and one: random_number random_number = np.random.random(size=1) # If less than p, it's a success so add one to n_success if random_number < p: n_success += 1 return n_success def perform_bernoulli_trials(n, p): \"\"\" Perform n Bernoulli trials with success probability p and return number of successes. That is to say: If I toss coin 10 times, and landed head 7 times, then success rate is 70% -> this is what I should return. But note this is binary. \"\"\" # Initialize number of successes: n_success n_success = 0 # Perform trials,# Choose random number between zero and one: random_number # If less than p, it's a success so add one to n_success random_number_arr = [True if np.random.random(size=n) < p else False] n_success = np.sum(random_number_arr, axis = None) return n_success # import iris and load as dataframe iris = load_iris ( return_X_y = False , as_frame = True ) # make a copy of iris df_iris = iris . frame . copy () # change target to species and map 0,1,2 to species df_iris . columns = [ 'sepal length (cm)' , 'sepal width (cm)' , 'petal length (cm)' , 'petal width (cm)' , 'species' ] species_mapping = { 0 : 'setosa' , 1 : 'versicolor' , 2 : 'virginica' } df_iris [ 'species' ] = df_iris [ 'species' ] . map ( species_mapping ) [2] Quantitative Exploratory Data Analysis Descriptive Statistics Mean ```numpy.mean(a, axis=None, dtype=None)``` * a: array containing numbers whose mean is required * axis: axis or axes along which the means are computed, * default is to compute the mean of the flattened array * dtype: type of data to be used in calculations # get versicolor's petal length versicolor_petal_length = df_iris . loc [ df_iris [ 'species' ] == 'versicolor' ][ 'petal length (cm)' ] . to_numpy ( dtype = np . float64 , copy = False ) # Compute the mean: mean_length_vers mean_length_vers = np . mean ( versicolor_petal_length , axis = None , dtype = np . float16 ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , mean_length_vers , 'cm' ) Iris. versicolor: 4.26 cm Median ```numpy.median(a, axis=None, out=None)``` * a: array containing numbers whose median is required * axis: axis or axes along which the median is computed * default is to compute the median of the flattened array * out: alternative output array to place the result, must have the same shape and buffer length as the expected output. # Compute the median: median_length_vers median_length_vers = np . median ( versicolor_petal_length , axis = None ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , median_length_vers , 'cm' ) Iris. versicolor: 4.35 cm Mode **The mode is the most frequently occurring number.** scipy . stats . mstats . mode ( a , axis = 0 ) * a: array containing numbers whose mode is required * axis: axis or axes along which the mode is computed * default is 0 * if None, compute the mode of the flattened array It returns (```mode: array of modal values, count: array of counts for each mode```). # Compute the mode: mode_length_vers mode_length_vers = scipy . stats . mstats . mode ( versicolor_petal_length , axis = None ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , mode_length_vers , 'cm' ) Iris. versicolor: ModeResult(mode=array([4.5]), count=array([7.])) cm Range ```numpy.ptp(a, axis=None, out=None)``` 'ptp' stands for 'peak to peak'. * a: array containing numbers whose range is required * axis: axis or axes along which the range is computed, * default is to compute the range of the flattened array. It returns a new array with the result. # Compute the range: range_length_vers range_length_vers = np . ptp ( versicolor_petal_length , axis = None ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , range_length_vers , 'cm' ) Iris. versicolor: 2.0999999999999996 cm Population Variance Variance can be calculated in python using different libraries like numpy, pandas, and statistics. numpy.var(a, axis=None, dtype=None, ddof=0) * a: array containing numbers whose variance is required * axis: axis or axes along which the variances are computed, default is to compute the mean of the flattened array * ddof : int, optional * ddof stands for delta degrees of freedom. It is the divisor used in the calculation, which is N - ddof, where N is the number of elements. * The default value of ddof is 0. **Formula** $$\\sigma^2 = \\frac{\\displaystyle\\sum_{i=1}^{n}(x_i - \\mu)^2} {n}$$ # Array of differences to mean: differences differences = versicolor_petal_length - \\ np . mean ( versicolor_petal_length , axis = None ) # Square the differences: diff_sq diff_sq = np . square ( differences ) # Compute the mean square difference: variance_explicit variance_explicit = np . sum ( np . square ( versicolor_petal_length - np . mean ( versicolor_petal_length , axis = None ))) / len ( versicolor_petal_length ) # Compute the variance using NumPy: variance_np variance_np = np . var ( versicolor_petal_length , axis = None ) # Print the results print ( variance_explicit , variance_np ) 0.21640000000000004 0.21640000000000004 Note that the unit of variance is not the same as the dataset, for example, if we are looking at the Iris dataset's versicolor petal length, which is in cm, and its variance is 0.2164 cm squared. So it is not easy to interpret the variance and hence we can look at the standard deviation, which square roots the variance, to make it the same unit as the dataset. With standard deviation, we have 0.465188 cm. Population Standard Deviation The standard deviation is the square root of variance. numpy.std(a, axis=None, dtype=None, ddof=0) Parameters are the same as ```numpy.var()```. * a: array containing numbers whose standard deviation is required * axis: axis or axes along which the standard deviations are computed, default is to compute the mean of the flattened array * ddof : int, optional * ddof stands for delta degrees of freedom. It is the divisor used in the calculation, which is N - ddof, where N is the number of elements. * The default value of ddof is 0. **Formula** $$\\sigma = \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^{n}(x_i - \\mu)^2} {n}}$$ Because the variance is the average of the distances from the mean _squared_, the standard deviation tells us approximately, on average, the distance of numbers in a distribution from the mean of the distribution. In the **Mean** section, we see that the average petal length is of 4.26 cm, our standard deviation tells us that ***on average***, each data point in the distribution (population) is around 0.465188~ cm away from the mean. # Compute the variance: variance variance = np . var ( versicolor_petal_length , axis = None ) # Print the square root of the variance print ( np . sqrt ( variance )) # Print the standard deviation print ( np . std ( versicolor_petal_length , axis = None )) 0.4651881339845203 0.4651881339845203 Percentile # Specify array of percentiles: percentiles percentiles = np . array ([ 2.5 , 25 , 50 , 75 , 97.5 ]) # Compute percentiles: ptiles_vers ptiles_vers = np . percentile ( a = versicolor_petal_length , q = percentiles , axis = None ) # Print the result print ( ptiles_vers ) [3.3 4. 4.35 4.6 4.9775] def ecdf ( data ): \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\" # Number of data points: n n = len ( data ) # x-data for the ECDF: x x = np . sort ( data ) # y-data for the ECDF: y y = np . arange ( start = 1 , stop = n + 1 ) / n return x , y # Plot the ECDF x_vers , y_vers = ecdf ( versicolor_petal_length ) _ = plt . plot ( x_vers , y_vers , \".\" ) _ = plt . xlabel ( 'petal length (cm)' ) _ = plt . ylabel ( 'ECDF' ) # Overlay percentiles as red diamonds. _ = plt . plot ( ptiles_vers , percentiles / 100 , marker = 'D' , color = 'red' , linestyle = 'none' ) # Save the plot save_fig ( \"[Versicolor] Percentile + ECDF Plot on Petal Length\" ) # Show the plot plt . show () Saving figure [Versicolor] Percentile + ECDF Plot on Petal Length ![png](day-3-probabilistically-discrete-variables_files/day-3-probabilistically-discrete-variables_41_1.png) Skewness scipy.stats.skew(a, axis=0) For normally distributed data, the skewness should be about 0. A skewness value > 0 means that there is more weight in the left tail of the distribution. Skewness refers to the lack of symmetry in a distribution of data. [Technical note: we will be talking about skewness here only in the context of _unimodal_ distributions.] ![image.png](attachment:e5188fd8-9bb3-422f-8121-a459a129189f.png) A *positive-skewed* distribution is one whose right tail is longer or fatter than its left. Conversely, a *negative-skewed* distribution is one whose left tail is longer or fatter than its right. Symmetric distributions have no skewness! #### Skewness and measures of central tendency The mean, median, and mode are affected by skewness. When a distribution is symmetric, the mean, median, and mode are the same. > Symmetric: mean == median == mode When a distribution is negatively skewed, the mean is less than the median, which is less than the mode. > Negative skew: mean < median < mode When a distribution is positively skewed, the mean is greater than the median, which is greater than the mode. > Positive skew: mode < median < mean You\u2019ve learned numerical measures of center, spread, and outliers, but what about **measures of shape**? The histogram can give you a general idea of the shape, but two numerical measures of shape give a more precise evaluation: **skewness tells you the amount and direction of skew** (departure from horizontal symmetry), and **kurtosis tells you how tall and sharp the central peak is**, relative to a standard bell curve. Why do we care? One application is **testing for normality**: many statistics inferences require that a distribution be normal or nearly normal. A normal distribution has skewness and excess kurtosis of 0, so if your distribution is close to those values then it is probably close to normal. # Compute the range: range_length_vers skew_length_vers = scipy . stats . skew ( versicolor_petal_length , axis = None ) # Print the result with some nice formatting print ( 'Iris. versicolor:' , skew_length_vers , 'cm' ) Iris. versicolor: -0.5881586743962586 cm Indeed, our skew is negative, indicating the data is in a slightly negative skewed distribution, where the left tail is longer. A natural question that follows is how to calculate skewness? How is the value -0.588158~ quantified? _ = sns . displot ( x = versicolor_petal_length , kind = 'kde' ) _ = plt . xlabel ( xlabel = 'petal length (cm)' ) _ = sns . displot ( x = versicolor_petal_length , kind = 'hist' ) _ = plt . xlabel ( xlabel = 'petal length (cm)' ) _ = sns . displot ( x = versicolor_petal_length , kind = 'ecdf' ) _ = plt . xlabel ( xlabel = 'petal length (cm)' ) ![png](day-3-probabilistically-discrete-variables_files/day-3-probabilistically-discrete-variables_48_0.png) ![png](day-3-probabilistically-discrete-variables_files/day-3-probabilistically-discrete-variables_48_1.png) ![png](day-3-probabilistically-discrete-variables_files/day-3-probabilistically-discrete-variables_48_2.png) Box and Whiskers Plot Making a box plot for the petal lengths is unnecessary because the iris data set is not too large and the bee swarm plot works fine. Furthermore, A box and whisker plot\u2014also called a box plot\u2014displays the five-number summary of a set of data. The five-number summary is the minimum, first quartile, median, third quartile, and maximum. In a box plot, we draw a box from the first quartile to the third quartile. A vertical/horizontal line goes through the box at the median. The whiskers go from each quartile to the minimum or maximum. # Create box plot with Seaborn's default settings _ = sns . boxplot ( x = 'species' , y = 'petal length (cm)' , data = df_iris ) # Label the axes _ = plt . xlabel ( xlabel = 'species' ) _ = plt . ylabel ( ylabel = 'petal length (cm)' ) # Save the plot save_fig ( \"[Versicolor] Box and Whiskers Plot on Petal Length\" ) # Show the plot plt . show () Saving figure [Versicolor] Box and Whiskers Plot on Petal Length ![png](day-3-probabilistically-discrete-variables_files/day-3-probabilistically-discrete-variables_51_1.png) To understand the graph above, let us just look at **versicolor** for consistency. In simple terms, the ECDF of this species can be interpreted as follows: what percentage of **versicolor** have a **petal length** of less than 4 cm? By eyeballing, we can tell that about $20\\%$ just by pinpointing which value on the y-axis (ECDF) corresponds to 4 cm on the x-axis (petal length).","title":"Day 3 probabilistically discrete variables"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/maximum_likelihood/","text":"\\[\\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\P}{\\mathcal{P}} \\newcommand{\\C}{\\mathbf{C}}\\] Density estimation is the problem of estimating the probability distribution for a sample of observations from a problem domain. There are many techniques for solving density estimation, although a common framework used throughout the field of machine learning is maximum likelihood estimation. Maximum likelihood estimation involves defining a likelihood function for calculating the conditional probability of observing the data sample given a probability distribution and distribution parameters. This approach can be used to search a space of possible distributions and parameters. This flexible probabilistic framework also provides the foundation for many machine learning algorithms, including important methods such as linear regression and logistic regression for predicting numeric values and class labels respectively, but also more generally for deep learning artificial neural networks. In this tutorial, you will discover a gentle introduction to maximum likelihood estimation. After reading this tutorial, you will know: \u0088 Maximum Likelihood Estimation is a probabilistic framework for solving the problem of density estimation. \u0088 It involves maximizing a likelihood function in order to find the probability distribution and parameters that best explain the observed data. \u0088 It provides a framework for predictive modeling in machine learning where finding model parameters can be framed as an optimization problem. Let\u2019s get started. Probability for Machine Learning - Jason Brownlee Intuition for Probability Distribution Function First you need to be very clear about what a probability distribution is. Consider that we have 10 students and we model their marks where the full marks of the test is 16/16. Define a random variable \\(X\\) where \\(X\\) represents the marks of each student. Assume further that this random variable \\(X\\) is following a normal distribution with \\(\\mu = 11\\) and \\(\\sigma = 3\\) , can we find the probability distribution for the marks of the whole cohort (10 students)? Yes we can, because we have the parameters of the distribution. If you do not know what is the meaning of parameters, please go revise on it 1 , it is very important for you to understand that the parameter decides the probability distribution of any model. Recall the general formula for the PDF of the normal distribution is \\[f(X = x) = \\dfrac{e^{-(x-\\mu)^2}/(2\\sigma^2)}{\\sigma \\sqrt{2\\pi}}\\] And in normal distribution once we have the mean and standard deviation of the dataset, we can recover the whole pdf of the model, hence the mean and standard deviation are our parameters. So let us say we want to find \\(P(11 < X < 13~|~\\mu = 11, \\sigma = 3)\\) , we can easily find it to be around \\(0.31 = 31\\%\\) , we can basically find any probabilities as long as we are given the parameters . So, we must have the correct mindset that probability density functions (or pmf alike) are legitimate functions that takes in any \\(X = x\\) and outputs the probability of this \\(x\\) happening . (Of course in continuous distribution we are usually only interested in the range of \\(x\\) , but for the purpose of intuition, we do not need to be so pedantic). For the more mathematically formal people, here is the more precise definition of what I described above: Suppose you have random variables \\(X\\) which arise from a parameterized distribution \\(\\P(X; \\theta)\\) , where \\(\\theta\\) is the parameter characterizing the distribution \\(\\P\\) . Then the probability of \\(X = x\\) would be: \\(P(X = x~|~\\theta) = \\P(x; \\theta)\\) , with known \\(\\theta\\) . Likelihood Function However, in the real world setting, more often than not, we have the data \\(X\\) , like we have conveniently the scores of all the 10 students above, which could be a random sample taken from the whole school's population. Now we are tasked to find the probability distribution of the whole population (say 10,000 students), and we would have calculated it ever so easily if we knew what the parameters were! Unfortunately we do not have the true parameters. Our main motivation now is to find the parameter , because without it, we cannot complete the task of finding the distribution of the population. We can never know the real/true parameter \\(\\theta = (\\mu, \\sigma)\\) , but we can obtain a good estimate of it by making use of the data that we do have! In this scenario we were given 10 data points (in real life it is usually much more), say the 10 data points are \\( \\(\\mathbf{X} = [3,9,4,10,12,16,5,11,9,9]\\) \\) So we do a sleight of hand using our original probability density function , \\(P(X = x~|~ \\theta)\\) . Instead of being a function of \\(X = x\\) where \\(\\theta\\) is known, we instead let \\(X = x\\) be fixed, and let \\(\\theta\\) be the variable now. The idea is that this function now is \\textbf{NO LONGER a function of} \\(X=x\\) , and is instead a function of \\(\\theta\\) , where it takes in all possible values of \\(\\theta\\) , and outputs a value called the \\textbf{likelihood value.} So now, in a less informal way, our new function looks like \\( \\(P(\\mathbf{X} = [3,9,4,10,12,16,5,11,9,9]~|~ \\theta)\\) \\) and it means \\textbf{what is the probability of OBSERVING these data points, given different values of theta.} One needs to plot the graph of likelihood out to get a better idea (wikipedia). \\bigskip \\bigskip So imagine our function (plot likelihood value vs parameter) has a local/global maximum, and that maximum is what we are finding ultimately. Because it is reasonable for us to believe that, the \\textbf{parameter} that gives us the maximum value of \\(P(\\mathbf{X} = [3,9,4,10,12,16,5,11,9,9]~|~ \\theta)\\) will suggest that \\textbf{given these 10 data points}, this \\(\\theta\\) that we just found, gives us the most \\textbf{likelihood/probability} that these 10 points are actually observed. \\bigskip We formally define this function to be $$\\mathcal{L}(\\theta~|~ X = x) = P(X = x~|~\\theta) $$ \\bigskip I cannot emphasize enough that even those the likelihood function \\(\\mathcal{L}\\) and the probability function \\(P\\) have the exact same form, they are fundamentally different in which one is a function of the parameter \\(\\theta\\) , and the other is a function of the data points \\(X = x\\) . https://en.wikipedia.org/wiki/Statistical_parameter \u21a9","title":"Maximum likelihood"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/maximum_likelihood/#intuition-for-probability-distribution-function","text":"First you need to be very clear about what a probability distribution is. Consider that we have 10 students and we model their marks where the full marks of the test is 16/16. Define a random variable \\(X\\) where \\(X\\) represents the marks of each student. Assume further that this random variable \\(X\\) is following a normal distribution with \\(\\mu = 11\\) and \\(\\sigma = 3\\) , can we find the probability distribution for the marks of the whole cohort (10 students)? Yes we can, because we have the parameters of the distribution. If you do not know what is the meaning of parameters, please go revise on it 1 , it is very important for you to understand that the parameter decides the probability distribution of any model. Recall the general formula for the PDF of the normal distribution is \\[f(X = x) = \\dfrac{e^{-(x-\\mu)^2}/(2\\sigma^2)}{\\sigma \\sqrt{2\\pi}}\\] And in normal distribution once we have the mean and standard deviation of the dataset, we can recover the whole pdf of the model, hence the mean and standard deviation are our parameters. So let us say we want to find \\(P(11 < X < 13~|~\\mu = 11, \\sigma = 3)\\) , we can easily find it to be around \\(0.31 = 31\\%\\) , we can basically find any probabilities as long as we are given the parameters . So, we must have the correct mindset that probability density functions (or pmf alike) are legitimate functions that takes in any \\(X = x\\) and outputs the probability of this \\(x\\) happening . (Of course in continuous distribution we are usually only interested in the range of \\(x\\) , but for the purpose of intuition, we do not need to be so pedantic). For the more mathematically formal people, here is the more precise definition of what I described above: Suppose you have random variables \\(X\\) which arise from a parameterized distribution \\(\\P(X; \\theta)\\) , where \\(\\theta\\) is the parameter characterizing the distribution \\(\\P\\) . Then the probability of \\(X = x\\) would be: \\(P(X = x~|~\\theta) = \\P(x; \\theta)\\) , with known \\(\\theta\\) .","title":"Intuition for Probability Distribution Function"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/maximum_likelihood/#likelihood-function","text":"However, in the real world setting, more often than not, we have the data \\(X\\) , like we have conveniently the scores of all the 10 students above, which could be a random sample taken from the whole school's population. Now we are tasked to find the probability distribution of the whole population (say 10,000 students), and we would have calculated it ever so easily if we knew what the parameters were! Unfortunately we do not have the true parameters. Our main motivation now is to find the parameter , because without it, we cannot complete the task of finding the distribution of the population. We can never know the real/true parameter \\(\\theta = (\\mu, \\sigma)\\) , but we can obtain a good estimate of it by making use of the data that we do have! In this scenario we were given 10 data points (in real life it is usually much more), say the 10 data points are \\( \\(\\mathbf{X} = [3,9,4,10,12,16,5,11,9,9]\\) \\) So we do a sleight of hand using our original probability density function , \\(P(X = x~|~ \\theta)\\) . Instead of being a function of \\(X = x\\) where \\(\\theta\\) is known, we instead let \\(X = x\\) be fixed, and let \\(\\theta\\) be the variable now. The idea is that this function now is \\textbf{NO LONGER a function of} \\(X=x\\) , and is instead a function of \\(\\theta\\) , where it takes in all possible values of \\(\\theta\\) , and outputs a value called the \\textbf{likelihood value.} So now, in a less informal way, our new function looks like \\( \\(P(\\mathbf{X} = [3,9,4,10,12,16,5,11,9,9]~|~ \\theta)\\) \\) and it means \\textbf{what is the probability of OBSERVING these data points, given different values of theta.} One needs to plot the graph of likelihood out to get a better idea (wikipedia). \\bigskip \\bigskip So imagine our function (plot likelihood value vs parameter) has a local/global maximum, and that maximum is what we are finding ultimately. Because it is reasonable for us to believe that, the \\textbf{parameter} that gives us the maximum value of \\(P(\\mathbf{X} = [3,9,4,10,12,16,5,11,9,9]~|~ \\theta)\\) will suggest that \\textbf{given these 10 data points}, this \\(\\theta\\) that we just found, gives us the most \\textbf{likelihood/probability} that these 10 points are actually observed. \\bigskip We formally define this function to be $$\\mathcal{L}(\\theta~|~ X = x) = P(X = x~|~\\theta) $$ \\bigskip I cannot emphasize enough that even those the likelihood function \\(\\mathcal{L}\\) and the probability function \\(P\\) have the exact same form, they are fundamentally different in which one is a function of the parameter \\(\\theta\\) , and the other is a function of the data points \\(X = x\\) . https://en.wikipedia.org/wiki/Statistical_parameter \u21a9","title":"Likelihood Function"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/probability4datascience/","text":"import os import random import string from functools import cache import matplotlib.pyplot as plt import numpy as np from numba import jit from numpy.random import default_rng from typing import * Consider one day to code up random generators like Uniform Distribution from scratch: https://github.com/neerajkumarvaid/Data-Science-From-Scratch-Python/blob/master/probability.py https://towardsdatascience.com/how-to-generate-random-variables-from-scratch-no-library-used-4b71eb3c8dc7 def seed_all ( seed : int = 1992 ) -> None : \"\"\"Seed all random number generators.\"\"\" print ( f \"Using Seed Number { seed } \" ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value np . random . seed ( seed ) # for numpy pseudo-random generator random . seed ( seed ) # set fixed value for python built-in pseudo-random generator seed_all ( 1992 ) Using Seed Number 1992 Chapter 1 Question 6 def f ( x , y ): return np . divide ( 1 , np . multiply ( 2 * np . sqrt ( 3 ), np . pi )) * np . exp ( np . multiply ( np . divide ( - 1 , 6 ), ( x ** 2 - 2 * x * y - 2 * x + 4 * y ** 2 + 2 * y + 1 ), ) ) Create meshgrids such that we enumerate cases of the range \\([-3, 3] \\times [-3, 3]\\) for the values that \\(X\\) and \\(Y\\) can take on. Correspondingly, set \\(Z = f(X, Y)\\) such that we have constant values for the set of values we got from the meshgrid. As an example: When \\(X = -3, Y = 3\\) , we have \\(Z = f(X, Y) = 2.8986519194402697e-07\\) . This is one contour line in the 2d space, but why it looks like a curvature (circle)? This suggests that when keeping \\(Z\\) to be the constant of \\(2.8986519194402697e-07\\) , there are many different set of \\((X, Y)\\) that gives this value! X = np . linspace ( - 3 , 3 , 10 ) Y = np . linspace ( - 3 , 3 , 10 ) X , Y = np . meshgrid ( X , Y ) Z = f ( X , Y ) plt . contour ( X , Y , Z , 20 , cmap = 'RdGy' ) plt . colorbar (); Question 9 @cache def calc_vowel_consonant_prob ( num_simulations : int , * args , ** kwargs ) -> float : \"\"\"A collection of 26 English letters, a-z, is mixed in a jar. Two letters are drawn at random, one after the other without replacement. What is the probability of drawing a vowel (a,e,i,o,u) and a consonant in either order? Args: num_simulations (int): Number of simulations to run. Returns: float: The probability of drawing a vowel and a consonant in either order. \"\"\" count = 0 rng = default_rng () for sim_num in range ( num_simulations ): sample_2_letters_without_replacement = rng . choice ( * args , ** kwargs ) chosen_letters = np . asarray ( all_letters )[ sample_2_letters_without_replacement ] if not ( set ( chosen_letters ) . issubset ( vowels ) or set ( chosen_letters ) . issubset ( consonants ) ): count += 1 return count / num_simulations all_letters = list ( string . ascii_lowercase ) vowels = [ \"a\" , \"e\" , \"i\" , \"o\" , \"u\" ] consonants = list ( set ( all_letters ) - set ( vowels )) num_simulations = 1000000 calc_vowel_consonant_prob ( num_simulations , a = 26 , size = 2 , replace = False ) 0.323559 sample_2_letters_without_replacement = rng.choice(a = 26, size = 2, replace=False) : This is equivalent to random.sample(range(26), 2) which if we set the parameters correctly, means we will sample index 0 to 25 twice, without replacement. For example, the sampled index is in a form of a array of size 2: [1, 4] which corresponds to the letters [b, e] . Note in particular this sampling is a using a uniform distribution where each letter has \\(\\frac{1}{26}\\) chance of getting selected in the first sample. chosen_letters = np.asarray(all_letters)[sample_2_letters_without_replacement] : This is just subsetting the index from the all_letters . Since all_letters is a list which enumerates the alphabets in order, it suffices for us to just subset the array directly to get the chosen letters. if not (set(chosen_letters).issubset(vowels) or set(chosen_letters).issubset(consonant)): count += 1 : If our chosen_letters is neither a subset of the vowels or the consonant, then this means that it fulfills our condition, (i.e. one consonant and one vowel, we don't care order since the question said either order). If condition fulfilled, count adds 1. Lastly, calculate the probability by dividing the count by the num_simulations to get the frequency (i.e the probability). Indeed with enough simulations, the probability converges to the theoretical answer of \\(0.3230...\\) . Question 10: Birthday Paradox Settings: 50 people Assume each person has a \\(\\frac{1}{365}\\) probability to be assigned a birthday. In other words, the person's birthday should come from a uniform distribution from 1 to 365. So simple modelling just allows us to draw numbers for these 50 people from \\([1, 365]\\) and whenever the number is same we say they are of the same birthday. Want to find probability (frequency) of at least 2 people have same birthday. Note that in your code one should also consider any number \\(>=2\\) . rng = np . random . default_rng () num_possible_birthdays = 365 num_people = 50 num_simulations = 1000 def containsDuplicate ( nums : List [ int ]) -> bool : \"\"\"Check if a list contains duplicate elements. Args: nums (List[int]): List of integers. Returns: bool: Boolean value to indicate if the list contains duplicate elements. \"\"\" dup_dict = {} for _ , num in enumerate ( nums ): if num not in dup_dict : dup_dict [ num ] = 0 else : return True return False def generate_one_random_birthday ( num_possible_birthdays : int = 365 ) -> int : \"\"\"Generate one random birthday from 1 to num_possible_birthdays. Samples 1 integer from 1 to 365 from a uniform distribution. Args: num_possible_birthdays (int): The number of possible birthdays. Defaults to 365. Returns: birthday (int): The random birthday in integer. \"\"\" # Return random integers from the \"discrete uniform\" distribution of the specified dtype. If high is None (the default), then results are from 0 to low. birthday = rng . integers ( num_possible_birthdays , size = None ) # size=None to return integer instead of array of ints return birthday def generate_k_birthdays ( num_people : int , * args , ** kwargs ) -> List [ int ]: \"\"\"Generates all possible birthdays for a given number of people sampled from a uniform distribution. Example: If there are 3 people, the possible birthdays can be understood to be sampled from a uniform distribution of 1 to 365 inclusive with replacement. >>> generate_k_birthdays(3, 365) Args: num_people (int): The number of people in the group. num_possible_birthdays (int, optional): Number of possible birthdays. Defaults to 365. Returns: birthdays (List[int]): A list of birthdays. \"\"\" birthdays = [ generate_one_random_birthday ( * args , ** kwargs ) for _ in range ( num_people ) ] return birthdays def calculate_same_birthday_probability ( num_simulations : int , * args , ** kwargs ) -> float : \"\"\"Calculates the probability of the Birthday Paradox Problem. Args: num_simulations (int, optional): The number of simulations to run. Returns: probability (float): The probability of the Birthday Paradox. \"\"\" count = 0 for _ in range ( num_simulations ): birthdays = generate_k_birthdays ( * args , ** kwargs ) if containsDuplicate ( birthdays ): count += 1 probability = count / num_simulations return probability calculate_same_birthday_probability ( num_simulations = 10000 , num_people = 50 , num_possible_birthdays = 365 ) 0.97 We go through one loop of the simulation to understand the code: birthdays = default_rng().choice(a=num_possible_birthdays, size=num_people, replace=True) : what this does is two folds, Samples 1 integer from 1 to 365 from a uniform distribution. (i.e. 1 to num_possible_birthdays) Repeat the sampling of 1 integer 50 times. (i.e. num_people=50) In short, it returns an array of 50 elements, each element is sampled uniformly from 1 to 365 inclusive. if has_duplicates(birthdays) checks whether the array has duplicates (i.e. akin to checking if 2 or more people has the same birthdays). If True , count +=1 . Finally, the probability is the number of count divided by the total number of simulations. It should converge to around \\(0.97\\) . One should realize by now probability in most parts, is just the frequency of \"occurring\" over the total number of \"events\". def calculate_same_birthday_probability_rng_choice ( num_simulations : int , num_people : int = 50 , num_possible_birthdays : int = 365 , replace : bool = True , ) -> float : \"\"\"Calculates the probability of the Birthday Paradox Problem. Args: num_simulations (int, optional): The number of simulations to run. num_people (int, optional): The number of people in the simulation. num_possible_birthdays (int, optional): The number of possible birthdays. replace (bool, optional): Whether or not to sample with replacement. Returns: probability (float): The probability of the Birthday Paradox. \"\"\" count = 0 for _ in range ( num_simulations ): birthdays = default_rng () . choice ( a = num_possible_birthdays , size = num_people , replace = True ) if containsDuplicate ( birthdays ): count += 1 probability = count / num_simulations return probability calculate_same_birthday_probability_rng_choice ( num_simulations = 10000 , num_people = 50 , num_possible_birthdays = 365 , replace = True ) 0.9714 The below code is not mine and is taken from here . For my reference to see if I coded correctly. from random import randint import matplotlib.pyplot as plt import seaborn as sns MIN_NUM_PEOPLE = 2 MAX_NUM_PEOPLE = 60 NUM_POSSIBLE_BIRTHDAYS = 365 NUM_TRIALS = 10000 def generate_random_birthday (): birthday = randint ( 1 , NUM_POSSIBLE_BIRTHDAYS ) return birthday def generate_k_birthdays ( k ): birthdays = [ generate_random_birthday () for _ in range ( k )] return birthdays def aloc ( birthdays ): unique_birthdays = set ( birthdays ) num_birthdays = len ( birthdays ) num_unique_birthdays = len ( unique_birthdays ) has_coincidence = ( num_birthdays != num_unique_birthdays ) return has_coincidence def estimate_p_aloc ( k ): num_aloc = 0 for _ in range ( NUM_TRIALS ): birthdays = generate_k_birthdays ( k ) has_coincidence = aloc ( birthdays ) if has_coincidence : num_aloc += 1 p_aloc = num_aloc / NUM_TRIALS return p_aloc def estimate_p_aloc_for_range ( ks ): k_probabilities = [] for k in ks : p_aloc = estimate_p_aloc ( k ) k_probabilities . append ( p_aloc ) return k_probabilities ks = range ( MIN_NUM_PEOPLE , MAX_NUM_PEOPLE + 1 ) k_probabilities = estimate_p_aloc_for_range ( ks ) fig , ax = plt . subplots ( figsize = ( 10 , 10 ), dpi = 49 ) ax . set_facecolor ( '#518792' ) ax . xaxis . set_tick_params ( width = 5 , color = '#2d3233' ) ax . yaxis . set_tick_params ( width = 5 , color = '#2d3233' ) sns . lineplot ( x = ks , y = k_probabilities , color = '#2d3233' ) plt . xticks ( fontsize = 15 , color = '#2d3233' ) y_range = [ 0 , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 , 0.9 , 1 ] plt . yticks ( y_range , fontsize = 15 , color = '#2d3233' ) plt . grid () plt . xlim ([ 0 , 60 ]) plt . ylim ([ 0 , 1 ]) plt . xlabel ( 'Number of people' , fontsize = 30 , color = '#2d3233' ) plt . ylabel ( 'P(At Least One Coincidence)' , fontsize = 30 , color = '#2d3233' ) plt . show () Chapter 2: Probability","title":"Introduction to Probability for Data Science (Stanley H. Chan)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/probability4datascience/#chapter-1","text":"","title":"Chapter 1"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/probability4datascience/#question-6","text":"def f ( x , y ): return np . divide ( 1 , np . multiply ( 2 * np . sqrt ( 3 ), np . pi )) * np . exp ( np . multiply ( np . divide ( - 1 , 6 ), ( x ** 2 - 2 * x * y - 2 * x + 4 * y ** 2 + 2 * y + 1 ), ) ) Create meshgrids such that we enumerate cases of the range \\([-3, 3] \\times [-3, 3]\\) for the values that \\(X\\) and \\(Y\\) can take on. Correspondingly, set \\(Z = f(X, Y)\\) such that we have constant values for the set of values we got from the meshgrid. As an example: When \\(X = -3, Y = 3\\) , we have \\(Z = f(X, Y) = 2.8986519194402697e-07\\) . This is one contour line in the 2d space, but why it looks like a curvature (circle)? This suggests that when keeping \\(Z\\) to be the constant of \\(2.8986519194402697e-07\\) , there are many different set of \\((X, Y)\\) that gives this value! X = np . linspace ( - 3 , 3 , 10 ) Y = np . linspace ( - 3 , 3 , 10 ) X , Y = np . meshgrid ( X , Y ) Z = f ( X , Y ) plt . contour ( X , Y , Z , 20 , cmap = 'RdGy' ) plt . colorbar ();","title":"Question 6"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/probability4datascience/#question-9","text":"@cache def calc_vowel_consonant_prob ( num_simulations : int , * args , ** kwargs ) -> float : \"\"\"A collection of 26 English letters, a-z, is mixed in a jar. Two letters are drawn at random, one after the other without replacement. What is the probability of drawing a vowel (a,e,i,o,u) and a consonant in either order? Args: num_simulations (int): Number of simulations to run. Returns: float: The probability of drawing a vowel and a consonant in either order. \"\"\" count = 0 rng = default_rng () for sim_num in range ( num_simulations ): sample_2_letters_without_replacement = rng . choice ( * args , ** kwargs ) chosen_letters = np . asarray ( all_letters )[ sample_2_letters_without_replacement ] if not ( set ( chosen_letters ) . issubset ( vowels ) or set ( chosen_letters ) . issubset ( consonants ) ): count += 1 return count / num_simulations all_letters = list ( string . ascii_lowercase ) vowels = [ \"a\" , \"e\" , \"i\" , \"o\" , \"u\" ] consonants = list ( set ( all_letters ) - set ( vowels )) num_simulations = 1000000 calc_vowel_consonant_prob ( num_simulations , a = 26 , size = 2 , replace = False ) 0.323559 sample_2_letters_without_replacement = rng.choice(a = 26, size = 2, replace=False) : This is equivalent to random.sample(range(26), 2) which if we set the parameters correctly, means we will sample index 0 to 25 twice, without replacement. For example, the sampled index is in a form of a array of size 2: [1, 4] which corresponds to the letters [b, e] . Note in particular this sampling is a using a uniform distribution where each letter has \\(\\frac{1}{26}\\) chance of getting selected in the first sample. chosen_letters = np.asarray(all_letters)[sample_2_letters_without_replacement] : This is just subsetting the index from the all_letters . Since all_letters is a list which enumerates the alphabets in order, it suffices for us to just subset the array directly to get the chosen letters. if not (set(chosen_letters).issubset(vowels) or set(chosen_letters).issubset(consonant)): count += 1 : If our chosen_letters is neither a subset of the vowels or the consonant, then this means that it fulfills our condition, (i.e. one consonant and one vowel, we don't care order since the question said either order). If condition fulfilled, count adds 1. Lastly, calculate the probability by dividing the count by the num_simulations to get the frequency (i.e the probability). Indeed with enough simulations, the probability converges to the theoretical answer of \\(0.3230...\\) .","title":"Question 9"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/probability4datascience/#question-10-birthday-paradox","text":"Settings: 50 people Assume each person has a \\(\\frac{1}{365}\\) probability to be assigned a birthday. In other words, the person's birthday should come from a uniform distribution from 1 to 365. So simple modelling just allows us to draw numbers for these 50 people from \\([1, 365]\\) and whenever the number is same we say they are of the same birthday. Want to find probability (frequency) of at least 2 people have same birthday. Note that in your code one should also consider any number \\(>=2\\) . rng = np . random . default_rng () num_possible_birthdays = 365 num_people = 50 num_simulations = 1000 def containsDuplicate ( nums : List [ int ]) -> bool : \"\"\"Check if a list contains duplicate elements. Args: nums (List[int]): List of integers. Returns: bool: Boolean value to indicate if the list contains duplicate elements. \"\"\" dup_dict = {} for _ , num in enumerate ( nums ): if num not in dup_dict : dup_dict [ num ] = 0 else : return True return False def generate_one_random_birthday ( num_possible_birthdays : int = 365 ) -> int : \"\"\"Generate one random birthday from 1 to num_possible_birthdays. Samples 1 integer from 1 to 365 from a uniform distribution. Args: num_possible_birthdays (int): The number of possible birthdays. Defaults to 365. Returns: birthday (int): The random birthday in integer. \"\"\" # Return random integers from the \"discrete uniform\" distribution of the specified dtype. If high is None (the default), then results are from 0 to low. birthday = rng . integers ( num_possible_birthdays , size = None ) # size=None to return integer instead of array of ints return birthday def generate_k_birthdays ( num_people : int , * args , ** kwargs ) -> List [ int ]: \"\"\"Generates all possible birthdays for a given number of people sampled from a uniform distribution. Example: If there are 3 people, the possible birthdays can be understood to be sampled from a uniform distribution of 1 to 365 inclusive with replacement. >>> generate_k_birthdays(3, 365) Args: num_people (int): The number of people in the group. num_possible_birthdays (int, optional): Number of possible birthdays. Defaults to 365. Returns: birthdays (List[int]): A list of birthdays. \"\"\" birthdays = [ generate_one_random_birthday ( * args , ** kwargs ) for _ in range ( num_people ) ] return birthdays def calculate_same_birthday_probability ( num_simulations : int , * args , ** kwargs ) -> float : \"\"\"Calculates the probability of the Birthday Paradox Problem. Args: num_simulations (int, optional): The number of simulations to run. Returns: probability (float): The probability of the Birthday Paradox. \"\"\" count = 0 for _ in range ( num_simulations ): birthdays = generate_k_birthdays ( * args , ** kwargs ) if containsDuplicate ( birthdays ): count += 1 probability = count / num_simulations return probability calculate_same_birthday_probability ( num_simulations = 10000 , num_people = 50 , num_possible_birthdays = 365 ) 0.97 We go through one loop of the simulation to understand the code: birthdays = default_rng().choice(a=num_possible_birthdays, size=num_people, replace=True) : what this does is two folds, Samples 1 integer from 1 to 365 from a uniform distribution. (i.e. 1 to num_possible_birthdays) Repeat the sampling of 1 integer 50 times. (i.e. num_people=50) In short, it returns an array of 50 elements, each element is sampled uniformly from 1 to 365 inclusive. if has_duplicates(birthdays) checks whether the array has duplicates (i.e. akin to checking if 2 or more people has the same birthdays). If True , count +=1 . Finally, the probability is the number of count divided by the total number of simulations. It should converge to around \\(0.97\\) . One should realize by now probability in most parts, is just the frequency of \"occurring\" over the total number of \"events\". def calculate_same_birthday_probability_rng_choice ( num_simulations : int , num_people : int = 50 , num_possible_birthdays : int = 365 , replace : bool = True , ) -> float : \"\"\"Calculates the probability of the Birthday Paradox Problem. Args: num_simulations (int, optional): The number of simulations to run. num_people (int, optional): The number of people in the simulation. num_possible_birthdays (int, optional): The number of possible birthdays. replace (bool, optional): Whether or not to sample with replacement. Returns: probability (float): The probability of the Birthday Paradox. \"\"\" count = 0 for _ in range ( num_simulations ): birthdays = default_rng () . choice ( a = num_possible_birthdays , size = num_people , replace = True ) if containsDuplicate ( birthdays ): count += 1 probability = count / num_simulations return probability calculate_same_birthday_probability_rng_choice ( num_simulations = 10000 , num_people = 50 , num_possible_birthdays = 365 , replace = True ) 0.9714 The below code is not mine and is taken from here . For my reference to see if I coded correctly. from random import randint import matplotlib.pyplot as plt import seaborn as sns MIN_NUM_PEOPLE = 2 MAX_NUM_PEOPLE = 60 NUM_POSSIBLE_BIRTHDAYS = 365 NUM_TRIALS = 10000 def generate_random_birthday (): birthday = randint ( 1 , NUM_POSSIBLE_BIRTHDAYS ) return birthday def generate_k_birthdays ( k ): birthdays = [ generate_random_birthday () for _ in range ( k )] return birthdays def aloc ( birthdays ): unique_birthdays = set ( birthdays ) num_birthdays = len ( birthdays ) num_unique_birthdays = len ( unique_birthdays ) has_coincidence = ( num_birthdays != num_unique_birthdays ) return has_coincidence def estimate_p_aloc ( k ): num_aloc = 0 for _ in range ( NUM_TRIALS ): birthdays = generate_k_birthdays ( k ) has_coincidence = aloc ( birthdays ) if has_coincidence : num_aloc += 1 p_aloc = num_aloc / NUM_TRIALS return p_aloc def estimate_p_aloc_for_range ( ks ): k_probabilities = [] for k in ks : p_aloc = estimate_p_aloc ( k ) k_probabilities . append ( p_aloc ) return k_probabilities ks = range ( MIN_NUM_PEOPLE , MAX_NUM_PEOPLE + 1 ) k_probabilities = estimate_p_aloc_for_range ( ks ) fig , ax = plt . subplots ( figsize = ( 10 , 10 ), dpi = 49 ) ax . set_facecolor ( '#518792' ) ax . xaxis . set_tick_params ( width = 5 , color = '#2d3233' ) ax . yaxis . set_tick_params ( width = 5 , color = '#2d3233' ) sns . lineplot ( x = ks , y = k_probabilities , color = '#2d3233' ) plt . xticks ( fontsize = 15 , color = '#2d3233' ) y_range = [ 0 , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 , 0.9 , 1 ] plt . yticks ( y_range , fontsize = 15 , color = '#2d3233' ) plt . grid () plt . xlim ([ 0 , 60 ]) plt . ylim ([ 0 , 1 ]) plt . xlabel ( 'Number of people' , fontsize = 30 , color = '#2d3233' ) plt . ylabel ( 'P(At Least One Coincidence)' , fontsize = 30 , color = '#2d3233' ) plt . show ()","title":"Question 10: Birthday Paradox"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/probability4datascience/#chapter-2-probability","text":"","title":"Chapter 2: Probability"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/01_preliminaries/01_permutations_and_combinations/","text":"\\[ \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathcal{F}} \\newcommand{\\S}{\\Omega} \\newcommand{\\C}{\\mathbf{C}} \\] Permutations and Combinations The Couting Principles To fill in by referring to Choo Yan Min's book on Counting Principles. The Multiplication Principle (MP) We start off with a simple example. Let us assume we have to choose lunch and dinner on an airplane. We were offered 2 choices in lunch menu and 3 choices in dinner menu which we denote \\(l_1, l_2\\) and \\(d_1, d_2, d_3\\) respectively. We claim that there are a total of \\(2 \\times 3 = 6\\) choices. We first convince ourselves this is true by enumerating manually: \\[ \\left|\\left\\{(l_1, d_1), (l_1, d_2), (l_1, d_3), (l_2, d_1), (l_2, d_2), (l_2, d_3)\\right\\}\\right| = 6 \\] Recall Multiplication is nothing but Addition , and \\(2 \\times 3\\) can be understood as \\(3 + 3\\) , where we can understood it as if we choose \\(l_1\\) and fix it as it is, how many choices can we have for dinner, the answer is 3 choices and therefore we have a total of \\(3 + 3\\) since we have 2 lunch choices, so we add twice. The same can be said if we see \\(2 \\times 3\\) as \\(2 + 2 + 2\\) , as we can fix dinner as \\(d_1\\) and ask, how many choices do we have now? The answer is 2, and we see that there are 3 dinner, so add them thrice. Why do you multiply probabilities? Also appear in Chapter 2 summary. Consider rolling a dice twice, what is the probability that you roll a 5 and 6 respectively. We all know the answer is \\(\\dfrac{1}{6} \\times \\dfrac{1}{6} = \\dfrac{1}{36}\\) . But why? This can be first understood that our denominator is the total outcomes in our sample space \\(\\S\\) . This is \\(36\\) , why? By our counting principle on multiplication, we know that if we have \\(6\\) choices in roll \\(1\\) and \\(6\\) choices in roll 2, then the cross-product is \\(6 \\times 6 = 36\\) total choices. One can enumerate \\(\\{(1,1), (1,2), \\ldots, (6,6)\\}\\) to see why. Now the numerator is also related to the counting principle of multiplication as well! In roll 1, rolling a 5 is 1 choice, rolling a 6 next is 1 choice, so total there is a only one combination choice \\(1 \\times 1\\) ! Now if we reframe the problem to what is the probability that you roll a 1, 2 or 3 in the first roll and 2 or 3 in the second roll. Then of course our denominator don't change as \\(36\\) , but our numerator changes, since in roll 1 we have 3 choices, and roll 2 have 2 choices, by the multiplicative principle we have a total of \\(3 \\times 2 = 6\\) choices, and so our probability is \\(\\dfrac{6}{36}\\) now. You can verify that there are indeed \\(6\\) choices manually. Now the most important part is we can use this if both events are independent! If not we need to be careful! .","title":"01 permutations and combinations"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/01_preliminaries/01_permutations_and_combinations/#permutations-and-combinations","text":"","title":"Permutations and Combinations"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/01_preliminaries/01_permutations_and_combinations/#the-couting-principles","text":"To fill in by referring to Choo Yan Min's book on Counting Principles.","title":"The Couting Principles"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/01_preliminaries/01_permutations_and_combinations/#the-multiplication-principle-mp","text":"We start off with a simple example. Let us assume we have to choose lunch and dinner on an airplane. We were offered 2 choices in lunch menu and 3 choices in dinner menu which we denote \\(l_1, l_2\\) and \\(d_1, d_2, d_3\\) respectively. We claim that there are a total of \\(2 \\times 3 = 6\\) choices. We first convince ourselves this is true by enumerating manually: \\[ \\left|\\left\\{(l_1, d_1), (l_1, d_2), (l_1, d_3), (l_2, d_1), (l_2, d_2), (l_2, d_3)\\right\\}\\right| = 6 \\] Recall Multiplication is nothing but Addition , and \\(2 \\times 3\\) can be understood as \\(3 + 3\\) , where we can understood it as if we choose \\(l_1\\) and fix it as it is, how many choices can we have for dinner, the answer is 3 choices and therefore we have a total of \\(3 + 3\\) since we have 2 lunch choices, so we add twice. The same can be said if we see \\(2 \\times 3\\) as \\(2 + 2 + 2\\) , as we can fix dinner as \\(d_1\\) and ask, how many choices do we have now? The answer is 2, and we see that there are 3 dinner, so add them thrice.","title":"The Multiplication Principle (MP)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/01_preliminaries/01_permutations_and_combinations/#why-do-you-multiply-probabilities","text":"Also appear in Chapter 2 summary. Consider rolling a dice twice, what is the probability that you roll a 5 and 6 respectively. We all know the answer is \\(\\dfrac{1}{6} \\times \\dfrac{1}{6} = \\dfrac{1}{36}\\) . But why? This can be first understood that our denominator is the total outcomes in our sample space \\(\\S\\) . This is \\(36\\) , why? By our counting principle on multiplication, we know that if we have \\(6\\) choices in roll \\(1\\) and \\(6\\) choices in roll 2, then the cross-product is \\(6 \\times 6 = 36\\) total choices. One can enumerate \\(\\{(1,1), (1,2), \\ldots, (6,6)\\}\\) to see why. Now the numerator is also related to the counting principle of multiplication as well! In roll 1, rolling a 5 is 1 choice, rolling a 6 next is 1 choice, so total there is a only one combination choice \\(1 \\times 1\\) ! Now if we reframe the problem to what is the probability that you roll a 1, 2 or 3 in the first roll and 2 or 3 in the second roll. Then of course our denominator don't change as \\(36\\) , but our numerator changes, since in roll 1 we have 3 choices, and roll 2 have 2 choices, by the multiplicative principle we have a total of \\(3 \\times 2 = 6\\) choices, and so our probability is \\(\\dfrac{6}{36}\\) now. You can verify that there are indeed \\(6\\) choices manually. Now the most important part is we can use this if both events are independent! If not we need to be careful! .","title":"Why do you multiply probabilities?"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.01_probability_space/","text":"\\[ \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathcal{F}} \\newcommand{\\S}{\\Omega} \\newcommand{\\C}{\\mathbf{C}}\\] Probability Space Definition (Sample Space \\(\\mathbf{\\Omega}\\) ) Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 59) Definition (Event space \\(\\mathcal{F}\\) ) Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 61) Definition (Events \\(E\\) ) Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 61) Definition (Probability Law and Function \\(\\mathbb{P}\\) ) Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 66) Definition (Probability Law is a Measure) The notion of measure is important for us to understand. Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 68) Definition (Measure Zero Sets) This definition here will be more obvious when we visit continuous distributions where it does not make sense to ask the question of the probability of a single point as it will always be zero. Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 71) Definition (Probability Space) Real-world scenarios often involve chance. We can model such scenarios mathematically. For this purpose, we'll use a mathematical object named the experiment \\(\\textbf{EXP}\\) (probability space), typically denoted as an ordered triplet: \\[\\text{Experiment} = (\\S, \\E, \\P)\\] defined as such: Sample Space \\(\\S\\) : This is simply the set of all possible outcomes. And an outcome is defined as a result of an experiment. Event Space \\(\\E\\) : This is the collection of all possible events. An event \\(E\\) is simply any set of possible outcomes, which means that an event is a subset of the sample space . In turn, the event space \\(\\F\\) is simply the set of all events. Probability Function \\(\\P\\) : A mapping function from an event \\(E\\) to a number \\(\\P(E)\\) which ideally measures the size of the event; usually, \\(\\P\\) simply assigns to each event some probability between \\(0\\) and \\(1\\) . This probability is interpreted as the likelihood of that particular event occurring. More readings here 1 . Example (Probability Space) Definition Example An Experiment is a scenario involving chance or probability Throwing a coin Outcome: Result of an experiment/Probability Space When you toss a coin, only outcomes are Heads (H) or Tails (T) Sample Space: Set of all possible outcomes \\(\\S = \\{\\text{Heads, Tails}\\}\\) Event Space: Set of all possible events \\(\\E = \\{\\emptyset, \\{\\text{Heads}\\}, \\{\\text{Tails}\\}, \\{\\text{Heads, Tails}\\}\\}\\) Events: Subset of the Sample Space An event A can be getting a heads = \\(\\{\\text{Heads}\\}\\) Probability Function: \\(\\P: \\E \\to \\R\\) assigns to each event a \\(\\textbf{probability}\\) which is a number between 0 and 1 \\(\\P(\\{\\text{Heads}\\}) = \\frac{1}{2}\\) Probability (Important!): If the sample space \\(\\S\\) consists of a finite number of equally likely outcomes, the probability of an event \\(A\\) , denoted by \\(\\P(A)\\) , is given by: \\[ \\P(A) = \\dfrac{n(A)}{n(\\S)} \\] where \\(n(A)\\) denotes the number of outcomes in the event \\(A\\) . So if event \\(A\\) is the event where you pick a red ball, we consider \\(n(A)\\) to be 6. This will be more formally stated later, but for now, understand the probability function as a frequency counter. The Notion of Experiments and Defining the Probability Space Consider the following example: We have 10 balls, 6 red and 4 black. We also know that 3 of the red balls is round, and only 1 of the black balls is round. The rest of the balls which are not round are assumed to be square (may not be important here). So we were asked, what is the probability of picking one of the ball that is round, given that the ball is red? What is our sample space \\(\\S\\) , event space \\(\\F\\) ? The beginner in probability (me) might not immediately see what the experiment is, and therefore cannot construct the sample space \\(\\S\\) immediately. In this context, we can define our experiment to be the action of picking a ball from the \\(10\\) balls. Notice that we did not mention any adjectives on the ball - we did not specify if the ball is red, blue or round. This can be specified here, but can also be mentioned in the sample space later. Now to define the sample space \\(\\S\\) , it is necessarily for us to know what outcomes are there from the experiment ? Well, from the problem, we know that the balls we pick can be red, black, round or square (not round). So our naive construction can be: \\[ \\S = \\{\\text{red}, \\text{black}, \\text{round}, \\text{not round}\\} \\] but this soon does not make sense because this sample space does not obey the Probability Axioms (which we will go in depth in the next section) , a simple inspection tells us that if we add the probability of drawing a red and a black ball, it sums up to \\(1\\) , but when we also sum up the probability of drawing a round ball and non-round ball, the probability gives us \\(1\\) again, when you sum these outcomes it becomes \\(2\\) , violating the fact that the probability of observing all possible outcomes is \\(1\\) . Hence, we cannot have such a \\(\\S\\) . With some thought, we can define our sample space \\(\\S\\) to be a set of tuples, where each tuple is parametrized by the balls' color and shape . We now denote red and black to be r and b respectively, and round and not round to be c and d respectively. We thus have: \\[ \\S = \\{(r, c), (r, d), (b, c), (b, d)\\} \\] as our sample space. Then the rest should follow, just like the experiment of rolling 2 die. However, what's more provoking is that this is the only way to define our sample space \\(\\S\\) , which may be confusing. A well known user on mathstackexchange has the following reply. Sometimes probability is so much more confusing than the rest of the fields in math - intuition is totally not there for me, notwithstanding the fact that most textbooks go straight into the axioms and formulas, which make me only want to rote learn the subject. One major hurdle that I find myself stuck in at first was how to define a sample space, a event and subsequently an event space. The textbooks examples seem too simple and when further questions present themselves, one tends to be overwhelmed. One should know that given an experiment, the sample space is entirely up to you to define it, as long as it satisfies the below: In the sample space, the outcomes \\(s_1,s_2,...,s_n\\) must be \\textbf{mutually exclusive.} The outcomes must be collectively exhaustive The sample space must have the right granularity depending on what we are interested in. We must remove irrelevant information from the sample space. In other words, we must choose the right abstraction (forget some irrelevant information). It is entirely up to us so long as the events that we are interested in discussing the probabilities of are subsets of the sample space that we chose and each result of an experiment is described uniquely by exactly one of the outcomes in the sample space. But looking carefully at our experiment, it says we want to pick a ball that is in a sense, both red and round. So it is important that in our outcome, there should and must be one unique outcome that describes this. In my previous attempt of coming up with a sample space pertaining to this experiment, I claimed that \\[ \\S = \\{\\text{red}, \\text{black}, \\text{round}, \\text{not round}\\} \\] The problem is there is no unique outcome in the sample space that desribes my red and round ball . We can say that 2 of the outcomes (red) and (round) describes my red and round ball, but we need one unique outcome to describe this red and round ball. Hence we have to tweak a little. There are some suggestions, not compulsory , however when choosing a sample space. First is simplicity. For instance, in the trial of tossing a coin, we could have as a sample space \\[ \\S_1 = \\{H,T\\} \\] Another possible sample space that we can come up with could be \\[ \\S_2= \\{H\\&R,H\\&NR,T\\&R,T\\&NR\\} \\] Here, \\(R\\) stands for rains and \\(NR\\) not rains. Obviously, \\(\\S_1\\) is a better choice than \\(\\S_2\\) as we do not care about how the weather affects the tossing of a coin. Secondly, we also tend to prefer sample spaces in which the outcomes are equiprobable, that is, each outcome in the sample space being equally likely to occur. We like these choices of sample spaces since in such a scenario we can use counting techniques to calculate probabilities by taking the ratio of the size of the event compared to the size of the sample space, something which cannot be done in general. Finally, back to our specific problem, we may temporarily assume the balls are uniquely numbered ! Yes, the balls might not have been numbered in reality, but by temporarily assuming they were numbered you should be able to convince yourself that the probabilities of selecting a ball of a certain type would stay the same as if they weren't and this now allows us to describe the problem with an equiprobable sample space. Here, we can let the balls be numbered \\(1,2,3,\\dots,10\\) . The three red round balls being labeled \\(1,2,3\\) , the not round red balls being \\(4,5,6\\) , the black round ball being \\(7\\) , and the black not round balls being \\(8,9,10\\) . Our sample space then is \\[ \\S = \\{1,2,3,4,5,6,7,8,9,10\\} \\] And our event space is the set of all subsets of our sample space. \\[ \\Sigma = \\{\\emptyset, \\{1\\},\\{2\\},..,\\{10\\},\\{1,2\\},\\{1,3\\},..,\\{9,10\\},...,\\{1,2,3,...,10\\}\\} \\] and of course any element of the event space is considered an event. For example, let \\(A\\) be the event such that the ball is round, and correspondingly, \\(A = \\{1,2,3,7\\}\\) . Let \\(B\\) be the event such that the ball is red, and the correspondingly, \\(B = \\{1,2,3,4,5,6\\}\\) . Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 74) \u21a9","title":"Probability Space"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.01_probability_space/#probability-space","text":"","title":"Probability Space"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.01_probability_space/#definition-sample-space-mathbfomega","text":"Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 59)","title":"Definition (Sample Space \\(\\mathbf{\\Omega}\\))"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.01_probability_space/#definition-event-space-mathcalf","text":"Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 61)","title":"Definition (Event space \\(\\mathcal{F}\\))"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.01_probability_space/#definition-events-e","text":"Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 61)","title":"Definition (Events \\(E\\))"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.01_probability_space/#definition-probability-law-and-function-mathbbp","text":"Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 66)","title":"Definition (Probability Law and Function \\(\\mathbb{P}\\))"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.01_probability_space/#definition-probability-law-is-a-measure","text":"The notion of measure is important for us to understand. Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 68)","title":"Definition (Probability Law is a Measure)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.01_probability_space/#definition-measure-zero-sets","text":"This definition here will be more obvious when we visit continuous distributions where it does not make sense to ask the question of the probability of a single point as it will always be zero. Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 71)","title":"Definition (Measure Zero Sets)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.01_probability_space/#definition-probability-space","text":"Real-world scenarios often involve chance. We can model such scenarios mathematically. For this purpose, we'll use a mathematical object named the experiment \\(\\textbf{EXP}\\) (probability space), typically denoted as an ordered triplet: \\[\\text{Experiment} = (\\S, \\E, \\P)\\] defined as such: Sample Space \\(\\S\\) : This is simply the set of all possible outcomes. And an outcome is defined as a result of an experiment. Event Space \\(\\E\\) : This is the collection of all possible events. An event \\(E\\) is simply any set of possible outcomes, which means that an event is a subset of the sample space . In turn, the event space \\(\\F\\) is simply the set of all events. Probability Function \\(\\P\\) : A mapping function from an event \\(E\\) to a number \\(\\P(E)\\) which ideally measures the size of the event; usually, \\(\\P\\) simply assigns to each event some probability between \\(0\\) and \\(1\\) . This probability is interpreted as the likelihood of that particular event occurring. More readings here 1 .","title":"Definition (Probability Space)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.01_probability_space/#example-probability-space","text":"Definition Example An Experiment is a scenario involving chance or probability Throwing a coin Outcome: Result of an experiment/Probability Space When you toss a coin, only outcomes are Heads (H) or Tails (T) Sample Space: Set of all possible outcomes \\(\\S = \\{\\text{Heads, Tails}\\}\\) Event Space: Set of all possible events \\(\\E = \\{\\emptyset, \\{\\text{Heads}\\}, \\{\\text{Tails}\\}, \\{\\text{Heads, Tails}\\}\\}\\) Events: Subset of the Sample Space An event A can be getting a heads = \\(\\{\\text{Heads}\\}\\) Probability Function: \\(\\P: \\E \\to \\R\\) assigns to each event a \\(\\textbf{probability}\\) which is a number between 0 and 1 \\(\\P(\\{\\text{Heads}\\}) = \\frac{1}{2}\\) Probability (Important!): If the sample space \\(\\S\\) consists of a finite number of equally likely outcomes, the probability of an event \\(A\\) , denoted by \\(\\P(A)\\) , is given by: \\[ \\P(A) = \\dfrac{n(A)}{n(\\S)} \\] where \\(n(A)\\) denotes the number of outcomes in the event \\(A\\) . So if event \\(A\\) is the event where you pick a red ball, we consider \\(n(A)\\) to be 6. This will be more formally stated later, but for now, understand the probability function as a frequency counter.","title":"Example (Probability Space)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.01_probability_space/#the-notion-of-experiments-and-defining-the-probability-space","text":"Consider the following example: We have 10 balls, 6 red and 4 black. We also know that 3 of the red balls is round, and only 1 of the black balls is round. The rest of the balls which are not round are assumed to be square (may not be important here). So we were asked, what is the probability of picking one of the ball that is round, given that the ball is red? What is our sample space \\(\\S\\) , event space \\(\\F\\) ? The beginner in probability (me) might not immediately see what the experiment is, and therefore cannot construct the sample space \\(\\S\\) immediately. In this context, we can define our experiment to be the action of picking a ball from the \\(10\\) balls. Notice that we did not mention any adjectives on the ball - we did not specify if the ball is red, blue or round. This can be specified here, but can also be mentioned in the sample space later. Now to define the sample space \\(\\S\\) , it is necessarily for us to know what outcomes are there from the experiment ? Well, from the problem, we know that the balls we pick can be red, black, round or square (not round). So our naive construction can be: \\[ \\S = \\{\\text{red}, \\text{black}, \\text{round}, \\text{not round}\\} \\] but this soon does not make sense because this sample space does not obey the Probability Axioms (which we will go in depth in the next section) , a simple inspection tells us that if we add the probability of drawing a red and a black ball, it sums up to \\(1\\) , but when we also sum up the probability of drawing a round ball and non-round ball, the probability gives us \\(1\\) again, when you sum these outcomes it becomes \\(2\\) , violating the fact that the probability of observing all possible outcomes is \\(1\\) . Hence, we cannot have such a \\(\\S\\) . With some thought, we can define our sample space \\(\\S\\) to be a set of tuples, where each tuple is parametrized by the balls' color and shape . We now denote red and black to be r and b respectively, and round and not round to be c and d respectively. We thus have: \\[ \\S = \\{(r, c), (r, d), (b, c), (b, d)\\} \\] as our sample space. Then the rest should follow, just like the experiment of rolling 2 die. However, what's more provoking is that this is the only way to define our sample space \\(\\S\\) , which may be confusing. A well known user on mathstackexchange has the following reply. Sometimes probability is so much more confusing than the rest of the fields in math - intuition is totally not there for me, notwithstanding the fact that most textbooks go straight into the axioms and formulas, which make me only want to rote learn the subject. One major hurdle that I find myself stuck in at first was how to define a sample space, a event and subsequently an event space. The textbooks examples seem too simple and when further questions present themselves, one tends to be overwhelmed. One should know that given an experiment, the sample space is entirely up to you to define it, as long as it satisfies the below: In the sample space, the outcomes \\(s_1,s_2,...,s_n\\) must be \\textbf{mutually exclusive.} The outcomes must be collectively exhaustive The sample space must have the right granularity depending on what we are interested in. We must remove irrelevant information from the sample space. In other words, we must choose the right abstraction (forget some irrelevant information). It is entirely up to us so long as the events that we are interested in discussing the probabilities of are subsets of the sample space that we chose and each result of an experiment is described uniquely by exactly one of the outcomes in the sample space. But looking carefully at our experiment, it says we want to pick a ball that is in a sense, both red and round. So it is important that in our outcome, there should and must be one unique outcome that describes this. In my previous attempt of coming up with a sample space pertaining to this experiment, I claimed that \\[ \\S = \\{\\text{red}, \\text{black}, \\text{round}, \\text{not round}\\} \\] The problem is there is no unique outcome in the sample space that desribes my red and round ball . We can say that 2 of the outcomes (red) and (round) describes my red and round ball, but we need one unique outcome to describe this red and round ball. Hence we have to tweak a little. There are some suggestions, not compulsory , however when choosing a sample space. First is simplicity. For instance, in the trial of tossing a coin, we could have as a sample space \\[ \\S_1 = \\{H,T\\} \\] Another possible sample space that we can come up with could be \\[ \\S_2= \\{H\\&R,H\\&NR,T\\&R,T\\&NR\\} \\] Here, \\(R\\) stands for rains and \\(NR\\) not rains. Obviously, \\(\\S_1\\) is a better choice than \\(\\S_2\\) as we do not care about how the weather affects the tossing of a coin. Secondly, we also tend to prefer sample spaces in which the outcomes are equiprobable, that is, each outcome in the sample space being equally likely to occur. We like these choices of sample spaces since in such a scenario we can use counting techniques to calculate probabilities by taking the ratio of the size of the event compared to the size of the sample space, something which cannot be done in general. Finally, back to our specific problem, we may temporarily assume the balls are uniquely numbered ! Yes, the balls might not have been numbered in reality, but by temporarily assuming they were numbered you should be able to convince yourself that the probabilities of selecting a ball of a certain type would stay the same as if they weren't and this now allows us to describe the problem with an equiprobable sample space. Here, we can let the balls be numbered \\(1,2,3,\\dots,10\\) . The three red round balls being labeled \\(1,2,3\\) , the not round red balls being \\(4,5,6\\) , the black round ball being \\(7\\) , and the black not round balls being \\(8,9,10\\) . Our sample space then is \\[ \\S = \\{1,2,3,4,5,6,7,8,9,10\\} \\] And our event space is the set of all subsets of our sample space. \\[ \\Sigma = \\{\\emptyset, \\{1\\},\\{2\\},..,\\{10\\},\\{1,2\\},\\{1,3\\},..,\\{9,10\\},...,\\{1,2,3,...,10\\}\\} \\] and of course any element of the event space is considered an event. For example, let \\(A\\) be the event such that the ball is round, and correspondingly, \\(A = \\{1,2,3,7\\}\\) . Let \\(B\\) be the event such that the ball is red, and the correspondingly, \\(B = \\{1,2,3,4,5,6\\}\\) . Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 74) \u21a9","title":"The Notion of Experiments and Defining the Probability Space"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.02_probability_axioms/","text":"\\[ \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathcal{F}} \\newcommand{\\S}{\\Omega} \\newcommand{\\C}{\\mathbf{C}}\\] Probability Axioms Definition (The Three Axioms of Probability (Kolmogorov Axioms)) A probability function \\(\\P\\) must satisfy the three axioms below. Recall that the probability function in a well defined experiment is a function \\(\\P: \\E \\to [0, 1]\\) . Informally, for any event \\(A\\) , \\(\\P(A)\\) is defined as the probability of event \\(A\\) happening. This function must satisfy the following: First axiom (Non - Negativity Axiom): \\(\\P(A) \\geq 0\\) for any event \\(A \\subseteq \\S\\) . Second Axiom (Normalization Axiom): \\(\\sum_{i=1}^{n}\\P(A_i) = 1\\) where \\(A_i\\) are all possible outcomes for \\(i = 1, 2,..., n\\) . Third Axiom (Additivity Axiom): Given a countable sequence of disjoint events \\(A_1, A_2, ..., A_n,... \\subset \\S\\) , we have \\[ \\P\\left(\\bigsqcup_{i=1}^{\\infty} A_i \\right) = \\sum_{i=1}^{\\infty}\\P[A_i] \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 74) Corollary (Implications of the Probability Axioms) Probability of Empty Set: \\(\\P(\\emptyset) = 0\\) Complements: \\(\\P(A) = 1 - \\P(A^{c})\\) Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 77) Corollary (Inclusion-Exclusion - Unions of Two Non-Disjoint Sets) \\[ \\P(A \\cup B) = \\P(A) + \\P(B) - \\P(A \\cap B) \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 78) Corollary (Inequality Bounds) Union Bound: \\(\\P(A \\cup B) \\leq \\P(A) + P(B)\\) Monotonicity: If \\(A \\subset B\\) , then \\(\\P(A) \\leq \\P(B)\\) Numeric Bound: It immediately follows that for any event \\(A\\) , \\(\\P(A) \\leq 1\\) by Monotonicity and Axiom 2. Because an event \\(A\\) can at most be summed to 1, so any events must be a subset of its summation, so the probability of the summation is 1, hence \\(\\P(A) \\leq 1\\) by Monotonicity. Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 79) Definition (Mutually Exclusive Events) In logic and probability theory, two events (or propositions) are mutually exclusive or disjoint if they cannot both occur at the same time. A clear example is the set of outcomes of a single coin toss, which can result in either heads or tails, but not both. To be concise, let the event of coin landing on head be \\(A\\) , the event of coin landing on tails be \\(B\\) , event \\(A\\) and \\(B\\) can never occur at the same time, it is the case that one cannot be true if the other one is true, or at least one of them cannot be true. One can draw a venn diagram with event \\(A\\) and \\(B\\) being disjoint to illustrate the idea. Also, by Unions of Two Non-Disjoint Sets , it is easy to see that \\(\\P(A \\cup B) = \\P(A) + \\P(B)\\) since \\(\\P(A \\cap B) = 0\\) . For the coin toss example, since \\(A \\cup B\\) spans the entire sample space, it is intuitive that \\(P(A \\cup B)\\) (the probability of throwing a head OR a tail) is 1.","title":"Probability Axioms"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.02_probability_axioms/#probability-axioms","text":"","title":"Probability Axioms"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.02_probability_axioms/#definition-the-three-axioms-of-probability-kolmogorov-axioms","text":"A probability function \\(\\P\\) must satisfy the three axioms below. Recall that the probability function in a well defined experiment is a function \\(\\P: \\E \\to [0, 1]\\) . Informally, for any event \\(A\\) , \\(\\P(A)\\) is defined as the probability of event \\(A\\) happening. This function must satisfy the following: First axiom (Non - Negativity Axiom): \\(\\P(A) \\geq 0\\) for any event \\(A \\subseteq \\S\\) . Second Axiom (Normalization Axiom): \\(\\sum_{i=1}^{n}\\P(A_i) = 1\\) where \\(A_i\\) are all possible outcomes for \\(i = 1, 2,..., n\\) . Third Axiom (Additivity Axiom): Given a countable sequence of disjoint events \\(A_1, A_2, ..., A_n,... \\subset \\S\\) , we have \\[ \\P\\left(\\bigsqcup_{i=1}^{\\infty} A_i \\right) = \\sum_{i=1}^{\\infty}\\P[A_i] \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 74)","title":"Definition (The Three Axioms of Probability (Kolmogorov Axioms))"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.02_probability_axioms/#corollary-implications-of-the-probability-axioms","text":"Probability of Empty Set: \\(\\P(\\emptyset) = 0\\) Complements: \\(\\P(A) = 1 - \\P(A^{c})\\) Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 77)","title":"Corollary (Implications of the Probability Axioms)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.02_probability_axioms/#corollary-inclusion-exclusion-unions-of-two-non-disjoint-sets","text":"\\[ \\P(A \\cup B) = \\P(A) + \\P(B) - \\P(A \\cap B) \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 78)","title":"Corollary (Inclusion-Exclusion - Unions of Two Non-Disjoint Sets)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.02_probability_axioms/#corollary-inequality-bounds","text":"Union Bound: \\(\\P(A \\cup B) \\leq \\P(A) + P(B)\\) Monotonicity: If \\(A \\subset B\\) , then \\(\\P(A) \\leq \\P(B)\\) Numeric Bound: It immediately follows that for any event \\(A\\) , \\(\\P(A) \\leq 1\\) by Monotonicity and Axiom 2. Because an event \\(A\\) can at most be summed to 1, so any events must be a subset of its summation, so the probability of the summation is 1, hence \\(\\P(A) \\leq 1\\) by Monotonicity. Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 79)","title":"Corollary (Inequality Bounds)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.02_probability_axioms/#definition-mutually-exclusive-events","text":"In logic and probability theory, two events (or propositions) are mutually exclusive or disjoint if they cannot both occur at the same time. A clear example is the set of outcomes of a single coin toss, which can result in either heads or tails, but not both. To be concise, let the event of coin landing on head be \\(A\\) , the event of coin landing on tails be \\(B\\) , event \\(A\\) and \\(B\\) can never occur at the same time, it is the case that one cannot be true if the other one is true, or at least one of them cannot be true. One can draw a venn diagram with event \\(A\\) and \\(B\\) being disjoint to illustrate the idea. Also, by Unions of Two Non-Disjoint Sets , it is easy to see that \\(\\P(A \\cup B) = \\P(A) + \\P(B)\\) since \\(\\P(A \\cap B) = 0\\) . For the coin toss example, since \\(A \\cup B\\) spans the entire sample space, it is intuitive that \\(P(A \\cup B)\\) (the probability of throwing a head OR a tail) is 1.","title":"Definition (Mutually Exclusive Events)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.03_conditional_probability/","text":"\\[ \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathcal{F}} \\newcommand{\\S}{\\Omega} \\newcommand{\\C}{\\mathbf{C}}\\] Conditional Probability Definition (Conditional Probability) Let \\(\\P\\) be a probability function and \\(A, B \\in \\E\\) be events. Then the conditional probability of \\(A\\) given that event \\(B\\) has occurred is denoted \\[ \\P(A|B) \\] and is defined by \\[ \\P(A|B) = \\dfrac{\\P(A\\cap B)}{\\P(B)} \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 81-84) Intuition (Conditional Probability) The intuition of the conditional probability might not be immediate for those not inclined in statistical ideas. We will follow this link illustrate the intuition 1 . Informally, the below figure 1 gives you an idea: the shaded area belong to both \\(A\\) and \\(B\\) , So given \\(B\\) has happened, what then, is the probability of event \\(A\\) occurring? In particular, in the sample space \\(B\\) now, there is only a portion of \\(A\\) there, and one sees that portion is \\(P(A \\cap B) = P(A)\\) . A good intuition is given that \\(B\\) occurred\u2014with or without \\(A\\) \u2014what is the probability of \\(A\\) ? I.e, we are now in the universe in which \\(B\\) occurred - which is the full right circle. In that circle, the probability of A is the area of A intersect B divided by the area of the circle - or in other words, the number of outcomes of \\(A\\) in the right circle (which is \\(n(A \\cap B)\\) , over the number of outcomes of the reduced sample space \\(B\\) . Fig 1 Therefore, after the intuition, one should not be constantly checking what the formula represents, if we have \\(\\P(A ~|~ B)\\) , then it just means given \\(B\\) has happened, what is the probability of \\(A\\) happening? The logic becomes apparent when we reduce the whole sample space \\(\\S\\) to be only \\(B\\) now, and that whatever \\(A\\) overlaps with \\(B\\) will be the probability of this conditional. Proposition (Conditional Probability) If \\(\\P(A) < \\P(B)\\) , then \\(\\P(A|B) < \\P(B|A)\\) If \\(\\P(A) > \\P(B)\\) , then \\(\\P(A|B) > \\P(B|A)\\) If \\(\\P(A) = \\P(B)\\) , then \\(\\P(A|B) = \\P(B|A)\\) https://stats.stackexchange.com/questions/326253/what-is-the-intuition-behind-the-formula-for-conditional-probability \u21a9","title":"Conditional Probability"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.03_conditional_probability/#conditional-probability","text":"","title":"Conditional Probability"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.03_conditional_probability/#definition-conditional-probability","text":"Let \\(\\P\\) be a probability function and \\(A, B \\in \\E\\) be events. Then the conditional probability of \\(A\\) given that event \\(B\\) has occurred is denoted \\[ \\P(A|B) \\] and is defined by \\[ \\P(A|B) = \\dfrac{\\P(A\\cap B)}{\\P(B)} \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 81-84)","title":"Definition (Conditional Probability)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.03_conditional_probability/#intuition-conditional-probability","text":"The intuition of the conditional probability might not be immediate for those not inclined in statistical ideas. We will follow this link illustrate the intuition 1 . Informally, the below figure 1 gives you an idea: the shaded area belong to both \\(A\\) and \\(B\\) , So given \\(B\\) has happened, what then, is the probability of event \\(A\\) occurring? In particular, in the sample space \\(B\\) now, there is only a portion of \\(A\\) there, and one sees that portion is \\(P(A \\cap B) = P(A)\\) . A good intuition is given that \\(B\\) occurred\u2014with or without \\(A\\) \u2014what is the probability of \\(A\\) ? I.e, we are now in the universe in which \\(B\\) occurred - which is the full right circle. In that circle, the probability of A is the area of A intersect B divided by the area of the circle - or in other words, the number of outcomes of \\(A\\) in the right circle (which is \\(n(A \\cap B)\\) , over the number of outcomes of the reduced sample space \\(B\\) . Fig 1 Therefore, after the intuition, one should not be constantly checking what the formula represents, if we have \\(\\P(A ~|~ B)\\) , then it just means given \\(B\\) has happened, what is the probability of \\(A\\) happening? The logic becomes apparent when we reduce the whole sample space \\(\\S\\) to be only \\(B\\) now, and that whatever \\(A\\) overlaps with \\(B\\) will be the probability of this conditional.","title":"Intuition (Conditional Probability)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.03_conditional_probability/#proposition-conditional-probability","text":"If \\(\\P(A) < \\P(B)\\) , then \\(\\P(A|B) < \\P(B|A)\\) If \\(\\P(A) > \\P(B)\\) , then \\(\\P(A|B) > \\P(B|A)\\) If \\(\\P(A) = \\P(B)\\) , then \\(\\P(A|B) = \\P(B|A)\\) https://stats.stackexchange.com/questions/326253/what-is-the-intuition-behind-the-formula-for-conditional-probability \u21a9","title":"Proposition (Conditional Probability)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.04_independence/","text":"\\[ \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathcal{F}} \\newcommand{\\S}{\\Omega} \\newcommand{\\C}{\\mathbf{C}}\\] Independence Definition (Independent Events) Two events \\(A, B \\in \\E\\) are statiscally independent if \\[ \\P(A \\cap B) = \\P(A)P(B) \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 85) Intuition (Independence) 1 2 The formula above is not at all intuitive. A more intuitive way to think about it is to think that two events \\(A\\) and \\(B\\) are independent if the occurrence of \\(B\\) does not affect the probability of the occurrence of \\(A\\) . This can be illustrated further with the following narrative. Let us assume the scenario: given that \\(B\\) occurred (with or without event \\(A\\) occurring), what is the probability of event \\(A\\) occurring? In other words, we are now in the universe in which \\(B\\) occurred - which is the full right circle. In that right hand side circle ( \\(B\\) ), the probability of \\(A\\) is the area of \\(A\\) intersect \\(B\\) divided by the area of the circle - or in other words, the probability of \\(A\\) is the number of outcomes of \\(A\\) in the right circle (which is \\(n(A \\cap B)\\) , over the number of outcomes of the reduced sample space \\(B\\) . Therefore, if we think of independence as event \\(B\\) occuring not affecting event \\(A\\) occurring, then it means that the probability of \\(A\\) occurring is still the probability of \\(A\\) occurring. i.e \\(\\P(A|B) = \\P(A)\\) It follows immediately that \\( \\(P(A) = P(A|B) = \\dfrac{P(A \\cap B)}{P(B)} \\Longrightarrow P(A) P(B) = P(A \\cap B)\\) \\) Fig 1 So the intuition can be understood by using conditional, say \\(\\P(A ~|~ B)\\) , if \\(A\\) and \\(B\\) are truly independent, then even if \\(B\\) happened, the probability of \\(A\\) should remain unchanged, which means that \\(\\P(A ~|~ B) = \\P(A)\\) , but also recall the definition of conditionals, \\(\\P(A ~|~ B) = \\dfrac{\\P(A \\cap B)}{B}\\) , so equating them we have the nice equation of \\(\\P(A)\\P(B) = \\P(A \\cap B)\\) . Definition (Equivalent Independence Definition) We have stated this in the previous intuition section. Now we formally state it: Let \\(A\\) nad \\(B\\) be two events such that \\(\\P(A)\\) and \\(\\P(B)\\) are more than \\(0\\) , then \\(A\\) and \\(B\\) are independent if \\[ \\P(A|B) = \\P(A) \\quad \\P(B|A) = \\P(B) \\] Definition (Disjoint vs Independence) Given two events \\(A\\) and \\(B\\) . The only condition when \\(\\textbf{Disjoint} \\iff \\textbf{Independence}\\) if that if \\(\\P(A) = 0\\) or \\(\\P(B) = 0\\) . Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 86-87) Exercise (Independence) 3 Consider the experiment of throwing a die twice. One should be clear from the context that the outcomes are in the form of a tuple \\((\\textbf{dice_1}, \\textbf{dice_2})\\) and the sample space is: \\[ \\S = \\left\\{(1, 1), (1, 2), \\ldots, (6, 6)\\right\\} \\] Define the three events below: \\[ A = \\{\\textbf{1st dice is 3}\\} \\quad B = \\{\\textbf{sum of two die is 7}\\} \\quad C = \\{\\textbf{sum of two die is 8}\\} \\] We want to find out if events \\(A\\) and \\(B\\) are independent? How about \\(A\\) and \\(C\\) ? We focus on the independence of \\(A\\) and \\(C\\) first. The author said that intuitively, given that event \\(C\\) has happened, will this affect the probability of \\(A\\) happening? I assume that this means we do have to know the probability of event \\(A\\) without \\(C\\) first. We can enumerate and see that event \\(A\\) has the following set representation: \\[ A = \\{(3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6)\\} \\] which amounts to \\(\\P(A) = \\frac{6}{36} = \\frac{1}{6}\\) . Now if \\(C\\) happened, we know that the two rolls have a sum of \\(8\\) , and we cannot construct a sum of \\(8\\) with a roll of \\(1\\) . To me, I immediately know that event \\(A\\) cannot have the outcome that has a \\(1\\) in the second roll, and thus the outcomes should only be limited to \\(5\\) instead of \\(6\\) and hence dependence is established. I believe somewhere my intuition is flawed, the author mentioned that: If you like a more intuitive argument, you can imagine that C has happened, i.e., the sum is 8. Then the probability for the first die to be 1 is 0 because there is no way to construct 8 when the first die is 1. As a result, we have eliminated one choice for the first die, leaving only five options. Therefore, since C has influenced the probability of A, they are dependent. I think I cannot understand why the author mentioned about \"first die\" when in event \\(A\\) , the first die is already a \\(3\\) . One can find more explanation here 4 and here 5 . The definition of independence is not intuitive \u21a9 Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 85-88) \u21a9 Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 87-88) \u21a9 Intuition on independence of two events \u21a9 Dartboard paradox and understanding independence \u21a9","title":"Independence"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.04_independence/#independence","text":"","title":"Independence"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.04_independence/#definition-independent-events","text":"Two events \\(A, B \\in \\E\\) are statiscally independent if \\[ \\P(A \\cap B) = \\P(A)P(B) \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 85)","title":"Definition (Independent Events)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.04_independence/#intuition-independence-1-2","text":"The formula above is not at all intuitive. A more intuitive way to think about it is to think that two events \\(A\\) and \\(B\\) are independent if the occurrence of \\(B\\) does not affect the probability of the occurrence of \\(A\\) . This can be illustrated further with the following narrative. Let us assume the scenario: given that \\(B\\) occurred (with or without event \\(A\\) occurring), what is the probability of event \\(A\\) occurring? In other words, we are now in the universe in which \\(B\\) occurred - which is the full right circle. In that right hand side circle ( \\(B\\) ), the probability of \\(A\\) is the area of \\(A\\) intersect \\(B\\) divided by the area of the circle - or in other words, the probability of \\(A\\) is the number of outcomes of \\(A\\) in the right circle (which is \\(n(A \\cap B)\\) , over the number of outcomes of the reduced sample space \\(B\\) . Therefore, if we think of independence as event \\(B\\) occuring not affecting event \\(A\\) occurring, then it means that the probability of \\(A\\) occurring is still the probability of \\(A\\) occurring. i.e \\(\\P(A|B) = \\P(A)\\) It follows immediately that \\( \\(P(A) = P(A|B) = \\dfrac{P(A \\cap B)}{P(B)} \\Longrightarrow P(A) P(B) = P(A \\cap B)\\) \\) Fig 1 So the intuition can be understood by using conditional, say \\(\\P(A ~|~ B)\\) , if \\(A\\) and \\(B\\) are truly independent, then even if \\(B\\) happened, the probability of \\(A\\) should remain unchanged, which means that \\(\\P(A ~|~ B) = \\P(A)\\) , but also recall the definition of conditionals, \\(\\P(A ~|~ B) = \\dfrac{\\P(A \\cap B)}{B}\\) , so equating them we have the nice equation of \\(\\P(A)\\P(B) = \\P(A \\cap B)\\) .","title":"Intuition (Independence) 1 2"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.04_independence/#definition-equivalent-independence-definition","text":"We have stated this in the previous intuition section. Now we formally state it: Let \\(A\\) nad \\(B\\) be two events such that \\(\\P(A)\\) and \\(\\P(B)\\) are more than \\(0\\) , then \\(A\\) and \\(B\\) are independent if \\[ \\P(A|B) = \\P(A) \\quad \\P(B|A) = \\P(B) \\]","title":"Definition (Equivalent Independence Definition)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.04_independence/#definition-disjoint-vs-independence","text":"Given two events \\(A\\) and \\(B\\) . The only condition when \\(\\textbf{Disjoint} \\iff \\textbf{Independence}\\) if that if \\(\\P(A) = 0\\) or \\(\\P(B) = 0\\) . Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 86-87)","title":"Definition (Disjoint vs Independence)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.04_independence/#exercise-independence-3","text":"Consider the experiment of throwing a die twice. One should be clear from the context that the outcomes are in the form of a tuple \\((\\textbf{dice_1}, \\textbf{dice_2})\\) and the sample space is: \\[ \\S = \\left\\{(1, 1), (1, 2), \\ldots, (6, 6)\\right\\} \\] Define the three events below: \\[ A = \\{\\textbf{1st dice is 3}\\} \\quad B = \\{\\textbf{sum of two die is 7}\\} \\quad C = \\{\\textbf{sum of two die is 8}\\} \\] We want to find out if events \\(A\\) and \\(B\\) are independent? How about \\(A\\) and \\(C\\) ? We focus on the independence of \\(A\\) and \\(C\\) first. The author said that intuitively, given that event \\(C\\) has happened, will this affect the probability of \\(A\\) happening? I assume that this means we do have to know the probability of event \\(A\\) without \\(C\\) first. We can enumerate and see that event \\(A\\) has the following set representation: \\[ A = \\{(3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6)\\} \\] which amounts to \\(\\P(A) = \\frac{6}{36} = \\frac{1}{6}\\) . Now if \\(C\\) happened, we know that the two rolls have a sum of \\(8\\) , and we cannot construct a sum of \\(8\\) with a roll of \\(1\\) . To me, I immediately know that event \\(A\\) cannot have the outcome that has a \\(1\\) in the second roll, and thus the outcomes should only be limited to \\(5\\) instead of \\(6\\) and hence dependence is established. I believe somewhere my intuition is flawed, the author mentioned that: If you like a more intuitive argument, you can imagine that C has happened, i.e., the sum is 8. Then the probability for the first die to be 1 is 0 because there is no way to construct 8 when the first die is 1. As a result, we have eliminated one choice for the first die, leaving only five options. Therefore, since C has influenced the probability of A, they are dependent. I think I cannot understand why the author mentioned about \"first die\" when in event \\(A\\) , the first die is already a \\(3\\) . One can find more explanation here 4 and here 5 . The definition of independence is not intuitive \u21a9 Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 85-88) \u21a9 Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 87-88) \u21a9 Intuition on independence of two events \u21a9 Dartboard paradox and understanding independence \u21a9","title":"Exercise (Independence) 3"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.05_bayes_theorem/","text":"\\[ \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathcal{F}} \\newcommand{\\S}{\\Omega} \\newcommand{\\C}{\\mathbf{C}} \\] Baye's Theorem and the Law of Total Probability Definition (Conditional Probability) As a refresher, we re-state the definition of conditional probability here. Let \\(\\P\\) be a probability function and \\(A, B \\in \\E\\) be events. Then the conditional probability of \\(A\\) given that event \\(B\\) has occurred is denoted \\[ \\P(A|B) \\] and is defined by \\[ \\P(A|B) = \\dfrac{\\P(A\\cap B)}{\\P(B)} \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 81-84) Definition (Baye's Theorem) Two events \\(A, B \\in \\E\\) such that \\(\\P(A) > 0\\) and \\(\\P(B) > 0\\) , we have \\[ \\P(A|B) = \\dfrac{\\P(B|A)\\P(A)}{\\P(B)} \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 89) Intuition (Baye's Theorem) The observant reader should find it easy that this formula is deduced by abusing the fact that \\(\\P(A \\cap B) = \\P(B \\cap A)\\) , and therefore \\[ \\P(A|B) = \\dfrac{\\P(A\\cap B)}{\\P(B)} = \\dfrac{\\P(B \\cap A)}{\\P(B)} = \\dfrac{\\P(B ~|~ A)\\P(A)}{\\P(B)} \\] since \\(\\P(B ~|~ A) = \\dfrac{\\P(B \\cap A)}{\\P(A)}\\) . Terminology (Posterior and Conditional Probability) From the proof of Baye's Theorem , we see that there are two ways to view \\(\\P(A \\cap B)\\) . If the context is clear, we may call \\(\\P(B|A)\\) the conditional probability and \\(\\P(A|B)\\) the posterior probability . Theorem (Law of Total Probability) Let \\(\\{A_1, \\ldots, A_n\\}\\) be a partition of the sample space \\(\\S\\) . This means that \\(A_1, \\ldots, A_n\\) are disjoint and \\(\\S = A_1 \\cup \\cdots \\cup A_n\\) . Then, for any \\(B \\subseteq \\S\\) , we have \\[ \\P(B) = \\sum_{i=1}^{n} \\P(B|A_i)\\P(A_i) \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 89-90) Intuition and Interpretation (Law of Total Probability) The law of total probability can be stated more intuitively as the sum of event \\(B\\) and each of the disjoint event \\(A_i\\) . We have to first recognize that the image below makes sense, assumming that the whole sample space can be made up of 3 disjoint events \\(A_1, A_2, A_3\\) , and we see that event \\(B\\) touches all of them (i.e. there are overlaps), then it is obvious from the figure that \\(\\P(B)\\) is the sum of \\(\\P(B \\cap A_i)\\) . Note that event \\(B\\) does not necessarily need to touch all \\(A_i\\) , if it doesn't, then \\(\\P(B \\cap A_i) = 0\\) . Now if this intuition is established, we just express \\(\\P(B \\cap A_i) = \\P(B|A_i)\\P(A_i)\\) by conditional probability and we recovered back the formula for the law of total probability. Fig 1: Partition of Law of Total Probability The intuition of this is also apparent after understanding that if a sample space can be broken down into disjoint events \\(A_1, A_2, \\ldots, A_k\\) , then any event \\(B\\) that is in the sample space must touch some of these disjoint events, whenever they overlap, we can represent them as \\(\\P(A_i \\cap B)\\) , and if we add them up it is just the event \\(B\\) itself. If they don't overlap, we can still add them anyways since \\(P(A_k \\cap B) = 0\\) . Note the loose usage of the index here, \\(i\\) means overlap, \\(k\\) means non-overlap. Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 90) Corollary (Law of Total Probability) Let \\(\\{A_1, \\ldots, A_n\\}\\) be a partition of the sample space \\(\\S\\) . This means that \\(A_1, \\ldots, A_n\\) are disjoint and \\(\\S = A_1 \\cup \\cdots \\cup A_n\\) . Then, for any \\(B \\subseteq \\S\\) , we have \\[ \\P(A_j|B) = \\dfrac{\\P(B|A_j)\\P(A_j)}{\\sum_{i=1}^{n}\\P(B|A_i)\\P(A_i)} \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 90) Exercise 2.47 Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 90-91) Exercise 2.48 Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 91)","title":"Bayes Theorem"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.05_bayes_theorem/#bayes-theorem-and-the-law-of-total-probability","text":"","title":"Baye's Theorem and the Law of Total Probability"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.05_bayes_theorem/#definition-conditional-probability","text":"As a refresher, we re-state the definition of conditional probability here. Let \\(\\P\\) be a probability function and \\(A, B \\in \\E\\) be events. Then the conditional probability of \\(A\\) given that event \\(B\\) has occurred is denoted \\[ \\P(A|B) \\] and is defined by \\[ \\P(A|B) = \\dfrac{\\P(A\\cap B)}{\\P(B)} \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 81-84)","title":"Definition (Conditional Probability)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.05_bayes_theorem/#definition-bayes-theorem","text":"Two events \\(A, B \\in \\E\\) such that \\(\\P(A) > 0\\) and \\(\\P(B) > 0\\) , we have \\[ \\P(A|B) = \\dfrac{\\P(B|A)\\P(A)}{\\P(B)} \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 89)","title":"Definition (Baye's Theorem)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.05_bayes_theorem/#intuition-bayes-theorem","text":"The observant reader should find it easy that this formula is deduced by abusing the fact that \\(\\P(A \\cap B) = \\P(B \\cap A)\\) , and therefore \\[ \\P(A|B) = \\dfrac{\\P(A\\cap B)}{\\P(B)} = \\dfrac{\\P(B \\cap A)}{\\P(B)} = \\dfrac{\\P(B ~|~ A)\\P(A)}{\\P(B)} \\] since \\(\\P(B ~|~ A) = \\dfrac{\\P(B \\cap A)}{\\P(A)}\\) .","title":"Intuition (Baye's Theorem)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.05_bayes_theorem/#terminology-posterior-and-conditional-probability","text":"From the proof of Baye's Theorem , we see that there are two ways to view \\(\\P(A \\cap B)\\) . If the context is clear, we may call \\(\\P(B|A)\\) the conditional probability and \\(\\P(A|B)\\) the posterior probability .","title":"Terminology (Posterior and Conditional Probability)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.05_bayes_theorem/#theorem-law-of-total-probability","text":"Let \\(\\{A_1, \\ldots, A_n\\}\\) be a partition of the sample space \\(\\S\\) . This means that \\(A_1, \\ldots, A_n\\) are disjoint and \\(\\S = A_1 \\cup \\cdots \\cup A_n\\) . Then, for any \\(B \\subseteq \\S\\) , we have \\[ \\P(B) = \\sum_{i=1}^{n} \\P(B|A_i)\\P(A_i) \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 89-90)","title":"Theorem (Law of Total Probability)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.05_bayes_theorem/#intuition-and-interpretation-law-of-total-probability","text":"The law of total probability can be stated more intuitively as the sum of event \\(B\\) and each of the disjoint event \\(A_i\\) . We have to first recognize that the image below makes sense, assumming that the whole sample space can be made up of 3 disjoint events \\(A_1, A_2, A_3\\) , and we see that event \\(B\\) touches all of them (i.e. there are overlaps), then it is obvious from the figure that \\(\\P(B)\\) is the sum of \\(\\P(B \\cap A_i)\\) . Note that event \\(B\\) does not necessarily need to touch all \\(A_i\\) , if it doesn't, then \\(\\P(B \\cap A_i) = 0\\) . Now if this intuition is established, we just express \\(\\P(B \\cap A_i) = \\P(B|A_i)\\P(A_i)\\) by conditional probability and we recovered back the formula for the law of total probability. Fig 1: Partition of Law of Total Probability The intuition of this is also apparent after understanding that if a sample space can be broken down into disjoint events \\(A_1, A_2, \\ldots, A_k\\) , then any event \\(B\\) that is in the sample space must touch some of these disjoint events, whenever they overlap, we can represent them as \\(\\P(A_i \\cap B)\\) , and if we add them up it is just the event \\(B\\) itself. If they don't overlap, we can still add them anyways since \\(P(A_k \\cap B) = 0\\) . Note the loose usage of the index here, \\(i\\) means overlap, \\(k\\) means non-overlap. Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 90)","title":"Intuition and Interpretation (Law of Total Probability)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.05_bayes_theorem/#corollary-law-of-total-probability","text":"Let \\(\\{A_1, \\ldots, A_n\\}\\) be a partition of the sample space \\(\\S\\) . This means that \\(A_1, \\ldots, A_n\\) are disjoint and \\(\\S = A_1 \\cup \\cdots \\cup A_n\\) . Then, for any \\(B \\subseteq \\S\\) , we have \\[ \\P(A_j|B) = \\dfrac{\\P(B|A_j)\\P(A_j)}{\\sum_{i=1}^{n}\\P(B|A_i)\\P(A_i)} \\] Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 90)","title":"Corollary (Law of Total Probability)"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.05_bayes_theorem/#exercise-247","text":"Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 90-91)","title":"Exercise 2.47"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.05_bayes_theorem/#exercise-248","text":"Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 91)","title":"Exercise 2.48"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.06_summary/","text":"\\[ \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\v}{\\mathbf{v}} \\newcommand{\\a}{\\mathbf{a}} \\newcommand{\\b}{\\mathbf{b}} \\newcommand{\\c}{\\mathbf{c}} \\newcommand{\\w}{\\mathbf{w}} \\newcommand{\\u}{\\mathbf{u}} \\newcommand{\\x}{\\mathbf{x}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\z}{\\mathbf{z}} \\newcommand{\\0}{\\mathbf{0}} \\newcommand{\\1}{\\mathbf{1}} \\newcommand{\\A}{\\mathbf{A}} \\newcommand{\\B}{\\mathbf{B}} \\newcommand{\\rank}{\\textbf{rank}} \\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathcal{F}} \\newcommand{\\S}{\\Omega} \\newcommand{\\C}{\\mathbf{C}} \\] Summary For now it is mostly intuition in this section. Conditional Therefore, after the intuition, one should not be constantly checking what the formula represents, if we have \\(\\P(A ~|~ B)\\) , then it just means given \\(B\\) has happened, what is the probability of \\(A\\) happening? The logic becomes apparent when we reduce the whole sample space \\(\\S\\) to be only \\(B\\) now, and that whatever \\(A\\) overlaps with \\(B\\) will be the probability of this conditional. Independence So the intuition can be understood by using conditional, say \\(\\P(A ~|~ B)\\) , if \\(A\\) and \\(B\\) are truly independent, then even if \\(B\\) happened, the probability of \\(A\\) should remain unchanged, which means that \\(\\P(A ~|~ B) = \\P(A)\\) , but also recall the definition of conditionals, \\(\\P(A ~|~ B) = \\dfrac{\\P(A \\cap B)}{B}\\) , so equating them we have the nice equation of \\(\\P(A)\\P(B) = \\P(A \\cap B)\\) . Bayes' Theorem The observant reader should find it easy that this formula is deduced by abusing the fact that \\(\\P(A \\cap B) = \\P(B \\cap A)\\) , and therefore \\[ \\P(A|B) = \\dfrac{\\P(A\\cap B)}{\\P(B)} = \\dfrac{\\P(B \\cap A)}{\\P(B)} = \\dfrac{\\P(B ~|~ A)\\P(A)}{\\P(B)} \\] since \\(\\P(B ~|~ A) = \\dfrac{\\P(B \\cap A)}{\\P(A)}\\) . The Law of Total Probability The intuition of this is also apparent after understanding that if a sample space can be broken down into disjoint events \\(A_1, A_2, \\ldots, A_k\\) , then any event \\(B\\) that is in the sample space must touch some of these disjoint events, whenever they overlap, we can represent them as \\(\\P(A_i \\cap B)\\) , and if we add them up it is just the event \\(B\\) itself. If they don't overlap, we can still add them anyways since \\(P(A_k \\cap B) = 0\\) . Note the loose usage of the index here, \\(i\\) means overlap, \\(k\\) means non-overlap. Why do you multiply probabilities? Consider rolling a dice twice, what is the probability that you roll a 5 and 6 respectively. We all know the answer is \\(\\dfrac{1}{6} \\times \\dfrac{1}{6} = \\dfrac{1}{36}\\) . But why? This can be first understood that our denominator is the total outcomes in our sample space \\(\\S\\) . This is \\(36\\) , why? By our counting principle on multiplication, we know that if we have \\(6\\) choices in roll \\(1\\) and \\(6\\) choices in roll 2, then the cross-product is \\(6 \\times 6 = 36\\) total choices. One can enumerate \\(\\{(1,1), (1,2), \\ldots, (6,6)\\}\\) to see why. Now the numerator is also related to the counting principle of multiplication as well! In roll 1, rolling a 5 is 1 choice, rolling a 6 next is 1 choice, so total there is a only one combination choice \\(1 \\times 1\\) ! Now if we reframe the problem to what is the probability that you roll a 1, 2 or 3 in the first roll and 2 or 3 in the second roll. Then of course our denominator don't change as \\(36\\) , but our numerator changes, since in roll 1 we have 3 choices, and roll 2 have 2 choices, by the multiplicative principle we have a total of \\(3 \\times 2 = 6\\) choices, and so our probability is \\(\\dfrac{6}{36}\\) now. You can verify that there are indeed \\(6\\) choices manually. Now the most important part is we can use this if both events are independent! If not we need to be careful! . Conditional, Priori, Posterior Common terms in ML world. Suppose there are three types of players in a tennis tournament: A, B, and C. Fifty percent of the contestants in the tournament are A players, 25% are B players, and 25% are C players. Your chance of beating the contestants depends on the class of the player, as follows: 0.3 against an A player 0.4 against a B player 0.5 against a C player If you play a match in this tournament, what is the probability of your winning the match? Supposing that you have won a match, what is the probability that you played against an A player? Let \\(W\\) be the event that you win and \\(A\\) be the event that you played vs player \\(A\\) , then Conditional: \\(\\P(W~|~A)\\) = given you played player \\(A\\) , what is your probability of winning? Priori: \\(\\P(A)\\) = without entering the game , what is your probability of facing player \\(A\\) ? Posterior: \\(\\P(A~|~W)\\) = after entering the game and winning the match , what is your probability that you have actually played with \\(A\\) ? Machine Learning: In many practical engineering problems, the question of interest is often the last one. That is, supposing that you have observed something, what is the most likely cause of that event? For example, supposing we have observed this particular dataset, what is the best Gaussian model that would fit the dataset? Questions like these require some analysis of conditional probability, prior probability, and posterior probability.","title":"Summary"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.06_summary/#summary","text":"For now it is mostly intuition in this section.","title":"Summary"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.06_summary/#conditional","text":"Therefore, after the intuition, one should not be constantly checking what the formula represents, if we have \\(\\P(A ~|~ B)\\) , then it just means given \\(B\\) has happened, what is the probability of \\(A\\) happening? The logic becomes apparent when we reduce the whole sample space \\(\\S\\) to be only \\(B\\) now, and that whatever \\(A\\) overlaps with \\(B\\) will be the probability of this conditional.","title":"Conditional"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.06_summary/#independence","text":"So the intuition can be understood by using conditional, say \\(\\P(A ~|~ B)\\) , if \\(A\\) and \\(B\\) are truly independent, then even if \\(B\\) happened, the probability of \\(A\\) should remain unchanged, which means that \\(\\P(A ~|~ B) = \\P(A)\\) , but also recall the definition of conditionals, \\(\\P(A ~|~ B) = \\dfrac{\\P(A \\cap B)}{B}\\) , so equating them we have the nice equation of \\(\\P(A)\\P(B) = \\P(A \\cap B)\\) .","title":"Independence"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.06_summary/#bayes-theorem","text":"The observant reader should find it easy that this formula is deduced by abusing the fact that \\(\\P(A \\cap B) = \\P(B \\cap A)\\) , and therefore \\[ \\P(A|B) = \\dfrac{\\P(A\\cap B)}{\\P(B)} = \\dfrac{\\P(B \\cap A)}{\\P(B)} = \\dfrac{\\P(B ~|~ A)\\P(A)}{\\P(B)} \\] since \\(\\P(B ~|~ A) = \\dfrac{\\P(B \\cap A)}{\\P(A)}\\) .","title":"Bayes' Theorem"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.06_summary/#the-law-of-total-probability","text":"The intuition of this is also apparent after understanding that if a sample space can be broken down into disjoint events \\(A_1, A_2, \\ldots, A_k\\) , then any event \\(B\\) that is in the sample space must touch some of these disjoint events, whenever they overlap, we can represent them as \\(\\P(A_i \\cap B)\\) , and if we add them up it is just the event \\(B\\) itself. If they don't overlap, we can still add them anyways since \\(P(A_k \\cap B) = 0\\) . Note the loose usage of the index here, \\(i\\) means overlap, \\(k\\) means non-overlap.","title":"The Law of Total Probability"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.06_summary/#why-do-you-multiply-probabilities","text":"Consider rolling a dice twice, what is the probability that you roll a 5 and 6 respectively. We all know the answer is \\(\\dfrac{1}{6} \\times \\dfrac{1}{6} = \\dfrac{1}{36}\\) . But why? This can be first understood that our denominator is the total outcomes in our sample space \\(\\S\\) . This is \\(36\\) , why? By our counting principle on multiplication, we know that if we have \\(6\\) choices in roll \\(1\\) and \\(6\\) choices in roll 2, then the cross-product is \\(6 \\times 6 = 36\\) total choices. One can enumerate \\(\\{(1,1), (1,2), \\ldots, (6,6)\\}\\) to see why. Now the numerator is also related to the counting principle of multiplication as well! In roll 1, rolling a 5 is 1 choice, rolling a 6 next is 1 choice, so total there is a only one combination choice \\(1 \\times 1\\) ! Now if we reframe the problem to what is the probability that you roll a 1, 2 or 3 in the first roll and 2 or 3 in the second roll. Then of course our denominator don't change as \\(36\\) , but our numerator changes, since in roll 1 we have 3 choices, and roll 2 have 2 choices, by the multiplicative principle we have a total of \\(3 \\times 2 = 6\\) choices, and so our probability is \\(\\dfrac{6}{36}\\) now. You can verify that there are indeed \\(6\\) choices manually. Now the most important part is we can use this if both events are independent! If not we need to be careful! .","title":"Why do you multiply probabilities?"},{"location":"reighns_ml_journey/mathematics/probability_statistics_theory/02_introduction_to_probability/02.06_summary/#conditional-priori-posterior","text":"Common terms in ML world. Suppose there are three types of players in a tennis tournament: A, B, and C. Fifty percent of the contestants in the tournament are A players, 25% are B players, and 25% are C players. Your chance of beating the contestants depends on the class of the player, as follows: 0.3 against an A player 0.4 against a B player 0.5 against a C player If you play a match in this tournament, what is the probability of your winning the match? Supposing that you have won a match, what is the probability that you played against an A player? Let \\(W\\) be the event that you win and \\(A\\) be the event that you played vs player \\(A\\) , then Conditional: \\(\\P(W~|~A)\\) = given you played player \\(A\\) , what is your probability of winning? Priori: \\(\\P(A)\\) = without entering the game , what is your probability of facing player \\(A\\) ? Posterior: \\(\\P(A~|~W)\\) = after entering the game and winning the match , what is your probability that you have actually played with \\(A\\) ? Machine Learning: In many practical engineering problems, the question of interest is often the last one. That is, supposing that you have observed something, what is the most likely cause of that event? For example, supposing we have observed this particular dataset, what is the best Gaussian model that would fit the dataset? Questions like these require some analysis of conditional probability, prior probability, and posterior probability.","title":"Conditional, Priori, Posterior"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/","text":"\\[ \\newcommand{\\M}{\\mathcal{M}} \\newcommand{\\y}{\\mathbf{y}} \\newcommand{\\yhat}{\\mathbf{\\hat{y}}} \\newcommand{\\iou}{\\textbf{IOU}} \\] Data Collection and Label Original Dataset 500 images of size \\(4032 \\times 3024\\) provided by LTA: 150 positive class 1 where 1 means defective; 350 negative class 0 where 0 means non-defective; Class labels are subjected to changes depending on model used (i.e. F-RCNN treats background as 0 while Yolo does not care) There is some slight class imbalance: We checked if we can garner more data; We were given the green light; We collected about 1500 more photos. Labelling The total number of images is \\(2000\\) ; We need to label all of them as labels were not provided; Shortage of manpower prompted us to think of ways to reduce manual labour. Semi-Supervised Learning Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training. Semi-supervised learning falls between unsupervised learning (with no labeled training data) and supervised learning (with only labeled training data). It is a special instance of weak supervision. High-level overview We manually labour \\(500\\) images of 50-50 ratio with class balanced; We train on the \\(500\\) images using an Object Detection Model \\(\\M_1\\) until convergence (i.e. an acceptable result say MAP > 0.8, but more importantly, we do not care the class accuracy, rather, we want the localization error to be low); We use \\(\\M_1\\) and perform inference on the remaining \\(1500\\) images so that \\(\\M_1\\) can return us each image's bounding box coordinates, during this process we can discard bounding boxes with low confidences if we feel that an image won't contain more than say, 5 tactile tiles; Note that we emphasized on a low localization error from \\(\\M_1\\) and therefore expect that at the very least the bounding boxes of the tactile tiles are accurate as drawing bounding boxes manually is more time consuming than labelling whether a given bounding box is of class 0 or 1; We then run through manually over the predicted \\(1500\\) images to see if the predicted bounding boxes by \\(\\M_1\\) makes sense, and also to correct them if need be. Establish Metrics After understanding the problem better, we should probably define a metric to optimize. We adopt the commonly used metrics for object detection. IOU The concept of Intersection over Union (IOU) , also known as the Jaccard Index is used to decide whether the predicted bounding box is giving us a good outcome. It is defined by the formula: \\( \\(J(A,B) = \\dfrac{|(A \\cap B)|}{|(A \\cup B)|}\\) \\) where A and B are the area of the ground truth bounding box and predicted ground truth bounding box respectively as shown in figure below. The Typical Brothers (TP, FP, TN, FN) Object Detection at its core is a complicated algorithm comprising of both regression and classification. We first define the 4 good brothers that we see in a typical classification problem . Note in usual classification problem, we will have a probabality logit at the end of a softmax/sigmoid layer, which aids us in determining whether a classification belongs to TP, FP, TN or FN. In object detection, we use the IOU to determine if a given a bounding box prediction belongs to the four brothers. Let us define: \\(\\y\\) : 1 single ground truth bbox; \\(\\yhat\\) : 1 single predicted bbox; \\(\\iou(\\y, \\yhat)\\) : The IOU between them. \\(t\\) : The threshold for IOU to cross for it to be a positive, defaults to \\(0.5\\) . Then: TP: The model classified it as positive and it indeed is positive; \\(\\yhat\\) is TP iff \\(\\iou(\\y, \\yhat) > t\\) ; both the predictor and the ground truth are in agreement; FP: The model classified it as positive but it is negative; \\(\\yhat\\) is FP iff \\(\\iou(\\y, \\yhat) < t\\) ; the predictor raised a false alarm that there is an object but there actually isn't; FN: The model classified it as negative but it is positive; \\(\\yhat\\) is FN iff there exists a ground truth \\(\\y\\) that is not detected by our model; TN: This is usually ignored since it means that both the predictor and the annotator ground truth did not have a bounding box; it is often termed as correct rejections because there exist infinite places on an image where there are no bounding boxes from both the predictor and the annotator. The Iconic DUO (Precision and Recall) As with any other classification problem, we will see this iconic duo. Let us recap these 2 metrics in the settings of object detection. Precision Precision measures how many of the samples predicted as positive are actually positive. Mathematically, it is expressed as: \\[ \\text{Precision} = \\dfrac{\\text{TP}}{\\text{TP} + \\text{FP}}=P(Y=1 | \\hat{Y} = 1) \\] A Probablistic Interpretation Notice that the above definition has a probabilitic interpretation \\(P(Y = 1 | \\hat{Y} = 1)\\) , where \\(Y\\) and \\(\\hat{Y}\\) refers to the actual label and predicted labels respectively. We interpreted precision and recall not as ratios but as estimations of probabilities . Precision is then the estimated probability that a random point selected from the samples are positive. This might be a tough pill to swallow as someone who was never good in statistics but it is just conditional probability. If you try to think a bit further, you can form an intuition as follows: > If your classifier \\(h\\) is trained and the last layer is say, sigmoid, which in binary classification, calibrates the logits and turn them into probabilities. Then it can be interpretated that given a randomly chosen point \\(x \\in X_{train}\\) , what is the probability of this point \\(x\\) to be positive given that it is predicted as positive by the classifer? Informally, precision answers the question what proportion of positive predictions was actually correct ? In other words, out of all the positive predictions made by the model, how many of those positive predictions were actually positive when compared to the ground truth? In object detection, precision can be throught of as the fraction of correct object predictions among all objects detected by the model Recall Recall measures the following: out of all the actual positives (say, the real cancer patients), how many of them were identified correctly by the classifier? Mathematically, it is expressed as: \\[ \\text{Recall}= \\dfrac{\\text{TP}}{\\text{TP} + \\text{FN}}= P(\\hat{Y}=1 | Y = 1)=1-FNR \\] From the formula, we see the denominator to be defined as TP + FN, which is unsurprising as this gives you the actual number of positives. The dynamics is also similar to the one in precision. In object detection, recall can be thought of as the fraction of ground truth objects that are correctly detected by the model. Recall vs Precision The tug of war between this duo is still present, that is to say, as precision goes down, recall might go up and vice versa. Note that precision and recall are parametrized by the IOU threshold \\(t\\) , that means, for each threshold \\(t\\) , we can calculate the pair of precision and recall score. The Objectness Confidence Score Before we proceed to the behemoth Mean Average Precision , we should take a step back and recall that an usual object detection model is parametrized by: predicted bbox: [[...], [...]] 2 predictions; associated objectness confidence score: [0.2, 0.9] how confident that the predicted bbox really do contains an object; predicted labels: [1, 2] associated labels confidence score: [0.3, 0.8] how confident that the predicted label is correct, usually this is the probability logits. Before we even get to IOU calculation, we have another threshold to worry about, which is the objectness confidence score \\(\\tau\\) ; that is, if the predicted bboxes has confidence score below \\(\\tau\\) , then we immediately discard the predictions and do not even consider it a valid prediction. So if you are have a high \\(\\tau\\) threshold, then you may have a high precision at the cost of low recall. Let us breakdown why: If you raise \\(\\tau\\) , then we have a stringent requirement such that more objects might be missed by the model. A high FN ensues. If you decrease \\(\\tau\\) , then we may have many predictions, say a ground truth image has 2 gt bbox, but since we loosen \\(\\tau\\) , we have 10 predicted bboxes, this causes a lot of FPs. So a precision recall curve is a plot of precision vs recall at various thresholds \\(\\tau\\) . Note very carefully that the pr-curve is parametrized by \\(\\tau\\) and not \\(t\\) (the IOU threshold). Average Precision The big picture, precison-recall curve can be understood as y = f(x) where y is precision and recall x. More simply, it is just plotting pairs of precision-recall for each threshold \\(\\tau\\) and summing the area under the curve. At each confidence level (threshold), we ask what is the precision-recall score of the predictions of all bounding boxes at a specific IOU while discarding off those below the threshold, then average them over all thresholds? That's MAP Model Architecture RCNN Basic Architecture Perform selective search to extract multiple high-quality region proposals on the input image. These proposed regions are usually selected at multiple scales with different shapes and sizes. Each region proposal will be labeled with a class and a ground-truth bounding box. I believe out of the 2000 proposals, some of them won't even enclose any ground truth and so they should be discarded . Choose a pretrained CNN and truncate it before the output layer. Resize each region proposal to the input size required by the network, and output the extracted features for the region proposal through forward propagation. Take the extracted features and labeled class of each region proposal as an example. Train multiple support vector machines to classify objects, where each support vector machine individually determines whether the example contains a specific class. Take the extracted features and labeled bounding box of each region proposal as an example. Train a linear regression model to predict the ground-truth bounding box. Own words: Propose say 2000 regions (anchor boxes) then for each of the 2000 regions, we discard the ones with no IOU with ground truth; Run a CNN on each the remaining region proposals and take the output and: Feed into SVMs to classify the region; A linear regressor to regress the bboxes; Pros and Cons Cons : - Too slow as if 2000 proposals need to run 2000 CNNs on it. Fast-RCNN To resolve the 2000 proposals = 2000 CNNs issue, one can envision that we just use 1 CNN for the image and using this 1 CNN we \"inference on the 2000 proposals\". Basic Architecture Compared with the R-CNN, in the fast R-CNN the input of the CNN for feature extraction is the entire image, rather than individual region proposals. Moreover, this CNN is trainable. Given an input image, let the shape of the CNN output be \\(1 \\times c \\times h_1 \\times w_1\\) . Suppose that selective search generates \\(n\\) region proposals. These region proposals (of different shapes) mark regions of interest (of different shapes) on the CNN output. Then these regions of interest further extract features of the same shape (say height \\(h_2\\) and width \\(w_2\\) are specified) in order to be easily concatenated. To achieve this, the fast R-CNN introduces the region of interest (RoI) pooling layer: the CNN output and region proposals are input into this layer, outputting concatenated features of shape \\(n \\times c \\times h_2 \\times w_2\\) that are further extracted for all the region proposals. Using a fully-connected layer, transform the concatenated features into an output of shape \\(n \\times d\\) , where \\(d\\) depends on the model design. Predict the class and bounding box for each of the \\(n\\) region proposals. More concretely, in class and bounding box prediction, transform the fully-connected layer output into an output of shape \\(n \\times q\\) ( \\(q\\) is the number of classes) and an output of shape \\(n \\times 4\\) , respectively. The class prediction uses softmax regression. Own words: Decide on a CNN and truncate head Here say the CNN output feature map is shape (1, 128, 7, 7) with 128 filters of 7 by 7 Use proposal method to get say n=200 regions , these regions can be mapped to the CNN output in previous step. Each region can be shaped differently, so we use ROI pooling to shape all n of them into same width and height say 3 by 3. So now our shape is \\((200, 128, 3, 3)\\) where 200 is stacked region proposals. Then use the traditional FC with 2 heads to predict Pros and Cons Pros : - Solved 2000 CNN issue. Cons : - Selective search still slow. Faster-RCNN Basically solved selective search with RPN. Basic Architecture Use a \\(3\\times 3\\) convolutional layer with padding of 1 to transform the CNN output to a new output with \\(c\\) channels. In this way, each unit along the spatial dimensions of the CNN-extracted feature maps gets a new feature vector of length \\(c\\) . Centered on each pixel of the feature maps, generate multiple anchor boxes of different scales and aspect ratios and label them. Using the length- \\(c\\) feature vector at the center of each anchor box, predict the binary class (background or objects) and bounding box for this anchor box. Consider those predicted bounding boxes whose predicted classes are objects. Remove overlapped results using non-maximum suppression. The remaining predicted bounding boxes for objects are the region proposals required by the region of interest pooling layer. RPN like this, basically take feature map and connect to 2k and 4k mappings and compare with gt anchor boxes, can be learned so it is powerful and can predict better proposals. in_channels = 512 # depends on the output feature map. in vgg 16 it is equal to 512 mid_channels = 512 n_anchor = 9 # Number of anchors at each location conv1 = nn . Conv2d ( in_channels , mid_channels , 3 , 1 , 1 ) . to ( device ) conv1 . weight . data . normal_ ( 0 , 0.01 ) conv1 . bias . data . zero_ () reg_layer = nn . Conv2d ( mid_channels , n_anchor * 4 , 1 , 1 , 0 ) . to ( device ) reg_layer . weight . data . normal_ ( 0 , 0.01 ) reg_layer . bias . data . zero_ () cls_layer = nn . Conv2d ( mid_channels , n_anchor * 2 , 1 , 1 , 0 ) . to ( device ) # I will be going to use softmax here. you can equally use sigmoid if u replace 2 with 1. cls_layer . weight . data . normal_ ( 0 , 0.01 ) cls_layer . bias . data . zero_ (); It is worth noting that, as part of the faster R-CNN model, the region proposal network is jointly trained with the rest of the model. In other words, the objective function of the faster R-CNN includes not only the class and bounding box prediction in object detection, but also the binary class and bounding box prediction of anchor boxes in the region proposal network. As a result of the end-to-end training, the region proposal network learns how to generate high-quality region proposals, so as to stay accurate in object detection with a reduced number of region proposals that are learned from data. Pros and Cons Still considered 2-stage, accurate but slow. Yolo Pros and Cons VS faster rcnn Cons - Yolo v1 7 by 7 grid, each grid 2 bbox so total 98 bounding boxes. - In each grid cell one image is detected even though 2 bounding boxes proposed. - This means if objects in an image lie closely in a grid cell then will have issue detecting all of them. - It doesn\u2019t generalize well when objects in the image show rare aspects of ratio. Faster RCNN on the other hand, do detect small objects well since it has nine anchors in a single grid, however it fails to do real-time detection with its two step architecture cause too slow. Yolo V3 While YOLOv2 uses the DarkNet-19 as the model architecture, YOLOv3 uses a much more complex DarkNet-53 as the model backbone\u2014 a 106 layer neural network complete with residual blocks and upsampling networks. YOLOv3\u2019s architectural novelty allows it to predict at 3 different scales, with the feature maps being extracted at layers 82, 94, and 106 for these predictions.. By detecting features at 3 different scales, YOLOv3 makes up for the shortcomings of YOLOv2 and YOLO, particularly in the detection of smaller objects. With the architecture allowing the concatenation of the upsampled layer outputs with the features from previous layers, the fine-grained features that have been extracted are preserved thus making the detection of smaller objects easier. YOLOv3 only predicts 3 bounding boxes per cell (compared to 5 in YOLOv2) but it makes three predictions at different scales, totaling up to 9 anchor boxes. Screenshots Augmentations Augmentation techniques. This helps artificially expanding the dataset, intuition is in each training iteration (batch), the model sees a slightly different version of the original image, and thus helps to generalize. - Normal flips and rotational geometrical transformation, that is a given since photos can be upside down, left-right flipped. - Hue, Saturation and Color to match dusk, noon and dawn. - Random Eraser, similar to dropout, we mask certain parts of the image to force the model to learn with less information, a regularization to overfitting and memorization.","title":"LTA"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#data-collection-and-label","text":"","title":"Data Collection and Label"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#original-dataset","text":"500 images of size \\(4032 \\times 3024\\) provided by LTA: 150 positive class 1 where 1 means defective; 350 negative class 0 where 0 means non-defective; Class labels are subjected to changes depending on model used (i.e. F-RCNN treats background as 0 while Yolo does not care) There is some slight class imbalance: We checked if we can garner more data; We were given the green light; We collected about 1500 more photos.","title":"Original Dataset"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#labelling","text":"The total number of images is \\(2000\\) ; We need to label all of them as labels were not provided; Shortage of manpower prompted us to think of ways to reduce manual labour.","title":"Labelling"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#semi-supervised-learning","text":"Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training. Semi-supervised learning falls between unsupervised learning (with no labeled training data) and supervised learning (with only labeled training data). It is a special instance of weak supervision. High-level overview We manually labour \\(500\\) images of 50-50 ratio with class balanced; We train on the \\(500\\) images using an Object Detection Model \\(\\M_1\\) until convergence (i.e. an acceptable result say MAP > 0.8, but more importantly, we do not care the class accuracy, rather, we want the localization error to be low); We use \\(\\M_1\\) and perform inference on the remaining \\(1500\\) images so that \\(\\M_1\\) can return us each image's bounding box coordinates, during this process we can discard bounding boxes with low confidences if we feel that an image won't contain more than say, 5 tactile tiles; Note that we emphasized on a low localization error from \\(\\M_1\\) and therefore expect that at the very least the bounding boxes of the tactile tiles are accurate as drawing bounding boxes manually is more time consuming than labelling whether a given bounding box is of class 0 or 1; We then run through manually over the predicted \\(1500\\) images to see if the predicted bounding boxes by \\(\\M_1\\) makes sense, and also to correct them if need be.","title":"Semi-Supervised Learning"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#establish-metrics","text":"After understanding the problem better, we should probably define a metric to optimize. We adopt the commonly used metrics for object detection.","title":"Establish Metrics"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#iou","text":"The concept of Intersection over Union (IOU) , also known as the Jaccard Index is used to decide whether the predicted bounding box is giving us a good outcome. It is defined by the formula: \\( \\(J(A,B) = \\dfrac{|(A \\cap B)|}{|(A \\cup B)|}\\) \\) where A and B are the area of the ground truth bounding box and predicted ground truth bounding box respectively as shown in figure below.","title":"IOU"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#the-typical-brothers-tp-fp-tn-fn","text":"Object Detection at its core is a complicated algorithm comprising of both regression and classification. We first define the 4 good brothers that we see in a typical classification problem . Note in usual classification problem, we will have a probabality logit at the end of a softmax/sigmoid layer, which aids us in determining whether a classification belongs to TP, FP, TN or FN. In object detection, we use the IOU to determine if a given a bounding box prediction belongs to the four brothers. Let us define: \\(\\y\\) : 1 single ground truth bbox; \\(\\yhat\\) : 1 single predicted bbox; \\(\\iou(\\y, \\yhat)\\) : The IOU between them. \\(t\\) : The threshold for IOU to cross for it to be a positive, defaults to \\(0.5\\) . Then: TP: The model classified it as positive and it indeed is positive; \\(\\yhat\\) is TP iff \\(\\iou(\\y, \\yhat) > t\\) ; both the predictor and the ground truth are in agreement; FP: The model classified it as positive but it is negative; \\(\\yhat\\) is FP iff \\(\\iou(\\y, \\yhat) < t\\) ; the predictor raised a false alarm that there is an object but there actually isn't; FN: The model classified it as negative but it is positive; \\(\\yhat\\) is FN iff there exists a ground truth \\(\\y\\) that is not detected by our model; TN: This is usually ignored since it means that both the predictor and the annotator ground truth did not have a bounding box; it is often termed as correct rejections because there exist infinite places on an image where there are no bounding boxes from both the predictor and the annotator.","title":"The Typical Brothers (TP, FP, TN, FN)"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#the-iconic-duo-precision-and-recall","text":"As with any other classification problem, we will see this iconic duo. Let us recap these 2 metrics in the settings of object detection.","title":"The Iconic DUO (Precision and Recall)"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#precision","text":"Precision measures how many of the samples predicted as positive are actually positive. Mathematically, it is expressed as: \\[ \\text{Precision} = \\dfrac{\\text{TP}}{\\text{TP} + \\text{FP}}=P(Y=1 | \\hat{Y} = 1) \\] A Probablistic Interpretation Notice that the above definition has a probabilitic interpretation \\(P(Y = 1 | \\hat{Y} = 1)\\) , where \\(Y\\) and \\(\\hat{Y}\\) refers to the actual label and predicted labels respectively. We interpreted precision and recall not as ratios but as estimations of probabilities . Precision is then the estimated probability that a random point selected from the samples are positive. This might be a tough pill to swallow as someone who was never good in statistics but it is just conditional probability. If you try to think a bit further, you can form an intuition as follows: > If your classifier \\(h\\) is trained and the last layer is say, sigmoid, which in binary classification, calibrates the logits and turn them into probabilities. Then it can be interpretated that given a randomly chosen point \\(x \\in X_{train}\\) , what is the probability of this point \\(x\\) to be positive given that it is predicted as positive by the classifer? Informally, precision answers the question what proportion of positive predictions was actually correct ? In other words, out of all the positive predictions made by the model, how many of those positive predictions were actually positive when compared to the ground truth? In object detection, precision can be throught of as the fraction of correct object predictions among all objects detected by the model","title":"Precision"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#recall","text":"Recall measures the following: out of all the actual positives (say, the real cancer patients), how many of them were identified correctly by the classifier? Mathematically, it is expressed as: \\[ \\text{Recall}= \\dfrac{\\text{TP}}{\\text{TP} + \\text{FN}}= P(\\hat{Y}=1 | Y = 1)=1-FNR \\] From the formula, we see the denominator to be defined as TP + FN, which is unsurprising as this gives you the actual number of positives. The dynamics is also similar to the one in precision. In object detection, recall can be thought of as the fraction of ground truth objects that are correctly detected by the model.","title":"Recall"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#recall-vs-precision","text":"The tug of war between this duo is still present, that is to say, as precision goes down, recall might go up and vice versa. Note that precision and recall are parametrized by the IOU threshold \\(t\\) , that means, for each threshold \\(t\\) , we can calculate the pair of precision and recall score.","title":"Recall vs Precision"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#the-objectness-confidence-score","text":"Before we proceed to the behemoth Mean Average Precision , we should take a step back and recall that an usual object detection model is parametrized by: predicted bbox: [[...], [...]] 2 predictions; associated objectness confidence score: [0.2, 0.9] how confident that the predicted bbox really do contains an object; predicted labels: [1, 2] associated labels confidence score: [0.3, 0.8] how confident that the predicted label is correct, usually this is the probability logits. Before we even get to IOU calculation, we have another threshold to worry about, which is the objectness confidence score \\(\\tau\\) ; that is, if the predicted bboxes has confidence score below \\(\\tau\\) , then we immediately discard the predictions and do not even consider it a valid prediction. So if you are have a high \\(\\tau\\) threshold, then you may have a high precision at the cost of low recall. Let us breakdown why: If you raise \\(\\tau\\) , then we have a stringent requirement such that more objects might be missed by the model. A high FN ensues. If you decrease \\(\\tau\\) , then we may have many predictions, say a ground truth image has 2 gt bbox, but since we loosen \\(\\tau\\) , we have 10 predicted bboxes, this causes a lot of FPs. So a precision recall curve is a plot of precision vs recall at various thresholds \\(\\tau\\) . Note very carefully that the pr-curve is parametrized by \\(\\tau\\) and not \\(t\\) (the IOU threshold).","title":"The Objectness Confidence Score"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#average-precision","text":"The big picture, precison-recall curve can be understood as y = f(x) where y is precision and recall x. More simply, it is just plotting pairs of precision-recall for each threshold \\(\\tau\\) and summing the area under the curve. At each confidence level (threshold), we ask what is the precision-recall score of the predictions of all bounding boxes at a specific IOU while discarding off those below the threshold, then average them over all thresholds? That's MAP","title":"Average Precision"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#model-architecture","text":"","title":"Model Architecture"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#rcnn","text":"","title":"RCNN"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#basic-architecture","text":"Perform selective search to extract multiple high-quality region proposals on the input image. These proposed regions are usually selected at multiple scales with different shapes and sizes. Each region proposal will be labeled with a class and a ground-truth bounding box. I believe out of the 2000 proposals, some of them won't even enclose any ground truth and so they should be discarded . Choose a pretrained CNN and truncate it before the output layer. Resize each region proposal to the input size required by the network, and output the extracted features for the region proposal through forward propagation. Take the extracted features and labeled class of each region proposal as an example. Train multiple support vector machines to classify objects, where each support vector machine individually determines whether the example contains a specific class. Take the extracted features and labeled bounding box of each region proposal as an example. Train a linear regression model to predict the ground-truth bounding box. Own words: Propose say 2000 regions (anchor boxes) then for each of the 2000 regions, we discard the ones with no IOU with ground truth; Run a CNN on each the remaining region proposals and take the output and: Feed into SVMs to classify the region; A linear regressor to regress the bboxes;","title":"Basic Architecture"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#pros-and-cons","text":"Cons : - Too slow as if 2000 proposals need to run 2000 CNNs on it.","title":"Pros and Cons"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#fast-rcnn","text":"To resolve the 2000 proposals = 2000 CNNs issue, one can envision that we just use 1 CNN for the image and using this 1 CNN we \"inference on the 2000 proposals\".","title":"Fast-RCNN"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#basic-architecture_1","text":"Compared with the R-CNN, in the fast R-CNN the input of the CNN for feature extraction is the entire image, rather than individual region proposals. Moreover, this CNN is trainable. Given an input image, let the shape of the CNN output be \\(1 \\times c \\times h_1 \\times w_1\\) . Suppose that selective search generates \\(n\\) region proposals. These region proposals (of different shapes) mark regions of interest (of different shapes) on the CNN output. Then these regions of interest further extract features of the same shape (say height \\(h_2\\) and width \\(w_2\\) are specified) in order to be easily concatenated. To achieve this, the fast R-CNN introduces the region of interest (RoI) pooling layer: the CNN output and region proposals are input into this layer, outputting concatenated features of shape \\(n \\times c \\times h_2 \\times w_2\\) that are further extracted for all the region proposals. Using a fully-connected layer, transform the concatenated features into an output of shape \\(n \\times d\\) , where \\(d\\) depends on the model design. Predict the class and bounding box for each of the \\(n\\) region proposals. More concretely, in class and bounding box prediction, transform the fully-connected layer output into an output of shape \\(n \\times q\\) ( \\(q\\) is the number of classes) and an output of shape \\(n \\times 4\\) , respectively. The class prediction uses softmax regression. Own words: Decide on a CNN and truncate head Here say the CNN output feature map is shape (1, 128, 7, 7) with 128 filters of 7 by 7 Use proposal method to get say n=200 regions , these regions can be mapped to the CNN output in previous step. Each region can be shaped differently, so we use ROI pooling to shape all n of them into same width and height say 3 by 3. So now our shape is \\((200, 128, 3, 3)\\) where 200 is stacked region proposals. Then use the traditional FC with 2 heads to predict","title":"Basic Architecture"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#pros-and-cons_1","text":"Pros : - Solved 2000 CNN issue. Cons : - Selective search still slow.","title":"Pros and Cons"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#faster-rcnn","text":"Basically solved selective search with RPN.","title":"Faster-RCNN"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#basic-architecture_2","text":"Use a \\(3\\times 3\\) convolutional layer with padding of 1 to transform the CNN output to a new output with \\(c\\) channels. In this way, each unit along the spatial dimensions of the CNN-extracted feature maps gets a new feature vector of length \\(c\\) . Centered on each pixel of the feature maps, generate multiple anchor boxes of different scales and aspect ratios and label them. Using the length- \\(c\\) feature vector at the center of each anchor box, predict the binary class (background or objects) and bounding box for this anchor box. Consider those predicted bounding boxes whose predicted classes are objects. Remove overlapped results using non-maximum suppression. The remaining predicted bounding boxes for objects are the region proposals required by the region of interest pooling layer. RPN like this, basically take feature map and connect to 2k and 4k mappings and compare with gt anchor boxes, can be learned so it is powerful and can predict better proposals. in_channels = 512 # depends on the output feature map. in vgg 16 it is equal to 512 mid_channels = 512 n_anchor = 9 # Number of anchors at each location conv1 = nn . Conv2d ( in_channels , mid_channels , 3 , 1 , 1 ) . to ( device ) conv1 . weight . data . normal_ ( 0 , 0.01 ) conv1 . bias . data . zero_ () reg_layer = nn . Conv2d ( mid_channels , n_anchor * 4 , 1 , 1 , 0 ) . to ( device ) reg_layer . weight . data . normal_ ( 0 , 0.01 ) reg_layer . bias . data . zero_ () cls_layer = nn . Conv2d ( mid_channels , n_anchor * 2 , 1 , 1 , 0 ) . to ( device ) # I will be going to use softmax here. you can equally use sigmoid if u replace 2 with 1. cls_layer . weight . data . normal_ ( 0 , 0.01 ) cls_layer . bias . data . zero_ (); It is worth noting that, as part of the faster R-CNN model, the region proposal network is jointly trained with the rest of the model. In other words, the objective function of the faster R-CNN includes not only the class and bounding box prediction in object detection, but also the binary class and bounding box prediction of anchor boxes in the region proposal network. As a result of the end-to-end training, the region proposal network learns how to generate high-quality region proposals, so as to stay accurate in object detection with a reduced number of region proposals that are learned from data.","title":"Basic Architecture"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#pros-and-cons_2","text":"Still considered 2-stage, accurate but slow.","title":"Pros and Cons"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#yolo","text":"","title":"Yolo"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#pros-and-cons-vs-faster-rcnn","text":"Cons - Yolo v1 7 by 7 grid, each grid 2 bbox so total 98 bounding boxes. - In each grid cell one image is detected even though 2 bounding boxes proposed. - This means if objects in an image lie closely in a grid cell then will have issue detecting all of them. - It doesn\u2019t generalize well when objects in the image show rare aspects of ratio. Faster RCNN on the other hand, do detect small objects well since it has nine anchors in a single grid, however it fails to do real-time detection with its two step architecture cause too slow.","title":"Pros and Cons VS faster rcnn"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#yolo-v3","text":"While YOLOv2 uses the DarkNet-19 as the model architecture, YOLOv3 uses a much more complex DarkNet-53 as the model backbone\u2014 a 106 layer neural network complete with residual blocks and upsampling networks. YOLOv3\u2019s architectural novelty allows it to predict at 3 different scales, with the feature maps being extracted at layers 82, 94, and 106 for these predictions.. By detecting features at 3 different scales, YOLOv3 makes up for the shortcomings of YOLOv2 and YOLO, particularly in the detection of smaller objects. With the architecture allowing the concatenation of the upsampled layer outputs with the features from previous layers, the fine-grained features that have been extracted are preserved thus making the detection of smaller objects easier. YOLOv3 only predicts 3 bounding boxes per cell (compared to 5 in YOLOv2) but it makes three predictions at different scales, totaling up to 9 anchor boxes.","title":"Yolo V3"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#screenshots","text":"","title":"Screenshots"},{"location":"reighns_ml_journey/projects/LTA_road_cracks_detection/notebooks/walkthrough/#augmentations","text":"Augmentation techniques. This helps artificially expanding the dataset, intuition is in each training iteration (batch), the model sees a slightly different version of the original image, and thus helps to generalize. - Normal flips and rotational geometrical transformation, that is a given since photos can be upside down, left-right flipped. - Hue, Saturation and Color to match dusk, noon and dawn. - Random Eraser, similar to dropout, we mask certain parts of the image to force the model to learn with less information, a regularization to overfitting and memorization.","title":"Augmentations"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/","text":"Seeding and Device import os import random import numpy as np import torch def seed_all ( seed : int = 1930 ): \"\"\"Seed all random number generators.\"\"\" print ( \"Using Seed Number {} \" . format ( seed )) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator random . seed ( seed ) # set fixed value for python built-in pseudo-random generator torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False torch . backends . cudnn . enabled = False def seed_worker ( _worker_id ): \"\"\"Seed a worker with the given ID.\"\"\" worker_seed = torch . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) _ = seed_all ( 1992 ) device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) Using Seed Number 1992 Introduction Extracted from Kaggle Serious complications can occur as a result of malpositioned lines and tubes in patients. Doctors and nurses frequently use checklists for placement of lifesaving equipment to ensure they follow protocol in managing patients. Yet, these steps can be time consuming and are still prone to human error, especially in stressful situations when hospitals are at capacity. Hospital patients can have catheters and lines inserted during the course of their admission and serious complications can arise if they are positioned incorrectly. Nasogastric tube malpositioning into the airways has been reported in up to 3% of cases, with up to 40% of these cases demonstrating complications [1-3]. Airway tube malposition in adult patients intubated outside the operating room is seen in up to 25% of cases [4,5]. The likelihood of complication is directly related to both the experience level and specialty of the proceduralist. Early recognition of malpositioned tubes is the key to preventing risky complications (even death), even more so now that millions of COVID-19 patients are in need of these tubes and lines. The gold standard for the confirmation of line and tube positions are chest radiographs. However, a physician or radiologist must manually check these chest x-rays to verify that the lines and tubes are in the optimal position. Not only does this leave room for human error, but delays are also common as radiologists can be busy reporting other scans. Deep learning algorithms may be able to automatically detect malpositioned catheters and lines. Once alerted, clinicians can reposition or remove them to avoid life-threatening complications. The Royal Australian and New Zealand College of Radiologists (RANZCR) is a not-for-profit professional organisation for clinical radiologists and radiation oncologists in Australia, New Zealand, and Singapore. The group is one of many medical organisations around the world (including the NHS) that recognizes malpositioned tubes and lines as preventable. RANZCR is helping design safety systems where such errors will be caught. In this competition, you\u2019ll detect the presence and position of catheters and lines on chest x-rays. Use machine learning to train and test your model on 40,000 images to categorize a tube that is poorly placed. The dataset has been labelled with a set of definitions to ensure consistency with labelling. The normal category includes lines that were appropriately positioned and did not require repositioning. The borderline category includes lines that would ideally require some repositioning but would in most cases still function adequately in their current position. The abnormal category included lines that required immediate repositioning. If successful, your efforts may help clinicians save lives. Earlier detection of malpositioned catheters and lines is even more important as COVID-19 cases continue to surge. Many hospitals are at capacity and more patients are in need of these tubes and lines. Quick feedback on catheter and line placement could help clinicians better treat these patients. Beyond COVID-19, detection of line and tube position will ALWAYS be a requirement in many ill hospital patients. Dataset: Understanding our Data We will go through the data that we were given. Data Catalog/Description In this competition, you'll detect the presence and position of catheters and lines on chest x-rays. Use machine learning to train and test your model on \\(40,000\\) images to categorize a tube that is poorly placed. Train Set: \\(30083\\) images Public Test Set: \\(3582\\) images Private Test Set: ~ \\(14000\\) images train.csv : containing image IDs, labels and patient IDs . sample_submission.csv : a sample submission file in the correct format test/ : test images train/ : training images In particular the train csv has these columns: StudyInstanceUID - unique ID for each image ETT - Abnormal - endotracheal tube placement abnormal ETT - Borderline - endotracheal tube placement borderline abnormal ETT - Normal - endotracheal tube placement normal NGT - Abnormal - nasogastric tube placement abnormal NGT - Borderline - nasogastric tube placement borderline abnormal NGT - Incompletely Imaged - nasogastric tube placement inconclusive due to imaging NGT - Normal - nasogastric tube placement borderline normal CVC - Abnormal - central venous catheter placement abnormal CVC - Borderline - central venous catheter placement borderline abnormal CVC - Normal - central venous catheter placement normal Swan Ganz Catheter Present PatientID - unique ID for each patient in the dataset Objective: Multi-Label Binary Classification In general, a patient's single chest X-ray could present multiple medical conditions. Fig 1: Patient ID 323464123; By Hongnan G. Patient 323464123's first row corresponds to an unique image defined by the study instance UID. Noticed the 1's under the columns ETT-Normal , NGT - Incompletely Images , CVC-Borderline and CVC-Normal and 0's elsewhere. Unlike multi-class classification, where classes are mutually exclusive , multi-label is not. For example, a patient's X-ray scan of the lungs can show up pneumonia and covid-19 (both are conditions), as a result the class labels are not mutually exclusive (unlike multi-class). The same logic is applied in this setting, where the tube can be labelled differently. Metrics: Establish Metrics Macro-Averaged AUROC Then Macro-Average AUROC is calculated for each individual class, and then averaged over the total number of classes. \\[\\text{Macro-Average AUROC} = \\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}R_{i}\\] where \\(R_i\\) is the AUROC score for each individual class. A small example clears up the air: Consider 3 classes of apple, banana and carrot as a multi-label problem with class index \\([0, 1, 2]\\) . y_true : is a one-hot encoded matrix of 4 rows and 3 columns. The rows means 4 samples, and columns mean the class where 1 means positive and 0 negative. It is not a surprise that each row can hold multiple 1's since it is a multi-label problem. [0, 1, 1] just means that the \"image data\" contains both banana and carrot; y_pred : the predicted matrix, and is the same shape as y_true . We now treat the problem running multiple binary ROC computation: Calculate the ROC score between column \\(i\\) of y_true and y_pred respectively and call them \\(R_i\\) ; Sum \\(R_i\\) and divide by the number of classes and get the Macro-Averaged AUROC. import numpy as np from sklearn.metrics import roc_auc_score y_true = np . asarray ([[ 0 , 1 , 1 ], [ 0 , 0 , 1 ], [ 1 , 1 , 0 ], [ 1 , 1 , 1 ]]) y_pred = np . asarray ([[ 0 , 1 , 0 ], [ 1 , 0 , 0 ], [ 1 , 1 , 0 ], [ 1 , 0 , 1 ]]) macro_auroc = np . mean ([ roc_auc_score ( y_true [:, i ], y_pred [:, i ]) for i in range ( 3 )]) macro_auroc 0.75 Tip For a more wholesome treatment of metrics, see my Melanoma write-up and blog . Validation and Resampling: Cross-Validation How should we split out data into folds? We should examine the data for a few factors: Is the data \\(\\mathcal{X}\\) imbalanced? Is the data \\(\\mathcal{X}\\) generated in a i.i.d. manner, more specifically, if I split \\(\\mathcal{X}\\) to \\(\\mathcal{X}_{train}\\) and \\(\\mathcal{X}_{val}\\) , can we ensure that \\(\\mathcal{X}_{val}\\) has no dependency on \\(\\mathcal{X}_{train}\\) ? We came to the conclusion: Yes, there is quite some imbalanced distribution, in particular, CVC - Normal , ETT - Normal and CVC - Borderline are significantly more than the rest of the classes. Therefore, a stratified cross validation is reasonable. Stratified KFold ensures that relative class frequencies is approximately preserved in each train and validation fold. More concretely, we will not experience the scenario where \\(X_{train}\\) has \\(m^{+}\\) and \\(m^{-}\\) positive and negative samples, but \\(X_{val}\\) has only \\(p^{+}\\) positive samples only and 0 negative samples, simply due to the scarcity of negative samples In medical imaging, it is a well known fact that most of the data contains patient level repeatedly. To put it bluntly, if I have 100 samples, and according to PatientID , we see that the id 123456 (John Doe) appeared 20 times, this is normal as a patient can undergo multiple settings of say, X-rays. If we allow John Doe's data to appear in both train and validation set, then this poses a problem of information leakage, in which the data is no longer i.i.d. . One can think of each patient has an \"unique, underlying features\" which are highly correlated across their different samples. As a result, it is paramount to ensure that amongst this 3255 unique patients, we need to ensure that each unique patients' images DO NOT appear in the validation fold. That is to say, if patient John Doe has 100 X-ray images, but during our 5-fold splits, he has 70 images in Fold 1-4, while 30 images are in Fold 5, then if we were to train on Fold 1-4 and validate on Fold 5, there may be potential leakage and the model will predict with confidence for John Doe's images. This is under the assumption that John Doe's data does not fulfill the i.i.d process. StratifiedGroupKFold With the above consideration, we will use StratifiedGroupKFold where \\(K = 5\\) splits. There wasn't this splitting function in scikit-learn at the time of competition and as a result, we used a custom written (by someone else) RepeatedStratifiedGroupKFold function and just set n_splits = 1 to get StratifiedGroupKFold (yes we cannot afford to do repeated sample, so setting the split to be 1 will collapse the repeated function to just the normal stratified group kfold). However, as of 2022, this function is readily available in the Scikit-Learn library. To recap, we applied stratified logic such that each train and validation set has an equal weightage of positive and negative samples. We also grouped the patients in the process such that patient \\(i\\) will not appear in both training and validation set. Data leakage can cause you to have blind confidence on your model. We are also guilty of committing one since we trained our models with the NiH pretrained weights, without taking into consideration if the weights overlap with the training and validation folds information. In other words, we did not check properly if the weights trained on the NiH dataset has information in our RANZCR dataset. Take note this is different from training altogether on the NiH dataset, we are merely using the weights instead of the imagenet weights, which brings to the next point. Referring to figure 1, patient 323464123 has 6 images uniquely recorded on different visits. We should absolutely put them all in either train or validation set, as if say 2 images are in train and 4 in validation, there might be data leakage. Cross-Validation Workflow To recap, we have the following: Training Set ( \\(X_{\\text{train}}\\) ) : This will be further split into K validation sets during our cross-validation. This set is used to fit a particular hypothesis \\(h \\in \\mathcal{H}\\) . Validation Set ( \\(X_{\\text{val}}\\) ) : This is split from our \\(X_{\\text{train}}\\) during cross-validation. This set is used for model selection (i.e. find best hyperparameters, attempt to produce a best hypothesis \\(g \\in \\mathcal{H}\\) ). Test Set ( \\(X_{\\text{test}}\\) ) : This is an unseen test set, and we will only use it after we finish tuning our model/hypothesis. Suppose we have a final best model \\(g\\) , we will use \\(g\\) to predict on the test set to get an estimate of the generalization error (also called out-of-sample error). Pipeline. Courtesy of scikit-learn on a typical Cross-Validation workflow. Transfer Learning: The core of Deep Learning As we all know, if we train on imagenet weights, we may take quite a while to converge, even if we finetune it. The intuition is simple, imagenet were trained on many common items in life, and none of them resemble closely to the image structures of X-rays . Therefore, we have a few options. Freeze earlier layers but unfreeze the later Conv Layers: this is intuitive as earlier layers detect shapes and colors, all low level details that is very useful even for such dissimilar tasks , and unfreeze the later conv layers which is what we call the \"abstract feature layers\", where it is more important for the model to learn from scratch. Fine-Tuning; Feature Extraction; Fine-Tuning Instead of random initialization, we initialize the network with a pretrained network, like the one that is trained on imagenet 1000 dataset. This is what we will be doing and we managed to find a set of pretrained weights trained specifically on this dataset as a starting point. The weights can be found here . We used a few models and found out that resnet200d has the best results on this set of training images. The reason we used this is mostly empirical, but using gradcam we can see how the model sees the images. Feature Extraction ConvNet as fixed feature extractor: Here, we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained. This is less relevant to us as we aren't using it for feature extractions. Therefore, the model may have a hard time detecting abstract features such shapes and details from the X-rays. We can of course unfreeze all the layers and retrain them from scratch, using various backbones, Preprocessing Most preprocessing techniques we do in an image recognition competition is mostly as follows: Mean and Standard Deviation Perform mean and std for the dataset given to us. Note that this step may make sense on paper, but empirically, using imagenet's default mean std will always work as well, if not better. Nevertheless, here are the stats: Imagenet: mean = [0.485, 0.456, 0.406] and; std = [0.229, 0.224, 0.225] RANZCR: mean = [0.4887381077884414, ...] and; std = [0.23064819430546407, ...] Channel Distribution This is usually done to check for \"surprises\". More specifically, I remember vividly when participating in Singapore Airline challenge where the classifier recognize weird objects as luggages. After plotting the pixel histogram, we observed that the luggages colors are all of a non-normal distribution, in fact, it is quite scattered. Then it dawned upon us that the classifier is learning the \"color\" too much, instead of the shape of the luggage. When we grayed out the images, the classifier starts to ignore the noise in the colors, and instead focus on other features like shapes. So this removes signal to noise in a way - using the objection detection example such as detecting a strawberry in a tree full of green leaves, then color is important, but if we detect leaves in a tree full of green leaves, we do not wish to incorporate color here as anything green might suggest that it is a leaf. We found, and as mentioned also by Rueben Schmidt in this post , there are some images that have black borders around them. I experimented by removed them during both the training process. There was no significant increase on the LB score, even if there was, it is in the 3-4th decimal places, but I noticed my local cv increased, so I think that some noise are removed locally, but not reflected in the test set. Therefore, during inference, I also removed the black borders, which should be the correct approach (learning from mistakes!). In conclusion, there is a small boost in score, if I keep this consistent in both training and inference, I reckon that no surprise factor would pop out. Here is the code: image = cv2 . imread ( image_path , cv2 . IMREAD_GRAYSCALE ) mask = image > 0 image = image [ np . ix_ ( mask . any ( 1 ), mask . any ( 0 ))] image = cv2 . cvtColor ( image , cv2 . COLOR_GRAY2RGB ) Notice that the code removes any pixel that is > 0, where black pixel is 0. On hindsight for the Singapore Airline project, I now know there is GradCam , where we can see how the model is learning, as it will highlight the areas on which the model is focusing on in an image. Convert Gray to RGB We know that X-rays are Grayscale images so converting a grayscale image to RGB is just setting R=G=B=Grayscale pixel for all channels. import cv2 image = cv2 . imread ( \"../images/1.2.826.0.1.3680043.8.498.10000428974990117276582711948006105617.png\" , cv2 . IMREAD_GRAYSCALE ) print ( image . shape ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) print ( image . shape ) (256, 256) (256, 256, 3) Augmentations We know that augmentation is central in an image competition, as essentially we are adding more data into the training process, effectively reducing overfitting and improve generalization . Heavy augmentations are used during Train-Time-Augmentation. But during Test-Time-Augmentation, we used the same set of training augmentations to inference with \\(100\\%\\) probability. Train-Time Augmentation The typicals! train_augmentations = [ albumentations . RandomResizedCrop ( height = config . image_size , width = config . image_size ), albumentations . HorizontalFlip ( p = 0.5 ), albumentations . ShiftScaleRotate ( p = 0.5 ), albumentations . HueSaturationValue ( hue_shift_limit = 0.2 , sat_shift_limit = 0.2 , val_shift_limit = 0.2 , p = 0.5 ), albumentations . RandomBrightnessContrast ( brightness_limit = ( - 0.1 , 0.1 ), contrast_limit = ( - 0.1 , 0.1 ), p = 0.5 ), albumentations . CoarseDropout ( p = 0.5 ), albumentations . Normalize ( mean = [ 0.485 , 0.456 , 0.406 ], std = [ 0.229 , 0.224 , 0.225 ], max_pixel_value = 255.0 , p = 1.0 , ), ToTensorV2 ( p = 1.0 ), ] Test-Time Augmentation The exact same set of augmentations were used in inference. Not all TTAs provided a increase in score. Model Architectures, Training Parameters & Tricks Model Architecture Overview A brief overview of our model architecture is shown in fig 2.1 and 2.2: Fig 2.1; Single-Head Approach courtesy of Tawara Fig 2.2; Multi-Head Approach courtesy of Tawara Backbone We used both resnet200d and seresnet152d but will focus more on the first model. We used resnet200d , a ResNet variant model as our main backbone. ResNet-D is a modification on the ResNet architecture that utilises an average pooling tweak for downsampling. The motivation is that in the unmodified ResNet, the 1\u00d71 convolution for the downsampling block ignores 3/4 of input feature maps, so this is modified so no information will be ignored. Info So 1x1 convolutional reduces the feature maps depth but not the width or height while pooling reduces the width or height but not the depth. I think the results are better with the latter. In our case, we did the following: Create the model with: model = timm.create_model('resnet200d', pretrained=True, num_classes=1000) ; Load the pretrained weights from NiH trained ; Reset Classifier Head with Global Average Pooling: self.model.reset_classifier(num_classes=0, global_pool=\"avg\") ; Attach our own Classifier Head with 11 classes. import torch import timm from torchinfo import summary model = timm . create_model ( 'resnet18' , pretrained = True , num_classes = 1000 ) batch_size = 2 image_shape = ( 3 , 224 , 224 ) input_image_tensor = torch . rand ( size = ( batch_size , * image_shape )) # print(summary(model, (2, 3, 224, 224))) model.reset_classifier(num_classes=0, global_pool=\"\") means we do not want global average pooling and thus the shape at the last conv layer (penultimate layer) is \\((2, 512, 7, 7)\\) model.reset_classifier(num_classes=0, global_pool=\"avg\") means we do want global average pooling and thus the shape at the last conv layer (penultimate layer) is \\((2, 512)\\) whereby for each and every of the 512 feature maps \\(f_i\\) , we average \\(f_i\\) across all pixels (i.e. if \\(f_i\\) is 3 by 3 then average means add all \\(3 \\times 3 = 9\\) pixels and average) and concat to become one \\(512\\) vector. model = timm . create_model ( 'resnet18' , pretrained = True , num_classes = 1000 ) o = model ( input_image_tensor ) print ( f 'Original shape: { o . shape } ' ) model . reset_classifier ( num_classes = 0 , global_pool = \"\" ) o = model ( input_image_tensor ) print ( f 'Unpooled shape: { o . shape } ' ) Original shape: torch.Size([2, 1000]) Unpooled shape: torch.Size([2, 512, 7, 7]) model = timm . create_model ( 'resnet18' , pretrained = True , num_classes = 1000 ) o = model ( input_image_tensor ) print ( f 'Original shape: { o . shape } ' ) model . reset_classifier ( num_classes = 0 , global_pool = \"avg\" ) o = model ( input_image_tensor ) print ( f 'Pooled shape: { o . shape } ' ) Original shape: torch.Size([2, 1000]) Pooled shape: torch.Size([2, 512]) Note: Empirically, we realized the ResNet200D works very well for this particular task. We all asked ourselves why, and it was also discussed by many, but we all agreed that through various experiments, this model seems to consistently outperform their other SOTA counterparts. However, the closest possible paper on Revisiting ResNets: Improved Training and Scaling Strategies . Of course, to add diversity to our final predictions, we trained one more SeResNet152d as well. In general, ensembling models with vastly different architectures may result in a more robust solution. As an example, you can think of each model as a \"average learner\", and if their structure is different, it may very well so learn information that the other model might miss, hence ensembling them will average out such differences. Later on I will touch upon an ensembling technique called Forward Ensembling/Selection in this task, it has since worked well for other similar competitions. Classifier Heads - Multi-Head Approach We will focus a bit more on the multi-heads we used. Reading on self attention in X-ray What is a multi-headed model? And what exactly is a 'head' in a model? Intuition The usage of multi-heads is not uncommon, let us detail a simple example in Object Detection. The image below shows the general architecture: In object detection, we want to predict two things, the image class label and its bounding box coordinates ; The backbone network (\"convolution and pooling\") is responsible for extracting a feature map from the image that contains higher level summarized information. Each head uses this feature map as input to predict its desired outcome. The main intuition why feature maps of the last few layers (last layer usually) are important is one needs to recognize the earlier conv layer's feature maps find simple features like shapes, sizes, edges from an image, while the deep conv layers will be of more abstract features in an image. As a result, we really just want the abstract feature maps as they are more class specific to the image instead of the earlier layers which gives generic shapes . Let us say you used a ResNet as the backbone, then: Remove the classifier head, or rather just take the backbone which is all layers up to the last conv layer: say at the last layer. the output feature maps has a shape of (512, 7, 7); These 512 feature maps of 7 by 7 are high level information of the image encoded; We then connect a classification head to the backbone to predict the image's class given the true class labels; We then connect a regression head to the backbone to predict the image's bounding box coordinates given the true bounding box coordinates; We can create two heads, one responsible for classification for the class label and the other regression to work on the localization of the bounding boxes; Thus here we have 2 heads, one for classifying what class the image object is, the other is to localize where the image object is. The loss that you optimize for during training is usually a weighted sum of the individual losses for each prediction head. Multi-Head for Multi-Label Since we have 11 targets in this competition and they can be divided into 4 distinct groups: ETT , NGT , CVC and Swan . We envision that different groups have different areas in images to focus on. One possible way to leverage this idea is a multi-head approach we talked about. Multipe groups can share one single CNN backbone but have independent classifier heads. Fig 2.1; Single-Head Approach courtesy of Tawara Fig 2.2; Multi-Head Approach courtesy of Tawara With this in mind, let us move on: Multi-Label This is a multi-label classification problem. The section on the activation functions fully explained the single head version of using sigmoid layer. In fact, it is not uncommon to train N number of heads on a N-class Multi-Label problem. One thing to note is that if your classification head is Linear layer only (with BCE loss), then the back gradient propagation is the same whether you train one head, or multiple heads. However, we have non-linear layers in the head, including the SpatialAttentionBlock ! At the time of writing, I won't say I fully grasp of all the inner workings of an Attention Module across various use cases, but an analogy to aid my understanding is as follows: Having taken Learning From Data from Professor Yaser, the inner joke is about the Hypothesis Space. Let me elaborate, given a resnet200D as our hypothesis space \\(\\mathcal{H}\\) , we aim to find a \\(h \\in \\mathcal{H}\\) that best represents our true function \\(f\\) . Now suppose our learning algorithm \\(\\mathcal{A}\\) does a good job in helping us to find such a optimal \\(h\\) , it may take time, maybe say 100 epochs before finding it. Now if I break down the problem into 4 parts, each corresponding to a group, and we \"aid\" the learning algorithm by giving more attention to 4 focused areas, then we might find both a good \\(h\\) that estimate the \\(f\\) well, and may even be faster! If the above is too meh for understanding, imagine you are taking an exam in Machine Learning, as we all know, this field is a rabbit hole with never ending topics, let us say that there are 20 topics for you to study for the exam, you are dilligent and does that. But you have limited time and you decided to devote equal time to each topic, the consequence is you may not perform well for the exam due to limited understanding of each topic. Now, if I were to tell you that, hey, out of the 20 topics, can you study these 4 topics, as I think they have a higher chance of coming out, you will likely do better in the exam given that you devoted much more time on those \"focused (attention!)\" topics. The following code explains this methodology with reference to the above images. We first note to the readers that typically, if we use a single head approach, where if we were given a problem set \\(\\mathcal{D} = X \\times y\\) , a hypothesis space \\(\\mathcal{H}\\) we learn from a learning algorithm \\(\\mathcal{A}\\) , producing a final hypothesis \\(g\\) (or h, depends on your notation), that predicts as such \\(g(X_{val}) = y_{\\text{val_pred}}\\) , where each element in \\(y_{\\text{val_pred}}\\) corresponds to the class. Think of the basic MNIST example, our prediction vector's first element corresponds to the probability of it being an 0, and so on and so forth (assuming we use soft labels here). The change here is after the feature extraction layer (i.e. the feature logits after backbone), instead of just connecting it to a linear head for classification, we instead split the 11 outputs to 4 distinct groups. Each group will go through the head independent of the others, and this may prompt the model to put more attention on the independent groups. Finally, we torch.cat(..,axis=1) the outputs after they gone through their respective heads to recover the 11 outputs. model = CustomModel ( config , pretrained = True , load_weight = True , load_url = False , out_dim_heads = [ 3 , 4 , 3 , 1 ], ) # Multi Head for i , out_dim in enumerate ( self . out_dim_heads ): layer_name = f \"head_ { i } \" layer = torch . nn . Sequential ( SpatialAttentionBlock ( in_features , [ 64 , 32 , 16 , 1 ]), torch . nn . AdaptiveAvgPool2d ( output_size = 1 ), torch . nn . Flatten ( start_dim = 1 ), torch . nn . Linear ( in_features , in_features ), self . activation , torch . nn . Dropout ( 0.3 ), torch . nn . Linear ( in_features , out_dim ), ) setattr ( self , layer_name , layer ) def forward ( self , input_neurons ): \"\"\"Define the computation performed at every call.\"\"\" if self . use_custom_layers is False : output_predictions = self . model ( input_neurons ) else : if len ( self . out_dim_heads ) > 1 : output_logits_backbone = self . architecture [ \"backbone\" ]( input_neurons ) multi_outputs = [ getattr ( self , f \"head_ { i } \" )( output_logits_backbone ) for i in range ( self . num_heads ) ] output_predictions = torch . cat ( multi_outputs , axis = 1 ) We built-upon fellow Kaggler Tawara\u2019s Multi-head model for our best scoring models. In particular, we experimented with the activation functions and dropout rates. We found models with Swish activation in the multi-head component of the network to perform > best in our experiments. Our best scoring single model is a multi-head model with a resnet200d backbone. In particular, one single fold of resnet200d gives a private score of 0.970. Another very interesting approach is 3-4 stage training. We did not have time to experiment with the 3-4 stage training as we joined the competition late. Model Architectures: layer = torch.nn.Sequential( SpatialAttentionBlock(in_features, [64, 32, 16, 1]), torch.nn.AdaptiveAvgPool2d(output_size=1), torch.nn.Flatten(start_dim=1), torch.nn.Linear(in_features, in_features), self.activation, torch.nn.Dropout(0.3), torch.nn.Linear(in_features, out_dim), ) - Backbone : ResNet200D and SeResNet152d - Classifier Head: Separated and Independent Spatial-Attention Module and the typical Multi-Layer Perceptron for Target Group (ETT(3), NGT(4), CVC(3), and Swan(1)). - Spatial-Attention Module: SpatialAttentionBlock(in_features, [64, 32, 16, 1]) - MLP: : Linear -> Swish -> Dropout -> Linear ; It is worth noting after the Linear layer, there is a Sigmoid layer in this particular setup as we are using BCEWITHLOGITSLOSS from PyTorch for numerical stability. - Activation: One thing to note is we used Swish in our Classifier Head. Swish is a smooth and non-monotonic function, the latter contrasts when compared to many other activations. I will explain a bit in the next section. Activation Functions As we all know, activation functions are used to transform a neurons' linearity to non-linearity and decide whether to \"fire\" a neuron or not. We chose Swish as our main activation function in the classifier head layers. Swish When we design or choose an activation function, we need to ensure the follows: (Smoothness) Differentiable and Continuous: For example, the sigmoid function is continuous and hence differentiable. If the property is not fulfilled, we might face issues as backpropagation may not be performed properly since we cannot differentiate it.If you notice, the heaviside function is not. We cant perform GD using the HF as we cannot compute gradients but for the logistic function we can. The gradient of sigmoid function g is g(1-g) conveniently Monotonic: This helps the model to converge faster. But spoiler alert, Swish is not monotonic. The properties of Swish are as follows: Bounded below: It is claimed in the paper it serves as a strong regularization. Smoothness: More smooth than ReLU which allows the model to optimize better, the error landscape, when smoothed, is easier to traverse in order to find a minima. An intuitive idea is the hill again, imagine you traverse down Bukit Timah Hill, vs traversing down Mount Himalaya LOL!!! Let us see how swish looks like when plotted. import math import matplotlib.pyplot as plt import numpy as np def swish ( x ): sigmoid = 1 / ( 1 + np . exp ( - x )) swish = x * sigmoid return swish epsilon = 1e-20 x = np . linspace ( - 10 , 10 , 10 ) z = swish ( x ) print ( f \"x= { x } \" ) print ( f \" \\n z=swish(x)= { z } \" ) print ( f \" \\n min z = { min ( z ) } \" ) x=[-10. -7.77777778 -5.55555556 -3.33333333 -1.11111111 1.11111111 3.33333333 5.55555556 7.77777778 10. ] z=swish(x)=[-4.53978687e-04 -3.25707421e-03 -2.13946242e-02 -1.14817319e-01 -2.75182001e-01 8.35929110e-01 3.21851601e+00 5.53416093e+00 7.77452070e+00 9.99954602e+00] min z = -0.27518200126563513 plt . plot ( x , z ) plt . xlabel ( \"x\" ) plt . ylabel ( \"Swish(X)\" ) plt . show (); Model Architecture: Final Activation Layer Sigmoid vs Softmax I've noticed people often get directed to this question when searching whether to use sigmoid vs softmax in neural networks. If you are one of those people building a neural network classifier, here is how to decide whether to apply sigmoid or softmax to the raw output values from your network: If you have a multi-label classification problem = there is more than one \"right answer\" = the outputs are NOT mutually exclusive, then use a sigmoid function on each raw output independently. The sigmoid will allow you to have high probability for all of your classes, some of them, or none of them. Example: classifying diseases in a chest x-ray image. The image might contain pneumonia, emphysema, and/or cancer, or none of those findings. If you have a multi-class classification problem = there is only one \"right answer\" = the outputs are mutually exclusive, then use a softmax function. The softmax will enforce that the sum of the probabilities of your output classes are equal to one, so in order to increase the probability of a particular class, your model must correspondingly decrease the probability of at least one of the other classes. Example: classifying images from the MNIST data set of handwritten digits. A single picture of a digit has only one true identity - the picture cannot be a 7 and an 8 at the same time. In the below code we understand that our model's forward() call gives us a output output_logits of shape (8, 11) if the batch size is 8, and the 11 represents each logit for each of the class. If we apply Softmax to this function on dimension=1 , it simply means we are applying the function each row, from row 1 to 8. Take row 1 for example, the softmax function will squash all the 11 values into a 0-1 range, you can say this is a probability calibration, and the output_predictions is also of shape (8, 11) but all sums up to 1. If we apply Sigmoid to this function on dimension=1 , although PyTorch does not specifiy this because it automatically assumes we are applying sigmoid elementwise, that is to say you cannot simply pass an array of 11 elements to sigmoid function and but we are applying the sigmoid function each row as well. There is a lot of nuance and intricacies here. We take the first row as an example, the first element corresponds to the class ETT-Abnormal , when we apply sigmoid to this element 0.0762, we get 0.5190, and for the second element class ETT-Borderline , we have 0.0877 and when we apply sigmoid, we get 0.5219, so on and so forth for the first row. You should by now observe that they do not sum to 1. This is because each time sigmoid is applied, it is in a one-vs-all scenario. Meaning to say, the 0.519 for ETT-Abnormal means that ETT-Abnormal is treated as the positive class, and the remaining 10 classes are treated as negative class 0. In other words, with 11 elements and sigmoid, we are essentially performing 11 binary classification on the said 11 classes. So 0.519 actually means that the probability of it being class 1 ( ETT-Abnormal ) is 0.519, and the probability of it being NOT class 1 (ALL other classes) is 0.481. The same logic applies to each of the element in the first row. One thing worth noting is that the predictions for row 1 is not mutually exclusive , meaning that from the 11 classes, we can have say, ETT-Abnormal, NGH-Abnormal, CVC-Abnormal to all have say probability score of 0.9, meaning to say, it is highly likely to be all 3 conditions! This is okay and common in X-Ray imaging. In the table dataframe below, I put them into a dataframe for easy visualization. classes = [ \"ETT - Abnormal\" , \"ETT - Borderline\" , \"ETT - Normal\" , \"NGT - Abnormal\" , \"NGT - Borderline\" , \"NGT - Incompletely Imaged\" , \"NGT - Normal\" , \"CVC - Abnormal\" , \"CVC - Borderline\" , \"CVC - Normal\" , \"Swan Ganz Catheter Present\" , ] import torch import pandas as pd output_logits = torch . tensor ([ [ 0.0762 , 0.0877 , 0.1205 , - 0.0615 , - 0.0054 , 0.0661 , 0.1567 , - 0.0978 , 0.0248 , - 0.0350 , 0.0084 ], [ - 0.0196 , - 0.0729 , 0.0534 , 0.0307 , - 0.0428 , - 0.0016 , 0.0013 , - 0.0247 , - 0.0094 , - 0.0424 , 0.0192 ], [ - 0.0125 , - 0.0310 , 0.0118 , - 0.1301 , 0.0418 , 0.0229 , 0.0139 , - 0.0526 , 0.0870 , - 0.0681 , - 0.0068 ], [ - 0.0259 , - 0.0544 , - 0.0262 , 0.0018 , 0.0161 , - 0.0369 , - 0.0370 , - 0.0157 , 0.0036 , - 0.0592 , 0.0107 ], [ - 0.0366 , - 0.0695 , 0.0740 , - 0.0353 , - 0.0363 , - 0.0019 , 0.0085 , - 0.0144 , 0.0129 , - 0.0470 , 0.0043 ], [ - 0.0445 , - 0.0822 , 0.0487 , - 0.0851 , 0.0269 , - 0.0809 , - 0.0434 , 0.0110 , - 0.0631 , - 0.0733 , - 0.0188 ], [ - 0.0304 , 0.0012 , 0.0233 , - 0.0121 , - 0.0406 , - 0.0459 , - 0.0363 , 0.0089 , - 0.0009 , - 0.0797 , - 0.0017 ], [ - 0.0415 , 0.0787 , 0.0283 , - 0.0617 , - 0.0526 , - 0.0016 , - 0.0409 , - 0.0481 , 0.0583 , - 0.0810 , - 0.0050 ]], dtype = torch . float64 , device = device ) sigmoid = torch . nn . Sigmoid () softmax = torch . nn . Softmax ( dim = 1 ) output_predictions_sigmoid = sigmoid ( output_logits ) output_predictions_softmax = softmax ( output_logits ) print ( output_predictions_sigmoid ) print ( output_predictions_softmax ) tensor([[0.5190, 0.5219, 0.5301, 0.4846, 0.4987, 0.5165, 0.5391, 0.4756, 0.5062, 0.4913, 0.5021], [0.4951, 0.4818, 0.5133, 0.5077, 0.4893, 0.4996, 0.5003, 0.4938, 0.4977, 0.4894, 0.5048], [0.4969, 0.4923, 0.5029, 0.4675, 0.5104, 0.5057, 0.5035, 0.4869, 0.5217, 0.4830, 0.4983], [0.4935, 0.4864, 0.4935, 0.5004, 0.5040, 0.4908, 0.4908, 0.4961, 0.5009, 0.4852, 0.5027], [0.4909, 0.4826, 0.5185, 0.4912, 0.4909, 0.4995, 0.5021, 0.4964, 0.5032, 0.4883, 0.5011], [0.4889, 0.4795, 0.5122, 0.4787, 0.5067, 0.4798, 0.4892, 0.5027, 0.4842, 0.4817, 0.4953], [0.4924, 0.5003, 0.5058, 0.4970, 0.4899, 0.4885, 0.4909, 0.5022, 0.4998, 0.4801, 0.4996], [0.4896, 0.5197, 0.5071, 0.4846, 0.4869, 0.4996, 0.4898, 0.4880, 0.5146, 0.4798, 0.4988]], dtype=torch.float64) tensor([[0.0948, 0.0959, 0.0991, 0.0826, 0.0874, 0.0939, 0.1028, 0.0797, 0.0901, 0.0849, 0.0886], [0.0900, 0.0853, 0.0968, 0.0946, 0.0879, 0.0916, 0.0919, 0.0895, 0.0909, 0.0879, 0.0935], [0.0907, 0.0890, 0.0929, 0.0806, 0.0957, 0.0939, 0.0931, 0.0871, 0.1001, 0.0858, 0.0912], [0.0904, 0.0878, 0.0903, 0.0929, 0.0942, 0.0894, 0.0894, 0.0913, 0.0931, 0.0874, 0.0937], [0.0887, 0.0858, 0.0991, 0.0888, 0.0887, 0.0918, 0.0928, 0.0907, 0.0932, 0.0878, 0.0924], [0.0901, 0.0868, 0.0989, 0.0865, 0.0968, 0.0869, 0.0902, 0.0953, 0.0885, 0.0876, 0.0925], [0.0899, 0.0928, 0.0948, 0.0915, 0.0890, 0.0885, 0.0894, 0.0935, 0.0926, 0.0856, 0.0925], [0.0884, 0.0997, 0.0948, 0.0867, 0.0875, 0.0920, 0.0885, 0.0879, 0.0977, 0.0850, 0.0917]], dtype=torch.float64) df = pd . DataFrame ( data = output_predictions_sigmoid . detach () . cpu () . numpy (), columns = classes ) display ( df ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ETT - Abnormal ETT - Borderline ETT - Normal NGT - Abnormal NGT - Borderline NGT - Incompletely Imaged NGT - Normal CVC - Abnormal CVC - Borderline CVC - Normal Swan Ganz Catheter Present 0 0.519041 0.521911 0.530089 0.484630 0.498650 0.516519 0.539095 0.475569 0.506200 0.491251 0.502100 1 0.495100 0.481783 0.513347 0.507674 0.489302 0.499600 0.500325 0.493825 0.497650 0.489402 0.504800 2 0.496875 0.492251 0.502950 0.467521 0.510448 0.505725 0.503475 0.486853 0.521736 0.482982 0.498300 3 0.493525 0.486403 0.493450 0.500450 0.504025 0.490776 0.490751 0.496075 0.500900 0.485204 0.502675 4 0.490851 0.482632 0.518492 0.491176 0.490926 0.499525 0.502125 0.496400 0.503225 0.488252 0.501075 5 0.488877 0.479462 0.512173 0.478738 0.506725 0.479786 0.489152 0.502750 0.484230 0.481683 0.495300 6 0.492401 0.500300 0.505825 0.496975 0.489851 0.488527 0.490926 0.502225 0.499775 0.480086 0.499575 7 0.489626 0.519665 0.507075 0.484580 0.486853 0.499600 0.489776 0.487977 0.514571 0.479761 0.498750 Batch Size and Tricks Due to hardware limitation, we can barely fit in anything more than a batch_size of 8. Quoting from here : It has been observed in practice that when using a larger batch there is a degradation in the quality of the model, as measured by its ability to generalize [...] large-batch methods tend to converge to sharp minimizers of the training and testing functions\u2014and as is well known, sharp minima lead to poorer generalization. In contrast, small-batch methods consistently converge to flat minimizers, and our experiments support a commonly held view that this is due to the inherent noise in the gradient estimation. The above shows that large batch size may fit the model too well, as the model will learn features of the dataset in less iterations, and may memorize this particular dataset's features, leading to overfitting and poor generalization. However, too small a batch size causes our convergence to go too slow, empirically, we take 32 or 64 as the ideal batch size in this competition. We used both torch.amp and gradient accumulation to be able to fit more batch sizes. We did not freeze the batch_norm layers, which still yielded great results. What we should have done is to experiment more on how to freeze the batch norm layers properly, as I believe that it may help. In the end, we used a batch size of 8 and fit 4 iterations using gradient accumulation and trained a total number of 20 epochs to get a local CV score of roughly 0.969. Optimizer, Scheduler and Loss Scheduler The configuration can be seen here. But note that we incorporated GradualWarmUpScheduler along with CosineAnnealingLR , we also experimented with CosineAnnealingWarmRestarts , the results are similar. From the paper Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour , we learnt about the warmup technique. Although the context of the paper was training under large batch size, we find it helpful even in small batches for the training to converge. The basic algorithm is as follows: Set a base_lr or initial lr for what you want in a model, say 1e-4. If we set our warmup epoch to be 10, then we will start from with 1e-4/10 in the first epoch, and take equal steps each time to converge to 1e-4 in the 10th epoch. After the 10th epoch, warmup ends, we start applying our scheduler's normal steps. However, I took quite some time to understand the idea of gradual warmup, I made my understanding here . We should try OneCyclePolicy as detailed by fastai. num_epochs = 20 CosineAnnealingLR : T_max : num_epochs - 1 eta_min : 1.0e-07 last_epoch : - 1 verbose : true Notice in my configuration above, we set the parameter T_max to be the 19, which is like a one-shot training. import torch import matplotlib.pyplot as plt num_epochs = 20 model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) cosine_annealing_lr_scheduler_one_shot = torch . optim . lr_scheduler . CosineAnnealingLR ( optimizer , T_max = 19 , eta_min = 1e-7 ) cosine_annealing_lr_one_shot = [] for i in range ( num_epochs ): optimizer . step () cosine_annealing_lr_one_shot . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) cosine_annealing_lr_scheduler_one_shot . step () plt . plot ( cosine_annealing_lr_one_shot ); num_epochs = 20 model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) cosine_annealing_lr_scheduler_normal = torch . optim . lr_scheduler . CosineAnnealingLR ( optimizer , T_max = 2 , eta_min = 1e-7 ) cosine_annealing_lr_normal = [] for i in range ( num_epochs ): optimizer . step () cosine_annealing_lr_normal . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) cosine_annealing_lr_scheduler_normal . step () plt . plot ( cosine_annealing_lr_normal ) [<matplotlib.lines.Line2D at 0x260cde7e7c0>] Loss We should also experiment with Focal Loss but seeing negative results from fellow Kagglers, on top with limited resources, we did not try it. Ensembling Forward Ensembling We made use of the Forward Ensembling idea from Chris in SIIM-ISIC Melanoma Classification back in August 2020, I modified the code for this specific task. A simple description is as follows, modified from Chris, with more mathematical notations. We start off with a dataset \\(\\mathcal{D} = X \\times y\\) where it is sampled from the true population \\(\\mathcal{X} \\times \\mathcal{Y}\\) . We apply KFold (5 splits) to the dataset, as illustrated in the diagram. We can now train five different hypothesis \\(h_{F1}, h_{F2},...,h_{F5}\\) , where \\(h_{F1}\\) is trained on Fold 2 to Fold 5 and predict on Fold 1, \\(h_{F2}\\) is trained on Fold 1,3,4,5 and predict on Fold 2. The logic follows for all 5 hypothesis. Notice that in the five models, we are predicting on a unique validation fold, and as a result, after we trained all 5 folds, we will have the predictions made on the whole training set (F1-F5). This predictions is called the Out-of-Fold predictions. We then go a step further and calculate the AUC score with the OOF predictions with the ground truth to get the OOF AUC. We save it to a csv or dataframe called oof_1.csv , subsequent oof trained on different hypothesis space should be named oof_i.csv where \\(i \\in [2,3,...]\\) . After we trained all 5 folds, we will use \\(h_{1}\\) to predict on \\(X_{test}\\) and obtain predictions \\(Y_{\\text{h1 preds}}\\) , we then use \\(h_{2}\\) to predict on \\(X_{test}\\) and obtain predictions \\(Y_{\\text{h2 preds}}\\) , we do this for all five folds and finally \\(Y_{\\text{final preds}} = \\dfrac{1}{5}\\sum_{i=1}^{5}Y_{\\text{hi preds}}\\) . This is a typical pipeline in most machine learning problems. We save this final predictions as sub_1.csv , subsequence predictions trained on different hypothesis space should be named sub_i.csv where \\(i \\in [2,3,...]\\) . Now if we train another model, a completely different hypothesis space is used, to be more pedantic, we denote the previous model to be taken from the hypothesis space \\(\\mathcal{H}_{1}\\) , and now we move on to \\(\\mathcal{H}_{2}\\) . We repeat step 1-6 on this new model (Note that you are essentially training 10 \"models\" now since we are doing KFold twice, and oh, please set the seed of KFold to be the same, it should never be the case that both model comes from different splitting seed for apparent reasons). Here is the key (given the above setup with 2 different models trained on 5 folds): Normally, most people do a simple mean ensemble, that is \\(\\dfrac{Y_{\\text{final preds H1}} + Y_{\\text{final preds H2}}}{2}\\) . This works well most of the time as we trust both model holds equal importance in the final predictions. One issue may be that certain models should be weighted more than the rest, we should not simply take Leaderboard feedback score to judge the weight assignment. A general heuristic here is called Forward Selection. (Extract from Chris) Now say that you build 2 models (that means that you did 5 KFold twice). You now have oof_1.csv, oof_2.csv, sub_1.csv, and sub_2.csv. How do we blend the two models? We find the weight w such that w * oof_1.predictions + (1-w) * oof_2.predictions has the largest AUC. all = [] for w in [ 0.00 , 0.01 , 0.02 , ... , 0.98 , 0.99 , 1.00 ]: ensemble_pred = w * oof_1 . predictions + ( 1 - w ) * oof_2 . predictions ensemble_auc = roc_auc_score ( oof . target , ensemble_pred ) all . append ( ensemble_auc ) best_weight = np . argmax ( all ) / 100. Then we can assign the best weight like: final_ensemble_pred = best_weight * sub_1 . target + ( 1 - best_weight ) * sub_2 . target Coutersy of Chris In this competition, there are two approaches, either maximize the average of the macro AUC score of all the classes, or maximize each column/class separately. It turns out that maximizing the columns separately led to disastrous results (it could be my code and idea is wrong, as ROC is a ranking metric). Conclusion What we could have done better: Use more variety of classifier head like GeM . Use more variety of backbone . Use Neptune.ai to log our experiments as soon things start to get messy. Basically MLOps is important! Experiment on 3-4 stage training. Pseudo Labelling. Knowledge Distillation. Experiment more on maximizing AUC during ensembles. rank_pct etc. See novel three stage training: https://www.kaggle.com/yasufuminakama/ranzcr-resnet200d-3-stage-training-step1 References Multi-Head Deep Learning Model with Multi-Label Classification AUC Metric on Multi-Label Sigmoid and Softmax for Multi-Label Multi-Label Classification Tutorial Why we should use Multi-Head in Multi-Label Classification Follow Up 1 Follow Up 2 Follow Up 3 Sigmoid is Binary Cross Entropy Attention Blocks in Computer Vision Spatial Attention Blocks Spatial Attention Module Convolutional Block Attention Module [Dive Into Deep Learning - Chapter 10: Attention Mechanisms] Gradual Warmup: Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour","title":"RANZCR CLiP - Catheter and Line Position Challenge"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#seeding-and-device","text":"import os import random import numpy as np import torch def seed_all ( seed : int = 1930 ): \"\"\"Seed all random number generators.\"\"\" print ( \"Using Seed Number {} \" . format ( seed )) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator random . seed ( seed ) # set fixed value for python built-in pseudo-random generator torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False torch . backends . cudnn . enabled = False def seed_worker ( _worker_id ): \"\"\"Seed a worker with the given ID.\"\"\" worker_seed = torch . initial_seed () % 2 ** 32 np . random . seed ( worker_seed ) random . seed ( worker_seed ) _ = seed_all ( 1992 ) device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) Using Seed Number 1992","title":"Seeding and Device"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#introduction","text":"Extracted from Kaggle Serious complications can occur as a result of malpositioned lines and tubes in patients. Doctors and nurses frequently use checklists for placement of lifesaving equipment to ensure they follow protocol in managing patients. Yet, these steps can be time consuming and are still prone to human error, especially in stressful situations when hospitals are at capacity. Hospital patients can have catheters and lines inserted during the course of their admission and serious complications can arise if they are positioned incorrectly. Nasogastric tube malpositioning into the airways has been reported in up to 3% of cases, with up to 40% of these cases demonstrating complications [1-3]. Airway tube malposition in adult patients intubated outside the operating room is seen in up to 25% of cases [4,5]. The likelihood of complication is directly related to both the experience level and specialty of the proceduralist. Early recognition of malpositioned tubes is the key to preventing risky complications (even death), even more so now that millions of COVID-19 patients are in need of these tubes and lines. The gold standard for the confirmation of line and tube positions are chest radiographs. However, a physician or radiologist must manually check these chest x-rays to verify that the lines and tubes are in the optimal position. Not only does this leave room for human error, but delays are also common as radiologists can be busy reporting other scans. Deep learning algorithms may be able to automatically detect malpositioned catheters and lines. Once alerted, clinicians can reposition or remove them to avoid life-threatening complications. The Royal Australian and New Zealand College of Radiologists (RANZCR) is a not-for-profit professional organisation for clinical radiologists and radiation oncologists in Australia, New Zealand, and Singapore. The group is one of many medical organisations around the world (including the NHS) that recognizes malpositioned tubes and lines as preventable. RANZCR is helping design safety systems where such errors will be caught. In this competition, you\u2019ll detect the presence and position of catheters and lines on chest x-rays. Use machine learning to train and test your model on 40,000 images to categorize a tube that is poorly placed. The dataset has been labelled with a set of definitions to ensure consistency with labelling. The normal category includes lines that were appropriately positioned and did not require repositioning. The borderline category includes lines that would ideally require some repositioning but would in most cases still function adequately in their current position. The abnormal category included lines that required immediate repositioning. If successful, your efforts may help clinicians save lives. Earlier detection of malpositioned catheters and lines is even more important as COVID-19 cases continue to surge. Many hospitals are at capacity and more patients are in need of these tubes and lines. Quick feedback on catheter and line placement could help clinicians better treat these patients. Beyond COVID-19, detection of line and tube position will ALWAYS be a requirement in many ill hospital patients.","title":"Introduction"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#dataset-understanding-our-data","text":"We will go through the data that we were given.","title":"Dataset: Understanding our Data"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#data-catalogdescription","text":"In this competition, you'll detect the presence and position of catheters and lines on chest x-rays. Use machine learning to train and test your model on \\(40,000\\) images to categorize a tube that is poorly placed. Train Set: \\(30083\\) images Public Test Set: \\(3582\\) images Private Test Set: ~ \\(14000\\) images train.csv : containing image IDs, labels and patient IDs . sample_submission.csv : a sample submission file in the correct format test/ : test images train/ : training images In particular the train csv has these columns: StudyInstanceUID - unique ID for each image ETT - Abnormal - endotracheal tube placement abnormal ETT - Borderline - endotracheal tube placement borderline abnormal ETT - Normal - endotracheal tube placement normal NGT - Abnormal - nasogastric tube placement abnormal NGT - Borderline - nasogastric tube placement borderline abnormal NGT - Incompletely Imaged - nasogastric tube placement inconclusive due to imaging NGT - Normal - nasogastric tube placement borderline normal CVC - Abnormal - central venous catheter placement abnormal CVC - Borderline - central venous catheter placement borderline abnormal CVC - Normal - central venous catheter placement normal Swan Ganz Catheter Present PatientID - unique ID for each patient in the dataset","title":"Data Catalog/Description"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#objective-multi-label-binary-classification","text":"In general, a patient's single chest X-ray could present multiple medical conditions. Fig 1: Patient ID 323464123; By Hongnan G. Patient 323464123's first row corresponds to an unique image defined by the study instance UID. Noticed the 1's under the columns ETT-Normal , NGT - Incompletely Images , CVC-Borderline and CVC-Normal and 0's elsewhere. Unlike multi-class classification, where classes are mutually exclusive , multi-label is not. For example, a patient's X-ray scan of the lungs can show up pneumonia and covid-19 (both are conditions), as a result the class labels are not mutually exclusive (unlike multi-class). The same logic is applied in this setting, where the tube can be labelled differently.","title":"Objective: Multi-Label Binary Classification"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#metrics-establish-metrics","text":"","title":"Metrics: Establish Metrics"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#macro-averaged-auroc","text":"Then Macro-Average AUROC is calculated for each individual class, and then averaged over the total number of classes. \\[\\text{Macro-Average AUROC} = \\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}R_{i}\\] where \\(R_i\\) is the AUROC score for each individual class. A small example clears up the air: Consider 3 classes of apple, banana and carrot as a multi-label problem with class index \\([0, 1, 2]\\) . y_true : is a one-hot encoded matrix of 4 rows and 3 columns. The rows means 4 samples, and columns mean the class where 1 means positive and 0 negative. It is not a surprise that each row can hold multiple 1's since it is a multi-label problem. [0, 1, 1] just means that the \"image data\" contains both banana and carrot; y_pred : the predicted matrix, and is the same shape as y_true . We now treat the problem running multiple binary ROC computation: Calculate the ROC score between column \\(i\\) of y_true and y_pred respectively and call them \\(R_i\\) ; Sum \\(R_i\\) and divide by the number of classes and get the Macro-Averaged AUROC. import numpy as np from sklearn.metrics import roc_auc_score y_true = np . asarray ([[ 0 , 1 , 1 ], [ 0 , 0 , 1 ], [ 1 , 1 , 0 ], [ 1 , 1 , 1 ]]) y_pred = np . asarray ([[ 0 , 1 , 0 ], [ 1 , 0 , 0 ], [ 1 , 1 , 0 ], [ 1 , 0 , 1 ]]) macro_auroc = np . mean ([ roc_auc_score ( y_true [:, i ], y_pred [:, i ]) for i in range ( 3 )]) macro_auroc 0.75 Tip For a more wholesome treatment of metrics, see my Melanoma write-up and blog .","title":"Macro-Averaged AUROC"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#validation-and-resampling-cross-validation","text":"","title":"Validation and Resampling: Cross-Validation"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#how-should-we-split-out-data-into-folds","text":"We should examine the data for a few factors: Is the data \\(\\mathcal{X}\\) imbalanced? Is the data \\(\\mathcal{X}\\) generated in a i.i.d. manner, more specifically, if I split \\(\\mathcal{X}\\) to \\(\\mathcal{X}_{train}\\) and \\(\\mathcal{X}_{val}\\) , can we ensure that \\(\\mathcal{X}_{val}\\) has no dependency on \\(\\mathcal{X}_{train}\\) ? We came to the conclusion: Yes, there is quite some imbalanced distribution, in particular, CVC - Normal , ETT - Normal and CVC - Borderline are significantly more than the rest of the classes. Therefore, a stratified cross validation is reasonable. Stratified KFold ensures that relative class frequencies is approximately preserved in each train and validation fold. More concretely, we will not experience the scenario where \\(X_{train}\\) has \\(m^{+}\\) and \\(m^{-}\\) positive and negative samples, but \\(X_{val}\\) has only \\(p^{+}\\) positive samples only and 0 negative samples, simply due to the scarcity of negative samples In medical imaging, it is a well known fact that most of the data contains patient level repeatedly. To put it bluntly, if I have 100 samples, and according to PatientID , we see that the id 123456 (John Doe) appeared 20 times, this is normal as a patient can undergo multiple settings of say, X-rays. If we allow John Doe's data to appear in both train and validation set, then this poses a problem of information leakage, in which the data is no longer i.i.d. . One can think of each patient has an \"unique, underlying features\" which are highly correlated across their different samples. As a result, it is paramount to ensure that amongst this 3255 unique patients, we need to ensure that each unique patients' images DO NOT appear in the validation fold. That is to say, if patient John Doe has 100 X-ray images, but during our 5-fold splits, he has 70 images in Fold 1-4, while 30 images are in Fold 5, then if we were to train on Fold 1-4 and validate on Fold 5, there may be potential leakage and the model will predict with confidence for John Doe's images. This is under the assumption that John Doe's data does not fulfill the i.i.d process.","title":"How should we split out data into folds?"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#stratifiedgroupkfold","text":"With the above consideration, we will use StratifiedGroupKFold where \\(K = 5\\) splits. There wasn't this splitting function in scikit-learn at the time of competition and as a result, we used a custom written (by someone else) RepeatedStratifiedGroupKFold function and just set n_splits = 1 to get StratifiedGroupKFold (yes we cannot afford to do repeated sample, so setting the split to be 1 will collapse the repeated function to just the normal stratified group kfold). However, as of 2022, this function is readily available in the Scikit-Learn library. To recap, we applied stratified logic such that each train and validation set has an equal weightage of positive and negative samples. We also grouped the patients in the process such that patient \\(i\\) will not appear in both training and validation set. Data leakage can cause you to have blind confidence on your model. We are also guilty of committing one since we trained our models with the NiH pretrained weights, without taking into consideration if the weights overlap with the training and validation folds information. In other words, we did not check properly if the weights trained on the NiH dataset has information in our RANZCR dataset. Take note this is different from training altogether on the NiH dataset, we are merely using the weights instead of the imagenet weights, which brings to the next point. Referring to figure 1, patient 323464123 has 6 images uniquely recorded on different visits. We should absolutely put them all in either train or validation set, as if say 2 images are in train and 4 in validation, there might be data leakage.","title":"StratifiedGroupKFold"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#cross-validation-workflow","text":"To recap, we have the following: Training Set ( \\(X_{\\text{train}}\\) ) : This will be further split into K validation sets during our cross-validation. This set is used to fit a particular hypothesis \\(h \\in \\mathcal{H}\\) . Validation Set ( \\(X_{\\text{val}}\\) ) : This is split from our \\(X_{\\text{train}}\\) during cross-validation. This set is used for model selection (i.e. find best hyperparameters, attempt to produce a best hypothesis \\(g \\in \\mathcal{H}\\) ). Test Set ( \\(X_{\\text{test}}\\) ) : This is an unseen test set, and we will only use it after we finish tuning our model/hypothesis. Suppose we have a final best model \\(g\\) , we will use \\(g\\) to predict on the test set to get an estimate of the generalization error (also called out-of-sample error). Pipeline. Courtesy of scikit-learn on a typical Cross-Validation workflow.","title":"Cross-Validation Workflow"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#transfer-learning-the-core-of-deep-learning","text":"As we all know, if we train on imagenet weights, we may take quite a while to converge, even if we finetune it. The intuition is simple, imagenet were trained on many common items in life, and none of them resemble closely to the image structures of X-rays . Therefore, we have a few options. Freeze earlier layers but unfreeze the later Conv Layers: this is intuitive as earlier layers detect shapes and colors, all low level details that is very useful even for such dissimilar tasks , and unfreeze the later conv layers which is what we call the \"abstract feature layers\", where it is more important for the model to learn from scratch. Fine-Tuning; Feature Extraction;","title":"Transfer Learning: The core of Deep Learning"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#fine-tuning","text":"Instead of random initialization, we initialize the network with a pretrained network, like the one that is trained on imagenet 1000 dataset. This is what we will be doing and we managed to find a set of pretrained weights trained specifically on this dataset as a starting point. The weights can be found here . We used a few models and found out that resnet200d has the best results on this set of training images. The reason we used this is mostly empirical, but using gradcam we can see how the model sees the images.","title":"Fine-Tuning"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#feature-extraction","text":"ConvNet as fixed feature extractor: Here, we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained. This is less relevant to us as we aren't using it for feature extractions. Therefore, the model may have a hard time detecting abstract features such shapes and details from the X-rays. We can of course unfreeze all the layers and retrain them from scratch, using various backbones,","title":"Feature Extraction"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#preprocessing","text":"Most preprocessing techniques we do in an image recognition competition is mostly as follows:","title":"Preprocessing"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#mean-and-standard-deviation","text":"Perform mean and std for the dataset given to us. Note that this step may make sense on paper, but empirically, using imagenet's default mean std will always work as well, if not better. Nevertheless, here are the stats: Imagenet: mean = [0.485, 0.456, 0.406] and; std = [0.229, 0.224, 0.225] RANZCR: mean = [0.4887381077884414, ...] and; std = [0.23064819430546407, ...]","title":"Mean and Standard Deviation"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#channel-distribution","text":"This is usually done to check for \"surprises\". More specifically, I remember vividly when participating in Singapore Airline challenge where the classifier recognize weird objects as luggages. After plotting the pixel histogram, we observed that the luggages colors are all of a non-normal distribution, in fact, it is quite scattered. Then it dawned upon us that the classifier is learning the \"color\" too much, instead of the shape of the luggage. When we grayed out the images, the classifier starts to ignore the noise in the colors, and instead focus on other features like shapes. So this removes signal to noise in a way - using the objection detection example such as detecting a strawberry in a tree full of green leaves, then color is important, but if we detect leaves in a tree full of green leaves, we do not wish to incorporate color here as anything green might suggest that it is a leaf. We found, and as mentioned also by Rueben Schmidt in this post , there are some images that have black borders around them. I experimented by removed them during both the training process. There was no significant increase on the LB score, even if there was, it is in the 3-4th decimal places, but I noticed my local cv increased, so I think that some noise are removed locally, but not reflected in the test set. Therefore, during inference, I also removed the black borders, which should be the correct approach (learning from mistakes!). In conclusion, there is a small boost in score, if I keep this consistent in both training and inference, I reckon that no surprise factor would pop out. Here is the code: image = cv2 . imread ( image_path , cv2 . IMREAD_GRAYSCALE ) mask = image > 0 image = image [ np . ix_ ( mask . any ( 1 ), mask . any ( 0 ))] image = cv2 . cvtColor ( image , cv2 . COLOR_GRAY2RGB ) Notice that the code removes any pixel that is > 0, where black pixel is 0. On hindsight for the Singapore Airline project, I now know there is GradCam , where we can see how the model is learning, as it will highlight the areas on which the model is focusing on in an image.","title":"Channel Distribution"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#convert-gray-to-rgb","text":"We know that X-rays are Grayscale images so converting a grayscale image to RGB is just setting R=G=B=Grayscale pixel for all channels. import cv2 image = cv2 . imread ( \"../images/1.2.826.0.1.3680043.8.498.10000428974990117276582711948006105617.png\" , cv2 . IMREAD_GRAYSCALE ) print ( image . shape ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) print ( image . shape ) (256, 256) (256, 256, 3)","title":"Convert Gray to RGB"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#augmentations","text":"We know that augmentation is central in an image competition, as essentially we are adding more data into the training process, effectively reducing overfitting and improve generalization . Heavy augmentations are used during Train-Time-Augmentation. But during Test-Time-Augmentation, we used the same set of training augmentations to inference with \\(100\\%\\) probability.","title":"Augmentations"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#train-time-augmentation","text":"The typicals! train_augmentations = [ albumentations . RandomResizedCrop ( height = config . image_size , width = config . image_size ), albumentations . HorizontalFlip ( p = 0.5 ), albumentations . ShiftScaleRotate ( p = 0.5 ), albumentations . HueSaturationValue ( hue_shift_limit = 0.2 , sat_shift_limit = 0.2 , val_shift_limit = 0.2 , p = 0.5 ), albumentations . RandomBrightnessContrast ( brightness_limit = ( - 0.1 , 0.1 ), contrast_limit = ( - 0.1 , 0.1 ), p = 0.5 ), albumentations . CoarseDropout ( p = 0.5 ), albumentations . Normalize ( mean = [ 0.485 , 0.456 , 0.406 ], std = [ 0.229 , 0.224 , 0.225 ], max_pixel_value = 255.0 , p = 1.0 , ), ToTensorV2 ( p = 1.0 ), ]","title":"Train-Time Augmentation"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#test-time-augmentation","text":"The exact same set of augmentations were used in inference. Not all TTAs provided a increase in score.","title":"Test-Time Augmentation"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#model-architectures-training-parameters-tricks","text":"","title":"Model Architectures, Training Parameters &amp; Tricks"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#model-architecture","text":"","title":"Model Architecture"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#overview","text":"A brief overview of our model architecture is shown in fig 2.1 and 2.2: Fig 2.1; Single-Head Approach courtesy of Tawara Fig 2.2; Multi-Head Approach courtesy of Tawara","title":"Overview"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#backbone","text":"We used both resnet200d and seresnet152d but will focus more on the first model. We used resnet200d , a ResNet variant model as our main backbone. ResNet-D is a modification on the ResNet architecture that utilises an average pooling tweak for downsampling. The motivation is that in the unmodified ResNet, the 1\u00d71 convolution for the downsampling block ignores 3/4 of input feature maps, so this is modified so no information will be ignored. Info So 1x1 convolutional reduces the feature maps depth but not the width or height while pooling reduces the width or height but not the depth. I think the results are better with the latter. In our case, we did the following: Create the model with: model = timm.create_model('resnet200d', pretrained=True, num_classes=1000) ; Load the pretrained weights from NiH trained ; Reset Classifier Head with Global Average Pooling: self.model.reset_classifier(num_classes=0, global_pool=\"avg\") ; Attach our own Classifier Head with 11 classes. import torch import timm from torchinfo import summary model = timm . create_model ( 'resnet18' , pretrained = True , num_classes = 1000 ) batch_size = 2 image_shape = ( 3 , 224 , 224 ) input_image_tensor = torch . rand ( size = ( batch_size , * image_shape )) # print(summary(model, (2, 3, 224, 224))) model.reset_classifier(num_classes=0, global_pool=\"\") means we do not want global average pooling and thus the shape at the last conv layer (penultimate layer) is \\((2, 512, 7, 7)\\) model.reset_classifier(num_classes=0, global_pool=\"avg\") means we do want global average pooling and thus the shape at the last conv layer (penultimate layer) is \\((2, 512)\\) whereby for each and every of the 512 feature maps \\(f_i\\) , we average \\(f_i\\) across all pixels (i.e. if \\(f_i\\) is 3 by 3 then average means add all \\(3 \\times 3 = 9\\) pixels and average) and concat to become one \\(512\\) vector. model = timm . create_model ( 'resnet18' , pretrained = True , num_classes = 1000 ) o = model ( input_image_tensor ) print ( f 'Original shape: { o . shape } ' ) model . reset_classifier ( num_classes = 0 , global_pool = \"\" ) o = model ( input_image_tensor ) print ( f 'Unpooled shape: { o . shape } ' ) Original shape: torch.Size([2, 1000]) Unpooled shape: torch.Size([2, 512, 7, 7]) model = timm . create_model ( 'resnet18' , pretrained = True , num_classes = 1000 ) o = model ( input_image_tensor ) print ( f 'Original shape: { o . shape } ' ) model . reset_classifier ( num_classes = 0 , global_pool = \"avg\" ) o = model ( input_image_tensor ) print ( f 'Pooled shape: { o . shape } ' ) Original shape: torch.Size([2, 1000]) Pooled shape: torch.Size([2, 512]) Note: Empirically, we realized the ResNet200D works very well for this particular task. We all asked ourselves why, and it was also discussed by many, but we all agreed that through various experiments, this model seems to consistently outperform their other SOTA counterparts. However, the closest possible paper on Revisiting ResNets: Improved Training and Scaling Strategies . Of course, to add diversity to our final predictions, we trained one more SeResNet152d as well. In general, ensembling models with vastly different architectures may result in a more robust solution. As an example, you can think of each model as a \"average learner\", and if their structure is different, it may very well so learn information that the other model might miss, hence ensembling them will average out such differences. Later on I will touch upon an ensembling technique called Forward Ensembling/Selection in this task, it has since worked well for other similar competitions.","title":"Backbone"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#classifier-heads-multi-head-approach","text":"We will focus a bit more on the multi-heads we used. Reading on self attention in X-ray What is a multi-headed model? And what exactly is a 'head' in a model?","title":"Classifier Heads - Multi-Head Approach"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#intuition","text":"The usage of multi-heads is not uncommon, let us detail a simple example in Object Detection. The image below shows the general architecture: In object detection, we want to predict two things, the image class label and its bounding box coordinates ; The backbone network (\"convolution and pooling\") is responsible for extracting a feature map from the image that contains higher level summarized information. Each head uses this feature map as input to predict its desired outcome. The main intuition why feature maps of the last few layers (last layer usually) are important is one needs to recognize the earlier conv layer's feature maps find simple features like shapes, sizes, edges from an image, while the deep conv layers will be of more abstract features in an image. As a result, we really just want the abstract feature maps as they are more class specific to the image instead of the earlier layers which gives generic shapes . Let us say you used a ResNet as the backbone, then: Remove the classifier head, or rather just take the backbone which is all layers up to the last conv layer: say at the last layer. the output feature maps has a shape of (512, 7, 7); These 512 feature maps of 7 by 7 are high level information of the image encoded; We then connect a classification head to the backbone to predict the image's class given the true class labels; We then connect a regression head to the backbone to predict the image's bounding box coordinates given the true bounding box coordinates; We can create two heads, one responsible for classification for the class label and the other regression to work on the localization of the bounding boxes; Thus here we have 2 heads, one for classifying what class the image object is, the other is to localize where the image object is. The loss that you optimize for during training is usually a weighted sum of the individual losses for each prediction head.","title":"Intuition"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#multi-head-for-multi-label","text":"Since we have 11 targets in this competition and they can be divided into 4 distinct groups: ETT , NGT , CVC and Swan . We envision that different groups have different areas in images to focus on. One possible way to leverage this idea is a multi-head approach we talked about. Multipe groups can share one single CNN backbone but have independent classifier heads. Fig 2.1; Single-Head Approach courtesy of Tawara Fig 2.2; Multi-Head Approach courtesy of Tawara With this in mind, let us move on: Multi-Label This is a multi-label classification problem. The section on the activation functions fully explained the single head version of using sigmoid layer. In fact, it is not uncommon to train N number of heads on a N-class Multi-Label problem. One thing to note is that if your classification head is Linear layer only (with BCE loss), then the back gradient propagation is the same whether you train one head, or multiple heads. However, we have non-linear layers in the head, including the SpatialAttentionBlock ! At the time of writing, I won't say I fully grasp of all the inner workings of an Attention Module across various use cases, but an analogy to aid my understanding is as follows: Having taken Learning From Data from Professor Yaser, the inner joke is about the Hypothesis Space. Let me elaborate, given a resnet200D as our hypothesis space \\(\\mathcal{H}\\) , we aim to find a \\(h \\in \\mathcal{H}\\) that best represents our true function \\(f\\) . Now suppose our learning algorithm \\(\\mathcal{A}\\) does a good job in helping us to find such a optimal \\(h\\) , it may take time, maybe say 100 epochs before finding it. Now if I break down the problem into 4 parts, each corresponding to a group, and we \"aid\" the learning algorithm by giving more attention to 4 focused areas, then we might find both a good \\(h\\) that estimate the \\(f\\) well, and may even be faster! If the above is too meh for understanding, imagine you are taking an exam in Machine Learning, as we all know, this field is a rabbit hole with never ending topics, let us say that there are 20 topics for you to study for the exam, you are dilligent and does that. But you have limited time and you decided to devote equal time to each topic, the consequence is you may not perform well for the exam due to limited understanding of each topic. Now, if I were to tell you that, hey, out of the 20 topics, can you study these 4 topics, as I think they have a higher chance of coming out, you will likely do better in the exam given that you devoted much more time on those \"focused (attention!)\" topics. The following code explains this methodology with reference to the above images. We first note to the readers that typically, if we use a single head approach, where if we were given a problem set \\(\\mathcal{D} = X \\times y\\) , a hypothesis space \\(\\mathcal{H}\\) we learn from a learning algorithm \\(\\mathcal{A}\\) , producing a final hypothesis \\(g\\) (or h, depends on your notation), that predicts as such \\(g(X_{val}) = y_{\\text{val_pred}}\\) , where each element in \\(y_{\\text{val_pred}}\\) corresponds to the class. Think of the basic MNIST example, our prediction vector's first element corresponds to the probability of it being an 0, and so on and so forth (assuming we use soft labels here). The change here is after the feature extraction layer (i.e. the feature logits after backbone), instead of just connecting it to a linear head for classification, we instead split the 11 outputs to 4 distinct groups. Each group will go through the head independent of the others, and this may prompt the model to put more attention on the independent groups. Finally, we torch.cat(..,axis=1) the outputs after they gone through their respective heads to recover the 11 outputs. model = CustomModel ( config , pretrained = True , load_weight = True , load_url = False , out_dim_heads = [ 3 , 4 , 3 , 1 ], ) # Multi Head for i , out_dim in enumerate ( self . out_dim_heads ): layer_name = f \"head_ { i } \" layer = torch . nn . Sequential ( SpatialAttentionBlock ( in_features , [ 64 , 32 , 16 , 1 ]), torch . nn . AdaptiveAvgPool2d ( output_size = 1 ), torch . nn . Flatten ( start_dim = 1 ), torch . nn . Linear ( in_features , in_features ), self . activation , torch . nn . Dropout ( 0.3 ), torch . nn . Linear ( in_features , out_dim ), ) setattr ( self , layer_name , layer ) def forward ( self , input_neurons ): \"\"\"Define the computation performed at every call.\"\"\" if self . use_custom_layers is False : output_predictions = self . model ( input_neurons ) else : if len ( self . out_dim_heads ) > 1 : output_logits_backbone = self . architecture [ \"backbone\" ]( input_neurons ) multi_outputs = [ getattr ( self , f \"head_ { i } \" )( output_logits_backbone ) for i in range ( self . num_heads ) ] output_predictions = torch . cat ( multi_outputs , axis = 1 ) We built-upon fellow Kaggler Tawara\u2019s Multi-head model for our best scoring models. In particular, we experimented with the activation functions and dropout rates. We found models with Swish activation in the multi-head component of the network to perform > best in our experiments. Our best scoring single model is a multi-head model with a resnet200d backbone. In particular, one single fold of resnet200d gives a private score of 0.970. Another very interesting approach is 3-4 stage training. We did not have time to experiment with the 3-4 stage training as we joined the competition late. Model Architectures: layer = torch.nn.Sequential( SpatialAttentionBlock(in_features, [64, 32, 16, 1]), torch.nn.AdaptiveAvgPool2d(output_size=1), torch.nn.Flatten(start_dim=1), torch.nn.Linear(in_features, in_features), self.activation, torch.nn.Dropout(0.3), torch.nn.Linear(in_features, out_dim), ) - Backbone : ResNet200D and SeResNet152d - Classifier Head: Separated and Independent Spatial-Attention Module and the typical Multi-Layer Perceptron for Target Group (ETT(3), NGT(4), CVC(3), and Swan(1)). - Spatial-Attention Module: SpatialAttentionBlock(in_features, [64, 32, 16, 1]) - MLP: : Linear -> Swish -> Dropout -> Linear ; It is worth noting after the Linear layer, there is a Sigmoid layer in this particular setup as we are using BCEWITHLOGITSLOSS from PyTorch for numerical stability. - Activation: One thing to note is we used Swish in our Classifier Head. Swish is a smooth and non-monotonic function, the latter contrasts when compared to many other activations. I will explain a bit in the next section.","title":"Multi-Head for Multi-Label"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#activation-functions","text":"As we all know, activation functions are used to transform a neurons' linearity to non-linearity and decide whether to \"fire\" a neuron or not. We chose Swish as our main activation function in the classifier head layers.","title":"Activation Functions"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#swish","text":"When we design or choose an activation function, we need to ensure the follows: (Smoothness) Differentiable and Continuous: For example, the sigmoid function is continuous and hence differentiable. If the property is not fulfilled, we might face issues as backpropagation may not be performed properly since we cannot differentiate it.If you notice, the heaviside function is not. We cant perform GD using the HF as we cannot compute gradients but for the logistic function we can. The gradient of sigmoid function g is g(1-g) conveniently Monotonic: This helps the model to converge faster. But spoiler alert, Swish is not monotonic. The properties of Swish are as follows: Bounded below: It is claimed in the paper it serves as a strong regularization. Smoothness: More smooth than ReLU which allows the model to optimize better, the error landscape, when smoothed, is easier to traverse in order to find a minima. An intuitive idea is the hill again, imagine you traverse down Bukit Timah Hill, vs traversing down Mount Himalaya LOL!!! Let us see how swish looks like when plotted. import math import matplotlib.pyplot as plt import numpy as np def swish ( x ): sigmoid = 1 / ( 1 + np . exp ( - x )) swish = x * sigmoid return swish epsilon = 1e-20 x = np . linspace ( - 10 , 10 , 10 ) z = swish ( x ) print ( f \"x= { x } \" ) print ( f \" \\n z=swish(x)= { z } \" ) print ( f \" \\n min z = { min ( z ) } \" ) x=[-10. -7.77777778 -5.55555556 -3.33333333 -1.11111111 1.11111111 3.33333333 5.55555556 7.77777778 10. ] z=swish(x)=[-4.53978687e-04 -3.25707421e-03 -2.13946242e-02 -1.14817319e-01 -2.75182001e-01 8.35929110e-01 3.21851601e+00 5.53416093e+00 7.77452070e+00 9.99954602e+00] min z = -0.27518200126563513 plt . plot ( x , z ) plt . xlabel ( \"x\" ) plt . ylabel ( \"Swish(X)\" ) plt . show ();","title":"Swish"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#model-architecture-final-activation-layer","text":"Sigmoid vs Softmax I've noticed people often get directed to this question when searching whether to use sigmoid vs softmax in neural networks. If you are one of those people building a neural network classifier, here is how to decide whether to apply sigmoid or softmax to the raw output values from your network: If you have a multi-label classification problem = there is more than one \"right answer\" = the outputs are NOT mutually exclusive, then use a sigmoid function on each raw output independently. The sigmoid will allow you to have high probability for all of your classes, some of them, or none of them. Example: classifying diseases in a chest x-ray image. The image might contain pneumonia, emphysema, and/or cancer, or none of those findings. If you have a multi-class classification problem = there is only one \"right answer\" = the outputs are mutually exclusive, then use a softmax function. The softmax will enforce that the sum of the probabilities of your output classes are equal to one, so in order to increase the probability of a particular class, your model must correspondingly decrease the probability of at least one of the other classes. Example: classifying images from the MNIST data set of handwritten digits. A single picture of a digit has only one true identity - the picture cannot be a 7 and an 8 at the same time. In the below code we understand that our model's forward() call gives us a output output_logits of shape (8, 11) if the batch size is 8, and the 11 represents each logit for each of the class. If we apply Softmax to this function on dimension=1 , it simply means we are applying the function each row, from row 1 to 8. Take row 1 for example, the softmax function will squash all the 11 values into a 0-1 range, you can say this is a probability calibration, and the output_predictions is also of shape (8, 11) but all sums up to 1. If we apply Sigmoid to this function on dimension=1 , although PyTorch does not specifiy this because it automatically assumes we are applying sigmoid elementwise, that is to say you cannot simply pass an array of 11 elements to sigmoid function and but we are applying the sigmoid function each row as well. There is a lot of nuance and intricacies here. We take the first row as an example, the first element corresponds to the class ETT-Abnormal , when we apply sigmoid to this element 0.0762, we get 0.5190, and for the second element class ETT-Borderline , we have 0.0877 and when we apply sigmoid, we get 0.5219, so on and so forth for the first row. You should by now observe that they do not sum to 1. This is because each time sigmoid is applied, it is in a one-vs-all scenario. Meaning to say, the 0.519 for ETT-Abnormal means that ETT-Abnormal is treated as the positive class, and the remaining 10 classes are treated as negative class 0. In other words, with 11 elements and sigmoid, we are essentially performing 11 binary classification on the said 11 classes. So 0.519 actually means that the probability of it being class 1 ( ETT-Abnormal ) is 0.519, and the probability of it being NOT class 1 (ALL other classes) is 0.481. The same logic applies to each of the element in the first row. One thing worth noting is that the predictions for row 1 is not mutually exclusive , meaning that from the 11 classes, we can have say, ETT-Abnormal, NGH-Abnormal, CVC-Abnormal to all have say probability score of 0.9, meaning to say, it is highly likely to be all 3 conditions! This is okay and common in X-Ray imaging. In the table dataframe below, I put them into a dataframe for easy visualization. classes = [ \"ETT - Abnormal\" , \"ETT - Borderline\" , \"ETT - Normal\" , \"NGT - Abnormal\" , \"NGT - Borderline\" , \"NGT - Incompletely Imaged\" , \"NGT - Normal\" , \"CVC - Abnormal\" , \"CVC - Borderline\" , \"CVC - Normal\" , \"Swan Ganz Catheter Present\" , ] import torch import pandas as pd output_logits = torch . tensor ([ [ 0.0762 , 0.0877 , 0.1205 , - 0.0615 , - 0.0054 , 0.0661 , 0.1567 , - 0.0978 , 0.0248 , - 0.0350 , 0.0084 ], [ - 0.0196 , - 0.0729 , 0.0534 , 0.0307 , - 0.0428 , - 0.0016 , 0.0013 , - 0.0247 , - 0.0094 , - 0.0424 , 0.0192 ], [ - 0.0125 , - 0.0310 , 0.0118 , - 0.1301 , 0.0418 , 0.0229 , 0.0139 , - 0.0526 , 0.0870 , - 0.0681 , - 0.0068 ], [ - 0.0259 , - 0.0544 , - 0.0262 , 0.0018 , 0.0161 , - 0.0369 , - 0.0370 , - 0.0157 , 0.0036 , - 0.0592 , 0.0107 ], [ - 0.0366 , - 0.0695 , 0.0740 , - 0.0353 , - 0.0363 , - 0.0019 , 0.0085 , - 0.0144 , 0.0129 , - 0.0470 , 0.0043 ], [ - 0.0445 , - 0.0822 , 0.0487 , - 0.0851 , 0.0269 , - 0.0809 , - 0.0434 , 0.0110 , - 0.0631 , - 0.0733 , - 0.0188 ], [ - 0.0304 , 0.0012 , 0.0233 , - 0.0121 , - 0.0406 , - 0.0459 , - 0.0363 , 0.0089 , - 0.0009 , - 0.0797 , - 0.0017 ], [ - 0.0415 , 0.0787 , 0.0283 , - 0.0617 , - 0.0526 , - 0.0016 , - 0.0409 , - 0.0481 , 0.0583 , - 0.0810 , - 0.0050 ]], dtype = torch . float64 , device = device ) sigmoid = torch . nn . Sigmoid () softmax = torch . nn . Softmax ( dim = 1 ) output_predictions_sigmoid = sigmoid ( output_logits ) output_predictions_softmax = softmax ( output_logits ) print ( output_predictions_sigmoid ) print ( output_predictions_softmax ) tensor([[0.5190, 0.5219, 0.5301, 0.4846, 0.4987, 0.5165, 0.5391, 0.4756, 0.5062, 0.4913, 0.5021], [0.4951, 0.4818, 0.5133, 0.5077, 0.4893, 0.4996, 0.5003, 0.4938, 0.4977, 0.4894, 0.5048], [0.4969, 0.4923, 0.5029, 0.4675, 0.5104, 0.5057, 0.5035, 0.4869, 0.5217, 0.4830, 0.4983], [0.4935, 0.4864, 0.4935, 0.5004, 0.5040, 0.4908, 0.4908, 0.4961, 0.5009, 0.4852, 0.5027], [0.4909, 0.4826, 0.5185, 0.4912, 0.4909, 0.4995, 0.5021, 0.4964, 0.5032, 0.4883, 0.5011], [0.4889, 0.4795, 0.5122, 0.4787, 0.5067, 0.4798, 0.4892, 0.5027, 0.4842, 0.4817, 0.4953], [0.4924, 0.5003, 0.5058, 0.4970, 0.4899, 0.4885, 0.4909, 0.5022, 0.4998, 0.4801, 0.4996], [0.4896, 0.5197, 0.5071, 0.4846, 0.4869, 0.4996, 0.4898, 0.4880, 0.5146, 0.4798, 0.4988]], dtype=torch.float64) tensor([[0.0948, 0.0959, 0.0991, 0.0826, 0.0874, 0.0939, 0.1028, 0.0797, 0.0901, 0.0849, 0.0886], [0.0900, 0.0853, 0.0968, 0.0946, 0.0879, 0.0916, 0.0919, 0.0895, 0.0909, 0.0879, 0.0935], [0.0907, 0.0890, 0.0929, 0.0806, 0.0957, 0.0939, 0.0931, 0.0871, 0.1001, 0.0858, 0.0912], [0.0904, 0.0878, 0.0903, 0.0929, 0.0942, 0.0894, 0.0894, 0.0913, 0.0931, 0.0874, 0.0937], [0.0887, 0.0858, 0.0991, 0.0888, 0.0887, 0.0918, 0.0928, 0.0907, 0.0932, 0.0878, 0.0924], [0.0901, 0.0868, 0.0989, 0.0865, 0.0968, 0.0869, 0.0902, 0.0953, 0.0885, 0.0876, 0.0925], [0.0899, 0.0928, 0.0948, 0.0915, 0.0890, 0.0885, 0.0894, 0.0935, 0.0926, 0.0856, 0.0925], [0.0884, 0.0997, 0.0948, 0.0867, 0.0875, 0.0920, 0.0885, 0.0879, 0.0977, 0.0850, 0.0917]], dtype=torch.float64) df = pd . DataFrame ( data = output_predictions_sigmoid . detach () . cpu () . numpy (), columns = classes ) display ( df ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ETT - Abnormal ETT - Borderline ETT - Normal NGT - Abnormal NGT - Borderline NGT - Incompletely Imaged NGT - Normal CVC - Abnormal CVC - Borderline CVC - Normal Swan Ganz Catheter Present 0 0.519041 0.521911 0.530089 0.484630 0.498650 0.516519 0.539095 0.475569 0.506200 0.491251 0.502100 1 0.495100 0.481783 0.513347 0.507674 0.489302 0.499600 0.500325 0.493825 0.497650 0.489402 0.504800 2 0.496875 0.492251 0.502950 0.467521 0.510448 0.505725 0.503475 0.486853 0.521736 0.482982 0.498300 3 0.493525 0.486403 0.493450 0.500450 0.504025 0.490776 0.490751 0.496075 0.500900 0.485204 0.502675 4 0.490851 0.482632 0.518492 0.491176 0.490926 0.499525 0.502125 0.496400 0.503225 0.488252 0.501075 5 0.488877 0.479462 0.512173 0.478738 0.506725 0.479786 0.489152 0.502750 0.484230 0.481683 0.495300 6 0.492401 0.500300 0.505825 0.496975 0.489851 0.488527 0.490926 0.502225 0.499775 0.480086 0.499575 7 0.489626 0.519665 0.507075 0.484580 0.486853 0.499600 0.489776 0.487977 0.514571 0.479761 0.498750","title":"Model Architecture: Final Activation Layer"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#batch-size-and-tricks","text":"Due to hardware limitation, we can barely fit in anything more than a batch_size of 8. Quoting from here : It has been observed in practice that when using a larger batch there is a degradation in the quality of the model, as measured by its ability to generalize [...] large-batch methods tend to converge to sharp minimizers of the training and testing functions\u2014and as is well known, sharp minima lead to poorer generalization. In contrast, small-batch methods consistently converge to flat minimizers, and our experiments support a commonly held view that this is due to the inherent noise in the gradient estimation. The above shows that large batch size may fit the model too well, as the model will learn features of the dataset in less iterations, and may memorize this particular dataset's features, leading to overfitting and poor generalization. However, too small a batch size causes our convergence to go too slow, empirically, we take 32 or 64 as the ideal batch size in this competition. We used both torch.amp and gradient accumulation to be able to fit more batch sizes. We did not freeze the batch_norm layers, which still yielded great results. What we should have done is to experiment more on how to freeze the batch norm layers properly, as I believe that it may help. In the end, we used a batch size of 8 and fit 4 iterations using gradient accumulation and trained a total number of 20 epochs to get a local CV score of roughly 0.969.","title":"Batch Size and Tricks"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#optimizer-scheduler-and-loss","text":"","title":"Optimizer, Scheduler and Loss"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#scheduler","text":"The configuration can be seen here. But note that we incorporated GradualWarmUpScheduler along with CosineAnnealingLR , we also experimented with CosineAnnealingWarmRestarts , the results are similar. From the paper Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour , we learnt about the warmup technique. Although the context of the paper was training under large batch size, we find it helpful even in small batches for the training to converge. The basic algorithm is as follows: Set a base_lr or initial lr for what you want in a model, say 1e-4. If we set our warmup epoch to be 10, then we will start from with 1e-4/10 in the first epoch, and take equal steps each time to converge to 1e-4 in the 10th epoch. After the 10th epoch, warmup ends, we start applying our scheduler's normal steps. However, I took quite some time to understand the idea of gradual warmup, I made my understanding here . We should try OneCyclePolicy as detailed by fastai. num_epochs = 20 CosineAnnealingLR : T_max : num_epochs - 1 eta_min : 1.0e-07 last_epoch : - 1 verbose : true Notice in my configuration above, we set the parameter T_max to be the 19, which is like a one-shot training. import torch import matplotlib.pyplot as plt num_epochs = 20 model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) cosine_annealing_lr_scheduler_one_shot = torch . optim . lr_scheduler . CosineAnnealingLR ( optimizer , T_max = 19 , eta_min = 1e-7 ) cosine_annealing_lr_one_shot = [] for i in range ( num_epochs ): optimizer . step () cosine_annealing_lr_one_shot . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) cosine_annealing_lr_scheduler_one_shot . step () plt . plot ( cosine_annealing_lr_one_shot ); num_epochs = 20 model = torch . nn . Linear ( 2 , 1 ) optimizer = torch . optim . SGD ( model . parameters (), lr = 100 ) cosine_annealing_lr_scheduler_normal = torch . optim . lr_scheduler . CosineAnnealingLR ( optimizer , T_max = 2 , eta_min = 1e-7 ) cosine_annealing_lr_normal = [] for i in range ( num_epochs ): optimizer . step () cosine_annealing_lr_normal . append ( optimizer . param_groups [ 0 ][ \"lr\" ]) # print(\"Factor = \",i,\" , Learning Rate = \",optimizer.param_groups[0][\"lr\"]) cosine_annealing_lr_scheduler_normal . step () plt . plot ( cosine_annealing_lr_normal ) [<matplotlib.lines.Line2D at 0x260cde7e7c0>]","title":"Scheduler"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#loss","text":"We should also experiment with Focal Loss but seeing negative results from fellow Kagglers, on top with limited resources, we did not try it.","title":"Loss"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#ensembling","text":"","title":"Ensembling"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#forward-ensembling","text":"We made use of the Forward Ensembling idea from Chris in SIIM-ISIC Melanoma Classification back in August 2020, I modified the code for this specific task. A simple description is as follows, modified from Chris, with more mathematical notations. We start off with a dataset \\(\\mathcal{D} = X \\times y\\) where it is sampled from the true population \\(\\mathcal{X} \\times \\mathcal{Y}\\) . We apply KFold (5 splits) to the dataset, as illustrated in the diagram. We can now train five different hypothesis \\(h_{F1}, h_{F2},...,h_{F5}\\) , where \\(h_{F1}\\) is trained on Fold 2 to Fold 5 and predict on Fold 1, \\(h_{F2}\\) is trained on Fold 1,3,4,5 and predict on Fold 2. The logic follows for all 5 hypothesis. Notice that in the five models, we are predicting on a unique validation fold, and as a result, after we trained all 5 folds, we will have the predictions made on the whole training set (F1-F5). This predictions is called the Out-of-Fold predictions. We then go a step further and calculate the AUC score with the OOF predictions with the ground truth to get the OOF AUC. We save it to a csv or dataframe called oof_1.csv , subsequent oof trained on different hypothesis space should be named oof_i.csv where \\(i \\in [2,3,...]\\) . After we trained all 5 folds, we will use \\(h_{1}\\) to predict on \\(X_{test}\\) and obtain predictions \\(Y_{\\text{h1 preds}}\\) , we then use \\(h_{2}\\) to predict on \\(X_{test}\\) and obtain predictions \\(Y_{\\text{h2 preds}}\\) , we do this for all five folds and finally \\(Y_{\\text{final preds}} = \\dfrac{1}{5}\\sum_{i=1}^{5}Y_{\\text{hi preds}}\\) . This is a typical pipeline in most machine learning problems. We save this final predictions as sub_1.csv , subsequence predictions trained on different hypothesis space should be named sub_i.csv where \\(i \\in [2,3,...]\\) . Now if we train another model, a completely different hypothesis space is used, to be more pedantic, we denote the previous model to be taken from the hypothesis space \\(\\mathcal{H}_{1}\\) , and now we move on to \\(\\mathcal{H}_{2}\\) . We repeat step 1-6 on this new model (Note that you are essentially training 10 \"models\" now since we are doing KFold twice, and oh, please set the seed of KFold to be the same, it should never be the case that both model comes from different splitting seed for apparent reasons). Here is the key (given the above setup with 2 different models trained on 5 folds): Normally, most people do a simple mean ensemble, that is \\(\\dfrac{Y_{\\text{final preds H1}} + Y_{\\text{final preds H2}}}{2}\\) . This works well most of the time as we trust both model holds equal importance in the final predictions. One issue may be that certain models should be weighted more than the rest, we should not simply take Leaderboard feedback score to judge the weight assignment. A general heuristic here is called Forward Selection. (Extract from Chris) Now say that you build 2 models (that means that you did 5 KFold twice). You now have oof_1.csv, oof_2.csv, sub_1.csv, and sub_2.csv. How do we blend the two models? We find the weight w such that w * oof_1.predictions + (1-w) * oof_2.predictions has the largest AUC. all = [] for w in [ 0.00 , 0.01 , 0.02 , ... , 0.98 , 0.99 , 1.00 ]: ensemble_pred = w * oof_1 . predictions + ( 1 - w ) * oof_2 . predictions ensemble_auc = roc_auc_score ( oof . target , ensemble_pred ) all . append ( ensemble_auc ) best_weight = np . argmax ( all ) / 100. Then we can assign the best weight like: final_ensemble_pred = best_weight * sub_1 . target + ( 1 - best_weight ) * sub_2 . target Coutersy of Chris In this competition, there are two approaches, either maximize the average of the macro AUC score of all the classes, or maximize each column/class separately. It turns out that maximizing the columns separately led to disastrous results (it could be my code and idea is wrong, as ROC is a ranking metric).","title":"Forward Ensembling"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#conclusion","text":"What we could have done better: Use more variety of classifier head like GeM . Use more variety of backbone . Use Neptune.ai to log our experiments as soon things start to get messy. Basically MLOps is important! Experiment on 3-4 stage training. Pseudo Labelling. Knowledge Distillation. Experiment more on maximizing AUC during ensembles. rank_pct etc. See novel three stage training: https://www.kaggle.com/yasufuminakama/ranzcr-resnet200d-3-stage-training-step1","title":"Conclusion"},{"location":"reighns_ml_journey/projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/#references","text":"Multi-Head Deep Learning Model with Multi-Label Classification AUC Metric on Multi-Label Sigmoid and Softmax for Multi-Label Multi-Label Classification Tutorial Why we should use Multi-Head in Multi-Label Classification Follow Up 1 Follow Up 2 Follow Up 3 Sigmoid is Binary Cross Entropy Attention Blocks in Computer Vision Spatial Attention Blocks Spatial Attention Module Convolutional Block Attention Module [Dive Into Deep Learning - Chapter 10: Attention Mechanisms] Gradual Warmup: Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour","title":"References"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/model_summary/","text":"Model Architectures, Training Parameters No Meta Data Model Architecture For models that did not make use of meta data, we have the following architecture. No Meta Data Model Architecture. Meta Data Model Architecture For models that did made use of meta data, we have the following architecture. Meta Data Model Architecture. We concat the flattened feature maps with the meta features: Meta Features : [ 'sex' , 'age_approx' , 'site_head/neck' , 'site_lower extremity' , 'site_oral/genital' , 'site_palms/soles' , 'site_torso' , 'site_upper extremity' , 'site_nan' ] and the meta features has its own sequential layers as ANN: OrderedDict ( [ ( \"fc1\" , torch . nn . Linear ( self . num_meta_features , 512 ), ), ( \"bn1\" , torch . nn . BatchNorm1d ( 512 ), ), ( \"swish1\" , torch . nn . SiLU (), ), ( \"dropout1\" , torch . nn . Dropout ( p = 0.3 ), ), ( \"fc2\" , torch . nn . Linear ( 512 , 128 ), ), ( \"bn2\" , torch . nn . BatchNorm1d ( 128 ), ), ( \"swish2\" , torch . nn . SiLU (), ), ] ) For example: image shape: \\([32, 3, 256, 256]\\) meta_inputs shape: \\([32, 9]\\) we have 9 features. feature_logits shape: \\([32, 1280]\\) flattened feature maps at the last conv layer. meta_logits shape: \\([32, 128]\\) where we passed in a small sequential ANN for the meta data. concat_logits shape: \\([32, 1280 + 128]\\) if self . use_meta : # from cnn images feature_logits = self . extract_features ( image ) # from meta features meta_logits = self . meta_layer ( meta_inputs ) # concatenate concat_logits = torch . cat (( feature_logits , meta_logits ), dim = 1 ) # classifier head classifier_logits = self . architecture [ \"head\" ]( concat_logits ) Activation Functions As we all know, activation functions are used to transform a neurons' linearity to non-linearity and decide whether to \"fire\" a neuron or not. When we design or choose an activation function, we need to ensure the follows: (Smoothness) Differentiable and Continuous: For example, the sigmoid function is continuous and hence differentiable. If the property is not fulfilled, we might face issues as backpropagation may not be performed properly since we cannot differentiate it.If you notice, the heaviside function is not. We cant perform GD using the HF as we cannot compute gradients but for the logistic function we can. The gradient of sigmoid function g is g(1-g) conveniently Monotonic: This helps the model to converge faster. But spoiler alert, Swish is not monotonic. The properties of Swish are as follows: Bounded below: It is claimed in the paper it serves as a strong regularization. Smoothness: More smooth than ReLU which allows the model to optimize better, the error landscape, when smoothed, is easier to traverse in order to find a minima. An intuitive idea is the hill again, imagine you traverse down your neighbourhood hill, vs traversing down Mount Himalaya. # Import matplotlib, numpy and math import matplotlib.pyplot as plt import numpy as np import math def swish ( x ): sigmoid = 1 / ( 1 + np . exp ( - x )) swish = x * sigmoid return swish epsilon = 1e-20 x = np . linspace ( - 100 , 100 , 100 ) z = swish ( x ) print ( z ) print ( min ( z )) plt . plot ( x , z ) plt . xlabel ( \"x\" ) plt . ylabel ( \"Swish(X)\" ) plt . show () ! pip install torchinfo Collecting torchinfo Downloading torchinfo-1.6.3-py3-none-any.whl (20 kB) Installing collected packages: torchinfo Successfully installed torchinfo-1.6.3 WARNING: You are using pip version 21.3.1; however, version 22.0.3 is available. You should consider upgrading via the 'C:\\Users\\reighns\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command. import timm from dataclasses import asdict , dataclass , field from pathlib import Path from typing import Any , Dict , List , Union import torchinfo import torch # Utility functions. import gc import json import os import random from pathlib import Path , PurePath from typing import Dict , Union , List import numpy as np import torch def seed_all ( seed : int = 1992 ) -> None : \"\"\"Seed all random number generators.\"\"\" print ( f \"Using Seed Number { seed } \" ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator # set fixed value for python built-in pseudo-random generator random . seed ( seed ) torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False torch . backends . cudnn . enabled = False seed_all () Using Seed Number 1992 @dataclass class ModelParams : \"\"\"A class to track model parameters. model_name (str): name of the model. pretrained (bool): If True, use pretrained model. input_channels (int): RGB image - 3 channels or Grayscale 1 channel output_dimension (int): Final output neuron. It is the number of classes in classification. Caution: If you use sigmoid layer for Binary, then it is 1. classification_type (str): classification type. \"\"\" model_name : str = \"resnet50d\" # resnet50d resnext50_32x4d \"tf_efficientnet_b0_ns\" # Debug use tf_efficientnet_b0_ns else tf_efficientnet_b4_ns vgg16 pretrained : bool = True input_channels : int = 3 output_dimension : int = 2 classification_type : str = \"multiclass\" use_meta : bool = False def to_dict ( self ) -> Dict [ str , Any ]: \"\"\"Convert to dictionary.\"\"\" return asdict ( self ) MODEL_PARAMS = ModelParams () class CustomNeuralNet ( torch . nn . Module ): def __init__ ( self , model_name : str = MODEL_PARAMS . model_name , out_features : int = MODEL_PARAMS . output_dimension , in_channels : int = MODEL_PARAMS . input_channels , pretrained : bool = MODEL_PARAMS . pretrained , use_meta : bool = MODEL_PARAMS . use_meta , ): \"\"\"Construct a new model. Args: model_name ([type], str): The name of the model to use. Defaults to MODEL_PARAMS.model_name. out_features ([type], int): The number of output features, this is usually the number of classes, but if you use sigmoid, then the output is 1. Defaults to MODEL_PARAMS.output_dimension. in_channels ([type], int): The number of input channels; RGB = 3, Grayscale = 1. Defaults to MODEL_PARAMS.input_channels. pretrained ([type], bool): If True, use pretrained model. Defaults to MODEL_PARAMS.pretrained. \"\"\" super () . __init__ () self . in_channels = in_channels self . pretrained = pretrained self . use_meta = use_meta self . backbone = timm . create_model ( model_name , pretrained = self . pretrained , in_chans = self . in_channels ) # removes head from backbone: # TODO: Global pool = \"avg\" vs \"\" behaves differently in shape, caution! self . backbone . reset_classifier ( num_classes = 0 , global_pool = \"avg\" ) # get the last layer's number of features in backbone (feature map) self . in_features = self . backbone . num_features self . out_features = out_features # Custom Head self . single_head_fc = torch . nn . Sequential ( torch . nn . Linear ( self . in_features , self . out_features ), ) self . architecture : Dict [ str , Callable ] = { \"backbone\" : self . backbone , \"bottleneck\" : None , \"head\" : self . single_head_fc , } def extract_features ( self , image : torch . FloatTensor ) -> torch . FloatTensor : \"\"\"Extract the features mapping logits from the model. This is the output from the backbone of a CNN. Args: image (torch.FloatTensor): The input image. Returns: feature_logits (torch.FloatTensor): The features logits. \"\"\" # TODO: To rename feature_logits to image embeddings, also find out what is image embedding. feature_logits = self . architecture [ \"backbone\" ]( image ) print ( f \"feature logits shape = { feature_logits . shape } \" ) return feature_logits def forward ( self , image : torch . FloatTensor ) -> torch . FloatTensor : \"\"\"The forward call of the model. Args: image (torch.FloatTensor): The input image. Returns: classifier_logits (torch.FloatTensor): The output logits of the classifier head. \"\"\" feature_logits = self . extract_features ( image ) classifier_logits = self . architecture [ \"head\" ]( feature_logits ) print ( f \"classifier_logits shape = { classifier_logits . shape } \" ) return classifier_logits model = CustomNeuralNet () batch_size , channel , height , width = 8 , 3 , 256 , 256 X = torch . randn (( batch_size , channel , height , width )) y = model ( image = X ) feature logits shape = torch.Size([8, 2048]) classifier_logits shape = torch.Size([8, 2]) _ = torchinfo . summary ( model , ( batch_size , channel , height , width ), col_names = [ \"input_size\" , \"output_size\" , \"num_params\" , \"kernel_size\" , \"mult_adds\" , ], depth = 3 , verbose = 1 ) torch.Size([8, 2048]) torch.Size([8, 2]) ========================================================================================================================================================================== Layer (type:depth-idx) Input Shape Output Shape Param # Kernel Shape Mult-Adds ========================================================================================================================================================================== CustomNeuralNet -- -- -- -- -- \u251c\u2500ResNet: 1-1 [8, 3, 256, 256] [8, 2048] -- -- -- \u2502 \u2514\u2500Sequential: 2-1 [8, 3, 256, 256] [8, 64, 128, 128] -- -- -- \u2502 \u2502 \u2514\u2500Conv2d: 3-1 [8, 3, 256, 256] [8, 32, 128, 128] 864 [3, 32, 3, 3] 113,246,208 \u2502 \u2502 \u2514\u2500BatchNorm2d: 3-2 [8, 32, 128, 128] [8, 32, 128, 128] 64 [32] 512 \u2502 \u2502 \u2514\u2500ReLU: 3-3 [8, 32, 128, 128] [8, 32, 128, 128] -- -- -- \u2502 \u2502 \u2514\u2500Conv2d: 3-4 [8, 32, 128, 128] [8, 32, 128, 128] 9,216 [32, 32, 3, 3] 1,207,959,552 \u2502 \u2502 \u2514\u2500BatchNorm2d: 3-5 [8, 32, 128, 128] [8, 32, 128, 128] 64 [32] 512 \u2502 \u2502 \u2514\u2500ReLU: 3-6 [8, 32, 128, 128] [8, 32, 128, 128] -- -- -- \u2502 \u2502 \u2514\u2500Conv2d: 3-7 [8, 32, 128, 128] [8, 64, 128, 128] 18,432 [32, 64, 3, 3] 2,415,919,104 \u2502 \u2514\u2500BatchNorm2d: 2-2 [8, 64, 128, 128] [8, 64, 128, 128] 128 [64] 1,024 \u2502 \u2514\u2500ReLU: 2-3 [8, 64, 128, 128] [8, 64, 128, 128] -- -- -- \u2502 \u2514\u2500MaxPool2d: 2-4 [8, 64, 128, 128] [8, 64, 64, 64] -- -- -- \u2502 \u2514\u2500Sequential: 2-5 [8, 64, 64, 64] [8, 256, 64, 64] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-8 [8, 64, 64, 64] [8, 256, 64, 64] 75,008 -- 2,415,929,344 \u2502 \u2502 \u2514\u2500Bottleneck: 3-9 [8, 256, 64, 64] [8, 256, 64, 64] 70,400 -- 2,281,707,520 \u2502 \u2502 \u2514\u2500Bottleneck: 3-10 [8, 256, 64, 64] [8, 256, 64, 64] 70,400 -- 2,281,707,520 \u2502 \u2514\u2500Sequential: 2-6 [8, 256, 64, 64] [8, 512, 32, 32] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-11 [8, 256, 64, 64] [8, 512, 32, 32] 379,392 -- 3,892,334,592 \u2502 \u2502 \u2514\u2500Bottleneck: 3-12 [8, 512, 32, 32] [8, 512, 32, 32] 280,064 -- 2,281,713,664 \u2502 \u2502 \u2514\u2500Bottleneck: 3-13 [8, 512, 32, 32] [8, 512, 32, 32] 280,064 -- 2,281,713,664 \u2502 \u2502 \u2514\u2500Bottleneck: 3-14 [8, 512, 32, 32] [8, 512, 32, 32] 280,064 -- 2,281,713,664 \u2502 \u2514\u2500Sequential: 2-7 [8, 512, 32, 32] [8, 1024, 16, 16] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-15 [8, 512, 32, 32] [8, 1024, 16, 16] 1,512,448 -- 3,892,355,072 \u2502 \u2502 \u2514\u2500Bottleneck: 3-16 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-17 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-18 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-19 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-20 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2514\u2500Sequential: 2-8 [8, 1024, 16, 16] [8, 2048, 8, 8] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-21 [8, 1024, 16, 16] [8, 2048, 8, 8] 6,039,552 -- 3,892,396,032 \u2502 \u2502 \u2514\u2500Bottleneck: 3-22 [8, 2048, 8, 8] [8, 2048, 8, 8] 4,462,592 -- 2,281,750,528 \u2502 \u2502 \u2514\u2500Bottleneck: 3-23 [8, 2048, 8, 8] [8, 2048, 8, 8] 4,462,592 -- 2,281,750,528 \u2502 \u2514\u2500SelectAdaptivePool2d: 2-9 [8, 2048, 8, 8] [8, 2048] -- -- -- \u2502 \u2502 \u2514\u2500AdaptiveAvgPool2d: 3-24 [8, 2048, 8, 8] [8, 2048, 1, 1] -- -- -- \u2502 \u2502 \u2514\u2500Flatten: 3-25 [8, 2048, 1, 1] [8, 2048] -- -- -- \u2502 \u2514\u2500Identity: 2-10 [8, 2048] [8, 2048] -- -- -- \u251c\u2500Sequential: 1-2 [8, 2048] [8, 2] -- -- -- \u2502 \u2514\u2500Linear: 2-11 [8, 2048] [8, 2] 4,098 [2048, 2] 32,784 ========================================================================================================================================================================== Total params: 23,531,362 Trainable params: 23,531,362 Non-trainable params: 0 Total mult-adds (G): 45.21 ========================================================================================================================================================================== Input size (MB): 6.29 Forward/backward pass size (MB): 1992.29 Params size (MB): 94.13 Estimated Total Size (MB): 2092.71 ========================================================================================================================================================================== This model architechure means that if I pass in a batch of \\(8\\) images of size \\((3, 256, 256)\\) , the model statistics will tell us a lot of information. Let us give some examples with a naive ResNet50d . Input Shape: \\([8, 3, 256, 256]\\) passing through the first Sequential Layer's Conv2d (3-1) with kernel size of Kernel Shape: \\([3, 32, 3, 3]\\) which means \\([\\textbf{in_channels, out_channels, kernel_size, kernel_size}]\\) will yield an output shape of Output Shape: \\([8, 32, 128, 128]\\) indicating that the each input images are now transformed into 32 kernels of size 256 by 256. Params: The Params column calculates the number of parameters in this layer at 864 learnable parameters. Once we know how to interpret the table, we can also see that our CustomNeuralnet() has extract_features which outputs the input at the last convolutional layer, in this example, it is at SelectAdaptivePool2d: 2-9 where it first went through AdaptiveAvgPool2d: 3-24 to squash the feature maps to \\([8, 2048, 1, 1]\\) and subsequently a Flatten: 3-25 layer to flatten out the last 2 dimensions to become \\([8, 2048]\\) so we can pass on to the dense layers. We can verify this by X = torch . randn (( batch_size , channel , height , width )) y = model ( image = X ) yielding feature logits shape = torch . Size ([ 8 , 2048 ]) classifier_logits shape = torch . Size ([ 8 , 2 ]) where the latter is the final shape of the input after passing through all the dense layers at \\([8, 2]\\) , where one can envision it as 2 output neurons.","title":"Model summary"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/model_summary/#model-architectures-training-parameters","text":"","title":"Model Architectures, Training Parameters"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/model_summary/#no-meta-data-model-architecture","text":"For models that did not make use of meta data, we have the following architecture. No Meta Data Model Architecture.","title":"No Meta Data Model Architecture"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/model_summary/#meta-data-model-architecture","text":"For models that did made use of meta data, we have the following architecture. Meta Data Model Architecture. We concat the flattened feature maps with the meta features: Meta Features : [ 'sex' , 'age_approx' , 'site_head/neck' , 'site_lower extremity' , 'site_oral/genital' , 'site_palms/soles' , 'site_torso' , 'site_upper extremity' , 'site_nan' ] and the meta features has its own sequential layers as ANN: OrderedDict ( [ ( \"fc1\" , torch . nn . Linear ( self . num_meta_features , 512 ), ), ( \"bn1\" , torch . nn . BatchNorm1d ( 512 ), ), ( \"swish1\" , torch . nn . SiLU (), ), ( \"dropout1\" , torch . nn . Dropout ( p = 0.3 ), ), ( \"fc2\" , torch . nn . Linear ( 512 , 128 ), ), ( \"bn2\" , torch . nn . BatchNorm1d ( 128 ), ), ( \"swish2\" , torch . nn . SiLU (), ), ] ) For example: image shape: \\([32, 3, 256, 256]\\) meta_inputs shape: \\([32, 9]\\) we have 9 features. feature_logits shape: \\([32, 1280]\\) flattened feature maps at the last conv layer. meta_logits shape: \\([32, 128]\\) where we passed in a small sequential ANN for the meta data. concat_logits shape: \\([32, 1280 + 128]\\) if self . use_meta : # from cnn images feature_logits = self . extract_features ( image ) # from meta features meta_logits = self . meta_layer ( meta_inputs ) # concatenate concat_logits = torch . cat (( feature_logits , meta_logits ), dim = 1 ) # classifier head classifier_logits = self . architecture [ \"head\" ]( concat_logits )","title":"Meta Data Model Architecture"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/model_summary/#activation-functions","text":"As we all know, activation functions are used to transform a neurons' linearity to non-linearity and decide whether to \"fire\" a neuron or not. When we design or choose an activation function, we need to ensure the follows: (Smoothness) Differentiable and Continuous: For example, the sigmoid function is continuous and hence differentiable. If the property is not fulfilled, we might face issues as backpropagation may not be performed properly since we cannot differentiate it.If you notice, the heaviside function is not. We cant perform GD using the HF as we cannot compute gradients but for the logistic function we can. The gradient of sigmoid function g is g(1-g) conveniently Monotonic: This helps the model to converge faster. But spoiler alert, Swish is not monotonic. The properties of Swish are as follows: Bounded below: It is claimed in the paper it serves as a strong regularization. Smoothness: More smooth than ReLU which allows the model to optimize better, the error landscape, when smoothed, is easier to traverse in order to find a minima. An intuitive idea is the hill again, imagine you traverse down your neighbourhood hill, vs traversing down Mount Himalaya. # Import matplotlib, numpy and math import matplotlib.pyplot as plt import numpy as np import math def swish ( x ): sigmoid = 1 / ( 1 + np . exp ( - x )) swish = x * sigmoid return swish epsilon = 1e-20 x = np . linspace ( - 100 , 100 , 100 ) z = swish ( x ) print ( z ) print ( min ( z )) plt . plot ( x , z ) plt . xlabel ( \"x\" ) plt . ylabel ( \"Swish(X)\" ) plt . show () ! pip install torchinfo Collecting torchinfo Downloading torchinfo-1.6.3-py3-none-any.whl (20 kB) Installing collected packages: torchinfo Successfully installed torchinfo-1.6.3 WARNING: You are using pip version 21.3.1; however, version 22.0.3 is available. You should consider upgrading via the 'C:\\Users\\reighns\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command. import timm from dataclasses import asdict , dataclass , field from pathlib import Path from typing import Any , Dict , List , Union import torchinfo import torch # Utility functions. import gc import json import os import random from pathlib import Path , PurePath from typing import Dict , Union , List import numpy as np import torch def seed_all ( seed : int = 1992 ) -> None : \"\"\"Seed all random number generators.\"\"\" print ( f \"Using Seed Number { seed } \" ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator # set fixed value for python built-in pseudo-random generator random . seed ( seed ) torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False torch . backends . cudnn . enabled = False seed_all () Using Seed Number 1992 @dataclass class ModelParams : \"\"\"A class to track model parameters. model_name (str): name of the model. pretrained (bool): If True, use pretrained model. input_channels (int): RGB image - 3 channels or Grayscale 1 channel output_dimension (int): Final output neuron. It is the number of classes in classification. Caution: If you use sigmoid layer for Binary, then it is 1. classification_type (str): classification type. \"\"\" model_name : str = \"resnet50d\" # resnet50d resnext50_32x4d \"tf_efficientnet_b0_ns\" # Debug use tf_efficientnet_b0_ns else tf_efficientnet_b4_ns vgg16 pretrained : bool = True input_channels : int = 3 output_dimension : int = 2 classification_type : str = \"multiclass\" use_meta : bool = False def to_dict ( self ) -> Dict [ str , Any ]: \"\"\"Convert to dictionary.\"\"\" return asdict ( self ) MODEL_PARAMS = ModelParams () class CustomNeuralNet ( torch . nn . Module ): def __init__ ( self , model_name : str = MODEL_PARAMS . model_name , out_features : int = MODEL_PARAMS . output_dimension , in_channels : int = MODEL_PARAMS . input_channels , pretrained : bool = MODEL_PARAMS . pretrained , use_meta : bool = MODEL_PARAMS . use_meta , ): \"\"\"Construct a new model. Args: model_name ([type], str): The name of the model to use. Defaults to MODEL_PARAMS.model_name. out_features ([type], int): The number of output features, this is usually the number of classes, but if you use sigmoid, then the output is 1. Defaults to MODEL_PARAMS.output_dimension. in_channels ([type], int): The number of input channels; RGB = 3, Grayscale = 1. Defaults to MODEL_PARAMS.input_channels. pretrained ([type], bool): If True, use pretrained model. Defaults to MODEL_PARAMS.pretrained. \"\"\" super () . __init__ () self . in_channels = in_channels self . pretrained = pretrained self . use_meta = use_meta self . backbone = timm . create_model ( model_name , pretrained = self . pretrained , in_chans = self . in_channels ) # removes head from backbone: # TODO: Global pool = \"avg\" vs \"\" behaves differently in shape, caution! self . backbone . reset_classifier ( num_classes = 0 , global_pool = \"avg\" ) # get the last layer's number of features in backbone (feature map) self . in_features = self . backbone . num_features self . out_features = out_features # Custom Head self . single_head_fc = torch . nn . Sequential ( torch . nn . Linear ( self . in_features , self . out_features ), ) self . architecture : Dict [ str , Callable ] = { \"backbone\" : self . backbone , \"bottleneck\" : None , \"head\" : self . single_head_fc , } def extract_features ( self , image : torch . FloatTensor ) -> torch . FloatTensor : \"\"\"Extract the features mapping logits from the model. This is the output from the backbone of a CNN. Args: image (torch.FloatTensor): The input image. Returns: feature_logits (torch.FloatTensor): The features logits. \"\"\" # TODO: To rename feature_logits to image embeddings, also find out what is image embedding. feature_logits = self . architecture [ \"backbone\" ]( image ) print ( f \"feature logits shape = { feature_logits . shape } \" ) return feature_logits def forward ( self , image : torch . FloatTensor ) -> torch . FloatTensor : \"\"\"The forward call of the model. Args: image (torch.FloatTensor): The input image. Returns: classifier_logits (torch.FloatTensor): The output logits of the classifier head. \"\"\" feature_logits = self . extract_features ( image ) classifier_logits = self . architecture [ \"head\" ]( feature_logits ) print ( f \"classifier_logits shape = { classifier_logits . shape } \" ) return classifier_logits model = CustomNeuralNet () batch_size , channel , height , width = 8 , 3 , 256 , 256 X = torch . randn (( batch_size , channel , height , width )) y = model ( image = X ) feature logits shape = torch.Size([8, 2048]) classifier_logits shape = torch.Size([8, 2]) _ = torchinfo . summary ( model , ( batch_size , channel , height , width ), col_names = [ \"input_size\" , \"output_size\" , \"num_params\" , \"kernel_size\" , \"mult_adds\" , ], depth = 3 , verbose = 1 ) torch.Size([8, 2048]) torch.Size([8, 2]) ========================================================================================================================================================================== Layer (type:depth-idx) Input Shape Output Shape Param # Kernel Shape Mult-Adds ========================================================================================================================================================================== CustomNeuralNet -- -- -- -- -- \u251c\u2500ResNet: 1-1 [8, 3, 256, 256] [8, 2048] -- -- -- \u2502 \u2514\u2500Sequential: 2-1 [8, 3, 256, 256] [8, 64, 128, 128] -- -- -- \u2502 \u2502 \u2514\u2500Conv2d: 3-1 [8, 3, 256, 256] [8, 32, 128, 128] 864 [3, 32, 3, 3] 113,246,208 \u2502 \u2502 \u2514\u2500BatchNorm2d: 3-2 [8, 32, 128, 128] [8, 32, 128, 128] 64 [32] 512 \u2502 \u2502 \u2514\u2500ReLU: 3-3 [8, 32, 128, 128] [8, 32, 128, 128] -- -- -- \u2502 \u2502 \u2514\u2500Conv2d: 3-4 [8, 32, 128, 128] [8, 32, 128, 128] 9,216 [32, 32, 3, 3] 1,207,959,552 \u2502 \u2502 \u2514\u2500BatchNorm2d: 3-5 [8, 32, 128, 128] [8, 32, 128, 128] 64 [32] 512 \u2502 \u2502 \u2514\u2500ReLU: 3-6 [8, 32, 128, 128] [8, 32, 128, 128] -- -- -- \u2502 \u2502 \u2514\u2500Conv2d: 3-7 [8, 32, 128, 128] [8, 64, 128, 128] 18,432 [32, 64, 3, 3] 2,415,919,104 \u2502 \u2514\u2500BatchNorm2d: 2-2 [8, 64, 128, 128] [8, 64, 128, 128] 128 [64] 1,024 \u2502 \u2514\u2500ReLU: 2-3 [8, 64, 128, 128] [8, 64, 128, 128] -- -- -- \u2502 \u2514\u2500MaxPool2d: 2-4 [8, 64, 128, 128] [8, 64, 64, 64] -- -- -- \u2502 \u2514\u2500Sequential: 2-5 [8, 64, 64, 64] [8, 256, 64, 64] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-8 [8, 64, 64, 64] [8, 256, 64, 64] 75,008 -- 2,415,929,344 \u2502 \u2502 \u2514\u2500Bottleneck: 3-9 [8, 256, 64, 64] [8, 256, 64, 64] 70,400 -- 2,281,707,520 \u2502 \u2502 \u2514\u2500Bottleneck: 3-10 [8, 256, 64, 64] [8, 256, 64, 64] 70,400 -- 2,281,707,520 \u2502 \u2514\u2500Sequential: 2-6 [8, 256, 64, 64] [8, 512, 32, 32] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-11 [8, 256, 64, 64] [8, 512, 32, 32] 379,392 -- 3,892,334,592 \u2502 \u2502 \u2514\u2500Bottleneck: 3-12 [8, 512, 32, 32] [8, 512, 32, 32] 280,064 -- 2,281,713,664 \u2502 \u2502 \u2514\u2500Bottleneck: 3-13 [8, 512, 32, 32] [8, 512, 32, 32] 280,064 -- 2,281,713,664 \u2502 \u2502 \u2514\u2500Bottleneck: 3-14 [8, 512, 32, 32] [8, 512, 32, 32] 280,064 -- 2,281,713,664 \u2502 \u2514\u2500Sequential: 2-7 [8, 512, 32, 32] [8, 1024, 16, 16] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-15 [8, 512, 32, 32] [8, 1024, 16, 16] 1,512,448 -- 3,892,355,072 \u2502 \u2502 \u2514\u2500Bottleneck: 3-16 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-17 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-18 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-19 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-20 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2514\u2500Sequential: 2-8 [8, 1024, 16, 16] [8, 2048, 8, 8] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-21 [8, 1024, 16, 16] [8, 2048, 8, 8] 6,039,552 -- 3,892,396,032 \u2502 \u2502 \u2514\u2500Bottleneck: 3-22 [8, 2048, 8, 8] [8, 2048, 8, 8] 4,462,592 -- 2,281,750,528 \u2502 \u2502 \u2514\u2500Bottleneck: 3-23 [8, 2048, 8, 8] [8, 2048, 8, 8] 4,462,592 -- 2,281,750,528 \u2502 \u2514\u2500SelectAdaptivePool2d: 2-9 [8, 2048, 8, 8] [8, 2048] -- -- -- \u2502 \u2502 \u2514\u2500AdaptiveAvgPool2d: 3-24 [8, 2048, 8, 8] [8, 2048, 1, 1] -- -- -- \u2502 \u2502 \u2514\u2500Flatten: 3-25 [8, 2048, 1, 1] [8, 2048] -- -- -- \u2502 \u2514\u2500Identity: 2-10 [8, 2048] [8, 2048] -- -- -- \u251c\u2500Sequential: 1-2 [8, 2048] [8, 2] -- -- -- \u2502 \u2514\u2500Linear: 2-11 [8, 2048] [8, 2] 4,098 [2048, 2] 32,784 ========================================================================================================================================================================== Total params: 23,531,362 Trainable params: 23,531,362 Non-trainable params: 0 Total mult-adds (G): 45.21 ========================================================================================================================================================================== Input size (MB): 6.29 Forward/backward pass size (MB): 1992.29 Params size (MB): 94.13 Estimated Total Size (MB): 2092.71 ========================================================================================================================================================================== This model architechure means that if I pass in a batch of \\(8\\) images of size \\((3, 256, 256)\\) , the model statistics will tell us a lot of information. Let us give some examples with a naive ResNet50d . Input Shape: \\([8, 3, 256, 256]\\) passing through the first Sequential Layer's Conv2d (3-1) with kernel size of Kernel Shape: \\([3, 32, 3, 3]\\) which means \\([\\textbf{in_channels, out_channels, kernel_size, kernel_size}]\\) will yield an output shape of Output Shape: \\([8, 32, 128, 128]\\) indicating that the each input images are now transformed into 32 kernels of size 256 by 256. Params: The Params column calculates the number of parameters in this layer at 864 learnable parameters. Once we know how to interpret the table, we can also see that our CustomNeuralnet() has extract_features which outputs the input at the last convolutional layer, in this example, it is at SelectAdaptivePool2d: 2-9 where it first went through AdaptiveAvgPool2d: 3-24 to squash the feature maps to \\([8, 2048, 1, 1]\\) and subsequently a Flatten: 3-25 layer to flatten out the last 2 dimensions to become \\([8, 2048]\\) so we can pass on to the dense layers. We can verify this by X = torch . randn (( batch_size , channel , height , width )) y = model ( image = X ) yielding feature logits shape = torch . Size ([ 8 , 2048 ]) classifier_logits shape = torch . Size ([ 8 , 2 ]) where the latter is the final shape of the input after passing through all the dense layers at \\([8, 2]\\) , where one can envision it as 2 output neurons.","title":"Activation Functions"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/","text":"SIIM-ISIC Melanoma Classification This competition is hosted on Kaggle and the description and overview is stated below . Skin cancer is the most prevalent type of cancer. Melanoma, specifically, is responsible for 75% of skin cancer deaths, despite being the least common skin cancer. The American Cancer Society estimates over 100,000 new melanoma cases will be diagnosed in 2020. It's also expected that almost 7,000 people will die from the disease. As with other cancers, early and accurate detection\u2014potentially aided by data science\u2014can make treatment more effective. Currently, dermatologists evaluate every one of a patient's moles to identify outlier lesions or \u201cugly ducklings\u201d that are most likely to be melanoma. Existing AI approaches have not adequately considered this clinical frame of reference. Dermatologists could enhance their diagnostic accuracy if detection algorithms take into account \u201ccontextual\u201d images within the same patient to determine which images represent a melanoma. If successful, classifiers would be more accurate and could better support dermatological clinic work. As the leading healthcare organization for informatics in medical imaging, the Society for Imaging Informatics in Medicine (SIIM)'s mission is to advance medical imaging informatics through education, research, and innovation in a multi-disciplinary community. SIIM is joined by the International Skin Imaging Collaboration (ISIC), an international effort to improve melanoma diagnosis. The ISIC Archive contains the largest publicly available collection of quality-controlled dermoscopic images of skin lesions. In this competition, you\u2019ll identify melanoma in images of skin lesions. In particular, you\u2019ll use images within the same patient and determine which are likely to represent a melanoma. Using patient-level contextual information may help the development of image analysis tools, which could better support clinical dermatologists. Melanoma is a deadly disease, but if caught early, most melanomas can be cured with minor surgery. Image analysis tools that automate the diagnosis of melanoma will improve dermatologists' diagnostic accuracy. Better detection of melanoma has the opportunity to positively impact millions of people. Establish Metrics After understanding the problem better, we should probably define a metric to optimize. As usual, this step should be closely tied to business problem. We were already given a metric score by the competition host and let us understand it better. Recall that we wish to have a well-calibrated model, the intuition is that a high performance model may not output meaningful probabilities, even if they can have extremely good performance score. Consider a model that outputs logits of \\(0.51\\) when y_true is 1 and \\(0.49\\) otherwise, then a decision threshold of \\(0.5\\) guarantees an accuracy of \\(100\\%\\) , we have no complaints here if we have no issue with our threshold if our only goal is to have a high scoring model. However, if in medical case, where doctor wants to understand \"probablistically\" the survival of a patient, then we might want to turn into logits probs. But apparently the example here holds almost no meaning, when compared to a \"well calibrated model\", more concretely. y_true = [ 0 , 0 , 1 , 1 ] y_prob_uncalibrated = [ 0.49 , 0.49 , 0.51 , 0.51 ] y_prob_calibrated = [ 0.1 , 0.45 , 0.99 , 0.6 ] both models give \\(100\\%\\) accuracy, but the latter (assuming calibrated), can give us a laymen idea that ok this patient has 0.99 chance and the other patient 0.6 chance of surviving etc. Benefit Structure One can introduce a benefit structure with relevant cost-benefit assignment. TP: + 100 FN: -1000 FP: -10 TP+FP: -1 (screening for example) With each TP, we net a profit of 100, and with each FN, we lose -1000, FP loses -10 and whenever the patient get predicted to die (1), send for further screening -1. So towards the end, we can have: \\[ cost = 100*TP - 1000 * FN - 10 * FP - 1 * (TP+FP) \\] This structure helps us decide which metrics to choose. ROC Definition: The basic (non-probablistic intepretation) of ROC is graph that plots the True Positive Rate on the y-axis and False Positive Rate on the x-axis parametrized by a threshold vector t . We then look at the area under the ROC curve (AUROC) to get an overall performance measure. Note that TPR is recall . TPR (recall) = TP / (TP + FN) FPR = FP / (FP + TN) Threshold invariant The ROC looks at the performance of a model hypothesis at all thresholds. This is better than just optimizing recall which only looks at a fixed threshold. Scale Invariant Not necessarily a good thing in this context, as this makes ROC a semi-proper scoring metric, that is, it takes in non-calibrated scores and perform well. The below code shows that as long as the order is preserved, y2 and y4 make zero difference in the outcome. In this case, the doctor may not be able to have a \u201cconfidence\u201d level of how likely the patient is going to survive. y1 = [ 1 , 0 , 1 , 0 ] y2 = [ 0.52 , 0.51 , 0.52 , 0.51 ] y3 = [ 52 , 51 , 52 , 51 ] y4 = [ 0.99 , 0.51 , 0.98 , 0.51 ] uncalibrated_roc = roc ( y1 , y2 ) == roc ( y1 , y3 ) == roc ( y1 , y4 ) print ( f \" { uncalibrated_roc } \" ) -> 1.0 This brings us to the next point. More info in notebook. Brier Score Loss Brier Score computes the squared difference between the probability of a prediction and its actual outcome. Intuitively, this score punishes \u201cunconfident and neutral\u201d probability logits. If a model consistently spits out probability that is near 0.5, then this score will be large. Proper scoring Tells us if the scores output are well calibrated. If not well calibrated, prompt us to either use a different model that calibrated well, or to perform calibration on the model itself. Logistic regression produces natural well calibrated probabilities since it optimizes the log-loss (ce loss), in fact, I think MLE models should always produce well calibrated probabilities since behind the scene it is minimizing KL divergence between ground truth distribution P and estimated distribution Q. It follows that models like DT do not produce well calibrated probabilities. More info in notebook. What can we explore? Did not provide insight if Precision-recall curve and if it may be well posed for this problem than ROC since there is some class imbalance. Did not go into details on calibration methods, in fact, models like RF are not well calibrated by construction. https://scikit-learn.org/stable/modules/calibration.html Validation and Resampling Strategy How should we split out data into folds? We should examine the data for a few factors: Is the data \\(\\mathcal{X}\\) imbalanced? Is the data \\(\\mathcal{X}\\) generated in a i.i.d. manner, more specifically, if I split \\(\\mathcal{X}\\) to \\(\\mathcal{X}_{train}\\) and \\(\\mathcal{X}_{val}\\) , can we ensure that \\(\\mathcal{X}_{val}\\) has no dependency on \\(\\mathcal{X}_{train}\\) ? We came to the conclusion: Yes, the data is severely imbalanced in which there are only around \\(2\\%\\) of positive (malignant) samples. Therefore, a stratified cross validation is reasonable. StratifiedKFold ensures that relative class frequencies is approximately preserved in each train and validation fold. More concretely, we will not experience the scenario where \\(X_{train}\\) has \\(m^{+}\\) and \\(m^{-}\\) positive and negative samples, but \\(X_{val}\\) has only \\(p^{+}\\) positive samples only and 0 negative samples, simply due to the scarcity of negative samples. In medical imaging, it is a well known fact that most of the data contains patient level repeatedly. To put it bluntly, if I have 100 samples, and according to PatientID , we see that the id 123456 (John Doe) appeared 20 times, this is normal as a patient can undergo multiple settings of say, X-rays. If we allow John Doe's data to appear in both train and validation set, then this poses a problem of information leakage, in which the data is no longer i.i.d. . One can think of each patient has an \"unique, underlying features\" which are highly correlated across their different samples. As a result, it is paramount to ensure that amongst this 3255 unique patients, we need to ensure that each unique patients' images DO NOT appear in the validation fold. That is to say, if patient John Doe has 100 X-ray images, but during our 5-fold splits, he has 70 images in Fold 1-4, while 30 images are in Fold 5, then if we were to train on Fold 1-4 and validate on Fold 5, there may be potential leakage and the model will predict with confidence for John Doe's images. This is under the assumption that John Doe's data does not fulfill the i.i.d proces With the above consideration, we will use StratifiedGroupKFold where \\(K = 5\\) splits. There wasn't this splitting function in scikit-learn at the time of competition and as a result, we used a custom written (by someone else) RepeatedStratifiedGroupKFold function and just set n_splits = 1 to get StratifiedGroupKFold (yes we cannot afford to repeated sample, so setting the split to be 1 will collapse the repeated function to just the normal stratified group kfold). However, as of 2022, this function is readily available in the Scikit-Learn library. To recap, we applied stratified logic such that each train and validation set has an equal weightage of positive and negative samples. We also grouped the patients in the process such that patient \\(i\\) will not appear in both training and validation set. It is worth mentioning the famous Kaggler Chris Deotte went one step further to Triple Stratify the data where he balanced patient count distribution. One can read more here . Cross-Validation Workflow To recap, we have the following: Training Set ( \\(X_{\\text{train}}\\) ) : This will be further split into K validation sets during our cross-validation. This set is used to fit a particular hypothesis \\(h \\in \\mathcal{H}\\) . Validation Set ( \\(X_{\\text{val}}\\) ) : This is split from our \\(X_{\\text{train}}\\) during cross-validation. This set is used for model selection (i.e. find best hyperparameters, attempt to produce a best hypothesis \\(g \\in \\mathcal{H}\\) ). Test Set ( \\(X_{\\text{test}}\\) ) : This is an unseen test set, and we will only use it after we finish tuning our model/hypothesis. Suppose we have a final best model \\(g\\) , we will use \\(g\\) to predict on the test set to get an estimate of the generalization error (also called out-of-sample error). Pipeline. Courtesy of scikit-learn on a typical Cross-Validation workflow. Transfer Learning Traditionally, training on ImageNet weights is a good choice to start. In the event that our training set has a very different distribution of what's inside ImageNet , the model may take a while to converge, even if we finetune it. The intuition is simple, ImageNet was trained on many common items in life, and none of them resemble closely to the image structures of Melanoma Images . Consequently, the model may have a hard time detecting shapes and details from these medical images. We can of course unfreeze all the layers and retrain them from scratch, using various backbones, however, due to limited hardware, we decided it is best to first check if ImageNet yields good results, if not, we can explore weights that were originally trained on skin cancer images. The community used a few models and found out that the EfficientNet variants yielded the best results on this set of training images using ImageNet and hence we adopt the EfficientNet family moving forward. Examining the Grad-CAM of the models revealed that this family of models not only focus on the center nucleus of the skin image but also corners, perhaps they capture something other models don't? We will compare them briefly later. Fine-Tuning Instead of random initialization, we initialize the network with a pretrained network, like the one that is trained on imagenet 1000 dataset. This is what we will be doing. References below. Feature Extraction ConvNet as fixed feature extractor: Here, we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained. Preprocessing Most preprocessing techniques we do in an image recognition competition is mostly as follows: Mean and Standard Deviation Perform mean and std for the dataset given to us. Note that this step may make sense on paper, but empirically, using imagenet's default mean std will always work as well, if not better. You can read my blog post here \" Imagenet on RGB: mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225] Channel Distribution This is usually done to check for \"surprises\". More specifically, I remembered once that someone trained a CNN on the blood cells dataset (red, white blood cells etc), as a beginner who just came out from MNIST, he/she grayscaled the images and yielded poor results. This is because one distinct way for the model to differentiate these cells might be because of the colors of the cells. Let the Model tell you where went wrong! Alternatively, the issues are not obvious and we can use tools like Grad-CAM to see where our model is looking to deduce why the model is performing poorly. Augmentations We know that augmentation is central in an image competition, as essentially we are adding more data into the training process, effectively reducing overfitting. Heavy augmentations are used during Train-Time-Augmentation. But during Test-Time-Augmentation, we used the same set of training augmentations to inference with \\(100\\%\\) probability. Train-Time Augmentation Community power. We made use of some innovative augmentations: AdvancedHairAugmentation where hairs were randomly added to the image and Microscope where images were made to look as if they were taken from a microscope. Both of these augmentations provided a steady increase in CV and LB. albumentations . Compose ( [ AdvancedHairAugmentation ( hairs_folder = pipeline_config . transforms . hairs_folder ), albumentations . RandomResizedCrop ( height = pipeline_config . transforms . image_size , width = pipeline_config . transforms . image_size , scale = ( 0.8 , 1.0 ), ratio = ( 0.75 , 1.3333333333333333 ), p = 1.0 , ), albumentations . VerticalFlip ( p = 0.5 ), albumentations . HorizontalFlip ( p = 0.5 ), albumentations . Cutout ( max_h_size = int ( pipeline_config . transforms . image_size * 0.375 ), max_w_size = int ( pipeline_config . transforms . image_size * 0.375 ), num_holes = 1 , p = 0.3 , ), Microscope ( p = 0.5 ), albumentations . Normalize ( mean = pipeline_config . transforms . mean , std = pipeline_config . transforms . std , max_pixel_value = 255.0 , p = 1.0 , ), ToTensorV2 ( p = 1.0 ), ] ) Test-Time Augmentation The exact same set of augmentations were used in inference. Not all TTAs provided a increase in score. Optimizer, Scheduler and Loss Optimizer We used good old AdamW keeping in mind the rule of thumb that if batch size increase by a factor of 2, learning rate should increase by a factor of 2 as well. optimizer_name : str = \"AdamW\" optimizer_params : Dict [ str , Any ] = field ( default_factory = lambda : { \"lr\" : 1e-4 , \"betas\" : ( 0.9 , 0.999 ), \"amsgrad\" : False , \"weight_decay\" : 1e-6 , \"eps\" : 1e-08 , } ) Scheduler We used the following settings: scheduler_name : str = \"CosineAnnealingWarmRestarts\" # Debug if scheduler_name == \"CosineAnnealingWarmRestarts\" : scheduler_params : Dict [ str , Any ] = field ( default_factory = lambda : { \"T_0\" : 10 , \"T_mult\" : 1 , \"eta_min\" : 1e-6 , \"last_epoch\" : - 1 , } ) One should note that OneCycleLR is very popular and yields good results with shorter convergence time. Loss We used CrossEntropyLoss loss with default parameters. Read more in my blog post . train_criterion_name : str = \"CrossEntropyLoss\" train_criterion_params : Dict [ str , Any ] = field ( default_factory = lambda : { \"weight\" : None , \"size_average\" : None , \"ignore_index\" : - 100 , \"reduce\" : None , \"reduction\" : \"mean\" , \"label_smoothing\" : 0.0 , } ) Model Architectures, Training Parameters No Meta Data Model Architecture For models that did not make use of meta data, we have the following architecture. No Meta Data Model Architecture. Meta Data Model Architecture For models that did made use of meta data, we have the following architecture. Meta Data Model Architecture. We concat the flattened feature maps with the meta features: Meta Features : [ 'sex' , 'age_approx' , 'site_head/neck' , 'site_lower extremity' , 'site_oral/genital' , 'site_palms/soles' , 'site_torso' , 'site_upper extremity' , 'site_nan' ] and the meta features has its own sequential layers as ANN: OrderedDict ( [ ( \"fc1\" , torch . nn . Linear ( self . num_meta_features , 512 ), ), ( \"bn1\" , torch . nn . BatchNorm1d ( 512 ), ), ( \"swish1\" , torch . nn . SiLU (), ), ( \"dropout1\" , torch . nn . Dropout ( p = 0.3 ), ), ( \"fc2\" , torch . nn . Linear ( 512 , 128 ), ), ( \"bn2\" , torch . nn . BatchNorm1d ( 128 ), ), ( \"swish2\" , torch . nn . SiLU (), ), ] ) For example: image shape: \\([32, 3, 256, 256]\\) meta_inputs shape: \\([32, 9]\\) we have 9 features. feature_logits shape: \\([32, 1280]\\) flattened feature maps at the last conv layer. meta_logits shape: \\([32, 128]\\) where we passed in a small sequential ANN for the meta data. concat_logits shape: \\([32, 1280 + 128]\\) if self . use_meta : # from cnn images feature_logits = self . extract_features ( image ) # from meta features meta_logits = self . meta_layer ( meta_inputs ) # concatenate concat_logits = torch . cat (( feature_logits , meta_logits ), dim = 1 ) # classifier head classifier_logits = self . architecture [ \"head\" ]( concat_logits ) Activation Functions As we all know, activation functions are used to transform a neurons' linearity to non-linearity and decide whether to \"fire\" a neuron or not. When we design or choose an activation function, we need to ensure the follows: (Smoothness) Differentiable and Continuous: For example, the sigmoid function is continuous and hence differentiable. If the property is not fulfilled, we might face issues as backpropagation may not be performed properly since we cannot differentiate it.If you notice, the heaviside function is not. We cant perform GD using the HF as we cannot compute gradients but for the logistic function we can. The gradient of sigmoid function g is g(1-g) conveniently Monotonic: This helps the model to converge faster. But spoiler alert, Swish is not monotonic. The properties of Swish are as follows: Bounded below: It is claimed in the paper it serves as a strong regularization. Smoothness: More smooth than ReLU which allows the model to optimize better, the error landscape, when smoothed, is easier to traverse in order to find a minima. An intuitive idea is the hill again, imagine you traverse down your neighbourhood hill, vs traversing down Mount Himalaya. # Import matplotlib, numpy and math import matplotlib.pyplot as plt import numpy as np import math def swish ( x ): sigmoid = 1 / ( 1 + np . exp ( - x )) swish = x * sigmoid return swish epsilon = 1e-20 x = np . linspace ( - 100 , 100 , 100 ) z = swish ( x ) print ( z ) print ( min ( z )) plt . plot ( x , z ) plt . xlabel ( \"x\" ) plt . ylabel ( \"Swish(X)\" ) plt . show () Ensemble Theory Mean Blending This is just simple mean blending. Forward Ensembling We made use of the Forward Ensembling idea from Chris in SIIM-ISIC Melanoma Classification back in August 2020, I modified the code for this specific task. A simple description is as follows, modified from Chris, with more mathematical notations. We start off with a dataset \\(\\mathcal{D} = X \\times y\\) where it is sampled from the true population \\(\\mathcal{X} \\times \\mathcal{Y}\\) . We apply KFold (5 splits) to the dataset, as illustrated in the diagram. We can now train five different hypothesis \\(h_{F1}, h_{F2},...,h_{F5}\\) , where \\(h_{F1}\\) is trained on Fold 2 to Fold 5 and predict on Fold 1, \\(h_{F2}\\) is trained on Fold 1,3,4,5 and predict on Fold 2. The logic follows for all 5 hypothesis. Notice that in the five models, we are predicting on a unique validation fold, and as a result, after we trained all 5 folds, we will have the predictions made on the whole training set (F1-F5). This predictions is called the Out-of-Fold predictions. We then go a step further and calculate the AUC score with the OOF predictions with the ground truth to get the OOF AUC. We save it to a csv or dataframe called oof_1.csv , subsequent oof trained on different hypothesis space should be named oof_i.csv where \\(i \\in [2,3,...]\\) . After we trained all 5 folds, we will use \\(h_{1}\\) to predict on \\(X_{test}\\) and obtain predictions \\(Y_{\\text{h1 preds}}\\) , we then use \\(h_{2}\\) to predict on \\(X_{test}\\) and obtain predictions \\(Y_{\\text{h2 preds}}\\) , we do this for all five folds and finally \\(Y_{\\text{final preds}} = \\dfrac{1}{5}\\sum_{i=1}^{5}Y_{\\text{hi preds}}\\) . This is a typical pipeline in most machine learning problems. We save this final predictions as sub_1.csv , subsequence predictions trained on different hypothesis space should be named sub_i.csv where \\(i \\in [2,3,...]\\) . Now if we train another model, a completely different hypothesis space is used, to be more pedantic, we denote the previous model to be taken from the hypothesis space \\(\\mathcal{H}_{1}\\) , and now we move on to \\(\\mathcal{H}_{2}\\) . We repeat step 1-6 on this new model (Note that you are essentially training 10 \"models\" now since we are doing KFold twice, and oh, please set the seed of KFold to be the same, it should never be the case that both model comes from different splitting seed for apparent reasons). Here is the key (given the above setup with 2 different models trained on 5 folds): Normally, most people do a simple mean ensemble, that is \\(\\dfrac{Y_{\\text{final preds H1}} + Y_{\\text{final preds H2}}}{2}\\) . This works well most of the time as we trust both model holds equal importance in the final predictions. One issue may be that certain models should be weighted more than the rest, we should not simply take Leaderboard feedback score to judge the weight assignment. A general heuristic here is called Forward Selection. (Extracted from Chris) Now say that you build 2 models (that means that you did 5 KFold twice). You now have oof_1.csv, oof_2.csv, sub_1.csv, and sub_2.csv. How do we blend the two models? We find the weight w such that w * oof_1.predictions + (1-w) * oof_2.predictions has the largest AUC. all = [] for w in [ 0.00 , 0.01 , 0.02 , ... , 0.98 , 0.99 , 1.00 ]: ensemble_pred = w * oof_1 . predictions + ( 1 - w ) * oof_2 . predictions ensemble_auc = roc_auc_score ( oof . target , ensemble_pred ) all . append ( ensemble_auc ) best_weight = np . argmax ( all ) / 100. Then we can assign the best weight like: final_ensemble_pred = best_weight * sub_1 . target + ( 1 - best_weight ) * sub_2 . target Read more from my blog post in references below. ! pip install torchinfo Collecting torchinfo Downloading torchinfo-1.6.3-py3-none-any.whl (20 kB) Installing collected packages: torchinfo Successfully installed torchinfo-1.6.3 WARNING: You are using pip version 21.3.1; however, version 22.0.3 is available. You should consider upgrading via the 'C:\\Users\\reighns\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command. import timm from dataclasses import asdict , dataclass , field from pathlib import Path from typing import Any , Dict , List , Union import torchinfo import torch # Utility functions. import gc import json import os import random from pathlib import Path , PurePath from typing import Dict , Union , List import numpy as np import torch def seed_all ( seed : int = 1992 ) -> None : \"\"\"Seed all random number generators.\"\"\" print ( f \"Using Seed Number { seed } \" ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator # set fixed value for python built-in pseudo-random generator random . seed ( seed ) torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False torch . backends . cudnn . enabled = False seed_all () Using Seed Number 1992 @dataclass class ModelParams : \"\"\"A class to track model parameters. model_name (str): name of the model. pretrained (bool): If True, use pretrained model. input_channels (int): RGB image - 3 channels or Grayscale 1 channel output_dimension (int): Final output neuron. It is the number of classes in classification. Caution: If you use sigmoid layer for Binary, then it is 1. classification_type (str): classification type. \"\"\" model_name : str = \"resnet50d\" # resnet50d resnext50_32x4d \"tf_efficientnet_b0_ns\" # Debug use tf_efficientnet_b0_ns else tf_efficientnet_b4_ns vgg16 pretrained : bool = True input_channels : int = 3 output_dimension : int = 2 classification_type : str = \"multiclass\" use_meta : bool = False def to_dict ( self ) -> Dict [ str , Any ]: \"\"\"Convert to dictionary.\"\"\" return asdict ( self ) MODEL_PARAMS = ModelParams () class CustomNeuralNet ( torch . nn . Module ): def __init__ ( self , model_name : str = MODEL_PARAMS . model_name , out_features : int = MODEL_PARAMS . output_dimension , in_channels : int = MODEL_PARAMS . input_channels , pretrained : bool = MODEL_PARAMS . pretrained , use_meta : bool = MODEL_PARAMS . use_meta , ): \"\"\"Construct a new model. Args: model_name ([type], str): The name of the model to use. Defaults to MODEL_PARAMS.model_name. out_features ([type], int): The number of output features, this is usually the number of classes, but if you use sigmoid, then the output is 1. Defaults to MODEL_PARAMS.output_dimension. in_channels ([type], int): The number of input channels; RGB = 3, Grayscale = 1. Defaults to MODEL_PARAMS.input_channels. pretrained ([type], bool): If True, use pretrained model. Defaults to MODEL_PARAMS.pretrained. \"\"\" super () . __init__ () self . in_channels = in_channels self . pretrained = pretrained self . use_meta = use_meta self . backbone = timm . create_model ( model_name , pretrained = self . pretrained , in_chans = self . in_channels ) # removes head from backbone: # TODO: Global pool = \"avg\" vs \"\" behaves differently in shape, caution! self . backbone . reset_classifier ( num_classes = 0 , global_pool = \"avg\" ) # get the last layer's number of features in backbone (feature map) self . in_features = self . backbone . num_features self . out_features = out_features # Custom Head self . single_head_fc = torch . nn . Sequential ( torch . nn . Linear ( self . in_features , self . out_features ), ) self . architecture : Dict [ str , Callable ] = { \"backbone\" : self . backbone , \"bottleneck\" : None , \"head\" : self . single_head_fc , } def extract_features ( self , image : torch . FloatTensor ) -> torch . FloatTensor : \"\"\"Extract the features mapping logits from the model. This is the output from the backbone of a CNN. Args: image (torch.FloatTensor): The input image. Returns: feature_logits (torch.FloatTensor): The features logits. \"\"\" # TODO: To rename feature_logits to image embeddings, also find out what is image embedding. feature_logits = self . architecture [ \"backbone\" ]( image ) print ( f \"feature logits shape = { feature_logits . shape } \" ) return feature_logits def forward ( self , image : torch . FloatTensor ) -> torch . FloatTensor : \"\"\"The forward call of the model. Args: image (torch.FloatTensor): The input image. Returns: classifier_logits (torch.FloatTensor): The output logits of the classifier head. \"\"\" feature_logits = self . extract_features ( image ) classifier_logits = self . architecture [ \"head\" ]( feature_logits ) print ( f \"classifier_logits shape = { classifier_logits . shape } \" ) return classifier_logits model = CustomNeuralNet () batch_size , channel , height , width = 8 , 3 , 256 , 256 X = torch . randn (( batch_size , channel , height , width )) y = model ( image = X ) feature logits shape = torch.Size([8, 2048]) classifier_logits shape = torch.Size([8, 2]) _ = torchinfo . summary ( model , ( batch_size , channel , height , width ), col_names = [ \"input_size\" , \"output_size\" , \"num_params\" , \"kernel_size\" , \"mult_adds\" , ], depth = 3 , verbose = 1 ) torch.Size([8, 2048]) torch.Size([8, 2]) ========================================================================================================================================================================== Layer (type:depth-idx) Input Shape Output Shape Param # Kernel Shape Mult-Adds ========================================================================================================================================================================== CustomNeuralNet -- -- -- -- -- \u251c\u2500ResNet: 1-1 [8, 3, 256, 256] [8, 2048] -- -- -- \u2502 \u2514\u2500Sequential: 2-1 [8, 3, 256, 256] [8, 64, 128, 128] -- -- -- \u2502 \u2502 \u2514\u2500Conv2d: 3-1 [8, 3, 256, 256] [8, 32, 128, 128] 864 [3, 32, 3, 3] 113,246,208 \u2502 \u2502 \u2514\u2500BatchNorm2d: 3-2 [8, 32, 128, 128] [8, 32, 128, 128] 64 [32] 512 \u2502 \u2502 \u2514\u2500ReLU: 3-3 [8, 32, 128, 128] [8, 32, 128, 128] -- -- -- \u2502 \u2502 \u2514\u2500Conv2d: 3-4 [8, 32, 128, 128] [8, 32, 128, 128] 9,216 [32, 32, 3, 3] 1,207,959,552 \u2502 \u2502 \u2514\u2500BatchNorm2d: 3-5 [8, 32, 128, 128] [8, 32, 128, 128] 64 [32] 512 \u2502 \u2502 \u2514\u2500ReLU: 3-6 [8, 32, 128, 128] [8, 32, 128, 128] -- -- -- \u2502 \u2502 \u2514\u2500Conv2d: 3-7 [8, 32, 128, 128] [8, 64, 128, 128] 18,432 [32, 64, 3, 3] 2,415,919,104 \u2502 \u2514\u2500BatchNorm2d: 2-2 [8, 64, 128, 128] [8, 64, 128, 128] 128 [64] 1,024 \u2502 \u2514\u2500ReLU: 2-3 [8, 64, 128, 128] [8, 64, 128, 128] -- -- -- \u2502 \u2514\u2500MaxPool2d: 2-4 [8, 64, 128, 128] [8, 64, 64, 64] -- -- -- \u2502 \u2514\u2500Sequential: 2-5 [8, 64, 64, 64] [8, 256, 64, 64] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-8 [8, 64, 64, 64] [8, 256, 64, 64] 75,008 -- 2,415,929,344 \u2502 \u2502 \u2514\u2500Bottleneck: 3-9 [8, 256, 64, 64] [8, 256, 64, 64] 70,400 -- 2,281,707,520 \u2502 \u2502 \u2514\u2500Bottleneck: 3-10 [8, 256, 64, 64] [8, 256, 64, 64] 70,400 -- 2,281,707,520 \u2502 \u2514\u2500Sequential: 2-6 [8, 256, 64, 64] [8, 512, 32, 32] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-11 [8, 256, 64, 64] [8, 512, 32, 32] 379,392 -- 3,892,334,592 \u2502 \u2502 \u2514\u2500Bottleneck: 3-12 [8, 512, 32, 32] [8, 512, 32, 32] 280,064 -- 2,281,713,664 \u2502 \u2502 \u2514\u2500Bottleneck: 3-13 [8, 512, 32, 32] [8, 512, 32, 32] 280,064 -- 2,281,713,664 \u2502 \u2502 \u2514\u2500Bottleneck: 3-14 [8, 512, 32, 32] [8, 512, 32, 32] 280,064 -- 2,281,713,664 \u2502 \u2514\u2500Sequential: 2-7 [8, 512, 32, 32] [8, 1024, 16, 16] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-15 [8, 512, 32, 32] [8, 1024, 16, 16] 1,512,448 -- 3,892,355,072 \u2502 \u2502 \u2514\u2500Bottleneck: 3-16 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-17 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-18 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-19 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-20 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2514\u2500Sequential: 2-8 [8, 1024, 16, 16] [8, 2048, 8, 8] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-21 [8, 1024, 16, 16] [8, 2048, 8, 8] 6,039,552 -- 3,892,396,032 \u2502 \u2502 \u2514\u2500Bottleneck: 3-22 [8, 2048, 8, 8] [8, 2048, 8, 8] 4,462,592 -- 2,281,750,528 \u2502 \u2502 \u2514\u2500Bottleneck: 3-23 [8, 2048, 8, 8] [8, 2048, 8, 8] 4,462,592 -- 2,281,750,528 \u2502 \u2514\u2500SelectAdaptivePool2d: 2-9 [8, 2048, 8, 8] [8, 2048] -- -- -- \u2502 \u2502 \u2514\u2500AdaptiveAvgPool2d: 3-24 [8, 2048, 8, 8] [8, 2048, 1, 1] -- -- -- \u2502 \u2502 \u2514\u2500Flatten: 3-25 [8, 2048, 1, 1] [8, 2048] -- -- -- \u2502 \u2514\u2500Identity: 2-10 [8, 2048] [8, 2048] -- -- -- \u251c\u2500Sequential: 1-2 [8, 2048] [8, 2] -- -- -- \u2502 \u2514\u2500Linear: 2-11 [8, 2048] [8, 2] 4,098 [2048, 2] 32,784 ========================================================================================================================================================================== Total params: 23,531,362 Trainable params: 23,531,362 Non-trainable params: 0 Total mult-adds (G): 45.21 ========================================================================================================================================================================== Input size (MB): 6.29 Forward/backward pass size (MB): 1992.29 Params size (MB): 94.13 Estimated Total Size (MB): 2092.71 ========================================================================================================================================================================== This model architechure means that if I pass in a batch of \\(8\\) images of size \\((3, 256, 256)\\) , the model statistics will tell us a lot of information. Let us give some examples with a naive ResNet50d . Input Shape: \\([8, 3, 256, 256]\\) passing through the first Sequential Layer's Conv2d (3-1) with kernel size of Kernel Shape: \\([3, 32, 3, 3]\\) which means \\([\\textbf{in_channels, out_channels, kernel_size, kernel_size}]\\) will yield an output shape of Output Shape: \\([8, 32, 128, 128]\\) indicating that the each input images are now transformed into 32 kernels of size 256 by 256. Params: The Params column calculates the number of parameters in this layer at 864 learnable parameters. Once we know how to interpret the table, we can also see that our CustomNeuralnet() has extract_features which outputs the input at the last convolutional layer, in this example, it is at SelectAdaptivePool2d: 2-9 where it first went through AdaptiveAvgPool2d: 3-24 to squash the feature maps to \\([8, 2048, 1, 1]\\) and subsequently a Flatten: 3-25 layer to flatten out the last 2 dimensions to become \\([8, 2048]\\) so we can pass on to the dense layers. We can verify this by X = torch . randn (( batch_size , channel , height , width )) y = model ( image = X ) yielding feature logits shape = torch . Size ([ 8 , 2048 ]) classifier_logits shape = torch . Size ([ 8 , 2 ]) where the latter is the final shape of the input after passing through all the dense layers at \\([8, 2]\\) , where one can envision it as 2 output neurons. Error Analysis using Grad-CAM There is some distinct difference when Grad-CAM is applied to different models, which can help us do error analysis. Grad-CAM of ResNet50d Grad-CAM of EfficietNet For more info on Grad-CAM , see my blog post. Next Steps MLOps (Weights & Biases for experiment tracking) Model Persistence Benefit Structure References Image Normalization Triple Stratified Leak-Free KFold CV Transfer Learning PyTorch Transfer Learning TensorFlow Cross-Entropy Loss Forward Ensemble Forward Ensemble Discussion Grad-CAM","title":"SIIM-ISIC Melanoma Classification"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#siim-isic-melanoma-classification","text":"This competition is hosted on Kaggle and the description and overview is stated below . Skin cancer is the most prevalent type of cancer. Melanoma, specifically, is responsible for 75% of skin cancer deaths, despite being the least common skin cancer. The American Cancer Society estimates over 100,000 new melanoma cases will be diagnosed in 2020. It's also expected that almost 7,000 people will die from the disease. As with other cancers, early and accurate detection\u2014potentially aided by data science\u2014can make treatment more effective. Currently, dermatologists evaluate every one of a patient's moles to identify outlier lesions or \u201cugly ducklings\u201d that are most likely to be melanoma. Existing AI approaches have not adequately considered this clinical frame of reference. Dermatologists could enhance their diagnostic accuracy if detection algorithms take into account \u201ccontextual\u201d images within the same patient to determine which images represent a melanoma. If successful, classifiers would be more accurate and could better support dermatological clinic work. As the leading healthcare organization for informatics in medical imaging, the Society for Imaging Informatics in Medicine (SIIM)'s mission is to advance medical imaging informatics through education, research, and innovation in a multi-disciplinary community. SIIM is joined by the International Skin Imaging Collaboration (ISIC), an international effort to improve melanoma diagnosis. The ISIC Archive contains the largest publicly available collection of quality-controlled dermoscopic images of skin lesions. In this competition, you\u2019ll identify melanoma in images of skin lesions. In particular, you\u2019ll use images within the same patient and determine which are likely to represent a melanoma. Using patient-level contextual information may help the development of image analysis tools, which could better support clinical dermatologists. Melanoma is a deadly disease, but if caught early, most melanomas can be cured with minor surgery. Image analysis tools that automate the diagnosis of melanoma will improve dermatologists' diagnostic accuracy. Better detection of melanoma has the opportunity to positively impact millions of people.","title":"SIIM-ISIC Melanoma Classification"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#establish-metrics","text":"After understanding the problem better, we should probably define a metric to optimize. As usual, this step should be closely tied to business problem. We were already given a metric score by the competition host and let us understand it better. Recall that we wish to have a well-calibrated model, the intuition is that a high performance model may not output meaningful probabilities, even if they can have extremely good performance score. Consider a model that outputs logits of \\(0.51\\) when y_true is 1 and \\(0.49\\) otherwise, then a decision threshold of \\(0.5\\) guarantees an accuracy of \\(100\\%\\) , we have no complaints here if we have no issue with our threshold if our only goal is to have a high scoring model. However, if in medical case, where doctor wants to understand \"probablistically\" the survival of a patient, then we might want to turn into logits probs. But apparently the example here holds almost no meaning, when compared to a \"well calibrated model\", more concretely. y_true = [ 0 , 0 , 1 , 1 ] y_prob_uncalibrated = [ 0.49 , 0.49 , 0.51 , 0.51 ] y_prob_calibrated = [ 0.1 , 0.45 , 0.99 , 0.6 ] both models give \\(100\\%\\) accuracy, but the latter (assuming calibrated), can give us a laymen idea that ok this patient has 0.99 chance and the other patient 0.6 chance of surviving etc.","title":"Establish Metrics"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#benefit-structure","text":"One can introduce a benefit structure with relevant cost-benefit assignment. TP: + 100 FN: -1000 FP: -10 TP+FP: -1 (screening for example) With each TP, we net a profit of 100, and with each FN, we lose -1000, FP loses -10 and whenever the patient get predicted to die (1), send for further screening -1. So towards the end, we can have: \\[ cost = 100*TP - 1000 * FN - 10 * FP - 1 * (TP+FP) \\] This structure helps us decide which metrics to choose.","title":"Benefit Structure"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#roc","text":"Definition: The basic (non-probablistic intepretation) of ROC is graph that plots the True Positive Rate on the y-axis and False Positive Rate on the x-axis parametrized by a threshold vector t . We then look at the area under the ROC curve (AUROC) to get an overall performance measure. Note that TPR is recall . TPR (recall) = TP / (TP + FN) FPR = FP / (FP + TN) Threshold invariant The ROC looks at the performance of a model hypothesis at all thresholds. This is better than just optimizing recall which only looks at a fixed threshold. Scale Invariant Not necessarily a good thing in this context, as this makes ROC a semi-proper scoring metric, that is, it takes in non-calibrated scores and perform well. The below code shows that as long as the order is preserved, y2 and y4 make zero difference in the outcome. In this case, the doctor may not be able to have a \u201cconfidence\u201d level of how likely the patient is going to survive. y1 = [ 1 , 0 , 1 , 0 ] y2 = [ 0.52 , 0.51 , 0.52 , 0.51 ] y3 = [ 52 , 51 , 52 , 51 ] y4 = [ 0.99 , 0.51 , 0.98 , 0.51 ] uncalibrated_roc = roc ( y1 , y2 ) == roc ( y1 , y3 ) == roc ( y1 , y4 ) print ( f \" { uncalibrated_roc } \" ) -> 1.0 This brings us to the next point. More info in notebook.","title":"ROC"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#brier-score-loss","text":"Brier Score computes the squared difference between the probability of a prediction and its actual outcome. Intuitively, this score punishes \u201cunconfident and neutral\u201d probability logits. If a model consistently spits out probability that is near 0.5, then this score will be large. Proper scoring Tells us if the scores output are well calibrated. If not well calibrated, prompt us to either use a different model that calibrated well, or to perform calibration on the model itself. Logistic regression produces natural well calibrated probabilities since it optimizes the log-loss (ce loss), in fact, I think MLE models should always produce well calibrated probabilities since behind the scene it is minimizing KL divergence between ground truth distribution P and estimated distribution Q. It follows that models like DT do not produce well calibrated probabilities. More info in notebook.","title":"Brier Score Loss"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#what-can-we-explore","text":"Did not provide insight if Precision-recall curve and if it may be well posed for this problem than ROC since there is some class imbalance. Did not go into details on calibration methods, in fact, models like RF are not well calibrated by construction. https://scikit-learn.org/stable/modules/calibration.html","title":"What can we explore?"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#validation-and-resampling-strategy","text":"","title":"Validation and Resampling Strategy"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#how-should-we-split-out-data-into-folds","text":"We should examine the data for a few factors: Is the data \\(\\mathcal{X}\\) imbalanced? Is the data \\(\\mathcal{X}\\) generated in a i.i.d. manner, more specifically, if I split \\(\\mathcal{X}\\) to \\(\\mathcal{X}_{train}\\) and \\(\\mathcal{X}_{val}\\) , can we ensure that \\(\\mathcal{X}_{val}\\) has no dependency on \\(\\mathcal{X}_{train}\\) ? We came to the conclusion: Yes, the data is severely imbalanced in which there are only around \\(2\\%\\) of positive (malignant) samples. Therefore, a stratified cross validation is reasonable. StratifiedKFold ensures that relative class frequencies is approximately preserved in each train and validation fold. More concretely, we will not experience the scenario where \\(X_{train}\\) has \\(m^{+}\\) and \\(m^{-}\\) positive and negative samples, but \\(X_{val}\\) has only \\(p^{+}\\) positive samples only and 0 negative samples, simply due to the scarcity of negative samples. In medical imaging, it is a well known fact that most of the data contains patient level repeatedly. To put it bluntly, if I have 100 samples, and according to PatientID , we see that the id 123456 (John Doe) appeared 20 times, this is normal as a patient can undergo multiple settings of say, X-rays. If we allow John Doe's data to appear in both train and validation set, then this poses a problem of information leakage, in which the data is no longer i.i.d. . One can think of each patient has an \"unique, underlying features\" which are highly correlated across their different samples. As a result, it is paramount to ensure that amongst this 3255 unique patients, we need to ensure that each unique patients' images DO NOT appear in the validation fold. That is to say, if patient John Doe has 100 X-ray images, but during our 5-fold splits, he has 70 images in Fold 1-4, while 30 images are in Fold 5, then if we were to train on Fold 1-4 and validate on Fold 5, there may be potential leakage and the model will predict with confidence for John Doe's images. This is under the assumption that John Doe's data does not fulfill the i.i.d proces With the above consideration, we will use StratifiedGroupKFold where \\(K = 5\\) splits. There wasn't this splitting function in scikit-learn at the time of competition and as a result, we used a custom written (by someone else) RepeatedStratifiedGroupKFold function and just set n_splits = 1 to get StratifiedGroupKFold (yes we cannot afford to repeated sample, so setting the split to be 1 will collapse the repeated function to just the normal stratified group kfold). However, as of 2022, this function is readily available in the Scikit-Learn library. To recap, we applied stratified logic such that each train and validation set has an equal weightage of positive and negative samples. We also grouped the patients in the process such that patient \\(i\\) will not appear in both training and validation set. It is worth mentioning the famous Kaggler Chris Deotte went one step further to Triple Stratify the data where he balanced patient count distribution. One can read more here .","title":"How should we split out data into folds?"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#cross-validation-workflow","text":"To recap, we have the following: Training Set ( \\(X_{\\text{train}}\\) ) : This will be further split into K validation sets during our cross-validation. This set is used to fit a particular hypothesis \\(h \\in \\mathcal{H}\\) . Validation Set ( \\(X_{\\text{val}}\\) ) : This is split from our \\(X_{\\text{train}}\\) during cross-validation. This set is used for model selection (i.e. find best hyperparameters, attempt to produce a best hypothesis \\(g \\in \\mathcal{H}\\) ). Test Set ( \\(X_{\\text{test}}\\) ) : This is an unseen test set, and we will only use it after we finish tuning our model/hypothesis. Suppose we have a final best model \\(g\\) , we will use \\(g\\) to predict on the test set to get an estimate of the generalization error (also called out-of-sample error). Pipeline. Courtesy of scikit-learn on a typical Cross-Validation workflow.","title":"Cross-Validation Workflow"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#transfer-learning","text":"Traditionally, training on ImageNet weights is a good choice to start. In the event that our training set has a very different distribution of what's inside ImageNet , the model may take a while to converge, even if we finetune it. The intuition is simple, ImageNet was trained on many common items in life, and none of them resemble closely to the image structures of Melanoma Images . Consequently, the model may have a hard time detecting shapes and details from these medical images. We can of course unfreeze all the layers and retrain them from scratch, using various backbones, however, due to limited hardware, we decided it is best to first check if ImageNet yields good results, if not, we can explore weights that were originally trained on skin cancer images. The community used a few models and found out that the EfficientNet variants yielded the best results on this set of training images using ImageNet and hence we adopt the EfficientNet family moving forward. Examining the Grad-CAM of the models revealed that this family of models not only focus on the center nucleus of the skin image but also corners, perhaps they capture something other models don't? We will compare them briefly later.","title":"Transfer Learning"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#fine-tuning","text":"Instead of random initialization, we initialize the network with a pretrained network, like the one that is trained on imagenet 1000 dataset. This is what we will be doing. References below.","title":"Fine-Tuning"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#feature-extraction","text":"ConvNet as fixed feature extractor: Here, we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained.","title":"Feature Extraction"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#preprocessing","text":"Most preprocessing techniques we do in an image recognition competition is mostly as follows:","title":"Preprocessing"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#mean-and-standard-deviation","text":"Perform mean and std for the dataset given to us. Note that this step may make sense on paper, but empirically, using imagenet's default mean std will always work as well, if not better. You can read my blog post here \" Imagenet on RGB: mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]","title":"Mean and Standard Deviation"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#channel-distribution","text":"This is usually done to check for \"surprises\". More specifically, I remembered once that someone trained a CNN on the blood cells dataset (red, white blood cells etc), as a beginner who just came out from MNIST, he/she grayscaled the images and yielded poor results. This is because one distinct way for the model to differentiate these cells might be because of the colors of the cells.","title":"Channel Distribution"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#let-the-model-tell-you-where-went-wrong","text":"Alternatively, the issues are not obvious and we can use tools like Grad-CAM to see where our model is looking to deduce why the model is performing poorly.","title":"Let the Model tell you where went wrong!"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#augmentations","text":"We know that augmentation is central in an image competition, as essentially we are adding more data into the training process, effectively reducing overfitting. Heavy augmentations are used during Train-Time-Augmentation. But during Test-Time-Augmentation, we used the same set of training augmentations to inference with \\(100\\%\\) probability.","title":"Augmentations"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#train-time-augmentation","text":"Community power. We made use of some innovative augmentations: AdvancedHairAugmentation where hairs were randomly added to the image and Microscope where images were made to look as if they were taken from a microscope. Both of these augmentations provided a steady increase in CV and LB. albumentations . Compose ( [ AdvancedHairAugmentation ( hairs_folder = pipeline_config . transforms . hairs_folder ), albumentations . RandomResizedCrop ( height = pipeline_config . transforms . image_size , width = pipeline_config . transforms . image_size , scale = ( 0.8 , 1.0 ), ratio = ( 0.75 , 1.3333333333333333 ), p = 1.0 , ), albumentations . VerticalFlip ( p = 0.5 ), albumentations . HorizontalFlip ( p = 0.5 ), albumentations . Cutout ( max_h_size = int ( pipeline_config . transforms . image_size * 0.375 ), max_w_size = int ( pipeline_config . transforms . image_size * 0.375 ), num_holes = 1 , p = 0.3 , ), Microscope ( p = 0.5 ), albumentations . Normalize ( mean = pipeline_config . transforms . mean , std = pipeline_config . transforms . std , max_pixel_value = 255.0 , p = 1.0 , ), ToTensorV2 ( p = 1.0 ), ] )","title":"Train-Time Augmentation"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#test-time-augmentation","text":"The exact same set of augmentations were used in inference. Not all TTAs provided a increase in score.","title":"Test-Time Augmentation"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#optimizer-scheduler-and-loss","text":"","title":"Optimizer, Scheduler and Loss"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#optimizer","text":"We used good old AdamW keeping in mind the rule of thumb that if batch size increase by a factor of 2, learning rate should increase by a factor of 2 as well. optimizer_name : str = \"AdamW\" optimizer_params : Dict [ str , Any ] = field ( default_factory = lambda : { \"lr\" : 1e-4 , \"betas\" : ( 0.9 , 0.999 ), \"amsgrad\" : False , \"weight_decay\" : 1e-6 , \"eps\" : 1e-08 , } )","title":"Optimizer"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#scheduler","text":"We used the following settings: scheduler_name : str = \"CosineAnnealingWarmRestarts\" # Debug if scheduler_name == \"CosineAnnealingWarmRestarts\" : scheduler_params : Dict [ str , Any ] = field ( default_factory = lambda : { \"T_0\" : 10 , \"T_mult\" : 1 , \"eta_min\" : 1e-6 , \"last_epoch\" : - 1 , } ) One should note that OneCycleLR is very popular and yields good results with shorter convergence time.","title":"Scheduler"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#loss","text":"We used CrossEntropyLoss loss with default parameters. Read more in my blog post . train_criterion_name : str = \"CrossEntropyLoss\" train_criterion_params : Dict [ str , Any ] = field ( default_factory = lambda : { \"weight\" : None , \"size_average\" : None , \"ignore_index\" : - 100 , \"reduce\" : None , \"reduction\" : \"mean\" , \"label_smoothing\" : 0.0 , } )","title":"Loss"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#model-architectures-training-parameters","text":"","title":"Model Architectures, Training Parameters"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#no-meta-data-model-architecture","text":"For models that did not make use of meta data, we have the following architecture. No Meta Data Model Architecture.","title":"No Meta Data Model Architecture"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#meta-data-model-architecture","text":"For models that did made use of meta data, we have the following architecture. Meta Data Model Architecture. We concat the flattened feature maps with the meta features: Meta Features : [ 'sex' , 'age_approx' , 'site_head/neck' , 'site_lower extremity' , 'site_oral/genital' , 'site_palms/soles' , 'site_torso' , 'site_upper extremity' , 'site_nan' ] and the meta features has its own sequential layers as ANN: OrderedDict ( [ ( \"fc1\" , torch . nn . Linear ( self . num_meta_features , 512 ), ), ( \"bn1\" , torch . nn . BatchNorm1d ( 512 ), ), ( \"swish1\" , torch . nn . SiLU (), ), ( \"dropout1\" , torch . nn . Dropout ( p = 0.3 ), ), ( \"fc2\" , torch . nn . Linear ( 512 , 128 ), ), ( \"bn2\" , torch . nn . BatchNorm1d ( 128 ), ), ( \"swish2\" , torch . nn . SiLU (), ), ] ) For example: image shape: \\([32, 3, 256, 256]\\) meta_inputs shape: \\([32, 9]\\) we have 9 features. feature_logits shape: \\([32, 1280]\\) flattened feature maps at the last conv layer. meta_logits shape: \\([32, 128]\\) where we passed in a small sequential ANN for the meta data. concat_logits shape: \\([32, 1280 + 128]\\) if self . use_meta : # from cnn images feature_logits = self . extract_features ( image ) # from meta features meta_logits = self . meta_layer ( meta_inputs ) # concatenate concat_logits = torch . cat (( feature_logits , meta_logits ), dim = 1 ) # classifier head classifier_logits = self . architecture [ \"head\" ]( concat_logits )","title":"Meta Data Model Architecture"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#activation-functions","text":"As we all know, activation functions are used to transform a neurons' linearity to non-linearity and decide whether to \"fire\" a neuron or not. When we design or choose an activation function, we need to ensure the follows: (Smoothness) Differentiable and Continuous: For example, the sigmoid function is continuous and hence differentiable. If the property is not fulfilled, we might face issues as backpropagation may not be performed properly since we cannot differentiate it.If you notice, the heaviside function is not. We cant perform GD using the HF as we cannot compute gradients but for the logistic function we can. The gradient of sigmoid function g is g(1-g) conveniently Monotonic: This helps the model to converge faster. But spoiler alert, Swish is not monotonic. The properties of Swish are as follows: Bounded below: It is claimed in the paper it serves as a strong regularization. Smoothness: More smooth than ReLU which allows the model to optimize better, the error landscape, when smoothed, is easier to traverse in order to find a minima. An intuitive idea is the hill again, imagine you traverse down your neighbourhood hill, vs traversing down Mount Himalaya. # Import matplotlib, numpy and math import matplotlib.pyplot as plt import numpy as np import math def swish ( x ): sigmoid = 1 / ( 1 + np . exp ( - x )) swish = x * sigmoid return swish epsilon = 1e-20 x = np . linspace ( - 100 , 100 , 100 ) z = swish ( x ) print ( z ) print ( min ( z )) plt . plot ( x , z ) plt . xlabel ( \"x\" ) plt . ylabel ( \"Swish(X)\" ) plt . show ()","title":"Activation Functions"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#ensemble-theory","text":"","title":"Ensemble Theory"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#mean-blending","text":"This is just simple mean blending.","title":"Mean Blending"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#forward-ensembling","text":"We made use of the Forward Ensembling idea from Chris in SIIM-ISIC Melanoma Classification back in August 2020, I modified the code for this specific task. A simple description is as follows, modified from Chris, with more mathematical notations. We start off with a dataset \\(\\mathcal{D} = X \\times y\\) where it is sampled from the true population \\(\\mathcal{X} \\times \\mathcal{Y}\\) . We apply KFold (5 splits) to the dataset, as illustrated in the diagram. We can now train five different hypothesis \\(h_{F1}, h_{F2},...,h_{F5}\\) , where \\(h_{F1}\\) is trained on Fold 2 to Fold 5 and predict on Fold 1, \\(h_{F2}\\) is trained on Fold 1,3,4,5 and predict on Fold 2. The logic follows for all 5 hypothesis. Notice that in the five models, we are predicting on a unique validation fold, and as a result, after we trained all 5 folds, we will have the predictions made on the whole training set (F1-F5). This predictions is called the Out-of-Fold predictions. We then go a step further and calculate the AUC score with the OOF predictions with the ground truth to get the OOF AUC. We save it to a csv or dataframe called oof_1.csv , subsequent oof trained on different hypothesis space should be named oof_i.csv where \\(i \\in [2,3,...]\\) . After we trained all 5 folds, we will use \\(h_{1}\\) to predict on \\(X_{test}\\) and obtain predictions \\(Y_{\\text{h1 preds}}\\) , we then use \\(h_{2}\\) to predict on \\(X_{test}\\) and obtain predictions \\(Y_{\\text{h2 preds}}\\) , we do this for all five folds and finally \\(Y_{\\text{final preds}} = \\dfrac{1}{5}\\sum_{i=1}^{5}Y_{\\text{hi preds}}\\) . This is a typical pipeline in most machine learning problems. We save this final predictions as sub_1.csv , subsequence predictions trained on different hypothesis space should be named sub_i.csv where \\(i \\in [2,3,...]\\) . Now if we train another model, a completely different hypothesis space is used, to be more pedantic, we denote the previous model to be taken from the hypothesis space \\(\\mathcal{H}_{1}\\) , and now we move on to \\(\\mathcal{H}_{2}\\) . We repeat step 1-6 on this new model (Note that you are essentially training 10 \"models\" now since we are doing KFold twice, and oh, please set the seed of KFold to be the same, it should never be the case that both model comes from different splitting seed for apparent reasons). Here is the key (given the above setup with 2 different models trained on 5 folds): Normally, most people do a simple mean ensemble, that is \\(\\dfrac{Y_{\\text{final preds H1}} + Y_{\\text{final preds H2}}}{2}\\) . This works well most of the time as we trust both model holds equal importance in the final predictions. One issue may be that certain models should be weighted more than the rest, we should not simply take Leaderboard feedback score to judge the weight assignment. A general heuristic here is called Forward Selection. (Extracted from Chris) Now say that you build 2 models (that means that you did 5 KFold twice). You now have oof_1.csv, oof_2.csv, sub_1.csv, and sub_2.csv. How do we blend the two models? We find the weight w such that w * oof_1.predictions + (1-w) * oof_2.predictions has the largest AUC. all = [] for w in [ 0.00 , 0.01 , 0.02 , ... , 0.98 , 0.99 , 1.00 ]: ensemble_pred = w * oof_1 . predictions + ( 1 - w ) * oof_2 . predictions ensemble_auc = roc_auc_score ( oof . target , ensemble_pred ) all . append ( ensemble_auc ) best_weight = np . argmax ( all ) / 100. Then we can assign the best weight like: final_ensemble_pred = best_weight * sub_1 . target + ( 1 - best_weight ) * sub_2 . target Read more from my blog post in references below. ! pip install torchinfo Collecting torchinfo Downloading torchinfo-1.6.3-py3-none-any.whl (20 kB) Installing collected packages: torchinfo Successfully installed torchinfo-1.6.3 WARNING: You are using pip version 21.3.1; however, version 22.0.3 is available. You should consider upgrading via the 'C:\\Users\\reighns\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command. import timm from dataclasses import asdict , dataclass , field from pathlib import Path from typing import Any , Dict , List , Union import torchinfo import torch # Utility functions. import gc import json import os import random from pathlib import Path , PurePath from typing import Dict , Union , List import numpy as np import torch def seed_all ( seed : int = 1992 ) -> None : \"\"\"Seed all random number generators.\"\"\" print ( f \"Using Seed Number { seed } \" ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) # set PYTHONHASHSEED env var at fixed value torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . cuda . manual_seed ( seed ) # pytorch (both CPU and CUDA) np . random . seed ( seed ) # for numpy pseudo-random generator # set fixed value for python built-in pseudo-random generator random . seed ( seed ) torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False torch . backends . cudnn . enabled = False seed_all () Using Seed Number 1992 @dataclass class ModelParams : \"\"\"A class to track model parameters. model_name (str): name of the model. pretrained (bool): If True, use pretrained model. input_channels (int): RGB image - 3 channels or Grayscale 1 channel output_dimension (int): Final output neuron. It is the number of classes in classification. Caution: If you use sigmoid layer for Binary, then it is 1. classification_type (str): classification type. \"\"\" model_name : str = \"resnet50d\" # resnet50d resnext50_32x4d \"tf_efficientnet_b0_ns\" # Debug use tf_efficientnet_b0_ns else tf_efficientnet_b4_ns vgg16 pretrained : bool = True input_channels : int = 3 output_dimension : int = 2 classification_type : str = \"multiclass\" use_meta : bool = False def to_dict ( self ) -> Dict [ str , Any ]: \"\"\"Convert to dictionary.\"\"\" return asdict ( self ) MODEL_PARAMS = ModelParams () class CustomNeuralNet ( torch . nn . Module ): def __init__ ( self , model_name : str = MODEL_PARAMS . model_name , out_features : int = MODEL_PARAMS . output_dimension , in_channels : int = MODEL_PARAMS . input_channels , pretrained : bool = MODEL_PARAMS . pretrained , use_meta : bool = MODEL_PARAMS . use_meta , ): \"\"\"Construct a new model. Args: model_name ([type], str): The name of the model to use. Defaults to MODEL_PARAMS.model_name. out_features ([type], int): The number of output features, this is usually the number of classes, but if you use sigmoid, then the output is 1. Defaults to MODEL_PARAMS.output_dimension. in_channels ([type], int): The number of input channels; RGB = 3, Grayscale = 1. Defaults to MODEL_PARAMS.input_channels. pretrained ([type], bool): If True, use pretrained model. Defaults to MODEL_PARAMS.pretrained. \"\"\" super () . __init__ () self . in_channels = in_channels self . pretrained = pretrained self . use_meta = use_meta self . backbone = timm . create_model ( model_name , pretrained = self . pretrained , in_chans = self . in_channels ) # removes head from backbone: # TODO: Global pool = \"avg\" vs \"\" behaves differently in shape, caution! self . backbone . reset_classifier ( num_classes = 0 , global_pool = \"avg\" ) # get the last layer's number of features in backbone (feature map) self . in_features = self . backbone . num_features self . out_features = out_features # Custom Head self . single_head_fc = torch . nn . Sequential ( torch . nn . Linear ( self . in_features , self . out_features ), ) self . architecture : Dict [ str , Callable ] = { \"backbone\" : self . backbone , \"bottleneck\" : None , \"head\" : self . single_head_fc , } def extract_features ( self , image : torch . FloatTensor ) -> torch . FloatTensor : \"\"\"Extract the features mapping logits from the model. This is the output from the backbone of a CNN. Args: image (torch.FloatTensor): The input image. Returns: feature_logits (torch.FloatTensor): The features logits. \"\"\" # TODO: To rename feature_logits to image embeddings, also find out what is image embedding. feature_logits = self . architecture [ \"backbone\" ]( image ) print ( f \"feature logits shape = { feature_logits . shape } \" ) return feature_logits def forward ( self , image : torch . FloatTensor ) -> torch . FloatTensor : \"\"\"The forward call of the model. Args: image (torch.FloatTensor): The input image. Returns: classifier_logits (torch.FloatTensor): The output logits of the classifier head. \"\"\" feature_logits = self . extract_features ( image ) classifier_logits = self . architecture [ \"head\" ]( feature_logits ) print ( f \"classifier_logits shape = { classifier_logits . shape } \" ) return classifier_logits model = CustomNeuralNet () batch_size , channel , height , width = 8 , 3 , 256 , 256 X = torch . randn (( batch_size , channel , height , width )) y = model ( image = X ) feature logits shape = torch.Size([8, 2048]) classifier_logits shape = torch.Size([8, 2]) _ = torchinfo . summary ( model , ( batch_size , channel , height , width ), col_names = [ \"input_size\" , \"output_size\" , \"num_params\" , \"kernel_size\" , \"mult_adds\" , ], depth = 3 , verbose = 1 ) torch.Size([8, 2048]) torch.Size([8, 2]) ========================================================================================================================================================================== Layer (type:depth-idx) Input Shape Output Shape Param # Kernel Shape Mult-Adds ========================================================================================================================================================================== CustomNeuralNet -- -- -- -- -- \u251c\u2500ResNet: 1-1 [8, 3, 256, 256] [8, 2048] -- -- -- \u2502 \u2514\u2500Sequential: 2-1 [8, 3, 256, 256] [8, 64, 128, 128] -- -- -- \u2502 \u2502 \u2514\u2500Conv2d: 3-1 [8, 3, 256, 256] [8, 32, 128, 128] 864 [3, 32, 3, 3] 113,246,208 \u2502 \u2502 \u2514\u2500BatchNorm2d: 3-2 [8, 32, 128, 128] [8, 32, 128, 128] 64 [32] 512 \u2502 \u2502 \u2514\u2500ReLU: 3-3 [8, 32, 128, 128] [8, 32, 128, 128] -- -- -- \u2502 \u2502 \u2514\u2500Conv2d: 3-4 [8, 32, 128, 128] [8, 32, 128, 128] 9,216 [32, 32, 3, 3] 1,207,959,552 \u2502 \u2502 \u2514\u2500BatchNorm2d: 3-5 [8, 32, 128, 128] [8, 32, 128, 128] 64 [32] 512 \u2502 \u2502 \u2514\u2500ReLU: 3-6 [8, 32, 128, 128] [8, 32, 128, 128] -- -- -- \u2502 \u2502 \u2514\u2500Conv2d: 3-7 [8, 32, 128, 128] [8, 64, 128, 128] 18,432 [32, 64, 3, 3] 2,415,919,104 \u2502 \u2514\u2500BatchNorm2d: 2-2 [8, 64, 128, 128] [8, 64, 128, 128] 128 [64] 1,024 \u2502 \u2514\u2500ReLU: 2-3 [8, 64, 128, 128] [8, 64, 128, 128] -- -- -- \u2502 \u2514\u2500MaxPool2d: 2-4 [8, 64, 128, 128] [8, 64, 64, 64] -- -- -- \u2502 \u2514\u2500Sequential: 2-5 [8, 64, 64, 64] [8, 256, 64, 64] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-8 [8, 64, 64, 64] [8, 256, 64, 64] 75,008 -- 2,415,929,344 \u2502 \u2502 \u2514\u2500Bottleneck: 3-9 [8, 256, 64, 64] [8, 256, 64, 64] 70,400 -- 2,281,707,520 \u2502 \u2502 \u2514\u2500Bottleneck: 3-10 [8, 256, 64, 64] [8, 256, 64, 64] 70,400 -- 2,281,707,520 \u2502 \u2514\u2500Sequential: 2-6 [8, 256, 64, 64] [8, 512, 32, 32] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-11 [8, 256, 64, 64] [8, 512, 32, 32] 379,392 -- 3,892,334,592 \u2502 \u2502 \u2514\u2500Bottleneck: 3-12 [8, 512, 32, 32] [8, 512, 32, 32] 280,064 -- 2,281,713,664 \u2502 \u2502 \u2514\u2500Bottleneck: 3-13 [8, 512, 32, 32] [8, 512, 32, 32] 280,064 -- 2,281,713,664 \u2502 \u2502 \u2514\u2500Bottleneck: 3-14 [8, 512, 32, 32] [8, 512, 32, 32] 280,064 -- 2,281,713,664 \u2502 \u2514\u2500Sequential: 2-7 [8, 512, 32, 32] [8, 1024, 16, 16] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-15 [8, 512, 32, 32] [8, 1024, 16, 16] 1,512,448 -- 3,892,355,072 \u2502 \u2502 \u2514\u2500Bottleneck: 3-16 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-17 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-18 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-19 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2502 \u2514\u2500Bottleneck: 3-20 [8, 1024, 16, 16] [8, 1024, 16, 16] 1,117,184 -- 2,281,725,952 \u2502 \u2514\u2500Sequential: 2-8 [8, 1024, 16, 16] [8, 2048, 8, 8] -- -- -- \u2502 \u2502 \u2514\u2500Bottleneck: 3-21 [8, 1024, 16, 16] [8, 2048, 8, 8] 6,039,552 -- 3,892,396,032 \u2502 \u2502 \u2514\u2500Bottleneck: 3-22 [8, 2048, 8, 8] [8, 2048, 8, 8] 4,462,592 -- 2,281,750,528 \u2502 \u2502 \u2514\u2500Bottleneck: 3-23 [8, 2048, 8, 8] [8, 2048, 8, 8] 4,462,592 -- 2,281,750,528 \u2502 \u2514\u2500SelectAdaptivePool2d: 2-9 [8, 2048, 8, 8] [8, 2048] -- -- -- \u2502 \u2502 \u2514\u2500AdaptiveAvgPool2d: 3-24 [8, 2048, 8, 8] [8, 2048, 1, 1] -- -- -- \u2502 \u2502 \u2514\u2500Flatten: 3-25 [8, 2048, 1, 1] [8, 2048] -- -- -- \u2502 \u2514\u2500Identity: 2-10 [8, 2048] [8, 2048] -- -- -- \u251c\u2500Sequential: 1-2 [8, 2048] [8, 2] -- -- -- \u2502 \u2514\u2500Linear: 2-11 [8, 2048] [8, 2] 4,098 [2048, 2] 32,784 ========================================================================================================================================================================== Total params: 23,531,362 Trainable params: 23,531,362 Non-trainable params: 0 Total mult-adds (G): 45.21 ========================================================================================================================================================================== Input size (MB): 6.29 Forward/backward pass size (MB): 1992.29 Params size (MB): 94.13 Estimated Total Size (MB): 2092.71 ========================================================================================================================================================================== This model architechure means that if I pass in a batch of \\(8\\) images of size \\((3, 256, 256)\\) , the model statistics will tell us a lot of information. Let us give some examples with a naive ResNet50d . Input Shape: \\([8, 3, 256, 256]\\) passing through the first Sequential Layer's Conv2d (3-1) with kernel size of Kernel Shape: \\([3, 32, 3, 3]\\) which means \\([\\textbf{in_channels, out_channels, kernel_size, kernel_size}]\\) will yield an output shape of Output Shape: \\([8, 32, 128, 128]\\) indicating that the each input images are now transformed into 32 kernels of size 256 by 256. Params: The Params column calculates the number of parameters in this layer at 864 learnable parameters. Once we know how to interpret the table, we can also see that our CustomNeuralnet() has extract_features which outputs the input at the last convolutional layer, in this example, it is at SelectAdaptivePool2d: 2-9 where it first went through AdaptiveAvgPool2d: 3-24 to squash the feature maps to \\([8, 2048, 1, 1]\\) and subsequently a Flatten: 3-25 layer to flatten out the last 2 dimensions to become \\([8, 2048]\\) so we can pass on to the dense layers. We can verify this by X = torch . randn (( batch_size , channel , height , width )) y = model ( image = X ) yielding feature logits shape = torch . Size ([ 8 , 2048 ]) classifier_logits shape = torch . Size ([ 8 , 2 ]) where the latter is the final shape of the input after passing through all the dense layers at \\([8, 2]\\) , where one can envision it as 2 output neurons.","title":"Forward Ensembling"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#error-analysis-using-grad-cam","text":"There is some distinct difference when Grad-CAM is applied to different models, which can help us do error analysis. Grad-CAM of ResNet50d Grad-CAM of EfficietNet For more info on Grad-CAM , see my blog post.","title":"Error Analysis using Grad-CAM"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#next-steps","text":"MLOps (Weights & Biases for experiment tracking) Model Persistence Benefit Structure","title":"Next Steps"},{"location":"reighns_ml_journey/projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/#references","text":"Image Normalization Triple Stratified Leak-Free KFold CV Transfer Learning PyTorch Transfer Learning TensorFlow Cross-Entropy Loss Forward Ensemble Forward Ensemble Discussion Grad-CAM","title":"References"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/","text":"Notations Input Space: \\(\\mathcal{X}\\) The input space contains the set of all possible examples/instances in a population . This is generally unknown. Output Space: \\(\\mathcal{Y}\\) The output space is the set of all possible labels/targets that corresponds to each point in \\(\\mathcal{X}\\) . Distribution : \\(\\mathcal{P}\\) Reference: Learning From Data p43. The unknown distribution that generated our input space \\(\\mathcal{X}\\) . In general, instead of the mapping \\(\\mathrm{y} = f(\\mathrm{x})\\) , we can take the output \\(\\mathrm{y}\\) to be a random variable that is affected by, rather than determined by, the input \\(\\mathrm{x}\\) . Formally, we have a target distribution \\(\\mathcal{P}(\\mathrm{y} | \\mathrm{x})\\) instead of just \\(\\mathrm{y} = f(\\mathrm{x})\\) . Now we say that any point \\((\\mathrm{x}, \\mathrm{y})\\) in \\(\\mathcal{X}\\) is now generated by the joint distribution \\( \\(\\mathcal{P}(\\mathrm{x}, \\mathrm{y}) = \\mathcal{P}(\\mathrm{x})\\mathcal{P}(\\mathrm{y} | \\mathrm{x})\\) \\) Data: \\(\\mathcal{D}\\) This is the set of samples drawn from \\(\\mathcal{X} \\times \\mathcal{Y}\\) over a distribution \\(\\mathcal{P}\\) . The general notation is as follows: \\( \\(\\mathcal{D} = [(\\mathrm{x^{(1)}}, \\mathrm{y^{(1)}}), (\\mathrm{x^{(2)}}, \\mathrm{y^{(2)}}), ..., (\\mathrm{x^{(N)}}, \\mathrm{y^{(N)}}))]\\) \\) where \\(N\\) denotes the number of training samples, and each \\(\\mathrm{x}^{(i)} \\in \\mathbb{R}^{n}\\) with \\(n\\) features. In general, \\(\\mathrm{y}^{(i)} \\in \\mathbb{R}\\) and is a single label. We can split \\(\\mathcal{D}\\) into two sets respectively, where \\(\\mathrm{X}\\) consists of all the \\(\\mathrm{x}\\) , and \\(\\mathrm{Y}\\) consists of all the \\(\\mathrm{y}\\) . We will see this next. Design Matrix: \\(\\mathrm{X}\\) Let \\(\\mathrm{X}\\) be the design matrix of dimensions \\(m\u2005\\times\u2005(n\u2005+\u20051)\\) where \\(m\\) is the number of observations (training samples) and \\(n\\) independent feature/input variables. Note the inconsistency in the matrix size, I just want to point out that the second matrix, has a column of one in the first row because we usually have a bias term \\(\\mathrm{x_0}\\) , which we set to 1. \\[\\mathrm{X} = \\begin{bmatrix} (\\mathbf{x^{(1)}})^{T} \\\\ (\\mathbf{x^{(2)}})^{T} \\\\ \\vdots \\\\ (\\mathbf{x^{(m)}})^{T}\\end{bmatrix}_{m \\times n} = \\begin{bmatrix} 1 & x_1^{(1)} & x_2^{(1)} & \\cdots & x_n^{(1)} \\\\\\\\ 1 & x_1^{(2)} & x_2^{(2)} & \\cdots & x_n^{(2)} \\\\\\\\ \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\\\\ 1 & x_1^{(m)} & x_2^{(m)} & \\cdots & x_n^{(m)} \\end{bmatrix}_{m \\times (n+1)} \\] Single Training Vector: \\(\\mathrm{x}\\) It is worth noting the \\(\\mathrm{x}^{(i)}\\) defined above is formally defined to be the \\(i\\) -th column of \\(\\mathrm{X}\\) , which is the \\(i\\) -th training sample, represented as a \\(n \\times 1\\) column vector . However, the way we define the Design Matrix is that each row of \\(\\mathrm{X}\\) is the transpose of \\(\\mathrm{x}^{(i)}\\) . Note \\(x^{(i)}_j\\) is the value of feature/attribute j in the ith training instance. \\[\\mathbf{x^{(i)}} = \\begin{bmatrix} x_1^{(i)} \\\\ x_2^{(i)} \\\\ \\vdots \\\\ x_n^{(i)} \\end{bmatrix}_{n \\times 1}\\] Target/Label: \\(\\mathrm{Y}\\) This is the target vector. By default, it is a column vector of size \\(m \\times 1\\) . \\[\\mathbf{y} = \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)} \\end{bmatrix}_{m \\times 1}\\] Hypothesis Set: \\(\\mathcal{H}\\) The set where it contains all possible functions to approximate our true function \\(f\\) . Note that the Hypothesis Set can be either continuous or discrete, means to say it can be either a finite or infinite set. But in reality, it is almost always infinite. Hypothesis: \\(\\mathcal{h}: \\mathrm{X} \\to \\mathrm{Y}\\) where \\(\\mathrm{x} \\mapsto \\mathrm{y}\\) Note that this \\(\\mathcal{h} \\in \\mathcal{H}\\) is the hypothesis function, The final best hypothesis function is called \\(g\\) , which approximates the true function \\(f\\) . Learning Algorithm: \\(\\mathcal{A}\\) What this does is from the set of Hypothesis \\(\\mathcal{H}\\) , the learning algorithm's role is to pick one \\(\\mathcal{h} \\in \\mathcal{H}\\) such that this \\(h\\) is the hypothesis function. More often, we also call our final hypothesis learned from \\(\\mathcal{A}\\) \\(g\\) . Hypothesis Subscript \\(\\mathcal{D}\\) : \\(h_{\\mathcal{D}}\\) This is no different from the previous hypothesis, instead the previous \\(h\\) is a shorthand for this notation. This means that the hypothesis we choose is dependent on the sample data given to us, that is to say, given a \\(\\mathcal{D}\\) , we will use \\(\\mathcal{A}\\) to learn a \\(h_{\\mathcal{D}}\\) from \\(\\mathcal{H}\\) . Generalization Error/Test Error/Out-of-Sample Error: \\(\\mathcal{E}_{\\text{out}}(h)\\) Reference from Foundations of Machine Learning . Given a hypothesis \\(h \\in \\mathcal{H}\\) , a true function \\(f \\in \\mathcal{C}\\) , and an underlying distribution \\(\\mathcal{P}\\) , the test/out-of-sample error of \\(h\\) is defined by \\( \\(\\begin{aligned}\\mathcal{E}_{\\text{out}}(h) = \\underset{x \\sim \\mathcal{P}}{\\mathrm{Pr}}[h(\\mathrm{x}) \\neq f(\\mathrm{x})]\\end{aligned}\\) \\) Note that the above equation is just the error rate between the hypothesis function \\(h\\) and the true function \\(f\\) and as a result, the test error of a hypothesis is not known because both the distribution \\(\\mathcal{P}\\) and the true function \\(f\\) are unknown. This brings us to the next best thing we can measure, the In-sample/Empirical/Training Error. More formally, in a regression setting where we Mean Squared Error, \\( \\(\\begin{aligned}\\mathcal{E}_{\\text{out}}(h) = \\mathbb{E}_{\\mathrm{x}}\\left[(h_{\\mathcal{D}}(\\mathrm{x}) - f(\\mathrm{x}))^2 \\right] \\end{aligned}\\) \\) This is difficult and confusing to understand. To water down the formal definition, it is worth taking an example, in \\(\\mathcal{E}_{\\text{out}}(h)\\) we are only talking about the Expected Test Error over the Test Set and nothing else. Think of a test set with only one query point , we call it \\(\\mathrm{x}_{q}\\) , then the above equation is just \\( \\(\\begin{aligned}\\mathcal{E}_{\\text{out}}(h) = \\mathbb{E}_{\\mathrm{x}_{q}}\\left[(h_{\\mathcal{D}}(\\mathrm{x}_{q}) - f(\\mathrm{x}_{q}))^2 \\right] \\end{aligned}\\) \\) over a single point over the distribution \\(\\mathrm{x}_{q}\\) . That is if \\(\\mathrm{x}_{q} = 3\\) and \\(h_{\\mathcal{D}}(\\mathrm{x}_{q}) = 2\\) and \\(f(\\mathrm{x}_{q}) = 5\\) , then \\((h_{\\mathcal{D}}(\\mathrm{x}_{q}) - f(\\mathrm{x}_{q}))^2 = 9\\) and it follows that \\( \\(\\mathcal{E}_{\\text{out}}(h) = \\mathbb{E}_{\\mathrm{x}_{q}}\\left[(h_{\\mathcal{D}}(\\mathrm{x}_{q}) - f(\\mathrm{x}_{q}))^2 \\right] = \\mathbb{E}_{\\mathrm{x}_{q}}[9] = \\frac{9}{1} = 9\\) \\) Note that I purposely denoted the denominator to be 1 because we have only 1 test point, if we were to have 2 test point, say \\(\\mathrm{x} = [x_{p}, x_{q}] = [3, 6]\\) , then if \\(h_{\\mathcal{D}}(x_{p}) = 4\\) and \\(f(x_{p}) = 6\\) , then our \\((h_{\\mathcal{D}}(\\mathrm{x}_{p}) - f(\\mathrm{x}_{p}))^2 = 4\\) . Then our \\( \\(\\mathcal{E}_{\\text{out}}(h) = \\mathbb{E}_{\\mathrm{x}}\\left[(h_{\\mathcal{D}}(\\mathrm{x}) - f(\\mathrm{x}))^2 \\right] = \\mathbb{E}_{\\mathrm{x}_{q}}[[9, 4]] = \\frac{1}{2} [9 + 4] = 6.5\\) \\) Note how I secretly removed the subscript in \\(\\mathrm{x}\\) , and how when there are two points, we are taking expectation over the 2 points. So if we have \\(m\\) test points, then the expectation is taken over all the test points. Till now, our hypothesis \\(h\\) is fixed over a particular sample set \\(\\mathcal{D}\\) . We will now move on to the next concept on Expected Generalization Error (adding a word Expected in front makes a lot of difference). Expected Generalization Error/Test Error/Out-of-Sample Error: \\(\\mathbb{E}_{\\mathcal{D}}[\\mathcal{E}_{\\text{out}}(h)]\\) For the previous generalization error, we are only talking a fixed hypothesis generated by one particular \\(\\mathcal{D}\\) . In order to remove this dependency, we can simply take the expectation of Generalization Error of \\(h\\) over a particular \\(\\mathcal{D}\\) by simply taking the expectation over all such \\(\\mathcal{D}_{i}\\) , \\(i = 1,2,3,...K\\) . Then the Expected Generalization Test Error is independent of any particular realization of \\(\\mathcal{D}\\) : \\[\\begin{aligned}\\mathbb{E}_{\\mathcal{D}}[\\mathcal{E}_{\\text{out}}(h)] = \\mathbb{E}_{\\mathcal{D}}[\\mathbb{E}_{\\mathrm{x}}\\left[(h_{\\mathcal{D}}(\\mathrm{x}) - f(\\mathrm{x}))^2 \\right]] \\end{aligned}\\] In the following example, we can calculate the Expected Generalization Error, where we are using the Error to be Mean Squared Error, so in essence, we are finding the expected MSE. Empirical Error/Training Error/In-Sample Error: \\(\\mathcal{E}_{\\text{in}}(h)\\) Given a hypothesis \\(h \\in \\mathcal{H}\\) , a true function \\(f \\in \\mathcal{C}\\) , and an underlying distribution \\(\\mathcal{P}\\) , and a sample \\(\\mathrm{X}\\) drawn from \\(\\mathcal{X}\\) i.i.d with distribution \\(\\mathcal{P}\\) , the test/out-of-sample error of \\(h\\) is defined by \\( \\(\\begin{aligned}\\mathcal{E}_{\\text{in}}(h) = \\frac{1}{\\mathrm{m}}\\sum_{i=1}^{\\mathrm{m}}\\text{sign}[h(\\mathrm{x}^{(i)}) \\neq f(\\mathrm{x}^{(i)})]\\end{aligned}\\) \\) Here the sign function is mainly used for binary classification, where if \\(h\\) and \\(f\\) disagrees at any point \\(x^{(i)}\\) , then \\(\\text{sign}[h(\\mathrm{x}^{(i)}) \\neq f(\\mathrm{x}^{(i)})]\\) evaluates to 1. We take the sum of all disagreements and divide by the total number of samples. In short, that is just the misclassification/error rate. The empirical error of \\(h \\in \\mathcal{H}\\) is its average error over the sample \\(\\mathcal{X}\\) , in contrast, the generalization error is its expected error based on the distribution \\(\\mathcal{P}\\) . Take careful note here that \\(h(x^{(i)})\\) is the prediction made by our hypothesis (model), we can conventionally call it \\(\\hat{y}^{(i)}\\) whereby our \\(f(x^{(i)})\\) is our ground truth label \\(y^{(i)}\\) . I believe that this ground truth label is realized once we draw the sample from \\(\\mathcal{X}\\) even though we do not know what \\(f\\) is. An additional note here, is that the summand of the in-sample error function is not fixated to the sign function. In fact, I believe you can define any loss function to calculate the \"error\". As an example, if we are dealing with regression, then we can modify the summand to our favourite Mean Squared Error. \\[\\begin{aligned}\\mathcal{E}_{\\text{in}}(h) = \\frac{1}{\\mathrm{m}}\\sum_{i=1}^{\\mathrm{m}}[h(\\mathrm{x}^{(i)}) - f(\\mathrm{x}^{(i)})]^2\\end{aligned}\\] Bias - Variance Decomposition This is a decomposition of the Expected Generalization Error. Formal Proof please read Learning From Data. Unless otherwise stated, we consider only the univariate case where \\(\\mathrm{x}\\) is a single test point. \\[\\begin{align*} \\mathbb{E}_{\\mathcal{D}}[\\mathcal{E}_{\\text{out}}(h)] &= \\mathbb{E}_{\\mathcal{D}}[\\mathbb{E}_{\\mathrm{x}}\\left[(h_{\\mathcal{D}}(\\mathrm{x}) - f(\\mathrm{x}))^2 \\right]] \\\\ &= \\big(\\;\\mathbb{E}_{\\mathcal{D}}[\\;h_{\\mathcal{D}}(x)\\;] - f(x)\\;\\big)^2 + \\mathbb{E}_{\\mathcal{D}}\\big[\\;(\\;h_{\\mathcal{D}}(x) - \\mathbb{E}_{\\mathcal{D}}[\\;h_{\\mathcal{D}}(x)\\;])^2\\;\\big] + \\mathbb{E}\\big[(y-f(x))^2\\big] \\\\ &= \\big(\\;\\bar{h}(\\mathrm{x}) - f(x)\\;\\big)^2 + \\mathbb{E}_\\mathcal{D}\\big[\\;(\\;h_{\\mathcal{D}}(x) - \\bar{h}(\\mathrm{x}) \\;])^2\\;\\big]+ \\mathbb{E}\\big[(y-f(x))^2\\big] \\end{align*} \\] Where $\\big(\\;\\mathbb{E} {\\mathcal{D}}[\\;h }(x)\\;] - f(x)\\;\\big)^2 $ is the Bias, \\(\\mathbb{E}_\\mathcal{D}\\big[\\;(\\;h_{\\mathcal{D}}(x) - \\mathbb{E}_{\\mathcal{D}}[\\;h_{\\mathcal{D}}(x)\\;])^2\\;\\big]\\) is the Variance and \\(\\mathbb{E}\\big[(y-f(x))^2\\big]\\) is the irreducible error \\(\\epsilon\\) . Bias: \\(\\big(\\;\\mathbb{E}_\\mathcal{D}[\\;h_{\\mathcal{D}}(x)\\;] - f(x)\\;\\big)^2\\) In other form, we can express Bias as \\( \\(\\big(\\;\\mathbb{E}_{\\mathcal{D}}[\\;h_{\\mathcal{D}}(x)\\;] - f(x)\\;\\big)^2 = \\big(\\;\\bar{h}(\\mathrm{x}) - f(x)\\;\\big)^2\\) \\) See simulation on Bias-Variance Tradeoff to understand. If our test point is \\(x_{q} = 0.9\\) , then our bias is as such: \\[ \\widehat{\\text{bias}} \\left(\\hat{f}(0.90) \\right) = \\frac{1}{n_{\\texttt{sims}}}\\sum_{i = 1}^{n_{\\texttt{sims}}} \\left(\\hat{f}_k^{[i]}(0.90) \\right) - f(0.90) \\] Variance: \\(\\mathbb{E}_\\mathcal{D}\\big[\\;(\\;h_{\\mathcal{D}}(x) - \\mathbb{E}_{\\mathcal{D}}[\\;h_{\\mathcal{D}}(x)\\;])^2\\;\\big]\\) This is more confusing, but we first express Variance as: \\[\\mathbb{E}_\\mathcal{D}\\big[\\;(\\;h_{\\mathcal{D}}(x) - \\mathbb{E}_{\\mathcal{D}}[\\;h_{\\mathcal{D}}(x)\\;])^2\\;\\big] = \\mathbb{E}_\\mathcal{D}\\big[\\;(\\;h_{\\mathcal{D}}(x) - \\bar{h}(\\mathrm{x}) \\;])^2\\;\\big]\\] If our test point is \\(x_{q} = 0.9\\) , then our variance is as such: \\[ \\widehat{\\text{var}} \\left(\\hat{f}(0.90) \\right) = \\frac{1}{n_{\\texttt{sims}}}\\sum_{i = 1}^{n_{\\texttt{sims}}} \\left(\\hat{f}_k^{[i]}(0.90) - \\frac{1}{n_{\\texttt{sims}}}\\sum_{i = 1}^{n_{\\texttt{sims}}}\\hat{f}_k^{[i]}(0.90) \\right)^2 \\] Pseudo Code Cross-Validation Define \\(G\\) as the set of combination of hyperparamters. Define number of splits to be \\(K\\) . For each set of hyperparameter \\(z \\in Z\\) : for fold \\(j\\) in K: Set \\(F_{\\text{train}}=\\bigcup\\limits_{i\\neq k}^{K} F_{i}\\) Set \\(F_{\\text{val}} = F_{j}\\) as the validation set Perform Standard Scaling on \\(F_{\\text{train}}\\) and find the mean and std Perform VIF recursively on \\(F_{\\text{train}}\\) and find the selected features Transform \\(F_{\\text{val}}\\) using the mean and std found using \\(F_{\\text{train}}\\) Transform \\(F_{\\text{val}}\\) to have only the selected features from \\(F_{\\text{train}}\\) Train and fit on \\(F_{\\text{train}}\\) Evaluate the fitted parameters on \\(F_{\\text{val}}\\) to obtain \\(\\mathcal{M}\\) Logistic Regression Given target variable \\(Y \\in \\{0, 1\\}\\) and predictors \\(X\\) , denote \\(\\mathbb{P}(X) = P(Y = 1 | X)\\) to estimate the probability of \\(Y\\) is of positive (malignant) class. LR expresses \\(\\mathbb{P}\\) as a function the predictors \\(X\\) as \\(\\mathbb{P}(X) = \\sigma(\\hat{\\mathrm{\\beta}}^T X) = \\frac{1}{1 + \\exp(\\hat{\\mathrm{\\beta}}^T X)}\\) where \\(\\hat{\\beta}\\) is the estimated coefficients of the model. One thing worth mentioning is the logistic function \\(\\sigma(z) = \\frac{1}{1 + \\exp(-z)}\\) outputs values from 0 to 1 which is actually the functional form of our hypothesis, and therefore makes up the \\textbf{Hypothesis Space} \\(\\mathcal{H}\\) . We then uses a learning algorithm \\(\\mathcal{A}\\) , \\textbf{Maximum Likelihood Estimation (MLE)}, to estimate the coefficients of our predictors; however, since there is no closed form solution to MLE, the learning algorithm will use optimization techniques like \\textbf{Gradient Descent}\\footnote{We can use Gradient Descent if we instead minimze the negative loglikehood function which is the same as maximizing MLE} to find \\(\\hat{\\beta}\\) . Readings and References False-positive and false-negative cases of fine-needle aspiration cytology for palpable breast lesions What is a Dendrogram? Breast Biopsy - Mayo Clinic Data Centric - Andrew Ng When is Multicollinearity not an issue - Paul Allison Intuitive Explanation of Multicollinearity in Linear Regression - Stackoverflow Hypothesis Testing Across Models Hypothesis Test for Comparing ML Algorithms - Jason Brownlee Regression Modelling Strategies - Professor Frank Harrell Damage Caused by Classification Accuracy and Other Discontinuous Improper Accuracy Scoring Rules - Professor Frank Harrell On a reliable cross validation split 1 On a reliable cross validation split 2 Estimate Generalization Error Using Boxplot to compare Model's Performance Common Pitfalls - Scikit-Learn Common pitfalls in the interpretation of coefficients of linear models - Scikit-Learn Calibrated Classification - Jason Brownlee scikit learn calibration Are you sure your models return probabilities? cambridge's probability calibration calibration in ML Terms Brier Score and Model Calibration - Neptune AI Google's take on calibrated models IMPORTANT: WHAT IS CALIBRATION Hands on sklearn calibration Hands on sklearn calibration v2 Examples of scoring rules Logistic Regression is well calibrated","title":"Notations"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#notations","text":"","title":"Notations"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#input-space-mathcalx","text":"The input space contains the set of all possible examples/instances in a population . This is generally unknown.","title":"Input Space: \\(\\mathcal{X}\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#output-space-mathcaly","text":"The output space is the set of all possible labels/targets that corresponds to each point in \\(\\mathcal{X}\\) .","title":"Output Space: \\(\\mathcal{Y}\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#distribution-mathcalp","text":"Reference: Learning From Data p43. The unknown distribution that generated our input space \\(\\mathcal{X}\\) . In general, instead of the mapping \\(\\mathrm{y} = f(\\mathrm{x})\\) , we can take the output \\(\\mathrm{y}\\) to be a random variable that is affected by, rather than determined by, the input \\(\\mathrm{x}\\) . Formally, we have a target distribution \\(\\mathcal{P}(\\mathrm{y} | \\mathrm{x})\\) instead of just \\(\\mathrm{y} = f(\\mathrm{x})\\) . Now we say that any point \\((\\mathrm{x}, \\mathrm{y})\\) in \\(\\mathcal{X}\\) is now generated by the joint distribution \\( \\(\\mathcal{P}(\\mathrm{x}, \\mathrm{y}) = \\mathcal{P}(\\mathrm{x})\\mathcal{P}(\\mathrm{y} | \\mathrm{x})\\) \\)","title":"Distribution: \\(\\mathcal{P}\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#data-mathcald","text":"This is the set of samples drawn from \\(\\mathcal{X} \\times \\mathcal{Y}\\) over a distribution \\(\\mathcal{P}\\) . The general notation is as follows: \\( \\(\\mathcal{D} = [(\\mathrm{x^{(1)}}, \\mathrm{y^{(1)}}), (\\mathrm{x^{(2)}}, \\mathrm{y^{(2)}}), ..., (\\mathrm{x^{(N)}}, \\mathrm{y^{(N)}}))]\\) \\) where \\(N\\) denotes the number of training samples, and each \\(\\mathrm{x}^{(i)} \\in \\mathbb{R}^{n}\\) with \\(n\\) features. In general, \\(\\mathrm{y}^{(i)} \\in \\mathbb{R}\\) and is a single label. We can split \\(\\mathcal{D}\\) into two sets respectively, where \\(\\mathrm{X}\\) consists of all the \\(\\mathrm{x}\\) , and \\(\\mathrm{Y}\\) consists of all the \\(\\mathrm{y}\\) . We will see this next.","title":"Data: \\(\\mathcal{D}\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#design-matrix-mathrmx","text":"Let \\(\\mathrm{X}\\) be the design matrix of dimensions \\(m\u2005\\times\u2005(n\u2005+\u20051)\\) where \\(m\\) is the number of observations (training samples) and \\(n\\) independent feature/input variables. Note the inconsistency in the matrix size, I just want to point out that the second matrix, has a column of one in the first row because we usually have a bias term \\(\\mathrm{x_0}\\) , which we set to 1. \\[\\mathrm{X} = \\begin{bmatrix} (\\mathbf{x^{(1)}})^{T} \\\\ (\\mathbf{x^{(2)}})^{T} \\\\ \\vdots \\\\ (\\mathbf{x^{(m)}})^{T}\\end{bmatrix}_{m \\times n} = \\begin{bmatrix} 1 & x_1^{(1)} & x_2^{(1)} & \\cdots & x_n^{(1)} \\\\\\\\ 1 & x_1^{(2)} & x_2^{(2)} & \\cdots & x_n^{(2)} \\\\\\\\ \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\\\\ 1 & x_1^{(m)} & x_2^{(m)} & \\cdots & x_n^{(m)} \\end{bmatrix}_{m \\times (n+1)} \\]","title":"Design Matrix: \\(\\mathrm{X}\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#single-training-vector-mathrmx","text":"It is worth noting the \\(\\mathrm{x}^{(i)}\\) defined above is formally defined to be the \\(i\\) -th column of \\(\\mathrm{X}\\) , which is the \\(i\\) -th training sample, represented as a \\(n \\times 1\\) column vector . However, the way we define the Design Matrix is that each row of \\(\\mathrm{X}\\) is the transpose of \\(\\mathrm{x}^{(i)}\\) . Note \\(x^{(i)}_j\\) is the value of feature/attribute j in the ith training instance. \\[\\mathbf{x^{(i)}} = \\begin{bmatrix} x_1^{(i)} \\\\ x_2^{(i)} \\\\ \\vdots \\\\ x_n^{(i)} \\end{bmatrix}_{n \\times 1}\\]","title":"Single Training Vector: \\(\\mathrm{x}\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#targetlabel-mathrmy","text":"This is the target vector. By default, it is a column vector of size \\(m \\times 1\\) . \\[\\mathbf{y} = \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)} \\end{bmatrix}_{m \\times 1}\\]","title":"Target/Label: \\(\\mathrm{Y}\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#hypothesis-set-mathcalh","text":"The set where it contains all possible functions to approximate our true function \\(f\\) . Note that the Hypothesis Set can be either continuous or discrete, means to say it can be either a finite or infinite set. But in reality, it is almost always infinite.","title":"Hypothesis Set: \\(\\mathcal{H}\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#hypothesis-mathcalh-mathrmx-to-mathrmy-where-mathrmx-mapsto-mathrmy","text":"Note that this \\(\\mathcal{h} \\in \\mathcal{H}\\) is the hypothesis function, The final best hypothesis function is called \\(g\\) , which approximates the true function \\(f\\) .","title":"Hypothesis: \\(\\mathcal{h}: \\mathrm{X} \\to \\mathrm{Y}\\) where \\(\\mathrm{x} \\mapsto \\mathrm{y}\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#learning-algorithm-mathcala","text":"What this does is from the set of Hypothesis \\(\\mathcal{H}\\) , the learning algorithm's role is to pick one \\(\\mathcal{h} \\in \\mathcal{H}\\) such that this \\(h\\) is the hypothesis function. More often, we also call our final hypothesis learned from \\(\\mathcal{A}\\) \\(g\\) .","title":"Learning Algorithm: \\(\\mathcal{A}\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#hypothesis-subscript-mathcald-h_mathcald","text":"This is no different from the previous hypothesis, instead the previous \\(h\\) is a shorthand for this notation. This means that the hypothesis we choose is dependent on the sample data given to us, that is to say, given a \\(\\mathcal{D}\\) , we will use \\(\\mathcal{A}\\) to learn a \\(h_{\\mathcal{D}}\\) from \\(\\mathcal{H}\\) .","title":"Hypothesis Subscript \\(\\mathcal{D}\\): \\(h_{\\mathcal{D}}\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#generalization-errortest-errorout-of-sample-error-mathcale_textouth","text":"Reference from Foundations of Machine Learning . Given a hypothesis \\(h \\in \\mathcal{H}\\) , a true function \\(f \\in \\mathcal{C}\\) , and an underlying distribution \\(\\mathcal{P}\\) , the test/out-of-sample error of \\(h\\) is defined by \\( \\(\\begin{aligned}\\mathcal{E}_{\\text{out}}(h) = \\underset{x \\sim \\mathcal{P}}{\\mathrm{Pr}}[h(\\mathrm{x}) \\neq f(\\mathrm{x})]\\end{aligned}\\) \\) Note that the above equation is just the error rate between the hypothesis function \\(h\\) and the true function \\(f\\) and as a result, the test error of a hypothesis is not known because both the distribution \\(\\mathcal{P}\\) and the true function \\(f\\) are unknown. This brings us to the next best thing we can measure, the In-sample/Empirical/Training Error. More formally, in a regression setting where we Mean Squared Error, \\( \\(\\begin{aligned}\\mathcal{E}_{\\text{out}}(h) = \\mathbb{E}_{\\mathrm{x}}\\left[(h_{\\mathcal{D}}(\\mathrm{x}) - f(\\mathrm{x}))^2 \\right] \\end{aligned}\\) \\) This is difficult and confusing to understand. To water down the formal definition, it is worth taking an example, in \\(\\mathcal{E}_{\\text{out}}(h)\\) we are only talking about the Expected Test Error over the Test Set and nothing else. Think of a test set with only one query point , we call it \\(\\mathrm{x}_{q}\\) , then the above equation is just \\( \\(\\begin{aligned}\\mathcal{E}_{\\text{out}}(h) = \\mathbb{E}_{\\mathrm{x}_{q}}\\left[(h_{\\mathcal{D}}(\\mathrm{x}_{q}) - f(\\mathrm{x}_{q}))^2 \\right] \\end{aligned}\\) \\) over a single point over the distribution \\(\\mathrm{x}_{q}\\) . That is if \\(\\mathrm{x}_{q} = 3\\) and \\(h_{\\mathcal{D}}(\\mathrm{x}_{q}) = 2\\) and \\(f(\\mathrm{x}_{q}) = 5\\) , then \\((h_{\\mathcal{D}}(\\mathrm{x}_{q}) - f(\\mathrm{x}_{q}))^2 = 9\\) and it follows that \\( \\(\\mathcal{E}_{\\text{out}}(h) = \\mathbb{E}_{\\mathrm{x}_{q}}\\left[(h_{\\mathcal{D}}(\\mathrm{x}_{q}) - f(\\mathrm{x}_{q}))^2 \\right] = \\mathbb{E}_{\\mathrm{x}_{q}}[9] = \\frac{9}{1} = 9\\) \\) Note that I purposely denoted the denominator to be 1 because we have only 1 test point, if we were to have 2 test point, say \\(\\mathrm{x} = [x_{p}, x_{q}] = [3, 6]\\) , then if \\(h_{\\mathcal{D}}(x_{p}) = 4\\) and \\(f(x_{p}) = 6\\) , then our \\((h_{\\mathcal{D}}(\\mathrm{x}_{p}) - f(\\mathrm{x}_{p}))^2 = 4\\) . Then our \\( \\(\\mathcal{E}_{\\text{out}}(h) = \\mathbb{E}_{\\mathrm{x}}\\left[(h_{\\mathcal{D}}(\\mathrm{x}) - f(\\mathrm{x}))^2 \\right] = \\mathbb{E}_{\\mathrm{x}_{q}}[[9, 4]] = \\frac{1}{2} [9 + 4] = 6.5\\) \\) Note how I secretly removed the subscript in \\(\\mathrm{x}\\) , and how when there are two points, we are taking expectation over the 2 points. So if we have \\(m\\) test points, then the expectation is taken over all the test points. Till now, our hypothesis \\(h\\) is fixed over a particular sample set \\(\\mathcal{D}\\) . We will now move on to the next concept on Expected Generalization Error (adding a word Expected in front makes a lot of difference).","title":"Generalization Error/Test Error/Out-of-Sample Error: \\(\\mathcal{E}_{\\text{out}}(h)\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#expected-generalization-errortest-errorout-of-sample-error-mathbbe_mathcaldmathcale_textouth","text":"For the previous generalization error, we are only talking a fixed hypothesis generated by one particular \\(\\mathcal{D}\\) . In order to remove this dependency, we can simply take the expectation of Generalization Error of \\(h\\) over a particular \\(\\mathcal{D}\\) by simply taking the expectation over all such \\(\\mathcal{D}_{i}\\) , \\(i = 1,2,3,...K\\) . Then the Expected Generalization Test Error is independent of any particular realization of \\(\\mathcal{D}\\) : \\[\\begin{aligned}\\mathbb{E}_{\\mathcal{D}}[\\mathcal{E}_{\\text{out}}(h)] = \\mathbb{E}_{\\mathcal{D}}[\\mathbb{E}_{\\mathrm{x}}\\left[(h_{\\mathcal{D}}(\\mathrm{x}) - f(\\mathrm{x}))^2 \\right]] \\end{aligned}\\] In the following example, we can calculate the Expected Generalization Error, where we are using the Error to be Mean Squared Error, so in essence, we are finding the expected MSE.","title":"Expected Generalization Error/Test Error/Out-of-Sample Error: \\(\\mathbb{E}_{\\mathcal{D}}[\\mathcal{E}_{\\text{out}}(h)]\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#empirical-errortraining-errorin-sample-error-mathcale_textinh","text":"Given a hypothesis \\(h \\in \\mathcal{H}\\) , a true function \\(f \\in \\mathcal{C}\\) , and an underlying distribution \\(\\mathcal{P}\\) , and a sample \\(\\mathrm{X}\\) drawn from \\(\\mathcal{X}\\) i.i.d with distribution \\(\\mathcal{P}\\) , the test/out-of-sample error of \\(h\\) is defined by \\( \\(\\begin{aligned}\\mathcal{E}_{\\text{in}}(h) = \\frac{1}{\\mathrm{m}}\\sum_{i=1}^{\\mathrm{m}}\\text{sign}[h(\\mathrm{x}^{(i)}) \\neq f(\\mathrm{x}^{(i)})]\\end{aligned}\\) \\) Here the sign function is mainly used for binary classification, where if \\(h\\) and \\(f\\) disagrees at any point \\(x^{(i)}\\) , then \\(\\text{sign}[h(\\mathrm{x}^{(i)}) \\neq f(\\mathrm{x}^{(i)})]\\) evaluates to 1. We take the sum of all disagreements and divide by the total number of samples. In short, that is just the misclassification/error rate. The empirical error of \\(h \\in \\mathcal{H}\\) is its average error over the sample \\(\\mathcal{X}\\) , in contrast, the generalization error is its expected error based on the distribution \\(\\mathcal{P}\\) . Take careful note here that \\(h(x^{(i)})\\) is the prediction made by our hypothesis (model), we can conventionally call it \\(\\hat{y}^{(i)}\\) whereby our \\(f(x^{(i)})\\) is our ground truth label \\(y^{(i)}\\) . I believe that this ground truth label is realized once we draw the sample from \\(\\mathcal{X}\\) even though we do not know what \\(f\\) is. An additional note here, is that the summand of the in-sample error function is not fixated to the sign function. In fact, I believe you can define any loss function to calculate the \"error\". As an example, if we are dealing with regression, then we can modify the summand to our favourite Mean Squared Error. \\[\\begin{aligned}\\mathcal{E}_{\\text{in}}(h) = \\frac{1}{\\mathrm{m}}\\sum_{i=1}^{\\mathrm{m}}[h(\\mathrm{x}^{(i)}) - f(\\mathrm{x}^{(i)})]^2\\end{aligned}\\]","title":"Empirical Error/Training Error/In-Sample Error: \\(\\mathcal{E}_{\\text{in}}(h)\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#bias-variance-decomposition","text":"This is a decomposition of the Expected Generalization Error. Formal Proof please read Learning From Data. Unless otherwise stated, we consider only the univariate case where \\(\\mathrm{x}\\) is a single test point. \\[\\begin{align*} \\mathbb{E}_{\\mathcal{D}}[\\mathcal{E}_{\\text{out}}(h)] &= \\mathbb{E}_{\\mathcal{D}}[\\mathbb{E}_{\\mathrm{x}}\\left[(h_{\\mathcal{D}}(\\mathrm{x}) - f(\\mathrm{x}))^2 \\right]] \\\\ &= \\big(\\;\\mathbb{E}_{\\mathcal{D}}[\\;h_{\\mathcal{D}}(x)\\;] - f(x)\\;\\big)^2 + \\mathbb{E}_{\\mathcal{D}}\\big[\\;(\\;h_{\\mathcal{D}}(x) - \\mathbb{E}_{\\mathcal{D}}[\\;h_{\\mathcal{D}}(x)\\;])^2\\;\\big] + \\mathbb{E}\\big[(y-f(x))^2\\big] \\\\ &= \\big(\\;\\bar{h}(\\mathrm{x}) - f(x)\\;\\big)^2 + \\mathbb{E}_\\mathcal{D}\\big[\\;(\\;h_{\\mathcal{D}}(x) - \\bar{h}(\\mathrm{x}) \\;])^2\\;\\big]+ \\mathbb{E}\\big[(y-f(x))^2\\big] \\end{align*} \\] Where $\\big(\\;\\mathbb{E} {\\mathcal{D}}[\\;h }(x)\\;] - f(x)\\;\\big)^2 $ is the Bias, \\(\\mathbb{E}_\\mathcal{D}\\big[\\;(\\;h_{\\mathcal{D}}(x) - \\mathbb{E}_{\\mathcal{D}}[\\;h_{\\mathcal{D}}(x)\\;])^2\\;\\big]\\) is the Variance and \\(\\mathbb{E}\\big[(y-f(x))^2\\big]\\) is the irreducible error \\(\\epsilon\\) .","title":"Bias - Variance Decomposition"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#bias-bigmathbbe_mathcaldh_mathcaldx-fxbig2","text":"In other form, we can express Bias as \\( \\(\\big(\\;\\mathbb{E}_{\\mathcal{D}}[\\;h_{\\mathcal{D}}(x)\\;] - f(x)\\;\\big)^2 = \\big(\\;\\bar{h}(\\mathrm{x}) - f(x)\\;\\big)^2\\) \\) See simulation on Bias-Variance Tradeoff to understand. If our test point is \\(x_{q} = 0.9\\) , then our bias is as such: \\[ \\widehat{\\text{bias}} \\left(\\hat{f}(0.90) \\right) = \\frac{1}{n_{\\texttt{sims}}}\\sum_{i = 1}^{n_{\\texttt{sims}}} \\left(\\hat{f}_k^{[i]}(0.90) \\right) - f(0.90) \\]","title":"Bias: \\(\\big(\\;\\mathbb{E}_\\mathcal{D}[\\;h_{\\mathcal{D}}(x)\\;] - f(x)\\;\\big)^2\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#variance-mathbbe_mathcaldbigh_mathcaldx-mathbbe_mathcaldh_mathcaldx2big","text":"This is more confusing, but we first express Variance as: \\[\\mathbb{E}_\\mathcal{D}\\big[\\;(\\;h_{\\mathcal{D}}(x) - \\mathbb{E}_{\\mathcal{D}}[\\;h_{\\mathcal{D}}(x)\\;])^2\\;\\big] = \\mathbb{E}_\\mathcal{D}\\big[\\;(\\;h_{\\mathcal{D}}(x) - \\bar{h}(\\mathrm{x}) \\;])^2\\;\\big]\\] If our test point is \\(x_{q} = 0.9\\) , then our variance is as such: \\[ \\widehat{\\text{var}} \\left(\\hat{f}(0.90) \\right) = \\frac{1}{n_{\\texttt{sims}}}\\sum_{i = 1}^{n_{\\texttt{sims}}} \\left(\\hat{f}_k^{[i]}(0.90) - \\frac{1}{n_{\\texttt{sims}}}\\sum_{i = 1}^{n_{\\texttt{sims}}}\\hat{f}_k^{[i]}(0.90) \\right)^2 \\]","title":"Variance: \\(\\mathbb{E}_\\mathcal{D}\\big[\\;(\\;h_{\\mathcal{D}}(x) - \\mathbb{E}_{\\mathcal{D}}[\\;h_{\\mathcal{D}}(x)\\;])^2\\;\\big]\\)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#pseudo-code","text":"","title":"Pseudo Code"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#cross-validation","text":"Define \\(G\\) as the set of combination of hyperparamters. Define number of splits to be \\(K\\) . For each set of hyperparameter \\(z \\in Z\\) : for fold \\(j\\) in K: Set \\(F_{\\text{train}}=\\bigcup\\limits_{i\\neq k}^{K} F_{i}\\) Set \\(F_{\\text{val}} = F_{j}\\) as the validation set Perform Standard Scaling on \\(F_{\\text{train}}\\) and find the mean and std Perform VIF recursively on \\(F_{\\text{train}}\\) and find the selected features Transform \\(F_{\\text{val}}\\) using the mean and std found using \\(F_{\\text{train}}\\) Transform \\(F_{\\text{val}}\\) to have only the selected features from \\(F_{\\text{train}}\\) Train and fit on \\(F_{\\text{train}}\\) Evaluate the fitted parameters on \\(F_{\\text{val}}\\) to obtain \\(\\mathcal{M}\\)","title":"Cross-Validation"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#logistic-regression","text":"Given target variable \\(Y \\in \\{0, 1\\}\\) and predictors \\(X\\) , denote \\(\\mathbb{P}(X) = P(Y = 1 | X)\\) to estimate the probability of \\(Y\\) is of positive (malignant) class. LR expresses \\(\\mathbb{P}\\) as a function the predictors \\(X\\) as \\(\\mathbb{P}(X) = \\sigma(\\hat{\\mathrm{\\beta}}^T X) = \\frac{1}{1 + \\exp(\\hat{\\mathrm{\\beta}}^T X)}\\) where \\(\\hat{\\beta}\\) is the estimated coefficients of the model. One thing worth mentioning is the logistic function \\(\\sigma(z) = \\frac{1}{1 + \\exp(-z)}\\) outputs values from 0 to 1 which is actually the functional form of our hypothesis, and therefore makes up the \\textbf{Hypothesis Space} \\(\\mathcal{H}\\) . We then uses a learning algorithm \\(\\mathcal{A}\\) , \\textbf{Maximum Likelihood Estimation (MLE)}, to estimate the coefficients of our predictors; however, since there is no closed form solution to MLE, the learning algorithm will use optimization techniques like \\textbf{Gradient Descent}\\footnote{We can use Gradient Descent if we instead minimze the negative loglikehood function which is the same as maximizing MLE} to find \\(\\hat{\\beta}\\) .","title":"Logistic Regression"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Appendix/#readings-and-references","text":"False-positive and false-negative cases of fine-needle aspiration cytology for palpable breast lesions What is a Dendrogram? Breast Biopsy - Mayo Clinic Data Centric - Andrew Ng When is Multicollinearity not an issue - Paul Allison Intuitive Explanation of Multicollinearity in Linear Regression - Stackoverflow Hypothesis Testing Across Models Hypothesis Test for Comparing ML Algorithms - Jason Brownlee Regression Modelling Strategies - Professor Frank Harrell Damage Caused by Classification Accuracy and Other Discontinuous Improper Accuracy Scoring Rules - Professor Frank Harrell On a reliable cross validation split 1 On a reliable cross validation split 2 Estimate Generalization Error Using Boxplot to compare Model's Performance Common Pitfalls - Scikit-Learn Common pitfalls in the interpretation of coefficients of linear models - Scikit-Learn Calibrated Classification - Jason Brownlee scikit learn calibration Are you sure your models return probabilities? cambridge's probability calibration calibration in ML Terms Brier Score and Model Calibration - Neptune AI Google's take on calibrated models IMPORTANT: WHAT IS CALIBRATION Hands on sklearn calibration Hands on sklearn calibration v2 Examples of scoring rules Logistic Regression is well calibrated","title":"Readings and References"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%200%20-%20Introduction%20and%20Problem%20Statement/","text":"Stage 0: Defining Problem and Assumptions by Hongnan Gao Introduction Note Breast cancer accounts for 30% of the cancers in females, making it the most common cancer in women. Breast cancer is also one of the most curable disease if detected early and there are many measures in place to help. Courtesy of Singapore Cancer Society In our context, we are presented with a dataset that are taken from a biopsy procedure called Fine Needle Aspiration (FNA) performed on the breast. The tissue taken from the biopsy will then be sent to a lab and be examined by a pathologist, a report will be written if cancerous cells are spotted or not and be sent to the specialist to further explain the results to the patient. However, there may be disagreements whereby the pathologist report shows there are no signs of cancerous cells, while radiologist may disagree as he/she might find suspicious lesions from the mammogram/CT/MRI scans. This can happen if the biopsy taken is only on the benign cells and if there is dispute, a more thorough of biopsy may be performed again. Although our aim in Machine Learning is to classify whether a tumor is benign or malignant, we should bear in mind that we are not trying to dispute the expertise of the doctors/pathologists/radiologists. Instead, we develop models to aid their understanding, and also to come up with a more systematic benchmark for one to refer to. More concretely, the dataset has features that are computed from a digitized image from FNA , and each observation describes statistics/characteristics of the cell nucleus. There are 10 base features, and 3 different measurements are taken for each feature, namely, the mean, standard error and the \"worst/largest\" . One thing to note is that worst means the mean of the three largest values . Attribute Information: ID number Diagnosis (M = malignant, B = benign) Ten real-valued features are computed for each cell nucleus: radius (mean of distances from center to points on the perimeter) texture (standard deviation of gray-scale values) perimeter area smoothness (local variation in radius lengths) compactness ( \\(\\text{perimeter}^2 / \\text{area} - 1.0\\) ) concavity (severity of concave portions of the contour) concave points (number of concave portions of the contour) symmetry fractal dimension (\"coastline approximation\" - 1) With these in mind, let us move on to defining the problem and state some initial assumptions. Problem Statement Informal Description To develop a Machine Learning Model that can classify whether a tumor is benign or malignant. We also note that we care more about whether a cancer patient is classified correctly. Formal Description Given a dataset \\(\\mathcal{D}\\) describing characteristics of a tumor, the task \\(\\mathcal{T}\\) is a binary classification problem where we aim to find an optimal hypothesis \\(g \\in \\mathcal{H}\\) using a learning algorithm \\(\\mathcal{A}\\) . The optimal hypothesis \\(g\\) should generalize well, that is to say, has a low expected generalization error \\(\\mathcal{E}\\) over a performance measure \\(\\mathrm{M}\\) . We will choose the performance measure in the later sections (not accuracy). Considerations Info Size of Dataset: The dataset is not too large, we need to be wary of an overly complex model which may easily overfit, but may not generalize well. Model Interpretation: There is a tradeoff between Model's complexity/flexibility and it's interpretability. If we need to explain our model to our business stakeholders, then it is a good idea to choose a model that can be interpreted well, models like Logistic Regression with Lasso may be a good choice as the model itself has better interpretation, and with lasso we can reduce the number of features. If we only care about our model's ability to predict, then interpretability may not be so important and we may choose a model that performs well, but the weights may be more difficult to understand. Time and Space Complexity: Practically speaking, we need to strike a balance between the speed of the training and the performance measure of the model. Data Centric vs Model Centric: From the one and only Andrew Ng 1 we understood that data plays a critical role in the Machine Learning world. https://analyticsindiamag.com/big-data-to-good-data-andrew-ng-urges-ml-community-to-be-more-data-centric-and-less-model-centric/ \u21a9","title":"Introduction"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%200%20-%20Introduction%20and%20Problem%20Statement/#introduction","text":"Note Breast cancer accounts for 30% of the cancers in females, making it the most common cancer in women. Breast cancer is also one of the most curable disease if detected early and there are many measures in place to help. Courtesy of Singapore Cancer Society In our context, we are presented with a dataset that are taken from a biopsy procedure called Fine Needle Aspiration (FNA) performed on the breast. The tissue taken from the biopsy will then be sent to a lab and be examined by a pathologist, a report will be written if cancerous cells are spotted or not and be sent to the specialist to further explain the results to the patient. However, there may be disagreements whereby the pathologist report shows there are no signs of cancerous cells, while radiologist may disagree as he/she might find suspicious lesions from the mammogram/CT/MRI scans. This can happen if the biopsy taken is only on the benign cells and if there is dispute, a more thorough of biopsy may be performed again. Although our aim in Machine Learning is to classify whether a tumor is benign or malignant, we should bear in mind that we are not trying to dispute the expertise of the doctors/pathologists/radiologists. Instead, we develop models to aid their understanding, and also to come up with a more systematic benchmark for one to refer to. More concretely, the dataset has features that are computed from a digitized image from FNA , and each observation describes statistics/characteristics of the cell nucleus. There are 10 base features, and 3 different measurements are taken for each feature, namely, the mean, standard error and the \"worst/largest\" . One thing to note is that worst means the mean of the three largest values . Attribute Information: ID number Diagnosis (M = malignant, B = benign) Ten real-valued features are computed for each cell nucleus: radius (mean of distances from center to points on the perimeter) texture (standard deviation of gray-scale values) perimeter area smoothness (local variation in radius lengths) compactness ( \\(\\text{perimeter}^2 / \\text{area} - 1.0\\) ) concavity (severity of concave portions of the contour) concave points (number of concave portions of the contour) symmetry fractal dimension (\"coastline approximation\" - 1) With these in mind, let us move on to defining the problem and state some initial assumptions.","title":"Introduction"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%200%20-%20Introduction%20and%20Problem%20Statement/#problem-statement","text":"Informal Description To develop a Machine Learning Model that can classify whether a tumor is benign or malignant. We also note that we care more about whether a cancer patient is classified correctly. Formal Description Given a dataset \\(\\mathcal{D}\\) describing characteristics of a tumor, the task \\(\\mathcal{T}\\) is a binary classification problem where we aim to find an optimal hypothesis \\(g \\in \\mathcal{H}\\) using a learning algorithm \\(\\mathcal{A}\\) . The optimal hypothesis \\(g\\) should generalize well, that is to say, has a low expected generalization error \\(\\mathcal{E}\\) over a performance measure \\(\\mathrm{M}\\) . We will choose the performance measure in the later sections (not accuracy).","title":"Problem Statement"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%200%20-%20Introduction%20and%20Problem%20Statement/#considerations","text":"Info Size of Dataset: The dataset is not too large, we need to be wary of an overly complex model which may easily overfit, but may not generalize well. Model Interpretation: There is a tradeoff between Model's complexity/flexibility and it's interpretability. If we need to explain our model to our business stakeholders, then it is a good idea to choose a model that can be interpreted well, models like Logistic Regression with Lasso may be a good choice as the model itself has better interpretation, and with lasso we can reduce the number of features. If we only care about our model's ability to predict, then interpretability may not be so important and we may choose a model that performs well, but the weights may be more difficult to understand. Time and Space Complexity: Practically speaking, we need to strike a balance between the speed of the training and the performance measure of the model. Data Centric vs Model Centric: From the one and only Andrew Ng 1 we understood that data plays a critical role in the Machine Learning world. https://analyticsindiamag.com/big-data-to-good-data-andrew-ng-urges-ml-community-to-be-more-data-centric-and-less-model-centric/ \u21a9","title":"Considerations"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%201%20-%20Preliminary%20Data%20Inspection%20and%20Cleaning/","text":"Stage 1: Preliminary Data Inspection and Clearning by Hongnan Gao Quick Navigation Dependencies and Configuration Stage 1: Preliminary Data Inspection and Cleaning Load the dataset A brief look at the dataset Drop, drop, drop the columns! Data Types Summary Statistics Missing Data Save Data Dependencies and Configuration import random from dataclasses import dataclass , field from typing import List , Dict import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns @dataclass class config : raw_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/raw/data.csv\" processed_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/processed.csv\" train_size : float = 0.9 seed : int = 1992 num_folds : int = 5 cv_schema : str = \"StratifiedKFold\" classification_type : str = \"binary\" target_col : List [ str ] = field ( default_factory = lambda : [ \"diagnosis\" ]) unwanted_cols : List [ str ] = field ( default_factory = lambda : [ \"id\" , \"Unnamed: 32\" ]) # Plotting colors : List [ str ] = field ( default_factory = lambda : [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ] ) cmap_reversed = plt . cm . get_cmap ( \"mako_r\" ) def to_dict ( self ) -> Dict : \"\"\"Convert the config object to a dictionary. Returns: Dict: The config object as a dictionary. \"\"\" return { \"raw_data\" : self . raw_data , \"processed_data\" : self . processed_data , \"train_size\" : self . train_size , \"seed\" : self . seed , \"num_folds\" : self . num_folds , \"cv_schema\" : self . cv_schema , \"classification_type\" : self . classification_type , \"target_col\" : self . target_col , \"unwanted_cols\" : self . unwanted_cols , \"colors\" : self . colors , \"cmap_reversed\" : self . cmap_reversed , } def set_seeds ( seed : int = 1234 ) -> None : \"\"\"Set seeds for reproducibility.\"\"\" np . random . seed ( seed ) random . seed ( seed ) # set config config = config () # set seeding for reproducibility _ = set_seeds ( seed = config . seed ) Stage 1: Preliminary Data Inspection and Cleaning Load the dataset df = pd . read_csv ( config . raw_data ) A brief look at the dataset Info We will query the first five rows of the dataframe to get a feel on the dataset we are working on. We also call df.info() to see the data types of the columns, and to briefly check if there is any missing values in our data (more on that later). # Column Non-Null Count Dtype --- ------ -------------- ----- 0 diagnosis 569 non - null int64 1 radius_mean 569 non - null float64 2 texture_mean 569 non - null float64 3 perimeter_mean 569 non - null float64 Importance of data types We must be sharp and ensure that each column is indeed stored in their respective data types! In the real world, we may often query \"dirty\" data from say, the database, where numeric data are represented in string. It is now our duty to ensure sanity checks are in place! display ( df . head ()) display ( df . info ( verbose = True )) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst Unnamed: 32 0 842302 M 17.99 10.38 122.80 1001.0 0.11840 0.27760 0.3001 0.14710 0.2419 0.07871 1.0950 0.9053 8.589 153.40 0.006399 0.04904 0.05373 0.01587 0.03003 0.006193 25.38 17.33 184.60 2019.0 0.1622 0.6656 0.7119 0.2654 0.4601 0.11890 NaN 1 842517 M 20.57 17.77 132.90 1326.0 0.08474 0.07864 0.0869 0.07017 0.1812 0.05667 0.5435 0.7339 3.398 74.08 0.005225 0.01308 0.01860 0.01340 0.01389 0.003532 24.99 23.41 158.80 1956.0 0.1238 0.1866 0.2416 0.1860 0.2750 0.08902 NaN 2 84300903 M 19.69 21.25 130.00 1203.0 0.10960 0.15990 0.1974 0.12790 0.2069 0.05999 0.7456 0.7869 4.585 94.03 0.006150 0.04006 0.03832 0.02058 0.02250 0.004571 23.57 25.53 152.50 1709.0 0.1444 0.4245 0.4504 0.2430 0.3613 0.08758 NaN 3 84348301 M 11.42 20.38 77.58 386.1 0.14250 0.28390 0.2414 0.10520 0.2597 0.09744 0.4956 1.1560 3.445 27.23 0.009110 0.07458 0.05661 0.01867 0.05963 0.009208 14.91 26.50 98.87 567.7 0.2098 0.8663 0.6869 0.2575 0.6638 0.17300 NaN 4 84358402 M 20.29 14.34 135.10 1297.0 0.10030 0.13280 0.1980 0.10430 0.1809 0.05883 0.7572 0.7813 5.438 94.44 0.011490 0.02461 0.05688 0.01885 0.01756 0.005115 22.54 16.67 152.20 1575.0 0.1374 0.2050 0.4000 0.1625 0.2364 0.07678 NaN <class 'pandas.core.frame.DataFrame'> RangeIndex: 569 entries, 0 to 568 Data columns (total 33 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 id 569 non-null int64 1 diagnosis 569 non-null object 2 radius_mean 569 non-null float64 3 texture_mean 569 non-null float64 4 perimeter_mean 569 non-null float64 5 area_mean 569 non-null float64 6 smoothness_mean 569 non-null float64 7 compactness_mean 569 non-null float64 8 concavity_mean 569 non-null float64 9 concave points_mean 569 non-null float64 10 symmetry_mean 569 non-null float64 11 fractal_dimension_mean 569 non-null float64 12 radius_se 569 non-null float64 13 texture_se 569 non-null float64 14 perimeter_se 569 non-null float64 15 area_se 569 non-null float64 16 smoothness_se 569 non-null float64 17 compactness_se 569 non-null float64 18 concavity_se 569 non-null float64 19 concave points_se 569 non-null float64 20 symmetry_se 569 non-null float64 21 fractal_dimension_se 569 non-null float64 22 radius_worst 569 non-null float64 23 texture_worst 569 non-null float64 24 perimeter_worst 569 non-null float64 25 area_worst 569 non-null float64 26 smoothness_worst 569 non-null float64 27 compactness_worst 569 non-null float64 28 concavity_worst 569 non-null float64 29 concave points_worst 569 non-null float64 30 symmetry_worst 569 non-null float64 31 fractal_dimension_worst 569 non-null float64 32 Unnamed: 32 0 non-null float64 dtypes: float64(31), int64(1), object(1) memory usage: 146.8+ KB None A brief overview tells us our data is alright! There is, however, a column which is unnamed and has no values. This can be of various data source issues, for now, we quickly check the definition given by the dataset from UCI's Breast Cancer Wisconsin (Diagnostic) Data Set and confirm that there should only be 32 columns. With this in mind, we can safely delete the column. We also note that from the above, that the id column is the identifier for each patient. We will also drop this column as it holds no predictive power. When can ID be important? We should try to question our move and justify it. In this dataset, we have to ensure that each ID is unique, if it is not, it may suggest that there are patient records with multiple observation, which is a violation of i.i.d assumption and we may take note when doing cross-validation, so as to avoid information leakage. Since the ID column is unique, we will delete it. We will keep this at the back of our mind in the event that we ever need them for feature engineering. print ( f \"The ID column is unique : { df [ 'id' ] . is_unique } \" ) The ID column is unique : True Drop, drop, drop the columns! Here we define a drop_columns function to drop the unwanted columns. def drop_columns ( df : pd . DataFrame , columns : List ) -> pd . DataFrame : \"\"\"Drop unwanted columns from dataframe. Args: df (pd.DataFrame): Dataframe to be cleaned columns (List): list of columns to be dropped Returns: df_copy (pd.DataFrame): Dataframe with unwanted columns dropped. \"\"\" df_copy = df . copy () df_copy = df_copy . drop ( columns = columns , axis = 1 , inplace = False ) return df_copy . reset_index ( drop = True ) df = drop_columns ( df , columns = config . unwanted_cols ) Data Types Let us split the data types into a few unbrellas: Info Categorical Variables: diagnosis: The target variable diagnosis, although represented as a string in the dataframe, should be categorical! This is because machines do not really like working with \"strings\" and prefer your type to be of \"numbers\". We will map them to 0 and 1, representing benign and malignant respectively. Since the target variable is just two unique values, we can use a simple map from pandas to do the job. class_dict = { \"B\" : 0 , \"M\" : 1 } df [ 'diagnosis' ] = df [ 'diagnosis' ] . map ( class_dict ) We will make sure that our mapping is accurate by asserting the following. assert df [ 'diagnosis' ] . value_counts () . to_dict ()[ 0 ] == 357 assert df [ 'diagnosis' ] . value_counts () . to_dict ()[ 1 ] == 212 Info Continuous Variables: A preliminary look seems to suggest all our predictors are continuous. Success From the brief overview, there does not seem to be any Ordinal or Nominal Predictors. This suggest that we may not need to perform encoding in our preprocessing. Summary Statistics We will use a simple, yet powerful function call to check on the summary statistics of our dataframe. We note to the readers that there are much more powerful libraries like pandas-profiling to give us an even more thorough summary, but for our purpose, we will use the good ol' df.describe() . display ( df . describe ( include = 'all' )) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst count 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 mean 0.372583 14.127292 19.289649 91.969033 654.889104 0.096360 0.104341 0.088799 0.048919 0.181162 0.062798 0.405172 1.216853 2.866059 40.337079 0.007041 0.025478 0.031894 0.011796 0.020542 0.003795 16.269190 25.677223 107.261213 880.583128 0.132369 0.254265 0.272188 0.114606 0.290076 0.083946 std 0.483918 3.524049 4.301036 24.298981 351.914129 0.014064 0.052813 0.079720 0.038803 0.027414 0.007060 0.277313 0.551648 2.021855 45.491006 0.003003 0.017908 0.030186 0.006170 0.008266 0.002646 4.833242 6.146258 33.602542 569.356993 0.022832 0.157336 0.208624 0.065732 0.061867 0.018061 min 0.000000 6.981000 9.710000 43.790000 143.500000 0.052630 0.019380 0.000000 0.000000 0.106000 0.049960 0.111500 0.360200 0.757000 6.802000 0.001713 0.002252 0.000000 0.000000 0.007882 0.000895 7.930000 12.020000 50.410000 185.200000 0.071170 0.027290 0.000000 0.000000 0.156500 0.055040 25% 0.000000 11.700000 16.170000 75.170000 420.300000 0.086370 0.064920 0.029560 0.020310 0.161900 0.057700 0.232400 0.833900 1.606000 17.850000 0.005169 0.013080 0.015090 0.007638 0.015160 0.002248 13.010000 21.080000 84.110000 515.300000 0.116600 0.147200 0.114500 0.064930 0.250400 0.071460 50% 0.000000 13.370000 18.840000 86.240000 551.100000 0.095870 0.092630 0.061540 0.033500 0.179200 0.061540 0.324200 1.108000 2.287000 24.530000 0.006380 0.020450 0.025890 0.010930 0.018730 0.003187 14.970000 25.410000 97.660000 686.500000 0.131300 0.211900 0.226700 0.099930 0.282200 0.080040 75% 1.000000 15.780000 21.800000 104.100000 782.700000 0.105300 0.130400 0.130700 0.074000 0.195700 0.066120 0.478900 1.474000 3.357000 45.190000 0.008146 0.032450 0.042050 0.014710 0.023480 0.004558 18.790000 29.720000 125.400000 1084.000000 0.146000 0.339100 0.382900 0.161400 0.317900 0.092080 max 1.000000 28.110000 39.280000 188.500000 2501.000000 0.163400 0.345400 0.426800 0.201200 0.304000 0.097440 2.873000 4.885000 21.980000 542.200000 0.031130 0.135400 0.396000 0.052790 0.078950 0.029840 36.040000 49.540000 251.200000 4254.000000 0.222600 1.058000 1.252000 0.291000 0.663800 0.207500 The table does give us a good overview: for example, a brief glance give me the following observations: The features do not seem to be of the same scale . This is going to be a problem as some models do not perform well if your features are not on the same scale. A prime example is a KNN model with Euclidean Distance as the distance metric, the difference in range of different features will be amplified with the squared term, and the feature with wider range will dominate the one with smaller range. From our dataset it we see that area_mean is very large and there is likely to be a squared term (possibly from radius_mean ), we can look into them later through EDA. Humans are more visual and that is why we still need EDA later to capture our attention on any anomaly from the dataset, and of course, if the dataset has many columns, then this summary statistics may even clog your progress if you were to read it line by line. Missing Data Missing Alert? Although from our analysis, we did not see any missing data, it is always good to remind ourselves to check it. A simple function that does the job is as follows. def report_missing ( df : pd . DataFrame , columns : List ) -> pd . DataFrame : \"\"\"A function to check for missing data. Args: df (pd.DataFrame): The DataFrame to check. columns (List): The columns to check. Returns: missing_data_df (pd.DataFrame): Returns a DataFrame that reports missing data. \"\"\" missing_dict = { \"missing num\" : [], \"missing percentage\" : []} for col in columns : num_missing = df [ col ] . isnull () . sum () percentage_missing = num_missing / len ( df ) missing_dict [ \"missing num\" ] . append ( num_missing ) missing_dict [ \"missing percentage\" ] . append ( percentage_missing ) missing_data_df = pd . DataFrame ( index = columns , data = missing_dict ) return missing_data_df missing_df = report_missing ( df , columns = df . columns ) display ( missing_df . head ()) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } missing num missing percentage diagnosis 0 0.0 radius_mean 0 0.0 texture_mean 0 0.0 perimeter_mean 0 0.0 area_mean 0 0.0 Save data We save the data to processed and we can call it later on in subsequent notebooks.","title":"Preliminary Data Inspection and Cleaning"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%201%20-%20Preliminary%20Data%20Inspection%20and%20Cleaning/#dependencies-and-configuration","text":"import random from dataclasses import dataclass , field from typing import List , Dict import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns @dataclass class config : raw_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/raw/data.csv\" processed_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/processed.csv\" train_size : float = 0.9 seed : int = 1992 num_folds : int = 5 cv_schema : str = \"StratifiedKFold\" classification_type : str = \"binary\" target_col : List [ str ] = field ( default_factory = lambda : [ \"diagnosis\" ]) unwanted_cols : List [ str ] = field ( default_factory = lambda : [ \"id\" , \"Unnamed: 32\" ]) # Plotting colors : List [ str ] = field ( default_factory = lambda : [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ] ) cmap_reversed = plt . cm . get_cmap ( \"mako_r\" ) def to_dict ( self ) -> Dict : \"\"\"Convert the config object to a dictionary. Returns: Dict: The config object as a dictionary. \"\"\" return { \"raw_data\" : self . raw_data , \"processed_data\" : self . processed_data , \"train_size\" : self . train_size , \"seed\" : self . seed , \"num_folds\" : self . num_folds , \"cv_schema\" : self . cv_schema , \"classification_type\" : self . classification_type , \"target_col\" : self . target_col , \"unwanted_cols\" : self . unwanted_cols , \"colors\" : self . colors , \"cmap_reversed\" : self . cmap_reversed , } def set_seeds ( seed : int = 1234 ) -> None : \"\"\"Set seeds for reproducibility.\"\"\" np . random . seed ( seed ) random . seed ( seed ) # set config config = config () # set seeding for reproducibility _ = set_seeds ( seed = config . seed )","title":"Dependencies and Configuration"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%201%20-%20Preliminary%20Data%20Inspection%20and%20Cleaning/#stage-1-preliminary-data-inspection-and-cleaning","text":"","title":"Stage 1: Preliminary Data Inspection and Cleaning"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%201%20-%20Preliminary%20Data%20Inspection%20and%20Cleaning/#load-the-dataset","text":"df = pd . read_csv ( config . raw_data )","title":"Load the dataset"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%201%20-%20Preliminary%20Data%20Inspection%20and%20Cleaning/#a-brief-look-at-the-dataset","text":"Info We will query the first five rows of the dataframe to get a feel on the dataset we are working on. We also call df.info() to see the data types of the columns, and to briefly check if there is any missing values in our data (more on that later). # Column Non-Null Count Dtype --- ------ -------------- ----- 0 diagnosis 569 non - null int64 1 radius_mean 569 non - null float64 2 texture_mean 569 non - null float64 3 perimeter_mean 569 non - null float64 Importance of data types We must be sharp and ensure that each column is indeed stored in their respective data types! In the real world, we may often query \"dirty\" data from say, the database, where numeric data are represented in string. It is now our duty to ensure sanity checks are in place! display ( df . head ()) display ( df . info ( verbose = True )) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst Unnamed: 32 0 842302 M 17.99 10.38 122.80 1001.0 0.11840 0.27760 0.3001 0.14710 0.2419 0.07871 1.0950 0.9053 8.589 153.40 0.006399 0.04904 0.05373 0.01587 0.03003 0.006193 25.38 17.33 184.60 2019.0 0.1622 0.6656 0.7119 0.2654 0.4601 0.11890 NaN 1 842517 M 20.57 17.77 132.90 1326.0 0.08474 0.07864 0.0869 0.07017 0.1812 0.05667 0.5435 0.7339 3.398 74.08 0.005225 0.01308 0.01860 0.01340 0.01389 0.003532 24.99 23.41 158.80 1956.0 0.1238 0.1866 0.2416 0.1860 0.2750 0.08902 NaN 2 84300903 M 19.69 21.25 130.00 1203.0 0.10960 0.15990 0.1974 0.12790 0.2069 0.05999 0.7456 0.7869 4.585 94.03 0.006150 0.04006 0.03832 0.02058 0.02250 0.004571 23.57 25.53 152.50 1709.0 0.1444 0.4245 0.4504 0.2430 0.3613 0.08758 NaN 3 84348301 M 11.42 20.38 77.58 386.1 0.14250 0.28390 0.2414 0.10520 0.2597 0.09744 0.4956 1.1560 3.445 27.23 0.009110 0.07458 0.05661 0.01867 0.05963 0.009208 14.91 26.50 98.87 567.7 0.2098 0.8663 0.6869 0.2575 0.6638 0.17300 NaN 4 84358402 M 20.29 14.34 135.10 1297.0 0.10030 0.13280 0.1980 0.10430 0.1809 0.05883 0.7572 0.7813 5.438 94.44 0.011490 0.02461 0.05688 0.01885 0.01756 0.005115 22.54 16.67 152.20 1575.0 0.1374 0.2050 0.4000 0.1625 0.2364 0.07678 NaN <class 'pandas.core.frame.DataFrame'> RangeIndex: 569 entries, 0 to 568 Data columns (total 33 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 id 569 non-null int64 1 diagnosis 569 non-null object 2 radius_mean 569 non-null float64 3 texture_mean 569 non-null float64 4 perimeter_mean 569 non-null float64 5 area_mean 569 non-null float64 6 smoothness_mean 569 non-null float64 7 compactness_mean 569 non-null float64 8 concavity_mean 569 non-null float64 9 concave points_mean 569 non-null float64 10 symmetry_mean 569 non-null float64 11 fractal_dimension_mean 569 non-null float64 12 radius_se 569 non-null float64 13 texture_se 569 non-null float64 14 perimeter_se 569 non-null float64 15 area_se 569 non-null float64 16 smoothness_se 569 non-null float64 17 compactness_se 569 non-null float64 18 concavity_se 569 non-null float64 19 concave points_se 569 non-null float64 20 symmetry_se 569 non-null float64 21 fractal_dimension_se 569 non-null float64 22 radius_worst 569 non-null float64 23 texture_worst 569 non-null float64 24 perimeter_worst 569 non-null float64 25 area_worst 569 non-null float64 26 smoothness_worst 569 non-null float64 27 compactness_worst 569 non-null float64 28 concavity_worst 569 non-null float64 29 concave points_worst 569 non-null float64 30 symmetry_worst 569 non-null float64 31 fractal_dimension_worst 569 non-null float64 32 Unnamed: 32 0 non-null float64 dtypes: float64(31), int64(1), object(1) memory usage: 146.8+ KB None A brief overview tells us our data is alright! There is, however, a column which is unnamed and has no values. This can be of various data source issues, for now, we quickly check the definition given by the dataset from UCI's Breast Cancer Wisconsin (Diagnostic) Data Set and confirm that there should only be 32 columns. With this in mind, we can safely delete the column. We also note that from the above, that the id column is the identifier for each patient. We will also drop this column as it holds no predictive power. When can ID be important? We should try to question our move and justify it. In this dataset, we have to ensure that each ID is unique, if it is not, it may suggest that there are patient records with multiple observation, which is a violation of i.i.d assumption and we may take note when doing cross-validation, so as to avoid information leakage. Since the ID column is unique, we will delete it. We will keep this at the back of our mind in the event that we ever need them for feature engineering. print ( f \"The ID column is unique : { df [ 'id' ] . is_unique } \" ) The ID column is unique : True","title":"A brief look at the dataset"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%201%20-%20Preliminary%20Data%20Inspection%20and%20Cleaning/#drop-drop-drop-the-columns","text":"Here we define a drop_columns function to drop the unwanted columns. def drop_columns ( df : pd . DataFrame , columns : List ) -> pd . DataFrame : \"\"\"Drop unwanted columns from dataframe. Args: df (pd.DataFrame): Dataframe to be cleaned columns (List): list of columns to be dropped Returns: df_copy (pd.DataFrame): Dataframe with unwanted columns dropped. \"\"\" df_copy = df . copy () df_copy = df_copy . drop ( columns = columns , axis = 1 , inplace = False ) return df_copy . reset_index ( drop = True ) df = drop_columns ( df , columns = config . unwanted_cols )","title":"Drop, drop, drop the columns!"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%201%20-%20Preliminary%20Data%20Inspection%20and%20Cleaning/#data-types","text":"Let us split the data types into a few unbrellas: Info Categorical Variables: diagnosis: The target variable diagnosis, although represented as a string in the dataframe, should be categorical! This is because machines do not really like working with \"strings\" and prefer your type to be of \"numbers\". We will map them to 0 and 1, representing benign and malignant respectively. Since the target variable is just two unique values, we can use a simple map from pandas to do the job. class_dict = { \"B\" : 0 , \"M\" : 1 } df [ 'diagnosis' ] = df [ 'diagnosis' ] . map ( class_dict ) We will make sure that our mapping is accurate by asserting the following. assert df [ 'diagnosis' ] . value_counts () . to_dict ()[ 0 ] == 357 assert df [ 'diagnosis' ] . value_counts () . to_dict ()[ 1 ] == 212 Info Continuous Variables: A preliminary look seems to suggest all our predictors are continuous. Success From the brief overview, there does not seem to be any Ordinal or Nominal Predictors. This suggest that we may not need to perform encoding in our preprocessing.","title":"Data Types"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%201%20-%20Preliminary%20Data%20Inspection%20and%20Cleaning/#summary-statistics","text":"We will use a simple, yet powerful function call to check on the summary statistics of our dataframe. We note to the readers that there are much more powerful libraries like pandas-profiling to give us an even more thorough summary, but for our purpose, we will use the good ol' df.describe() . display ( df . describe ( include = 'all' )) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst count 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 569.000000 mean 0.372583 14.127292 19.289649 91.969033 654.889104 0.096360 0.104341 0.088799 0.048919 0.181162 0.062798 0.405172 1.216853 2.866059 40.337079 0.007041 0.025478 0.031894 0.011796 0.020542 0.003795 16.269190 25.677223 107.261213 880.583128 0.132369 0.254265 0.272188 0.114606 0.290076 0.083946 std 0.483918 3.524049 4.301036 24.298981 351.914129 0.014064 0.052813 0.079720 0.038803 0.027414 0.007060 0.277313 0.551648 2.021855 45.491006 0.003003 0.017908 0.030186 0.006170 0.008266 0.002646 4.833242 6.146258 33.602542 569.356993 0.022832 0.157336 0.208624 0.065732 0.061867 0.018061 min 0.000000 6.981000 9.710000 43.790000 143.500000 0.052630 0.019380 0.000000 0.000000 0.106000 0.049960 0.111500 0.360200 0.757000 6.802000 0.001713 0.002252 0.000000 0.000000 0.007882 0.000895 7.930000 12.020000 50.410000 185.200000 0.071170 0.027290 0.000000 0.000000 0.156500 0.055040 25% 0.000000 11.700000 16.170000 75.170000 420.300000 0.086370 0.064920 0.029560 0.020310 0.161900 0.057700 0.232400 0.833900 1.606000 17.850000 0.005169 0.013080 0.015090 0.007638 0.015160 0.002248 13.010000 21.080000 84.110000 515.300000 0.116600 0.147200 0.114500 0.064930 0.250400 0.071460 50% 0.000000 13.370000 18.840000 86.240000 551.100000 0.095870 0.092630 0.061540 0.033500 0.179200 0.061540 0.324200 1.108000 2.287000 24.530000 0.006380 0.020450 0.025890 0.010930 0.018730 0.003187 14.970000 25.410000 97.660000 686.500000 0.131300 0.211900 0.226700 0.099930 0.282200 0.080040 75% 1.000000 15.780000 21.800000 104.100000 782.700000 0.105300 0.130400 0.130700 0.074000 0.195700 0.066120 0.478900 1.474000 3.357000 45.190000 0.008146 0.032450 0.042050 0.014710 0.023480 0.004558 18.790000 29.720000 125.400000 1084.000000 0.146000 0.339100 0.382900 0.161400 0.317900 0.092080 max 1.000000 28.110000 39.280000 188.500000 2501.000000 0.163400 0.345400 0.426800 0.201200 0.304000 0.097440 2.873000 4.885000 21.980000 542.200000 0.031130 0.135400 0.396000 0.052790 0.078950 0.029840 36.040000 49.540000 251.200000 4254.000000 0.222600 1.058000 1.252000 0.291000 0.663800 0.207500 The table does give us a good overview: for example, a brief glance give me the following observations: The features do not seem to be of the same scale . This is going to be a problem as some models do not perform well if your features are not on the same scale. A prime example is a KNN model with Euclidean Distance as the distance metric, the difference in range of different features will be amplified with the squared term, and the feature with wider range will dominate the one with smaller range. From our dataset it we see that area_mean is very large and there is likely to be a squared term (possibly from radius_mean ), we can look into them later through EDA. Humans are more visual and that is why we still need EDA later to capture our attention on any anomaly from the dataset, and of course, if the dataset has many columns, then this summary statistics may even clog your progress if you were to read it line by line.","title":"Summary Statistics"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%201%20-%20Preliminary%20Data%20Inspection%20and%20Cleaning/#missing-data","text":"Missing Alert? Although from our analysis, we did not see any missing data, it is always good to remind ourselves to check it. A simple function that does the job is as follows. def report_missing ( df : pd . DataFrame , columns : List ) -> pd . DataFrame : \"\"\"A function to check for missing data. Args: df (pd.DataFrame): The DataFrame to check. columns (List): The columns to check. Returns: missing_data_df (pd.DataFrame): Returns a DataFrame that reports missing data. \"\"\" missing_dict = { \"missing num\" : [], \"missing percentage\" : []} for col in columns : num_missing = df [ col ] . isnull () . sum () percentage_missing = num_missing / len ( df ) missing_dict [ \"missing num\" ] . append ( num_missing ) missing_dict [ \"missing percentage\" ] . append ( percentage_missing ) missing_data_df = pd . DataFrame ( index = columns , data = missing_dict ) return missing_data_df missing_df = report_missing ( df , columns = df . columns ) display ( missing_df . head ()) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } missing num missing percentage diagnosis 0 0.0 radius_mean 0 0.0 texture_mean 0 0.0 perimeter_mean 0 0.0 area_mean 0 0.0","title":"Missing Data"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%201%20-%20Preliminary%20Data%20Inspection%20and%20Cleaning/#save-data","text":"We save the data to processed and we can call it later on in subsequent notebooks.","title":"Save data"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/","text":"Stage 2: Preliminary EDA by Hongnan Gao Quick Navigation Dependencies and Configuration Stage 2: EDA: Preliminary Stage Distribution of Target and Predictor Target Distribution Univariate Distribution of Predictors Histogram and KDE Distribution Box Plots Correlation Plots Heatmap Cluster Plot Bivariate Analysis PCE and TSNE Save the Data Dependencies and Configuration import random from dataclasses import dataclass , field from typing import Dict , List import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns from scipy.cluster import hierarchy from scipy.spatial.distance import squareform from scipy.stats import pearsonr , spearmanr from sklearn import decomposition , manifold , preprocessing @dataclass class config : raw_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/raw/data.csv\" processed_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/processed.csv\" train_size : float = 0.9 seed : int = 1992 num_folds : int = 5 cv_schema : str = \"StratifiedKFold\" classification_type : str = \"binary\" target_col : List [ str ] = field ( default_factory = lambda : [ \"diagnosis\" ]) unwanted_cols : List [ str ] = field ( default_factory = lambda : [ \"id\" , \"Unnamed: 32\" ]) # Plotting colors : List [ str ] = field ( default_factory = lambda : [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ] ) cmap_reversed = plt . cm . get_cmap ( \"mako_r\" ) def to_dict ( self ) -> Dict : \"\"\"Convert the config object to a dictionary. Returns: Dict: The config object as a dictionary. \"\"\" return { \"raw_data\" : self . raw_data , \"processed_data\" : self . processed_data , \"train_size\" : self . train_size , \"seed\" : self . seed , \"num_folds\" : self . num_folds , \"cv_schema\" : self . cv_schema , \"classification_type\" : self . classification_type , \"target_col\" : self . target_col , \"unwanted_cols\" : self . unwanted_cols , \"colors\" : self . colors , \"cmap_reversed\" : self . cmap_reversed , } def set_seeds ( seed : int = 1234 ) -> None : \"\"\"Set seeds for reproducibility.\"\"\" np . random . seed ( seed ) random . seed ( seed ) # set config config = config () # set seeding for reproducibility _ = set_seeds ( seed = config . seed ) # read data df = pd . read_csv ( config . processed_data ) Stage 2: EDA (Preliminary Stage) Terminology Alert I call this stage the preliminary EDA for the following reasons (but not limited to!) - EDA is an iterative process! Data is never clean! So we scrub -> send in for modelling -> scrub -> get new data -> scrub scrub scrub again! - Typically, I do a basic EDA analysis after Stage 1. As an example, in a classical regression setting, I would check for some assumptions like normality checks. And if some variables are of a \"bad distribution\", we can perform a transformation on it first, and plot them again in the next round of EDA to check if we corrected the issues. The below image summarizes the process. Courtesy of Farcaster In summary, we will do the following EDA here: Target and Predictors Distribution. Univariate Analysis. Bivariate Analysis. Multivariate Analysis. Some fancy looking Dimensionality Reduction Techniques to see how our features can be visualized in lower dimensions. Distribution of Target and Predictor Target Let us first visualize our distribution of target variable. Since the target is discrete, we will just plot a simple count plot to check. Class Imbalance For Classification problems, we often plot the target count to get a good gauge on how imbalanced the dataset is. From there, we can think of whether the class imbalance is going to be a factor in our modelling process. df [ 'diagnosis' ] . value_counts ( normalize = True ) * 100 Malignant : 37.3 % Benign : 62.7 % There is to certain degree a class imbalance issue, although this is not what I have envisioned in the first place. After all, it is just natural that there should be more negative (benign) than positive (malignant) cases, given that in the general population, there are much more people without cancer than those who do. Nevertheless, despite the slight imbalance issue, we should still take them into account and perform stratification during cross-validation later. def plot_target_distribution ( df : pd . DataFrame , target : str , colors : List [ str ]) -> None : \"\"\"Plot Target Distribution with percentage labels. Args: df (pd.DataFrame): DataFrame to plot. target (str): Target column name. colors (List[str]): List of colors to use for plotting. \"\"\" plt . rcParams [ \"figure.dpi\" ] = 100 plt . rcParams [ \"savefig.dpi\" ] = 300 x_axis = df [ \"diagnosis\" ] . value_counts () . index y_axis = df [ \"diagnosis\" ] . value_counts () figure , target_bar = plt . subplots ( figsize = ( 6 , 4 )) bar = sns . barplot ( x = x_axis , y = y_axis , ax = target_bar , palette = { 1 : colors [ 0 ], 0 : colors [ 3 ]}) target_bar . set_xticklabels ([ \"Benign\" , \"Malignant\" ]) target_bar . set_ylabel ( \"Frequency Count\" ) target_bar . legend ([ \"Benign\" , \"Malignant\" ], loc = \"upper right\" ) target_bar . set_title ( \"Count of Target (Diagnosis)\" , fontsize = 16 ) figure . text ( x = 0.27 , y = 0.8 , s = \" {:.1f} %\" . format ( df [ \"diagnosis\" ] . value_counts ( normalize = True )[ 0 ] * 100 ), ** { \"weight\" : \"bold\" , \"color\" : \"black\" }, ) figure . text ( x = 0.66 , y = 0.5 , s = \" {:.1f} %\" . format ( df [ \"diagnosis\" ] . value_counts ( normalize = True )[ 1 ] * 100 ), ** { \"weight\" : \"bold\" , \"color\" : \"black\" }, ) plt . show () _ = plot_target_distribution ( df = df , target = config . target_col , colors = config . colors ) Univariate Distributions of Predictors Univariate Plot on Continuous Variables The predictors are all continuous variables. We can do a univariate plot to show the histogram/kde distribution of these features, we color the hue so that the distribution is parametrized by the target. In addition, we will also perform a box plot to check for potential outliers. predictor_cols = df . columns . to_list ()[ 1 :] Histogram and KDE distribution We can plot a histogram with KDE for each of the feature, parametrized by the target. The aim of this visual is to briefly see how skewed the features are, whether the features are gaussian, and also the distribution of each feature with respect to the target. def plot_univariate ( df : pd . DataFrame , predictor : str , colors : List [ str ]) -> None : \"\"\"Take in continuous predictors and plot univariate distribution. Note in this setting, we have kde=True. Args: df (pd.DataFrame): Dataframe. predictor (str): Predictor name. \"\"\" univariate_params = { \"nrows\" : 10 , \"ncols\" : 3 , \"figsize\" : ( 12 , 24 ), \"dpi\" : 80 } fig , axs = plt . subplots ( ** univariate_params ) for i , col in enumerate ( predictor ): sns . histplot ( data = df , x = col , kde = True , hue = \"diagnosis\" , ax = axs [ i % univariate_params [ \"nrows\" ]][ i // univariate_params [ \"nrows\" ]], legend = False , palette = { 1 : colors [ 0 ], 0 : colors [ 3 ]}, ) plt . subplots_adjust ( hspace = 2 ) fig . suptitle ( \"Breast Cancer Predictors Univariate Distribution\" , y = 1.01 , fontsize = \"x-large\" ) fig . legend ( df [ \"diagnosis\" ] . unique ()) fig . tight_layout () plt . show () _ = plot_univariate ( df = df , predictor = predictor_cols , colors = config . colors ) Univariate Insights From the plots above, we can form very basic hypothesis on the features, we select a few features to explain: - radius_mean: seems to have a clear boundary to discriminate between benign and malignant classes; in general, the bigger the radius mean, the higher the likelihood of the tumor being malignant; - smoothness_mean: judging the smoothness mean (jaggedness) alone , we can see there is quite a fair bit of overlaps in between the class distributions, the boundary in between both classes are not so clear when compared to radius_mean . This suggests that the feature alone may not distinguish whether a patient's tumor is malignant or not. However, seemingly \"non-informative\" features may become extremely useful when coupled with other features. We can see most graphs are skewed towards the right. Box Plots Although a good alternative to box plots is the violin plot, but we do have the the distribution of KDE earlier on, so we can just zoom in at the box plots to check for outliers. There are some outliers present in the features. Outliers Alert! Outliers are tricky, without domain knowledge, it is sometimes hard to tell whether or not an outlier should be removed. A rule of thumb is that if you are sure the outliers are caused by a labelling or human error, then you can remove them. Otherwise, we may need to investigate further to check if these outliers should be retained during modelling. def plot_univariate_boxplot ( df : pd . DataFrame , predictor : str ) -> None : \"\"\"Take in continuous predictors and plot univariate boxplot distribution. Note in this setting, we have kde=True. Args: df (pd.DataFrame): DataFrame. predictor (str): Predictor name. \"\"\" univariate_params = { \"nrows\" : 10 , \"ncols\" : 3 , \"figsize\" : ( 12 , 24 ), \"dpi\" : 80 } fig , axs = plt . subplots ( ** univariate_params ) for i , col in enumerate ( predictor ): sns . boxplot ( data = df , x = col , hue = \"diagnosis\" , ax = axs [ i % univariate_params [ \"nrows\" ]][ i // univariate_params [ \"nrows\" ]], ) plt . subplots_adjust ( hspace = 2 ) fig . suptitle ( \"Breast Cancer Predictors Boxplot Distribution\" , y = 1.01 , fontsize = \"x-large\" ) fig . legend ( df [ \"diagnosis\" ] . unique ()) fig . tight_layout () plt . show () predictor_cols = df . columns . to_list ()[ 1 :] _ = plot_univariate_boxplot ( df = df , predictor = predictor_cols ) Correlation Plots Through the definitions given on the features of the dataset, we know that there are some features that are correlated to each other. For example, we can even make some hypothesis before we plot. Hypothesis Radius Mean, Area Mean and Perimeter Mean are correlated. This makes sense as if a cell nucleus is approximately circle, then the radius \\(r\\) is related linearly with perimeter \\(2\\pi r\\) and quadratically related with area \\(\\pi r ^2\\) . Heatmap We can plot a simple correlation heatmap to visualize the \"hot spots\" in which the correlation value is high. def plot_heatmap ( df : pd . DataFrame , predictors : List [ str ], cmap : str ) -> pd . DataFrame : \"\"\"This function takes in a dataframe and a list of predictors, and output the correlation matrix, as well as a plot of heatmap. 1. Note that annot_kws attempts to make the size of the font visible and contained in the heatmap. 2. Note that the CMAP is reversed and darker color indicates higher correlation as I find this more intuitive. Args: df (pd.DataFrame): The dataframe to be plotted. predictors (List[str]): The list of predictors to be plotted. Returns: pd.DataFrame: [description] \"\"\" corr = df [ predictors ] . corr () annot_kws = { \"size\" : 35 / np . sqrt ( len ( corr ))} fig , _ = plt . subplots ( figsize = ( 16 , 12 )) sns . heatmap ( corr , annot = True , cmap = cmap , annot_kws = annot_kws ) return corr corr_matrix = plot_heatmap ( df = df , predictors = predictor_cols , cmap = config . cmap_reversed ) From the correlation plot above, we discovered quite a lot of features being correlated, indicating multi-collinearity. We can further strengthen our stance by using a clusterplot to check. Cluster Plot We can use a Hierarchical Clustering to visualize the correlated clusters, the Cluster Map outputs a Dendrogram and in our Seaborn plot, we used Ward's Linkage as our method and the distance metric is Euclidean's Distance. Hence, in the diagram below, the dendrogram implies A and B are more \"correlated\" than A and C. Courtesy of What is a Dendrogram? corr = df [ predictor_cols ] . corr () g = sns . clustermap ( corr , method = \"ward\" , metric = 'euclidean' , cmap = config . cmap_reversed ); Bivariate Analysis Clutter Alert! Now we have 30 predictors, if we plot all of them in the pairplots below, we will roughly have \\({30 \\choose 2} = 435\\) such figures, which is not really pleasing to look at. We can zoom in on a few predictors and see if we can find more insights. A good way is to be selective when you do pair plots. From the correlation plot above, we can further choose a set of correlated features and plot them. For our purpose, we will plot 10 features only, all of them are related to the mean of the features. The plot will have its diagonal conveniently displaying its univariate histogram and kde distribution, while the off-diagonal will show bivariate scatter plots. mean_cols = predictor_cols [: 10 ] def corrfunc ( x : np . ndarray , y : np . ndarray , ax = None , ** kws ) -> None : \"\"\"Plot the correlation coefficient in the top left hand corner of a plot. Args: x (np.ndarray): x-axis data. y (np.ndarray): y-axis data. ax ([type], optional): Defaults to None. Axes to plot on. \"\"\" r , _ = pearsonr ( x , y ) ax = ax or plt . gca () ax . annotate ( f \" { r : .1f } \" , xy = ( 0.7 , 0.15 ), xycoords = ax . transAxes ) pp_mean = sns . pairplot ( df , hue = \"diagnosis\" , vars = mean_cols , palette = { 1 : config . colors [ 0 ], 0 : config . colors [ 3 ]}, diag_kind = \"auto\" , corner = True , ) pp_mean = pp_mean . map_offdiag ( sns . scatterplot ) pp_mean = pp_mean . map_diag ( sns . histplot , kde = True ) pp_mean = pp_mean . map_lower ( corrfunc ) From the pairplot, we notice interesting things like the three \"good brothers\", radius, area and perimeter, whom are highly positively correlated. PCA, TSNE We can also plot PCA and TSNE to get a feel of how \"separable\" the data points are in 2 dimensional space. Standardization Alert A disclaimer/assumption here is that we are standardizing the full training set for the purpose of visualizations, and both PCA and TSNE benefit from data on the same scale. Note that preprocessing techniques such as standardization should not be applied to the test/hold-out set, as this will cause data leakage. def plot_dimensional_reduction ( df : pd . DataFrame , predictor_cols : List [ str ], colors : List [ str ] ): \"\"\"Plots PCA and TSNE for visualization of higher dimension to lower dimension. Args: df (pd.DataFrame): Dataframe to be plotted. predictor_cols (List[str]): List of predictor columns. colors (List[str]): List of colors for plotting. \"\"\" X_standardized = preprocessing . StandardScaler () . fit_transform ( df [ predictor_cols ]) # Binary classification: we can set n components to 2 to better visualize all features in 2 dimensions pca = decomposition . PCA ( n_components = 2 ) pca_2d = pca . fit_transform ( X_standardized ) tsne = manifold . TSNE ( n_components = 2 , verbose = 1 , perplexity = 40 , n_iter = 1500 ) tsne_2d = tsne . fit_transform ( X_standardized ) # Plot the TSNE and PCA visuals side-by-side plt . figure ( figsize = ( 16 , 11 )) plt . subplot ( 121 ) plt . scatter ( pca_2d [:, 0 ], pca_2d [:, 1 ], c = df [ \"diagnosis\" ], edgecolor = \"None\" , alpha = 0.35 ) plt . colorbar () plt . title ( \"PCA Scatter Plot\" ) plt . subplot ( 122 ) plt . scatter ( tsne_2d [:, 0 ], tsne_2d [:, 1 ], c = df [ \"diagnosis\" ], edgecolor = \"None\" , alpha = 0.35 , ) plt . colorbar () plt . title ( \"TSNE Scatter Plot\" ) plt . show () _ = plot_dimensional_reduction ( df = df , predictor_cols = predictor_cols , colors = [ config . colors [ 0 ], config . colors [ 1 ]]) [t-SNE] Computing 121 nearest neighbors... [t-SNE] Indexed 569 samples in 0.003s... [t-SNE] Computed neighbors for 569 samples in 0.052s... [t-SNE] Computed conditional probabilities for sample 569 / 569 [t-SNE] Mean sigma: 1.522404 [t-SNE] KL divergence after 250 iterations with early exaggeration: 63.866753 [t-SNE] KL divergence after 1450 iterations: 0.847863 Welp, the purpose of this plot is to show how well separated the data points are in 2d-space (binary classification). It does seem that TSNE can distinguish the clusters clearer than PCA. This may suggest that your data points are non-linear, which is one assumption that PCA takes. We are not restricted to only linear models, so this is fine!","title":"EDA"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/#dependencies-and-configuration","text":"import random from dataclasses import dataclass , field from typing import Dict , List import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns from scipy.cluster import hierarchy from scipy.spatial.distance import squareform from scipy.stats import pearsonr , spearmanr from sklearn import decomposition , manifold , preprocessing @dataclass class config : raw_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/raw/data.csv\" processed_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/processed.csv\" train_size : float = 0.9 seed : int = 1992 num_folds : int = 5 cv_schema : str = \"StratifiedKFold\" classification_type : str = \"binary\" target_col : List [ str ] = field ( default_factory = lambda : [ \"diagnosis\" ]) unwanted_cols : List [ str ] = field ( default_factory = lambda : [ \"id\" , \"Unnamed: 32\" ]) # Plotting colors : List [ str ] = field ( default_factory = lambda : [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ] ) cmap_reversed = plt . cm . get_cmap ( \"mako_r\" ) def to_dict ( self ) -> Dict : \"\"\"Convert the config object to a dictionary. Returns: Dict: The config object as a dictionary. \"\"\" return { \"raw_data\" : self . raw_data , \"processed_data\" : self . processed_data , \"train_size\" : self . train_size , \"seed\" : self . seed , \"num_folds\" : self . num_folds , \"cv_schema\" : self . cv_schema , \"classification_type\" : self . classification_type , \"target_col\" : self . target_col , \"unwanted_cols\" : self . unwanted_cols , \"colors\" : self . colors , \"cmap_reversed\" : self . cmap_reversed , } def set_seeds ( seed : int = 1234 ) -> None : \"\"\"Set seeds for reproducibility.\"\"\" np . random . seed ( seed ) random . seed ( seed ) # set config config = config () # set seeding for reproducibility _ = set_seeds ( seed = config . seed ) # read data df = pd . read_csv ( config . processed_data )","title":"Dependencies and Configuration"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/#stage-2-eda-preliminary-stage","text":"Terminology Alert I call this stage the preliminary EDA for the following reasons (but not limited to!) - EDA is an iterative process! Data is never clean! So we scrub -> send in for modelling -> scrub -> get new data -> scrub scrub scrub again! - Typically, I do a basic EDA analysis after Stage 1. As an example, in a classical regression setting, I would check for some assumptions like normality checks. And if some variables are of a \"bad distribution\", we can perform a transformation on it first, and plot them again in the next round of EDA to check if we corrected the issues. The below image summarizes the process. Courtesy of Farcaster In summary, we will do the following EDA here: Target and Predictors Distribution. Univariate Analysis. Bivariate Analysis. Multivariate Analysis. Some fancy looking Dimensionality Reduction Techniques to see how our features can be visualized in lower dimensions.","title":"Stage 2: EDA (Preliminary Stage)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/#distribution-of-target-and-predictor","text":"","title":"Distribution of Target and Predictor"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/#target","text":"Let us first visualize our distribution of target variable. Since the target is discrete, we will just plot a simple count plot to check. Class Imbalance For Classification problems, we often plot the target count to get a good gauge on how imbalanced the dataset is. From there, we can think of whether the class imbalance is going to be a factor in our modelling process. df [ 'diagnosis' ] . value_counts ( normalize = True ) * 100 Malignant : 37.3 % Benign : 62.7 % There is to certain degree a class imbalance issue, although this is not what I have envisioned in the first place. After all, it is just natural that there should be more negative (benign) than positive (malignant) cases, given that in the general population, there are much more people without cancer than those who do. Nevertheless, despite the slight imbalance issue, we should still take them into account and perform stratification during cross-validation later. def plot_target_distribution ( df : pd . DataFrame , target : str , colors : List [ str ]) -> None : \"\"\"Plot Target Distribution with percentage labels. Args: df (pd.DataFrame): DataFrame to plot. target (str): Target column name. colors (List[str]): List of colors to use for plotting. \"\"\" plt . rcParams [ \"figure.dpi\" ] = 100 plt . rcParams [ \"savefig.dpi\" ] = 300 x_axis = df [ \"diagnosis\" ] . value_counts () . index y_axis = df [ \"diagnosis\" ] . value_counts () figure , target_bar = plt . subplots ( figsize = ( 6 , 4 )) bar = sns . barplot ( x = x_axis , y = y_axis , ax = target_bar , palette = { 1 : colors [ 0 ], 0 : colors [ 3 ]}) target_bar . set_xticklabels ([ \"Benign\" , \"Malignant\" ]) target_bar . set_ylabel ( \"Frequency Count\" ) target_bar . legend ([ \"Benign\" , \"Malignant\" ], loc = \"upper right\" ) target_bar . set_title ( \"Count of Target (Diagnosis)\" , fontsize = 16 ) figure . text ( x = 0.27 , y = 0.8 , s = \" {:.1f} %\" . format ( df [ \"diagnosis\" ] . value_counts ( normalize = True )[ 0 ] * 100 ), ** { \"weight\" : \"bold\" , \"color\" : \"black\" }, ) figure . text ( x = 0.66 , y = 0.5 , s = \" {:.1f} %\" . format ( df [ \"diagnosis\" ] . value_counts ( normalize = True )[ 1 ] * 100 ), ** { \"weight\" : \"bold\" , \"color\" : \"black\" }, ) plt . show () _ = plot_target_distribution ( df = df , target = config . target_col , colors = config . colors )","title":"Target"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/#univariate-distributions-of-predictors","text":"Univariate Plot on Continuous Variables The predictors are all continuous variables. We can do a univariate plot to show the histogram/kde distribution of these features, we color the hue so that the distribution is parametrized by the target. In addition, we will also perform a box plot to check for potential outliers. predictor_cols = df . columns . to_list ()[ 1 :]","title":"Univariate Distributions of Predictors"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/#histogram-and-kde-distribution","text":"We can plot a histogram with KDE for each of the feature, parametrized by the target. The aim of this visual is to briefly see how skewed the features are, whether the features are gaussian, and also the distribution of each feature with respect to the target. def plot_univariate ( df : pd . DataFrame , predictor : str , colors : List [ str ]) -> None : \"\"\"Take in continuous predictors and plot univariate distribution. Note in this setting, we have kde=True. Args: df (pd.DataFrame): Dataframe. predictor (str): Predictor name. \"\"\" univariate_params = { \"nrows\" : 10 , \"ncols\" : 3 , \"figsize\" : ( 12 , 24 ), \"dpi\" : 80 } fig , axs = plt . subplots ( ** univariate_params ) for i , col in enumerate ( predictor ): sns . histplot ( data = df , x = col , kde = True , hue = \"diagnosis\" , ax = axs [ i % univariate_params [ \"nrows\" ]][ i // univariate_params [ \"nrows\" ]], legend = False , palette = { 1 : colors [ 0 ], 0 : colors [ 3 ]}, ) plt . subplots_adjust ( hspace = 2 ) fig . suptitle ( \"Breast Cancer Predictors Univariate Distribution\" , y = 1.01 , fontsize = \"x-large\" ) fig . legend ( df [ \"diagnosis\" ] . unique ()) fig . tight_layout () plt . show () _ = plot_univariate ( df = df , predictor = predictor_cols , colors = config . colors ) Univariate Insights From the plots above, we can form very basic hypothesis on the features, we select a few features to explain: - radius_mean: seems to have a clear boundary to discriminate between benign and malignant classes; in general, the bigger the radius mean, the higher the likelihood of the tumor being malignant; - smoothness_mean: judging the smoothness mean (jaggedness) alone , we can see there is quite a fair bit of overlaps in between the class distributions, the boundary in between both classes are not so clear when compared to radius_mean . This suggests that the feature alone may not distinguish whether a patient's tumor is malignant or not. However, seemingly \"non-informative\" features may become extremely useful when coupled with other features. We can see most graphs are skewed towards the right.","title":"Histogram and KDE distribution"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/#box-plots","text":"Although a good alternative to box plots is the violin plot, but we do have the the distribution of KDE earlier on, so we can just zoom in at the box plots to check for outliers. There are some outliers present in the features. Outliers Alert! Outliers are tricky, without domain knowledge, it is sometimes hard to tell whether or not an outlier should be removed. A rule of thumb is that if you are sure the outliers are caused by a labelling or human error, then you can remove them. Otherwise, we may need to investigate further to check if these outliers should be retained during modelling. def plot_univariate_boxplot ( df : pd . DataFrame , predictor : str ) -> None : \"\"\"Take in continuous predictors and plot univariate boxplot distribution. Note in this setting, we have kde=True. Args: df (pd.DataFrame): DataFrame. predictor (str): Predictor name. \"\"\" univariate_params = { \"nrows\" : 10 , \"ncols\" : 3 , \"figsize\" : ( 12 , 24 ), \"dpi\" : 80 } fig , axs = plt . subplots ( ** univariate_params ) for i , col in enumerate ( predictor ): sns . boxplot ( data = df , x = col , hue = \"diagnosis\" , ax = axs [ i % univariate_params [ \"nrows\" ]][ i // univariate_params [ \"nrows\" ]], ) plt . subplots_adjust ( hspace = 2 ) fig . suptitle ( \"Breast Cancer Predictors Boxplot Distribution\" , y = 1.01 , fontsize = \"x-large\" ) fig . legend ( df [ \"diagnosis\" ] . unique ()) fig . tight_layout () plt . show () predictor_cols = df . columns . to_list ()[ 1 :] _ = plot_univariate_boxplot ( df = df , predictor = predictor_cols )","title":"Box Plots"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/#correlation-plots","text":"Through the definitions given on the features of the dataset, we know that there are some features that are correlated to each other. For example, we can even make some hypothesis before we plot. Hypothesis Radius Mean, Area Mean and Perimeter Mean are correlated. This makes sense as if a cell nucleus is approximately circle, then the radius \\(r\\) is related linearly with perimeter \\(2\\pi r\\) and quadratically related with area \\(\\pi r ^2\\) .","title":"Correlation Plots"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/#heatmap","text":"We can plot a simple correlation heatmap to visualize the \"hot spots\" in which the correlation value is high. def plot_heatmap ( df : pd . DataFrame , predictors : List [ str ], cmap : str ) -> pd . DataFrame : \"\"\"This function takes in a dataframe and a list of predictors, and output the correlation matrix, as well as a plot of heatmap. 1. Note that annot_kws attempts to make the size of the font visible and contained in the heatmap. 2. Note that the CMAP is reversed and darker color indicates higher correlation as I find this more intuitive. Args: df (pd.DataFrame): The dataframe to be plotted. predictors (List[str]): The list of predictors to be plotted. Returns: pd.DataFrame: [description] \"\"\" corr = df [ predictors ] . corr () annot_kws = { \"size\" : 35 / np . sqrt ( len ( corr ))} fig , _ = plt . subplots ( figsize = ( 16 , 12 )) sns . heatmap ( corr , annot = True , cmap = cmap , annot_kws = annot_kws ) return corr corr_matrix = plot_heatmap ( df = df , predictors = predictor_cols , cmap = config . cmap_reversed ) From the correlation plot above, we discovered quite a lot of features being correlated, indicating multi-collinearity. We can further strengthen our stance by using a clusterplot to check.","title":"Heatmap"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/#cluster-plot","text":"We can use a Hierarchical Clustering to visualize the correlated clusters, the Cluster Map outputs a Dendrogram and in our Seaborn plot, we used Ward's Linkage as our method and the distance metric is Euclidean's Distance. Hence, in the diagram below, the dendrogram implies A and B are more \"correlated\" than A and C. Courtesy of What is a Dendrogram? corr = df [ predictor_cols ] . corr () g = sns . clustermap ( corr , method = \"ward\" , metric = 'euclidean' , cmap = config . cmap_reversed );","title":"Cluster Plot"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/#bivariate-analysis","text":"Clutter Alert! Now we have 30 predictors, if we plot all of them in the pairplots below, we will roughly have \\({30 \\choose 2} = 435\\) such figures, which is not really pleasing to look at. We can zoom in on a few predictors and see if we can find more insights. A good way is to be selective when you do pair plots. From the correlation plot above, we can further choose a set of correlated features and plot them. For our purpose, we will plot 10 features only, all of them are related to the mean of the features. The plot will have its diagonal conveniently displaying its univariate histogram and kde distribution, while the off-diagonal will show bivariate scatter plots. mean_cols = predictor_cols [: 10 ] def corrfunc ( x : np . ndarray , y : np . ndarray , ax = None , ** kws ) -> None : \"\"\"Plot the correlation coefficient in the top left hand corner of a plot. Args: x (np.ndarray): x-axis data. y (np.ndarray): y-axis data. ax ([type], optional): Defaults to None. Axes to plot on. \"\"\" r , _ = pearsonr ( x , y ) ax = ax or plt . gca () ax . annotate ( f \" { r : .1f } \" , xy = ( 0.7 , 0.15 ), xycoords = ax . transAxes ) pp_mean = sns . pairplot ( df , hue = \"diagnosis\" , vars = mean_cols , palette = { 1 : config . colors [ 0 ], 0 : config . colors [ 3 ]}, diag_kind = \"auto\" , corner = True , ) pp_mean = pp_mean . map_offdiag ( sns . scatterplot ) pp_mean = pp_mean . map_diag ( sns . histplot , kde = True ) pp_mean = pp_mean . map_lower ( corrfunc ) From the pairplot, we notice interesting things like the three \"good brothers\", radius, area and perimeter, whom are highly positively correlated.","title":"Bivariate Analysis"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/#pca-tsne","text":"We can also plot PCA and TSNE to get a feel of how \"separable\" the data points are in 2 dimensional space. Standardization Alert A disclaimer/assumption here is that we are standardizing the full training set for the purpose of visualizations, and both PCA and TSNE benefit from data on the same scale. Note that preprocessing techniques such as standardization should not be applied to the test/hold-out set, as this will cause data leakage. def plot_dimensional_reduction ( df : pd . DataFrame , predictor_cols : List [ str ], colors : List [ str ] ): \"\"\"Plots PCA and TSNE for visualization of higher dimension to lower dimension. Args: df (pd.DataFrame): Dataframe to be plotted. predictor_cols (List[str]): List of predictor columns. colors (List[str]): List of colors for plotting. \"\"\" X_standardized = preprocessing . StandardScaler () . fit_transform ( df [ predictor_cols ]) # Binary classification: we can set n components to 2 to better visualize all features in 2 dimensions pca = decomposition . PCA ( n_components = 2 ) pca_2d = pca . fit_transform ( X_standardized ) tsne = manifold . TSNE ( n_components = 2 , verbose = 1 , perplexity = 40 , n_iter = 1500 ) tsne_2d = tsne . fit_transform ( X_standardized ) # Plot the TSNE and PCA visuals side-by-side plt . figure ( figsize = ( 16 , 11 )) plt . subplot ( 121 ) plt . scatter ( pca_2d [:, 0 ], pca_2d [:, 1 ], c = df [ \"diagnosis\" ], edgecolor = \"None\" , alpha = 0.35 ) plt . colorbar () plt . title ( \"PCA Scatter Plot\" ) plt . subplot ( 122 ) plt . scatter ( tsne_2d [:, 0 ], tsne_2d [:, 1 ], c = df [ \"diagnosis\" ], edgecolor = \"None\" , alpha = 0.35 , ) plt . colorbar () plt . title ( \"TSNE Scatter Plot\" ) plt . show () _ = plot_dimensional_reduction ( df = df , predictor_cols = predictor_cols , colors = [ config . colors [ 0 ], config . colors [ 1 ]]) [t-SNE] Computing 121 nearest neighbors... [t-SNE] Indexed 569 samples in 0.003s... [t-SNE] Computed neighbors for 569 samples in 0.052s... [t-SNE] Computed conditional probabilities for sample 569 / 569 [t-SNE] Mean sigma: 1.522404 [t-SNE] KL divergence after 250 iterations with early exaggeration: 63.866753 [t-SNE] KL divergence after 1450 iterations: 0.847863 Welp, the purpose of this plot is to show how well separated the data points are in 2d-space (binary classification). It does seem that TSNE can distinguish the clusters clearer than PCA. This may suggest that your data points are non-linear, which is one assumption that PCA takes. We are not restricted to only linear models, so this is fine!","title":"PCA, TSNE"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%203%20-%20Feature%20Engineering/","text":"Stage 3: Feature Engineering by Hongnan Gao Quick Navigation Dependencies and Configuration Stage 3: Feature Engineering/Feature Selection Multicollinearity and Feature Selection Target Distribution Using Statsmodels Variance Inflation Factor Oh Dear, we have a Multicollinearity Problem Save the Data Dependencies and Configuration import random from collections import defaultdict from dataclasses import dataclass , field from typing import Dict , List , Union import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns from sklearn import ( base , decomposition , linear_model , manifold , metrics , preprocessing ) from statsmodels.stats.outliers_influence import variance_inflation_factor /usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead. import pandas.util.testing as tm @dataclass class config : raw_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/raw/data.csv\" processed_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/processed.csv\" train_size : float = 0.9 seed : int = 1992 num_folds : int = 5 cv_schema : str = \"StratifiedKFold\" classification_type : str = \"binary\" target_col : List [ str ] = field ( default_factory = lambda : [ \"diagnosis\" ]) unwanted_cols : List [ str ] = field ( default_factory = lambda : [ \"id\" , \"Unnamed: 32\" ]) # Plotting colors : List [ str ] = field ( default_factory = lambda : [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ] ) cmap_reversed = plt . cm . get_cmap ( \"mako_r\" ) def to_dict ( self ) -> Dict : \"\"\"Convert the config object to a dictionary. Returns: Dict: The config object as a dictionary. \"\"\" return { \"raw_data\" : self . raw_data , \"processed_data\" : self . processed_data , \"train_size\" : self . train_size , \"seed\" : self . seed , \"num_folds\" : self . num_folds , \"cv_schema\" : self . cv_schema , \"classification_type\" : self . classification_type , \"target_col\" : self . target_col , \"unwanted_cols\" : self . unwanted_cols , \"colors\" : self . colors , \"cmap_reversed\" : self . cmap_reversed , } def set_seeds ( seed : int = 1234 ) -> None : \"\"\"Set seeds for reproducibility.\"\"\" np . random . seed ( seed ) random . seed ( seed ) config = config () # set seeding for reproducibility _ = set_seeds ( seed = config . seed ) # read data df = pd . read_csv ( config . processed_data ) Stage 3: Feature Engineering/Feature Selection Foreward on Data Leakage We are fully aware that oftentimes practitioner may accidentally cause data leakage during preprocessing, for example, a subtle yet often mistake is to standardize the whole dataset prior to splitting, or performing feature selection prior to modelling using the information of our response/target variable. However, this does not mean we should not do any preprocessing before modelling, instead, in the case of removing multicollinearity features, we can still screen predictors for multicollinearity during EDA phase and have a good intuition on which predictors are highly correlated - subsequently, we will incorporate feature selection techniques in our modelling pipeline. Multicollinearity and Feature Selection Why Feature Selection? We need feature selection in certain problems for the following reasons: - Well, one would definitely have heard of the dreaded Curse of Dimensionality in the journey of learning Machine Learning where having too many predictor/features can lead to overfitting; on the other hand, too many dimensions can cause distance between observations to appear equidistance from one another. The equidistance phenomenon causes observations to become harder to cluster, thereby clogging the model's ability to cluster data points (imagine the horror if you use KNN on 1000 dimensions, all the points will be almost the same distance from each other, poor KNN will not know how to predict now). - In case you have access to Google's GPU clusters, you likely want to train your model faster. Reducing the number predictors can aid this process. - Reducing uninformative features may aid in model's performance, the idea is to remove unnecessary noise from the dataset. Multi-Collinearity Looking back at our dataset, it is clear to me that there are quite a number of features that are correlated with each other, causing multi-collinearity. Multi-Collinearity is an issue in the history of Linear Models, as quoted 1 Consider the simplest case where Y is regressed against X and Z and where X and Z are highly positively correlated. Then the effect of X on Y is hard to distinguish from the effect of Z on Y because any increase in X tends to be associated with an increase in Z. We also note that multi-collinearity is not that big of a problem for non-parametric models such as Decision Tree or Random Forests, however, I will attempt to show that it is still best to avoid in this problem setting. Feature Selection Methods There are many methods to perform feature selection. Scikit-Learn offers some of the following: - Univariate feature selection. - Recursive feature elimination. - Backward Elimination of features using Hypothesis Testing. We need to be careful when selecting features before cross-validation. It is therefore, recommended to include feature selection in cross-validation to avoid any \"bias\" introduced before model selection phase! I decided to use the good old Variance Inflation Factor (VIF) as a way to reduce multicollinearity. Unfortunately, there is no out-of-the-box function to integrate into the Pipeline of scikit-learn. Thus, I heavily modified an existing code in order achieve what I want below. Variance Inflation Factor A classical way to check for multicollinearity amongst predictors is to calculate the Variable Inflation Factor (VIF). It is simply done by regressing each predictor \\(\\mathrm{x}_i\\) against all other predictors \\(\\mathrm{x}_j, j \\neq i\\) . In other words, the VIF for a predictor variable \\(i\\) is given by: \\[\\text{VIF}_i = \\dfrac{1}{1 - R^{2}_{i}}\\] where \\(R^{2}_{i}\\) is, by definition, the proportion of the variation in the \"dependent variable\" \\(\\mathrm{x}_i\\) that is predictable from the indepedent predictors \\(\\mathrm{x}_j, j \\neq i\\) . Consequently, the higher the \\(R^2_i\\) of a predictor, the higher the VIF, and this indicates there is linear dependence among predictors. Using Statsmodels Variance Inflation Factor Note that we need to perform scaling first before fitting our ReduceVIF to get the exact same result as the previous version. In this version, I manually added a hard threshold for the number of features remaining to be 15. This hard coded number can be turned into a parameter (hyperparameter) in our pipeline. import numpy as np import pandas as pd from sklearn import base from statsmodels.regression.linear_model import OLS def variance_inflation_factor ( exog , idx_kept , vif_idx ): \"\"\"Compute VIF for one feature. Args: exog (np.ndarray): Observations idx_kept (List[int]): Indices of features to consider vif_idx (int): Index of feature for which to compute VIF Returns: float: VIF for the selected feature \"\"\" exog = np . asarray ( exog ) x_i = exog [:, vif_idx ] mask = [ col for col in idx_kept if col != vif_idx ] x_noti = exog [:, mask ] r_squared_i = OLS ( x_i , x_noti ) . fit () . rsquared vif = 1. / ( 1. - r_squared_i ) return vif class ReduceVIF ( base . BaseEstimator , base . TransformerMixin ): \"\"\"The base of the class structure is implemented in https://www.kaggle.com/ffisegydd/sklearn-multicollinearity-class; I heavily modified the class such that it can take in numpy arrays and correctly implemented the fit and transform method. \"\"\" def __init__ ( self , thresh = 10 , max_drop = 20 ): self . thresh = thresh self . max_drop = max_drop self . column_indices_kept_ = [] self . feature_names_kept_ = None def reset ( self ): \"\"\"Resets the state of predictor columns after each fold.\"\"\" self . column_indices_kept_ = [] self . feature_names_kept_ = None def fit ( self , X , y = None ): \"\"\"Fits the Recursive VIF on the training folds and save the selected feature names in self.feature_names Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" self . column_indices_kept_ , self . feature_names_kept_ = self . calculate_vif ( X ) return self def transform ( self , X , y = None ): \"\"\"Transforms the Validation Set according to the selected feature names. Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" return X [:, self . column_indices_kept_ ] def calculate_vif ( self , X : Union [ np . ndarray , pd . DataFrame ]): \"\"\"Implements a VIF function that recursively eliminates features. Args: X (Union[np.ndarray, pd.DataFrame]): [description] Returns: [type]: [description] \"\"\" feature_names = None column_indices_kept = list ( range ( X . shape [ 1 ])) if isinstance ( X , pd . DataFrame ): feature_names = X . columns dropped = True count = 0 while dropped and count <= self . max_drop : dropped = False max_vif , max_vif_col = None , None for col in column_indices_kept : vif = variance_inflation_factor ( X , column_indices_kept , col ) if max_vif is None or vif > max_vif : max_vif = vif max_vif_col = col if max_vif > self . thresh : print ( f \"Droppingggggg { max_vif_col } with vif= { max_vif } \" ) column_indices_kept . remove ( max_vif_col ) if feature_names is not None : feature_names . pop ( max_vif_col ) dropped = True count += 1 return column_indices_kept , feature_names We do a sanity check if this coincides with the previous defined class, and the results are the same. predictor_cols = df . columns [ 1 :] transformer = ReduceVIF () scaler = preprocessing . StandardScaler () X = scaler . fit_transform ( df [ predictor_cols ]) # Only use 10 columns for speed in this example X = transformer . fit_transform ( X ) print ( f \"Remaining Features: { transformer . column_indices_kept_ } \" ) Droppingggggg 0 with vif=3806.1152963979675 Droppingggggg 20 with vif=616.3508614719424 Droppingggggg 2 with vif=325.64131198187516 Droppingggggg 22 with vif=123.25781086343038 Droppingggggg 6 with vif=64.65479584770004 Droppingggggg 10 with vif=35.61751844352034 Droppingggggg 25 with vif=33.96063880508537 Droppingggggg 27 with vif=30.596655364834078 Droppingggggg 3 with vif=25.387829695531458 Droppingggggg 5 with vif=18.843208489973282 Droppingggggg 21 with vif=17.232376192128665 Droppingggggg 13 with vif=16.333806476471736 Droppingggggg 26 with vif=15.510661467365699 Remaining Features: [1, 4, 7, 8, 9, 11, 12, 14, 15, 16, 17, 18, 19, 23, 24, 28, 29] We have the remaining indices, and therefore simply use numpy to subset the column indices to get back the original column names that are kept. vif_df = pd . DataFrame ({ 'Predictors' : predictor_cols [ transformer . column_indices_kept_ ]}) display ( vif_df ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Predictors 0 texture_mean 1 smoothness_mean 2 concave points_mean 3 symmetry_mean 4 fractal_dimension_mean 5 texture_se 6 perimeter_se 7 smoothness_se 8 compactness_se 9 concavity_se 10 concave points_se 11 symmetry_se 12 fractal_dimension_se 13 area_worst 14 smoothness_worst 15 symmetry_worst 16 fractal_dimension_worst Oh Dear, we have a Multicollinearity Problem Using VIF in Modelling Pipeline At this step, we are just showing how we can remove multicollinear features using VIF; but we will not remove them at this point in time. We will incorporate this feature selection technique in our Cross-Validation pipeline in order to avoid data leakage. Save the Data In this phase, we did not make any changes to the predictor or target columns. So there is nothing to save. https://stats.stackexchange.com/questions/1149/is-there-an-intuitive-explanation-why-multicollinearity-is-a-problem-in-linear-r \u21a9","title":"Feature Engineering"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%203%20-%20Feature%20Engineering/#dependencies-and-configuration","text":"import random from collections import defaultdict from dataclasses import dataclass , field from typing import Dict , List , Union import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns from sklearn import ( base , decomposition , linear_model , manifold , metrics , preprocessing ) from statsmodels.stats.outliers_influence import variance_inflation_factor /usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead. import pandas.util.testing as tm @dataclass class config : raw_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/raw/data.csv\" processed_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/processed.csv\" train_size : float = 0.9 seed : int = 1992 num_folds : int = 5 cv_schema : str = \"StratifiedKFold\" classification_type : str = \"binary\" target_col : List [ str ] = field ( default_factory = lambda : [ \"diagnosis\" ]) unwanted_cols : List [ str ] = field ( default_factory = lambda : [ \"id\" , \"Unnamed: 32\" ]) # Plotting colors : List [ str ] = field ( default_factory = lambda : [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ] ) cmap_reversed = plt . cm . get_cmap ( \"mako_r\" ) def to_dict ( self ) -> Dict : \"\"\"Convert the config object to a dictionary. Returns: Dict: The config object as a dictionary. \"\"\" return { \"raw_data\" : self . raw_data , \"processed_data\" : self . processed_data , \"train_size\" : self . train_size , \"seed\" : self . seed , \"num_folds\" : self . num_folds , \"cv_schema\" : self . cv_schema , \"classification_type\" : self . classification_type , \"target_col\" : self . target_col , \"unwanted_cols\" : self . unwanted_cols , \"colors\" : self . colors , \"cmap_reversed\" : self . cmap_reversed , } def set_seeds ( seed : int = 1234 ) -> None : \"\"\"Set seeds for reproducibility.\"\"\" np . random . seed ( seed ) random . seed ( seed ) config = config () # set seeding for reproducibility _ = set_seeds ( seed = config . seed ) # read data df = pd . read_csv ( config . processed_data )","title":"Dependencies and Configuration"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%203%20-%20Feature%20Engineering/#stage-3-feature-engineeringfeature-selection","text":"Foreward on Data Leakage We are fully aware that oftentimes practitioner may accidentally cause data leakage during preprocessing, for example, a subtle yet often mistake is to standardize the whole dataset prior to splitting, or performing feature selection prior to modelling using the information of our response/target variable. However, this does not mean we should not do any preprocessing before modelling, instead, in the case of removing multicollinearity features, we can still screen predictors for multicollinearity during EDA phase and have a good intuition on which predictors are highly correlated - subsequently, we will incorporate feature selection techniques in our modelling pipeline.","title":"Stage 3: Feature Engineering/Feature Selection"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%203%20-%20Feature%20Engineering/#multicollinearity-and-feature-selection","text":"Why Feature Selection? We need feature selection in certain problems for the following reasons: - Well, one would definitely have heard of the dreaded Curse of Dimensionality in the journey of learning Machine Learning where having too many predictor/features can lead to overfitting; on the other hand, too many dimensions can cause distance between observations to appear equidistance from one another. The equidistance phenomenon causes observations to become harder to cluster, thereby clogging the model's ability to cluster data points (imagine the horror if you use KNN on 1000 dimensions, all the points will be almost the same distance from each other, poor KNN will not know how to predict now). - In case you have access to Google's GPU clusters, you likely want to train your model faster. Reducing the number predictors can aid this process. - Reducing uninformative features may aid in model's performance, the idea is to remove unnecessary noise from the dataset. Multi-Collinearity Looking back at our dataset, it is clear to me that there are quite a number of features that are correlated with each other, causing multi-collinearity. Multi-Collinearity is an issue in the history of Linear Models, as quoted 1 Consider the simplest case where Y is regressed against X and Z and where X and Z are highly positively correlated. Then the effect of X on Y is hard to distinguish from the effect of Z on Y because any increase in X tends to be associated with an increase in Z. We also note that multi-collinearity is not that big of a problem for non-parametric models such as Decision Tree or Random Forests, however, I will attempt to show that it is still best to avoid in this problem setting. Feature Selection Methods There are many methods to perform feature selection. Scikit-Learn offers some of the following: - Univariate feature selection. - Recursive feature elimination. - Backward Elimination of features using Hypothesis Testing. We need to be careful when selecting features before cross-validation. It is therefore, recommended to include feature selection in cross-validation to avoid any \"bias\" introduced before model selection phase! I decided to use the good old Variance Inflation Factor (VIF) as a way to reduce multicollinearity. Unfortunately, there is no out-of-the-box function to integrate into the Pipeline of scikit-learn. Thus, I heavily modified an existing code in order achieve what I want below.","title":"Multicollinearity and Feature Selection"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%203%20-%20Feature%20Engineering/#variance-inflation-factor","text":"A classical way to check for multicollinearity amongst predictors is to calculate the Variable Inflation Factor (VIF). It is simply done by regressing each predictor \\(\\mathrm{x}_i\\) against all other predictors \\(\\mathrm{x}_j, j \\neq i\\) . In other words, the VIF for a predictor variable \\(i\\) is given by: \\[\\text{VIF}_i = \\dfrac{1}{1 - R^{2}_{i}}\\] where \\(R^{2}_{i}\\) is, by definition, the proportion of the variation in the \"dependent variable\" \\(\\mathrm{x}_i\\) that is predictable from the indepedent predictors \\(\\mathrm{x}_j, j \\neq i\\) . Consequently, the higher the \\(R^2_i\\) of a predictor, the higher the VIF, and this indicates there is linear dependence among predictors.","title":"Variance Inflation Factor"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%203%20-%20Feature%20Engineering/#using-statsmodels-variance-inflation-factor","text":"Note that we need to perform scaling first before fitting our ReduceVIF to get the exact same result as the previous version. In this version, I manually added a hard threshold for the number of features remaining to be 15. This hard coded number can be turned into a parameter (hyperparameter) in our pipeline. import numpy as np import pandas as pd from sklearn import base from statsmodels.regression.linear_model import OLS def variance_inflation_factor ( exog , idx_kept , vif_idx ): \"\"\"Compute VIF for one feature. Args: exog (np.ndarray): Observations idx_kept (List[int]): Indices of features to consider vif_idx (int): Index of feature for which to compute VIF Returns: float: VIF for the selected feature \"\"\" exog = np . asarray ( exog ) x_i = exog [:, vif_idx ] mask = [ col for col in idx_kept if col != vif_idx ] x_noti = exog [:, mask ] r_squared_i = OLS ( x_i , x_noti ) . fit () . rsquared vif = 1. / ( 1. - r_squared_i ) return vif class ReduceVIF ( base . BaseEstimator , base . TransformerMixin ): \"\"\"The base of the class structure is implemented in https://www.kaggle.com/ffisegydd/sklearn-multicollinearity-class; I heavily modified the class such that it can take in numpy arrays and correctly implemented the fit and transform method. \"\"\" def __init__ ( self , thresh = 10 , max_drop = 20 ): self . thresh = thresh self . max_drop = max_drop self . column_indices_kept_ = [] self . feature_names_kept_ = None def reset ( self ): \"\"\"Resets the state of predictor columns after each fold.\"\"\" self . column_indices_kept_ = [] self . feature_names_kept_ = None def fit ( self , X , y = None ): \"\"\"Fits the Recursive VIF on the training folds and save the selected feature names in self.feature_names Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" self . column_indices_kept_ , self . feature_names_kept_ = self . calculate_vif ( X ) return self def transform ( self , X , y = None ): \"\"\"Transforms the Validation Set according to the selected feature names. Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" return X [:, self . column_indices_kept_ ] def calculate_vif ( self , X : Union [ np . ndarray , pd . DataFrame ]): \"\"\"Implements a VIF function that recursively eliminates features. Args: X (Union[np.ndarray, pd.DataFrame]): [description] Returns: [type]: [description] \"\"\" feature_names = None column_indices_kept = list ( range ( X . shape [ 1 ])) if isinstance ( X , pd . DataFrame ): feature_names = X . columns dropped = True count = 0 while dropped and count <= self . max_drop : dropped = False max_vif , max_vif_col = None , None for col in column_indices_kept : vif = variance_inflation_factor ( X , column_indices_kept , col ) if max_vif is None or vif > max_vif : max_vif = vif max_vif_col = col if max_vif > self . thresh : print ( f \"Droppingggggg { max_vif_col } with vif= { max_vif } \" ) column_indices_kept . remove ( max_vif_col ) if feature_names is not None : feature_names . pop ( max_vif_col ) dropped = True count += 1 return column_indices_kept , feature_names We do a sanity check if this coincides with the previous defined class, and the results are the same. predictor_cols = df . columns [ 1 :] transformer = ReduceVIF () scaler = preprocessing . StandardScaler () X = scaler . fit_transform ( df [ predictor_cols ]) # Only use 10 columns for speed in this example X = transformer . fit_transform ( X ) print ( f \"Remaining Features: { transformer . column_indices_kept_ } \" ) Droppingggggg 0 with vif=3806.1152963979675 Droppingggggg 20 with vif=616.3508614719424 Droppingggggg 2 with vif=325.64131198187516 Droppingggggg 22 with vif=123.25781086343038 Droppingggggg 6 with vif=64.65479584770004 Droppingggggg 10 with vif=35.61751844352034 Droppingggggg 25 with vif=33.96063880508537 Droppingggggg 27 with vif=30.596655364834078 Droppingggggg 3 with vif=25.387829695531458 Droppingggggg 5 with vif=18.843208489973282 Droppingggggg 21 with vif=17.232376192128665 Droppingggggg 13 with vif=16.333806476471736 Droppingggggg 26 with vif=15.510661467365699 Remaining Features: [1, 4, 7, 8, 9, 11, 12, 14, 15, 16, 17, 18, 19, 23, 24, 28, 29] We have the remaining indices, and therefore simply use numpy to subset the column indices to get back the original column names that are kept. vif_df = pd . DataFrame ({ 'Predictors' : predictor_cols [ transformer . column_indices_kept_ ]}) display ( vif_df ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Predictors 0 texture_mean 1 smoothness_mean 2 concave points_mean 3 symmetry_mean 4 fractal_dimension_mean 5 texture_se 6 perimeter_se 7 smoothness_se 8 compactness_se 9 concavity_se 10 concave points_se 11 symmetry_se 12 fractal_dimension_se 13 area_worst 14 smoothness_worst 15 symmetry_worst 16 fractal_dimension_worst","title":"Using Statsmodels Variance Inflation Factor"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%203%20-%20Feature%20Engineering/#oh-dear-we-have-a-multicollinearity-problem","text":"Using VIF in Modelling Pipeline At this step, we are just showing how we can remove multicollinear features using VIF; but we will not remove them at this point in time. We will incorporate this feature selection technique in our Cross-Validation pipeline in order to avoid data leakage.","title":"Oh Dear, we have a Multicollinearity Problem"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%203%20-%20Feature%20Engineering/#save-the-data","text":"In this phase, we did not make any changes to the predictor or target columns. So there is nothing to save. https://stats.stackexchange.com/questions/1149/is-there-an-intuitive-explanation-why-multicollinearity-is-a-problem-in-linear-r \u21a9","title":"Save the Data"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%204%20-%20Modelling%20%28Metric%20to%20Optimize%29/","text":"Stage 4: Modelling (Metrics) by Hongnan Gao Define Metrics Disclaimer: For a more detailed understanding of different metrics, do navigate to my self-made notes on metrics here . Choosing a metric to measure the classifier's (hypothesis) performance is important, as choosing the wrong one can lead to disastrous interpretations. One prime example is using the accuracy metric for imbalanced datasets; consider 1 mil data points, dichotomized by \\(99\\%\\) benign and \\(1\\%\\) malignant samples, even a baseline model zeroR model which predicts the majority class no matter the process will give a \\(99\\%\\) accuracy, completely missing out any positive samples, which unfortunately, is what we may be more interested in. Say No to Accuracy: Consider an imbalanced set, where the training data set has 100 patients (data points), and the ground truth is 90 patients are of class = 0, which means that these patients do not have cancer, whereas the remaining 10 patients are in class 1, where they do have cancer. This is an example of class imbalance where the ratio of class 1 to class 0 is 1:9. Consider a baseline (almost trivial) classifier : def zeroR ( patient_data ): training ... return benign where we predict the patient's class as the most frequent class. Meaning, the most frequent class in this question is the class = 0, where patients do not have cancer, so we just assign this class to everyone in this set. By doing this, we will inevitably achieve a in-sample accuracy rate of \\(\\frac{90}{100} = 90\\%\\) . But unfortunately, this supposedly high accuracy value is completely useless, because this classifier did not label any of the cancer patients correctly. The consequence can be serious, assuming the test set has the same distribution as our training set, where if we have a test set of 1000 patients, there are 900 negative and 100 positive. Our model just literally predict every one of them as benign, yielding a \\(90\\%\\) out-of-sample accuracy. What did we conclude? Well, for one, our accuracy can be 90% high and looks good to the laymen, but it failed to predict the most important class of people - yes, misclassifying true cancer patients as healthy people is very bad! For the reasons mentioned above, we will use metric that can help us reduce False Negatives, and at the same time, outputs meaningful predictions. In order to achieve for both, we will use Receiver operating characteristic (ROC) as the primary metric for the model to maximize (which is our \\(\\mathcal{M}\\) , and Brier Score , a proper scoring rule to measure the performance of our probabilistic predictions. We will go into some details in the next two subsections to justify our choice. Proper Scoring Rule The math behind the idea of Proper Scoring Rule is non-trivial. Here, we try to understand why a proper scoring rule is desired in the context of binary classification. Strictly Proper Scoring Rule: Brier Score Loss, for example, tells us that the best possible score, 0 (lowest loss), is obtained if and only if, the probability prediction we get for a sample, is the true probability itself. In other words, if a selected sample is of class 1, our prediction for this must be 1, with 100% probability, in order to get a score loss of 0. Proper Scoring Rule: Read [here](https://stats.stackexchange.com/questions/339919/what-does-it-mean-that-auc-is-a-semi-proper-scoring-rule) for this. Semi Proper Scoring Rule: AUROC, as mentioned, does not help out in telling whether a prediction by a classifier is close to the true probability or not. In our example, we even see that we can obtain a full score of 1, even if the probabilities all lie within 0.51 and 0.52. Improper Scoring Rule: Accuracy is a prime example, the accuracy score does not, whatsoever, tells us about how close our predicted probabilities are, to the true probability distribution of our samples. Receiver operating characteristic (ROC) Definition: The basic (non-probablistic intepretation) of ROC is graph that plots the True Positive Rate on the y-axis and False Positive Rate on the x-axis parametrized by a threshold vector $\\vec{t}$. We then look at the area under the ROC curve (AUROC) to get an overall performance measure. The choice of ROC over other metrics such as Accuracy is detailed initially. We also established we want to reduce False Negative (FN), since misclassifying a positive patient as benign is way more costly than the other way round. One can choose to minimize Recall in order to reduce FN, but this is less than ideal during training because it is a thresholded metric, and does not provide at which threshold the recall is at minimum. This leads us to choose ROC for the following two main reasons: Threshold Invariant By definition, ROC computes the pair \\(TPR \\times FPR\\) over all thresholds \\(t\\) , consequently, the AUROC is threshold invariant, allowing us to look at the model's performance over all thresholds. We note that ROC may not be that reliable in the case of very imbalanced datasets where majority is in the negative class, as \\(FPR = \\dfrac{FP}{FP+TN}\\) may seem deceptively low as denominator may be made small by the sheer amount of TN, in this case, we may also look at the Precision-Recall curve. Scale Invariant Technically, this is not the desired property that we need, as this means that the ROC is non-proper in scoring, it can take in non-calibrated scores and still perform relatively well. A classic example I always use is the following: y1 = [ 1 , 0 , 1 , 0 ] y2 = [ 0.52 , 0.51 , 0.52 , 0.51 ] y3 = [ 52 , 51 , 52 , 51 ] uncalibrated_roc = roc ( y1 , y2 ) == roc ( y1 , y3 ) print ( f \" { uncalibrated_roc } \" ) -> 1.0 The example tells us two things, as long as the ranking of predictions is preserved, the final AUROC score is the same, regardless of scale. We also notice that even though the model gives very unconfident predictions, the AUROC score is 1, which can be misleadingly over-optimistic. With that, we introduce Brier Score. Common Pitfalls Careful when using ROC function! We also note that when passing arguments to scikit-learn's roc_auc_score function, we should be careful not to pass y_score=model.predict(X) inside as we have to understand that we are passing in non-thresholded probabilities into y_score . If you pass the predicted values (full of 0 and 1s), then you are thresholding on 0 and 1 only, which is incorrect by definition. Brier Score Definition: Brier Score computes the squared difference between the probability of a prediction and its actual outcome. Brier Score is a strictly proper scoring rule while ROC is not ; the lower the Brier Score, the better the predictions are calibrated. We can first compute the AUROC score of the model, and compute Brier Score to give us how well calibrated (confident) the predictions are. Well Calibrated A intuitive way of understanding well calibrated probabilities is as follows, extracted from cambridge's probability calibration : In very simple terms, these are probabilities which can be interpreted as a confidence interval. Furthermore, a classifier is said to produce well calibrated probabilities if for the instances (data points) receiving probability 0.5, 50% of those instances belongs to the positive class. In my own words, if a classifier is well calibrated, say in our context where we predict binary target, and pretend that out of our test set, 100 of the samples have a probability of around 0.1, then this means 10% of these 100 samples actually belong to the positive class. The generic steps are as follows to calculate a calibrated plot: Sort all the samples by the classifier's predicted probabilities, in either ascending or descending order. Bin your diagram into N bins, usually we take 10, which means on the X-axis, note this does not mean we have 0-0.1, 0.1-0.2, ..., 0.9-1 as the 10 bins. What step 2 means is let's say you have 100 predictions, if you bin by 10 bins, and since the predictions are sorted , we can easily divide the 100 predictions into 10 intervals: for illustration, assume the 100 predictions are as follows, where we sort by ascending order and the prediction 0.1 has 10 of them, 0.2 have 10 of them, so on and so forth. y_pred = [ 0.1 , 0.1 , ..... , 0.2 , 0.2 , ... , 0.9 , 0.9 , ... , 1 , 1 , .. .1 ] Since we can divide the above into 10 bins, bin 1 will have 10 samples of predictions 0.1, bin 2 will have 10 samples of predictions 0.2, etc. We then take the mean of the predictions of each bin , that is for the first bin, we calculate \\(\\dfrac{1}{10}\\sum_{i=1}^{10}0.1 = 0.1\\) , and second bin, \\(\\dfrac{1}{10}\\sum_{i=1}^{10}0.2 = 0.2\\) . Note that this may not be such a nice number in reality, I made this example for the ease of illustration! Now, we have our X-axis from step 4, that is, we turned 10 bins, into 10 numbers, 0.1, 0.2, 0.3, ..., 1, and then we need to find the corresponding points for each of the 10 numbers! This is easy, for 0.1, the corresponding y-axis is just the fraction of positives , which means, out of the 10 samples in the first bin, how many of these 10 samples were actually positive? We do this for all 10 bins (points), and plot a line graph as seen in scikit-learn. Now this should be apparent now that a well calibrated model should lie close to the \\(y = x\\) line. That is, if the mean predicted probability is 0.1, then the y-axis should also be 0.1, meaning to say that out of all the samples that were predicted as 0.1, we should really only have about 10% of them being positive. The same logic applies to the rest! Brier Score Loss Brier Score Loss is a handy metric to measure whether a classifier is well calibrated, as quoted from scikit-learn : Brier Score Loss may be used to assess how well a classifier is calibrated. However, this metric should be used with care because a lower Brier score does not always mean a better calibrated model. This is because the Brier score metric is a combination of calibration loss and refinement loss. Calibration loss is defined as the mean squared deviation from empirical probabilities derived from the slope of ROC segments. Refinement loss can be defined as the expected optimal loss as measured by the area under the optimal cost curve. As refinement loss can change independently from calibration loss, a lower Brier score does not necessarily mean a better calibrated model. Common Pitfalls Class Imbalance: The good ol' class imbalance issue almost always pop up anywhere and everywhere. Intuitively, if we have a super rare positive/negative class, then if the model is very confident in its predictions for the majority class, but not so confident on the rare class, the overall Brier Score Loss may not be sufficient in discriminating the classifier's inability in correctly classifying the minority class.","title":"Modelling (Metrics)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%204%20-%20Modelling%20%28Metric%20to%20Optimize%29/#define-metrics","text":"Disclaimer: For a more detailed understanding of different metrics, do navigate to my self-made notes on metrics here . Choosing a metric to measure the classifier's (hypothesis) performance is important, as choosing the wrong one can lead to disastrous interpretations. One prime example is using the accuracy metric for imbalanced datasets; consider 1 mil data points, dichotomized by \\(99\\%\\) benign and \\(1\\%\\) malignant samples, even a baseline model zeroR model which predicts the majority class no matter the process will give a \\(99\\%\\) accuracy, completely missing out any positive samples, which unfortunately, is what we may be more interested in. Say No to Accuracy: Consider an imbalanced set, where the training data set has 100 patients (data points), and the ground truth is 90 patients are of class = 0, which means that these patients do not have cancer, whereas the remaining 10 patients are in class 1, where they do have cancer. This is an example of class imbalance where the ratio of class 1 to class 0 is 1:9. Consider a baseline (almost trivial) classifier : def zeroR ( patient_data ): training ... return benign where we predict the patient's class as the most frequent class. Meaning, the most frequent class in this question is the class = 0, where patients do not have cancer, so we just assign this class to everyone in this set. By doing this, we will inevitably achieve a in-sample accuracy rate of \\(\\frac{90}{100} = 90\\%\\) . But unfortunately, this supposedly high accuracy value is completely useless, because this classifier did not label any of the cancer patients correctly. The consequence can be serious, assuming the test set has the same distribution as our training set, where if we have a test set of 1000 patients, there are 900 negative and 100 positive. Our model just literally predict every one of them as benign, yielding a \\(90\\%\\) out-of-sample accuracy. What did we conclude? Well, for one, our accuracy can be 90% high and looks good to the laymen, but it failed to predict the most important class of people - yes, misclassifying true cancer patients as healthy people is very bad! For the reasons mentioned above, we will use metric that can help us reduce False Negatives, and at the same time, outputs meaningful predictions. In order to achieve for both, we will use Receiver operating characteristic (ROC) as the primary metric for the model to maximize (which is our \\(\\mathcal{M}\\) , and Brier Score , a proper scoring rule to measure the performance of our probabilistic predictions. We will go into some details in the next two subsections to justify our choice.","title":"Define Metrics"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%204%20-%20Modelling%20%28Metric%20to%20Optimize%29/#proper-scoring-rule","text":"The math behind the idea of Proper Scoring Rule is non-trivial. Here, we try to understand why a proper scoring rule is desired in the context of binary classification. Strictly Proper Scoring Rule: Brier Score Loss, for example, tells us that the best possible score, 0 (lowest loss), is obtained if and only if, the probability prediction we get for a sample, is the true probability itself. In other words, if a selected sample is of class 1, our prediction for this must be 1, with 100% probability, in order to get a score loss of 0. Proper Scoring Rule: Read [here](https://stats.stackexchange.com/questions/339919/what-does-it-mean-that-auc-is-a-semi-proper-scoring-rule) for this. Semi Proper Scoring Rule: AUROC, as mentioned, does not help out in telling whether a prediction by a classifier is close to the true probability or not. In our example, we even see that we can obtain a full score of 1, even if the probabilities all lie within 0.51 and 0.52. Improper Scoring Rule: Accuracy is a prime example, the accuracy score does not, whatsoever, tells us about how close our predicted probabilities are, to the true probability distribution of our samples.","title":"Proper Scoring Rule"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%204%20-%20Modelling%20%28Metric%20to%20Optimize%29/#receiver-operating-characteristic-roc","text":"Definition: The basic (non-probablistic intepretation) of ROC is graph that plots the True Positive Rate on the y-axis and False Positive Rate on the x-axis parametrized by a threshold vector $\\vec{t}$. We then look at the area under the ROC curve (AUROC) to get an overall performance measure. The choice of ROC over other metrics such as Accuracy is detailed initially. We also established we want to reduce False Negative (FN), since misclassifying a positive patient as benign is way more costly than the other way round. One can choose to minimize Recall in order to reduce FN, but this is less than ideal during training because it is a thresholded metric, and does not provide at which threshold the recall is at minimum. This leads us to choose ROC for the following two main reasons:","title":"Receiver operating characteristic (ROC)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%204%20-%20Modelling%20%28Metric%20to%20Optimize%29/#threshold-invariant","text":"By definition, ROC computes the pair \\(TPR \\times FPR\\) over all thresholds \\(t\\) , consequently, the AUROC is threshold invariant, allowing us to look at the model's performance over all thresholds. We note that ROC may not be that reliable in the case of very imbalanced datasets where majority is in the negative class, as \\(FPR = \\dfrac{FP}{FP+TN}\\) may seem deceptively low as denominator may be made small by the sheer amount of TN, in this case, we may also look at the Precision-Recall curve.","title":"Threshold Invariant"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%204%20-%20Modelling%20%28Metric%20to%20Optimize%29/#scale-invariant","text":"Technically, this is not the desired property that we need, as this means that the ROC is non-proper in scoring, it can take in non-calibrated scores and still perform relatively well. A classic example I always use is the following: y1 = [ 1 , 0 , 1 , 0 ] y2 = [ 0.52 , 0.51 , 0.52 , 0.51 ] y3 = [ 52 , 51 , 52 , 51 ] uncalibrated_roc = roc ( y1 , y2 ) == roc ( y1 , y3 ) print ( f \" { uncalibrated_roc } \" ) -> 1.0 The example tells us two things, as long as the ranking of predictions is preserved, the final AUROC score is the same, regardless of scale. We also notice that even though the model gives very unconfident predictions, the AUROC score is 1, which can be misleadingly over-optimistic. With that, we introduce Brier Score.","title":"Scale Invariant"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%204%20-%20Modelling%20%28Metric%20to%20Optimize%29/#common-pitfalls","text":"Careful when using ROC function! We also note that when passing arguments to scikit-learn's roc_auc_score function, we should be careful not to pass y_score=model.predict(X) inside as we have to understand that we are passing in non-thresholded probabilities into y_score . If you pass the predicted values (full of 0 and 1s), then you are thresholding on 0 and 1 only, which is incorrect by definition.","title":"Common Pitfalls"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%204%20-%20Modelling%20%28Metric%20to%20Optimize%29/#brier-score","text":"Definition: Brier Score computes the squared difference between the probability of a prediction and its actual outcome. Brier Score is a strictly proper scoring rule while ROC is not ; the lower the Brier Score, the better the predictions are calibrated. We can first compute the AUROC score of the model, and compute Brier Score to give us how well calibrated (confident) the predictions are.","title":"Brier Score"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%204%20-%20Modelling%20%28Metric%20to%20Optimize%29/#well-calibrated","text":"A intuitive way of understanding well calibrated probabilities is as follows, extracted from cambridge's probability calibration : In very simple terms, these are probabilities which can be interpreted as a confidence interval. Furthermore, a classifier is said to produce well calibrated probabilities if for the instances (data points) receiving probability 0.5, 50% of those instances belongs to the positive class. In my own words, if a classifier is well calibrated, say in our context where we predict binary target, and pretend that out of our test set, 100 of the samples have a probability of around 0.1, then this means 10% of these 100 samples actually belong to the positive class. The generic steps are as follows to calculate a calibrated plot: Sort all the samples by the classifier's predicted probabilities, in either ascending or descending order. Bin your diagram into N bins, usually we take 10, which means on the X-axis, note this does not mean we have 0-0.1, 0.1-0.2, ..., 0.9-1 as the 10 bins. What step 2 means is let's say you have 100 predictions, if you bin by 10 bins, and since the predictions are sorted , we can easily divide the 100 predictions into 10 intervals: for illustration, assume the 100 predictions are as follows, where we sort by ascending order and the prediction 0.1 has 10 of them, 0.2 have 10 of them, so on and so forth. y_pred = [ 0.1 , 0.1 , ..... , 0.2 , 0.2 , ... , 0.9 , 0.9 , ... , 1 , 1 , .. .1 ] Since we can divide the above into 10 bins, bin 1 will have 10 samples of predictions 0.1, bin 2 will have 10 samples of predictions 0.2, etc. We then take the mean of the predictions of each bin , that is for the first bin, we calculate \\(\\dfrac{1}{10}\\sum_{i=1}^{10}0.1 = 0.1\\) , and second bin, \\(\\dfrac{1}{10}\\sum_{i=1}^{10}0.2 = 0.2\\) . Note that this may not be such a nice number in reality, I made this example for the ease of illustration! Now, we have our X-axis from step 4, that is, we turned 10 bins, into 10 numbers, 0.1, 0.2, 0.3, ..., 1, and then we need to find the corresponding points for each of the 10 numbers! This is easy, for 0.1, the corresponding y-axis is just the fraction of positives , which means, out of the 10 samples in the first bin, how many of these 10 samples were actually positive? We do this for all 10 bins (points), and plot a line graph as seen in scikit-learn. Now this should be apparent now that a well calibrated model should lie close to the \\(y = x\\) line. That is, if the mean predicted probability is 0.1, then the y-axis should also be 0.1, meaning to say that out of all the samples that were predicted as 0.1, we should really only have about 10% of them being positive. The same logic applies to the rest!","title":"Well Calibrated"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%204%20-%20Modelling%20%28Metric%20to%20Optimize%29/#brier-score-loss","text":"Brier Score Loss is a handy metric to measure whether a classifier is well calibrated, as quoted from scikit-learn : Brier Score Loss may be used to assess how well a classifier is calibrated. However, this metric should be used with care because a lower Brier score does not always mean a better calibrated model. This is because the Brier score metric is a combination of calibration loss and refinement loss. Calibration loss is defined as the mean squared deviation from empirical probabilities derived from the slope of ROC segments. Refinement loss can be defined as the expected optimal loss as measured by the area under the optimal cost curve. As refinement loss can change independently from calibration loss, a lower Brier score does not necessarily mean a better calibrated model.","title":"Brier Score Loss"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%204%20-%20Modelling%20%28Metric%20to%20Optimize%29/#common-pitfalls_1","text":"Class Imbalance: The good ol' class imbalance issue almost always pop up anywhere and everywhere. Intuitively, if we have a super rare positive/negative class, then if the model is very confident in its predictions for the majority class, but not so confident on the rare class, the overall Brier Score Loss may not be sufficient in discriminating the classifier's inability in correctly classifying the minority class.","title":"Common Pitfalls"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%205%20-%20Modelling%20%28Cross-Validation%20Methodology%29/","text":"Stage 5: Modelling (Cross-Validation) by Hongnan Gao Dependencies and Configuration import logging import random from dataclasses import dataclass , field from time import time from typing import Any , Callable , Dict , List , Optional , Union import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns from sklearn import model_selection @dataclass class config : raw_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/raw/data.csv\" processed_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/processed.csv\" train_size : float = 0.9 seed : int = 1992 num_folds : int = 5 cv_schema : str = \"StratifiedKFold\" classification_type : str = \"binary\" target_col : List [ str ] = field ( default_factory = lambda : [ \"diagnosis\" ]) unwanted_cols : List [ str ] = field ( default_factory = lambda : [ \"id\" , \"Unnamed: 32\" ]) # Plotting colors : List [ str ] = field ( default_factory = lambda : [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ]) cmap_reversed = plt . cm . get_cmap ( 'mako_r' ) def to_dict ( self ) -> Dict : \"\"\"Convert the config object to a dictionary. Returns: Dict: The config object as a dictionary. \"\"\" return { \"raw_data\" : self . raw_data , \"processed_data\" : self . processed_data , \"train_size\" : self . train_size , \"seed\" : self . seed , \"num_folds\" : self . num_folds , \"cv_schema\" : self . cv_schema , \"classification_type\" : self . classification_type , \"target_col\" : self . target_col , \"unwanted_cols\" : self . unwanted_cols , \"colors\" : self . colors , \"cmap_reversed\" : self . cmap_reversed } def set_seeds ( seed : int = 1234 ) -> None : \"\"\"Set seeds for reproducibility.\"\"\" np . random . seed ( seed ) random . seed ( seed ) def init_logger ( log_file : str = \"info.log\" ): \"\"\" Initialize logger. \"\"\" logger = logging . getLogger ( __name__ ) logger . setLevel ( logging . INFO ) stream_handler = logging . StreamHandler () stream_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) file_handler = logging . FileHandler ( filename = log_file ) file_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) logger . addHandler ( stream_handler ) logger . addHandler ( file_handler ) return logger config = config () logger = init_logger () # set seeding for reproducibility _ = set_seeds ( seed = config . seed ) # read data df = pd . read_csv ( config . processed_data ) Cross-Validation Strategy Generalization Ultimately, we are interested in the Generalization Error made by the model, that is, how well the model perform on unseen data that is not taken from our sample set \\(\\mathcal{D}\\) . In general, we use validation set for Model Selection and the test set for an estimate of generalization error on new data. - Refactored from Elements of Statistical Learning, Chapter 7.2 Step 1: Train-Test-Split Since this dataset is relatively small, we will not use the train-validation-test split and only split into train and test in a ratio of 9:1, whereby the split is stratified on our target, using stratify=y parameter in train_test_split() to ensure that our target has equal representation in both train and test. We note that this is a relatively small dataset and in practice, we need a large sample size to get a reliable/stable split, it is also recommended to retrain the whole dataset (without the \"unseen\" test set) after we have done the model selection process (eg. finding best hyperparameters). Step 2: Resampling Strategy Note that we will be performing StratifiedKFold as our resampling strategy. After our split in Step 1, we have a training set \\(X_{\\text{train}}\\) , we will then perform our resampling strategy on this \\(X_{\\text{train}}\\) . We will choose our choice of \\(K = 5\\) . The choice of \\(K\\) is somewhat arbitrary, and is derived empirically . Cross-Validation Workflow To recap, we have the following: Training Set ( \\(X_{\\text{train}}\\) ) : This will be further split into K validation sets during our cross-validation. This set is used to fit a particular hypothesis \\(h \\in \\mathcal{H}\\) . Validation Set ( \\(X_{\\text{val}}\\) ) : This is split from our \\(X_{\\text{train}}\\) during cross-validation. This set is used for model selection (i.e. find best hyperparameters, attempt to produce a best hypothesis \\(g \\in \\mathcal{H}\\) ). Test Set ( \\(X_{\\text{test}}\\) ) : This is an unseen test set, and we will only use it after we finish tuning our model/hypothesis. Suppose we have a final best model \\(g\\) , we will use \\(g\\) to predict on the test set to get an estimate of the generalization error (also called out-of-sample error). Courtesy of scikit-learn on a typical Cross-Validation workflow. # Make a copy of df and assign it to X X = df . copy () # Pop diagnosis, the target column from X and assign the target column data to y y = X . pop ( \"diagnosis\" ) # Assign predictors and target accordingly predictor_cols = X . columns . to_list () target_col = config . target_col # Split train - test X_train , X_test , y_train , y_test = model_selection . train_test_split ( X , y , train_size = config . train_size , shuffle = True , stratify = y , random_state = config . seed , ) We confirm that we have stratified properly. We do observe that the distribution of targets in both y_train and y_test are similar. # Log and send a class proportion plot to wandb for both train and test set logger . info ( f \"Y Train Distribution is : { y_train . value_counts ( normalize = True ) . to_dict () } \" ) logger . info ( f \"Y Test Distribution is : { y_test . value_counts ( normalize = True ) . to_dict () } \" ) # wandb.sklearn.plot_class_proportions(y_train, y_test, labels=[0, 1]) 2021-11-13,09:53:22 - Y Train Distribution is : {0: 0.626953125, 1: 0.373046875} 2021-11-13,09:53:22 - Y Test Distribution is : {0: 0.631578947368421, 1: 0.3684210526315789} def make_folds ( df : pd . DataFrame , num_folds : int , cv_schema : str , seed : int , predictor_col : List , target_col : List , ) -> pd . DataFrame : \"\"\"Split the given dataframe into training folds. Args: df (pd.DataFrame): The dataframe to be split. num_folds (int): The number of folds to be created. cv_schema (str): The type of cross validation to be used. seed (int): The seed number to be used. Returns: df_folds (pd.DataFrame): The dataframe containing the folds. \"\"\" if cv_schema == \"KFold\" : df_folds = df . copy () kf = model_selection . KFold ( n_splits = num_folds , shuffle = True , random_state = seed ) for fold , ( train_idx , val_idx ) in enumerate ( kf . split ( X = df_folds [ predictor_col ], y = df_folds [ target_col ]) ): df_folds . loc [ val_idx , \"fold\" ] = int ( fold + 1 ) df_folds [ \"fold\" ] = df_folds [ \"fold\" ] . astype ( int ) elif cv_schema == \"StratifiedKFold\" : df_folds = df . copy () skf = model_selection . StratifiedKFold ( n_splits = num_folds , shuffle = True , random_state = seed ) for fold , ( train_idx , val_idx ) in enumerate ( skf . split ( X = df_folds [ predictor_col ], y = df_folds [ target_col ]) ): df_folds . loc [ val_idx , \"fold\" ] = int ( fold + 1 ) df_folds [ \"fold\" ] = df_folds [ \"fold\" ] . astype ( int ) print ( df_folds . groupby ([ \"fold\" , \"diagnosis\" ]) . size ()) return df_folds # Concat X_train and y_train to apply make_folds on it and return a new dataframe df_folds with # an additional column fold to indicate each sample's fold X_y_train = pd . concat ([ X_train , y_train ], axis = 1 ) . reset_index ( drop = True ) df_folds = make_folds ( X_y_train , num_folds = config . num_folds , cv_schema = config . cv_schema , seed = config . seed , predictor_col = predictor_cols , target_col = config . target_col , ) # TODO: write directly to GCP df_folds . to_csv ( \"df_folds.csv\" , index = False ) fold diagnosis 1 0 64 1 39 2 0 65 1 38 3 0 64 1 38 4 0 64 1 38 5 0 64 1 38 dtype: int64 Looks good! All our five folds are stratified!","title":"Modelling (Cross-Validation Schema)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%205%20-%20Modelling%20%28Cross-Validation%20Methodology%29/#dependencies-and-configuration","text":"import logging import random from dataclasses import dataclass , field from time import time from typing import Any , Callable , Dict , List , Optional , Union import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns from sklearn import model_selection @dataclass class config : raw_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/raw/data.csv\" processed_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/processed.csv\" train_size : float = 0.9 seed : int = 1992 num_folds : int = 5 cv_schema : str = \"StratifiedKFold\" classification_type : str = \"binary\" target_col : List [ str ] = field ( default_factory = lambda : [ \"diagnosis\" ]) unwanted_cols : List [ str ] = field ( default_factory = lambda : [ \"id\" , \"Unnamed: 32\" ]) # Plotting colors : List [ str ] = field ( default_factory = lambda : [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ]) cmap_reversed = plt . cm . get_cmap ( 'mako_r' ) def to_dict ( self ) -> Dict : \"\"\"Convert the config object to a dictionary. Returns: Dict: The config object as a dictionary. \"\"\" return { \"raw_data\" : self . raw_data , \"processed_data\" : self . processed_data , \"train_size\" : self . train_size , \"seed\" : self . seed , \"num_folds\" : self . num_folds , \"cv_schema\" : self . cv_schema , \"classification_type\" : self . classification_type , \"target_col\" : self . target_col , \"unwanted_cols\" : self . unwanted_cols , \"colors\" : self . colors , \"cmap_reversed\" : self . cmap_reversed } def set_seeds ( seed : int = 1234 ) -> None : \"\"\"Set seeds for reproducibility.\"\"\" np . random . seed ( seed ) random . seed ( seed ) def init_logger ( log_file : str = \"info.log\" ): \"\"\" Initialize logger. \"\"\" logger = logging . getLogger ( __name__ ) logger . setLevel ( logging . INFO ) stream_handler = logging . StreamHandler () stream_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) file_handler = logging . FileHandler ( filename = log_file ) file_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) logger . addHandler ( stream_handler ) logger . addHandler ( file_handler ) return logger config = config () logger = init_logger () # set seeding for reproducibility _ = set_seeds ( seed = config . seed ) # read data df = pd . read_csv ( config . processed_data )","title":"Dependencies and Configuration"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%205%20-%20Modelling%20%28Cross-Validation%20Methodology%29/#cross-validation-strategy","text":"Generalization Ultimately, we are interested in the Generalization Error made by the model, that is, how well the model perform on unseen data that is not taken from our sample set \\(\\mathcal{D}\\) . In general, we use validation set for Model Selection and the test set for an estimate of generalization error on new data. - Refactored from Elements of Statistical Learning, Chapter 7.2","title":"Cross-Validation Strategy"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%205%20-%20Modelling%20%28Cross-Validation%20Methodology%29/#step-1-train-test-split","text":"Since this dataset is relatively small, we will not use the train-validation-test split and only split into train and test in a ratio of 9:1, whereby the split is stratified on our target, using stratify=y parameter in train_test_split() to ensure that our target has equal representation in both train and test. We note that this is a relatively small dataset and in practice, we need a large sample size to get a reliable/stable split, it is also recommended to retrain the whole dataset (without the \"unseen\" test set) after we have done the model selection process (eg. finding best hyperparameters).","title":"Step 1: Train-Test-Split"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%205%20-%20Modelling%20%28Cross-Validation%20Methodology%29/#step-2-resampling-strategy","text":"Note that we will be performing StratifiedKFold as our resampling strategy. After our split in Step 1, we have a training set \\(X_{\\text{train}}\\) , we will then perform our resampling strategy on this \\(X_{\\text{train}}\\) . We will choose our choice of \\(K = 5\\) . The choice of \\(K\\) is somewhat arbitrary, and is derived empirically .","title":"Step 2: Resampling Strategy"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%205%20-%20Modelling%20%28Cross-Validation%20Methodology%29/#cross-validation-workflow","text":"To recap, we have the following: Training Set ( \\(X_{\\text{train}}\\) ) : This will be further split into K validation sets during our cross-validation. This set is used to fit a particular hypothesis \\(h \\in \\mathcal{H}\\) . Validation Set ( \\(X_{\\text{val}}\\) ) : This is split from our \\(X_{\\text{train}}\\) during cross-validation. This set is used for model selection (i.e. find best hyperparameters, attempt to produce a best hypothesis \\(g \\in \\mathcal{H}\\) ). Test Set ( \\(X_{\\text{test}}\\) ) : This is an unseen test set, and we will only use it after we finish tuning our model/hypothesis. Suppose we have a final best model \\(g\\) , we will use \\(g\\) to predict on the test set to get an estimate of the generalization error (also called out-of-sample error). Courtesy of scikit-learn on a typical Cross-Validation workflow. # Make a copy of df and assign it to X X = df . copy () # Pop diagnosis, the target column from X and assign the target column data to y y = X . pop ( \"diagnosis\" ) # Assign predictors and target accordingly predictor_cols = X . columns . to_list () target_col = config . target_col # Split train - test X_train , X_test , y_train , y_test = model_selection . train_test_split ( X , y , train_size = config . train_size , shuffle = True , stratify = y , random_state = config . seed , ) We confirm that we have stratified properly. We do observe that the distribution of targets in both y_train and y_test are similar. # Log and send a class proportion plot to wandb for both train and test set logger . info ( f \"Y Train Distribution is : { y_train . value_counts ( normalize = True ) . to_dict () } \" ) logger . info ( f \"Y Test Distribution is : { y_test . value_counts ( normalize = True ) . to_dict () } \" ) # wandb.sklearn.plot_class_proportions(y_train, y_test, labels=[0, 1]) 2021-11-13,09:53:22 - Y Train Distribution is : {0: 0.626953125, 1: 0.373046875} 2021-11-13,09:53:22 - Y Test Distribution is : {0: 0.631578947368421, 1: 0.3684210526315789} def make_folds ( df : pd . DataFrame , num_folds : int , cv_schema : str , seed : int , predictor_col : List , target_col : List , ) -> pd . DataFrame : \"\"\"Split the given dataframe into training folds. Args: df (pd.DataFrame): The dataframe to be split. num_folds (int): The number of folds to be created. cv_schema (str): The type of cross validation to be used. seed (int): The seed number to be used. Returns: df_folds (pd.DataFrame): The dataframe containing the folds. \"\"\" if cv_schema == \"KFold\" : df_folds = df . copy () kf = model_selection . KFold ( n_splits = num_folds , shuffle = True , random_state = seed ) for fold , ( train_idx , val_idx ) in enumerate ( kf . split ( X = df_folds [ predictor_col ], y = df_folds [ target_col ]) ): df_folds . loc [ val_idx , \"fold\" ] = int ( fold + 1 ) df_folds [ \"fold\" ] = df_folds [ \"fold\" ] . astype ( int ) elif cv_schema == \"StratifiedKFold\" : df_folds = df . copy () skf = model_selection . StratifiedKFold ( n_splits = num_folds , shuffle = True , random_state = seed ) for fold , ( train_idx , val_idx ) in enumerate ( skf . split ( X = df_folds [ predictor_col ], y = df_folds [ target_col ]) ): df_folds . loc [ val_idx , \"fold\" ] = int ( fold + 1 ) df_folds [ \"fold\" ] = df_folds [ \"fold\" ] . astype ( int ) print ( df_folds . groupby ([ \"fold\" , \"diagnosis\" ]) . size ()) return df_folds # Concat X_train and y_train to apply make_folds on it and return a new dataframe df_folds with # an additional column fold to indicate each sample's fold X_y_train = pd . concat ([ X_train , y_train ], axis = 1 ) . reset_index ( drop = True ) df_folds = make_folds ( X_y_train , num_folds = config . num_folds , cv_schema = config . cv_schema , seed = config . seed , predictor_col = predictor_cols , target_col = config . target_col , ) # TODO: write directly to GCP df_folds . to_csv ( \"df_folds.csv\" , index = False ) fold diagnosis 1 0 64 1 39 2 0 65 1 38 3 0 64 1 38 4 0 64 1 38 5 0 64 1 38 dtype: int64 Looks good! All our five folds are stratified!","title":"Cross-Validation Workflow"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%206%20-%20Modelling%20%28Preprocessing%20and%20Spot%20Checking%29/","text":"Stage 6: Spot Checking Algorithms by Hongnan Gao Dependencies and Configuration # !pip install gcloud == 0.18.3 ! pip install - q mlxtend == 0.19.0 ! pip install - q statsmodels == 0.13.1 import copy import csv import logging import random from dataclasses import dataclass , field from functools import wraps from time import time from typing import Any , Callable , Dict , List , Optional , Union , Tuple import matplotlib.pyplot as plt import mlxtend import numpy as np import pandas as pd import seaborn as sns from mlxtend.evaluate import bias_variance_decomp , paired_ttest_5x2cv from scipy import stats from sklearn import ( base , decomposition , dummy , ensemble , feature_selection , linear_model , metrics , model_selection , neighbors , pipeline , preprocessing , svm , tree ) from statsmodels.regression.linear_model import OLS \u001b[K |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.3 MB 5.2 MB/s \u001b[K |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9.8 MB 1.3 MB/s \u001b[?25h @dataclass class config : raw_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/raw/data.csv\" processed_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/processed.csv\" df_folds : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/df_folds.csv\" train_size : float = 0.9 seed : int = 1992 num_folds : int = 5 cv_schema : str = \"StratifiedKFold\" classification_type : str = \"binary\" target_col : List [ str ] = field ( default_factory = lambda : [ \"diagnosis\" ]) unwanted_cols : List [ str ] = field ( default_factory = lambda : [ \"id\" , \"Unnamed: 32\" ]) # Plotting colors : List [ str ] = field ( default_factory = lambda : [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ]) cmap_reversed = plt . cm . get_cmap ( 'mako_r' ) def to_dict ( self ) -> Dict : \"\"\"Convert the config object to a dictionary. Returns: Dict: The config object as a dictionary. \"\"\" return { \"raw_data\" : self . raw_data , \"processed_data\" : self . processed_data , \"train_size\" : self . train_size , \"seed\" : self . seed , \"num_folds\" : self . num_folds , \"cv_schema\" : self . cv_schema , \"classification_type\" : self . classification_type , \"target_col\" : self . target_col , \"unwanted_cols\" : self . unwanted_cols , \"colors\" : self . colors , \"cmap_reversed\" : self . cmap_reversed } # spot_checking_boxplot = \"../data/images/spot_checking_boxplot.png\" # oof_confusion_matrix = \"../data/images/oof_confusion_matrix.png\" # final_train_confusion_matrix = \"../data/images/final_train_confusion_matrix.png\" # precision_recall_threshold_plot = \"../data/images/precision_recall_threshold_plot.png\" # roc_plot = \"../data/images/roc_plot.png\" # feature_importance = \"../data/images/feature_importance.png\" def set_seeds ( seed : int = 1234 ) -> None : \"\"\"Set seeds for reproducibility.\"\"\" np . random . seed ( seed ) random . seed ( seed ) def init_logger ( log_file : str = \"info.log\" ): \"\"\" Initialize logger. \"\"\" logger = logging . getLogger ( __name__ ) logger . setLevel ( logging . INFO ) stream_handler = logging . StreamHandler () stream_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) file_handler = logging . FileHandler ( filename = log_file ) file_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) logger . addHandler ( stream_handler ) logger . addHandler ( file_handler ) return logger # Utils functions that we need def variance_inflation_factor ( exog , idx_kept , vif_idx ): \"\"\"Compute VIF for one feature. Args: exog (np.ndarray): Observations idx_kept (List[int]): Indices of features to consider vif_idx (int): Index of feature for which to compute VIF Returns: float: VIF for the selected feature \"\"\" exog = np . asarray ( exog ) x_i = exog [:, vif_idx ] mask = [ col for col in idx_kept if col != vif_idx ] x_noti = exog [:, mask ] r_squared_i = OLS ( x_i , x_noti ) . fit () . rsquared vif = 1. / ( 1. - r_squared_i ) return vif class ReduceVIF ( base . BaseEstimator , base . TransformerMixin ): \"\"\"The base of the class structure is implemented in https://www.kaggle.com/ffisegydd/sklearn-multicollinearity-class; I heavily modified the class such that it can take in numpy arrays and correctly implemented the fit and transform method. \"\"\" def __init__ ( self , thresh = 10 , max_drop = 20 ): self . thresh = thresh self . max_drop = max_drop self . column_indices_kept_ = [] self . feature_names_kept_ = None def reset ( self ): \"\"\"Resets the state of predictor columns after each fold.\"\"\" self . column_indices_kept_ = [] self . feature_names_kept_ = None def fit ( self , X , y = None ): \"\"\"Fits the Recursive VIF on the training folds and save the selected feature names in self.feature_names Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" self . column_indices_kept_ , self . feature_names_kept_ = self . calculate_vif ( X ) return self def transform ( self , X , y = None ): \"\"\"Transforms the Validation Set according to the selected feature names. Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" return X [:, self . column_indices_kept_ ] def calculate_vif ( self , X : Union [ np . ndarray , pd . DataFrame ]): \"\"\"Implements a VIF function that recursively eliminates features. Args: X (Union[np.ndarray, pd.DataFrame]): [description] Returns: [type]: [description] \"\"\" feature_names = None column_indices_kept = list ( range ( X . shape [ 1 ])) if isinstance ( X , pd . DataFrame ): feature_names = X . columns dropped = True count = 0 while dropped and count <= self . max_drop : dropped = False max_vif , max_vif_col = None , None for col in column_indices_kept : vif = variance_inflation_factor ( X , column_indices_kept , col ) if max_vif is None or vif > max_vif : max_vif = vif max_vif_col = col if max_vif > self . thresh : # print(f\"Dropping {max_vif_col} with vif={max_vif}\") column_indices_kept . remove ( max_vif_col ) if feature_names is not None : feature_names . pop ( max_vif_col ) dropped = True count += 1 return column_indices_kept , feature_names config = config () logger = init_logger () # set seeding for reproducibility _ = set_seeds ( seed = config . seed ) # read data df_folds = pd . read_csv ( config . df_folds ) # Assign predictors and target accordingly predictor_cols = df_folds . columns . to_list ()[: - 2 ] target_col = config . target_col Spot Checking Algorithms Terminology Alert! This method is advocated by Jason Brownlee PhD and this serves as the first stage of my modelling process. We will rapidly test (spot check) different classifier algorithms, from DummyClassifier , to LinearModel to more sophisticated ensemble trees like RandomForest . I also note to the readers that we need to think of a few things when choosing the \"optimal\" machine learning algorithm: No Lunch Free Theorem intuitively says that no single optimization algorithm can work best in all situations. Therefore, spot checking can help us form a basis of which algorithm might work better in this particular scenario. Occam's Razor often appears in many Machine Learning textbook, and the narrative is that a simpler model more often times generalizes better than a complex model. This is not unfamiliar when we think of the bias-variance tradeoff, and that is why there is always a tradeoff that we must make. Say No to Data Leakage! Say No to Data Leakage: This has been emphasized throughout and we must be careful as we should never touch the test set when fitting the model. In fact, we should try our best to not contaminate our validation set as well. This means that preprocessing steps such as StandardScaling() should only be fitted on the training data, and then apply the same transformation (mean and std) on the test data. In other words, do not apply scaling on the whole dataset before splitting. However, it is also equally important to take note not to contaminate our validation set, which is often overlooked, resulting in over optimistic results from model selection phase, but perform badly on unseen test set. As a result, when we use a 5 fold cross validation, we should be careful during fitting that the preprocessing steps are only applied on the training folds, and not on all 5 folds. The same idea is also applied to our ReduceVIF() preprocessing step. We should also include this in our pipeline and not select the features outside the cross-validation loop. Quoting from scikit-learn : Data leakage occurs when information that would not be available at prediction time is used when building the model. This results in overly optimistic performance estimates, for example from cross-validation , and thus poorer performance when the model is used on actually novel data, for example during production. A common cause is not keeping the test and train data subsets separate. Test data should never be used to make choices about the model. The general rule is to never call fit on the test data. While this may sound obvious, this is easy to miss in some cases, for example when applying certain pre-processing steps. Although both train and test data subsets should receive the same preprocessing transformation (as described in the previous section), it is important that these transformations are only learnt from the training data. For example, if you have a normalization step where you divide by the average value, the average should be the average of the train subset, not the average of all the data. If the test subset is included in the average calculation, information from the test subset is influencing the model. How to avoid Data Leakage? We know the pitfalls of fitting on validation/test data, the natural question is how can we avoid it completely? You can code it up yourself, but as a starter, we can use scikit-learn's Pipeline object. My tips are as follows: Any preprocessing step must be done after splitting the whole dataset into train and test. If you are also using cross-validation, then we should only apply the preprocessing steps on the train set, and then use the metrics obtained from the train set to transform the validation set. You can see my pseudo-code below for a rough outline. The Pipeline object of Scikit-Learn can help prevent data leakage. Pseudo-Code of Cross-Validation and Pipeline The below outlines a pseudo code of the cross-validation scheme using Pipeline object. Note that I included the most outer loop, which is searching for hyperparameters. Define \\(G\\) as the set of combination of hyperparamters. Define number of splits to be \\(K\\) . For each set of hyperparameter \\(z \\in Z\\) : for fold \\(j\\) in K: Set \\(F_{\\text{train}}=\\bigcup\\limits_{i\\neq k}^{K} F_{i}\\) Set \\(F_{\\text{val}} = F_{j}\\) as the validation set Perform Standard Scaling on \\(F_{\\text{train}}\\) and find the mean and std Perform VIF recursively on \\(F_{\\text{train}}\\) and find the selected features Transform \\(F_{\\text{val}}\\) using the mean and std found using \\(F_{\\text{train}}\\) Transform \\(F_{\\text{val}}\\) to have only the selected features from \\(F_{\\text{train}}\\) Train and fit on \\(F_{\\text{train}}\\) Evaluate the fitted parameters on \\(F_{\\text{val}}\\) to obtain \\(\\mathcal{M}\\) Training Pipeline Make Pipeline # @ TODO: https://www.kaggle.com/kabure/predicting-house-prices-xgb-rf-bagging-reg-pipe # Different models can potentially have different pre-processing steps, consider putting steps as a # passable list. def make_pipeline ( model : Callable ) -> Callable : \"\"\"Create a feature preparation pipeline for a model. Args: model (Callable): The model to be used. Returns: _pipeline (Callable): pipeline object \"\"\" # Create a list of steps, note that some models may not need certain steps, and hence # may need an if-else here steps = list () # standardization steps . append (( \"standardize\" , preprocessing . StandardScaler ())) # reduce VIF steps . append (( \"remove_multicollinearity\" , ReduceVIF ( thresh = 10 ))) # the model to be appended at the last step steps . append (( \"model\" , model )) # create pipeline _pipeline = pipeline . Pipeline ( steps = steps ) return _pipeline classifiers = [ # baseline model dummy . DummyClassifier ( random_state = config . seed , strategy = \"stratified\" ), # linear model linear_model . LogisticRegression ( random_state = config . seed , solver = \"liblinear\" ), # nearest neighbours neighbors . KNeighborsClassifier ( n_neighbors = 8 ), # SVM svm . SVC ( probability = True , random_state = config . seed ), # tree tree . DecisionTreeClassifier ( random_state = config . seed ), # ensemble ensemble . RandomForestClassifier ( n_estimators = 10 , random_state = config . seed ), ] classifiers = [ make_pipeline ( model ) for model in classifiers ] Results Class The Results class will help us store model's results. Careful when using ROC function! We also note that when passing arguments to scikit-learn's roc_auc_score function, we should be careful not to pass y_score=model.predict(X) inside as we have to understand that we are passing in non-thresholded probabilities into y_score . If you pass the predicted values (full of 0 and 1s), then you are thresholding on 0 and 1 only, which is incorrect by definition. default_result_names = [ \"y_true\" , \"y_pred\" , \"y_prob\" ] default_logit_names = [ \"y_true\" , \"y_pred\" , \"y_prob\" ] default_score_names = [ \"accuracy_score\" , \"precision_recall_fscore_support\" , \"confusion_matrix\" , # \"average_precision_score\", \"multiclass_roc_auc_score\" , \"brier_score_loss\" , ] custom_score_names = [ \"multiclass_roc_auc_score\" , \"brier_score_loss\" ] use_preds = [ \"accuracy_score\" , \"precision_recall_fscore_support\" , \"confusion_matrix\" , ] use_probs = [ \"average_precision_score\" ] class Results : \"\"\"Stores results for model training in columnwise format.\"\"\" _result_dict : Dict logit_names : List [ str ] score_names : List [ str ] def __init__ ( self , logit_names : List [ str ] = default_logit_names , score_names : List [ str ] = default_score_names , existing_dict : Optional [ Dict ] = None , ): \"\"\"Construct a new results store.\"\"\" self . logit_names = logit_names self . score_names = score_names if existing_dict is not None : self . _result_dict = copy . deepcopy ( existing_dict ) return dict_keys = [ \"identifier\" , * logit_names , * score_names ] self . _result_dict = { key : [] for key in dict_keys } def add ( self , identifier : str , results : Dict , in_place = False ): \"\"\"Add a new results row.\"\"\" if not in_place : return Results ( self . logit_names , self . score_names , self . _result_dict ) . add ( identifier , results , in_place = True ) self . _result_dict [ \"identifier\" ] . append ( identifier ) for result_name in set ([ * results . keys (), * self . logit_names , * self . score_names ]): result_value = results . get ( result_name , np . nan ) self . _result_dict [ result_name ] . append ( result_value ) return self def get_result ( self , result_name : str ) -> Dict [ str , Any ]: \"\"\"Get a map of identifiers to result values for a result.\"\"\" return { identifier : result_value for identifier , result_value in zip ( self . _result_dict [ \"identifier\" ], self . _result_dict [ result_name ]) } def get_result_values ( self , result_name : str ) -> List [ Any ]: \"\"\"Get a list of values for a result.\"\"\" return self . _result_dict [ result_name ] def to_dataframe ( self ) -> pd . DataFrame : \"\"\"Get a Data Frame containing the results.\"\"\" return pd . DataFrame . from_dict ( self . _result_dict ) def to_dict ( self ) -> Dict : \"\"\"Get a dictionary containing the results. Returns: Dict[str, List[Any]]: Dictionary of result columns \"\"\" return self . _result_dict def multiclass_label_binarize ( y : np . ndarray , class_labels : List [ int ], pos_label = 1 , neg_label = 0 ): \"\"\"Binarize labels in one-vs-all fashion. # TODO: to replace with the above vstack method. Args: y (np.ndarray) Sequence of integer labels to encode class_labels (array-like) Labels for each class pos_label (int) Value for positive labels neg_label (int) Value for negative labels Returns: np.ndarray of shape (n_samples, n_classes) Encoded dataset \"\"\" if isinstance ( y , list ): y = np . asarray ( y ) columns = [ np . where ( y == label , pos_label , neg_label ) for label in class_labels ] return np . column_stack ( columns ) def multiclass_roc_auc_score ( y_true , y_score , classes = None ): \"\"\"Compute ROC-AUC score for each class in a multiclass dataset. Args: y_true (np.ndarray of shape (n_samples, n_classes)) True labels y_score (np.ndarray of shape (n_samples, n_classes)) Target scores classes (array-like of shape (n_classes,)) List of dataset classes. If `None`, the lexicographical order of the labels in `y_true` is used. Returns: array-like: ROC-AUC score for each class, in the same order as `classes` \"\"\" classes = ( np . unique ( y_true ) if classes is None else classes ) y_true_multiclass = multiclass_label_binarize ( y_true , class_labels = classes ) def oneclass_roc_auc_score ( class_id ): y_true_class = y_true_multiclass [:, class_id ] y_score_class = y_score [:, class_id ] fpr , tpr , _ = metrics . roc_curve ( y_true = y_true_class , y_score = y_score_class , pos_label = 1 ) return metrics . auc ( fpr , tpr ) return [ oneclass_roc_auc_score ( class_id ) for class_id in range ( len ( classes )) ] Utilities Some utility functions to prepare data and post-process data. def prepare_y ( y : np . ndarray ) -> np . ndarray : \"\"\"Prepare the target variable for the model. If Binary Classification, we need to ravel the array to 1d. Args: y (np.ndarray): Target variable. Returns: np.ndarray: Transformed Target variable. \"\"\" return y . ravel () if config . classification_type == \"binary\" else y def mean_score ( score_values ) -> Union [ float , np . ndarray ]: \"\"\"Compute the mean score.\"\"\" score_values = np . array ( score_values ) shape = score_values . shape if len ( shape ) == 1 : return score_values . mean () return score_values . mean ( axis = 0 ) def mean_cv_results ( model_results : Results ) -> Dict : \"\"\"Add mean cross-validation results. This method computes the mean value for all score types in the model_results, including for scores (e.g., confusion matrix) where the mean value may contain decimal places. \"\"\" cv_logits = { y_result : np . concatenate ( model_results . get_result_values ( y_result )) for y_result in model_results . logit_names } cv_scores = { score : mean_score ( model_results . get_result_values ( score ) ) for score in model_results . score_names } return { ** cv_logits , ** cv_scores , } def oof_cv_results ( model_results : Results ) -> Dict : \"\"\"Add OOF cross-validation results.\"\"\" cv_logits = { y_result : np . concatenate ( model_results . get_result_values ( y_result ) ) for y_result in model_results . logit_names } cv_scores = compute_metrics ( cv_logits ) return { ** cv_logits , ** cv_scores , } def add_cv_results ( model_results : Results ): \"\"\"Add cross-validation results. This method returns a copy of the given model results with summary columns for mean and CV cross-validation. \"\"\" mean_cv = mean_cv_results ( model_results ) oof_cv = oof_cv_results ( model_results ) return ( model_results . add ( \"mean_cv\" , mean_cv ) . add ( \"oof_cv\" , oof_cv ) ) def compute_metrics ( logits : Dict [ str , np . ndarray ]) -> Dict [ str , Any ]: \"\"\"Compute metrics from logits. use_probs: all metrics that use probabilities. use_preds: all metrics that use thresholded predictions. # TODO add this precision, recall, fbeta_score, _ = metrics.precision_recall_fscore_support( y_true=y_val, y_pred = y_val_pred, labels=np.unique(y_val), average=None ) \"\"\" y_true , y_pred , y_prob = ( logits [ \"y_true\" ], logits [ \"y_pred\" ], logits [ \"y_prob\" ], ) use_preds = [ \"accuracy_score\" , \"precision_recall_fscore_support\" , \"confusion_matrix\" , ] use_probs = [ \"average_precision_score\" ] default_metrics_dict : Dict [ str , float ] = {} custom_metrics_dict : Dict [ str , float ] = {} for metric_name in default_score_names : if hasattr ( metrics , metric_name ): # TODO: get metric score with default parameters, consider adding kwargs if you want to configure parameters if metric_name in use_preds : metric_score = getattr ( metrics , metric_name )( y_true , y_pred ) elif metric_name in use_probs : # logger.info(\"TODO: write custom scores for precision-recall as here is hardcoded\") pass # metric_score = getattr(metrics, metric_name)( # y_true, y_prob # ) else : # add custom metrics here multiclass_roc_auc = multiclass_roc_auc_score ( y_true , y_prob ) brier_score_loss = ( metrics . brier_score_loss ( y_true = y_true , y_prob = y_prob [:, 1 ]) if config . classification_type == \"binary\" else np . nan ) custom_metrics_dict [ \"multiclass_roc_auc_score\" ] = multiclass_roc_auc custom_metrics_dict [ \"brier_score_loss\" ] = brier_score_loss if metric_name not in default_metrics_dict : default_metrics_dict [ metric_name ] = metric_score metrics_dict = { ** default_metrics_dict , ** custom_metrics_dict } return metrics_dict def train_on_fold ( df_folds : pd . DataFrame , models : List [ Callable ], num_folds : int , predictor_col : List [ str ], target_col : List [ str ], ) -> Dict [ str , List ]: \"\"\"Take in a dataframe with fold number as column, and a models which holds a list of callable models, we will loop through and return a dictionary of cv results. Args: df_folds (pd.DataFrame): Dataframe with fold number as column. model (Callable): A callable model. num_folds (int): Number of folds. predictor_col (List[str]): List of predictor columns. target_col (List[str]): List of target columns. Returns: model_dict (Dict[str, Results]: Dictionary of model results with model name as key. \"\"\" y_true = df_folds [ target_col ] . values . flatten () # test_pred_arr: np.ndarray = np.zeros(len(X_test)) model_dict = {} for model in models : model_results = Results () if isinstance ( model , pipeline . Pipeline ): model_name = model [ \"model\" ] . __class__ . __name__ else : model_name = model . __class__ . __name__ # out-of-fold validation predictions oof_pred_arr : np . ndarray = np . zeros ( len ( df_folds )) for fold in range ( 1 , num_folds + 1 ): train_df = df_folds [ df_folds [ \"fold\" ] != fold ] . reset_index ( drop = True ) val_df = df_folds [ df_folds [ \"fold\" ] == fold ] . reset_index ( drop = True ) val_idx = df_folds [ df_folds [ \"fold\" ] == fold ] . index . values X_train , y_train = train_df [ predictor_col ] . values , prepare_y ( train_df [ target_col ] . values ) X_val , y_val = val_df [ predictor_col ] . values , prepare_y ( val_df [ target_col ] . values ) model . fit ( X_train , y_train ) y_val_pred = model . predict ( X_val ) y_val_prob = model . predict_proba ( X_val ) logits = { \"y_true\" : y_val , \"y_pred\" : y_val_pred , \"y_prob\" : y_val_prob , } metrics = compute_metrics ( logits ) model_results . add ( f \"fold { fold } \" , { ** logits , ** metrics }, in_place = True ) if model_name not in model_dict : model_dict [ model_name ] = model_results return model_dict # Returns a dict in the format of # {'LogisticRegression': <__main__.Results at 0x7f3bca575e90>} model_dict = train_on_fold ( df_folds , models = classifiers , num_folds = 5 , predictor_col = predictor_cols , target_col = config . target_col ) # Takes in a model_dict and add cv results to the dict model_dict_with_summary = { model : add_cv_results ( model_results ) for model , model_results in model_dict . items () } # Transforms model_dict_with_summary to a Dict of dataframes # model_results_df['LogisticRegression'] -> df model_results_df = { name : results . to_dataframe () . T for name , results in model_dict_with_summary . items () } results_df = pd . concat ( model_results_df , axis = 0 ) results_df . columns = [ 'fold 1' , 'fold 2' , 'fold 3' , 'fold 4' , 'fold 5' , 'mean_cv' , 'oof_cv' ] results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } fold 1 fold 2 fold 3 fold 4 fold 5 mean_cv oof_cv RandomForestClassifier accuracy_score 0.932039 0.961165 0.95098 0.960784 0.95098 0.95119 0.951172 precision_recall_fscore_support ([0.9672131147540983, 0.8809523809523809], [0.... ([0.9552238805970149, 0.9722222222222222], [0.... ([0.927536231884058, 1.0], [1.0, 0.86842105263... ([0.9545454545454546, 0.9722222222222222], [0.... ([0.9402985074626866, 0.9714285714285714], [0.... [[0.9489634378486625, 0.9593650793650793], [0.... ([0.9484848484848485, 0.9560439560439561], [0.... confusion_matrix [[59, 5], [2, 37]] [[64, 1], [3, 35]] [[64, 0], [5, 33]] [[63, 1], [3, 35]] [[63, 1], [4, 34]] [[62.6, 1.6], [3.4, 34.8]] [[313, 8], [17, 174]] multiclass_roc_auc_score [0.9709535256410255, 0.9709535256410255] [0.9896761133603239, 0.9896761133603239] [0.9967105263157895, 0.9967105263157895] [0.9930098684210527, 0.9930098684210527] [0.9802631578947368, 0.980263157894737] [0.9861226383265856, 0.9861226383265856] [0.9849374500497463, 0.9849374500497464] brier_score_loss 0.0594175 0.0415534 0.0376471 0.0347059 0.0413725 0.0429393 0.0429688 Comparison of Cross-Validated Models (CV + OOF) The point of the following comparison is to check how different models are performing across folds. More specifically, if we have 5 folds, we will have a metric score for each fold, subsequently, we can find the standard error of model's performance. We need to be aware of models that have high variance across folds in terms of the metrics performance. This can indicate that the model is highly unstable, and may be a sign of overfitting. def summarize_metrics ( model_dict : Dict [ str , Results ], metric_name : str = \"roc\" , pos_label : int = 1 ): \"\"\" Summarize metrics of each fold with its standard error. We also plot a boxplot to show the results. \"\"\" results = [] for model_name , model_results in model_dict . items (): result_dict = model_results . get_result ( result_name = metric_name ) tmp_score = [] for fold , metric in result_dict . items (): pos_class_score = metric [ pos_label ] results . append (( model_name , fold , pos_class_score )) tmp_score . append ( pos_class_score ) # append the Standard Error of K folds results . append ( ( model_name , \"SE\" , np . std ( tmp_score , ddof = 1 ) / len ( tmp_score ) ** 0.5 ) ) summary_df = pd . DataFrame ( results , columns = [ \"model\" , \"fold\" , metric_name ]) fig , ax = plt . subplots ( figsize = ( 15 , 8 )) _ = sns . boxplot ( x = \"model\" , y = metric_name , data = summary_df [ ( summary_df [ \"model\" ] != \"DummyClassifier\" ) & ( summary_df [ \"fold\" ] != \"SE\" ) ], ax = ax , ) # fig.savefig(config.spot_checking_boxplot, format='png', dpi=300) return summary_df summary_df = summarize_metrics ( model_dict = model_dict , metric_name = \"multiclass_roc_auc_score\" ) display ( summary_df . tail ( 12 )) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } model fold multiclass_roc_auc_score 24 DecisionTreeClassifier fold 1 0.865585 25 DecisionTreeClassifier fold 2 0.924291 26 DecisionTreeClassifier fold 3 0.923931 27 DecisionTreeClassifier fold 4 0.923931 28 DecisionTreeClassifier fold 5 0.895148 29 DecisionTreeClassifier SE 0.011677 30 RandomForestClassifier fold 1 0.970954 31 RandomForestClassifier fold 2 0.989676 32 RandomForestClassifier fold 3 0.996711 33 RandomForestClassifier fold 4 0.993010 34 RandomForestClassifier fold 5 0.980263 35 RandomForestClassifier SE 0.004672 Out-of-Fold Confusion Matrix We do have information on the performance of each folds, we now look at the performance of all 5 folds together. Typicall there are two ways to do it, one is to simply take the average of the score of five folds, the other is to take a look at out of folds predictions. From the confusion matrix of the out of fold performance, Logistic Regression does seem to be a model we can explore on, although slightly lower in terms of overall AUROC score than SVC, it seems to have the quite low False Negatives amongst all. With further hyperparameter tuning and threshold optimization, we can make it better. model_names = [ model for model in model_dict . keys ()] def plot_binary_confusion_matrix ( results_df : pd . DataFrame , model_names : List [ str ] ) -> None : n_models = len ( model_names ) # if 7 models, then 3 rows, 2 columns, and 7 subplots # always fix column to be 3 n_cols = 3 n_rows = int ( np . ceil ( n_models / n_cols )) fig , ax = plt . subplots ( n_rows , n_cols , figsize = ( 10 , 10 )) for axes , algo in zip ( ax . ravel (), model_names ): # Unravel into tn, fp, fn and tp tn , fp , fn , tp = results_df . oof_cv [ algo ] . confusion_matrix . ravel () # reshape into tp, fp, fn, tn - this is personal preference reshaped_cm = np . asarray ([[ tp , fp ], [ fn , tn ]]) # Get positive ROC score - hardcoded here. positive_class_auroc = results_df . oof_cv [ algo ] . multiclass_roc_auc_score [ 1 ] # annotations labels = [ \"True Pos\" , \"False Pos\" , \"False Neg\" , \"True Neg\" ] counts = [ \" {0:0.0f} \" . format ( value ) for value in reshaped_cm . flatten ()] percentages = [ \" {0:.2%} \" . format ( value ) for value in reshaped_cm . flatten () / np . sum ( reshaped_cm ) ] # final annotations label = ( np . array ( [ f \" { v1 } \\n { v2 } \\n { v3 } \" for v1 , v2 , v3 in zip ( labels , counts , percentages )] ) ) . reshape ( 2 , 2 ) # heatmap sns . heatmap ( data = reshaped_cm , vmin = 0 , vmax = 330 , cmap = [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ], linewidth = 2 , linecolor = \"white\" , square = True , ax = axes , annot = label , fmt = \"\" , cbar = False , annot_kws = { \"size\" : 10 , \"color\" : \"black\" , \"weight\" : \"bold\" , \"alpha\" : 0.8 }, alpha = 1 , ) axes . text ( 0 , - 0 , \" {} \" . format ( algo ), { \"size\" : 12 , \"color\" : \"black\" , \"weight\" : \"bold\" } ) axes . scatter ( 1 , 1 , s = 3500 , c = \"white\" ) axes . text ( 0.72 , 1.0 , \"AUC: {} \" . format ( np . round ( positive_class_auroc , 3 )), { \"size\" : 10 , \"color\" : \"black\" , \"weight\" : \"bold\" }, ) ## ticks and labels axes . set_xticklabels ( \"\" ) axes . set_yticklabels ( \"\" ) ## titles and text fig . text ( 0 , 1.05 , \"Out Of Fold Confusion Matrix\" , { \"size\" : 22 , \"weight\" : \"bold\" }, alpha = 1 ) fig . text ( 0 , 1 , \"\"\"This Visualization show the results of various classifiers and there respective results.\"\"\" , { \"size\" : 14 , \"weight\" : \"normal\" }, alpha = 0.98 , ) fig . tight_layout ( pad = 2.5 , w_pad = 2.5 , h_pad = 2.5 ) # fig.savefig(config.oof_confusion_matrix, format='png', dpi=300) plot_binary_confusion_matrix ( results_df , model_names ) Hypothesis Testing Across Models I am slightly shocked at the performance of plain LogisticRegression, I decide to use an idea from Hypothesis Testing Across Models to check if the difference is really by chance or not. Note that I will be modifying his code as his code does not split using StratifiedKFold. The basic idea is to test if two model's difference in scores (in this case roc), is statistically significant or not. However, we note that this method may violate an assumption of Student's t test. Null Hypothesis \\(H_0\\) : The difference in the performance score of two classifiers is Statistically Significant. Alternate Hypothesis \\(H_1\\) : The difference in the performance score of two classifiers is not Statistically Significant. def paired_ttest_skfold_cv ( estimator1 : Callable , estimator2 : Callable , X : np . ndarray , y : np . ndarray , cv : int = 10 , scoring : str = None , shuffle : bool = False , random_seed : int = None , ) -> float : \"\"\"Modified from https://github.com/rasbt/mlxtend/blob/master/mlxtend/evaluate/ttest.py to accomodate StratifiedKFold. Args: estimator1 (Callable): [description] estimator2 (Callable): [description] X (np.ndarray): [description] y (np.ndarray): [description] cv (int, optional): [description]. Defaults to 10. scoring (str, optional): [description]. Defaults to None. shuffle (bool, optional): [description]. Defaults to False. random_seed (int, optional): [description]. Defaults to None. Raises: AttributeError: [description] Returns: float: [description] \"\"\" if not shuffle : skf = model_selection . StratifiedKFold ( n_splits = cv , shuffle = shuffle ) else : skf = model_selection . StratifiedKFold ( n_splits = cv , random_state = random_seed , shuffle = shuffle ) if scoring is None : if estimator1 . _estimator_type == \"classifier\" : scoring = \"accuracy\" elif estimator1 . _estimator_type == \"regressor\" : scoring = \"r2\" else : raise AttributeError ( \"Estimator must \" \"be a Classifier or Regressor.\" ) if isinstance ( scoring , str ): scorer = metrics . get_scorer ( scoring ) else : scorer = scoring score_diff = [] for train_index , test_index in skf . split ( X = X , y = y ): X_train , X_test = X [ train_index ], X [ test_index ] y_train , y_test = y [ train_index ], y [ test_index ] estimator1 . fit ( X_train , y_train ) estimator2 . fit ( X_train , y_train ) est1_score = scorer ( estimator1 , X_test , y_test ) est2_score = scorer ( estimator2 , X_test , y_test ) score_diff . append ( est1_score - est2_score ) avg_diff = np . mean ( score_diff ) numerator = avg_diff * np . sqrt ( cv ) denominator = np . sqrt ( sum ([( diff - avg_diff ) ** 2 for diff in score_diff ]) / ( cv - 1 ) ) t_stat = numerator / denominator pvalue = stats . t . sf ( np . abs ( t_stat ), cv - 1 ) * 2.0 return float ( t_stat ), float ( pvalue ) # check if difference between algorithms is real X_tmp = df_folds [ predictor_cols ] . values y_tmp = df_folds [ 'diagnosis' ] . values t , p = paired_ttest_skfold_cv ( estimator1 = classifiers [ 1 ], estimator2 = classifiers [ - 1 ], shuffle = True , cv = 5 , X = X_tmp , y = y_tmp , scoring = 'roc_auc' , random_seed = config . seed ) logger . info ( 'P-value: %.3f , t-Statistic: %.3f ' % ( p , t )) 2021-11-13,14:04:35 - P-value: 0.171, t-Statistic: 1.667 2021-11-13,14:04:35 - P-value: 0.171, t-Statistic: 1.667 Since \\(p\\) -value is quite high, and more the basic threshold of 0.05 or 0.1, we fail to reject the null hypothesis, and say that there is no significant difference between these two models.","title":"Modelling (Preprocessing and Spot Checking)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%206%20-%20Modelling%20%28Preprocessing%20and%20Spot%20Checking%29/#dependencies-and-configuration","text":"# !pip install gcloud == 0.18.3 ! pip install - q mlxtend == 0.19.0 ! pip install - q statsmodels == 0.13.1 import copy import csv import logging import random from dataclasses import dataclass , field from functools import wraps from time import time from typing import Any , Callable , Dict , List , Optional , Union , Tuple import matplotlib.pyplot as plt import mlxtend import numpy as np import pandas as pd import seaborn as sns from mlxtend.evaluate import bias_variance_decomp , paired_ttest_5x2cv from scipy import stats from sklearn import ( base , decomposition , dummy , ensemble , feature_selection , linear_model , metrics , model_selection , neighbors , pipeline , preprocessing , svm , tree ) from statsmodels.regression.linear_model import OLS \u001b[K |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.3 MB 5.2 MB/s \u001b[K |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9.8 MB 1.3 MB/s \u001b[?25h @dataclass class config : raw_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/raw/data.csv\" processed_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/processed.csv\" df_folds : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/df_folds.csv\" train_size : float = 0.9 seed : int = 1992 num_folds : int = 5 cv_schema : str = \"StratifiedKFold\" classification_type : str = \"binary\" target_col : List [ str ] = field ( default_factory = lambda : [ \"diagnosis\" ]) unwanted_cols : List [ str ] = field ( default_factory = lambda : [ \"id\" , \"Unnamed: 32\" ]) # Plotting colors : List [ str ] = field ( default_factory = lambda : [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ]) cmap_reversed = plt . cm . get_cmap ( 'mako_r' ) def to_dict ( self ) -> Dict : \"\"\"Convert the config object to a dictionary. Returns: Dict: The config object as a dictionary. \"\"\" return { \"raw_data\" : self . raw_data , \"processed_data\" : self . processed_data , \"train_size\" : self . train_size , \"seed\" : self . seed , \"num_folds\" : self . num_folds , \"cv_schema\" : self . cv_schema , \"classification_type\" : self . classification_type , \"target_col\" : self . target_col , \"unwanted_cols\" : self . unwanted_cols , \"colors\" : self . colors , \"cmap_reversed\" : self . cmap_reversed } # spot_checking_boxplot = \"../data/images/spot_checking_boxplot.png\" # oof_confusion_matrix = \"../data/images/oof_confusion_matrix.png\" # final_train_confusion_matrix = \"../data/images/final_train_confusion_matrix.png\" # precision_recall_threshold_plot = \"../data/images/precision_recall_threshold_plot.png\" # roc_plot = \"../data/images/roc_plot.png\" # feature_importance = \"../data/images/feature_importance.png\" def set_seeds ( seed : int = 1234 ) -> None : \"\"\"Set seeds for reproducibility.\"\"\" np . random . seed ( seed ) random . seed ( seed ) def init_logger ( log_file : str = \"info.log\" ): \"\"\" Initialize logger. \"\"\" logger = logging . getLogger ( __name__ ) logger . setLevel ( logging . INFO ) stream_handler = logging . StreamHandler () stream_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) file_handler = logging . FileHandler ( filename = log_file ) file_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) logger . addHandler ( stream_handler ) logger . addHandler ( file_handler ) return logger # Utils functions that we need def variance_inflation_factor ( exog , idx_kept , vif_idx ): \"\"\"Compute VIF for one feature. Args: exog (np.ndarray): Observations idx_kept (List[int]): Indices of features to consider vif_idx (int): Index of feature for which to compute VIF Returns: float: VIF for the selected feature \"\"\" exog = np . asarray ( exog ) x_i = exog [:, vif_idx ] mask = [ col for col in idx_kept if col != vif_idx ] x_noti = exog [:, mask ] r_squared_i = OLS ( x_i , x_noti ) . fit () . rsquared vif = 1. / ( 1. - r_squared_i ) return vif class ReduceVIF ( base . BaseEstimator , base . TransformerMixin ): \"\"\"The base of the class structure is implemented in https://www.kaggle.com/ffisegydd/sklearn-multicollinearity-class; I heavily modified the class such that it can take in numpy arrays and correctly implemented the fit and transform method. \"\"\" def __init__ ( self , thresh = 10 , max_drop = 20 ): self . thresh = thresh self . max_drop = max_drop self . column_indices_kept_ = [] self . feature_names_kept_ = None def reset ( self ): \"\"\"Resets the state of predictor columns after each fold.\"\"\" self . column_indices_kept_ = [] self . feature_names_kept_ = None def fit ( self , X , y = None ): \"\"\"Fits the Recursive VIF on the training folds and save the selected feature names in self.feature_names Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" self . column_indices_kept_ , self . feature_names_kept_ = self . calculate_vif ( X ) return self def transform ( self , X , y = None ): \"\"\"Transforms the Validation Set according to the selected feature names. Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" return X [:, self . column_indices_kept_ ] def calculate_vif ( self , X : Union [ np . ndarray , pd . DataFrame ]): \"\"\"Implements a VIF function that recursively eliminates features. Args: X (Union[np.ndarray, pd.DataFrame]): [description] Returns: [type]: [description] \"\"\" feature_names = None column_indices_kept = list ( range ( X . shape [ 1 ])) if isinstance ( X , pd . DataFrame ): feature_names = X . columns dropped = True count = 0 while dropped and count <= self . max_drop : dropped = False max_vif , max_vif_col = None , None for col in column_indices_kept : vif = variance_inflation_factor ( X , column_indices_kept , col ) if max_vif is None or vif > max_vif : max_vif = vif max_vif_col = col if max_vif > self . thresh : # print(f\"Dropping {max_vif_col} with vif={max_vif}\") column_indices_kept . remove ( max_vif_col ) if feature_names is not None : feature_names . pop ( max_vif_col ) dropped = True count += 1 return column_indices_kept , feature_names config = config () logger = init_logger () # set seeding for reproducibility _ = set_seeds ( seed = config . seed ) # read data df_folds = pd . read_csv ( config . df_folds ) # Assign predictors and target accordingly predictor_cols = df_folds . columns . to_list ()[: - 2 ] target_col = config . target_col","title":"Dependencies and Configuration"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%206%20-%20Modelling%20%28Preprocessing%20and%20Spot%20Checking%29/#spot-checking-algorithms","text":"Terminology Alert! This method is advocated by Jason Brownlee PhD and this serves as the first stage of my modelling process. We will rapidly test (spot check) different classifier algorithms, from DummyClassifier , to LinearModel to more sophisticated ensemble trees like RandomForest . I also note to the readers that we need to think of a few things when choosing the \"optimal\" machine learning algorithm: No Lunch Free Theorem intuitively says that no single optimization algorithm can work best in all situations. Therefore, spot checking can help us form a basis of which algorithm might work better in this particular scenario. Occam's Razor often appears in many Machine Learning textbook, and the narrative is that a simpler model more often times generalizes better than a complex model. This is not unfamiliar when we think of the bias-variance tradeoff, and that is why there is always a tradeoff that we must make.","title":"Spot Checking Algorithms"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%206%20-%20Modelling%20%28Preprocessing%20and%20Spot%20Checking%29/#say-no-to-data-leakage","text":"Say No to Data Leakage: This has been emphasized throughout and we must be careful as we should never touch the test set when fitting the model. In fact, we should try our best to not contaminate our validation set as well. This means that preprocessing steps such as StandardScaling() should only be fitted on the training data, and then apply the same transformation (mean and std) on the test data. In other words, do not apply scaling on the whole dataset before splitting. However, it is also equally important to take note not to contaminate our validation set, which is often overlooked, resulting in over optimistic results from model selection phase, but perform badly on unseen test set. As a result, when we use a 5 fold cross validation, we should be careful during fitting that the preprocessing steps are only applied on the training folds, and not on all 5 folds. The same idea is also applied to our ReduceVIF() preprocessing step. We should also include this in our pipeline and not select the features outside the cross-validation loop. Quoting from scikit-learn : Data leakage occurs when information that would not be available at prediction time is used when building the model. This results in overly optimistic performance estimates, for example from cross-validation , and thus poorer performance when the model is used on actually novel data, for example during production. A common cause is not keeping the test and train data subsets separate. Test data should never be used to make choices about the model. The general rule is to never call fit on the test data. While this may sound obvious, this is easy to miss in some cases, for example when applying certain pre-processing steps. Although both train and test data subsets should receive the same preprocessing transformation (as described in the previous section), it is important that these transformations are only learnt from the training data. For example, if you have a normalization step where you divide by the average value, the average should be the average of the train subset, not the average of all the data. If the test subset is included in the average calculation, information from the test subset is influencing the model. How to avoid Data Leakage? We know the pitfalls of fitting on validation/test data, the natural question is how can we avoid it completely? You can code it up yourself, but as a starter, we can use scikit-learn's Pipeline object. My tips are as follows: Any preprocessing step must be done after splitting the whole dataset into train and test. If you are also using cross-validation, then we should only apply the preprocessing steps on the train set, and then use the metrics obtained from the train set to transform the validation set. You can see my pseudo-code below for a rough outline. The Pipeline object of Scikit-Learn can help prevent data leakage.","title":"Say No to Data Leakage!"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%206%20-%20Modelling%20%28Preprocessing%20and%20Spot%20Checking%29/#pseudo-code-of-cross-validation-and-pipeline","text":"The below outlines a pseudo code of the cross-validation scheme using Pipeline object. Note that I included the most outer loop, which is searching for hyperparameters. Define \\(G\\) as the set of combination of hyperparamters. Define number of splits to be \\(K\\) . For each set of hyperparameter \\(z \\in Z\\) : for fold \\(j\\) in K: Set \\(F_{\\text{train}}=\\bigcup\\limits_{i\\neq k}^{K} F_{i}\\) Set \\(F_{\\text{val}} = F_{j}\\) as the validation set Perform Standard Scaling on \\(F_{\\text{train}}\\) and find the mean and std Perform VIF recursively on \\(F_{\\text{train}}\\) and find the selected features Transform \\(F_{\\text{val}}\\) using the mean and std found using \\(F_{\\text{train}}\\) Transform \\(F_{\\text{val}}\\) to have only the selected features from \\(F_{\\text{train}}\\) Train and fit on \\(F_{\\text{train}}\\) Evaluate the fitted parameters on \\(F_{\\text{val}}\\) to obtain \\(\\mathcal{M}\\)","title":"Pseudo-Code of Cross-Validation and Pipeline"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%206%20-%20Modelling%20%28Preprocessing%20and%20Spot%20Checking%29/#training-pipeline","text":"","title":"Training Pipeline"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%206%20-%20Modelling%20%28Preprocessing%20and%20Spot%20Checking%29/#make-pipeline","text":"# @ TODO: https://www.kaggle.com/kabure/predicting-house-prices-xgb-rf-bagging-reg-pipe # Different models can potentially have different pre-processing steps, consider putting steps as a # passable list. def make_pipeline ( model : Callable ) -> Callable : \"\"\"Create a feature preparation pipeline for a model. Args: model (Callable): The model to be used. Returns: _pipeline (Callable): pipeline object \"\"\" # Create a list of steps, note that some models may not need certain steps, and hence # may need an if-else here steps = list () # standardization steps . append (( \"standardize\" , preprocessing . StandardScaler ())) # reduce VIF steps . append (( \"remove_multicollinearity\" , ReduceVIF ( thresh = 10 ))) # the model to be appended at the last step steps . append (( \"model\" , model )) # create pipeline _pipeline = pipeline . Pipeline ( steps = steps ) return _pipeline classifiers = [ # baseline model dummy . DummyClassifier ( random_state = config . seed , strategy = \"stratified\" ), # linear model linear_model . LogisticRegression ( random_state = config . seed , solver = \"liblinear\" ), # nearest neighbours neighbors . KNeighborsClassifier ( n_neighbors = 8 ), # SVM svm . SVC ( probability = True , random_state = config . seed ), # tree tree . DecisionTreeClassifier ( random_state = config . seed ), # ensemble ensemble . RandomForestClassifier ( n_estimators = 10 , random_state = config . seed ), ] classifiers = [ make_pipeline ( model ) for model in classifiers ]","title":"Make Pipeline"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%206%20-%20Modelling%20%28Preprocessing%20and%20Spot%20Checking%29/#results-class","text":"The Results class will help us store model's results. Careful when using ROC function! We also note that when passing arguments to scikit-learn's roc_auc_score function, we should be careful not to pass y_score=model.predict(X) inside as we have to understand that we are passing in non-thresholded probabilities into y_score . If you pass the predicted values (full of 0 and 1s), then you are thresholding on 0 and 1 only, which is incorrect by definition. default_result_names = [ \"y_true\" , \"y_pred\" , \"y_prob\" ] default_logit_names = [ \"y_true\" , \"y_pred\" , \"y_prob\" ] default_score_names = [ \"accuracy_score\" , \"precision_recall_fscore_support\" , \"confusion_matrix\" , # \"average_precision_score\", \"multiclass_roc_auc_score\" , \"brier_score_loss\" , ] custom_score_names = [ \"multiclass_roc_auc_score\" , \"brier_score_loss\" ] use_preds = [ \"accuracy_score\" , \"precision_recall_fscore_support\" , \"confusion_matrix\" , ] use_probs = [ \"average_precision_score\" ] class Results : \"\"\"Stores results for model training in columnwise format.\"\"\" _result_dict : Dict logit_names : List [ str ] score_names : List [ str ] def __init__ ( self , logit_names : List [ str ] = default_logit_names , score_names : List [ str ] = default_score_names , existing_dict : Optional [ Dict ] = None , ): \"\"\"Construct a new results store.\"\"\" self . logit_names = logit_names self . score_names = score_names if existing_dict is not None : self . _result_dict = copy . deepcopy ( existing_dict ) return dict_keys = [ \"identifier\" , * logit_names , * score_names ] self . _result_dict = { key : [] for key in dict_keys } def add ( self , identifier : str , results : Dict , in_place = False ): \"\"\"Add a new results row.\"\"\" if not in_place : return Results ( self . logit_names , self . score_names , self . _result_dict ) . add ( identifier , results , in_place = True ) self . _result_dict [ \"identifier\" ] . append ( identifier ) for result_name in set ([ * results . keys (), * self . logit_names , * self . score_names ]): result_value = results . get ( result_name , np . nan ) self . _result_dict [ result_name ] . append ( result_value ) return self def get_result ( self , result_name : str ) -> Dict [ str , Any ]: \"\"\"Get a map of identifiers to result values for a result.\"\"\" return { identifier : result_value for identifier , result_value in zip ( self . _result_dict [ \"identifier\" ], self . _result_dict [ result_name ]) } def get_result_values ( self , result_name : str ) -> List [ Any ]: \"\"\"Get a list of values for a result.\"\"\" return self . _result_dict [ result_name ] def to_dataframe ( self ) -> pd . DataFrame : \"\"\"Get a Data Frame containing the results.\"\"\" return pd . DataFrame . from_dict ( self . _result_dict ) def to_dict ( self ) -> Dict : \"\"\"Get a dictionary containing the results. Returns: Dict[str, List[Any]]: Dictionary of result columns \"\"\" return self . _result_dict def multiclass_label_binarize ( y : np . ndarray , class_labels : List [ int ], pos_label = 1 , neg_label = 0 ): \"\"\"Binarize labels in one-vs-all fashion. # TODO: to replace with the above vstack method. Args: y (np.ndarray) Sequence of integer labels to encode class_labels (array-like) Labels for each class pos_label (int) Value for positive labels neg_label (int) Value for negative labels Returns: np.ndarray of shape (n_samples, n_classes) Encoded dataset \"\"\" if isinstance ( y , list ): y = np . asarray ( y ) columns = [ np . where ( y == label , pos_label , neg_label ) for label in class_labels ] return np . column_stack ( columns ) def multiclass_roc_auc_score ( y_true , y_score , classes = None ): \"\"\"Compute ROC-AUC score for each class in a multiclass dataset. Args: y_true (np.ndarray of shape (n_samples, n_classes)) True labels y_score (np.ndarray of shape (n_samples, n_classes)) Target scores classes (array-like of shape (n_classes,)) List of dataset classes. If `None`, the lexicographical order of the labels in `y_true` is used. Returns: array-like: ROC-AUC score for each class, in the same order as `classes` \"\"\" classes = ( np . unique ( y_true ) if classes is None else classes ) y_true_multiclass = multiclass_label_binarize ( y_true , class_labels = classes ) def oneclass_roc_auc_score ( class_id ): y_true_class = y_true_multiclass [:, class_id ] y_score_class = y_score [:, class_id ] fpr , tpr , _ = metrics . roc_curve ( y_true = y_true_class , y_score = y_score_class , pos_label = 1 ) return metrics . auc ( fpr , tpr ) return [ oneclass_roc_auc_score ( class_id ) for class_id in range ( len ( classes )) ]","title":"Results Class"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%206%20-%20Modelling%20%28Preprocessing%20and%20Spot%20Checking%29/#utilities","text":"Some utility functions to prepare data and post-process data. def prepare_y ( y : np . ndarray ) -> np . ndarray : \"\"\"Prepare the target variable for the model. If Binary Classification, we need to ravel the array to 1d. Args: y (np.ndarray): Target variable. Returns: np.ndarray: Transformed Target variable. \"\"\" return y . ravel () if config . classification_type == \"binary\" else y def mean_score ( score_values ) -> Union [ float , np . ndarray ]: \"\"\"Compute the mean score.\"\"\" score_values = np . array ( score_values ) shape = score_values . shape if len ( shape ) == 1 : return score_values . mean () return score_values . mean ( axis = 0 ) def mean_cv_results ( model_results : Results ) -> Dict : \"\"\"Add mean cross-validation results. This method computes the mean value for all score types in the model_results, including for scores (e.g., confusion matrix) where the mean value may contain decimal places. \"\"\" cv_logits = { y_result : np . concatenate ( model_results . get_result_values ( y_result )) for y_result in model_results . logit_names } cv_scores = { score : mean_score ( model_results . get_result_values ( score ) ) for score in model_results . score_names } return { ** cv_logits , ** cv_scores , } def oof_cv_results ( model_results : Results ) -> Dict : \"\"\"Add OOF cross-validation results.\"\"\" cv_logits = { y_result : np . concatenate ( model_results . get_result_values ( y_result ) ) for y_result in model_results . logit_names } cv_scores = compute_metrics ( cv_logits ) return { ** cv_logits , ** cv_scores , } def add_cv_results ( model_results : Results ): \"\"\"Add cross-validation results. This method returns a copy of the given model results with summary columns for mean and CV cross-validation. \"\"\" mean_cv = mean_cv_results ( model_results ) oof_cv = oof_cv_results ( model_results ) return ( model_results . add ( \"mean_cv\" , mean_cv ) . add ( \"oof_cv\" , oof_cv ) ) def compute_metrics ( logits : Dict [ str , np . ndarray ]) -> Dict [ str , Any ]: \"\"\"Compute metrics from logits. use_probs: all metrics that use probabilities. use_preds: all metrics that use thresholded predictions. # TODO add this precision, recall, fbeta_score, _ = metrics.precision_recall_fscore_support( y_true=y_val, y_pred = y_val_pred, labels=np.unique(y_val), average=None ) \"\"\" y_true , y_pred , y_prob = ( logits [ \"y_true\" ], logits [ \"y_pred\" ], logits [ \"y_prob\" ], ) use_preds = [ \"accuracy_score\" , \"precision_recall_fscore_support\" , \"confusion_matrix\" , ] use_probs = [ \"average_precision_score\" ] default_metrics_dict : Dict [ str , float ] = {} custom_metrics_dict : Dict [ str , float ] = {} for metric_name in default_score_names : if hasattr ( metrics , metric_name ): # TODO: get metric score with default parameters, consider adding kwargs if you want to configure parameters if metric_name in use_preds : metric_score = getattr ( metrics , metric_name )( y_true , y_pred ) elif metric_name in use_probs : # logger.info(\"TODO: write custom scores for precision-recall as here is hardcoded\") pass # metric_score = getattr(metrics, metric_name)( # y_true, y_prob # ) else : # add custom metrics here multiclass_roc_auc = multiclass_roc_auc_score ( y_true , y_prob ) brier_score_loss = ( metrics . brier_score_loss ( y_true = y_true , y_prob = y_prob [:, 1 ]) if config . classification_type == \"binary\" else np . nan ) custom_metrics_dict [ \"multiclass_roc_auc_score\" ] = multiclass_roc_auc custom_metrics_dict [ \"brier_score_loss\" ] = brier_score_loss if metric_name not in default_metrics_dict : default_metrics_dict [ metric_name ] = metric_score metrics_dict = { ** default_metrics_dict , ** custom_metrics_dict } return metrics_dict def train_on_fold ( df_folds : pd . DataFrame , models : List [ Callable ], num_folds : int , predictor_col : List [ str ], target_col : List [ str ], ) -> Dict [ str , List ]: \"\"\"Take in a dataframe with fold number as column, and a models which holds a list of callable models, we will loop through and return a dictionary of cv results. Args: df_folds (pd.DataFrame): Dataframe with fold number as column. model (Callable): A callable model. num_folds (int): Number of folds. predictor_col (List[str]): List of predictor columns. target_col (List[str]): List of target columns. Returns: model_dict (Dict[str, Results]: Dictionary of model results with model name as key. \"\"\" y_true = df_folds [ target_col ] . values . flatten () # test_pred_arr: np.ndarray = np.zeros(len(X_test)) model_dict = {} for model in models : model_results = Results () if isinstance ( model , pipeline . Pipeline ): model_name = model [ \"model\" ] . __class__ . __name__ else : model_name = model . __class__ . __name__ # out-of-fold validation predictions oof_pred_arr : np . ndarray = np . zeros ( len ( df_folds )) for fold in range ( 1 , num_folds + 1 ): train_df = df_folds [ df_folds [ \"fold\" ] != fold ] . reset_index ( drop = True ) val_df = df_folds [ df_folds [ \"fold\" ] == fold ] . reset_index ( drop = True ) val_idx = df_folds [ df_folds [ \"fold\" ] == fold ] . index . values X_train , y_train = train_df [ predictor_col ] . values , prepare_y ( train_df [ target_col ] . values ) X_val , y_val = val_df [ predictor_col ] . values , prepare_y ( val_df [ target_col ] . values ) model . fit ( X_train , y_train ) y_val_pred = model . predict ( X_val ) y_val_prob = model . predict_proba ( X_val ) logits = { \"y_true\" : y_val , \"y_pred\" : y_val_pred , \"y_prob\" : y_val_prob , } metrics = compute_metrics ( logits ) model_results . add ( f \"fold { fold } \" , { ** logits , ** metrics }, in_place = True ) if model_name not in model_dict : model_dict [ model_name ] = model_results return model_dict # Returns a dict in the format of # {'LogisticRegression': <__main__.Results at 0x7f3bca575e90>} model_dict = train_on_fold ( df_folds , models = classifiers , num_folds = 5 , predictor_col = predictor_cols , target_col = config . target_col ) # Takes in a model_dict and add cv results to the dict model_dict_with_summary = { model : add_cv_results ( model_results ) for model , model_results in model_dict . items () } # Transforms model_dict_with_summary to a Dict of dataframes # model_results_df['LogisticRegression'] -> df model_results_df = { name : results . to_dataframe () . T for name , results in model_dict_with_summary . items () } results_df = pd . concat ( model_results_df , axis = 0 ) results_df . columns = [ 'fold 1' , 'fold 2' , 'fold 3' , 'fold 4' , 'fold 5' , 'mean_cv' , 'oof_cv' ] results_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } fold 1 fold 2 fold 3 fold 4 fold 5 mean_cv oof_cv RandomForestClassifier accuracy_score 0.932039 0.961165 0.95098 0.960784 0.95098 0.95119 0.951172 precision_recall_fscore_support ([0.9672131147540983, 0.8809523809523809], [0.... ([0.9552238805970149, 0.9722222222222222], [0.... ([0.927536231884058, 1.0], [1.0, 0.86842105263... ([0.9545454545454546, 0.9722222222222222], [0.... ([0.9402985074626866, 0.9714285714285714], [0.... [[0.9489634378486625, 0.9593650793650793], [0.... ([0.9484848484848485, 0.9560439560439561], [0.... confusion_matrix [[59, 5], [2, 37]] [[64, 1], [3, 35]] [[64, 0], [5, 33]] [[63, 1], [3, 35]] [[63, 1], [4, 34]] [[62.6, 1.6], [3.4, 34.8]] [[313, 8], [17, 174]] multiclass_roc_auc_score [0.9709535256410255, 0.9709535256410255] [0.9896761133603239, 0.9896761133603239] [0.9967105263157895, 0.9967105263157895] [0.9930098684210527, 0.9930098684210527] [0.9802631578947368, 0.980263157894737] [0.9861226383265856, 0.9861226383265856] [0.9849374500497463, 0.9849374500497464] brier_score_loss 0.0594175 0.0415534 0.0376471 0.0347059 0.0413725 0.0429393 0.0429688","title":"Utilities"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%206%20-%20Modelling%20%28Preprocessing%20and%20Spot%20Checking%29/#comparison-of-cross-validated-models-cv-oof","text":"The point of the following comparison is to check how different models are performing across folds. More specifically, if we have 5 folds, we will have a metric score for each fold, subsequently, we can find the standard error of model's performance. We need to be aware of models that have high variance across folds in terms of the metrics performance. This can indicate that the model is highly unstable, and may be a sign of overfitting. def summarize_metrics ( model_dict : Dict [ str , Results ], metric_name : str = \"roc\" , pos_label : int = 1 ): \"\"\" Summarize metrics of each fold with its standard error. We also plot a boxplot to show the results. \"\"\" results = [] for model_name , model_results in model_dict . items (): result_dict = model_results . get_result ( result_name = metric_name ) tmp_score = [] for fold , metric in result_dict . items (): pos_class_score = metric [ pos_label ] results . append (( model_name , fold , pos_class_score )) tmp_score . append ( pos_class_score ) # append the Standard Error of K folds results . append ( ( model_name , \"SE\" , np . std ( tmp_score , ddof = 1 ) / len ( tmp_score ) ** 0.5 ) ) summary_df = pd . DataFrame ( results , columns = [ \"model\" , \"fold\" , metric_name ]) fig , ax = plt . subplots ( figsize = ( 15 , 8 )) _ = sns . boxplot ( x = \"model\" , y = metric_name , data = summary_df [ ( summary_df [ \"model\" ] != \"DummyClassifier\" ) & ( summary_df [ \"fold\" ] != \"SE\" ) ], ax = ax , ) # fig.savefig(config.spot_checking_boxplot, format='png', dpi=300) return summary_df summary_df = summarize_metrics ( model_dict = model_dict , metric_name = \"multiclass_roc_auc_score\" ) display ( summary_df . tail ( 12 )) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } model fold multiclass_roc_auc_score 24 DecisionTreeClassifier fold 1 0.865585 25 DecisionTreeClassifier fold 2 0.924291 26 DecisionTreeClassifier fold 3 0.923931 27 DecisionTreeClassifier fold 4 0.923931 28 DecisionTreeClassifier fold 5 0.895148 29 DecisionTreeClassifier SE 0.011677 30 RandomForestClassifier fold 1 0.970954 31 RandomForestClassifier fold 2 0.989676 32 RandomForestClassifier fold 3 0.996711 33 RandomForestClassifier fold 4 0.993010 34 RandomForestClassifier fold 5 0.980263 35 RandomForestClassifier SE 0.004672","title":"Comparison of Cross-Validated Models (CV + OOF)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%206%20-%20Modelling%20%28Preprocessing%20and%20Spot%20Checking%29/#out-of-fold-confusion-matrix","text":"We do have information on the performance of each folds, we now look at the performance of all 5 folds together. Typicall there are two ways to do it, one is to simply take the average of the score of five folds, the other is to take a look at out of folds predictions. From the confusion matrix of the out of fold performance, Logistic Regression does seem to be a model we can explore on, although slightly lower in terms of overall AUROC score than SVC, it seems to have the quite low False Negatives amongst all. With further hyperparameter tuning and threshold optimization, we can make it better. model_names = [ model for model in model_dict . keys ()] def plot_binary_confusion_matrix ( results_df : pd . DataFrame , model_names : List [ str ] ) -> None : n_models = len ( model_names ) # if 7 models, then 3 rows, 2 columns, and 7 subplots # always fix column to be 3 n_cols = 3 n_rows = int ( np . ceil ( n_models / n_cols )) fig , ax = plt . subplots ( n_rows , n_cols , figsize = ( 10 , 10 )) for axes , algo in zip ( ax . ravel (), model_names ): # Unravel into tn, fp, fn and tp tn , fp , fn , tp = results_df . oof_cv [ algo ] . confusion_matrix . ravel () # reshape into tp, fp, fn, tn - this is personal preference reshaped_cm = np . asarray ([[ tp , fp ], [ fn , tn ]]) # Get positive ROC score - hardcoded here. positive_class_auroc = results_df . oof_cv [ algo ] . multiclass_roc_auc_score [ 1 ] # annotations labels = [ \"True Pos\" , \"False Pos\" , \"False Neg\" , \"True Neg\" ] counts = [ \" {0:0.0f} \" . format ( value ) for value in reshaped_cm . flatten ()] percentages = [ \" {0:.2%} \" . format ( value ) for value in reshaped_cm . flatten () / np . sum ( reshaped_cm ) ] # final annotations label = ( np . array ( [ f \" { v1 } \\n { v2 } \\n { v3 } \" for v1 , v2 , v3 in zip ( labels , counts , percentages )] ) ) . reshape ( 2 , 2 ) # heatmap sns . heatmap ( data = reshaped_cm , vmin = 0 , vmax = 330 , cmap = [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ], linewidth = 2 , linecolor = \"white\" , square = True , ax = axes , annot = label , fmt = \"\" , cbar = False , annot_kws = { \"size\" : 10 , \"color\" : \"black\" , \"weight\" : \"bold\" , \"alpha\" : 0.8 }, alpha = 1 , ) axes . text ( 0 , - 0 , \" {} \" . format ( algo ), { \"size\" : 12 , \"color\" : \"black\" , \"weight\" : \"bold\" } ) axes . scatter ( 1 , 1 , s = 3500 , c = \"white\" ) axes . text ( 0.72 , 1.0 , \"AUC: {} \" . format ( np . round ( positive_class_auroc , 3 )), { \"size\" : 10 , \"color\" : \"black\" , \"weight\" : \"bold\" }, ) ## ticks and labels axes . set_xticklabels ( \"\" ) axes . set_yticklabels ( \"\" ) ## titles and text fig . text ( 0 , 1.05 , \"Out Of Fold Confusion Matrix\" , { \"size\" : 22 , \"weight\" : \"bold\" }, alpha = 1 ) fig . text ( 0 , 1 , \"\"\"This Visualization show the results of various classifiers and there respective results.\"\"\" , { \"size\" : 14 , \"weight\" : \"normal\" }, alpha = 0.98 , ) fig . tight_layout ( pad = 2.5 , w_pad = 2.5 , h_pad = 2.5 ) # fig.savefig(config.oof_confusion_matrix, format='png', dpi=300) plot_binary_confusion_matrix ( results_df , model_names )","title":"Out-of-Fold Confusion Matrix"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%206%20-%20Modelling%20%28Preprocessing%20and%20Spot%20Checking%29/#hypothesis-testing-across-models","text":"I am slightly shocked at the performance of plain LogisticRegression, I decide to use an idea from Hypothesis Testing Across Models to check if the difference is really by chance or not. Note that I will be modifying his code as his code does not split using StratifiedKFold. The basic idea is to test if two model's difference in scores (in this case roc), is statistically significant or not. However, we note that this method may violate an assumption of Student's t test. Null Hypothesis \\(H_0\\) : The difference in the performance score of two classifiers is Statistically Significant. Alternate Hypothesis \\(H_1\\) : The difference in the performance score of two classifiers is not Statistically Significant. def paired_ttest_skfold_cv ( estimator1 : Callable , estimator2 : Callable , X : np . ndarray , y : np . ndarray , cv : int = 10 , scoring : str = None , shuffle : bool = False , random_seed : int = None , ) -> float : \"\"\"Modified from https://github.com/rasbt/mlxtend/blob/master/mlxtend/evaluate/ttest.py to accomodate StratifiedKFold. Args: estimator1 (Callable): [description] estimator2 (Callable): [description] X (np.ndarray): [description] y (np.ndarray): [description] cv (int, optional): [description]. Defaults to 10. scoring (str, optional): [description]. Defaults to None. shuffle (bool, optional): [description]. Defaults to False. random_seed (int, optional): [description]. Defaults to None. Raises: AttributeError: [description] Returns: float: [description] \"\"\" if not shuffle : skf = model_selection . StratifiedKFold ( n_splits = cv , shuffle = shuffle ) else : skf = model_selection . StratifiedKFold ( n_splits = cv , random_state = random_seed , shuffle = shuffle ) if scoring is None : if estimator1 . _estimator_type == \"classifier\" : scoring = \"accuracy\" elif estimator1 . _estimator_type == \"regressor\" : scoring = \"r2\" else : raise AttributeError ( \"Estimator must \" \"be a Classifier or Regressor.\" ) if isinstance ( scoring , str ): scorer = metrics . get_scorer ( scoring ) else : scorer = scoring score_diff = [] for train_index , test_index in skf . split ( X = X , y = y ): X_train , X_test = X [ train_index ], X [ test_index ] y_train , y_test = y [ train_index ], y [ test_index ] estimator1 . fit ( X_train , y_train ) estimator2 . fit ( X_train , y_train ) est1_score = scorer ( estimator1 , X_test , y_test ) est2_score = scorer ( estimator2 , X_test , y_test ) score_diff . append ( est1_score - est2_score ) avg_diff = np . mean ( score_diff ) numerator = avg_diff * np . sqrt ( cv ) denominator = np . sqrt ( sum ([( diff - avg_diff ) ** 2 for diff in score_diff ]) / ( cv - 1 ) ) t_stat = numerator / denominator pvalue = stats . t . sf ( np . abs ( t_stat ), cv - 1 ) * 2.0 return float ( t_stat ), float ( pvalue ) # check if difference between algorithms is real X_tmp = df_folds [ predictor_cols ] . values y_tmp = df_folds [ 'diagnosis' ] . values t , p = paired_ttest_skfold_cv ( estimator1 = classifiers [ 1 ], estimator2 = classifiers [ - 1 ], shuffle = True , cv = 5 , X = X_tmp , y = y_tmp , scoring = 'roc_auc' , random_seed = config . seed ) logger . info ( 'P-value: %.3f , t-Statistic: %.3f ' % ( p , t )) 2021-11-13,14:04:35 - P-value: 0.171, t-Statistic: 1.667 2021-11-13,14:04:35 - P-value: 0.171, t-Statistic: 1.667 Since \\(p\\) -value is quite high, and more the basic threshold of 0.05 or 0.1, we fail to reject the null hypothesis, and say that there is no significant difference between these two models.","title":"Hypothesis Testing Across Models"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/","text":"Stage 7: Hyperparameter Tuning by Hongnan Gao Dependencies and Configuration %% capture ! pip install - q wandb # !pip install -q shap ! pip install - q mlxtend == 0.19.0 ! pip install - q statsmodels == 0.13.1 # !pip install gcloud == 0.18.3 import wandb wandb . login () \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect. True import copy import csv import logging import os import random from dataclasses import asdict , dataclass , field from functools import wraps from pathlib import Path from time import time from typing import Any , Callable , Dict , List , Optional , Tuple , Union import matplotlib.pyplot as plt import mlxtend import numpy as np import pandas as pd import seaborn as sns from joblib import dump , load from mlxtend.evaluate import bias_variance_decomp , paired_ttest_5x2cv from scipy import stats from sklearn import ( base , decomposition , dummy , ensemble , feature_selection , linear_model , metrics , model_selection , neighbors , pipeline , preprocessing , svm , tree ) from statsmodels.regression.linear_model import OLS Utils and Configurations @dataclass class config : raw_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/raw/data.csv\" processed_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/processed.csv\" df_folds : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/df_folds.csv\" train_size : float = 0.9 seed : int = 1992 num_folds : int = 5 cv_schema : str = \"StratifiedKFold\" classification_type : str = \"binary\" target_col : List [ str ] = field ( default_factory = lambda : [ \"diagnosis\" ]) unwanted_cols : List [ str ] = field ( default_factory = lambda : [ \"id\" , \"Unnamed: 32\" ]) # Plotting colors : List [ str ] = field ( default_factory = lambda : [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ]) cmap_reversed = plt . cm . get_cmap ( 'mako_r' ) def to_dict ( self ) -> Dict [ str , Any ]: \"\"\"Convert the config object to a dictionary. Returns: Dict: The config object as a dictionary. \"\"\" return asdict ( self ) # spot_checking_boxplot = \"../data/images/spot_checking_boxplot.png\" # oof_confusion_matrix = \"../data/images/oof_confusion_matrix.png\" # final_train_confusion_matrix = \"../data/images/final_train_confusion_matrix.png\" # precision_recall_threshold_plot = \"../data/images/precision_recall_threshold_plot.png\" # roc_plot = \"../data/images/roc_plot.png\" # feature_importance = \"../data/images/feature_importance.png\" def set_seeds ( seed : int = 1234 ) -> None : \"\"\"Set seeds for reproducibility.\"\"\" np . random . seed ( seed ) random . seed ( seed ) def init_logger ( log_file : str = \"info.log\" ): \"\"\" Initialize logger. \"\"\" logger = logging . getLogger ( __name__ ) logger . setLevel ( logging . INFO ) stream_handler = logging . StreamHandler () stream_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) file_handler = logging . FileHandler ( filename = log_file ) file_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) logger . addHandler ( stream_handler ) logger . addHandler ( file_handler ) return logger # Utils functions that we need def variance_inflation_factor ( exog , idx_kept , vif_idx ): \"\"\"Compute VIF for one feature. Args: exog (np.ndarray): Observations idx_kept (List[int]): Indices of features to consider vif_idx (int): Index of feature for which to compute VIF Returns: float: VIF for the selected feature \"\"\" exog = np . asarray ( exog ) x_i = exog [:, vif_idx ] mask = [ col for col in idx_kept if col != vif_idx ] x_noti = exog [:, mask ] r_squared_i = OLS ( x_i , x_noti ) . fit () . rsquared vif = 1. / ( 1. - r_squared_i ) return vif class ReduceVIF ( base . BaseEstimator , base . TransformerMixin ): \"\"\"The base of the class structure is implemented in https://www.kaggle.com/ffisegydd/sklearn-multicollinearity-class; I heavily modified the class such that it can take in numpy arrays and correctly implemented the fit and transform method. \"\"\" def __init__ ( self , thresh = 10 , max_drop = 20 ): self . thresh = thresh self . max_drop = max_drop self . column_indices_kept_ = [] self . feature_names_kept_ = None def reset ( self ): \"\"\"Resets the state of predictor columns after each fold.\"\"\" self . column_indices_kept_ = [] self . feature_names_kept_ = None def fit ( self , X , y = None ): \"\"\"Fits the Recursive VIF on the training folds and save the selected feature names in self.feature_names Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" self . column_indices_kept_ , self . feature_names_kept_ = self . calculate_vif ( X ) return self def transform ( self , X , y = None ): \"\"\"Transforms the Validation Set according to the selected feature names. Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" return X [:, self . column_indices_kept_ ] def calculate_vif ( self , X : Union [ np . ndarray , pd . DataFrame ]): \"\"\"Implements a VIF function that recursively eliminates features. Args: X (Union[np.ndarray, pd.DataFrame]): [description] Returns: [type]: [description] \"\"\" feature_names = None column_indices_kept = list ( range ( X . shape [ 1 ])) if isinstance ( X , pd . DataFrame ): feature_names = X . columns dropped = True count = 0 while dropped and count <= self . max_drop : dropped = False max_vif , max_vif_col = None , None for col in column_indices_kept : vif = variance_inflation_factor ( X , column_indices_kept , col ) if max_vif is None or vif > max_vif : max_vif = vif max_vif_col = col if max_vif > self . thresh : # print(f\"Dropping {max_vif_col} with vif={max_vif}\") column_indices_kept . remove ( max_vif_col ) if feature_names is not None : feature_names . pop ( max_vif_col ) dropped = True count += 1 return column_indices_kept , feature_names def prepare_y ( y : np . ndarray ) -> np . ndarray : \"\"\"Prepare the target variable for the model. If Binary Classification, we need to ravel the array to 1d. Args: y (np.ndarray): Target variable. Returns: np.ndarray: Transformed Target variable. \"\"\" return y . ravel () if config . classification_type == \"binary\" else y config = config () basic_config : Dict = config . to_dict () # train_config: Dict = Train().to_dict() global_config : Dict = dict ( basic = basic_config ) # We can log multiple dict under global_config - in wandb UI, it will show as basic. and train. to show which dict it is referring to. run = wandb . init ( project = \"bcw\" , name = \"classification\" , config = global_config ) # set logger logger = init_logger () # set seeding for reproducibility _ = set_seeds ( seed = config . seed ) # read data df_folds = pd . read_csv ( config . df_folds ) # Assign predictors and target accordingly predictor_cols = df_folds . columns . to_list ()[: - 2 ] target_col = config . target_col Model Selection: Hyperparameter Tuning with GridSearchCV Hyperparameter Tuning We have done a quick spot checking on algorithms and realized that LogisticRegression is doing well for this task. For this purpose, I will just perform hyperparameter tuning on this single algorithm. However, in practice and if resources are allowed, I will also tune other models such as RandomForest() , or gradient boosting algorithms such as XGBoost , as I believe they will perform no worse than our Logistic Regression model given the right hyperparameters. Grid Search is the Gwei? Meh! We will use an old-fashioned way to search for hyperparameters, which is brute force method. The time complexity of Grid Search is high and if you have many hyperparameters to tune, I recommend trying out Random Grid Search or libraries like Optuna that uses Bayesian Optimization. TODO Try to code up your own GridSearchCV to have maximum flexibility. Make Finetuning Pipeline The following make_finetuning_pipeline does exactly the same thing is as make_pipeline earlier. The only difference is we can pass in flexible list of steps to the pipeline from outside. def make_finetuning_pipeline ( model : Callable , steps : List [ Tuple [ str , Callable ]] ) -> pipeline . Pipeline : \"\"\"Return a pipeline that can be used for finetuning. Args: model (Callable): A model with default parameters. steps (List[Tuple[str, Callable]]): A list of preprocessing steps to pass in Pipeline object. Returns: Pipeline: Returns a pipeline that can be used for finetuning. \"\"\" return pipeline . Pipeline ([ * steps , ( \"model\" , model )]) # TODO: Make a class to hold pipelines? # class MakePipeline: # def __init__(self, estimator: Callable, steps: List[Callable]): # pass # def spot_checking_pipeline(): # pass # def fine_tuning_pipeline(): # pass finetuning_pipeline_steps = [ # standardization ( \"standardize\" , preprocessing . StandardScaler ()), # reduce VIF ( \"remove_multicollinearity\" , ReduceVIF ( thresh = 10 )) ] Search Space Run our hyperparameter search with cross-validation. For example, our param_grid has \\(2 \\times 10 = 20\\) combinations, and our cross validation has 5 folds, then there will be a total of 100 fits. Below details the pseudo code of what happens under the hood: Define \\(G\\) as the set of combination of hyperparamters. Define number of splits to be \\(K\\) . For each set of hyperparameter \\(z \\in Z\\) : for fold \\(j\\) in K: Set \\(F_{\\text{train}}=\\bigcup\\limits_{i\\neq k}^{K} F_{i}\\) Set \\(F_{\\text{val}} = F_{j}\\) as the validation set Perform Standard Scaling on \\(F_{\\text{train}}\\) and find the mean and std Perform VIF recursively on \\(F_{\\text{train}}\\) and find the selected features Transform \\(F_{\\text{val}}\\) using the mean and std found using \\(F_{\\text{train}}\\) Transform \\(F_{\\text{val}}\\) to have only the selected features from \\(F_{\\text{train}}\\) Train and fit on \\(F_{\\text{train}}\\) Evaluate the fitted parameters on \\(F_{\\text{val}}\\) to obtain \\(\\mathcal{M}\\) @dataclass class ModelForTuning : model : Callable param_grid : Dict Define our search space for the hyperparameters: logistic_r_param_grid = { model__penalty = [ \"l1\" , \"l2\" ], model__C = np . logspace ( - 4 , 4 , 10 )} We conveniently use dataclass to act as a medium so we can pass in model and param_grid independently for each model. We then collate them into a list of ModelForTuning object. models_list = [ ModelForTuning ( model = linear_model . LogisticRegression ( solver = \"saga\" , random_state = config . seed , max_iter = 10000 , n_jobs =- 1 , fit_intercept = True , ), param_grid = dict ( model__penalty = [ \"l1\" , \"l2\" ], model__C = np . logspace ( - 4 , 4 , 10 ), ), ), ModelForTuning ( model = tree . DecisionTreeClassifier ( random_state = config . seed ), param_grid = dict ( model__max_depth = [ 2 , 3 , 5 , 10 , 20 ], model__min_samples_leaf = [ 5 , 10 , 20 , 50 , 100 ], model__criterion = [ \"gini\" , \"entropy\" ], ), ), ModelForTuning ( model = ensemble . GradientBoostingClassifier ( n_estimators = 100 ), param_grid = dict ( model__max_depth = [ 3 , 6 ], model__learning_rate = [ 0.1 , 0.05 ], model__subsample = [ 1 , 0.5 , ], ), ), ] def optimize_models ( models_list : List [ ModelForTuning ], X_train : np . ndarray , y_train : np . ndarray , scorer : Union [ str , Callable ], steps : List [ Tuple [ str , Callable ]], ) -> List [ Callable ]: \"\"\"Optimize models in models_list using X_train and y_train. We are using GridSearchCV to find the best parameters for each model. Consider using Optuna for hyperparameter optimization (or wandb for hyperparameter optimization). Args: models_list (List[ModelForTuning]): List of models to optimize. X_train (np.ndarray): X_train data. y_train (np.ndarray): y_train data. Returns: grids (List[Callable]): List of optimized models. \"\"\" # @ TODO: make a scoring list to pass in so we can evaluate multiple metrics. grids = [ model_selection . GridSearchCV ( make_finetuning_pipeline ( model . model , steps ), param_grid = model . param_grid , cv = 5 , refit = True , verbose = 1 , scoring = scorer , n_jobs =- 1 , ) for model in models_list ] for grid in grids : grid . fit ( X_train , y_train ) return grids roc_auc_scorer = \"roc_auc_ovr\" # Unsure why this gives much lower score - to investigate # metrics.make_scorer(metrics.roc_auc_score, average=\"macro\", multi_class='ovr') X_train , y_train = df_folds [ predictor_cols ] . values , df_folds [ target_col ] . values y_train = prepare_y ( y_train ) grids = optimize_models ( models_list , X_train , y_train , scorer = roc_auc_scorer , steps = finetuning_pipeline_steps ) Fitting 5 folds for each of 20 candidates, totalling 100 fits Fitting 5 folds for each of 50 candidates, totalling 250 fits Fitting 5 folds for each of 8 candidates, totalling 40 fits # The above optimize code is equivalent to the below, for better readability # pipeline_logistic = make_finetuning_pipeline( # linear_model.LogisticRegression( # solver=\"saga\", random_state=config.seed, max_iter=10000, n_jobs=None, fit_intercept=True # ), steps=steps # ) # param_grid = dict( # model__penalty=[\"l1\", \"l2\"], # model__C=np.logspace(-4, 4, 10), # ) # grid = model_selection.GridSearchCV(pipeline_logistic, param_grid=param_grid, cv=5, refit=True, verbose=3, scoring = \"roc_auc\") # _ = grid.fit(X_train, y_train) We can save our results in a dataframe, we will also look at the top performing hyperparameter by querying the below: grid_cv_df = pd . DataFrame ( grid . cv_results_ ) grid_cv_df . loc [ grid_cv_df [ 'rank_test_score' ] == 1 ] # For example, we can see Logistic Regression's GridSearchCV # results like this. grid_cv_df = pd . DataFrame ( grids [ 0 ] . cv_results_ ) display ( grid_cv_df . loc [ grid_cv_df [ 'rank_test_score' ] == 1 ]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mean_fit_time std_fit_time mean_score_time std_score_time param_model__C param_model__penalty params split0_test_score split1_test_score split2_test_score split3_test_score split4_test_score mean_test_score std_test_score rank_test_score 8 0.931891 0.058794 0.002457 0.000387 0.359381 l1 {'model__C': 0.3593813663804626, 'model__penal... 0.997997 0.995547 0.997944 0.990132 0.995477 0.995419 0.002863 1 def return_grid_df ( grids : List [ model_selection . GridSearchCV ], ) -> Union [ pd . DataFrame , List [ model_selection . GridSearchCV ]]: \"\"\"Return a dataframe of the grids with shorted names. Args: grids (List[model_selection.GridSearchCV]): A list of GridSearchCV models that are tuned. Returns: grid_df, grids (Union[pd.DataFrame, List[model_selection.GridSearchCV]]): A dataframe of the grids with shorted names. \"\"\" def shorten_param ( param_name ): if \"__\" in param_name : return param_name . rsplit ( \"__\" , 1 )[ 1 ] return param_name grid_df = [] for grid in grids : model_name = grid . estimator [ \"model\" ] . __class__ . __name__ cv_results = pd . DataFrame ( grid . cv_results_ ) . sort_values ( \"mean_test_score\" , ascending = False ) # get the parameter names column_results = [ f \"param_ { name } \" for name in grid . param_grid . keys ()] column_results += [ \"mean_test_score\" , \"std_test_score\" , \"rank_test_score\" , ] cv_results = cv_results [ column_results ] cv_results = cv_results . rename ( shorten_param , axis = 1 ) cv_results [ \"model_name\" ] = model_name grid_df . append ( cv_results ) return grid_df , grids # grid_df and grids should necessarily be in the same sequence. # grid_df[0] == grids[0] in terms of model information, in this # case, the first index of both should be logistic regression. grid_df , grids = return_grid_df ( grids ) for model_df , grid in zip ( grid_df , grids ): best_hyperparams_df = model_df . iloc [[ 0 ]] model_name = best_hyperparams_df . model_name . unique ()[ 0 ] logger . info ( f \"Best hyperparameters found for { model_name } is as follows: \\n { grid . best_params_ } \" ) display ( best_hyperparams_df ) print () 2021-11-16,09:19:36 - Best hyperparameters found for LogisticRegression is as follows: {'model__C': 0.3593813663804626, 'model__penalty': 'l1'} 2021-11-16,09:19:36 - Best hyperparameters found for LogisticRegression is as follows: {'model__C': 0.3593813663804626, 'model__penalty': 'l1'} .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } penalty C mean_test_score std_test_score rank_test_score model_name 8 l1 0.359381 0.995419 0.002863 1 LogisticRegression 2021-11-16,09:19:36 - Best hyperparameters found for DecisionTreeClassifier is as follows: {'model__criterion': 'entropy', 'model__max_depth': 10, 'model__min_samples_leaf': 10} 2021-11-16,09:19:36 - Best hyperparameters found for DecisionTreeClassifier is as follows: {'model__criterion': 'entropy', 'model__max_depth': 10, 'model__min_samples_leaf': 10} .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } max_depth min_samples_leaf criterion mean_test_score std_test_score rank_test_score model_name 41 10 10 entropy 0.954515 0.015913 1 DecisionTreeClassifier 2021-11-16,09:19:37 - Best hyperparameters found for GradientBoostingClassifier is as follows: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__subsample': 0.5} 2021-11-16,09:19:37 - Best hyperparameters found for GradientBoostingClassifier is as follows: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__subsample': 0.5} .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } max_depth learning_rate subsample mean_test_score std_test_score rank_test_score model_name 1 3 0.1 0.5 0.991031 0.005869 1 GradientBoostingClassifier Success Our best performing set of hyperparameters for Logistic Regression {'model__C': 0.3593813663804626, 'model__penalty': 'l1'} gives rise to a mean cross validation score of \\(0.995419\\) , which is higher than the model with default hyperparameter scoring, \\(0.995\\) by a small margin. Not too surprising for Logistic Regression here since there aren't many things to tune, and should not see major improvements, but for Decesion Tree, it has increased from 0.907 to around 0.95, seeing quite a big jump with tuned params. DANGERRRRRRRRRRRRR I am being a bit hand wavy in terms of comparison here, I assumed THAT GridSearchCV used the exact same splitting strategy (yes it uses StratifiedKFold here) with the exact SEED/RANDOM_STATE , which I cannot promise as of now. Thus, a different splitting will, unfortunately, result in different results, although, I don't expect by a huge margin - so I think it is a no-go to compare like this. We can probably pass in a cv function into GridSearchCV to ensure seeding. This also highlights a problem that even K-fold splitting does not guarantee the reduction in variance. Room for Improvement Apart from the other methods to search for the optimal hyperparameters, we can also include preprocessing step as a tunable hyperparameter. More specifically, in our ReduceVIF() step, we hard coded two manual criterion in which the algorithm will stop; if the threshold reaches 10, or if the number of features removed hit 20; we can include them in the search space so we do not need to worry about how many features to remove! Model Persistence (Saving Models) Model Persistence We save our models using joblib and we can load it back any time. Note Save it to wandb or GCP storage to store models for better consistency. model_path = \"/content/\" def save_model ( grids : List [ Callable ], path : str ): \"\"\"Save a model to a file\"\"\" for grid in grids : model_name = grid . best_estimator_ [ \"model\" ] . __class__ . __name__ path_to_save = Path ( path , f \" { model_name } _grid.joblib\" ) # Dump to local path dump ( grid , Path ( path , path_to_save )) # Dump to wandb cloud # \"model.h5\" is saved in wandb.run.dir & will be uploaded at the end of training wandb . save ( os . path . join ( wandb . run . dir , path_to_save )) Save the model! Wandb We first see how we save and load using wandb. save_model ( grids , model_path ) \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\") \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\") \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\") logistic_path = \"LogisticRegression_grid.joblib\" # restore the model file \"model.h5\" from a specific run by user \"lavanyashukla\" # in project \"save_and_restore\" from run \"10pr4joa\" best_model = wandb . restore ( logistic_path ) # use the \"name\" attribute of the returned object # if your framework expects a filename, e.g. as in Keras # model.load_weights(best_model.name) Joblib We see how we use joblib to save and load. Load the model, and we can test it now if our loaded models is predicting correctly! logistic_grid = load ( \"/content/LogisticRegression_grid.joblib\" ) Great it seems to work! Sanity Check Note We just make sure our loaded weight from path is the same as the one we trained. We can easily compare predictions (or coefficients) by the following. load ( best_model . name ) . predict ( X_train ) . all () == logistic_grid . predict ( X_train ) . all () == grids [ 0 ] . predict ( X_train ) . all () True metrics . roc_auc_score ( y_train , logistic_grid . predict_proba ( X_train )[:, 1 ] ) == metrics . roc_auc_score ( y_train , grids [ 0 ] . predict_proba ( X_train )[:, 1 ] ) == metrics . roc_auc_score ( y_train , load ( best_model . name ) . predict_proba ( X_train )[:, 1 ] ) True Seems like the save and load method works perfectly. Warning Do not call this directly. grids [ 0 ] . best_estimator_ [ \"model\" ] . predict ( X_train ) This is because grids[0].best_estimator_[\"model\"] is only referring to the Logistic Regression Model WITHOUT the pipeline (preprocessing) steps. And hence will raise error if the preprocessing steps has feature selection. But the main idea is, be careful when using the above. # grids[0].best_estimator_[\"model\"].predict(X_train) Retrain using Hyperparameters Retraining Methods From the discussion 1 , my doubts are cleared. Quoting verbatim from the discussion, we have: K-folds cross validation was devised as a way to assess model performance using training data. A great paper on this from Sebastian Raschka is a must read https://arxiv.org/abs/1811.12808. You use K-folds cv to tune you model, then retrain on all training data with best hyperparamters found. However, once you have run K-fold cv, you get \\(K\\) trained models. Kagglers quickly found that ensembling these models was giving good results at zero computation cost, rather than having to retrain a model on full data. It soon became a very common practice. Takeway For small-medium datasets, after finding the best hyperparameters \\(G\\) , we use \\(G\\) in our model \\(h\\) to train on the whole dataset \\(\\mathcal{X}\\) again to get the fitted parameters of \\(h\\) . Then you use the newly gained fitted parameters to then evaluate on the Test Set . For large and computationally expensive datasets, when you finished your K-folds, say 5 folds, you get 5 \"different\" models, \\(h_{i}, i \\in {1, 2, 3, 4, 5}\\) , what you can do is to save the weights (or in normal ML, weights refer to the parameters gained), and evaluate on the test set for each of the five models, you then get 5 different test predictions, and a common practice is the do a simple mean of these 5 set of predictions. Retrain on K-Folds TODO: This should be easy for me as I dabbled more in Kaggle comp and are more familiar with this methodology. Retrain on the whole training set A common practice after the hyperparameter tuning phase is to retrain the model on the whole dataset \\(X_{\\text{train}}\\) where we will get the estimator's coefficients obtained from the retraining. This is actually already done as the scikit-learn's GridSearchCV has a parameter refit ; if we select it to be true, then after the model selection process is done (i.e. getting the best hyperparameters after cross validation with grid search), the grid search object will retrain on the whole \\(X_{\\text{train}}\\) with the best hyperparameters internally, and return us back an object in which we can call predict etc. Paranoia Alert However, to be extra careful, we can retrain manually using the best hyperparameters and check if scikit-learn is true to its documentation. We will just reconstruct the pipeline using the grid's best hyper parameters. We will then test if the retrained model's coefficients coincide with the grid's best estimator's coefficients. If there difference is 0, this means they are trained under the same circumstances and we can be sure that the refit parameter is behaving true to its words. grid_best_hyperparams = grid . best_params_ print ( grid_best_hyperparams ) -> { 'model__C' : 0.3593813663804626 , 'model__penalty' : 'l1' } retrain_logistic_pipeline = pipeline . Pipeline ( [ ( \"standardize\" , preprocessing . StandardScaler ()), ( \"remove_multicollinearity\" , ReduceVIF ( thresh = 10 )), ( \"model\" , linear_model . LogisticRegression ( C = 0.3593813663804626 , max_iter = 10000 , random_state = 1992 , solver = \"saga\" , penalty = \"l1\" , ), ), ] ) _ = retrain_logistic_pipeline . fit ( X_train , y_train ) logistic_grid = grids [ 0 ] coef_diff = ( retrain_logistic_pipeline [ \"model\" ] . coef_ - logistic_grid . best_estimator_ [ \"model\" ] . coef_ ) print ( \"...\" ) assert np . all ( coef_diff == 0 ) == True logger . info ( \"Retraining Assertion Passed!\" ) 2021-11-16,09:19:38 - Retraining Assertion Passed! 2021-11-16,09:19:38 - Retraining Assertion Passed! ... https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/275883 \u21a9","title":"Modelling (Model Selection)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/#dependencies-and-configuration","text":"%% capture ! pip install - q wandb # !pip install -q shap ! pip install - q mlxtend == 0.19.0 ! pip install - q statsmodels == 0.13.1 # !pip install gcloud == 0.18.3 import wandb wandb . login () \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect. True import copy import csv import logging import os import random from dataclasses import asdict , dataclass , field from functools import wraps from pathlib import Path from time import time from typing import Any , Callable , Dict , List , Optional , Tuple , Union import matplotlib.pyplot as plt import mlxtend import numpy as np import pandas as pd import seaborn as sns from joblib import dump , load from mlxtend.evaluate import bias_variance_decomp , paired_ttest_5x2cv from scipy import stats from sklearn import ( base , decomposition , dummy , ensemble , feature_selection , linear_model , metrics , model_selection , neighbors , pipeline , preprocessing , svm , tree ) from statsmodels.regression.linear_model import OLS","title":"Dependencies and Configuration"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/#utils-and-configurations","text":"@dataclass class config : raw_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/raw/data.csv\" processed_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/processed.csv\" df_folds : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/df_folds.csv\" train_size : float = 0.9 seed : int = 1992 num_folds : int = 5 cv_schema : str = \"StratifiedKFold\" classification_type : str = \"binary\" target_col : List [ str ] = field ( default_factory = lambda : [ \"diagnosis\" ]) unwanted_cols : List [ str ] = field ( default_factory = lambda : [ \"id\" , \"Unnamed: 32\" ]) # Plotting colors : List [ str ] = field ( default_factory = lambda : [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ]) cmap_reversed = plt . cm . get_cmap ( 'mako_r' ) def to_dict ( self ) -> Dict [ str , Any ]: \"\"\"Convert the config object to a dictionary. Returns: Dict: The config object as a dictionary. \"\"\" return asdict ( self ) # spot_checking_boxplot = \"../data/images/spot_checking_boxplot.png\" # oof_confusion_matrix = \"../data/images/oof_confusion_matrix.png\" # final_train_confusion_matrix = \"../data/images/final_train_confusion_matrix.png\" # precision_recall_threshold_plot = \"../data/images/precision_recall_threshold_plot.png\" # roc_plot = \"../data/images/roc_plot.png\" # feature_importance = \"../data/images/feature_importance.png\" def set_seeds ( seed : int = 1234 ) -> None : \"\"\"Set seeds for reproducibility.\"\"\" np . random . seed ( seed ) random . seed ( seed ) def init_logger ( log_file : str = \"info.log\" ): \"\"\" Initialize logger. \"\"\" logger = logging . getLogger ( __name__ ) logger . setLevel ( logging . INFO ) stream_handler = logging . StreamHandler () stream_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) file_handler = logging . FileHandler ( filename = log_file ) file_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) logger . addHandler ( stream_handler ) logger . addHandler ( file_handler ) return logger # Utils functions that we need def variance_inflation_factor ( exog , idx_kept , vif_idx ): \"\"\"Compute VIF for one feature. Args: exog (np.ndarray): Observations idx_kept (List[int]): Indices of features to consider vif_idx (int): Index of feature for which to compute VIF Returns: float: VIF for the selected feature \"\"\" exog = np . asarray ( exog ) x_i = exog [:, vif_idx ] mask = [ col for col in idx_kept if col != vif_idx ] x_noti = exog [:, mask ] r_squared_i = OLS ( x_i , x_noti ) . fit () . rsquared vif = 1. / ( 1. - r_squared_i ) return vif class ReduceVIF ( base . BaseEstimator , base . TransformerMixin ): \"\"\"The base of the class structure is implemented in https://www.kaggle.com/ffisegydd/sklearn-multicollinearity-class; I heavily modified the class such that it can take in numpy arrays and correctly implemented the fit and transform method. \"\"\" def __init__ ( self , thresh = 10 , max_drop = 20 ): self . thresh = thresh self . max_drop = max_drop self . column_indices_kept_ = [] self . feature_names_kept_ = None def reset ( self ): \"\"\"Resets the state of predictor columns after each fold.\"\"\" self . column_indices_kept_ = [] self . feature_names_kept_ = None def fit ( self , X , y = None ): \"\"\"Fits the Recursive VIF on the training folds and save the selected feature names in self.feature_names Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" self . column_indices_kept_ , self . feature_names_kept_ = self . calculate_vif ( X ) return self def transform ( self , X , y = None ): \"\"\"Transforms the Validation Set according to the selected feature names. Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" return X [:, self . column_indices_kept_ ] def calculate_vif ( self , X : Union [ np . ndarray , pd . DataFrame ]): \"\"\"Implements a VIF function that recursively eliminates features. Args: X (Union[np.ndarray, pd.DataFrame]): [description] Returns: [type]: [description] \"\"\" feature_names = None column_indices_kept = list ( range ( X . shape [ 1 ])) if isinstance ( X , pd . DataFrame ): feature_names = X . columns dropped = True count = 0 while dropped and count <= self . max_drop : dropped = False max_vif , max_vif_col = None , None for col in column_indices_kept : vif = variance_inflation_factor ( X , column_indices_kept , col ) if max_vif is None or vif > max_vif : max_vif = vif max_vif_col = col if max_vif > self . thresh : # print(f\"Dropping {max_vif_col} with vif={max_vif}\") column_indices_kept . remove ( max_vif_col ) if feature_names is not None : feature_names . pop ( max_vif_col ) dropped = True count += 1 return column_indices_kept , feature_names def prepare_y ( y : np . ndarray ) -> np . ndarray : \"\"\"Prepare the target variable for the model. If Binary Classification, we need to ravel the array to 1d. Args: y (np.ndarray): Target variable. Returns: np.ndarray: Transformed Target variable. \"\"\" return y . ravel () if config . classification_type == \"binary\" else y config = config () basic_config : Dict = config . to_dict () # train_config: Dict = Train().to_dict() global_config : Dict = dict ( basic = basic_config ) # We can log multiple dict under global_config - in wandb UI, it will show as basic. and train. to show which dict it is referring to. run = wandb . init ( project = \"bcw\" , name = \"classification\" , config = global_config ) # set logger logger = init_logger () # set seeding for reproducibility _ = set_seeds ( seed = config . seed ) # read data df_folds = pd . read_csv ( config . df_folds ) # Assign predictors and target accordingly predictor_cols = df_folds . columns . to_list ()[: - 2 ] target_col = config . target_col","title":"Utils and Configurations"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/#model-selection-hyperparameter-tuning-with-gridsearchcv","text":"Hyperparameter Tuning We have done a quick spot checking on algorithms and realized that LogisticRegression is doing well for this task. For this purpose, I will just perform hyperparameter tuning on this single algorithm. However, in practice and if resources are allowed, I will also tune other models such as RandomForest() , or gradient boosting algorithms such as XGBoost , as I believe they will perform no worse than our Logistic Regression model given the right hyperparameters. Grid Search is the Gwei? Meh! We will use an old-fashioned way to search for hyperparameters, which is brute force method. The time complexity of Grid Search is high and if you have many hyperparameters to tune, I recommend trying out Random Grid Search or libraries like Optuna that uses Bayesian Optimization. TODO Try to code up your own GridSearchCV to have maximum flexibility.","title":"Model Selection: Hyperparameter Tuning with GridSearchCV"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/#make-finetuning-pipeline","text":"The following make_finetuning_pipeline does exactly the same thing is as make_pipeline earlier. The only difference is we can pass in flexible list of steps to the pipeline from outside. def make_finetuning_pipeline ( model : Callable , steps : List [ Tuple [ str , Callable ]] ) -> pipeline . Pipeline : \"\"\"Return a pipeline that can be used for finetuning. Args: model (Callable): A model with default parameters. steps (List[Tuple[str, Callable]]): A list of preprocessing steps to pass in Pipeline object. Returns: Pipeline: Returns a pipeline that can be used for finetuning. \"\"\" return pipeline . Pipeline ([ * steps , ( \"model\" , model )]) # TODO: Make a class to hold pipelines? # class MakePipeline: # def __init__(self, estimator: Callable, steps: List[Callable]): # pass # def spot_checking_pipeline(): # pass # def fine_tuning_pipeline(): # pass finetuning_pipeline_steps = [ # standardization ( \"standardize\" , preprocessing . StandardScaler ()), # reduce VIF ( \"remove_multicollinearity\" , ReduceVIF ( thresh = 10 )) ]","title":"Make Finetuning Pipeline"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/#search-space","text":"Run our hyperparameter search with cross-validation. For example, our param_grid has \\(2 \\times 10 = 20\\) combinations, and our cross validation has 5 folds, then there will be a total of 100 fits. Below details the pseudo code of what happens under the hood: Define \\(G\\) as the set of combination of hyperparamters. Define number of splits to be \\(K\\) . For each set of hyperparameter \\(z \\in Z\\) : for fold \\(j\\) in K: Set \\(F_{\\text{train}}=\\bigcup\\limits_{i\\neq k}^{K} F_{i}\\) Set \\(F_{\\text{val}} = F_{j}\\) as the validation set Perform Standard Scaling on \\(F_{\\text{train}}\\) and find the mean and std Perform VIF recursively on \\(F_{\\text{train}}\\) and find the selected features Transform \\(F_{\\text{val}}\\) using the mean and std found using \\(F_{\\text{train}}\\) Transform \\(F_{\\text{val}}\\) to have only the selected features from \\(F_{\\text{train}}\\) Train and fit on \\(F_{\\text{train}}\\) Evaluate the fitted parameters on \\(F_{\\text{val}}\\) to obtain \\(\\mathcal{M}\\) @dataclass class ModelForTuning : model : Callable param_grid : Dict Define our search space for the hyperparameters: logistic_r_param_grid = { model__penalty = [ \"l1\" , \"l2\" ], model__C = np . logspace ( - 4 , 4 , 10 )} We conveniently use dataclass to act as a medium so we can pass in model and param_grid independently for each model. We then collate them into a list of ModelForTuning object. models_list = [ ModelForTuning ( model = linear_model . LogisticRegression ( solver = \"saga\" , random_state = config . seed , max_iter = 10000 , n_jobs =- 1 , fit_intercept = True , ), param_grid = dict ( model__penalty = [ \"l1\" , \"l2\" ], model__C = np . logspace ( - 4 , 4 , 10 ), ), ), ModelForTuning ( model = tree . DecisionTreeClassifier ( random_state = config . seed ), param_grid = dict ( model__max_depth = [ 2 , 3 , 5 , 10 , 20 ], model__min_samples_leaf = [ 5 , 10 , 20 , 50 , 100 ], model__criterion = [ \"gini\" , \"entropy\" ], ), ), ModelForTuning ( model = ensemble . GradientBoostingClassifier ( n_estimators = 100 ), param_grid = dict ( model__max_depth = [ 3 , 6 ], model__learning_rate = [ 0.1 , 0.05 ], model__subsample = [ 1 , 0.5 , ], ), ), ] def optimize_models ( models_list : List [ ModelForTuning ], X_train : np . ndarray , y_train : np . ndarray , scorer : Union [ str , Callable ], steps : List [ Tuple [ str , Callable ]], ) -> List [ Callable ]: \"\"\"Optimize models in models_list using X_train and y_train. We are using GridSearchCV to find the best parameters for each model. Consider using Optuna for hyperparameter optimization (or wandb for hyperparameter optimization). Args: models_list (List[ModelForTuning]): List of models to optimize. X_train (np.ndarray): X_train data. y_train (np.ndarray): y_train data. Returns: grids (List[Callable]): List of optimized models. \"\"\" # @ TODO: make a scoring list to pass in so we can evaluate multiple metrics. grids = [ model_selection . GridSearchCV ( make_finetuning_pipeline ( model . model , steps ), param_grid = model . param_grid , cv = 5 , refit = True , verbose = 1 , scoring = scorer , n_jobs =- 1 , ) for model in models_list ] for grid in grids : grid . fit ( X_train , y_train ) return grids roc_auc_scorer = \"roc_auc_ovr\" # Unsure why this gives much lower score - to investigate # metrics.make_scorer(metrics.roc_auc_score, average=\"macro\", multi_class='ovr') X_train , y_train = df_folds [ predictor_cols ] . values , df_folds [ target_col ] . values y_train = prepare_y ( y_train ) grids = optimize_models ( models_list , X_train , y_train , scorer = roc_auc_scorer , steps = finetuning_pipeline_steps ) Fitting 5 folds for each of 20 candidates, totalling 100 fits Fitting 5 folds for each of 50 candidates, totalling 250 fits Fitting 5 folds for each of 8 candidates, totalling 40 fits # The above optimize code is equivalent to the below, for better readability # pipeline_logistic = make_finetuning_pipeline( # linear_model.LogisticRegression( # solver=\"saga\", random_state=config.seed, max_iter=10000, n_jobs=None, fit_intercept=True # ), steps=steps # ) # param_grid = dict( # model__penalty=[\"l1\", \"l2\"], # model__C=np.logspace(-4, 4, 10), # ) # grid = model_selection.GridSearchCV(pipeline_logistic, param_grid=param_grid, cv=5, refit=True, verbose=3, scoring = \"roc_auc\") # _ = grid.fit(X_train, y_train) We can save our results in a dataframe, we will also look at the top performing hyperparameter by querying the below: grid_cv_df = pd . DataFrame ( grid . cv_results_ ) grid_cv_df . loc [ grid_cv_df [ 'rank_test_score' ] == 1 ] # For example, we can see Logistic Regression's GridSearchCV # results like this. grid_cv_df = pd . DataFrame ( grids [ 0 ] . cv_results_ ) display ( grid_cv_df . loc [ grid_cv_df [ 'rank_test_score' ] == 1 ]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mean_fit_time std_fit_time mean_score_time std_score_time param_model__C param_model__penalty params split0_test_score split1_test_score split2_test_score split3_test_score split4_test_score mean_test_score std_test_score rank_test_score 8 0.931891 0.058794 0.002457 0.000387 0.359381 l1 {'model__C': 0.3593813663804626, 'model__penal... 0.997997 0.995547 0.997944 0.990132 0.995477 0.995419 0.002863 1 def return_grid_df ( grids : List [ model_selection . GridSearchCV ], ) -> Union [ pd . DataFrame , List [ model_selection . GridSearchCV ]]: \"\"\"Return a dataframe of the grids with shorted names. Args: grids (List[model_selection.GridSearchCV]): A list of GridSearchCV models that are tuned. Returns: grid_df, grids (Union[pd.DataFrame, List[model_selection.GridSearchCV]]): A dataframe of the grids with shorted names. \"\"\" def shorten_param ( param_name ): if \"__\" in param_name : return param_name . rsplit ( \"__\" , 1 )[ 1 ] return param_name grid_df = [] for grid in grids : model_name = grid . estimator [ \"model\" ] . __class__ . __name__ cv_results = pd . DataFrame ( grid . cv_results_ ) . sort_values ( \"mean_test_score\" , ascending = False ) # get the parameter names column_results = [ f \"param_ { name } \" for name in grid . param_grid . keys ()] column_results += [ \"mean_test_score\" , \"std_test_score\" , \"rank_test_score\" , ] cv_results = cv_results [ column_results ] cv_results = cv_results . rename ( shorten_param , axis = 1 ) cv_results [ \"model_name\" ] = model_name grid_df . append ( cv_results ) return grid_df , grids # grid_df and grids should necessarily be in the same sequence. # grid_df[0] == grids[0] in terms of model information, in this # case, the first index of both should be logistic regression. grid_df , grids = return_grid_df ( grids ) for model_df , grid in zip ( grid_df , grids ): best_hyperparams_df = model_df . iloc [[ 0 ]] model_name = best_hyperparams_df . model_name . unique ()[ 0 ] logger . info ( f \"Best hyperparameters found for { model_name } is as follows: \\n { grid . best_params_ } \" ) display ( best_hyperparams_df ) print () 2021-11-16,09:19:36 - Best hyperparameters found for LogisticRegression is as follows: {'model__C': 0.3593813663804626, 'model__penalty': 'l1'} 2021-11-16,09:19:36 - Best hyperparameters found for LogisticRegression is as follows: {'model__C': 0.3593813663804626, 'model__penalty': 'l1'} .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } penalty C mean_test_score std_test_score rank_test_score model_name 8 l1 0.359381 0.995419 0.002863 1 LogisticRegression 2021-11-16,09:19:36 - Best hyperparameters found for DecisionTreeClassifier is as follows: {'model__criterion': 'entropy', 'model__max_depth': 10, 'model__min_samples_leaf': 10} 2021-11-16,09:19:36 - Best hyperparameters found for DecisionTreeClassifier is as follows: {'model__criterion': 'entropy', 'model__max_depth': 10, 'model__min_samples_leaf': 10} .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } max_depth min_samples_leaf criterion mean_test_score std_test_score rank_test_score model_name 41 10 10 entropy 0.954515 0.015913 1 DecisionTreeClassifier 2021-11-16,09:19:37 - Best hyperparameters found for GradientBoostingClassifier is as follows: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__subsample': 0.5} 2021-11-16,09:19:37 - Best hyperparameters found for GradientBoostingClassifier is as follows: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__subsample': 0.5} .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } max_depth learning_rate subsample mean_test_score std_test_score rank_test_score model_name 1 3 0.1 0.5 0.991031 0.005869 1 GradientBoostingClassifier Success Our best performing set of hyperparameters for Logistic Regression {'model__C': 0.3593813663804626, 'model__penalty': 'l1'} gives rise to a mean cross validation score of \\(0.995419\\) , which is higher than the model with default hyperparameter scoring, \\(0.995\\) by a small margin. Not too surprising for Logistic Regression here since there aren't many things to tune, and should not see major improvements, but for Decesion Tree, it has increased from 0.907 to around 0.95, seeing quite a big jump with tuned params. DANGERRRRRRRRRRRRR I am being a bit hand wavy in terms of comparison here, I assumed THAT GridSearchCV used the exact same splitting strategy (yes it uses StratifiedKFold here) with the exact SEED/RANDOM_STATE , which I cannot promise as of now. Thus, a different splitting will, unfortunately, result in different results, although, I don't expect by a huge margin - so I think it is a no-go to compare like this. We can probably pass in a cv function into GridSearchCV to ensure seeding. This also highlights a problem that even K-fold splitting does not guarantee the reduction in variance. Room for Improvement Apart from the other methods to search for the optimal hyperparameters, we can also include preprocessing step as a tunable hyperparameter. More specifically, in our ReduceVIF() step, we hard coded two manual criterion in which the algorithm will stop; if the threshold reaches 10, or if the number of features removed hit 20; we can include them in the search space so we do not need to worry about how many features to remove!","title":"Search Space"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/#model-persistence-saving-models","text":"Model Persistence We save our models using joblib and we can load it back any time. Note Save it to wandb or GCP storage to store models for better consistency. model_path = \"/content/\" def save_model ( grids : List [ Callable ], path : str ): \"\"\"Save a model to a file\"\"\" for grid in grids : model_name = grid . best_estimator_ [ \"model\" ] . __class__ . __name__ path_to_save = Path ( path , f \" { model_name } _grid.joblib\" ) # Dump to local path dump ( grid , Path ( path , path_to_save )) # Dump to wandb cloud # \"model.h5\" is saved in wandb.run.dir & will be uploaded at the end of training wandb . save ( os . path . join ( wandb . run . dir , path_to_save )) Save the model!","title":"Model Persistence (Saving Models)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/#wandb","text":"We first see how we save and load using wandb. save_model ( grids , model_path ) \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\") \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\") \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\") logistic_path = \"LogisticRegression_grid.joblib\" # restore the model file \"model.h5\" from a specific run by user \"lavanyashukla\" # in project \"save_and_restore\" from run \"10pr4joa\" best_model = wandb . restore ( logistic_path ) # use the \"name\" attribute of the returned object # if your framework expects a filename, e.g. as in Keras # model.load_weights(best_model.name)","title":"Wandb"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/#joblib","text":"We see how we use joblib to save and load. Load the model, and we can test it now if our loaded models is predicting correctly! logistic_grid = load ( \"/content/LogisticRegression_grid.joblib\" ) Great it seems to work!","title":"Joblib"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/#sanity-check","text":"Note We just make sure our loaded weight from path is the same as the one we trained. We can easily compare predictions (or coefficients) by the following. load ( best_model . name ) . predict ( X_train ) . all () == logistic_grid . predict ( X_train ) . all () == grids [ 0 ] . predict ( X_train ) . all () True metrics . roc_auc_score ( y_train , logistic_grid . predict_proba ( X_train )[:, 1 ] ) == metrics . roc_auc_score ( y_train , grids [ 0 ] . predict_proba ( X_train )[:, 1 ] ) == metrics . roc_auc_score ( y_train , load ( best_model . name ) . predict_proba ( X_train )[:, 1 ] ) True Seems like the save and load method works perfectly. Warning Do not call this directly. grids [ 0 ] . best_estimator_ [ \"model\" ] . predict ( X_train ) This is because grids[0].best_estimator_[\"model\"] is only referring to the Logistic Regression Model WITHOUT the pipeline (preprocessing) steps. And hence will raise error if the preprocessing steps has feature selection. But the main idea is, be careful when using the above. # grids[0].best_estimator_[\"model\"].predict(X_train)","title":"Sanity Check"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/#retrain-using-hyperparameters","text":"Retraining Methods From the discussion 1 , my doubts are cleared. Quoting verbatim from the discussion, we have: K-folds cross validation was devised as a way to assess model performance using training data. A great paper on this from Sebastian Raschka is a must read https://arxiv.org/abs/1811.12808. You use K-folds cv to tune you model, then retrain on all training data with best hyperparamters found. However, once you have run K-fold cv, you get \\(K\\) trained models. Kagglers quickly found that ensembling these models was giving good results at zero computation cost, rather than having to retrain a model on full data. It soon became a very common practice. Takeway For small-medium datasets, after finding the best hyperparameters \\(G\\) , we use \\(G\\) in our model \\(h\\) to train on the whole dataset \\(\\mathcal{X}\\) again to get the fitted parameters of \\(h\\) . Then you use the newly gained fitted parameters to then evaluate on the Test Set . For large and computationally expensive datasets, when you finished your K-folds, say 5 folds, you get 5 \"different\" models, \\(h_{i}, i \\in {1, 2, 3, 4, 5}\\) , what you can do is to save the weights (or in normal ML, weights refer to the parameters gained), and evaluate on the test set for each of the five models, you then get 5 different test predictions, and a common practice is the do a simple mean of these 5 set of predictions.","title":"Retrain using Hyperparameters"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/#retrain-on-k-folds","text":"TODO: This should be easy for me as I dabbled more in Kaggle comp and are more familiar with this methodology.","title":"Retrain on K-Folds"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/#retrain-on-the-whole-training-set","text":"A common practice after the hyperparameter tuning phase is to retrain the model on the whole dataset \\(X_{\\text{train}}\\) where we will get the estimator's coefficients obtained from the retraining. This is actually already done as the scikit-learn's GridSearchCV has a parameter refit ; if we select it to be true, then after the model selection process is done (i.e. getting the best hyperparameters after cross validation with grid search), the grid search object will retrain on the whole \\(X_{\\text{train}}\\) with the best hyperparameters internally, and return us back an object in which we can call predict etc. Paranoia Alert However, to be extra careful, we can retrain manually using the best hyperparameters and check if scikit-learn is true to its documentation. We will just reconstruct the pipeline using the grid's best hyper parameters. We will then test if the retrained model's coefficients coincide with the grid's best estimator's coefficients. If there difference is 0, this means they are trained under the same circumstances and we can be sure that the refit parameter is behaving true to its words. grid_best_hyperparams = grid . best_params_ print ( grid_best_hyperparams ) -> { 'model__C' : 0.3593813663804626 , 'model__penalty' : 'l1' } retrain_logistic_pipeline = pipeline . Pipeline ( [ ( \"standardize\" , preprocessing . StandardScaler ()), ( \"remove_multicollinearity\" , ReduceVIF ( thresh = 10 )), ( \"model\" , linear_model . LogisticRegression ( C = 0.3593813663804626 , max_iter = 10000 , random_state = 1992 , solver = \"saga\" , penalty = \"l1\" , ), ), ] ) _ = retrain_logistic_pipeline . fit ( X_train , y_train ) logistic_grid = grids [ 0 ] coef_diff = ( retrain_logistic_pipeline [ \"model\" ] . coef_ - logistic_grid . best_estimator_ [ \"model\" ] . coef_ ) print ( \"...\" ) assert np . all ( coef_diff == 0 ) == True logger . info ( \"Retraining Assertion Passed!\" ) 2021-11-16,09:19:38 - Retraining Assertion Passed! 2021-11-16,09:19:38 - Retraining Assertion Passed! ... https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/275883 \u21a9","title":"Retrain on the whole training set"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%208%20-%20Modelling%20%28Model%20Evaluation%20and%20Interpretation%29/","text":"Stage 8: Model Evaluation by Hongnan Gao Dependencies and Configuration %% capture ! pip install - q wandb # !pip install -q shap ! pip install - q mlxtend == 0.19.0 ! pip install - q statsmodels == 0.13.1 # !pip install gcloud == 0.18.3 import wandb wandb . login () <IPython.core.display.Javascript object> \u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc True import copy import csv import logging import os import random from dataclasses import asdict , dataclass , field from functools import wraps from pathlib import Path from time import time from typing import Any , Callable , Dict , List , Optional , Tuple , Union import matplotlib.pyplot as plt import mlxtend import numpy as np import pandas as pd import seaborn as sns from joblib import dump , load from mlxtend.evaluate import bias_variance_decomp , paired_ttest_5x2cv from scipy import stats from sklearn import ( base , decomposition , dummy , ensemble , feature_selection , linear_model , metrics , model_selection , neighbors , pipeline , preprocessing , svm , tree ) from statsmodels.regression.linear_model import OLS Utils and Configurations We need import ReduceVIF if not we cannot call our model. @dataclass class config : raw_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/raw/data.csv\" processed_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/processed.csv\" df_folds : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/df_folds.csv\" train_size : float = 0.9 seed : int = 1992 num_folds : int = 5 cv_schema : str = \"StratifiedKFold\" classification_type : str = \"binary\" target_col : List [ str ] = field ( default_factory = lambda : [ \"diagnosis\" ]) unwanted_cols : List [ str ] = field ( default_factory = lambda : [ \"id\" , \"Unnamed: 32\" ] ) # Plotting colors : List [ str ] = field ( default_factory = lambda : [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ] ) cmap_reversed = plt . cm . get_cmap ( \"mako_r\" ) def to_dict ( self ) -> Dict [ str , Any ]: \"\"\"Convert the config object to a dictionary. Returns: Dict: The config object as a dictionary. \"\"\" return asdict ( self ) # spot_checking_boxplot = \"../data/images/spot_checking_boxplot.png\" # oof_confusion_matrix = \"../data/images/oof_confusion_matrix.png\" # final_train_confusion_matrix = \"../data/images/final_train_confusion_matrix.png\" # precision_recall_threshold_plot = \"../data/images/precision_recall_threshold_plot.png\" # roc_plot = \"../data/images/roc_plot.png\" # feature_importance = \"../data/images/feature_importance.png\" def set_seeds ( seed : int = 1234 ) -> None : \"\"\"Set seeds for reproducibility.\"\"\" np . random . seed ( seed ) random . seed ( seed ) def init_logger ( log_file : str = \"info.log\" ): \"\"\" Initialize logger. \"\"\" logger = logging . getLogger ( __name__ ) logger . setLevel ( logging . INFO ) stream_handler = logging . StreamHandler () stream_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) file_handler = logging . FileHandler ( filename = log_file ) file_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) logger . addHandler ( stream_handler ) logger . addHandler ( file_handler ) return logger # Utils functions that we need def variance_inflation_factor ( exog , idx_kept , vif_idx ): \"\"\"Compute VIF for one feature. Args: exog (np.ndarray): Observations idx_kept (List[int]): Indices of features to consider vif_idx (int): Index of feature for which to compute VIF Returns: float: VIF for the selected feature \"\"\" exog = np . asarray ( exog ) x_i = exog [:, vif_idx ] mask = [ col for col in idx_kept if col != vif_idx ] x_noti = exog [:, mask ] r_squared_i = OLS ( x_i , x_noti ) . fit () . rsquared vif = 1. / ( 1. - r_squared_i ) return vif class ReduceVIF ( base . BaseEstimator , base . TransformerMixin ): \"\"\"The base of the class structure is implemented in https://www.kaggle.com/ffisegydd/sklearn-multicollinearity-class; I heavily modified the class such that it can take in numpy arrays and correctly implemented the fit and transform method. \"\"\" def __init__ ( self , thresh = 10 , max_drop = 20 ): self . thresh = thresh self . max_drop = max_drop self . column_indices_kept_ = [] self . feature_names_kept_ = None def reset ( self ): \"\"\"Resets the state of predictor columns after each fold.\"\"\" self . column_indices_kept_ = [] self . feature_names_kept_ = None def fit ( self , X , y = None ): \"\"\"Fits the Recursive VIF on the training folds and save the selected feature names in self.feature_names Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" self . column_indices_kept_ , self . feature_names_kept_ = self . calculate_vif ( X ) return self def transform ( self , X , y = None ): \"\"\"Transforms the Validation Set according to the selected feature names. Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" return X [:, self . column_indices_kept_ ] def calculate_vif ( self , X : Union [ np . ndarray , pd . DataFrame ]): \"\"\"Implements a VIF function that recursively eliminates features. Args: X (Union[np.ndarray, pd.DataFrame]): [description] Returns: [type]: [description] \"\"\" feature_names = None column_indices_kept = list ( range ( X . shape [ 1 ])) if isinstance ( X , pd . DataFrame ): feature_names = X . columns dropped = True count = 0 while dropped and count <= self . max_drop : dropped = False max_vif , max_vif_col = None , None for col in column_indices_kept : vif = variance_inflation_factor ( X , column_indices_kept , col ) if max_vif is None or vif > max_vif : max_vif = vif max_vif_col = col if max_vif > self . thresh : # print(f\"Dropping {max_vif_col} with vif={max_vif}\") column_indices_kept . remove ( max_vif_col ) if feature_names is not None : feature_names . pop ( max_vif_col ) dropped = True count += 1 return column_indices_kept , feature_names def prepare_y ( y : np . ndarray ) -> np . ndarray : \"\"\"Prepare the target variable for the model. If Binary Classification, we need to ravel the array to 1d. Args: y (np.ndarray): Target variable. Returns: np.ndarray: Transformed Target variable. \"\"\" return y . ravel () if config . classification_type == \"binary\" else y config = config () logger = init_logger () # set seeding for reproducibility _ = set_seeds ( seed = config . seed ) # read data df_folds = pd . read_csv ( config . df_folds ) # Assign predictors and target accordingly predictor_cols = df_folds . columns . to_list ()[: - 2 ] target_col = config . target_col Resume Run and Load Weights Here we resume wandb using its run_id and then load the model's weights. # Resume run by getting run_id # TODO: return id as an artifact so we can get it easily. run = wandb . init ( project = \"bcw\" , name = \"classification\" , resume = True , id = '3qh37hoo' ) \u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mreighns\u001b[0m (use `wandb login --relogin` to force relogin) Resuming run classification to Weights & Biases ( docs ). logistic_path = \"LogisticRegression_grid.joblib\" dt_path = \"DecisionTreeClassifier_grid.joblib\" gdb_path = \"GradientBoostingClassifier_grid.joblib\" logistic_best_weight = wandb . restore ( logistic_path ) logistic_best_model = load ( logistic_best_weight . name ) \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout. \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout. Interpretation of Results Interpretation of Coefficients As shown in the figure below, all else being equal, for every square unit increase in mean cell area, the odds of the tumor being malignant increases by a factor of \\(e^{1.43} = 4.19\\) . The variation (standard error) of the characteristics of cells also are deemed important by the model, for example, area se played an important role in determining whether a cell is malignant; intuitively, if some cells are noticably larger than the rest, then it is also a good indicator of malignancy. selected_features_by_vif_index = logistic_best_model . best_estimator_ [ 'remove_multicollinearity' ] . column_indices_kept_ selected_feature_names = np . asarray ( predictor_cols )[ selected_features_by_vif_index ] selected_features_coefficients = logistic_best_model . best_estimator_ [ 'model' ] . coef_ . flatten () # assertion #assert grid.best_estimator_['remove_multicollinearity'].feature_names_ == retrain_pipeline['remove_multicollinearity'].feature_names_ fig , ax = plt . subplots ( figsize = ( 15 , 15 )) # .abs() _ = pd . Series ( selected_features_coefficients , index = selected_feature_names ) . sort_values () . plot ( ax = ax , kind = 'barh' ) # fig.savefig(config.feature_importance, format=\"png\", dpi=300) Interpretation of Metric Scores on Train Set We are also interested in choosing an optimal threshold for the model such that it gives the lowest recall, or False Negatives. We note that the default threshold when calling predict() from a model is \\(0.5\\) . In this section, we will explore one way to get the best tradeoff we can when choosing a high recall, while maintaining a reasonable score for precision. def evaluate_train_test_set ( estimator : Callable , X : Union [ pd . DataFrame , np . ndarray ], y : Union [ pd . DataFrame , np . ndarray ] ) -> Dict [ str , Union [ float , np . ndarray ]]: \"\"\"This function takes in X and y and returns a dictionary of scores. Args: estimator (Callable): [description] X (Union[pd.DataFrame, np.ndarray]): [description] y (Union[pd.DataFrame, np.ndarray]): [description] Returns: Dict[str, Union[float, np.ndarray]]: [description] \"\"\" test_results = {} y_pred = estimator . predict ( X ) # This is the probability array of class 1 (malignant) y_prob = estimator . predict_proba ( X )[:, 1 ] test_brier = metrics . brier_score_loss ( y , y_prob ) test_roc = metrics . roc_auc_score ( y , y_prob ) test_results [ \"brier\" ] = test_brier test_results [ \"roc\" ] = test_roc test_results [ \"y\" ] = np . asarray ( y ) . flatten () test_results [ \"y_pred\" ] = y_pred . flatten () test_results [ \"y_prob\" ] = y_prob . flatten () return test_results def plot_precision_recall_vs_threshold ( precisions , recalls , thresholds ): \"\"\" Modified from: Hands-On Machine learning with Scikit-Learn and TensorFlow; p.89 and courtesy of https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65 \"\"\" plt . figure ( figsize = ( 8 , 8 )) plt . title ( \"Precision and Recall Scores as a function of the decision threshold\" ) plt . plot ( thresholds , precisions [: - 1 ], \"b--\" , label = \"Precision\" ) plt . plot ( thresholds , recalls [: - 1 ], \"g-\" , label = \"Recall\" ) plt . ylabel ( \"Score\" ) plt . xlabel ( \"Decision Threshold\" ) plt . legend ( loc = 'best' ) plt . savefig ( config . precision_recall_threshold_plot , format = \"png\" , dpi = 300 ) def plot_roc_curve ( fpr , tpr , label = None ): \"\"\" The ROC curve, modified from Hands-On Machine learning with Scikit-Learn and TensorFlow; p.91 and courtesy of https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65 \"\"\" plt . figure ( figsize = ( 8 , 8 )) plt . title ( 'ROC Curve' ) plt . plot ( fpr , tpr , linewidth = 2 , label = label ) plt . plot ([ 0 , 1 ], [ 0 , 1 ], 'k--' ) plt . axis ([ - 0.005 , 1 , 0 , 1.005 ]) plt . xticks ( np . arange ( 0 , 1 , 0.05 ), rotation = 90 ) plt . xlabel ( \"False Positive Rate\" ) plt . ylabel ( \"True Positive Rate (Recall)\" ) plt . legend ( loc = 'best' ) plt . savefig ( config . roc_plot , format = \"png\" , dpi = 300 ) def adjusted_classes ( y_scores , t ): \"\"\" This function adjusts class predictions based on the prediction threshold (t). Will only work for binary classification problems. and courtesy of https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65 \"\"\" return [ 1 if y >= t else 0 for y in y_scores ] The plots below show the tradeoffs between precision and recall, recall and false positive rate. The confusion matrix on the train set tells us that there is still more false negatives than false positives. We can choose a particular threshold in order to minimize false negatives, at some expense of false positive. X_train , y_train = df_folds [ predictor_cols ] . values , df_folds [ target_col ] . values y_train = prepare_y ( y_train ) train_results = evaluate_train_test_set ( logistic_best_model , X_train , y_train ) def plot_confusion_matrix ( y_true : np . ndarray , y_pred : np . ndarray , title : str , labels : List [ str ], tick_labels : List [ str ], ) -> None : \"\"\"Plots a Binary Confusion Matrix. Args: y_true (np.ndarray): the actual labels. y_pred (np.ndarray): the predicted labels. title (str): the title of the plot. tick_labels (List[str]): The labels for the ticks. \"\"\" # Unravel into tn, fp, fn and tp tn , fp , fn , tp = metrics . confusion_matrix ( y_true , y_pred , labels = labels ) . ravel () # reshape into tp, fp, fn, tn - this is personal preference reshaped_cm = np . asarray ([[ tp , fp ], [ fn , tn ]]) # flatten this 2d array cm_flattened = reshaped_cm . flatten () labels = [ \"True Positive\" , \"False Positive\" , \"False Negative\" , \"True Negative\" , ] annot = ( np . asarray ( [ f \" { label } \\n { cm_count } \" for label , cm_count in zip ( labels , cm_flattened ) ] ) ) . reshape ( 2 , 2 ) ax = plt . subplot () heatmap = sns . heatmap ( reshaped_cm , annot = annot , fmt = \"\" , cmap = \"Greens\" , ax = ax , xticklabels = tick_labels , yticklabels = tick_labels , ) ax . set_title ( title ) ax . set_xlabel ( \"Predicted labels\" ) ax . set_ylabel ( \"True labels\" ) plt . show () # CM y_true , y_pred = train_results [ 'y' ], train_results [ 'y_pred' ] plot_confusion_matrix ( y_true , y_pred , title = \"Confusion Matrix (Malignant as +)\" , labels = [ 0 , 1 ], tick_labels = [ \"benign\" , \"malignant\" ], ) # fig, ax = plt.subplots(figsize=(10, 10)) # # CM # cm_train = metrics.confusion_matrix(train_results['y'], train_results['y_pred']) # #### scores # auc = metrics.roc_auc_score(train_results['y'], train_results['y_prob']) # #### annotations # labels = [\"True Neg\", \"False Pos\", \"False Neg\", \"True Pos\"] # counts = [\"{0:0.0f}\".format(value) for value in cm_train.flatten()] # percentages = [\"{0:.2%}\".format(value) for value in cm_train.flatten() / np.sum(cm_train)] # #### final annotations # label = ( # np.array([f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(labels, counts, percentages)]) # ).reshape(2, 2) # # heatmap # sns.heatmap( # data=cm_train, # vmin=0, # vmax=330, # cmap=[\"#fe4a49\", \"#2ab7ca\", \"#fed766\", \"#59981A\"], # linewidth=2, # linecolor=\"white\", # square=True, # ax=ax, # annot=label, # fmt=\"\", # cbar=False, # annot_kws={\"size\": 10, \"color\": \"black\", \"weight\": \"bold\", \"alpha\": 0.8}, # alpha=1, # ) # ax.scatter(1, 1, s=3500, c=\"white\") # ax.text( # 0.72, # 1.0, # \"AUC: {}\".format(round(auc, 3)), # {\"size\": 10, \"color\": \"black\", \"weight\": \"bold\"}, # ) # ## ticks and labels # ax.set_xticklabels(\"\") # ax.set_yticklabels(\"\") # ## titles and text # fig.text(0, 1.05, \"Train Set Confusion Matrix\", {\"size\": 22, \"weight\": \"bold\"}, alpha=1) # fig.text( # 0, # 1, # \"\"\"Training Set Confusion Matrix.\"\"\", # {\"size\": 12, \"weight\": \"normal\"}, # alpha=0.98, # ) # fig.tight_layout(pad=2.5, w_pad=2.5, h_pad=2.5) # # fig.savefig(config.final_train_confusion_matrix, format='png', dpi=300) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-26-3f454a3182d6> in <module>() 61 62 fig.tight_layout(pad=2.5, w_pad=2.5, h_pad=2.5) ---> 63 fig.savefig(config.final_train_confusion_matrix, format='png', dpi=300) AttributeError: 'config' object has no attribute 'final_train_confusion_matrix' # generate the precision recall curve precision , recall , pr_thresholds = metrics . precision_recall_curve ( train_results [ 'y' ], train_results [ 'y_prob' ]) fpr , tpr , roc_thresholds = metrics . roc_curve ( train_results [ 'y' ], train_results [ 'y_prob' ], pos_label = 1 ) # use the same p, r, thresholds that were previously calculated plot_precision_recall_vs_threshold ( precision , recall , pr_thresholds ) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-28-1a8ed36985bb> in <module>() 1 # use the same p, r, thresholds that were previously calculated ----> 2 plot_precision_recall_vs_threshold(precision, recall, pr_thresholds) <ipython-input-18-2dad3ff8a911> in plot_precision_recall_vs_threshold(precisions, recalls, thresholds) 12 plt.xlabel(\"Decision Threshold\") 13 plt.legend(loc='best') ---> 14 plt.savefig(config.precision_recall_threshold_plot, format=\"png\", dpi=300) 15 16 def plot_roc_curve(fpr, tpr, label=None): AttributeError: 'config' object has no attribute 'precision_recall_threshold_plot' Based on the tradeoff plot above, a good threshold can be set at \\(t = 0.35\\) , let us see how it performs with this threshold. y_pred_adj = adjusted_classes ( train_results [ \"y_prob\" ], t = 0.35 ) print ( pd . DataFrame ( metrics . confusion_matrix ( train_results [ \"y\" ], y_pred_adj ), columns = [ \"pred_neg\" , \"pred_pos\" ], index = [ \"neg\" , \"pos\" ], ) ) pred_neg pred_pos neg 313 8 pos 5 186 print ( metrics . classification_report ( y_true = train_results [ \"y\" ], y_pred = y_pred_adj )) train_brier = train_results [ 'brier' ] print ( f \"train brier: { train_brier } \" ) precision recall f1-score support 0 0.98 0.98 0.98 321 1 0.96 0.97 0.97 191 accuracy 0.97 512 macro avg 0.97 0.97 0.97 512 weighted avg 0.97 0.97 0.97 512 train brier: 0.022402196649862854 The False Negatives reduced from 15 to 9, at the expense of increase False Positives from 6 to 14. We should take comfort that less patients are falsely classified as benign when in fact they need treatment. This is a tradeoff that we have to choose. The ROC curve below also paints a similar story, in order for you to have high recall, one must accept that there will more False Positives. plot_roc_curve ( fpr , tpr , 'recall_optimized' ) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-31-893ec679a4c4> in <module>() ----> 1 plot_roc_curve(fpr, tpr, 'recall_optimized') <ipython-input-18-2dad3ff8a911> in plot_roc_curve(fpr, tpr, label) 29 plt.ylabel(\"True Positive Rate (Recall)\") 30 plt.legend(loc='best') ---> 31 plt.savefig(config.roc_plot, format=\"png\", dpi=300) 32 33 def adjusted_classes(y_scores, t): AttributeError: 'config' object has no attribute 'roc_plot' Evaluation on Test Set Ultimately, we are interested in finding the estimate of the generalization error of the model, and thus it is time for us to evaluate our model's performance on the \"unseen\" test set \\(X_{\\text{test}}\\) to get a good gauge on how well the model generalizes to unseen data. Take note that now everything has settled, we will use the exact hyperparameters to predict on test set, with the pre-defined threshold of 0.35. test_results = evaluate_train_test_set ( grid , X_test , y_test ) y_test_pred_adj = adjusted_classes ( test_results [ 'y_prob' ], t = 0.35 ) print ( pd . DataFrame ( metrics . confusion_matrix ( test_results [ 'y' ], y_test_pred_adj ), columns = [ 'pred_neg' , 'pred_pos' ], index = [ 'neg' , 'pos' ])) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-32-f47e1573a96d> in <module>() ----> 1 test_results = evaluate_train_test_set(grid, X_test, y_test) 2 y_test_pred_adj = adjusted_classes(test_results['y_prob'], t=0.35) 3 4 print(pd.DataFrame(metrics.confusion_matrix(test_results['y'], y_test_pred_adj), 5 columns=['pred_neg', 'pred_pos'], NameError: name 'grid' is not defined test_roc = test_results [ 'roc' ] test_brier = test_results [ 'brier' ] print ( test_roc ) print ( test_brier ) print ( metrics . classification_report ( y_true = test_results [ \"y\" ], y_pred = y_test_pred_adj )) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-33-0cc7fe660860> in <module>() ----> 1 test_roc = test_results['roc'] 2 test_brier = test_results['brier'] 3 print(test_roc) 4 print(test_brier) 5 print(metrics.classification_report(y_true=test_results[\"y\"], y_pred=y_test_pred_adj)) NameError: name 'test_results' is not defined Using the same threshold we used on training set, we see that the False Negative is quite low. The overall ROC score is 0.9828, and the corresponding Brier Score is 0.04136, both seem reasonably well performing. Benefit Structure Refer to health insurance project! https://ghnreigns.github.io/reighns-ml-website/metrics/classification_metrics/confusion_matrix/#benefit-structure # threshold_list : List[float] = [0.01, 0.1, 0.2, 0.5] # benefit_dict : Dict[str, int] = {\"old_structure\": {\"tp\":10, \"fn\":-10, \"fp\": -2, \"tp+fp\":-1}, # \"new_structure\": {\"tp\":100, \"fn\": -100, \"fp\": -2, \"tn+fp\":-1}} # columns = [\"threshold\", \"tp\", \"fn\", \"fp\", \"tn\", \"benefit_cost_old\", \"benefit_cost_new\"] # benefit_cost_list = [] # for t in threshold_list: # y_pred_adj = adjusted_classes(y_test_dt_prob, t=t) # cm = metrics.confusion_matrix(y_true=y_test_gt, y_pred = y_pred_adj) # tn, fp, fn, tp = metrics.confusion_matrix(y_true=y_test_gt, y_pred = y_pred_adj).ravel() # # this one check if it is correct formula # benefit_cost_old = tp*10 - fn*10 - fp*2 - (tp+fp)*1 # benefit_cost_new = tp*100 - fn*100 - fp*2 - (tp+fp)*1 # benefit_cost_list.append([t, tn, fn, fp, tn, benefit_cost_old, benefit_cost_new]) benefit_df = pd . DataFrame ( benefit_cost_list , columns = columns ) benefit_df Bias-Variance Tradeoff avg_expected_loss , avg_bias , avg_var = bias_variance_decomp ( grid . best_estimator_ [ 'model' ], X_train . values , y_train . values , X_test . values , y_test . values , loss = '0-1_loss' , random_seed = 123 ) print ( 'Average expected loss: %.3f ' % avg_expected_loss ) print ( 'Average bias: %.3f ' % avg_bias ) print ( 'Average variance: %.3f ' % avg_var ) We use the mlxtend library to estimate the Bias-Variance Tradeoff in our Logistic Regression model. The core idea behind this function is to use bagging and repeatedly sample from our training set so as to simulate that we are actually drawing samples from the \"true\" population over a distribution \\(\\mathcal{P}\\) . As expected, Logistic Regression being a linear model, its simplicity contributes to its high bias and low variance.","title":"Modelling (Model Evaluation)"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%208%20-%20Modelling%20%28Model%20Evaluation%20and%20Interpretation%29/#dependencies-and-configuration","text":"%% capture ! pip install - q wandb # !pip install -q shap ! pip install - q mlxtend == 0.19.0 ! pip install - q statsmodels == 0.13.1 # !pip install gcloud == 0.18.3 import wandb wandb . login () <IPython.core.display.Javascript object> \u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc True import copy import csv import logging import os import random from dataclasses import asdict , dataclass , field from functools import wraps from pathlib import Path from time import time from typing import Any , Callable , Dict , List , Optional , Tuple , Union import matplotlib.pyplot as plt import mlxtend import numpy as np import pandas as pd import seaborn as sns from joblib import dump , load from mlxtend.evaluate import bias_variance_decomp , paired_ttest_5x2cv from scipy import stats from sklearn import ( base , decomposition , dummy , ensemble , feature_selection , linear_model , metrics , model_selection , neighbors , pipeline , preprocessing , svm , tree ) from statsmodels.regression.linear_model import OLS","title":"Dependencies and Configuration"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%208%20-%20Modelling%20%28Model%20Evaluation%20and%20Interpretation%29/#utils-and-configurations","text":"We need import ReduceVIF if not we cannot call our model. @dataclass class config : raw_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/raw/data.csv\" processed_data : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/processed.csv\" df_folds : str = \"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/supervised_learning/classification/breast-cancer-wisconsin/data/processed/df_folds.csv\" train_size : float = 0.9 seed : int = 1992 num_folds : int = 5 cv_schema : str = \"StratifiedKFold\" classification_type : str = \"binary\" target_col : List [ str ] = field ( default_factory = lambda : [ \"diagnosis\" ]) unwanted_cols : List [ str ] = field ( default_factory = lambda : [ \"id\" , \"Unnamed: 32\" ] ) # Plotting colors : List [ str ] = field ( default_factory = lambda : [ \"#fe4a49\" , \"#2ab7ca\" , \"#fed766\" , \"#59981A\" ] ) cmap_reversed = plt . cm . get_cmap ( \"mako_r\" ) def to_dict ( self ) -> Dict [ str , Any ]: \"\"\"Convert the config object to a dictionary. Returns: Dict: The config object as a dictionary. \"\"\" return asdict ( self ) # spot_checking_boxplot = \"../data/images/spot_checking_boxplot.png\" # oof_confusion_matrix = \"../data/images/oof_confusion_matrix.png\" # final_train_confusion_matrix = \"../data/images/final_train_confusion_matrix.png\" # precision_recall_threshold_plot = \"../data/images/precision_recall_threshold_plot.png\" # roc_plot = \"../data/images/roc_plot.png\" # feature_importance = \"../data/images/feature_importance.png\" def set_seeds ( seed : int = 1234 ) -> None : \"\"\"Set seeds for reproducibility.\"\"\" np . random . seed ( seed ) random . seed ( seed ) def init_logger ( log_file : str = \"info.log\" ): \"\"\" Initialize logger. \"\"\" logger = logging . getLogger ( __name__ ) logger . setLevel ( logging . INFO ) stream_handler = logging . StreamHandler () stream_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) file_handler = logging . FileHandler ( filename = log_file ) file_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(message)s \" , datefmt = \"%Y-%m- %d ,%H:%M:%S\" )) logger . addHandler ( stream_handler ) logger . addHandler ( file_handler ) return logger # Utils functions that we need def variance_inflation_factor ( exog , idx_kept , vif_idx ): \"\"\"Compute VIF for one feature. Args: exog (np.ndarray): Observations idx_kept (List[int]): Indices of features to consider vif_idx (int): Index of feature for which to compute VIF Returns: float: VIF for the selected feature \"\"\" exog = np . asarray ( exog ) x_i = exog [:, vif_idx ] mask = [ col for col in idx_kept if col != vif_idx ] x_noti = exog [:, mask ] r_squared_i = OLS ( x_i , x_noti ) . fit () . rsquared vif = 1. / ( 1. - r_squared_i ) return vif class ReduceVIF ( base . BaseEstimator , base . TransformerMixin ): \"\"\"The base of the class structure is implemented in https://www.kaggle.com/ffisegydd/sklearn-multicollinearity-class; I heavily modified the class such that it can take in numpy arrays and correctly implemented the fit and transform method. \"\"\" def __init__ ( self , thresh = 10 , max_drop = 20 ): self . thresh = thresh self . max_drop = max_drop self . column_indices_kept_ = [] self . feature_names_kept_ = None def reset ( self ): \"\"\"Resets the state of predictor columns after each fold.\"\"\" self . column_indices_kept_ = [] self . feature_names_kept_ = None def fit ( self , X , y = None ): \"\"\"Fits the Recursive VIF on the training folds and save the selected feature names in self.feature_names Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" self . column_indices_kept_ , self . feature_names_kept_ = self . calculate_vif ( X ) return self def transform ( self , X , y = None ): \"\"\"Transforms the Validation Set according to the selected feature names. Args: X ([type]): [description] y ([type], optional): [description]. Defaults to None. Returns: [type]: [description] \"\"\" return X [:, self . column_indices_kept_ ] def calculate_vif ( self , X : Union [ np . ndarray , pd . DataFrame ]): \"\"\"Implements a VIF function that recursively eliminates features. Args: X (Union[np.ndarray, pd.DataFrame]): [description] Returns: [type]: [description] \"\"\" feature_names = None column_indices_kept = list ( range ( X . shape [ 1 ])) if isinstance ( X , pd . DataFrame ): feature_names = X . columns dropped = True count = 0 while dropped and count <= self . max_drop : dropped = False max_vif , max_vif_col = None , None for col in column_indices_kept : vif = variance_inflation_factor ( X , column_indices_kept , col ) if max_vif is None or vif > max_vif : max_vif = vif max_vif_col = col if max_vif > self . thresh : # print(f\"Dropping {max_vif_col} with vif={max_vif}\") column_indices_kept . remove ( max_vif_col ) if feature_names is not None : feature_names . pop ( max_vif_col ) dropped = True count += 1 return column_indices_kept , feature_names def prepare_y ( y : np . ndarray ) -> np . ndarray : \"\"\"Prepare the target variable for the model. If Binary Classification, we need to ravel the array to 1d. Args: y (np.ndarray): Target variable. Returns: np.ndarray: Transformed Target variable. \"\"\" return y . ravel () if config . classification_type == \"binary\" else y config = config () logger = init_logger () # set seeding for reproducibility _ = set_seeds ( seed = config . seed ) # read data df_folds = pd . read_csv ( config . df_folds ) # Assign predictors and target accordingly predictor_cols = df_folds . columns . to_list ()[: - 2 ] target_col = config . target_col","title":"Utils and Configurations"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%208%20-%20Modelling%20%28Model%20Evaluation%20and%20Interpretation%29/#resume-run-and-load-weights","text":"Here we resume wandb using its run_id and then load the model's weights. # Resume run by getting run_id # TODO: return id as an artifact so we can get it easily. run = wandb . init ( project = \"bcw\" , name = \"classification\" , resume = True , id = '3qh37hoo' ) \u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mreighns\u001b[0m (use `wandb login --relogin` to force relogin) Resuming run classification to Weights & Biases ( docs ). logistic_path = \"LogisticRegression_grid.joblib\" dt_path = \"DecisionTreeClassifier_grid.joblib\" gdb_path = \"GradientBoostingClassifier_grid.joblib\" logistic_best_weight = wandb . restore ( logistic_path ) logistic_best_model = load ( logistic_best_weight . name ) \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout. \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.","title":"Resume Run and Load Weights"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%208%20-%20Modelling%20%28Model%20Evaluation%20and%20Interpretation%29/#interpretation-of-results","text":"","title":"Interpretation of Results"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%208%20-%20Modelling%20%28Model%20Evaluation%20and%20Interpretation%29/#interpretation-of-coefficients","text":"As shown in the figure below, all else being equal, for every square unit increase in mean cell area, the odds of the tumor being malignant increases by a factor of \\(e^{1.43} = 4.19\\) . The variation (standard error) of the characteristics of cells also are deemed important by the model, for example, area se played an important role in determining whether a cell is malignant; intuitively, if some cells are noticably larger than the rest, then it is also a good indicator of malignancy. selected_features_by_vif_index = logistic_best_model . best_estimator_ [ 'remove_multicollinearity' ] . column_indices_kept_ selected_feature_names = np . asarray ( predictor_cols )[ selected_features_by_vif_index ] selected_features_coefficients = logistic_best_model . best_estimator_ [ 'model' ] . coef_ . flatten () # assertion #assert grid.best_estimator_['remove_multicollinearity'].feature_names_ == retrain_pipeline['remove_multicollinearity'].feature_names_ fig , ax = plt . subplots ( figsize = ( 15 , 15 )) # .abs() _ = pd . Series ( selected_features_coefficients , index = selected_feature_names ) . sort_values () . plot ( ax = ax , kind = 'barh' ) # fig.savefig(config.feature_importance, format=\"png\", dpi=300)","title":"Interpretation of Coefficients"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%208%20-%20Modelling%20%28Model%20Evaluation%20and%20Interpretation%29/#interpretation-of-metric-scores-on-train-set","text":"We are also interested in choosing an optimal threshold for the model such that it gives the lowest recall, or False Negatives. We note that the default threshold when calling predict() from a model is \\(0.5\\) . In this section, we will explore one way to get the best tradeoff we can when choosing a high recall, while maintaining a reasonable score for precision. def evaluate_train_test_set ( estimator : Callable , X : Union [ pd . DataFrame , np . ndarray ], y : Union [ pd . DataFrame , np . ndarray ] ) -> Dict [ str , Union [ float , np . ndarray ]]: \"\"\"This function takes in X and y and returns a dictionary of scores. Args: estimator (Callable): [description] X (Union[pd.DataFrame, np.ndarray]): [description] y (Union[pd.DataFrame, np.ndarray]): [description] Returns: Dict[str, Union[float, np.ndarray]]: [description] \"\"\" test_results = {} y_pred = estimator . predict ( X ) # This is the probability array of class 1 (malignant) y_prob = estimator . predict_proba ( X )[:, 1 ] test_brier = metrics . brier_score_loss ( y , y_prob ) test_roc = metrics . roc_auc_score ( y , y_prob ) test_results [ \"brier\" ] = test_brier test_results [ \"roc\" ] = test_roc test_results [ \"y\" ] = np . asarray ( y ) . flatten () test_results [ \"y_pred\" ] = y_pred . flatten () test_results [ \"y_prob\" ] = y_prob . flatten () return test_results def plot_precision_recall_vs_threshold ( precisions , recalls , thresholds ): \"\"\" Modified from: Hands-On Machine learning with Scikit-Learn and TensorFlow; p.89 and courtesy of https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65 \"\"\" plt . figure ( figsize = ( 8 , 8 )) plt . title ( \"Precision and Recall Scores as a function of the decision threshold\" ) plt . plot ( thresholds , precisions [: - 1 ], \"b--\" , label = \"Precision\" ) plt . plot ( thresholds , recalls [: - 1 ], \"g-\" , label = \"Recall\" ) plt . ylabel ( \"Score\" ) plt . xlabel ( \"Decision Threshold\" ) plt . legend ( loc = 'best' ) plt . savefig ( config . precision_recall_threshold_plot , format = \"png\" , dpi = 300 ) def plot_roc_curve ( fpr , tpr , label = None ): \"\"\" The ROC curve, modified from Hands-On Machine learning with Scikit-Learn and TensorFlow; p.91 and courtesy of https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65 \"\"\" plt . figure ( figsize = ( 8 , 8 )) plt . title ( 'ROC Curve' ) plt . plot ( fpr , tpr , linewidth = 2 , label = label ) plt . plot ([ 0 , 1 ], [ 0 , 1 ], 'k--' ) plt . axis ([ - 0.005 , 1 , 0 , 1.005 ]) plt . xticks ( np . arange ( 0 , 1 , 0.05 ), rotation = 90 ) plt . xlabel ( \"False Positive Rate\" ) plt . ylabel ( \"True Positive Rate (Recall)\" ) plt . legend ( loc = 'best' ) plt . savefig ( config . roc_plot , format = \"png\" , dpi = 300 ) def adjusted_classes ( y_scores , t ): \"\"\" This function adjusts class predictions based on the prediction threshold (t). Will only work for binary classification problems. and courtesy of https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65 \"\"\" return [ 1 if y >= t else 0 for y in y_scores ] The plots below show the tradeoffs between precision and recall, recall and false positive rate. The confusion matrix on the train set tells us that there is still more false negatives than false positives. We can choose a particular threshold in order to minimize false negatives, at some expense of false positive. X_train , y_train = df_folds [ predictor_cols ] . values , df_folds [ target_col ] . values y_train = prepare_y ( y_train ) train_results = evaluate_train_test_set ( logistic_best_model , X_train , y_train ) def plot_confusion_matrix ( y_true : np . ndarray , y_pred : np . ndarray , title : str , labels : List [ str ], tick_labels : List [ str ], ) -> None : \"\"\"Plots a Binary Confusion Matrix. Args: y_true (np.ndarray): the actual labels. y_pred (np.ndarray): the predicted labels. title (str): the title of the plot. tick_labels (List[str]): The labels for the ticks. \"\"\" # Unravel into tn, fp, fn and tp tn , fp , fn , tp = metrics . confusion_matrix ( y_true , y_pred , labels = labels ) . ravel () # reshape into tp, fp, fn, tn - this is personal preference reshaped_cm = np . asarray ([[ tp , fp ], [ fn , tn ]]) # flatten this 2d array cm_flattened = reshaped_cm . flatten () labels = [ \"True Positive\" , \"False Positive\" , \"False Negative\" , \"True Negative\" , ] annot = ( np . asarray ( [ f \" { label } \\n { cm_count } \" for label , cm_count in zip ( labels , cm_flattened ) ] ) ) . reshape ( 2 , 2 ) ax = plt . subplot () heatmap = sns . heatmap ( reshaped_cm , annot = annot , fmt = \"\" , cmap = \"Greens\" , ax = ax , xticklabels = tick_labels , yticklabels = tick_labels , ) ax . set_title ( title ) ax . set_xlabel ( \"Predicted labels\" ) ax . set_ylabel ( \"True labels\" ) plt . show () # CM y_true , y_pred = train_results [ 'y' ], train_results [ 'y_pred' ] plot_confusion_matrix ( y_true , y_pred , title = \"Confusion Matrix (Malignant as +)\" , labels = [ 0 , 1 ], tick_labels = [ \"benign\" , \"malignant\" ], ) # fig, ax = plt.subplots(figsize=(10, 10)) # # CM # cm_train = metrics.confusion_matrix(train_results['y'], train_results['y_pred']) # #### scores # auc = metrics.roc_auc_score(train_results['y'], train_results['y_prob']) # #### annotations # labels = [\"True Neg\", \"False Pos\", \"False Neg\", \"True Pos\"] # counts = [\"{0:0.0f}\".format(value) for value in cm_train.flatten()] # percentages = [\"{0:.2%}\".format(value) for value in cm_train.flatten() / np.sum(cm_train)] # #### final annotations # label = ( # np.array([f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(labels, counts, percentages)]) # ).reshape(2, 2) # # heatmap # sns.heatmap( # data=cm_train, # vmin=0, # vmax=330, # cmap=[\"#fe4a49\", \"#2ab7ca\", \"#fed766\", \"#59981A\"], # linewidth=2, # linecolor=\"white\", # square=True, # ax=ax, # annot=label, # fmt=\"\", # cbar=False, # annot_kws={\"size\": 10, \"color\": \"black\", \"weight\": \"bold\", \"alpha\": 0.8}, # alpha=1, # ) # ax.scatter(1, 1, s=3500, c=\"white\") # ax.text( # 0.72, # 1.0, # \"AUC: {}\".format(round(auc, 3)), # {\"size\": 10, \"color\": \"black\", \"weight\": \"bold\"}, # ) # ## ticks and labels # ax.set_xticklabels(\"\") # ax.set_yticklabels(\"\") # ## titles and text # fig.text(0, 1.05, \"Train Set Confusion Matrix\", {\"size\": 22, \"weight\": \"bold\"}, alpha=1) # fig.text( # 0, # 1, # \"\"\"Training Set Confusion Matrix.\"\"\", # {\"size\": 12, \"weight\": \"normal\"}, # alpha=0.98, # ) # fig.tight_layout(pad=2.5, w_pad=2.5, h_pad=2.5) # # fig.savefig(config.final_train_confusion_matrix, format='png', dpi=300) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-26-3f454a3182d6> in <module>() 61 62 fig.tight_layout(pad=2.5, w_pad=2.5, h_pad=2.5) ---> 63 fig.savefig(config.final_train_confusion_matrix, format='png', dpi=300) AttributeError: 'config' object has no attribute 'final_train_confusion_matrix' # generate the precision recall curve precision , recall , pr_thresholds = metrics . precision_recall_curve ( train_results [ 'y' ], train_results [ 'y_prob' ]) fpr , tpr , roc_thresholds = metrics . roc_curve ( train_results [ 'y' ], train_results [ 'y_prob' ], pos_label = 1 ) # use the same p, r, thresholds that were previously calculated plot_precision_recall_vs_threshold ( precision , recall , pr_thresholds ) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-28-1a8ed36985bb> in <module>() 1 # use the same p, r, thresholds that were previously calculated ----> 2 plot_precision_recall_vs_threshold(precision, recall, pr_thresholds) <ipython-input-18-2dad3ff8a911> in plot_precision_recall_vs_threshold(precisions, recalls, thresholds) 12 plt.xlabel(\"Decision Threshold\") 13 plt.legend(loc='best') ---> 14 plt.savefig(config.precision_recall_threshold_plot, format=\"png\", dpi=300) 15 16 def plot_roc_curve(fpr, tpr, label=None): AttributeError: 'config' object has no attribute 'precision_recall_threshold_plot' Based on the tradeoff plot above, a good threshold can be set at \\(t = 0.35\\) , let us see how it performs with this threshold. y_pred_adj = adjusted_classes ( train_results [ \"y_prob\" ], t = 0.35 ) print ( pd . DataFrame ( metrics . confusion_matrix ( train_results [ \"y\" ], y_pred_adj ), columns = [ \"pred_neg\" , \"pred_pos\" ], index = [ \"neg\" , \"pos\" ], ) ) pred_neg pred_pos neg 313 8 pos 5 186 print ( metrics . classification_report ( y_true = train_results [ \"y\" ], y_pred = y_pred_adj )) train_brier = train_results [ 'brier' ] print ( f \"train brier: { train_brier } \" ) precision recall f1-score support 0 0.98 0.98 0.98 321 1 0.96 0.97 0.97 191 accuracy 0.97 512 macro avg 0.97 0.97 0.97 512 weighted avg 0.97 0.97 0.97 512 train brier: 0.022402196649862854 The False Negatives reduced from 15 to 9, at the expense of increase False Positives from 6 to 14. We should take comfort that less patients are falsely classified as benign when in fact they need treatment. This is a tradeoff that we have to choose. The ROC curve below also paints a similar story, in order for you to have high recall, one must accept that there will more False Positives. plot_roc_curve ( fpr , tpr , 'recall_optimized' ) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-31-893ec679a4c4> in <module>() ----> 1 plot_roc_curve(fpr, tpr, 'recall_optimized') <ipython-input-18-2dad3ff8a911> in plot_roc_curve(fpr, tpr, label) 29 plt.ylabel(\"True Positive Rate (Recall)\") 30 plt.legend(loc='best') ---> 31 plt.savefig(config.roc_plot, format=\"png\", dpi=300) 32 33 def adjusted_classes(y_scores, t): AttributeError: 'config' object has no attribute 'roc_plot'","title":"Interpretation of Metric Scores on Train Set"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%208%20-%20Modelling%20%28Model%20Evaluation%20and%20Interpretation%29/#evaluation-on-test-set","text":"Ultimately, we are interested in finding the estimate of the generalization error of the model, and thus it is time for us to evaluate our model's performance on the \"unseen\" test set \\(X_{\\text{test}}\\) to get a good gauge on how well the model generalizes to unseen data. Take note that now everything has settled, we will use the exact hyperparameters to predict on test set, with the pre-defined threshold of 0.35. test_results = evaluate_train_test_set ( grid , X_test , y_test ) y_test_pred_adj = adjusted_classes ( test_results [ 'y_prob' ], t = 0.35 ) print ( pd . DataFrame ( metrics . confusion_matrix ( test_results [ 'y' ], y_test_pred_adj ), columns = [ 'pred_neg' , 'pred_pos' ], index = [ 'neg' , 'pos' ])) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-32-f47e1573a96d> in <module>() ----> 1 test_results = evaluate_train_test_set(grid, X_test, y_test) 2 y_test_pred_adj = adjusted_classes(test_results['y_prob'], t=0.35) 3 4 print(pd.DataFrame(metrics.confusion_matrix(test_results['y'], y_test_pred_adj), 5 columns=['pred_neg', 'pred_pos'], NameError: name 'grid' is not defined test_roc = test_results [ 'roc' ] test_brier = test_results [ 'brier' ] print ( test_roc ) print ( test_brier ) print ( metrics . classification_report ( y_true = test_results [ \"y\" ], y_pred = y_test_pred_adj )) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-33-0cc7fe660860> in <module>() ----> 1 test_roc = test_results['roc'] 2 test_brier = test_results['brier'] 3 print(test_roc) 4 print(test_brier) 5 print(metrics.classification_report(y_true=test_results[\"y\"], y_pred=y_test_pred_adj)) NameError: name 'test_results' is not defined Using the same threshold we used on training set, we see that the False Negative is quite low. The overall ROC score is 0.9828, and the corresponding Brier Score is 0.04136, both seem reasonably well performing.","title":"Evaluation on Test Set"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%208%20-%20Modelling%20%28Model%20Evaluation%20and%20Interpretation%29/#benefit-structure","text":"Refer to health insurance project! https://ghnreigns.github.io/reighns-ml-website/metrics/classification_metrics/confusion_matrix/#benefit-structure # threshold_list : List[float] = [0.01, 0.1, 0.2, 0.5] # benefit_dict : Dict[str, int] = {\"old_structure\": {\"tp\":10, \"fn\":-10, \"fp\": -2, \"tp+fp\":-1}, # \"new_structure\": {\"tp\":100, \"fn\": -100, \"fp\": -2, \"tn+fp\":-1}} # columns = [\"threshold\", \"tp\", \"fn\", \"fp\", \"tn\", \"benefit_cost_old\", \"benefit_cost_new\"] # benefit_cost_list = [] # for t in threshold_list: # y_pred_adj = adjusted_classes(y_test_dt_prob, t=t) # cm = metrics.confusion_matrix(y_true=y_test_gt, y_pred = y_pred_adj) # tn, fp, fn, tp = metrics.confusion_matrix(y_true=y_test_gt, y_pred = y_pred_adj).ravel() # # this one check if it is correct formula # benefit_cost_old = tp*10 - fn*10 - fp*2 - (tp+fp)*1 # benefit_cost_new = tp*100 - fn*100 - fp*2 - (tp+fp)*1 # benefit_cost_list.append([t, tn, fn, fp, tn, benefit_cost_old, benefit_cost_new]) benefit_df = pd . DataFrame ( benefit_cost_list , columns = columns ) benefit_df","title":"Benefit Structure"},{"location":"reighns_ml_journey/projects/breast_cancer_wisconsin/Stage%208%20-%20Modelling%20%28Model%20Evaluation%20and%20Interpretation%29/#bias-variance-tradeoff","text":"avg_expected_loss , avg_bias , avg_var = bias_variance_decomp ( grid . best_estimator_ [ 'model' ], X_train . values , y_train . values , X_test . values , y_test . values , loss = '0-1_loss' , random_seed = 123 ) print ( 'Average expected loss: %.3f ' % avg_expected_loss ) print ( 'Average bias: %.3f ' % avg_bias ) print ( 'Average variance: %.3f ' % avg_var ) We use the mlxtend library to estimate the Bias-Variance Tradeoff in our Logistic Regression model. The core idea behind this function is to use bagging and repeatedly sample from our training set so as to simulate that we are actually drawing samples from the \"true\" population over a distribution \\(\\mathcal{P}\\) . As expected, Logistic Regression being a linear model, its simplicity contributes to its high bias and low variance.","title":"Bias-Variance Tradeoff"},{"location":"reighns_ml_journey/software_engineering/code_design/","text":"Imports from typing import * from dataclasses import dataclass , field from typing import List , Union , Dict import uuid Common Pitfalls References Common Gotchas in Python Is None vs == None Not much of a big difference but better to use is to compare. A small caution is below. p = [ 1 ] q = [ 1 ] False p is q # False because they are not the same actual object p == q # True because they are equivalent True None/0 is False None and \\(0\\) are False by default in python, but the catch is: 0 is False evaluates to True but; None is False evaluates to False but; None is True is also False ; (not None) is True evaluates to True since (not None) is (not False) which is True ; not None is False evaluates to True since one should evaluate not (None is False) and since (None is False) is False so not False is True . not None is False # not (None is False) True Hash hash ( \"mystring\" ), hash (( 'foo' , 'bar' )), hash ( 1 ) (7474225329682574832, -283857846903866188, 1) Dataclasses General Properties Dataclass as boiler plate as a Class For example if you want to hash your class, then you need to write __hash__ and etc which takes time, dataclass can be done easily. Why need hash? For example the dunder method __repr__ are done for you in an easy to read manner rather than the default one which points to memory address. Default Factory Intuition By design, dataclass does not take in mutable default . What does that mean? Let us see a quick example. Passing Mutable Default Directly to Dataclass The following C_dataclass has init=True by default, and setting the attributes in the dataclass simply translates to a normal class with the __init__(a: int, b: int = 0) . @dataclass ( init = True ) class C_dataclass : a : int # 'a' has no default value b : int = 0 # assign a default value for 'b' class C_class : def __init__ ( self , a : int , b : int = 0 ): self . a = a self . b = b c_dataclass = C_dataclass ( a = 1 ) c_class = C_class ( a = 1 ) Notice that both classes have a default attribute b = 0 . This is totally fine! We can also set default attributes as a list for example in a normal class: class C_class : def __init__ ( self , a : int , b : int = 0 , c : List [ int ] = [ 1 , 2 , 3 ]): self . a = a self . b = b self . c = c However, if one tries to do that for dataclass , an error will pop out: ValueError : mutable default < class ' list '> for field c is not allowed: use default_factory @dataclass ( init = True ) class C_dataclass : a : int # 'a' has no default value b : int = 0 # assign a default value for 'b' c : List [ int ] = [ 1 , 2 , 3 ] But why? One major reason is that to to enforce avoidance of the mutable default argument problem . The Mutable Default Argument def append_to ( element , to = []): to . append ( element ) return to Let us append some values to 2 different variables: my_list = append_to ( 12 ) print ( my_list ) my_other_list = append_to ( 42 ) print ( my_other_list ) [12] [12, 42] One would expect the output to be: my_list = append_to ( 12 ) print ( my_list ) [ 12 ] my_other_list = append_to ( 42 ) print ( my_other_list ) [ 42 ] but the result is: my_list = append_to ( 12 ) print ( my_list ) [ 12 ] my_other_list = append_to ( 42 ) print ( my_other_list ) [ 12 , 42 ] A new list is created once when the function is defined, and the same list is used in each successive call. Python\u2019s default arguments are evaluated once when the function is defined, not each time the function is called (like it is in say, Ruby). This means that if you use a mutable default argument and mutate it, you will and have mutated that object for all future calls to the function as well. We hence see the same issue when passing in mutable defaults to a class: class C_class : def __init__ ( self , a : int , b : int = 0 , c : List [ int ] = [ 1 , 2 , 3 ]): self . a = a self . b = b self . c = c c1 = C_class ( a = 1 ) c2 = C_class ( a = 1 ) c1 . c . append ( 4 ) print ( c1 . c ) c2 . c . append ( 5 ) print ( c2 . c ) assert c1 . c == [ 1 , 2 , 3 , 4 , 5 ] assert c1 . c is c2 . c [1, 2, 3, 4] [1, 2, 3, 4, 5] Thus this is deeemed dangerous and dataclass does not allow you to do it out of the bat. More info on this design can be read here Mutable Default Values . Examples (Using Default Factory to Pass Mutable Defaults) The parameters to field() are: default_factory : If provided, it must be a zero-argument callable that will be called when a default value is needed for this field. Among other purposes, this can be used to specify fields with mutable default values, as discussed below. It is an error to specify both default and default_factory. @dataclass ( init = True ) class C_dataclass : a : int # 'a' has no default value b : int = 0 # assign a default value for 'b' c : List [ int ] = field ( default_factory = [ 1 , 2 , 3 ]) C_dataclass ( a = 1 ) Calling this dataclass will result in an error: TypeError : 'list' object is not callable because you are passing in a list of values and not what default_factory expects, a zero-argument callable . What is a zero-argument callable ? The examples below illustrates: Indeed, a list with values is not a function or class method, and hence not callable if you put the \"parenthesis\" () behind. The same error occurs. default_factory = [ 1 , 2 , 3 ] default_factory () --------------------------------------------------------------------------- TypeError Traceback (most recent call last) ~\\AppData\\Local\\Temp/ipykernel_4064/3467513020.py in <module> 1 default_factory = [1, 2, 3] ----> 2 default_factory() TypeError: 'list' object is not callable Now if we set default_factory as a function that returns the list [1, 2, 3] , then it is indeed callable and in fact, it's zero-argument callable since this function call takes in zero arguments : default_factory = lambda : [ 1 , 2 , 3 ] default_factory () So remember, if you want pass in a default mutable object with values inside, set a lambda as such: @dataclass ( init = True ) class C_dataclass : a : int # 'a' has no default value b : int = 0 # assign a default value for 'b' c : List [ int ] = field ( default_factory = lambda : [ 1 , 2 , 3 ]) c1 = C_dataclass ( a = 1 ) c1 . c [1, 2, 3] Generate Functions in Default Factory ( Important for Model Registry! ) This is very very useful especially if you are doing a ML project with multiple experiments, each experiments should be stored in an unique folder as a form of model registry. sample directory 1 2 3 4 5 6 7 8 model_registry/ exp1_uuid4/ weights/ logs/ ... exp2_uuid4/ weights/ logs/ We can simply say create a function called generate_uuid4() and pass it to field 's default_factory and it will generate a new unique id for each run of experiment. def generate_uuid4 () -> str : \"\"\"Generate a random UUID4. Returns: str: Random UUID4 \"\"\" return str ( uuid . uuid4 ()) @dataclass ( init = True , frozen = False ) class ModelRegistry : \"\"\"A class to keep track of model artifacts.\"\"\" project_name : str = \"pkd\" unique_id : str = field ( default_factory = generate_uuid4 ) exp1 = ModelRegistry ( project_name = \"pkd\" ) exp1 . unique_id 'd6f3eb61-72f7-4ed4-9637-6df42a179bdf' exp2 = ModelRegistry () exp2 . unique_id '56d5f4f8-adca-4e2c-a5f3-9207da7d1c9a' Although the unique_id should be run by the random generator uuid , users are allowed to modify it and that is something we do not want. We can therefore set init=False inside the field so it \"won't\" initialize let's see example below: # example where user can modify exp3 = ModelRegistry ( project_name = \"pkd\" , unique_id = \"123\" ) exp3 . unique_id '123' @dataclass ( init = True , frozen = False ) class ModelRegistry : \"\"\"A class to keep track of model artifacts.\"\"\" project_name : str = \"PeekingDuck\" unique_id : str = field ( init = False , default_factory = generate_uuid4 ) # example where user CANNOT modify and throws error exp3 = ModelRegistry ( project_name = \"pkd\" , unique_id = \"123\" ) exp3 . unique_id --------------------------------------------------------------------------- TypeError Traceback (most recent call last) ~\\AppData\\Local\\Temp/ipykernel_20736/826619969.py in <module> 1 # example where user CANNOT modify and throws error ----> 2 exp3 = ModelRegistry(project_name=\"pkd\", unique_id=\"123\") 3 exp3.unique_id TypeError: __init__() got an unexpected keyword argument 'unique_id' # you should not set the unique id yourself. exp3 = ModelRegistry ( project_name = \"pkd\" ) exp3 . unique_id '91679660-a805-423a-bb76-feffede8c731' References Passing default list argument to dataclasses Why can't dataclasses have mutable defaults in their class attributes declaration? Mutable Default Values This is why python dataclasses are awesome Frozen (Hashable/Mutable) Intuition When frozen is True, the dataclass is an immuatable object and immutable means you can't change the attributes or characteristics of an object after it's initialised. Note hash and immutable is a bit similar 1 . Tip Generally, making an object mutable is good since it stays constant. No surprises :) Examples Let us see the below example, both AugParamsFrozenTrue and AugParamsFrozenFalse have the same attributes, the only difference is that one is frozen and the other isn't. @dataclass ( init = True , frozen = True ) class AugParamsFrozenTrue : \"\"\"Class to keep track of the augmentation parameters.\"\"\" mean : List [ float ] = field ( default_factory = lambda : [ 0.485 , 0.456 , 0.406 ]) std : List [ float ] = field ( default_factory = lambda : [ 0.229 , 0.224 , 0.225 ]) image_size : int = 256 mixup : bool = False mixup_params : Dict [ str , Any ] = field ( default_factory = lambda : { \"mixup_alpha\" : 1 , \"use_cuda\" : True } ) When we freeze the dataclass AugParamsFrozenTrue then we can no longer change its attribute instances . For example, we cannot re-assign the mean attribute. aug_frozen_true = AugParamsFrozenTrue () print ( id ( aug_frozen_true . mean )) aug_frozen_true . mean = [ 1 , 2 , 3 ] # same as setattr(aug_frozen_true, \"mean\", [1, 2, 3]) 1693345842112 --------------------------------------------------------------------------- FrozenInstanceError Traceback (most recent call last) ~\\AppData\\Local\\Temp/ipykernel_4064/656634435.py in <module> 1 aug_frozen_true = AugParamsFrozenTrue() 2 print(id(aug_frozen_true.mean)) ----> 3 aug_frozen_true.mean = [1, 2, 3] # same as setattr(aug_frozen_true, \"mean\", [1, 2, 3]) <string> in __setattr__(self, name, value) FrozenInstanceError: cannot assign to field 'mean' However, frozen only applies to the dataclass instance itself \u2013 a frozen dataclass can contain mutable items such as lists, and a regular dataclass can contain frozen/immutable items such as tuples. This means that I can change the state of the attribute by mutating the list itself. Therefore, one must be careful that freezing a dataclass does not guarantee immutability of all its attributes. aug_frozen_true . mean [ 0 ] = 1 aug_frozen_true . mean [ 1 ] = 2 aug_frozen_true . mean [ 2 ] = 3 print ( aug_frozen_true . mean ) print ( id ( aug_frozen_true . mean )) [1, 2, 3] 1693345842112 On the other hand, if one set frozen=False , then it is just like any other class in Python, you can re-assign the attributes freely. @dataclass ( init = True , frozen = False ) class AugParamsFrozenFalse : \"\"\"Class to keep track of the augmentation parameters.\"\"\" mean : List [ float ] = field ( default_factory = lambda : [ 0.485 , 0.456 , 0.406 ]) std : List [ float ] = field ( default_factory = lambda : [ 0.229 , 0.224 , 0.225 ]) image_size : int = 256 mixup : bool = False mixup_params : Dict [ str , Any ] = field ( default_factory = lambda : { \"mixup_alpha\" : 1 , \"use_cuda\" : True } ) aug_frozen_false = AugParamsFrozenFalse () print ( id ( aug_frozen_false . mean )) print ( aug_frozen_false . mean ) print () aug_frozen_false . mean = [ 1 , 2 , 3 ] print ( id ( aug_frozen_false . mean )) print ( aug_frozen_false . mean ) 1693347054912 [0.485, 0.456, 0.406] 1693345843648 [1, 2, 3] References What is immutability and why should I worry about it? What does frozen mean for dataclasses? Post Init 2 Notice the example below that average_marks is an attribute that can only be known after marks is known. So we can set field(init=False) and tabulate using __post_init__ . Examples (Post Init) A dunder method: Motivation: you want an \"attribute\" that is derived from your other instance attributes; Average marks of a student for example can only be known when all his \"marks\" are known; We set average_marks as an attribute BUT init is False so it is not initialized by the class as we won't know it yet + we won't pass it in the dataclass; post_init helps us to calculate and return back the average marks. Tip average_marks should be a private member cause it is not something you want the user to call and change! @dataclass ( init = True , frozen = False ) class Student : name : str student_id : int marks : List [ Union [ int , float ]] _average_marks : float = field ( init = False ) def __post_init__ ( self ) -> Union [ int , float ]: self . _average_marks = sum ( self . marks ) / len ( self . marks ) student = Student ( name = \"hongnan\" , student_id = \"123\" , marks = [ 88 , 92 , 96 ]) print ( student ) print ( student . average_marks ) Student(name='hongnan', student_id='123', marks=[88, 92, 96], average_marks=92.0) 92.0 Using Dataclass as Config File Intuition Usually we store configurations in a .yaml file or the likes and load it as dict in our script and subsequently use the dict as a way to get the config values. We will now introduce a way to store our config in a dataclass : This method has a ton of benefits: We get code completion and type hints in the editor It's easier to maintain, since you only have to change a config property name in one place Can implement version reconciliation in the from_dict method Refactoring is a breeze, since editors can auto-refactor class property names Allows you to define configurations with python code, since you can instantiate the dataclasses directly in a settings.py file, for example It's testable. Parsing from Dict Consider a config file in yaml to be the following: model_params : { model_name : resnet50d , out_features : 2 , in_channels : 3 , pretrained : false , use_meta : false } aug_params : { image_size : 224 , mean : [ 0.485 , 0.456 , 0.406 ], std : [ 0.229 , 0.224 , 0.225 ] } train_params : { epochs : 10 , use_amp : true } We can easily parse it into a python dict by: import yaml from pathlib import Path config_dict = yaml . safe_load ( Path ( \"tmp.yaml\" ) . read_text ()) to get { \"model_params\" : { \"model_name\" : \"resnet50d\" , \"out_features\" : 2 , \"in_channels\" : 3 , \"pretrained\" : False , \"use_meta\" : False , }, \"aug_params\" : { \"image_size\" : 224 , \"mean\" : [ 0.485 , 0.456 , 0.406 ], \"std\" : [ 0.229 , 0.224 , 0.225 ], }, \"train_params\" : { \"epochs\" : 10 , \"use_amp\" : True }, } Whenever we want to use the config, we can call say config_dict[model_params][\"model_name\"] . This is cumbersome if the dict is very nested; This is prone to error as you need to write the correct keys; This is difficult to refactor and hard to read. Most importantly, we can parse the config file to multiple sub-configs that is responsible for each part of the configuration, for example, we can create 3 dataclasses named ModelParams , AugParams and TrainParams to indicate what each config does. @dataclass ( init = True , frozen = False ) class ModelParams : \"\"\"Model Params.\"\"\" model_name : str pretrained : bool input_channels : int output_dimension : int use_meta : bool @classmethod def from_dict ( cls : Type [ \"ModelParams\" ], params_dict : Dict [ str , Any ] ) -> Type [ \"ModelParams\" ]: return cls ( model_name = params_dict [ \"model_name\" ], pretrained = params_dict [ \"pretrained\" ], input_channels = params_dict [ \"input_channels\" ], output_dimension = params_dict [ \"output_dimension\" ], use_meta = params_dict [ \"use_meta\" ], ) @dataclass ( init = True , frozen = False ) class AugParams : \"\"\"Augmentation Params.\"\"\" mean : List [ float ] = field ( default_factory = lambda : [ 0.485 , 0.456 , 0.406 ]) std : List [ float ] = field ( default_factory = lambda : [ 0.229 , 0.224 , 0.225 ]) image_size : int = 256 @classmethod def from_dict ( cls : Type [ \"AugParams\" ], params_dict : Dict [ str , Any ] ) -> Type [ \"AugParams\" ]: return cls ( mean = params_dict [ \"mean\" ], std = params_dict [ \"std\" ], image_size = params_dict [ \"image_size\" ], ) @dataclass ( init = True , frozen = False ) class TrainParams : \"\"\"Global Train Params.\"\"\" epochs : int use_amp : bool @classmethod def from_dict ( cls : Type [ \"TrainParams\" ], params_dict : Dict [ str , Any ] ) -> Type [ \"TrainParams\" ]: return cls ( epochs = params_dict [ \"epochs\" ], use_amp = params_dict [ \"use_amp\" ] ) config_dict = { \"model_params\" : { \"model_name\" : \"resnet50d\" , \"out_features\" : 2 , \"in_channels\" : 3 , \"pretrained\" : False , \"use_meta\" : False , }, \"aug_params\" : { \"image_size\" : 224 , \"mean\" : [ 0.485 , 0.456 , 0.406 ], \"std\" : [ 0.229 , 0.224 , 0.225 ], }, \"train_params\" : { \"epochs\" : 10 , \"use_amp\" : True }, } train_dict = config_dict [ \"train_params\" ] train_config = TrainParams . from_dict ( params_dict = train_dict ) print ( train_config ) print ( train_config . epochs ) TrainParams(epochs=10, use_amp=True) 10 We can do the same for the rest. To Dict or Yaml You can also define method to to_dict to convert dataclass to dict. Can define variable name In yaml file, it is very difficult to define python variable inside! For example, @dataclass class FilePaths : \"\"\"Class to keep track of the files.\"\"\" train_images : Path = Path ( config . DATA_DIR , \"train\" ) I can call Path directly on the config key whereas if you put in yaml it needs a lot of tweaks. Testing We can even test our dataclass config to ensure no mistakes were made when populating the keys. # Testing import unittest class TestTrainConfig ( unittest . TestCase ): def test_example_config ( self ): raw_train_dict = { \"epochs\" : 10 , \"use_amp\" : True } expected_dict_from_dataclass = TrainParams ( epochs = 10 , use_amp = True ) self . assertEqual ( TrainParams . from_dict ( raw_train_dict ), expected_dict_from_dataclass ) TestTrainConfig () . test_example_config () References Using Dataclasses for Configuration in Python Main References https://www.youtube.com/watch?v=CvQ7e6yUtnw and his other dataclass videos.s Object-Oriented Programming (OOP) in Python 3 The main reference details a lot of practices on classes in Python. Creating a Class [ Line 1 ] : This defines a class Dog . [ Line 5 ] : The init method must take in self alongside with other optional arguments. The optional arguments are attributes . class Dog : # Class attribute species = \"Pomeranian\" def __init__ ( self , name , age ) -> None : print ( f \"Class Instance id: { id ( Dog ) } \" ) # instance attributes self . name = name self . age = age print ( f \"Object Instance id: { id ( self ) } \\n \" ) Terminologies A Class Instance Note that if you call Dog , you are creating a class instance . The unique id of this class instance should preserve the whole session. class_instance = Dog print ( class_instance ) print ( id ( class_instance )) <class '__main__.Dog'> 1834272044992 An Object Instance Once you instantiated the class instance with the __init__ method, then you have created an object instance . Note that every time you create a new object instance , that is a brand new object and thus the unique id of these objects are different. Let us see the example below: d1 = Dog ( name = \"ben\" , age = 2 ) d2 = Dog ( name = \"ben\" , age = 2 ) d3 = Dog ( name = \"ken\" , age = 10 ) print ( f \"id(d1)= { id ( d1 ) } , id(d2)= { id ( d2 ) } , id(d3)= { id ( d3 ) } \" ) print ( id ( d1 ) != id ( d2 )) Class Instance id: 1834272031776 Object Instance id: 1834276348784 Class Instance id: 1834272031776 Object Instance id: 1834276141520 Class Instance id: 1834272031776 Object Instance id: 1834276142336 id(d1)=1834276348784, id(d2)=1834276141520, id(d3)=1834276142336 True Notice even though d1 and d2 has exactly the same attributes, they belong to different objects. However, notice that their class instance id is the same throughout. Class Attributes A class attribute can be defined before the __init__ method. We can call them as such: class_instance . species 'Pomeranian' Object Attributes This is the more common attribute that we usually see. They are usually defined by assigning it to self : self . name = name self . age = age d1 . name , d1 . age , d1 . species ('ben', 2, 'Pomeranian') You can also call the class attribute from the object . Class/Object is Mutable by Default In this example, you change the .age attribute of the d1 object to \\(10\\) . Then your d1 's age will no longer be \\(2\\) . The key takeaway here is that custom objects are mutable by default . An object is mutable if it can be altered dynamically. For example, lists and dictionaries are mutable, but strings and tuples are immutable. print ( d1 . age ) d1 . age = 100 print ( d1 . age ) 2 100 A fancier way is to use setattr to do the same thing: print ( d1 . name ) setattr ( d1 , \"name\" , \"mary\" ) print ( d1 . name ) ben mary Object Instance Methods Dunder Methods https://www.tutorialsteacher.com/python/magic-methods-in-python Str vs Repr We define two common dunder methods __str__ and __repr__ . class Dog : # Class attribute species = \"Pomeranian\" def __init__ ( self , name , age ) -> None : print ( f \"Class Instance id: { id ( Dog ) } \" ) # instance attributes self . name = name self . age = age print ( f \"Object Instance id: { id ( self ) } \\n \" ) def __str__ ( self ) -> str : return f \"Species { self . species } is called { self . name } and is { self . age } years old!\" def __repr__ ( self ) -> str : return f \"Dog('name'= { self . name } ', 'age'= { self . age } )\" Basically if you print the str(d4) you get a human readable string talking about the class. repr(d4) also returns a string, but the difference is we usually want to return the \"class object representation\". See example below for intuition. d4 = Dog ( name = \"ken\" , age = 10 ) print ( str ( d4 )) print ( repr ( d4 )) Class Instance id: 1834272031776 Object Instance id: 1834277502304 Species Pomeranian is called ken and is 10 years old! Dog('name'=ken', 'age'=10) Instance Methods class Pizza : def __init__ ( self , size : float ): self . size = size self . class_instance_id = id ( Pizza ) def get_pizza_size ( self ): return self . size , self @classmethod def return_classmethod ( cls ): assert id ( cls ) == id ( Pizza ), \"The id of both must be the same!\" return cls Initialize an instance of Pizza object with size 10 named p1 . Note the id of this p1 is id(p1) . p1 = Pizza ( size = 10 ) print ( id ( p1 )) 1470722576792 You can see the method get_pizza_size() takes one parameter, self , which points to an instance of Pizza when the method is called (but of course instance methods can accept more than just one parameter). I returned self.size and self for this method. pizza_size , instance_of_pizza = p1 . get_pizza_size () Note that id(instance_of_pizza) is equals to id(p1) since self points directly to p1 . assert id ( instance_of_pizza ) == id ( p1 ) Through the self parameter, instance methods can freely access attributes and other methods on the same object. This gives them a lot of power when it comes to modifying an object\u2019s state. In our example, under this get_pizza_size method, we can access the attribute size of the Pizza object by calling self.size , which is equivalent to Pizza(size=10).size . This is powerful cause we can modify the object instance's state! For example: class Pizza : def __init__ ( self , size : float ): self . size = size def get_pizza_size ( self ): self . size = 100 return self . size , self Now if we call: p1 = Pizza ( size = 10 ) pizza_size , _ = p1 . get_pizza_size () print ( p1 . size ) 100 and note that the attribute of p1 is no longer 10 but 100 since we changed it using self . It is like doing: p1 = Pizza ( size = 10 ) p1 . size = 100 print ( p1 . size ) Class Methods Instead of accepting a self parameter, class methods take a cls parameter that points to the class\u2014and not the object instance\u2014when the method is called. Recall earlier the minor difference between a class instance vs an object instance . # 1. recall that class instance is: Pizza , p1 . return_classmethod () (__main__.Pizza, __main__.Pizza) # 2. now compare id! class_instance_id = p1 . class_instance_id class_method_id = id ( p1 . return_classmethod ()) class_instance_id , class_method_id (1470710370600, 1470710370600) So now one should be clear that within the object instance p1 , the Pizza class id must be the same as the id of cls . Example Usage class Pizza : def __init__ ( self , ingredients : List [ str ]): self . ingredients = ingredients def __repr__ ( self ): return f 'Pizza( { self . ingredients !r} )' @classmethod def margherita ( cls ): return cls ([ 'mozzarella' , 'tomatoes' ]) @classmethod def prosciutto ( cls ): return cls ([ 'mozzarella' , 'tomatoes' , 'ham' ]) First, if we want to create two object instances named margherita and prosciutto that are created by: margherita = Pizza ([ 'mozzarella' , 'tomatoes' ]) prosciutto = Pizza ([ 'mozzarella' , 'tomatoes' , 'ham' ]) A neater way is to use classmethod . Pizza . margherita (), Pizza . prosciutto () (Pizza(['mozzarella', 'tomatoes']), Pizza(['mozzarella', 'tomatoes', 'ham'])) Static Method Note static method has no self or cls , so it can neither access to the class instance nor the object instance . Then why is it useful sometimes since it is as good as I were to define the static method outside the class as a function. One reason can be understood as follows, albeit a bit of a forced example: class Pizza : def __init__ ( self , radius , ingredients ): self . radius = radius self . ingredients = ingredients def __repr__ ( self ): return ( f 'Pizza( { self . radius !r} , ' f ' { self . ingredients !r} )' ) def calculate_pizza_area ( self ): return self . calculate_circle_area ( self . radius ) @staticmethod def calculate_circle_area ( r ): return r ** 2 * math . pi Maintain your class design, even though calculate_circle_area is independent of the class/object state, one can still argue that calculating circle area is still relevant to the whole architecture of the Pizza class since we have a method to calculate pizza area. Ease of testing, one can just test the static method without initializing the object instance itself. Abstract Methods This provides us a template or blueprint in a sense. from abc import ABCMeta , abstractmethod class AbstractPizza ( metaclass = ABCMeta ): def __init__ ( self , radius : float ): self . radius = radius @abstractmethod def calculate_pizza_area ( self ): raise NotImplementedError ( \"This method needs to be implemented\" ) AbstractPizza ( radius = 10 ) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) ~\\AppData\\Local\\Temp/ipykernel_4064/1152115237.py in <module> ----> 1 AbstractPizza(radius=10) TypeError: Can't instantiate abstract class AbstractPizza with abstract method calculate_pizza_area class Pizza ( AbstractPizza ): def __init__ ( self , radius : float ): self . radius = radius Pizza ( radius = 10 ) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) ~\\AppData\\Local\\Temp/ipykernel_4064/4082189809.py in <module> ----> 1 Pizza(radius=10) TypeError: Can't instantiate abstract class Pizza with abstract method calculate_pizza_area class Pizza ( AbstractPizza ): def __init__ ( self , radius : float ): self . radius = radius def calculate_pizza_area ( self ): return self . radius ** 2 * math . pi Pizza ( radius = 10 ) <__main__.Pizza at 0x18a435d3a00> Inheritance Inheritance is the process by which one class takes on the attributes and methods of another. Newly formed classes are called child classes, and the classes that child classes are derived from are called parent classes. Intuition Child classes can override or extend the attributes and methods of parent classes. In other words, child classes inherit all of the parent\u2019s attributes and methods but can also specify attributes and methods that are unique to themselves. Although the analogy isn\u2019t perfect, you can think of object inheritance sort of like genetic inheritance. You may have inherited your hair color from your mother. It\u2019s an attribute you were born with. Let\u2019s say you decide to color your hair purple. Assuming your mother doesn\u2019t have purple hair, you\u2019ve just overridden the hair color attribute that you inherited from your mom. You also inherit, in a sense, your language from your parents. If your parents speak English, then you\u2019ll also speak English. Now imagine you decide to learn a second language, like German. In this case you\u2019ve extended your attributes because you\u2019ve added an attribute that your parents don\u2019t have. How to use Inheritance A base parent class Employee with 2 attributes: employee_id employee_name A child class that inherits the parent class called SalaryEmployee ; note the __init__ of this child class takes in 3 attributes: employee_id : from parent employee_name : from parent monthly_salary : from child It is also worth noting we used super().__init__ to take in the parent class's attributes which is the same as calling Employee.__init__(employee_id, employee_name) , both of which initializes the parents class in the child class. Intuitively, you can think of that the child class has all the attributes and methods that the parent class has. class Employee : def __init__ ( self , employee_id : int , employee_name : str ) -> None : self . employee_id = employee_id self . employee_name = employee_name class SalaryEmployee ( Employee ): def __init__ ( self , employee_id : int , employee_name : str , monthly_salary : Union [ int , float ], ) -> None : super () . __init__ ( employee_id , employee_name ) self . monthly_salary = monthly_salary def calculate_annual_salary ( self ) -> Union [ int , float ]: \"\"\"Calculate annual salary. Returns: Union[int, float]: Monthly salary * 12 \"\"\" return self . monthly_salary * 12 class CommissionEmployee ( SalaryEmployee ): def __init__ ( self , employee_id : int , employee_name : str , monthly_salary : Union [ int , float ], commission : Union [ int , float ], ) -> None : super () . __init__ ( employee_id , employee_name , monthly_salary ) self . commission = commission def calculate_annual_salary ( self ) -> Union [ int , float ]: \"\"\"Calculate annual salary + commission. Returns: Union[int, float]: Monthly salary * 12 + commission \"\"\" fixed_annual_salary = super () . calculate_annual_salary () return fixed_annual_salary + self . commission Simple example of inheritance. ken_salary = SalaryEmployee ( employee_id = 123 , employee_name = \"ken\" , monthly_salary = 5000 ) ken_salary . calculate_annual_salary () 60000 Slightly more complicated logic where one used super() in line 44. Why don't we just use fixed_annual_salary = self.monthly_salary * 12 to get the fixed year wage like how we did in SalaryEmployee . The problem with accessing the property directly is that if the implementation of SalaryEmployee.calculate_annual_salary() changes, then you\u2019ll have to also change the implementation of CommissionEmployee.calculate_annual_salary() . It\u2019s better to rely on the already implemented method in the base class and extend the functionality as needed. Calling super() in this child class will invoke the method in the parent class. So if calculate_annual_salary() in the parent class becomes something like monthly_salary * 13 , then you don't need to worry about changing the logic again in the child CommissionEmployee when calculating the total annual salary. ken_salary_and_commision = CommissionEmployee ( employee_id = 123 , employee_name = \"ken\" , monthly_salary = 5000 , commission = 10000 ) ken_salary_and_commision . calculate_annual_salary () 70000 Super Init and Inheritance Diamond https://stackoverflow.com/questions/29173299/super-init-vs-parent-init https://thepythonguru.com/python-classes-and-interfaces/ Main References Main Reference for Python Classes Designs Overall well rounder for many concepts. So if one has to choose one, this will be the one to read first or together with other references. Main Reference for Inheritance and Composition Mentions ABC class as well. Basic OOP Guide Object Instance Methods Main Reference for Python Classes Designs Python's Instance, Class, and Static Methods Demystified The definitive guide on how to use static, class or abstract methods in Python : Mostly Python 2 so slightly outdated but did mention about Python 3 inside. What is the advantage of using static methods? Class Methods in Python Args and Kwargs https://stackoverflow.com/questions/9872824/calling-a-python-function-with-args-kwargs-and-optional-default-arguments Immutable vs Hash . \u21a9 Post Init Example \u21a9","title":"Code Design"},{"location":"reighns_ml_journey/software_engineering/code_design/#imports","text":"from typing import * from dataclasses import dataclass , field from typing import List , Union , Dict import uuid","title":"Imports"},{"location":"reighns_ml_journey/software_engineering/code_design/#common-pitfalls","text":"","title":"Common Pitfalls"},{"location":"reighns_ml_journey/software_engineering/code_design/#references","text":"Common Gotchas in Python","title":"References"},{"location":"reighns_ml_journey/software_engineering/code_design/#is-none-vs-none","text":"Not much of a big difference but better to use is to compare. A small caution is below. p = [ 1 ] q = [ 1 ] False p is q # False because they are not the same actual object p == q # True because they are equivalent True","title":"Is None vs == None"},{"location":"reighns_ml_journey/software_engineering/code_design/#none0-is-false","text":"None and \\(0\\) are False by default in python, but the catch is: 0 is False evaluates to True but; None is False evaluates to False but; None is True is also False ; (not None) is True evaluates to True since (not None) is (not False) which is True ; not None is False evaluates to True since one should evaluate not (None is False) and since (None is False) is False so not False is True . not None is False # not (None is False) True","title":"None/0 is False"},{"location":"reighns_ml_journey/software_engineering/code_design/#hash","text":"hash ( \"mystring\" ), hash (( 'foo' , 'bar' )), hash ( 1 ) (7474225329682574832, -283857846903866188, 1)","title":"Hash"},{"location":"reighns_ml_journey/software_engineering/code_design/#dataclasses","text":"","title":"Dataclasses"},{"location":"reighns_ml_journey/software_engineering/code_design/#general-properties","text":"Dataclass as boiler plate as a Class For example if you want to hash your class, then you need to write __hash__ and etc which takes time, dataclass can be done easily. Why need hash? For example the dunder method __repr__ are done for you in an easy to read manner rather than the default one which points to memory address.","title":"General Properties"},{"location":"reighns_ml_journey/software_engineering/code_design/#default-factory","text":"","title":"Default Factory"},{"location":"reighns_ml_journey/software_engineering/code_design/#intuition","text":"By design, dataclass does not take in mutable default . What does that mean? Let us see a quick example.","title":"Intuition"},{"location":"reighns_ml_journey/software_engineering/code_design/#passing-mutable-default-directly-to-dataclass","text":"The following C_dataclass has init=True by default, and setting the attributes in the dataclass simply translates to a normal class with the __init__(a: int, b: int = 0) . @dataclass ( init = True ) class C_dataclass : a : int # 'a' has no default value b : int = 0 # assign a default value for 'b' class C_class : def __init__ ( self , a : int , b : int = 0 ): self . a = a self . b = b c_dataclass = C_dataclass ( a = 1 ) c_class = C_class ( a = 1 ) Notice that both classes have a default attribute b = 0 . This is totally fine! We can also set default attributes as a list for example in a normal class: class C_class : def __init__ ( self , a : int , b : int = 0 , c : List [ int ] = [ 1 , 2 , 3 ]): self . a = a self . b = b self . c = c However, if one tries to do that for dataclass , an error will pop out: ValueError : mutable default < class ' list '> for field c is not allowed: use default_factory @dataclass ( init = True ) class C_dataclass : a : int # 'a' has no default value b : int = 0 # assign a default value for 'b' c : List [ int ] = [ 1 , 2 , 3 ] But why? One major reason is that to to enforce avoidance of the mutable default argument problem .","title":"Passing Mutable Default Directly to Dataclass"},{"location":"reighns_ml_journey/software_engineering/code_design/#the-mutable-default-argument","text":"def append_to ( element , to = []): to . append ( element ) return to Let us append some values to 2 different variables: my_list = append_to ( 12 ) print ( my_list ) my_other_list = append_to ( 42 ) print ( my_other_list ) [12] [12, 42] One would expect the output to be: my_list = append_to ( 12 ) print ( my_list ) [ 12 ] my_other_list = append_to ( 42 ) print ( my_other_list ) [ 42 ] but the result is: my_list = append_to ( 12 ) print ( my_list ) [ 12 ] my_other_list = append_to ( 42 ) print ( my_other_list ) [ 12 , 42 ] A new list is created once when the function is defined, and the same list is used in each successive call. Python\u2019s default arguments are evaluated once when the function is defined, not each time the function is called (like it is in say, Ruby). This means that if you use a mutable default argument and mutate it, you will and have mutated that object for all future calls to the function as well. We hence see the same issue when passing in mutable defaults to a class: class C_class : def __init__ ( self , a : int , b : int = 0 , c : List [ int ] = [ 1 , 2 , 3 ]): self . a = a self . b = b self . c = c c1 = C_class ( a = 1 ) c2 = C_class ( a = 1 ) c1 . c . append ( 4 ) print ( c1 . c ) c2 . c . append ( 5 ) print ( c2 . c ) assert c1 . c == [ 1 , 2 , 3 , 4 , 5 ] assert c1 . c is c2 . c [1, 2, 3, 4] [1, 2, 3, 4, 5] Thus this is deeemed dangerous and dataclass does not allow you to do it out of the bat. More info on this design can be read here Mutable Default Values .","title":"The Mutable Default Argument"},{"location":"reighns_ml_journey/software_engineering/code_design/#examples-using-default-factory-to-pass-mutable-defaults","text":"The parameters to field() are: default_factory : If provided, it must be a zero-argument callable that will be called when a default value is needed for this field. Among other purposes, this can be used to specify fields with mutable default values, as discussed below. It is an error to specify both default and default_factory. @dataclass ( init = True ) class C_dataclass : a : int # 'a' has no default value b : int = 0 # assign a default value for 'b' c : List [ int ] = field ( default_factory = [ 1 , 2 , 3 ]) C_dataclass ( a = 1 ) Calling this dataclass will result in an error: TypeError : 'list' object is not callable because you are passing in a list of values and not what default_factory expects, a zero-argument callable . What is a zero-argument callable ? The examples below illustrates: Indeed, a list with values is not a function or class method, and hence not callable if you put the \"parenthesis\" () behind. The same error occurs. default_factory = [ 1 , 2 , 3 ] default_factory () --------------------------------------------------------------------------- TypeError Traceback (most recent call last) ~\\AppData\\Local\\Temp/ipykernel_4064/3467513020.py in <module> 1 default_factory = [1, 2, 3] ----> 2 default_factory() TypeError: 'list' object is not callable Now if we set default_factory as a function that returns the list [1, 2, 3] , then it is indeed callable and in fact, it's zero-argument callable since this function call takes in zero arguments : default_factory = lambda : [ 1 , 2 , 3 ] default_factory () So remember, if you want pass in a default mutable object with values inside, set a lambda as such: @dataclass ( init = True ) class C_dataclass : a : int # 'a' has no default value b : int = 0 # assign a default value for 'b' c : List [ int ] = field ( default_factory = lambda : [ 1 , 2 , 3 ]) c1 = C_dataclass ( a = 1 ) c1 . c [1, 2, 3]","title":"Examples (Using Default Factory to Pass Mutable Defaults)"},{"location":"reighns_ml_journey/software_engineering/code_design/#generate-functions-in-default-factory-important-for-model-registry","text":"This is very very useful especially if you are doing a ML project with multiple experiments, each experiments should be stored in an unique folder as a form of model registry. sample directory 1 2 3 4 5 6 7 8 model_registry/ exp1_uuid4/ weights/ logs/ ... exp2_uuid4/ weights/ logs/ We can simply say create a function called generate_uuid4() and pass it to field 's default_factory and it will generate a new unique id for each run of experiment. def generate_uuid4 () -> str : \"\"\"Generate a random UUID4. Returns: str: Random UUID4 \"\"\" return str ( uuid . uuid4 ()) @dataclass ( init = True , frozen = False ) class ModelRegistry : \"\"\"A class to keep track of model artifacts.\"\"\" project_name : str = \"pkd\" unique_id : str = field ( default_factory = generate_uuid4 ) exp1 = ModelRegistry ( project_name = \"pkd\" ) exp1 . unique_id 'd6f3eb61-72f7-4ed4-9637-6df42a179bdf' exp2 = ModelRegistry () exp2 . unique_id '56d5f4f8-adca-4e2c-a5f3-9207da7d1c9a' Although the unique_id should be run by the random generator uuid , users are allowed to modify it and that is something we do not want. We can therefore set init=False inside the field so it \"won't\" initialize let's see example below: # example where user can modify exp3 = ModelRegistry ( project_name = \"pkd\" , unique_id = \"123\" ) exp3 . unique_id '123' @dataclass ( init = True , frozen = False ) class ModelRegistry : \"\"\"A class to keep track of model artifacts.\"\"\" project_name : str = \"PeekingDuck\" unique_id : str = field ( init = False , default_factory = generate_uuid4 ) # example where user CANNOT modify and throws error exp3 = ModelRegistry ( project_name = \"pkd\" , unique_id = \"123\" ) exp3 . unique_id --------------------------------------------------------------------------- TypeError Traceback (most recent call last) ~\\AppData\\Local\\Temp/ipykernel_20736/826619969.py in <module> 1 # example where user CANNOT modify and throws error ----> 2 exp3 = ModelRegistry(project_name=\"pkd\", unique_id=\"123\") 3 exp3.unique_id TypeError: __init__() got an unexpected keyword argument 'unique_id' # you should not set the unique id yourself. exp3 = ModelRegistry ( project_name = \"pkd\" ) exp3 . unique_id '91679660-a805-423a-bb76-feffede8c731'","title":"Generate Functions in Default Factory (Important for Model Registry!)"},{"location":"reighns_ml_journey/software_engineering/code_design/#references_1","text":"Passing default list argument to dataclasses Why can't dataclasses have mutable defaults in their class attributes declaration? Mutable Default Values This is why python dataclasses are awesome","title":"References"},{"location":"reighns_ml_journey/software_engineering/code_design/#frozen-hashablemutable","text":"","title":"Frozen (Hashable/Mutable)"},{"location":"reighns_ml_journey/software_engineering/code_design/#intuition_1","text":"When frozen is True, the dataclass is an immuatable object and immutable means you can't change the attributes or characteristics of an object after it's initialised. Note hash and immutable is a bit similar 1 . Tip Generally, making an object mutable is good since it stays constant. No surprises :)","title":"Intuition"},{"location":"reighns_ml_journey/software_engineering/code_design/#examples","text":"Let us see the below example, both AugParamsFrozenTrue and AugParamsFrozenFalse have the same attributes, the only difference is that one is frozen and the other isn't. @dataclass ( init = True , frozen = True ) class AugParamsFrozenTrue : \"\"\"Class to keep track of the augmentation parameters.\"\"\" mean : List [ float ] = field ( default_factory = lambda : [ 0.485 , 0.456 , 0.406 ]) std : List [ float ] = field ( default_factory = lambda : [ 0.229 , 0.224 , 0.225 ]) image_size : int = 256 mixup : bool = False mixup_params : Dict [ str , Any ] = field ( default_factory = lambda : { \"mixup_alpha\" : 1 , \"use_cuda\" : True } ) When we freeze the dataclass AugParamsFrozenTrue then we can no longer change its attribute instances . For example, we cannot re-assign the mean attribute. aug_frozen_true = AugParamsFrozenTrue () print ( id ( aug_frozen_true . mean )) aug_frozen_true . mean = [ 1 , 2 , 3 ] # same as setattr(aug_frozen_true, \"mean\", [1, 2, 3]) 1693345842112 --------------------------------------------------------------------------- FrozenInstanceError Traceback (most recent call last) ~\\AppData\\Local\\Temp/ipykernel_4064/656634435.py in <module> 1 aug_frozen_true = AugParamsFrozenTrue() 2 print(id(aug_frozen_true.mean)) ----> 3 aug_frozen_true.mean = [1, 2, 3] # same as setattr(aug_frozen_true, \"mean\", [1, 2, 3]) <string> in __setattr__(self, name, value) FrozenInstanceError: cannot assign to field 'mean' However, frozen only applies to the dataclass instance itself \u2013 a frozen dataclass can contain mutable items such as lists, and a regular dataclass can contain frozen/immutable items such as tuples. This means that I can change the state of the attribute by mutating the list itself. Therefore, one must be careful that freezing a dataclass does not guarantee immutability of all its attributes. aug_frozen_true . mean [ 0 ] = 1 aug_frozen_true . mean [ 1 ] = 2 aug_frozen_true . mean [ 2 ] = 3 print ( aug_frozen_true . mean ) print ( id ( aug_frozen_true . mean )) [1, 2, 3] 1693345842112 On the other hand, if one set frozen=False , then it is just like any other class in Python, you can re-assign the attributes freely. @dataclass ( init = True , frozen = False ) class AugParamsFrozenFalse : \"\"\"Class to keep track of the augmentation parameters.\"\"\" mean : List [ float ] = field ( default_factory = lambda : [ 0.485 , 0.456 , 0.406 ]) std : List [ float ] = field ( default_factory = lambda : [ 0.229 , 0.224 , 0.225 ]) image_size : int = 256 mixup : bool = False mixup_params : Dict [ str , Any ] = field ( default_factory = lambda : { \"mixup_alpha\" : 1 , \"use_cuda\" : True } ) aug_frozen_false = AugParamsFrozenFalse () print ( id ( aug_frozen_false . mean )) print ( aug_frozen_false . mean ) print () aug_frozen_false . mean = [ 1 , 2 , 3 ] print ( id ( aug_frozen_false . mean )) print ( aug_frozen_false . mean ) 1693347054912 [0.485, 0.456, 0.406] 1693345843648 [1, 2, 3]","title":"Examples"},{"location":"reighns_ml_journey/software_engineering/code_design/#references_2","text":"What is immutability and why should I worry about it? What does frozen mean for dataclasses?","title":"References"},{"location":"reighns_ml_journey/software_engineering/code_design/#post-init-2","text":"Notice the example below that average_marks is an attribute that can only be known after marks is known. So we can set field(init=False) and tabulate using __post_init__ .","title":"Post Init 2"},{"location":"reighns_ml_journey/software_engineering/code_design/#examples-post-init","text":"A dunder method: Motivation: you want an \"attribute\" that is derived from your other instance attributes; Average marks of a student for example can only be known when all his \"marks\" are known; We set average_marks as an attribute BUT init is False so it is not initialized by the class as we won't know it yet + we won't pass it in the dataclass; post_init helps us to calculate and return back the average marks. Tip average_marks should be a private member cause it is not something you want the user to call and change! @dataclass ( init = True , frozen = False ) class Student : name : str student_id : int marks : List [ Union [ int , float ]] _average_marks : float = field ( init = False ) def __post_init__ ( self ) -> Union [ int , float ]: self . _average_marks = sum ( self . marks ) / len ( self . marks ) student = Student ( name = \"hongnan\" , student_id = \"123\" , marks = [ 88 , 92 , 96 ]) print ( student ) print ( student . average_marks ) Student(name='hongnan', student_id='123', marks=[88, 92, 96], average_marks=92.0) 92.0","title":"Examples (Post Init)"},{"location":"reighns_ml_journey/software_engineering/code_design/#using-dataclass-as-config-file","text":"","title":"Using Dataclass as Config File"},{"location":"reighns_ml_journey/software_engineering/code_design/#intuition_2","text":"Usually we store configurations in a .yaml file or the likes and load it as dict in our script and subsequently use the dict as a way to get the config values. We will now introduce a way to store our config in a dataclass : This method has a ton of benefits: We get code completion and type hints in the editor It's easier to maintain, since you only have to change a config property name in one place Can implement version reconciliation in the from_dict method Refactoring is a breeze, since editors can auto-refactor class property names Allows you to define configurations with python code, since you can instantiate the dataclasses directly in a settings.py file, for example It's testable.","title":"Intuition"},{"location":"reighns_ml_journey/software_engineering/code_design/#parsing-from-dict","text":"Consider a config file in yaml to be the following: model_params : { model_name : resnet50d , out_features : 2 , in_channels : 3 , pretrained : false , use_meta : false } aug_params : { image_size : 224 , mean : [ 0.485 , 0.456 , 0.406 ], std : [ 0.229 , 0.224 , 0.225 ] } train_params : { epochs : 10 , use_amp : true } We can easily parse it into a python dict by: import yaml from pathlib import Path config_dict = yaml . safe_load ( Path ( \"tmp.yaml\" ) . read_text ()) to get { \"model_params\" : { \"model_name\" : \"resnet50d\" , \"out_features\" : 2 , \"in_channels\" : 3 , \"pretrained\" : False , \"use_meta\" : False , }, \"aug_params\" : { \"image_size\" : 224 , \"mean\" : [ 0.485 , 0.456 , 0.406 ], \"std\" : [ 0.229 , 0.224 , 0.225 ], }, \"train_params\" : { \"epochs\" : 10 , \"use_amp\" : True }, } Whenever we want to use the config, we can call say config_dict[model_params][\"model_name\"] . This is cumbersome if the dict is very nested; This is prone to error as you need to write the correct keys; This is difficult to refactor and hard to read. Most importantly, we can parse the config file to multiple sub-configs that is responsible for each part of the configuration, for example, we can create 3 dataclasses named ModelParams , AugParams and TrainParams to indicate what each config does. @dataclass ( init = True , frozen = False ) class ModelParams : \"\"\"Model Params.\"\"\" model_name : str pretrained : bool input_channels : int output_dimension : int use_meta : bool @classmethod def from_dict ( cls : Type [ \"ModelParams\" ], params_dict : Dict [ str , Any ] ) -> Type [ \"ModelParams\" ]: return cls ( model_name = params_dict [ \"model_name\" ], pretrained = params_dict [ \"pretrained\" ], input_channels = params_dict [ \"input_channels\" ], output_dimension = params_dict [ \"output_dimension\" ], use_meta = params_dict [ \"use_meta\" ], ) @dataclass ( init = True , frozen = False ) class AugParams : \"\"\"Augmentation Params.\"\"\" mean : List [ float ] = field ( default_factory = lambda : [ 0.485 , 0.456 , 0.406 ]) std : List [ float ] = field ( default_factory = lambda : [ 0.229 , 0.224 , 0.225 ]) image_size : int = 256 @classmethod def from_dict ( cls : Type [ \"AugParams\" ], params_dict : Dict [ str , Any ] ) -> Type [ \"AugParams\" ]: return cls ( mean = params_dict [ \"mean\" ], std = params_dict [ \"std\" ], image_size = params_dict [ \"image_size\" ], ) @dataclass ( init = True , frozen = False ) class TrainParams : \"\"\"Global Train Params.\"\"\" epochs : int use_amp : bool @classmethod def from_dict ( cls : Type [ \"TrainParams\" ], params_dict : Dict [ str , Any ] ) -> Type [ \"TrainParams\" ]: return cls ( epochs = params_dict [ \"epochs\" ], use_amp = params_dict [ \"use_amp\" ] ) config_dict = { \"model_params\" : { \"model_name\" : \"resnet50d\" , \"out_features\" : 2 , \"in_channels\" : 3 , \"pretrained\" : False , \"use_meta\" : False , }, \"aug_params\" : { \"image_size\" : 224 , \"mean\" : [ 0.485 , 0.456 , 0.406 ], \"std\" : [ 0.229 , 0.224 , 0.225 ], }, \"train_params\" : { \"epochs\" : 10 , \"use_amp\" : True }, } train_dict = config_dict [ \"train_params\" ] train_config = TrainParams . from_dict ( params_dict = train_dict ) print ( train_config ) print ( train_config . epochs ) TrainParams(epochs=10, use_amp=True) 10 We can do the same for the rest.","title":"Parsing from Dict"},{"location":"reighns_ml_journey/software_engineering/code_design/#to-dict-or-yaml","text":"You can also define method to to_dict to convert dataclass to dict.","title":"To Dict or Yaml"},{"location":"reighns_ml_journey/software_engineering/code_design/#can-define-variable-name","text":"In yaml file, it is very difficult to define python variable inside! For example, @dataclass class FilePaths : \"\"\"Class to keep track of the files.\"\"\" train_images : Path = Path ( config . DATA_DIR , \"train\" ) I can call Path directly on the config key whereas if you put in yaml it needs a lot of tweaks.","title":"Can define variable name"},{"location":"reighns_ml_journey/software_engineering/code_design/#testing","text":"We can even test our dataclass config to ensure no mistakes were made when populating the keys. # Testing import unittest class TestTrainConfig ( unittest . TestCase ): def test_example_config ( self ): raw_train_dict = { \"epochs\" : 10 , \"use_amp\" : True } expected_dict_from_dataclass = TrainParams ( epochs = 10 , use_amp = True ) self . assertEqual ( TrainParams . from_dict ( raw_train_dict ), expected_dict_from_dataclass ) TestTrainConfig () . test_example_config ()","title":"Testing"},{"location":"reighns_ml_journey/software_engineering/code_design/#references_3","text":"Using Dataclasses for Configuration in Python","title":"References"},{"location":"reighns_ml_journey/software_engineering/code_design/#main-references","text":"https://www.youtube.com/watch?v=CvQ7e6yUtnw and his other dataclass videos.s","title":"Main References"},{"location":"reighns_ml_journey/software_engineering/code_design/#object-oriented-programming-oop-in-python-3","text":"The main reference details a lot of practices on classes in Python.","title":"Object-Oriented Programming (OOP) in Python 3"},{"location":"reighns_ml_journey/software_engineering/code_design/#creating-a-class","text":"[ Line 1 ] : This defines a class Dog . [ Line 5 ] : The init method must take in self alongside with other optional arguments. The optional arguments are attributes . class Dog : # Class attribute species = \"Pomeranian\" def __init__ ( self , name , age ) -> None : print ( f \"Class Instance id: { id ( Dog ) } \" ) # instance attributes self . name = name self . age = age print ( f \"Object Instance id: { id ( self ) } \\n \" )","title":"Creating a Class"},{"location":"reighns_ml_journey/software_engineering/code_design/#terminologies","text":"","title":"Terminologies"},{"location":"reighns_ml_journey/software_engineering/code_design/#a-class-instance","text":"Note that if you call Dog , you are creating a class instance . The unique id of this class instance should preserve the whole session. class_instance = Dog print ( class_instance ) print ( id ( class_instance )) <class '__main__.Dog'> 1834272044992","title":"A Class Instance"},{"location":"reighns_ml_journey/software_engineering/code_design/#an-object-instance","text":"Once you instantiated the class instance with the __init__ method, then you have created an object instance . Note that every time you create a new object instance , that is a brand new object and thus the unique id of these objects are different. Let us see the example below: d1 = Dog ( name = \"ben\" , age = 2 ) d2 = Dog ( name = \"ben\" , age = 2 ) d3 = Dog ( name = \"ken\" , age = 10 ) print ( f \"id(d1)= { id ( d1 ) } , id(d2)= { id ( d2 ) } , id(d3)= { id ( d3 ) } \" ) print ( id ( d1 ) != id ( d2 )) Class Instance id: 1834272031776 Object Instance id: 1834276348784 Class Instance id: 1834272031776 Object Instance id: 1834276141520 Class Instance id: 1834272031776 Object Instance id: 1834276142336 id(d1)=1834276348784, id(d2)=1834276141520, id(d3)=1834276142336 True Notice even though d1 and d2 has exactly the same attributes, they belong to different objects. However, notice that their class instance id is the same throughout.","title":"An Object Instance"},{"location":"reighns_ml_journey/software_engineering/code_design/#class-attributes","text":"A class attribute can be defined before the __init__ method. We can call them as such: class_instance . species 'Pomeranian'","title":"Class Attributes"},{"location":"reighns_ml_journey/software_engineering/code_design/#object-attributes","text":"This is the more common attribute that we usually see. They are usually defined by assigning it to self : self . name = name self . age = age d1 . name , d1 . age , d1 . species ('ben', 2, 'Pomeranian') You can also call the class attribute from the object .","title":"Object Attributes"},{"location":"reighns_ml_journey/software_engineering/code_design/#classobject-is-mutable-by-default","text":"In this example, you change the .age attribute of the d1 object to \\(10\\) . Then your d1 's age will no longer be \\(2\\) . The key takeaway here is that custom objects are mutable by default . An object is mutable if it can be altered dynamically. For example, lists and dictionaries are mutable, but strings and tuples are immutable. print ( d1 . age ) d1 . age = 100 print ( d1 . age ) 2 100 A fancier way is to use setattr to do the same thing: print ( d1 . name ) setattr ( d1 , \"name\" , \"mary\" ) print ( d1 . name ) ben mary","title":"Class/Object is Mutable by Default"},{"location":"reighns_ml_journey/software_engineering/code_design/#object-instance-methods","text":"","title":"Object Instance Methods"},{"location":"reighns_ml_journey/software_engineering/code_design/#dunder-methods","text":"https://www.tutorialsteacher.com/python/magic-methods-in-python","title":"Dunder Methods"},{"location":"reighns_ml_journey/software_engineering/code_design/#str-vs-repr","text":"We define two common dunder methods __str__ and __repr__ . class Dog : # Class attribute species = \"Pomeranian\" def __init__ ( self , name , age ) -> None : print ( f \"Class Instance id: { id ( Dog ) } \" ) # instance attributes self . name = name self . age = age print ( f \"Object Instance id: { id ( self ) } \\n \" ) def __str__ ( self ) -> str : return f \"Species { self . species } is called { self . name } and is { self . age } years old!\" def __repr__ ( self ) -> str : return f \"Dog('name'= { self . name } ', 'age'= { self . age } )\" Basically if you print the str(d4) you get a human readable string talking about the class. repr(d4) also returns a string, but the difference is we usually want to return the \"class object representation\". See example below for intuition. d4 = Dog ( name = \"ken\" , age = 10 ) print ( str ( d4 )) print ( repr ( d4 )) Class Instance id: 1834272031776 Object Instance id: 1834277502304 Species Pomeranian is called ken and is 10 years old! Dog('name'=ken', 'age'=10)","title":"Str vs Repr"},{"location":"reighns_ml_journey/software_engineering/code_design/#instance-methods","text":"class Pizza : def __init__ ( self , size : float ): self . size = size self . class_instance_id = id ( Pizza ) def get_pizza_size ( self ): return self . size , self @classmethod def return_classmethod ( cls ): assert id ( cls ) == id ( Pizza ), \"The id of both must be the same!\" return cls Initialize an instance of Pizza object with size 10 named p1 . Note the id of this p1 is id(p1) . p1 = Pizza ( size = 10 ) print ( id ( p1 )) 1470722576792 You can see the method get_pizza_size() takes one parameter, self , which points to an instance of Pizza when the method is called (but of course instance methods can accept more than just one parameter). I returned self.size and self for this method. pizza_size , instance_of_pizza = p1 . get_pizza_size () Note that id(instance_of_pizza) is equals to id(p1) since self points directly to p1 . assert id ( instance_of_pizza ) == id ( p1 ) Through the self parameter, instance methods can freely access attributes and other methods on the same object. This gives them a lot of power when it comes to modifying an object\u2019s state. In our example, under this get_pizza_size method, we can access the attribute size of the Pizza object by calling self.size , which is equivalent to Pizza(size=10).size . This is powerful cause we can modify the object instance's state! For example: class Pizza : def __init__ ( self , size : float ): self . size = size def get_pizza_size ( self ): self . size = 100 return self . size , self Now if we call: p1 = Pizza ( size = 10 ) pizza_size , _ = p1 . get_pizza_size () print ( p1 . size ) 100 and note that the attribute of p1 is no longer 10 but 100 since we changed it using self . It is like doing: p1 = Pizza ( size = 10 ) p1 . size = 100 print ( p1 . size )","title":"Instance Methods"},{"location":"reighns_ml_journey/software_engineering/code_design/#class-methods","text":"Instead of accepting a self parameter, class methods take a cls parameter that points to the class\u2014and not the object instance\u2014when the method is called. Recall earlier the minor difference between a class instance vs an object instance . # 1. recall that class instance is: Pizza , p1 . return_classmethod () (__main__.Pizza, __main__.Pizza) # 2. now compare id! class_instance_id = p1 . class_instance_id class_method_id = id ( p1 . return_classmethod ()) class_instance_id , class_method_id (1470710370600, 1470710370600) So now one should be clear that within the object instance p1 , the Pizza class id must be the same as the id of cls .","title":"Class Methods"},{"location":"reighns_ml_journey/software_engineering/code_design/#example-usage","text":"class Pizza : def __init__ ( self , ingredients : List [ str ]): self . ingredients = ingredients def __repr__ ( self ): return f 'Pizza( { self . ingredients !r} )' @classmethod def margherita ( cls ): return cls ([ 'mozzarella' , 'tomatoes' ]) @classmethod def prosciutto ( cls ): return cls ([ 'mozzarella' , 'tomatoes' , 'ham' ]) First, if we want to create two object instances named margherita and prosciutto that are created by: margherita = Pizza ([ 'mozzarella' , 'tomatoes' ]) prosciutto = Pizza ([ 'mozzarella' , 'tomatoes' , 'ham' ]) A neater way is to use classmethod . Pizza . margherita (), Pizza . prosciutto () (Pizza(['mozzarella', 'tomatoes']), Pizza(['mozzarella', 'tomatoes', 'ham']))","title":"Example Usage"},{"location":"reighns_ml_journey/software_engineering/code_design/#static-method","text":"Note static method has no self or cls , so it can neither access to the class instance nor the object instance . Then why is it useful sometimes since it is as good as I were to define the static method outside the class as a function. One reason can be understood as follows, albeit a bit of a forced example: class Pizza : def __init__ ( self , radius , ingredients ): self . radius = radius self . ingredients = ingredients def __repr__ ( self ): return ( f 'Pizza( { self . radius !r} , ' f ' { self . ingredients !r} )' ) def calculate_pizza_area ( self ): return self . calculate_circle_area ( self . radius ) @staticmethod def calculate_circle_area ( r ): return r ** 2 * math . pi Maintain your class design, even though calculate_circle_area is independent of the class/object state, one can still argue that calculating circle area is still relevant to the whole architecture of the Pizza class since we have a method to calculate pizza area. Ease of testing, one can just test the static method without initializing the object instance itself.","title":"Static Method"},{"location":"reighns_ml_journey/software_engineering/code_design/#abstract-methods","text":"This provides us a template or blueprint in a sense. from abc import ABCMeta , abstractmethod class AbstractPizza ( metaclass = ABCMeta ): def __init__ ( self , radius : float ): self . radius = radius @abstractmethod def calculate_pizza_area ( self ): raise NotImplementedError ( \"This method needs to be implemented\" ) AbstractPizza ( radius = 10 ) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) ~\\AppData\\Local\\Temp/ipykernel_4064/1152115237.py in <module> ----> 1 AbstractPizza(radius=10) TypeError: Can't instantiate abstract class AbstractPizza with abstract method calculate_pizza_area class Pizza ( AbstractPizza ): def __init__ ( self , radius : float ): self . radius = radius Pizza ( radius = 10 ) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) ~\\AppData\\Local\\Temp/ipykernel_4064/4082189809.py in <module> ----> 1 Pizza(radius=10) TypeError: Can't instantiate abstract class Pizza with abstract method calculate_pizza_area class Pizza ( AbstractPizza ): def __init__ ( self , radius : float ): self . radius = radius def calculate_pizza_area ( self ): return self . radius ** 2 * math . pi Pizza ( radius = 10 ) <__main__.Pizza at 0x18a435d3a00>","title":"Abstract Methods"},{"location":"reighns_ml_journey/software_engineering/code_design/#inheritance","text":"Inheritance is the process by which one class takes on the attributes and methods of another. Newly formed classes are called child classes, and the classes that child classes are derived from are called parent classes.","title":"Inheritance"},{"location":"reighns_ml_journey/software_engineering/code_design/#intuition_3","text":"Child classes can override or extend the attributes and methods of parent classes. In other words, child classes inherit all of the parent\u2019s attributes and methods but can also specify attributes and methods that are unique to themselves. Although the analogy isn\u2019t perfect, you can think of object inheritance sort of like genetic inheritance. You may have inherited your hair color from your mother. It\u2019s an attribute you were born with. Let\u2019s say you decide to color your hair purple. Assuming your mother doesn\u2019t have purple hair, you\u2019ve just overridden the hair color attribute that you inherited from your mom. You also inherit, in a sense, your language from your parents. If your parents speak English, then you\u2019ll also speak English. Now imagine you decide to learn a second language, like German. In this case you\u2019ve extended your attributes because you\u2019ve added an attribute that your parents don\u2019t have.","title":"Intuition"},{"location":"reighns_ml_journey/software_engineering/code_design/#how-to-use-inheritance","text":"A base parent class Employee with 2 attributes: employee_id employee_name A child class that inherits the parent class called SalaryEmployee ; note the __init__ of this child class takes in 3 attributes: employee_id : from parent employee_name : from parent monthly_salary : from child It is also worth noting we used super().__init__ to take in the parent class's attributes which is the same as calling Employee.__init__(employee_id, employee_name) , both of which initializes the parents class in the child class. Intuitively, you can think of that the child class has all the attributes and methods that the parent class has. class Employee : def __init__ ( self , employee_id : int , employee_name : str ) -> None : self . employee_id = employee_id self . employee_name = employee_name class SalaryEmployee ( Employee ): def __init__ ( self , employee_id : int , employee_name : str , monthly_salary : Union [ int , float ], ) -> None : super () . __init__ ( employee_id , employee_name ) self . monthly_salary = monthly_salary def calculate_annual_salary ( self ) -> Union [ int , float ]: \"\"\"Calculate annual salary. Returns: Union[int, float]: Monthly salary * 12 \"\"\" return self . monthly_salary * 12 class CommissionEmployee ( SalaryEmployee ): def __init__ ( self , employee_id : int , employee_name : str , monthly_salary : Union [ int , float ], commission : Union [ int , float ], ) -> None : super () . __init__ ( employee_id , employee_name , monthly_salary ) self . commission = commission def calculate_annual_salary ( self ) -> Union [ int , float ]: \"\"\"Calculate annual salary + commission. Returns: Union[int, float]: Monthly salary * 12 + commission \"\"\" fixed_annual_salary = super () . calculate_annual_salary () return fixed_annual_salary + self . commission Simple example of inheritance. ken_salary = SalaryEmployee ( employee_id = 123 , employee_name = \"ken\" , monthly_salary = 5000 ) ken_salary . calculate_annual_salary () 60000 Slightly more complicated logic where one used super() in line 44. Why don't we just use fixed_annual_salary = self.monthly_salary * 12 to get the fixed year wage like how we did in SalaryEmployee . The problem with accessing the property directly is that if the implementation of SalaryEmployee.calculate_annual_salary() changes, then you\u2019ll have to also change the implementation of CommissionEmployee.calculate_annual_salary() . It\u2019s better to rely on the already implemented method in the base class and extend the functionality as needed. Calling super() in this child class will invoke the method in the parent class. So if calculate_annual_salary() in the parent class becomes something like monthly_salary * 13 , then you don't need to worry about changing the logic again in the child CommissionEmployee when calculating the total annual salary. ken_salary_and_commision = CommissionEmployee ( employee_id = 123 , employee_name = \"ken\" , monthly_salary = 5000 , commission = 10000 ) ken_salary_and_commision . calculate_annual_salary () 70000","title":"How to use Inheritance"},{"location":"reighns_ml_journey/software_engineering/code_design/#super-init-and-inheritance-diamond","text":"https://stackoverflow.com/questions/29173299/super-init-vs-parent-init https://thepythonguru.com/python-classes-and-interfaces/","title":"Super Init and Inheritance Diamond"},{"location":"reighns_ml_journey/software_engineering/code_design/#main-references_1","text":"Main Reference for Python Classes Designs Overall well rounder for many concepts. So if one has to choose one, this will be the one to read first or together with other references. Main Reference for Inheritance and Composition Mentions ABC class as well. Basic OOP Guide Object Instance Methods Main Reference for Python Classes Designs Python's Instance, Class, and Static Methods Demystified The definitive guide on how to use static, class or abstract methods in Python : Mostly Python 2 so slightly outdated but did mention about Python 3 inside. What is the advantage of using static methods?","title":"Main References"},{"location":"reighns_ml_journey/software_engineering/code_design/#class-methods-in-python","text":"","title":"Class Methods in Python"},{"location":"reighns_ml_journey/software_engineering/code_design/#args-and-kwargs","text":"https://stackoverflow.com/questions/9872824/calling-a-python-function-with-args-kwargs-and-optional-default-arguments Immutable vs Hash . \u21a9 Post Init Example \u21a9","title":"Args and Kwargs"},{"location":"reighns_ml_journey/software_engineering/gcp/","text":"GCP Bucket This is a tutorial for myself on how to setup GCP Bucket and use python to upload/download files. These are references here 2 . Create GCP Bucket We first create GCP Bucket here by following the steps here 1 . Python Google Cloud Storage Install the Cloud Client Libraries for Python for an individual API like Cloud Storage !pip install --upgrade google-cloud-storage Install Cloud SDK Install Cloud SDK which can be used to access Cloud Storage services from the command line and then do gcloud auth application-default login . Note that this command generates credentials for client libraries. The steps are detailed here 3 . After installation, we need to install gcloud . !pip install gcloud You can also install Cloud SDK in command line: # Windows ( New-Object Net.WebClient ) .DownloadFile ( \"https://dl.google.com/dl/cloudsdk/channels/rapid/GoogleCloudSDKInstaller.exe\" , \" $env :Temp\\GoogleCloudSDKInstaller.exe\" ) & $env :Temp \\G oogleCloudSDKInstaller.exe Follow the prompts to install the Cloud SDK. Note it will also ask you to set the default project. You can choose the project you want to use. Setup Service Account We open cmd prompt, cd to the directory where you are working on, then type gcloud auth login . Since I do not have a service account, we follow this link 4 and follow the steps using either the Cloud Consoler or Command Line. (I prefer the Cloud Console). The documentation is clear and you just need to follow the steps. Create a service account key by the following: 1. In the Cloud Console, click the email address for the service account that you created. 2. Click Keys. 3. Click Add key, then click Create new key. 4. Click Create. A JSON key file is downloaded to your computer. 5. Click Close. Setup Authenticated Environment Now you have a json file from previous step. Put the json file in a folder. Then everytime you start a terminal or new window, you can use $env :GOOGLE_APPLICATION_CREDENTIALS = \" $PATH$TO$JSON \" It seems a hassle to type the command everytime. May look into this link 5 and this 6 to see how to setup the environment. Upload and Download Files from gcloud import storage def return_bucket ( project_id : str ) -> List : \"\"\"Return a list of buckets for a given project. Args: project_id (str): The project id. Returns: List: A list of buckets. \"\"\" storage_client = storage . Client ( project = project_id ) buckets = list ( storage_client . list_buckets ()) return buckets def upload_to_bucket ( source_file_name : str , destination_blob_name : str , bucket_name : str , project_id : str , ) -> str : \"\"\"Uploads a file to the bucket and returns the public url. Args: source_file_name (str): The file in local that you want to upload. destination_blob_name (str): The name of the file in the bucket. To include full path. bucket_name (str): The name of the bucket. \"\"\" storage_client = storage . Client ( project = project_id ) bucket = storage_client . bucket ( bucket_name ) blob = bucket . blob ( destination_blob_name ) blob . upload_from_filename ( source_file_name ) print ( f \"file { source_file_name } uploaded to bucket { bucket_name } successfully!\" ) return blob . public_url def download_from_bucket ( source_file_name : str , destination_blob_name : str , bucket_name : str , project_id : str , ) -> None : \"\"\"Download file from GCP bucket. Just do the opposite of upload_to_bucket.\"\"\" storage_client = storage . Client ( project = project_id ) bucket = storage_client . bucket ( bucket_name ) blob = bucket . blob ( destination_blob_name ) blob . download_to_filename ( source_file_name ) if __name__ == \"__main__\" : PROJECT_ID = \"Your Project ID\" BUCKET_NAME = \"Bucket Name\" SOURCE_FILE_NAME = \"Source File Name stored Locally\" DESTINATION_BLOB_NAME = \"Destination File Name in GCP Bucket\" upload_to_bucket ( SOURCE_FILE_NAME , DESTINATION_BLOB_NAME , BUCKET_NAME , PROJECT_ID ) download_from_bucket ( SOURCE_FILE_NAME , DESTINATION_BLOB_NAME , BUCKET_NAME , PROJECT_ID ) If you want to mass upload or download, you just need to create a loop as such: for file in os . listdir ( path ): upload_to_bucket ( SOURCE_FILE_NAME , DESTINATION_BLOB_NAME , BUCKET_NAME , PROJECT_ID ) Creating GCP Buckets \u21a9 How to write files from Local to GCP using Python \u21a9 Install Cloud SDK \u21a9 Service Account \u21a9 How to upload a file to Google Cloud Storage on Python 3? \u21a9 Setting GOOGLE_APPLICATION_CREDENTIALS for BigQuery Python CLI \u21a9","title":"GCP"},{"location":"reighns_ml_journey/software_engineering/gcp/#gcp-bucket","text":"This is a tutorial for myself on how to setup GCP Bucket and use python to upload/download files. These are references here 2 .","title":"GCP Bucket"},{"location":"reighns_ml_journey/software_engineering/gcp/#create-gcp-bucket","text":"We first create GCP Bucket here by following the steps here 1 .","title":"Create GCP Bucket"},{"location":"reighns_ml_journey/software_engineering/gcp/#python-google-cloud-storage","text":"Install the Cloud Client Libraries for Python for an individual API like Cloud Storage !pip install --upgrade google-cloud-storage","title":"Python Google Cloud Storage"},{"location":"reighns_ml_journey/software_engineering/gcp/#install-cloud-sdk","text":"Install Cloud SDK which can be used to access Cloud Storage services from the command line and then do gcloud auth application-default login . Note that this command generates credentials for client libraries. The steps are detailed here 3 . After installation, we need to install gcloud . !pip install gcloud You can also install Cloud SDK in command line: # Windows ( New-Object Net.WebClient ) .DownloadFile ( \"https://dl.google.com/dl/cloudsdk/channels/rapid/GoogleCloudSDKInstaller.exe\" , \" $env :Temp\\GoogleCloudSDKInstaller.exe\" ) & $env :Temp \\G oogleCloudSDKInstaller.exe Follow the prompts to install the Cloud SDK. Note it will also ask you to set the default project. You can choose the project you want to use.","title":"Install Cloud SDK"},{"location":"reighns_ml_journey/software_engineering/gcp/#setup-service-account","text":"We open cmd prompt, cd to the directory where you are working on, then type gcloud auth login . Since I do not have a service account, we follow this link 4 and follow the steps using either the Cloud Consoler or Command Line. (I prefer the Cloud Console). The documentation is clear and you just need to follow the steps. Create a service account key by the following: 1. In the Cloud Console, click the email address for the service account that you created. 2. Click Keys. 3. Click Add key, then click Create new key. 4. Click Create. A JSON key file is downloaded to your computer. 5. Click Close.","title":"Setup Service Account"},{"location":"reighns_ml_journey/software_engineering/gcp/#setup-authenticated-environment","text":"Now you have a json file from previous step. Put the json file in a folder. Then everytime you start a terminal or new window, you can use $env :GOOGLE_APPLICATION_CREDENTIALS = \" $PATH$TO$JSON \" It seems a hassle to type the command everytime. May look into this link 5 and this 6 to see how to setup the environment.","title":"Setup Authenticated Environment"},{"location":"reighns_ml_journey/software_engineering/gcp/#upload-and-download-files","text":"from gcloud import storage def return_bucket ( project_id : str ) -> List : \"\"\"Return a list of buckets for a given project. Args: project_id (str): The project id. Returns: List: A list of buckets. \"\"\" storage_client = storage . Client ( project = project_id ) buckets = list ( storage_client . list_buckets ()) return buckets def upload_to_bucket ( source_file_name : str , destination_blob_name : str , bucket_name : str , project_id : str , ) -> str : \"\"\"Uploads a file to the bucket and returns the public url. Args: source_file_name (str): The file in local that you want to upload. destination_blob_name (str): The name of the file in the bucket. To include full path. bucket_name (str): The name of the bucket. \"\"\" storage_client = storage . Client ( project = project_id ) bucket = storage_client . bucket ( bucket_name ) blob = bucket . blob ( destination_blob_name ) blob . upload_from_filename ( source_file_name ) print ( f \"file { source_file_name } uploaded to bucket { bucket_name } successfully!\" ) return blob . public_url def download_from_bucket ( source_file_name : str , destination_blob_name : str , bucket_name : str , project_id : str , ) -> None : \"\"\"Download file from GCP bucket. Just do the opposite of upload_to_bucket.\"\"\" storage_client = storage . Client ( project = project_id ) bucket = storage_client . bucket ( bucket_name ) blob = bucket . blob ( destination_blob_name ) blob . download_to_filename ( source_file_name ) if __name__ == \"__main__\" : PROJECT_ID = \"Your Project ID\" BUCKET_NAME = \"Bucket Name\" SOURCE_FILE_NAME = \"Source File Name stored Locally\" DESTINATION_BLOB_NAME = \"Destination File Name in GCP Bucket\" upload_to_bucket ( SOURCE_FILE_NAME , DESTINATION_BLOB_NAME , BUCKET_NAME , PROJECT_ID ) download_from_bucket ( SOURCE_FILE_NAME , DESTINATION_BLOB_NAME , BUCKET_NAME , PROJECT_ID ) If you want to mass upload or download, you just need to create a loop as such: for file in os . listdir ( path ): upload_to_bucket ( SOURCE_FILE_NAME , DESTINATION_BLOB_NAME , BUCKET_NAME , PROJECT_ID ) Creating GCP Buckets \u21a9 How to write files from Local to GCP using Python \u21a9 Install Cloud SDK \u21a9 Service Account \u21a9 How to upload a file to Google Cloud Storage on Python 3? \u21a9 Setting GOOGLE_APPLICATION_CREDENTIALS for BigQuery Python CLI \u21a9","title":"Upload and Download Files"},{"location":"reighns_ml_journey/software_engineering/git/","text":"Git Guide Introduction The following notes' taken from Colt Steele . However, I have added some steps on remote repositories towards the end. Git Downloading and Installing Git Git is primarily used via the command-line interface, which we can access with our system terminals. However, we first need to make sure that we have Git installed on our computers. Note You can download Git here: https://git-scm.com/downloads Click the download link for your specific operating system and then follow through the installation wizard to get things set up on your computer! After installing it, start your terminal and type the following command to verify that Git is ready to be used on your computer: git --version If everything went well, it should return the Git version that is installed on your computer. Note If you are using a Mac or Linux machine, then you can utilize the default Bash terminal that comes pre-installed on your machine. If you are using Windows, you can use its built-in Powershell terminal, or the Git Bash terminal which is bundled with the Git installation. For detailed windows Git and Git Bash install instructions, check out this blog post: https://zarkom.net/blogs/how-to-install-git-and-git-bash-on-windows-9140 Configure name and email In your terminal, run the following commands to identify yourself with Git: git config --global user.name \"Your Name\" git config --global user.email \"your@email.com\" Replace the values inside the quotes with your name and email address. This is to better identify who committed which lines of codes. Initialize Repositories Initialize Local Repo An isolated repository stored on your own computer, where you can work on the local version of your project. git init This command will generate a hidden .git directory for your project, where Git stores all internal tracking data for the current repository. ls -a # to see the hidden git repo Initialize Remote Repo Generally stored outside of your isolated local system, usually on a remote server. It's especially useful when working in teams - this is the place where you can share your project code, see other people's code and integrate it into your local version of the project, and also push your changes to the remote repository. Note Simply create this using this simple guide . Git Clone Special mention if you have just reset your computer and want to clone your repo from remote. Then you do not need git init and just use git clone https://git-scm.com/book/en/v2/Git-Basics-Getting-a-Git-Repository folder_name to clone your repo to local. See more here . Staging and committing code Committing is the process in which the changes are 'officially' added to the Git repository. In Git, we can consider commits to be checkpoints, or snapshots of your project at its current state. In other words, we basically save the current version of our code in a commit. We can create as many commits as we need in the commit history, and we can go back and forth between commits to see the different revisions of our project code. That allows us to efficiently manage our progress and track the project as it gets developed. Commits are usually created at logical points as we develop our project, usually after adding in specific contents, features or modifications (like new functionalities or bug fixes, for example). Creating gitignore Usually, I recommend creating .gitignore at this step, because you want to list down files that you do not wish git to track. This is important because some secret keys should never be pushed to the remote server for people to see. Furthermore, some large files should be kept in a storage as git cannot store too large files. To ignore files that you don't want to be tracked or added to the staging area, you can create a file called .gitignore in your main project folder. Inside of that file, you can list all the file and folder names that you definitely do not want to track (each ignored file and folder should go to a new line inside the .gitignore file). You can read an article about ignoring files on this link . Checking Status (git status) While located inside the project folder in our terminal, we can type the following command to check the status of our repository: git status This is a command that is very often used when working with Git. It shows us which files have been changed, which files are tracked, etc. We can add the untracked project files to the staging area based on the information from the git status command. At a later point, git status will report any modifications that we made to our tracked files before we decide to add them to the staging area again. Staging files (git add) Here we can tell git which files should be tracked. git add . # add all files git add filename.py file.md # add single/multiple individual files Making commits (git commit) A commit is a snapshot of our code at a particular time, which we are saving to the commit history of our repository. After adding all the files that we want to track to the staging area with the **git add ** command, we are ready to make a commit. To commit the files from the staging area, we use the following command: git config --global core.editor \"code --wait\" # use this code if popup editor does not appear. git commit -a # a pop up editor should appear for you to type the message. The commit message should be a descriptive summary of the changes that you are committing to the repository. After executing that command, you will get the technical details about the commit printed in the terminal. And that's basically it, you have successfully made a commit in your project! Tip Files that are changed in sync should be committed together. As an example, you made changes to three files, a, b and c, if a and b are related and c is unrelated to both of them, then it is logical to do the following: git add a b git commit -a \"Commit related files\" git add c git commit -a \"Commit c file\" Commit History To see all the commits that were made for our project, you can use the following command: git log The logs will show details for each commit, like the author name, the generated hash for the commit, date and time of the commit, and the commit message that we provided. To go back to a previous state of your project code that you committed, you can use the following command: git checkout <commit-hash> Replace <commit-hash> with the actual hash for the specific commit that you want to visit, which is listed with the git log command. To go back to the latest commit (the newest version of our project code), you can type this command: git checkout master Branches A branch could be interpreted as an individual timeline of our project commits. With Git, we can create many of these alternative environments (i.e. we can create different branches ) so other versions of our project code can exist and be tracked in parallel. That allows us to add new (experimental, unfinished, and potentially buggy) features in separate branches, without touching the ' official' stable version of our project code (which is usually kept on the master branch). When we initialize a repository and start making commits, they are saved to the master branch by default. Creating a new branch You can create a new branch using the following command: git branch <new-branch-name> The new branch that gets created will be the reference to the current state of your repository. Note It's a good idea to create a development branch where you can work on improving your code, adding new experimental features, and similar. After development and testing these new features to make sure they don't have any bugs and that they can be used, you can merge them to the master branch. Changing branches To switch to a different branch, you use the git checkout command: git checkout <branch-name> With that, you switch to a different isolated timeline of your project by changing branches. Note For example, you could be working on different features in your code and have a separate branch for each feature. When you switch to a branch, you can commit code changes which only affect that particular branch. Then, you can switch to another branch to work on a different feature, which won't be affected by the changes and commits made from the previous branch. To create a new branch and change to it at the same time, you can use the -b flag: git checkout -b <new-branch-name> Info To list the branches for your project, use this command: git branch To go back to the master branch, use this command: git checkout master Merging branches You can merge branches in situations where you want to implement the code changes that you made in an individual branch to a different branch. For example, after you fully implemented and tested a new feature in your code, you would want to merge those changes to the stable branch of your project (which is usually the default master branch). To merge the changes from a different branch into your current branch, you can use this command: git merge <branch-name> You would replace <branch-name> with the branch that you want to integrate into your current branch. Deleting a branch To delete a branch, you can run the git branch command with the -d flag: git branch -d <branch-name> Info Read more about branching and merging on this link . Git remote Note Note everything done above is still at local repository, as a result, we now need to push the changes into GitHub's remote server. Remote add origin To add a remote repository to our local repository, we first go create a personal access token[^github token], we can use the following command: git remote add origin \"your-repo-http\" # add remote origin git remote set-url origin https:// [ token ] @github.com/ [ username ] / [ repository ] # set the remote origin # remove remote origin if needed (usually no need path) To remove or show remote origins, use: git remote rm origin # remove origin git remote show origin # show remote origin Sometimes if you are using two github accounts in the same computer, you can do the following: 1. Create a personal access token for the second account and **tick all access**: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token 2. Add the remote origin for the second account. ```bash git remote add origin \"your-repo-http\" # add remote origin git remote set-url origin https://reigHns92@github.com/reigHns92/repo.git 3. Push the changes to the second account and a prompt opens for you to key in token access. Push Finally, we use git push origin master -u to push to master branch. Note One thing worth noting is that if you created the repository with some files in it, then the above steps will lead to error. Instead, to overwrite : do git push -f origin master . For newbies, it is safe to just init a repo with no files inside in the remote to avoid the error \"Updates were rejected because the tip...\". Pulling If you are writing code on your main desktop, say system A and committing a lot of changes, and when you are outside you are using your portable macbook, say system B, you may want to do the following: If your last commit of system A is at commit 6, and system B is at commit 3, where commit 4-6 were done on A, then you can simply call: git config --global pull.rebase false # merge (the default strategy) git pull origin master However, if you have uncommited changes on system B and did not commit yet, then what you can do is call: git stash # this saves a snapshot of your current work and remove the commit git pull origin master Useful Git Commands To undo git add before a commit, run git reset or git reset to unstage all changes. Git Branches For Personal Projects Guidelines Website and Blogging Assume that I wrote a notebook named blog.ipynb and I want to publish it to my personal blog. Here are the general guidelines. Say that I put the notebook blog.ipynb in the notebooks folder in master branch. Then before I publish, I have a collaborator named Joe who is also a collaborator of my personal blog (who acts as my editor). I will create a new branch named blog and push the notebook to the branch. Then I will commit the notebook to the branch and create a pull request for Joe to review. If Joe approves the pull request, then I will merge the branch to the master branch using squash and merge or merge commit . If Joe proposes some small changes, I will then go my branch blog and make the changes locally, and commit them with a pull request for Joe again. Once he approved, I will merge the branch to the master branch. After the merge, I will delete the branch blog as the updates are reflected in the master branch. The above can be outlined in pseudo code below: # Place the notebook `blog.ipynb` in the `notebooks` folder in master branch. # Create a new branch named `blog` and push the notebook to the branch. git checkout -b <new-branch-name> blog git status # to see the status of the current branch. # Convert the notebook to markdown if needed. jupyter nbconvert --to markdown mynotebook.ipynb # Commit the notebook to the branch. git add . git commit -a git push origin branch_name -u # Go to the pull request link, and select reviewer for review. # If no changes proposed, merge the branch to master. # If there are changes proposed, edit the codes in the branch locally and push the changes to the branch for review again. After that go to the same link and click on re-review. After review and approved by the reviewer, you have 3 merge options. Squash and Merge: Take all the commits during the review and merge them into one commit. The only downside is you cannot go back to one unique commit but you will see all commit messages tho and changes. Create a merge commit: Create a merge commit with the changes from the review. You can use this if you want git to track every single commit (messages). The merge will mean it is updated in master branch also. Then delete the branch if not in use. Git Branches For Machine Learning Projects git branch for pytorch pipeline: In my main PyTorch repo, the code is on the branch master . I want to create a branch for a new competition using the master branch. # git checkout -b ... Put the competition data in a different folder that stores all data. In a way, you can put it like this: data/competition_1_data/ data/competition_2_data/ I will write code inside the branch. Scenario 1: I made changes in the branch and also want to merge this change into main -> commit, push, merge, pull to master branch. You can also create a dev branch and work on it as well. Scenario 2: I made changes specific to this branch, and I don't want to merge and merge some commits that propels to the main. GIT Readme Profile Instructions here and template . https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token \u21a9 https://stackoverflow.com/questions/68779962/github-removed-username-password-authorization-now-what \u21a9","title":"Git"},{"location":"reighns_ml_journey/software_engineering/git/#introduction","text":"The following notes' taken from Colt Steele . However, I have added some steps on remote repositories towards the end.","title":"Introduction"},{"location":"reighns_ml_journey/software_engineering/git/#git","text":"","title":"Git"},{"location":"reighns_ml_journey/software_engineering/git/#downloading-and-installing-git","text":"Git is primarily used via the command-line interface, which we can access with our system terminals. However, we first need to make sure that we have Git installed on our computers. Note You can download Git here: https://git-scm.com/downloads Click the download link for your specific operating system and then follow through the installation wizard to get things set up on your computer! After installing it, start your terminal and type the following command to verify that Git is ready to be used on your computer: git --version If everything went well, it should return the Git version that is installed on your computer. Note If you are using a Mac or Linux machine, then you can utilize the default Bash terminal that comes pre-installed on your machine. If you are using Windows, you can use its built-in Powershell terminal, or the Git Bash terminal which is bundled with the Git installation. For detailed windows Git and Git Bash install instructions, check out this blog post: https://zarkom.net/blogs/how-to-install-git-and-git-bash-on-windows-9140","title":"Downloading and Installing Git"},{"location":"reighns_ml_journey/software_engineering/git/#configure-name-and-email","text":"In your terminal, run the following commands to identify yourself with Git: git config --global user.name \"Your Name\" git config --global user.email \"your@email.com\" Replace the values inside the quotes with your name and email address. This is to better identify who committed which lines of codes.","title":"Configure name and email"},{"location":"reighns_ml_journey/software_engineering/git/#initialize-repositories","text":"","title":"Initialize Repositories"},{"location":"reighns_ml_journey/software_engineering/git/#initialize-local-repo","text":"An isolated repository stored on your own computer, where you can work on the local version of your project. git init This command will generate a hidden .git directory for your project, where Git stores all internal tracking data for the current repository. ls -a # to see the hidden git repo","title":"Initialize Local Repo"},{"location":"reighns_ml_journey/software_engineering/git/#initialize-remote-repo","text":"Generally stored outside of your isolated local system, usually on a remote server. It's especially useful when working in teams - this is the place where you can share your project code, see other people's code and integrate it into your local version of the project, and also push your changes to the remote repository. Note Simply create this using this simple guide .","title":"Initialize Remote Repo"},{"location":"reighns_ml_journey/software_engineering/git/#git-clone","text":"Special mention if you have just reset your computer and want to clone your repo from remote. Then you do not need git init and just use git clone https://git-scm.com/book/en/v2/Git-Basics-Getting-a-Git-Repository folder_name to clone your repo to local. See more here .","title":"Git Clone"},{"location":"reighns_ml_journey/software_engineering/git/#staging-and-committing-code","text":"Committing is the process in which the changes are 'officially' added to the Git repository. In Git, we can consider commits to be checkpoints, or snapshots of your project at its current state. In other words, we basically save the current version of our code in a commit. We can create as many commits as we need in the commit history, and we can go back and forth between commits to see the different revisions of our project code. That allows us to efficiently manage our progress and track the project as it gets developed. Commits are usually created at logical points as we develop our project, usually after adding in specific contents, features or modifications (like new functionalities or bug fixes, for example).","title":"Staging and committing code"},{"location":"reighns_ml_journey/software_engineering/git/#creating-gitignore","text":"Usually, I recommend creating .gitignore at this step, because you want to list down files that you do not wish git to track. This is important because some secret keys should never be pushed to the remote server for people to see. Furthermore, some large files should be kept in a storage as git cannot store too large files. To ignore files that you don't want to be tracked or added to the staging area, you can create a file called .gitignore in your main project folder. Inside of that file, you can list all the file and folder names that you definitely do not want to track (each ignored file and folder should go to a new line inside the .gitignore file). You can read an article about ignoring files on this link .","title":"Creating gitignore"},{"location":"reighns_ml_journey/software_engineering/git/#checking-status-git-status","text":"While located inside the project folder in our terminal, we can type the following command to check the status of our repository: git status This is a command that is very often used when working with Git. It shows us which files have been changed, which files are tracked, etc. We can add the untracked project files to the staging area based on the information from the git status command. At a later point, git status will report any modifications that we made to our tracked files before we decide to add them to the staging area again.","title":"Checking Status (git status)"},{"location":"reighns_ml_journey/software_engineering/git/#staging-files-git-add","text":"Here we can tell git which files should be tracked. git add . # add all files git add filename.py file.md # add single/multiple individual files","title":"Staging files (git add)"},{"location":"reighns_ml_journey/software_engineering/git/#making-commits-git-commit","text":"A commit is a snapshot of our code at a particular time, which we are saving to the commit history of our repository. After adding all the files that we want to track to the staging area with the **git add ** command, we are ready to make a commit. To commit the files from the staging area, we use the following command: git config --global core.editor \"code --wait\" # use this code if popup editor does not appear. git commit -a # a pop up editor should appear for you to type the message. The commit message should be a descriptive summary of the changes that you are committing to the repository. After executing that command, you will get the technical details about the commit printed in the terminal. And that's basically it, you have successfully made a commit in your project! Tip Files that are changed in sync should be committed together. As an example, you made changes to three files, a, b and c, if a and b are related and c is unrelated to both of them, then it is logical to do the following: git add a b git commit -a \"Commit related files\" git add c git commit -a \"Commit c file\"","title":"Making commits (git commit)"},{"location":"reighns_ml_journey/software_engineering/git/#commit-history","text":"To see all the commits that were made for our project, you can use the following command: git log The logs will show details for each commit, like the author name, the generated hash for the commit, date and time of the commit, and the commit message that we provided. To go back to a previous state of your project code that you committed, you can use the following command: git checkout <commit-hash> Replace <commit-hash> with the actual hash for the specific commit that you want to visit, which is listed with the git log command. To go back to the latest commit (the newest version of our project code), you can type this command: git checkout master","title":"Commit History"},{"location":"reighns_ml_journey/software_engineering/git/#branches","text":"A branch could be interpreted as an individual timeline of our project commits. With Git, we can create many of these alternative environments (i.e. we can create different branches ) so other versions of our project code can exist and be tracked in parallel. That allows us to add new (experimental, unfinished, and potentially buggy) features in separate branches, without touching the ' official' stable version of our project code (which is usually kept on the master branch). When we initialize a repository and start making commits, they are saved to the master branch by default.","title":"Branches"},{"location":"reighns_ml_journey/software_engineering/git/#creating-a-new-branch","text":"You can create a new branch using the following command: git branch <new-branch-name> The new branch that gets created will be the reference to the current state of your repository. Note It's a good idea to create a development branch where you can work on improving your code, adding new experimental features, and similar. After development and testing these new features to make sure they don't have any bugs and that they can be used, you can merge them to the master branch.","title":"Creating a new branch"},{"location":"reighns_ml_journey/software_engineering/git/#changing-branches","text":"To switch to a different branch, you use the git checkout command: git checkout <branch-name> With that, you switch to a different isolated timeline of your project by changing branches. Note For example, you could be working on different features in your code and have a separate branch for each feature. When you switch to a branch, you can commit code changes which only affect that particular branch. Then, you can switch to another branch to work on a different feature, which won't be affected by the changes and commits made from the previous branch. To create a new branch and change to it at the same time, you can use the -b flag: git checkout -b <new-branch-name> Info To list the branches for your project, use this command: git branch To go back to the master branch, use this command: git checkout master","title":"Changing branches"},{"location":"reighns_ml_journey/software_engineering/git/#merging-branches","text":"You can merge branches in situations where you want to implement the code changes that you made in an individual branch to a different branch. For example, after you fully implemented and tested a new feature in your code, you would want to merge those changes to the stable branch of your project (which is usually the default master branch). To merge the changes from a different branch into your current branch, you can use this command: git merge <branch-name> You would replace <branch-name> with the branch that you want to integrate into your current branch.","title":"Merging branches"},{"location":"reighns_ml_journey/software_engineering/git/#deleting-a-branch","text":"To delete a branch, you can run the git branch command with the -d flag: git branch -d <branch-name> Info Read more about branching and merging on this link .","title":"Deleting a branch"},{"location":"reighns_ml_journey/software_engineering/git/#git-remote","text":"Note Note everything done above is still at local repository, as a result, we now need to push the changes into GitHub's remote server.","title":"Git remote"},{"location":"reighns_ml_journey/software_engineering/git/#remote-add-origin","text":"To add a remote repository to our local repository, we first go create a personal access token[^github token], we can use the following command: git remote add origin \"your-repo-http\" # add remote origin git remote set-url origin https:// [ token ] @github.com/ [ username ] / [ repository ] # set the remote origin # remove remote origin if needed (usually no need path) To remove or show remote origins, use: git remote rm origin # remove origin git remote show origin # show remote origin Sometimes if you are using two github accounts in the same computer, you can do the following: 1. Create a personal access token for the second account and **tick all access**: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token 2. Add the remote origin for the second account. ```bash git remote add origin \"your-repo-http\" # add remote origin git remote set-url origin https://reigHns92@github.com/reigHns92/repo.git 3. Push the changes to the second account and a prompt opens for you to key in token access.","title":"Remote add origin"},{"location":"reighns_ml_journey/software_engineering/git/#push","text":"Finally, we use git push origin master -u to push to master branch. Note One thing worth noting is that if you created the repository with some files in it, then the above steps will lead to error. Instead, to overwrite : do git push -f origin master . For newbies, it is safe to just init a repo with no files inside in the remote to avoid the error \"Updates were rejected because the tip...\".","title":"Push"},{"location":"reighns_ml_journey/software_engineering/git/#pulling","text":"If you are writing code on your main desktop, say system A and committing a lot of changes, and when you are outside you are using your portable macbook, say system B, you may want to do the following: If your last commit of system A is at commit 6, and system B is at commit 3, where commit 4-6 were done on A, then you can simply call: git config --global pull.rebase false # merge (the default strategy) git pull origin master However, if you have uncommited changes on system B and did not commit yet, then what you can do is call: git stash # this saves a snapshot of your current work and remove the commit git pull origin master","title":"Pulling"},{"location":"reighns_ml_journey/software_engineering/git/#useful-git-commands","text":"To undo git add before a commit, run git reset or git reset to unstage all changes.","title":"Useful Git Commands"},{"location":"reighns_ml_journey/software_engineering/git/#git-branches-for-personal-projects-guidelines","text":"","title":"Git Branches For Personal Projects Guidelines"},{"location":"reighns_ml_journey/software_engineering/git/#website-and-blogging","text":"Assume that I wrote a notebook named blog.ipynb and I want to publish it to my personal blog. Here are the general guidelines. Say that I put the notebook blog.ipynb in the notebooks folder in master branch. Then before I publish, I have a collaborator named Joe who is also a collaborator of my personal blog (who acts as my editor). I will create a new branch named blog and push the notebook to the branch. Then I will commit the notebook to the branch and create a pull request for Joe to review. If Joe approves the pull request, then I will merge the branch to the master branch using squash and merge or merge commit . If Joe proposes some small changes, I will then go my branch blog and make the changes locally, and commit them with a pull request for Joe again. Once he approved, I will merge the branch to the master branch. After the merge, I will delete the branch blog as the updates are reflected in the master branch. The above can be outlined in pseudo code below: # Place the notebook `blog.ipynb` in the `notebooks` folder in master branch. # Create a new branch named `blog` and push the notebook to the branch. git checkout -b <new-branch-name> blog git status # to see the status of the current branch. # Convert the notebook to markdown if needed. jupyter nbconvert --to markdown mynotebook.ipynb # Commit the notebook to the branch. git add . git commit -a git push origin branch_name -u # Go to the pull request link, and select reviewer for review. # If no changes proposed, merge the branch to master. # If there are changes proposed, edit the codes in the branch locally and push the changes to the branch for review again. After that go to the same link and click on re-review. After review and approved by the reviewer, you have 3 merge options. Squash and Merge: Take all the commits during the review and merge them into one commit. The only downside is you cannot go back to one unique commit but you will see all commit messages tho and changes. Create a merge commit: Create a merge commit with the changes from the review. You can use this if you want git to track every single commit (messages). The merge will mean it is updated in master branch also. Then delete the branch if not in use.","title":"Website and Blogging"},{"location":"reighns_ml_journey/software_engineering/git/#git-branches-for-machine-learning-projects","text":"git branch for pytorch pipeline: In my main PyTorch repo, the code is on the branch master . I want to create a branch for a new competition using the master branch. # git checkout -b ... Put the competition data in a different folder that stores all data. In a way, you can put it like this: data/competition_1_data/ data/competition_2_data/ I will write code inside the branch. Scenario 1: I made changes in the branch and also want to merge this change into main -> commit, push, merge, pull to master branch. You can also create a dev branch and work on it as well. Scenario 2: I made changes specific to this branch, and I don't want to merge and merge some commits that propels to the main.","title":"Git Branches For Machine Learning Projects"},{"location":"reighns_ml_journey/software_engineering/git/#git-readme-profile","text":"Instructions here and template . https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token \u21a9 https://stackoverflow.com/questions/68779962/github-removed-username-password-authorization-now-what \u21a9","title":"GIT Readme Profile"},{"location":"reighns_ml_journey/software_engineering/github_actions_test_packages_compatibility/","text":"We can use GitHub Actions to test for compatibility on different Operating Systems (OS) such as Windows/Linux. packages_compatibility.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 name : Commit Checks on : [ push , pull_request ] jobs : check_code : runs-on : ${{ matrix.os }} strategy : fail-fast : true matrix : os : [ ubuntu-latest , windows-latest ] python-version : [ 3.7 ] steps : - name : Checkout code uses : actions/checkout@v2 - name : Setup Python uses : actions/setup-python@v2 with : python-version : ${{ matrix.python-version }} cache : \"pip\" - name : Install dependencies run : | python -m pip install --upgrade pip setuptools wheel pip install -r requirements.txt [ Line 10 ] : This line tells us that we want to test the installation on both Ubuntu and Windows Latest version. [ Line 11 ] : This line tells us that we want to test the installation on python version 3.7. [ Lines 21 - 23 ] : This line tells us that we will run the installation using pip on requirements.txt file.","title":"Test Packages Compatibility"},{"location":"reighns_ml_journey/software_engineering/workflow/","text":"Setup Guide by Hongnan Gao Introduction This getting started guide is written to ensure I follow standard coding practices. Important To render Table of Content when compiling mkdocs serve , one must always have the following structure: # Type your article title here ## ... ## ... Notice that the top level header must be #, and subsequent nested headers should be ##. Setting up Environment Assuming VSCode setup, open up terminal/powershell in your respective system and type: code \"path to folder\" to open up VSCode. Virtual Environment In your IDE, you want to set up a virtual environment. # For Ubuntu sudo apt install python3.8 python3.8-venv python3-venv # For Mac pip3 install virtualenv You can activate the VM as follows: # Assuming Windows python -m venv venv_bcw . \\v env_bcw \\S cripts \\a ctivate python -m pip install --upgrade pip setuptools wheel # upgrade pip # Assuming Linux python3 -m venv venv_bcw source venv_bcw/bin/activate python -m pip install --upgrade pip setuptools wheel # upgrade pip # Assuming Mac virtualenv venv_bcw source venv_bcw/bin/activate python -m pip install --upgrade pip setuptools wheel # upgrade pip Setup and requirements Note For small projects, we can have requirements.txt and just run (venv_ml) pip install -r requirements.txt . For larger projects, we can follow the steps below. Create a file named setup.py and requirements.txt concurrently. The latter should have the libraries that one is interested in having for his project while the formal is a setup.py file where it contains the setup object which describes how to set up our package and it's dependencies. The first several lines cover metadata (name, description, etc.) and then we define the requirements. Here we're stating that we require a Python version equal to or above 3.8 and then passing in our required packages to install_requires. Finally, we define extra requirements that different types of users may require. This is a standard practice and more can be understood from madewithml.com. The user can now call the following commands to install the dependencies in their own virtual environment. See here on what pip install -e . does. pip install -e . # installs required packages only python -m pip install -e \".[dev]\" # installs required + dev packages python -m pip install -e \".[test]\" # installs required + test packages python -m pip install -e \".[docs_packages]\" # installs required documentation packages Important Something worth taking note is when you download PyTorch Library, there is a dependency link since we are downloading cuda directly, you may execute as such: pip install -e . -f https://download.pytorch.org/whl/torch_stable.html Command Line Something worth noting is we need to use dash instead of underscore when calling a function in command line. reighns_linear_regression regression-test --solver \"Batch Gradient Descent\" --num-epochs 500 Documentation Type Hints Mkdocs + Docstrings Copy paste the template from Goku in, most of what he use will be in mkdocs.yml file. Remember to create the mkdocs.yml in the root path. Then change accordingly the content inside mkdocs.yml , you can see my template that I have done up. Remember to run python -m pip install -e \".[docs_packages]\" to make sure you do have the packages. Along the way you need to create a few folders, follow the page tree in mkdocs.yml, everything should be created in docs/ folder. As an example, in our reighns-linear-regression folder, we want to show two scenarios: Scenario 1: I merely want a full markdown file to show on the website. In this case, in the \"watch\", we specify a path we want to watch in our docs/ folder. In this case, I created a documentation folder under docs/ so I specify that. Next in the docs/documentation/ folder I create a file called linear_regression.md where I dump all my markdown notes inside. Then in the nav tree in mkdocs.yml , specify nav: - Home: - Introduction: index.md - Getting started: getting_started.md - Detailed Notes: - Notes: documentation/linear_regression.md - Reference: documentation/reference_links.md Note that Home and Getting Started are optional but let us keep it for the sake of completeness. What you need to care is \"Detailed Notes\" and note the path I gave to them - which will point to the folders in docs/documentation/ . Scenario 2: I want a python file with detailed docstrings to appear in my static website. This is slightly more complicated. First if you want a new section of this you can create a section called code_reference , both under the nav above and also in the folder docs/ , meaning docs/code_reference/ must exist. Put it under watch as well. Now in docs/code_reference/ create a file named say linear_regression_from_scratch.md and put src.linear_regression inside, note that you should not have space in between. Run Run config.py as this will create folders for you automatically. Setting up GitHub Pages and Mkdocs (Website) Update November 9th, 2021 You can skip most steps if you just fork this repository and follow the format. Welcome to my example website! This website uses MkDocs with the Material theme and an automated deployment workflow for publishing to GitHub Pages . This guide will help you create your own GitHub Pages website with this setup. If you're using Windows, you should run all the commands in this guide on a Windows Subsystem for Linux (WSL) terminal. Initializing your Website Repository First, create a new repository on GitHub. Make sure to skip the initialization step on the website \u2014 you will be initializing the contents of this repository with this template! Note down the Git remote for your new repository, you'll need it later when initializing your local copy of the repository. Next, download the website template and extract it: $ wget https://github.com/jansky/test-website/archive/refs/tags/template.tar.gz $ tar xvf template.tar.gz $ rm template.tar.gz Note If the wget command is not found, you can install it using apt-get: sudo apt-get install wget . This will create a new folder called test-website-template in your current directory with the website template contents. You may wish to rename this folder to something like my-website : $ mv test-website-template my-website Now you can initialize a Git repository with the website contents: $ cd my-website $ git init $ git remote add origin YOUR_GITHUB_REPOSITORY_REMOTE Website Configuration The configuration for your website is stored in mkdocs.yml in the repository root. You only need to change a few settings at the top of the file: 1 2 3 4 5 6 7 site_name : Example Website site_url : https://reighns92.github.io/test-website nav : - Home : index.md - About : about.md - Notebooks : notebooks_list.md ... First, update the site_name and site_url fields to be correct for your website. The URL format for GitHub pages websites is https://USERNAME.github.io/REPOSITORY-NAME As you add content to your website, you can also control the pages that appear on your website's navbar in the nav field. Each nav list element is of the form Link Text : filename.md For navbar links pointing to pages in your site, you should use a file path which is relative to the docs/ folder where all your website content is stored. You may also link to external pages and include sub-links. For more information, you can view the MkDocs nav documentation . GitHub Actions Configuration You also need to update the GitHub Actions deployment workflow with the name and e-mail address to use when the workflow pushes your built website to the gh-pages branch of your repository. In the file .github/workflows/deploy-website.yml , update lines 25 and 26 to reflect your account information: 22 23 24 25 26 27 ... - name : Push Build Website to gh-pages Branch run : | git config --global user.name 'YOUR NAME(Automated)' git config --global user.email 'YOUR-GITHUB-USERNAME@users.noreply.github.com' ... Setting Up Local Development MkDocs makes it easy to develop your website locally and see your changes in real time. To begin, set up and activate Python virtual environment for this project. Then, install the project dependencies: ( venv ) $ pip install -r requirements.txt MkDocs includes a small webserver that allows you to preview your website in your browser as you make changes. Whenever you save one of your source files, the website will be rebuilt and your browser will automatically refresh to show the new changes. You can start this development server using the serve command: ( venv ) $ mkdocs serve INFO - Building documentation... ... INFO - Documentation built in 0 .16 seconds INFO - [ 20 :09:07 ] Serving on http://127.0.0.1:8000/... ... If you copy and paste the URL given by MkDocs into your browser you will see your website preview. Adding Website Content Markdown files added under the docs/ folder will be converted to HTML pages on your website. This website template enables some helpful extensions for rendering of math in LaTeX style, admonitions such as notes and warnings, and code blocks with syntax highlighting. In addition, MkDocs also supports GitHub-flavored Markdown tables. To see examples of syntax for these elements, see the MkDocs website here . Deploying Your Changes When you are ready to deploy your website for the first time, make an initial commit and push to your GitHub remote: $ git add . $ git commit -a -m \"Initial Commit\" $ git push origin master -u Activate Workflow The GitHub Actions deployment workflow included with this template runs whenever you push to the master branch. This workflow will build your website using MkDocs and push the built website files to the gh-pages branch of your repository, which GitHub Pages can use to serve your website. Once you have pushed your changes, go to your repository page on GitHub and confirm that the GitHub Actions workflow has completed successfully (you should see a green checkmark next to the name of the most recent commit). Then, go to your repository settings page, and click on 'Pages'. You will see a section that will let you set the source for your GitHub Pages website. Click the box labelled 'None' and select the gh-pages branch. Leave the selectd folder at '/ (root)' and click 'Save'. Your website is now live! To push additional changes, simply commit and push to the master branch. The GitHub Actions deployment workflow will handle deploying your changes to GitHub Pages. Pandoc (Markdown Converter) More often than not, you will need to convert a jupyter notebook to markdown file for deployment (as markdown supports Admonitions in Mkdocs). Here is a way to do it, it is very convenient as it not only converts your notebook files to markdown, it also stores your output as images in a folder for you. This means any images rendered in notebook by matplotlib etc will now show up in markdown! brew install pandoc git clone https://github.com/jupyter/nbconvert.git cd nbconvert pip install -e . Then to convert, simply do the following: jupyter nbconvert --to markdown mynotebook.ipynb Pandoc (Wikitext to Markdown) From the solution here . We can do the following: pandoc --from mediawiki --to = markdown-definition_lists wiki.txt -o wiki.md where wiki.txt is a text file with wiki markup. Miscellaneous Problems Path Environment Often times, you will encounter a problem with the path environment when working with Windows especially. For example, when you do the following: jupyter nbconvert --to markdown mynotebook.ipynb then 'jupyter' is not recognized as an internal or external command, operable program or batch file. is the error message even though jupyter is installed. Usually, the shell will prompt a message to check PATH . Now go to Advanced System Settings and click on Environment Variables. You will see a list of environment variables. You can add a new environment variable by clicking on the plus sign in the System Variables . Add the path recommended by jupyter to the PATH variable. In my case, it is the obscure C:\\Users\\reighns\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\Scripts . Mkdocs Full page width Use this custom css code to make page full width. Setup Main Directory (IDE) Let us create our main directory for the project: creating main directory 1 2 3 $ mkdir pkd_exercise_counter $ cd pkd_exercise_counter $ code . # (1) Open the project directory in Visual Studio Code. To change appropriately if using different IDE. Virtual Environment Set up a virtual environment in your IDE. Virtual Environment If you are using Linux or Mac, then you may need to install the virtual environment manager. For windows, python comes with a virtual environment manager venv installed. install venv 1 2 $ sudo apt install python3.8 python3.8-venv python3-venv # For Ubuntu $ pip3 install virtualenv # For Mac You can activate the virtual environment (assuming Windows) as follows: virtual environment windows 1 2 3 $ python -m venv venv_pkd_exercise_counter # (1) $ . \\v env_pkd_exercise_counter \\S cripts \\a ctivate # (2) ( venv ) $ python -m pip install --upgrade pip setuptools wheel # (3) Create virtual environment. Activate virtual environment. Upgrade pip. Note Although the virtual environment name is venv_pkd_exercise_counter , it is too long and I will use venv for future references. You should see the following directory structure: main directory tree 1 2 pkd_exercise_counter/ \u2514\u2500\u2500 venv_pkd_exercise_counter/ Requirements and Setup Note We note that echo > \"filename\" command is used to create a file in Windows. One can use touch in other OS such as macOS or even code if you are using Visual Studio Code. creating requirements 1 2 3 ( venv ) $ echo > setup.py ( venv ) $ echo > requirements.txt ( venv ) $ pip install -e . [ Line 1 -2 ] : setup.py file informs you about the module or package-dependencies you are about to install has been packaged and distributed with Distutils, which is the standard for distributing Python Modules. You can skip setup.py if you are just using requirements.txt to install dependencies. [ Line 3 ] : Installs packages from requirements.txt . One can also use commands such as python -m pip install -e \".[dev]\" to install additional dev packages specified in setup.py . After which we quickly run a verification to see if PeekingDuck is installed correctly. peekingduck verification 1 ( venv ) $ peekingduck --verify_install Info In my setup.py , I specified python to be \\(3.8\\) and above. This has been tested on ubuntu latest and windows latest in GitHub Actions. You should see the following directory structure: main directory tree 1 2 3 4 pkd_exercise_counter/ \u251c\u2500\u2500 venv_pkd_exercise_counter/ \u251c\u2500\u2500 requirements.txt \u2514\u2500\u2500 setup.py Git Git is a version control system that is used to track changes to files. It is integral to the development process of any software. Here we initiate our main directory with git. Note The commands below may differ depending on personal style and preferences. (i.e. ssh or https) git 1 2 3 4 5 6 7 8 9 10 ( venv ) $ echo > README.md ( venv ) $ echo > .gitignore ( venv ) $ git init ( venv ) $ git config --global user.name \"Your Name\" ( venv ) $ git config --global user.email \"your@email.com\" # (1) ( venv ) $ git add . ( venv ) $ git commit -a # (2) ( venv ) $ git remote add origin \"your-repo-http\" # (3) ( venv ) $ git remote set-url origin https:// [ token ] @github.com/ [ username ] / [ repository ] # (4) ( venv ) $ git push origin master -u # (5) important to set the email linked to the git account. write commit message. add remote origin. set the remote origin. push to remote origin. Styling and Formatting We will be using a very popular blend of style and formatting conventions that makes some very opinionated decisions on our behalf (with configurable options) 1 . black : an in-place reformatter that (mostly) adheres to PEP8. isort : sorts and formats import statements inside Python scripts. flake8 : a code linter with stylistic conventions that adhere to PEP8. We also have pyproject.toml and .flake8 to configure our formatter and linter. create pyproject.toml and .flake8 1 2 ( venv ) $ echo > pyproject.toml ( venv ) $ echo > .flake8 For example, the configuration for black below tells us that our maximum line length should be \\(79\\) characters. We also want to exclude certain file extensions and in particular the virtual environment folder we created earlier. pyproject.toml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Black formatting [tool.black] line-length = 79 include = '\\.pyi?$' exclude = ''' /( \\.eggs # exclude a few common directories in the | \\.git # root of the project | \\.hg | \\.mypy_cache | \\.tox | _build | buck-out | build | dist | venv_* )/ ''' You can run black --check to check if your code is formatted correctly or black . to format your code. Mkdocs Mkdocs Setup We will be using Mkdocs to generate our markdown documentation into a static website. The following requirements are necessary to run mkdocs : requirements.txt 1 2 3 4 mkdocs 1.3.0 mkdocs-material 8.2.13 mkdocs-material-extensions 1.0.3 mkdocstrings 0.18.1 Initialize default template by calling mkdocs new . where . refers to the current directory. The . can be replaced with a path to your directory as well. Subsequently, a folder docs alongside with mkdocs.yml file will be created. mkdocs folder structure 1 2 3 4 5 6 7 pkd_exercise_counter/ \u251c\u2500\u2500 venv_pkd_exercise_counter/ \u251c\u2500\u2500 docs/ \u2502 \u2514\u2500\u2500 index.md \u251c\u2500\u2500 mkdocs.yml \u251c\u2500\u2500 requirements.txt \u2514\u2500\u2500 setup.py We can specify the following configurations in mkdocs.yml : Show/Hide mkdocs.yml mkdocs.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 site_name: Hongnan G. PeekingDuck Exercise Counter site_url: \"\" nav: - Home: index.md - PeekingDuck: - Setup: workflows.md - Push-up Counter: pushup.md theme: name: material features: - content.code.annotate markdown_extensions: - attr_list - md_in_html - admonition - footnotes - pymdownx.highlight - pymdownx.inlinehilite - pymdownx.superfences - pymdownx.snippets - pymdownx.details - pymdownx.arithmatex: generic: true extra_javascript: - javascript/mathjax.js - https://polyfill.io/v3/polyfill.min.js?features=es6 - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js extra_css: - css/extra.css plugins: - search - mkdocstrings # plugins for mkdocstrings Some of the key features include: Code block Line Numbering ; Code block Annotations ; MathJax . One missing feature is the ability to toggle code blocks. Two workarounds are provided: Toggle Using Admonition Setting Up mkdir custom_hn_push_up_counter Toggle Using HTML Setting Up mkdir custom_hn_push_up_counter We added some custom CSS and JavaScript files. In particular, we added mathjax.js for easier latex integration. You can now call mkdocs serve to start the server at a local host to view your document. Tip To link to a section or header, you can do this: [link to Styling and Formatting by workflows.md#styling-and-formatting . Mkdocstrings We also can create docstrings as API reference using Mkdocstrings : Install mkdocstrings: pip install mkdocstrings Place plugings to mkdocs.yml : mkdocs.yml 1 2 3 plugins: - search - mkdocstrings In mkdocs.yml 's navigation tree: mkdocs.yml 1 2 - API Documentation: - Exercise Counter: api/exercise_counter_api.md For example you have a python file called exercise_counter.py and want to render it, create a file named api/exercise_counter_api.md and in this markdown file: api/exercise_counter_api.md 1 ::: custom_hn_exercise_counter.src.custom_nodes.dabble.exercise_counter # package path. Tests Set up pytest for testing codes. Install pytest 1 2 pytest == 6 .0.2 pytest-cov == 2 .10.1 In general, Pytest expects our testing codes to be grouped under a folder called tests . We can configure in our pyproject.toml file to override this if we wish to ask pytest to check from a different directory. After specifying the folder holding the test codes, pytest will then look for python scripts starting with tests_*.py ; we can also change the extensions accordingly if you want pytest to look for other kinds of files (extensions) 2 . pyproject.toml 1 2 3 4 # Pytest [ tool.pytest.ini_options ] testpaths = [ \"tests\" ] python_files = \"test_*.py\" CI/CD (GitHub Actions) The following content is with reference to: MLOps Basics [Week 6]: CI/CD - GitHub Actions CI/CD for Machine Learning We will be using GitHub Actions to setup our mini CI/CD. Commit Checks Commit checks is to ensure the following: The requirements can be installed on various OS and python versions. Ensure code quality and adherence to PEP8 (or other coding standards). Ensure tests are passed. lint_test.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 name : Commit Checks # (1) on : [ push , pull_request ] # (2) jobs : # (3) check_code : # (4) runs-on : ${{ matrix.os }} # (5) strategy : # (6) fail-fast : false # (7) matrix : # (8) os : [ ubuntu-latest , windows-latest ] # (9) python-version : [ 3.8 , 3.9 ] # (10) steps : # (11) - name : Checkout code # (12) uses : actions/checkout@v2 # (13) - name : Setup Python # (14) uses : actions/setup-python@v2 # (15) with : # (16) python-version : ${{ matrix.python-version }} # (17) cache : \"pip\" # (18) - name : Install dependencies # (19) run : | # (20) python -m pip install --upgrade pip setuptools wheel pip install -e . - name : Run Black Formatter # (21) run : black --check . # (22) # - name: Run flake8 Linter # run: flake8 . # look at my pyproject.toml file and see if there is a flake8 section, if so, run flake8 on the files in the flake8 section - name : Run Pytest # (23) run : python -m coverage run --source=custom_hn_exercise_counter -m pytest && python -m coverage report # (24) This is the name that will show up under the Actions tab in GitHub. Typically, we should name it appropriately like how we indicate the subject of an email. The list here indicates the workflow will be triggered whenever someone directly pushes or submits a PR to the main branch. Once an event is triggered, a set of jobs will run on a runner . In our example, we will run a job called check_code on a runner to check for formatting and linting errors as well as run the pytest tests. This is the name of the job that will run on the runner. We specify which OS system we want the code to be run on. We can simply say ubuntu-latest or windows-latest if we just want the code to be tested on a single OS. However, here we want to check if it works on both Ubuntu and Windows, and hence we define ${{ matrix.os }} where matrix.os is [ubuntu-latest, windows-latest] . A cartesian product is created for us and the job will run on both OSs. Strategy is a way to control how the jobs are run. In our example, we want the job to run as fast as possible, so we set strategy.fail-fast to false . If one job fails, then the whole workflow will fail, this is not ideal if we want to test multiple jobs, we can set fail-fast to false to allow the workflow to continue running on the remaining jobs. Matrix is a way to control how the jobs are run. In our example, we want to run the job on both Python 3.8 and 3.9, so we set matrix.python-version to [3.8, 3.9] . This list consists of the OS that the job will run on in cartesian product. This is the python version that the job will run on in cartesian product. We can simply say 3.8 or 3.9 if we just want the code to be tested on a single python version. However, here we want to check if it works on both python 3.8 and python 3.9, and hence we define ${{ matrix.python-version }} where matrix.python-version is [3.8, 3.9] . A cartesian product is created for us and the job will run on both python versions. This is a list of dictionaries that defines the steps that will be run. Name is the name of the step that will be run. It is important to specify @v2 as if unspecified, then the workflow will use the latest version from actions/checkout template, potentially causing libraries to break. The idea here is like your requirements.txt idea, if different versions then will break. Setup Python is a step that will be run before the job. Same as above, we specify @v2 as if unspecified, then the workflow will use the latest version from actions/setup-python template, potentially causing libraries to break. With is a way to pass parameters to the step. This is the python version that the job will run on in cartesian product and if run 1 python version then can define as just say 3.7 Cache is a way to control how the libraries are installed. Install dependencies is a step that will be run before the job. | is multi-line string that runs the below code, which sets up the libraries from setup.py file. Run Black Formatter is a step that will be run before the job. Runs black with configurations from pyproject.toml file. Run Pytest is a step that will be run before the job. Runs pytest, note that I specified python -m to resolve PATH issues. Deploy to Website The other workflow for this project is to deploy the website built from Mkdocsto gh-pages branch. Show/Hide content for deploy_website.yml deploy_website.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 name : Deploy Website to GitHub Pages on : push : branches : [ master ] paths : - \"docs/**\" - \"mkdocs.yml\" - \".github/workflows/deploy_website.yml\" permissions : write-all jobs : deploy : runs-on : ubuntu-latest name : Deploy Website steps : - uses : actions/checkout@v2 - name : Set Up Python uses : actions/setup-python@v2 with : python-version : 3.8 architecture : x64 - name : Install dependencies run : | # this symbol is called a multiline string python -m pip install --upgrade pip setuptools wheel pip install -e . - name : Build Website run : | mkdocs build - name : Push Built Website to gh-pages Branch run : | git config --global user.name 'Hongnan G.' git config --global user.email 'reighns92@users.noreply.github.com' ghp-import \\ --no-jekyll \\ --force \\ --no-history \\ --push \\ --message \"Deploying ${{ github.sha }}\" \\ site This part is extracted from madewithml . \u21a9 This part is extracted from madewithml . \u21a9","title":"Workflow"},{"location":"reighns_ml_journey/software_engineering/workflow/#introduction","text":"This getting started guide is written to ensure I follow standard coding practices. Important To render Table of Content when compiling mkdocs serve , one must always have the following structure: # Type your article title here ## ... ## ... Notice that the top level header must be #, and subsequent nested headers should be ##.","title":"Introduction"},{"location":"reighns_ml_journey/software_engineering/workflow/#setting-up-environment","text":"Assuming VSCode setup, open up terminal/powershell in your respective system and type: code \"path to folder\" to open up VSCode.","title":"Setting up Environment"},{"location":"reighns_ml_journey/software_engineering/workflow/#virtual-environment","text":"In your IDE, you want to set up a virtual environment. # For Ubuntu sudo apt install python3.8 python3.8-venv python3-venv # For Mac pip3 install virtualenv You can activate the VM as follows: # Assuming Windows python -m venv venv_bcw . \\v env_bcw \\S cripts \\a ctivate python -m pip install --upgrade pip setuptools wheel # upgrade pip # Assuming Linux python3 -m venv venv_bcw source venv_bcw/bin/activate python -m pip install --upgrade pip setuptools wheel # upgrade pip # Assuming Mac virtualenv venv_bcw source venv_bcw/bin/activate python -m pip install --upgrade pip setuptools wheel # upgrade pip","title":"Virtual Environment"},{"location":"reighns_ml_journey/software_engineering/workflow/#setup-and-requirements","text":"Note For small projects, we can have requirements.txt and just run (venv_ml) pip install -r requirements.txt . For larger projects, we can follow the steps below. Create a file named setup.py and requirements.txt concurrently. The latter should have the libraries that one is interested in having for his project while the formal is a setup.py file where it contains the setup object which describes how to set up our package and it's dependencies. The first several lines cover metadata (name, description, etc.) and then we define the requirements. Here we're stating that we require a Python version equal to or above 3.8 and then passing in our required packages to install_requires. Finally, we define extra requirements that different types of users may require. This is a standard practice and more can be understood from madewithml.com. The user can now call the following commands to install the dependencies in their own virtual environment. See here on what pip install -e . does. pip install -e . # installs required packages only python -m pip install -e \".[dev]\" # installs required + dev packages python -m pip install -e \".[test]\" # installs required + test packages python -m pip install -e \".[docs_packages]\" # installs required documentation packages Important Something worth taking note is when you download PyTorch Library, there is a dependency link since we are downloading cuda directly, you may execute as such: pip install -e . -f https://download.pytorch.org/whl/torch_stable.html","title":"Setup and requirements"},{"location":"reighns_ml_journey/software_engineering/workflow/#command-line","text":"Something worth noting is we need to use dash instead of underscore when calling a function in command line. reighns_linear_regression regression-test --solver \"Batch Gradient Descent\" --num-epochs 500","title":"Command Line"},{"location":"reighns_ml_journey/software_engineering/workflow/#documentation","text":"","title":"Documentation"},{"location":"reighns_ml_journey/software_engineering/workflow/#type-hints","text":"","title":"Type Hints"},{"location":"reighns_ml_journey/software_engineering/workflow/#mkdocs-docstrings","text":"Copy paste the template from Goku in, most of what he use will be in mkdocs.yml file. Remember to create the mkdocs.yml in the root path. Then change accordingly the content inside mkdocs.yml , you can see my template that I have done up. Remember to run python -m pip install -e \".[docs_packages]\" to make sure you do have the packages. Along the way you need to create a few folders, follow the page tree in mkdocs.yml, everything should be created in docs/ folder. As an example, in our reighns-linear-regression folder, we want to show two scenarios: Scenario 1: I merely want a full markdown file to show on the website. In this case, in the \"watch\", we specify a path we want to watch in our docs/ folder. In this case, I created a documentation folder under docs/ so I specify that. Next in the docs/documentation/ folder I create a file called linear_regression.md where I dump all my markdown notes inside. Then in the nav tree in mkdocs.yml , specify nav: - Home: - Introduction: index.md - Getting started: getting_started.md - Detailed Notes: - Notes: documentation/linear_regression.md - Reference: documentation/reference_links.md Note that Home and Getting Started are optional but let us keep it for the sake of completeness. What you need to care is \"Detailed Notes\" and note the path I gave to them - which will point to the folders in docs/documentation/ . Scenario 2: I want a python file with detailed docstrings to appear in my static website. This is slightly more complicated. First if you want a new section of this you can create a section called code_reference , both under the nav above and also in the folder docs/ , meaning docs/code_reference/ must exist. Put it under watch as well. Now in docs/code_reference/ create a file named say linear_regression_from_scratch.md and put src.linear_regression inside, note that you should not have space in between.","title":"Mkdocs + Docstrings"},{"location":"reighns_ml_journey/software_engineering/workflow/#run","text":"Run config.py as this will create folders for you automatically.","title":"Run"},{"location":"reighns_ml_journey/software_engineering/workflow/#setting-up-github-pages-and-mkdocs-website","text":"Update November 9th, 2021 You can skip most steps if you just fork this repository and follow the format. Welcome to my example website! This website uses MkDocs with the Material theme and an automated deployment workflow for publishing to GitHub Pages . This guide will help you create your own GitHub Pages website with this setup. If you're using Windows, you should run all the commands in this guide on a Windows Subsystem for Linux (WSL) terminal.","title":"Setting up GitHub Pages and Mkdocs (Website)"},{"location":"reighns_ml_journey/software_engineering/workflow/#initializing-your-website-repository","text":"First, create a new repository on GitHub. Make sure to skip the initialization step on the website \u2014 you will be initializing the contents of this repository with this template! Note down the Git remote for your new repository, you'll need it later when initializing your local copy of the repository. Next, download the website template and extract it: $ wget https://github.com/jansky/test-website/archive/refs/tags/template.tar.gz $ tar xvf template.tar.gz $ rm template.tar.gz Note If the wget command is not found, you can install it using apt-get: sudo apt-get install wget . This will create a new folder called test-website-template in your current directory with the website template contents. You may wish to rename this folder to something like my-website : $ mv test-website-template my-website Now you can initialize a Git repository with the website contents: $ cd my-website $ git init $ git remote add origin YOUR_GITHUB_REPOSITORY_REMOTE","title":"Initializing your Website Repository"},{"location":"reighns_ml_journey/software_engineering/workflow/#website-configuration","text":"The configuration for your website is stored in mkdocs.yml in the repository root. You only need to change a few settings at the top of the file: 1 2 3 4 5 6 7 site_name : Example Website site_url : https://reighns92.github.io/test-website nav : - Home : index.md - About : about.md - Notebooks : notebooks_list.md ... First, update the site_name and site_url fields to be correct for your website. The URL format for GitHub pages websites is https://USERNAME.github.io/REPOSITORY-NAME As you add content to your website, you can also control the pages that appear on your website's navbar in the nav field. Each nav list element is of the form Link Text : filename.md For navbar links pointing to pages in your site, you should use a file path which is relative to the docs/ folder where all your website content is stored. You may also link to external pages and include sub-links. For more information, you can view the MkDocs nav documentation .","title":"Website Configuration"},{"location":"reighns_ml_journey/software_engineering/workflow/#github-actions-configuration","text":"You also need to update the GitHub Actions deployment workflow with the name and e-mail address to use when the workflow pushes your built website to the gh-pages branch of your repository. In the file .github/workflows/deploy-website.yml , update lines 25 and 26 to reflect your account information: 22 23 24 25 26 27 ... - name : Push Build Website to gh-pages Branch run : | git config --global user.name 'YOUR NAME(Automated)' git config --global user.email 'YOUR-GITHUB-USERNAME@users.noreply.github.com' ...","title":"GitHub Actions Configuration"},{"location":"reighns_ml_journey/software_engineering/workflow/#setting-up-local-development","text":"MkDocs makes it easy to develop your website locally and see your changes in real time. To begin, set up and activate Python virtual environment for this project. Then, install the project dependencies: ( venv ) $ pip install -r requirements.txt MkDocs includes a small webserver that allows you to preview your website in your browser as you make changes. Whenever you save one of your source files, the website will be rebuilt and your browser will automatically refresh to show the new changes. You can start this development server using the serve command: ( venv ) $ mkdocs serve INFO - Building documentation... ... INFO - Documentation built in 0 .16 seconds INFO - [ 20 :09:07 ] Serving on http://127.0.0.1:8000/... ... If you copy and paste the URL given by MkDocs into your browser you will see your website preview.","title":"Setting Up Local Development"},{"location":"reighns_ml_journey/software_engineering/workflow/#adding-website-content","text":"Markdown files added under the docs/ folder will be converted to HTML pages on your website. This website template enables some helpful extensions for rendering of math in LaTeX style, admonitions such as notes and warnings, and code blocks with syntax highlighting. In addition, MkDocs also supports GitHub-flavored Markdown tables. To see examples of syntax for these elements, see the MkDocs website here .","title":"Adding Website Content"},{"location":"reighns_ml_journey/software_engineering/workflow/#deploying-your-changes","text":"When you are ready to deploy your website for the first time, make an initial commit and push to your GitHub remote: $ git add . $ git commit -a -m \"Initial Commit\" $ git push origin master -u","title":"Deploying Your Changes"},{"location":"reighns_ml_journey/software_engineering/workflow/#activate-workflow","text":"The GitHub Actions deployment workflow included with this template runs whenever you push to the master branch. This workflow will build your website using MkDocs and push the built website files to the gh-pages branch of your repository, which GitHub Pages can use to serve your website. Once you have pushed your changes, go to your repository page on GitHub and confirm that the GitHub Actions workflow has completed successfully (you should see a green checkmark next to the name of the most recent commit). Then, go to your repository settings page, and click on 'Pages'. You will see a section that will let you set the source for your GitHub Pages website. Click the box labelled 'None' and select the gh-pages branch. Leave the selectd folder at '/ (root)' and click 'Save'. Your website is now live! To push additional changes, simply commit and push to the master branch. The GitHub Actions deployment workflow will handle deploying your changes to GitHub Pages.","title":"Activate Workflow"},{"location":"reighns_ml_journey/software_engineering/workflow/#pandoc-markdown-converter","text":"More often than not, you will need to convert a jupyter notebook to markdown file for deployment (as markdown supports Admonitions in Mkdocs). Here is a way to do it, it is very convenient as it not only converts your notebook files to markdown, it also stores your output as images in a folder for you. This means any images rendered in notebook by matplotlib etc will now show up in markdown! brew install pandoc git clone https://github.com/jupyter/nbconvert.git cd nbconvert pip install -e . Then to convert, simply do the following: jupyter nbconvert --to markdown mynotebook.ipynb","title":"Pandoc (Markdown Converter)"},{"location":"reighns_ml_journey/software_engineering/workflow/#pandoc-wikitext-to-markdown","text":"From the solution here . We can do the following: pandoc --from mediawiki --to = markdown-definition_lists wiki.txt -o wiki.md where wiki.txt is a text file with wiki markup.","title":"Pandoc (Wikitext to Markdown)"},{"location":"reighns_ml_journey/software_engineering/workflow/#miscellaneous-problems","text":"","title":"Miscellaneous Problems"},{"location":"reighns_ml_journey/software_engineering/workflow/#path-environment","text":"Often times, you will encounter a problem with the path environment when working with Windows especially. For example, when you do the following: jupyter nbconvert --to markdown mynotebook.ipynb then 'jupyter' is not recognized as an internal or external command, operable program or batch file. is the error message even though jupyter is installed. Usually, the shell will prompt a message to check PATH . Now go to Advanced System Settings and click on Environment Variables. You will see a list of environment variables. You can add a new environment variable by clicking on the plus sign in the System Variables . Add the path recommended by jupyter to the PATH variable. In my case, it is the obscure C:\\Users\\reighns\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\Scripts .","title":"Path Environment"},{"location":"reighns_ml_journey/software_engineering/workflow/#mkdocs","text":"","title":"Mkdocs"},{"location":"reighns_ml_journey/software_engineering/workflow/#full-page-width","text":"Use this custom css code to make page full width.","title":"Full page width"},{"location":"reighns_ml_journey/software_engineering/workflow/#setup-main-directory-ide","text":"Let us create our main directory for the project: creating main directory 1 2 3 $ mkdir pkd_exercise_counter $ cd pkd_exercise_counter $ code . # (1) Open the project directory in Visual Studio Code. To change appropriately if using different IDE.","title":"Setup Main Directory (IDE)"},{"location":"reighns_ml_journey/software_engineering/workflow/#virtual-environment_1","text":"Set up a virtual environment in your IDE. Virtual Environment If you are using Linux or Mac, then you may need to install the virtual environment manager. For windows, python comes with a virtual environment manager venv installed. install venv 1 2 $ sudo apt install python3.8 python3.8-venv python3-venv # For Ubuntu $ pip3 install virtualenv # For Mac You can activate the virtual environment (assuming Windows) as follows: virtual environment windows 1 2 3 $ python -m venv venv_pkd_exercise_counter # (1) $ . \\v env_pkd_exercise_counter \\S cripts \\a ctivate # (2) ( venv ) $ python -m pip install --upgrade pip setuptools wheel # (3) Create virtual environment. Activate virtual environment. Upgrade pip. Note Although the virtual environment name is venv_pkd_exercise_counter , it is too long and I will use venv for future references. You should see the following directory structure: main directory tree 1 2 pkd_exercise_counter/ \u2514\u2500\u2500 venv_pkd_exercise_counter/","title":"Virtual Environment"},{"location":"reighns_ml_journey/software_engineering/workflow/#requirements-and-setup","text":"Note We note that echo > \"filename\" command is used to create a file in Windows. One can use touch in other OS such as macOS or even code if you are using Visual Studio Code. creating requirements 1 2 3 ( venv ) $ echo > setup.py ( venv ) $ echo > requirements.txt ( venv ) $ pip install -e . [ Line 1 -2 ] : setup.py file informs you about the module or package-dependencies you are about to install has been packaged and distributed with Distutils, which is the standard for distributing Python Modules. You can skip setup.py if you are just using requirements.txt to install dependencies. [ Line 3 ] : Installs packages from requirements.txt . One can also use commands such as python -m pip install -e \".[dev]\" to install additional dev packages specified in setup.py . After which we quickly run a verification to see if PeekingDuck is installed correctly. peekingduck verification 1 ( venv ) $ peekingduck --verify_install Info In my setup.py , I specified python to be \\(3.8\\) and above. This has been tested on ubuntu latest and windows latest in GitHub Actions. You should see the following directory structure: main directory tree 1 2 3 4 pkd_exercise_counter/ \u251c\u2500\u2500 venv_pkd_exercise_counter/ \u251c\u2500\u2500 requirements.txt \u2514\u2500\u2500 setup.py","title":"Requirements and Setup"},{"location":"reighns_ml_journey/software_engineering/workflow/#git","text":"Git is a version control system that is used to track changes to files. It is integral to the development process of any software. Here we initiate our main directory with git. Note The commands below may differ depending on personal style and preferences. (i.e. ssh or https) git 1 2 3 4 5 6 7 8 9 10 ( venv ) $ echo > README.md ( venv ) $ echo > .gitignore ( venv ) $ git init ( venv ) $ git config --global user.name \"Your Name\" ( venv ) $ git config --global user.email \"your@email.com\" # (1) ( venv ) $ git add . ( venv ) $ git commit -a # (2) ( venv ) $ git remote add origin \"your-repo-http\" # (3) ( venv ) $ git remote set-url origin https:// [ token ] @github.com/ [ username ] / [ repository ] # (4) ( venv ) $ git push origin master -u # (5) important to set the email linked to the git account. write commit message. add remote origin. set the remote origin. push to remote origin.","title":"Git"},{"location":"reighns_ml_journey/software_engineering/workflow/#styling-and-formatting","text":"We will be using a very popular blend of style and formatting conventions that makes some very opinionated decisions on our behalf (with configurable options) 1 . black : an in-place reformatter that (mostly) adheres to PEP8. isort : sorts and formats import statements inside Python scripts. flake8 : a code linter with stylistic conventions that adhere to PEP8. We also have pyproject.toml and .flake8 to configure our formatter and linter. create pyproject.toml and .flake8 1 2 ( venv ) $ echo > pyproject.toml ( venv ) $ echo > .flake8 For example, the configuration for black below tells us that our maximum line length should be \\(79\\) characters. We also want to exclude certain file extensions and in particular the virtual environment folder we created earlier. pyproject.toml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Black formatting [tool.black] line-length = 79 include = '\\.pyi?$' exclude = ''' /( \\.eggs # exclude a few common directories in the | \\.git # root of the project | \\.hg | \\.mypy_cache | \\.tox | _build | buck-out | build | dist | venv_* )/ ''' You can run black --check to check if your code is formatted correctly or black . to format your code.","title":"Styling and Formatting"},{"location":"reighns_ml_journey/software_engineering/workflow/#mkdocs_1","text":"","title":"Mkdocs"},{"location":"reighns_ml_journey/software_engineering/workflow/#mkdocs-setup","text":"We will be using Mkdocs to generate our markdown documentation into a static website. The following requirements are necessary to run mkdocs : requirements.txt 1 2 3 4 mkdocs 1.3.0 mkdocs-material 8.2.13 mkdocs-material-extensions 1.0.3 mkdocstrings 0.18.1 Initialize default template by calling mkdocs new . where . refers to the current directory. The . can be replaced with a path to your directory as well. Subsequently, a folder docs alongside with mkdocs.yml file will be created. mkdocs folder structure 1 2 3 4 5 6 7 pkd_exercise_counter/ \u251c\u2500\u2500 venv_pkd_exercise_counter/ \u251c\u2500\u2500 docs/ \u2502 \u2514\u2500\u2500 index.md \u251c\u2500\u2500 mkdocs.yml \u251c\u2500\u2500 requirements.txt \u2514\u2500\u2500 setup.py We can specify the following configurations in mkdocs.yml : Show/Hide mkdocs.yml mkdocs.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 site_name: Hongnan G. PeekingDuck Exercise Counter site_url: \"\" nav: - Home: index.md - PeekingDuck: - Setup: workflows.md - Push-up Counter: pushup.md theme: name: material features: - content.code.annotate markdown_extensions: - attr_list - md_in_html - admonition - footnotes - pymdownx.highlight - pymdownx.inlinehilite - pymdownx.superfences - pymdownx.snippets - pymdownx.details - pymdownx.arithmatex: generic: true extra_javascript: - javascript/mathjax.js - https://polyfill.io/v3/polyfill.min.js?features=es6 - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js extra_css: - css/extra.css plugins: - search - mkdocstrings # plugins for mkdocstrings Some of the key features include: Code block Line Numbering ; Code block Annotations ; MathJax . One missing feature is the ability to toggle code blocks. Two workarounds are provided: Toggle Using Admonition Setting Up mkdir custom_hn_push_up_counter Toggle Using HTML Setting Up mkdir custom_hn_push_up_counter We added some custom CSS and JavaScript files. In particular, we added mathjax.js for easier latex integration. You can now call mkdocs serve to start the server at a local host to view your document. Tip To link to a section or header, you can do this: [link to Styling and Formatting by workflows.md#styling-and-formatting .","title":"Mkdocs Setup"},{"location":"reighns_ml_journey/software_engineering/workflow/#mkdocstrings","text":"We also can create docstrings as API reference using Mkdocstrings : Install mkdocstrings: pip install mkdocstrings Place plugings to mkdocs.yml : mkdocs.yml 1 2 3 plugins: - search - mkdocstrings In mkdocs.yml 's navigation tree: mkdocs.yml 1 2 - API Documentation: - Exercise Counter: api/exercise_counter_api.md For example you have a python file called exercise_counter.py and want to render it, create a file named api/exercise_counter_api.md and in this markdown file: api/exercise_counter_api.md 1 ::: custom_hn_exercise_counter.src.custom_nodes.dabble.exercise_counter # package path.","title":"Mkdocstrings"},{"location":"reighns_ml_journey/software_engineering/workflow/#tests","text":"Set up pytest for testing codes. Install pytest 1 2 pytest == 6 .0.2 pytest-cov == 2 .10.1 In general, Pytest expects our testing codes to be grouped under a folder called tests . We can configure in our pyproject.toml file to override this if we wish to ask pytest to check from a different directory. After specifying the folder holding the test codes, pytest will then look for python scripts starting with tests_*.py ; we can also change the extensions accordingly if you want pytest to look for other kinds of files (extensions) 2 . pyproject.toml 1 2 3 4 # Pytest [ tool.pytest.ini_options ] testpaths = [ \"tests\" ] python_files = \"test_*.py\"","title":"Tests"},{"location":"reighns_ml_journey/software_engineering/workflow/#cicd-github-actions","text":"The following content is with reference to: MLOps Basics [Week 6]: CI/CD - GitHub Actions CI/CD for Machine Learning We will be using GitHub Actions to setup our mini CI/CD.","title":"CI/CD (GitHub Actions)"},{"location":"reighns_ml_journey/software_engineering/workflow/#commit-checks","text":"Commit checks is to ensure the following: The requirements can be installed on various OS and python versions. Ensure code quality and adherence to PEP8 (or other coding standards). Ensure tests are passed. lint_test.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 name : Commit Checks # (1) on : [ push , pull_request ] # (2) jobs : # (3) check_code : # (4) runs-on : ${{ matrix.os }} # (5) strategy : # (6) fail-fast : false # (7) matrix : # (8) os : [ ubuntu-latest , windows-latest ] # (9) python-version : [ 3.8 , 3.9 ] # (10) steps : # (11) - name : Checkout code # (12) uses : actions/checkout@v2 # (13) - name : Setup Python # (14) uses : actions/setup-python@v2 # (15) with : # (16) python-version : ${{ matrix.python-version }} # (17) cache : \"pip\" # (18) - name : Install dependencies # (19) run : | # (20) python -m pip install --upgrade pip setuptools wheel pip install -e . - name : Run Black Formatter # (21) run : black --check . # (22) # - name: Run flake8 Linter # run: flake8 . # look at my pyproject.toml file and see if there is a flake8 section, if so, run flake8 on the files in the flake8 section - name : Run Pytest # (23) run : python -m coverage run --source=custom_hn_exercise_counter -m pytest && python -m coverage report # (24) This is the name that will show up under the Actions tab in GitHub. Typically, we should name it appropriately like how we indicate the subject of an email. The list here indicates the workflow will be triggered whenever someone directly pushes or submits a PR to the main branch. Once an event is triggered, a set of jobs will run on a runner . In our example, we will run a job called check_code on a runner to check for formatting and linting errors as well as run the pytest tests. This is the name of the job that will run on the runner. We specify which OS system we want the code to be run on. We can simply say ubuntu-latest or windows-latest if we just want the code to be tested on a single OS. However, here we want to check if it works on both Ubuntu and Windows, and hence we define ${{ matrix.os }} where matrix.os is [ubuntu-latest, windows-latest] . A cartesian product is created for us and the job will run on both OSs. Strategy is a way to control how the jobs are run. In our example, we want the job to run as fast as possible, so we set strategy.fail-fast to false . If one job fails, then the whole workflow will fail, this is not ideal if we want to test multiple jobs, we can set fail-fast to false to allow the workflow to continue running on the remaining jobs. Matrix is a way to control how the jobs are run. In our example, we want to run the job on both Python 3.8 and 3.9, so we set matrix.python-version to [3.8, 3.9] . This list consists of the OS that the job will run on in cartesian product. This is the python version that the job will run on in cartesian product. We can simply say 3.8 or 3.9 if we just want the code to be tested on a single python version. However, here we want to check if it works on both python 3.8 and python 3.9, and hence we define ${{ matrix.python-version }} where matrix.python-version is [3.8, 3.9] . A cartesian product is created for us and the job will run on both python versions. This is a list of dictionaries that defines the steps that will be run. Name is the name of the step that will be run. It is important to specify @v2 as if unspecified, then the workflow will use the latest version from actions/checkout template, potentially causing libraries to break. The idea here is like your requirements.txt idea, if different versions then will break. Setup Python is a step that will be run before the job. Same as above, we specify @v2 as if unspecified, then the workflow will use the latest version from actions/setup-python template, potentially causing libraries to break. With is a way to pass parameters to the step. This is the python version that the job will run on in cartesian product and if run 1 python version then can define as just say 3.7 Cache is a way to control how the libraries are installed. Install dependencies is a step that will be run before the job. | is multi-line string that runs the below code, which sets up the libraries from setup.py file. Run Black Formatter is a step that will be run before the job. Runs black with configurations from pyproject.toml file. Run Pytest is a step that will be run before the job. Runs pytest, note that I specified python -m to resolve PATH issues.","title":"Commit Checks"},{"location":"reighns_ml_journey/software_engineering/workflow/#deploy-to-website","text":"The other workflow for this project is to deploy the website built from Mkdocsto gh-pages branch. Show/Hide content for deploy_website.yml deploy_website.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 name : Deploy Website to GitHub Pages on : push : branches : [ master ] paths : - \"docs/**\" - \"mkdocs.yml\" - \".github/workflows/deploy_website.yml\" permissions : write-all jobs : deploy : runs-on : ubuntu-latest name : Deploy Website steps : - uses : actions/checkout@v2 - name : Set Up Python uses : actions/setup-python@v2 with : python-version : 3.8 architecture : x64 - name : Install dependencies run : | # this symbol is called a multiline string python -m pip install --upgrade pip setuptools wheel pip install -e . - name : Build Website run : | mkdocs build - name : Push Built Website to gh-pages Branch run : | git config --global user.name 'Hongnan G.' git config --global user.email 'reighns92@users.noreply.github.com' ghp-import \\ --no-jekyll \\ --force \\ --no-history \\ --push \\ --message \"Deploying ${{ github.sha }}\" \\ site This part is extracted from madewithml . \u21a9 This part is extracted from madewithml . \u21a9","title":"Deploy to Website"}]}