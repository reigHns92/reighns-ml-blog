{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdMIc32_RsMv"
   },
   "source": [
    "## Dependencies and Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qVkn30yCDLLB"
   },
   "outputs": [],
   "source": [
    "# !pip install -q scikit-learn==1.0.1\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics, preprocessing\n",
    "import itertools\n",
    "from typing import List, Dict, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1AotyB4lRrwK"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_(y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Calculates the confusion matrix.\n",
    "    We assume that the inputs are binarized already.\n",
    "    This can be used in both binary and multiclass classification\n",
    "    provided that we label binarized the multiclass labels.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): the correct labels, shape (n_samples, )\n",
    "        y_pred (np.ndarray): the predicted labels, shape (n_samples, )\n",
    "\n",
    "    Returns:\n",
    "        cm (np.ndarray): the confusion matrix, shape (n_classes, n_classes)\n",
    "                         with [[tp, fp], [fn, tn]]\n",
    "    \"\"\"\n",
    "    tp, fp, fn, tn = 0, 0, 0, 0\n",
    "\n",
    "    for y_t, y_p in zip(y_true, y_pred):\n",
    "        # if actual and predicted both are positive class\n",
    "        if y_t == y_p == 1:\n",
    "            tp += 1\n",
    "        # if actual and predicted both are negative class\n",
    "        elif y_t == y_p == 0:\n",
    "            tn += 1\n",
    "        # if actual is negative and predicted is positive\n",
    "        elif y_t == 0 and y_p == 1:\n",
    "            fp += 1\n",
    "        # if actual is positive and predicted is negative\n",
    "        elif y_t == 1 and y_p == 0:\n",
    "            fn += 1\n",
    "\n",
    "    cm = np.asarray([[tp, fp], [fn, tn]])\n",
    "    return cm\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    title: str,\n",
    "    labels: List[str],\n",
    "    tick_labels: List[str],\n",
    ") -> None:\n",
    "    \"\"\"Plots a Binary Confusion Matrix.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): the actual labels.\n",
    "        y_pred (np.ndarray): the predicted labels.\n",
    "        title (str): the title of the plot.\n",
    "        tick_labels (List[str]): The labels for the ticks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Unravel into tn, fp, fn and tp\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(\n",
    "        y_true, y_pred, labels=labels\n",
    "    ).ravel()\n",
    "\n",
    "    # reshape into tp, fp, fn, tn - this is personal preference\n",
    "    reshaped_cm = np.asarray([[tp, fp], [fn, tn]])\n",
    "\n",
    "    # flatten this 2d array\n",
    "    cm_flattened = reshaped_cm.flatten()\n",
    "\n",
    "    labels = [\n",
    "        \"True Positive\",\n",
    "        \"False Positive\",\n",
    "        \"False Negative\",\n",
    "        \"True Negative\",\n",
    "    ]\n",
    "    annot = (\n",
    "        np.asarray(\n",
    "            [\n",
    "                f\"{label}\\n{cm_count}\"\n",
    "                for label, cm_count in zip(labels, cm_flattened)\n",
    "            ]\n",
    "        )\n",
    "    ).reshape(2, 2)\n",
    "\n",
    "    ax = plt.subplot()\n",
    "    heatmap = sns.heatmap(\n",
    "        reshaped_cm,\n",
    "        annot=annot,\n",
    "        fmt=\"\",\n",
    "        cmap=\"Greens\",\n",
    "        ax=ax,\n",
    "        xticklabels=tick_labels,\n",
    "        yticklabels=tick_labels,\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted labels\")\n",
    "    ax.set_ylabel(\"True labels\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_7SfOSX790F"
   },
   "source": [
    "## **Precision**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kp_Etvvn790F"
   },
   "source": [
    "### Definition\n",
    "\n",
    "!!! success \"Definition\"\n",
    "    Precision measures how many of the samples predicted as positive are actually positive. Mathematically, it is expressed as:\n",
    "\n",
    "    $$\\text{Precision} = \\dfrac{\\text{TP}}{\\text{TP} + \\text{FP}}=P(Y=1 | \\hat{Y} = 1)$$\n",
    "\n",
    "---\n",
    "\n",
    "!!! info \"Probablistic Interpretation\"\n",
    "    Notice that the above definition has a probabilitic interpretation $P(Y = 1 | \\hat{Y} = 1)$, where $Y$ and $\\hat{Y}$ refers to the actual label and predicted labels respectively. We interpreted precision and recall not as ratios but as [estimations of probabilities](https://en.wikipedia.org/wiki/Precision_and_recall).\n",
    "    Precision is then the estimated probability that a random point selected from the samples are positive. This might be a tough pill to swallow as someone who was never good in statistics but it is just conditional probability. If you try to think a bit further, you can form an intuition as follows:\n",
    "    > If your classifier $h$ is trained and the last layer is say, sigmoid, which in binary classification, calibrates the logits and turn them into probabilities. Then it can be interpretated that given a randomly chosen point $x \\in X_{train}$, what is the probability of this point $x$ to be positive given that it is predicted as positive by the classifer?\n",
    "\n",
    "---\n",
    "\n",
    "Informally, precision answers the question **what proportion of positive predictions was actually correct**? In other words, out of all the positive predictions made by the model, how many of those positive predictions were actually positive when compared to the ground truth?\n",
    "\n",
    "---\n",
    "\n",
    "When I learned this back then, it is not immediately obvious what the denominator is doing. Dissecting the formula helps. The loose dynamics is that TP and FP are inversely related, and assuming a fixed threshold, the denominator is fixed as follows:\n",
    "\n",
    "$$\\text{Predicted Number of Positives} = \\text{TP} + \\text{FP}$$    \n",
    "\n",
    "Thus, minimizing FP is equivalent to maximizing TP, doing so will lead to an increase in precision.\n",
    "\n",
    "---\n",
    "\n",
    "!!! note\n",
    "    Just like the confusion matrix, we yield different precision score should we treat benign as the positive class.\n",
    "\n",
    "---\n",
    "\n",
    "!!! example\n",
    "    Consider a email company that developed a email spam detector for their uses. There are two outcomes/classes:\n",
    "    ```python\n",
    "    positive class = spam\n",
    "    negative class = not spam\n",
    "    ```\n",
    "    From the company's perspective, they will be optimizing precision over recall because they want the spam detector to have minimal False Positives because predicting an not spam (which could be an important email) email as spam is much more costly than predicting a spam email as not spam. Imagine your important emails being put into spam folder by the spam detector?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ai0pWNkJ790F"
   },
   "source": [
    "### When to use Precision?\n",
    "\n",
    "- When your company needs you to ***restrict the number of False Positives***. Prime examples are email spam prediction.\n",
    "\n",
    "- There is a trade-off between precision and recall, and restricting the number of FP ***may*** give rise to the increase in FN. So ultimately, bear in mind that it is not simply a matter of ***restricting the number of False Positives*** but a matter of ***use cases in your business setting, on whether achieving lesser FP is more important than achieving a lesser FN***.\n",
    "\n",
    "### When NOT to use Precision?\n",
    "\n",
    "!!! danger\n",
    "    - If you have a precision score of 1, then this means that $TP = TP + FP = 1 \\implies FP = 0$. This means it can be achieved if your predictions have 0 False Positives, but this does not tell us **anything** about the False Negatives.\n",
    "    - When you prioritize recall/sensitivity more than precision for your business needs.\n",
    "    - You should never ever use `precision` as a single metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfZ2Cjvg790G"
   },
   "source": [
    "### Implementation of Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RacLwhPA790G",
    "outputId": "7e0d875b-2fb4-4e63-dd45-d600cb6f218e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our precision: 0.75\n",
      "sklearn precision: 0.75\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([1, 1, 0, 1, 0, 0, 1, 0, 0, 1])\n",
    "y_pred = np.array([1, 1, 1, 0, 0, 0, 1, 0, 0, 0])\n",
    "\n",
    "\n",
    "tp, fp, fn, tn = confusion_matrix_(y_true, y_pred).ravel()\n",
    "reighns_precision = tp / (tp + fp)\n",
    "\n",
    "print(f\"our precision: {reighns_precision}\")\n",
    "\n",
    "sklearn_precision = metrics.precision_score(y_true, y_pred, average=\"binary\")\n",
    "\n",
    "print(f\"sklearn precision: {sklearn_precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8SXvyid790G"
   },
   "source": [
    "## Recall/Sensitivity/True Positive Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVobSDW2790G"
   },
   "source": [
    "### Definition\n",
    "\n",
    "!!! success \"Definition\"\n",
    "    Recall measures the following: out of all the actual positives (say, the real cancer patients), how many of them were identified correctly by the classifier? Mathematically, it is expressed as:\n",
    "    \n",
    "    $$\\text{Recall}= \\dfrac{\\text{TP}}{\\text{TP} + \\text{FN}}= P(\\hat{Y}=1 | Y = 1)=1-FNR$$\n",
    "\n",
    "---\n",
    "\n",
    "!!! info \"Probabilistic Interpretation\"\n",
    "    Similarly, we can interpret recall probabilistically like how we did to precision. Recall is the conditional probability of the sample being predicted as positive given that the sample is positive.\n",
    "\n",
    "---\n",
    "\n",
    "!!! note\n",
    "    From the formula, we see the denominator to be defined as TP + FN, which is unsurprising as this gives you the actual number of positives. The dynamics is also similar to the one in precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U01aZ8XTSoYG"
   },
   "source": [
    "!!! example\n",
    "    For cancer data modeling, anything that doesn't account for false-negatives is like committing a crime indirectly (a strong statement, but lives are at stake here!). Recall is a better measure than precision in this aspect assuming that the positive class is malignant.\n",
    "    ```python\n",
    "    positive class = malignant\n",
    "    negative class = benign\n",
    "    ```\n",
    "    A healthcare company came up with a cancer test kit. Instead of reporting its accuracy, we should examine the recall first as the test kit should have minimum False Negatives because predicting a patient with cancer as benign yields a much higher cost than predicting a healthy patient to have cancer. You really do not want to miss any sick patients, you will see later on how we can tune the decision threshold of a classifier to achieve a higher recall at the expense of lowering precision.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbJ5yXPs790G"
   },
   "source": [
    "### When to use Recall?\n",
    "\n",
    "- When your company needs you to ***restrict the number of False Negatives***.\n",
    "\n",
    "### When to NOT use Recall?\n",
    "\n",
    "!!! danger\n",
    "    - If you have a recall score of 1, then this means that $TP = TP + FN = 1 \\implies FN = 0$; there are 0 False Negatives, but this does not tell us **anything** about the False Positives.\n",
    "    - When you prioritize precision more than recall for your business needs.\n",
    "    - You almost never ever use `recall` as a single metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Lvsxbo3790G"
   },
   "source": [
    "### Implementation of Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcAQtLo2790G",
    "outputId": "cb6865ca-59e9-4d52-aa23-27c5379c1649"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our recall: 0.6\n",
      "sklearn recall: 0.6\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([1, 1, 0, 1, 0, 0, 1, 0, 0, 1])\n",
    "y_pred = np.array([1, 1, 1, 0, 0, 0, 1, 0, 0, 0])\n",
    "\n",
    "\n",
    "tp, fp, fn, tn = confusion_matrix_(y_true, y_pred).ravel()\n",
    "reighns_recall = tp / (tp + fn)\n",
    "\n",
    "print(f\"our recall: {reighns_recall}\")\n",
    "\n",
    "sklearn_recall = metrics.recall_score(y_true, y_pred, average=\"binary\")\n",
    "\n",
    "print(f\"sklearn recall: {sklearn_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLyejjGl790H"
   },
   "source": [
    "## The Precision-Recall Tradeoff\n",
    "\n",
    "Does this term reminisce with the Bias-Variance Tradeoff? More specifically, when we talk about precision and recall in the sections above, we are fixated at one **decision threshold** of our classifier. One should note that both metrics are parametrized by $t$, the decision threshold. We can tune our threshold to achieve a better precision or recall, but usually not both, hence the tradeoff. \n",
    "\n",
    "---\n",
    "\n",
    "We can read more from [Google's Machine Learning Crash Course on Precison and Recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bpsQ83e790H"
   },
   "source": [
    "## Specificity/True Negative Rate\n",
    "\n",
    "!!! success \"Definition\"\n",
    "    $$TNR = \\dfrac{TN}{TN + FP} = P(\\hat{Y} = 0| Y=0) = 1 - FPR$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWQBsUaR790H"
   },
   "source": [
    "## False Positive Rate\n",
    "\n",
    "!!! success \"Definition\"\n",
    "    Out of all the real negative classes (negative ground truth), how many were predicted wrongly (predicted as positive from the model).\n",
    "   \n",
    "    $$FPR = \\dfrac{FP}{FP + TN}=1-TNR$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCFgJlJd790H"
   },
   "source": [
    "## False Negative Rate\n",
    "\n",
    "!!! success \"Definition\"\n",
    "    $$TNR = \\dfrac{FN}{FN + TP} = 1 - TPR$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMIKeCYk790H"
   },
   "source": [
    "## F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gliCTFqL790H"
   },
   "source": [
    "### Intuition\n",
    "\n",
    "Motivated by the examples above, where using single precision or recall do not tell us much about the whole story. We thus turn to a combination of the above metrics. Penalizes extreme values of precision and recall more than arithmetic mean[^1].\n",
    "\n",
    "[^1]: https://stackoverflow.com/questions/26355942/why-is-the-f-measure-a-harmonic-mean-and-not-an-arithmetic-mean-of-the-precision/26360501#26360501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzCAvVCs790H"
   },
   "source": [
    "### Definition\n",
    "\n",
    "!!! success \"Definition\"\n",
    "    The F1 score is the <b>harmonic mean</b> between Precision and Recall, bounded between 0 and 1. \n",
    "\n",
    "    $$F1 = \\dfrac{2(\\text{Precision} \\times \\text{Recall})}{\\text{Precision} + \\text{Recall}}$$\n",
    "\n",
    "!!! example\n",
    "    TO CITE: For example, imagine that the blood protein levels in diseased people and healthy people are normally distributed with means of 2 g/dL and 1 g/dL respectively. A medical test might measure the level of a certain protein in a blood sample and classify any number above a certain threshold as indicating disease. The experimenter can adjust the threshold (black vertical line in the figure), which will in turn change the false positive rate. Increasing the threshold would result in fewer false positives (and more false negatives), corresponding to a leftward movement on the curve. The actual shape of the curve is determined by how much overlap the two distributions have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YDCOo3kWbW_"
   },
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UI0Z0ZSgINhw"
   },
   "source": [
    "We can extend the binary classification metrics to a multiclass classification setting. Initially, it is not entirely clear how we should handle precision, recall and f1-score because metrics like False Negatives are not well defined - we simply do not know who is the \"positive\" and \"negative\" class here. It turns out that this is not a problem if we use the One-vs-Rest scheme.\n",
    "\n",
    "We introduce two ways to do so, which is either using micro-averaging, or macro-averaging. Before we go deeper, we first need to understand the notion of One-vs-Rest.\n",
    "\n",
    "Consider a multiclass problem with 3 labels:  \n",
    "```python\n",
    "# Our dataset is as follows\n",
    "label_dict = {\"benign\": 0, \"borderline\": 1, \"malignant\": 2}\n",
    "classes = [0, 1, 2]\n",
    "y_true = np.array(\n",
    "    [\"benign\", \"borderline\", \"malignant\", \"benign\", \"borderline\", \"malignant\"]\n",
    ")\n",
    "y_pred = np.array(\n",
    "    [\"benign\", \"malignant\", \"borderline\", \"benign\", \"benign\", \"borderline\"]\n",
    ")\n",
    "\n",
    "# Turn them into numbers in the label_dict\n",
    "y_true = np.array([label_dict[label] for label in y_true])\n",
    "y_pred = np.array([label_dict[label] for label in y_pred])\n",
    "```\n",
    "We can calculate the metrics (precision etc) for each label indepedently. What we mean here is that we treat an n-class problem as n-binary classification problem, such as the following:\n",
    "\n",
    "!!! example \"Benign as Positive Class\"\n",
    "    If we take benign as positive class, which is represented as 1, and both borderline and malignant as the negative class 0, then logically (even without the fancy term label binarize), we can just simply replace as follows:\n",
    "    ```python\n",
    "    y_true = [0,1,2,0,1,2] -> y_true = [1,0,0,1,0,0]\n",
    "    y_pred = [0,2,1,0,0,1] -> y_pred = [1,0,0,1,1,0]\n",
    "    ```\n",
    "    where we just replace all 0 (initially benign) to 1, and all 1 and 2 (initially borderline and malignant) to 0 (may be confusing at first).\n",
    "\n",
    "!!! example \"Borderline as Positive Class\"\n",
    "    If we take borderline as positive class, which is represented as 1, and both benign and malignant as the negative class 0, then logically (even without the fancy term label binarize), we can just simply replace as follows:\n",
    "    ```python\n",
    "    y_true = [0,1,2,0,1,2] -> y_true = [0,1,0,0,1,0]\n",
    "    y_pred = [0,2,1,0,0,1] -> y_pred = [0,0,1,0,0,1]\n",
    "    ```\n",
    "    where we just replace all 1 (initially borderline) to 1, and all 0 and 2 (initially benign and malignant) to 0.\n",
    "\n",
    "!!! example \"Malignant as Positive Class\"\n",
    "    If we take malignant as positive class, which is represented as 2, and both benign and borderline as the negative class 0, then logically (even without the fancy term label binarize), we can just simply replace as follows:\n",
    "    ```python\n",
    "    y_true = [0,1,2,0,1,2] -> y_true = [0,0,1,0,0,1]\n",
    "    y_pred = [0,2,1,0,0,1] -> y_pred = [0,1,0,0,0,0]\n",
    "    ```\n",
    "    where we just replace all 2 (initially malignant) to 1, and all 0 and 1 (initially benign and borderline) to 0.\n",
    "\n",
    "---\n",
    "\n",
    "In this case, we have 3 different confusion matrices, one for each class (diagram). In the example above, we did not mention a crucial technique, which is called label binarizer[^1]. We will introduce it in code below.\n",
    "\n",
    "[^1]: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eTGo_K9lRBlZ"
   },
   "outputs": [],
   "source": [
    "# Our dataset is as follows\n",
    "label_dict = {\"benign\": 0, \"borderline\": 1, \"malignant\": 2}\n",
    "classes = [0, 1, 2]\n",
    "y_true = np.array(\n",
    "    [\"benign\", \"borderline\", \"malignant\", \"benign\", \"borderline\", \"malignant\"]\n",
    ")\n",
    "y_pred = np.array(\n",
    "    [\"benign\", \"malignant\", \"borderline\", \"benign\", \"benign\", \"borderline\"]\n",
    ")\n",
    "\n",
    "# Turn them into numbers in the label_dict\n",
    "y_true = np.array([label_dict[label] for label in y_true])\n",
    "y_pred = np.array([label_dict[label] for label in y_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xG-1G0hXNHP8"
   },
   "source": [
    "### Label Binarize\n",
    "\n",
    "What we have just done in the previous example is that we binarized both `y_true` and `y_pred`. The process of treating each class $C_i$ as an independent class and then applying the \"replacement\" technique is called label binarizing. \n",
    "\n",
    "<figure>\n",
    "    <img src='https://storage.googleapis.com/reighns/reighns_ml_projects/docs/metrics/classification_metrics/label_binarize.png'/>\n",
    "    <figcaption>Label Binarizing, by Hongnan G.</figcaption>\n",
    "</figure>\n",
    "\n",
    "???+ note \"Steps to label binarize\"\n",
    "    1. For each label (0, 1 and 2 here), we call `np.where` such that whenever the y array has this label, we replace it with 1 (positive class), and 0 otherwise (negative class).\n",
    "    ```python\n",
    "    binarized_cols = []\n",
    "    for label in classes:\n",
    "        binarize_col = np.where(y_true == label, 1, 0)\n",
    "        binarized_cols.append(binarize_col)\n",
    "    ```\n",
    "    2. Conventially, we stack them column wise as follows: \n",
    "    ```python\n",
    "    binarized_cols = np.vstack(binarized_cols)\n",
    "    binarized_cols = binarized_cols.T\n",
    "    ```\n",
    "Let us look at the binarized array for `y_true`, notice that the first column `[1,0,0,1,0,0]` corresponds exactly to the example above when we treat benign as positive class (we can verify the same for the rest).\n",
    "\n",
    "```python\n",
    "array([[1, 0, 0],\n",
    "       [0, 1, 0],\n",
    "       [0, 0, 1],\n",
    "       [1, 0, 0],\n",
    "       [0, 1, 0],\n",
    "       [0, 0, 1]])\n",
    "```\n",
    "We note that it is commom practice to label binarize the y values first before passing in for metric calculation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup:**\n",
    "\n",
    "- `classes`: `[0, 1, 2]`\n",
    "- `y_true`: `([0, 1, 2, 0, 1, 2])`\n",
    "- `label_binarized_y`: \n",
    "    \n",
    "```python\n",
    "([[1, 0, 0],\n",
    "   [0, 1, 0],\n",
    "   [0, 0, 1],\n",
    "   [1, 0, 0],\n",
    "   [0, 1, 0],\n",
    "   [0, 0, 1]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nt3Bx_yZPkLS",
    "outputId": "949da462-9cd5-4ec0-df79-bddef5de2548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0]\n",
      "[0 1 0 0 1 0]\n",
      "[0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "binarized_cols = []\n",
    "# this is a column wise operation but should eventually show \"transposed\"\n",
    "for label in classes:\n",
    "    # in the first loop, label = 0, so replace all instance of 0 in y_true with pos class 1 and others 0 \n",
    "    binarize_col = np.where(y_true == label, 1, 0)\n",
    "    binarized_cols.append(binarize_col)\n",
    "    \n",
    "label_binarized_y = np.vstack(binarized_cols).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second way: \n",
    "\n",
    "- Initialize `label_binarized_y` with shape `(len(y_true), len(classes))`. That is, if `y_true` is of length 6 elements, and we have 3 classes, then it is **necessary** that after binarizing (one-hot), we must have $(6, 3)$ shape.\n",
    "- loop through `y_true` with `enumerate`:\n",
    "    - if we encounter `y_true = 0`, then we should have `[1, 0, 0]`, since we initialized our `label_binarized_y` as all zeros, then `label_binarized_y[y_index]` is just `[0, 0, 0]`, we want to assign the 0-th index (coincides with the class index by the way) as 1, so we do `label_binarized_y[y_index][int(each_y_true_element)] = 1`.\n",
    "    - if we encounter `y_true = 1`, then we should have `[0, 1, 0]`, since we initialized our `label_binarized_y` as all zeros, then `label_binarized_y[y_index]` is just `[0, 0, 0]`, we want to assign the 1-st index (coincides with the class index by the way) as 1, so we do `label_binarized_y[y_index][int(each_y_true_element)] = 1`.\n",
    "    - if we encounter `y_true = 2`, then we should have `[0, 0, 1]`, since we initialized our `label_binarized_y` as all zeros, then `label_binarized_y[y_index]` is just `[0, 0, 0]`, we want to assign the 2-nd index (coincides with the class index by the way) as 1, so we do `label_binarized_y[y_index][int(each_y_true_element)] = 1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarized_y = np.zeros(shape=(len(y_true), len(classes)))\n",
    "# this is a column wise operation but should eventually show \"transposed\"\n",
    "for y_index, each_y_true_element in enumerate(y_true):\n",
    "     label_binarized_y[y_index][int(each_y_true_element)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJyntNfeJrwP"
   },
   "source": [
    "### Macro-Averaging\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWWGqMzDwNU_"
   },
   "source": [
    "Back to where we ended off, we have 3 confusion matrices, we filled up each cell manually by inspection over which is considered TP, FP, FN or TN. Well, the good news is, with label binarizing done, we can just use our good ol' `confusion_matrix_` function done earlier to calculate them for us!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode the second method, the bad thing about this method is it has less flexibility than the first, if we wish to define \"custom\" positive label then we need to make more changes. For example, if positive label is defined to be 3, then this function can no longer take advantage that the class labels will always be in the form of `[0, 1, 2, ...]` where we easily index them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multiclass_label_binarize(\n",
    "#     y: np.ndarray, class_labels: List[int], pos_label=1, neg_label=0\n",
    "# ):\n",
    "#     \"\"\"Binarize labels in one-vs-all fashion.\n",
    "\n",
    "#     Args:\n",
    "#         y (np.ndarray) Sequence of integer labels to encode\n",
    "#         class_labels (array-like) Labels for each class\n",
    "#         pos_label (int) Value for positive labels\n",
    "#         neg_label (int) Value for negative labels\n",
    "#     Returns:\n",
    "#         np.ndarray of shape (n_samples, n_classes) Encoded dataset\n",
    "#     \"\"\"\n",
    "#     if isinstance(y, list):\n",
    "#         y = np.asarray(y)\n",
    "\n",
    "#     columns = [\n",
    "#         np.where(y == label, pos_label, neg_label) for label in class_labels\n",
    "#     ]\n",
    "#     label_binarized_y = np.vstack(columns).T\n",
    "#     return label_binarized_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6enGiQ2aW2hd"
   },
   "outputs": [],
   "source": [
    "def multiclass_label_binarize(y: np.ndarray, class_labels: List[int]):\n",
    "    \"\"\"Binarize labels in one-vs-all fashion.\n",
    "\n",
    "    Args:\n",
    "        y (np.ndarray) Sequence of integer labels to encode\n",
    "        class_labels (array-like) Labels for each class, must start from 0 and be in order.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray of shape (n_samples, n_classes) Encoded dataset\n",
    "\n",
    "    Example:\n",
    "        >>> y_true = np.array([0, 1, 2, 0, 1, 2])\n",
    "        >>> class_labels = [0, 1, 2]\n",
    "        >>> y_true_binarized = multiclass_label_binarize(y_true, class_labels)\n",
    "        >>> from sklearn.preprocessing import label_binarize\n",
    "        >>> assert label_binarize(y_true, classes = classes) == y_true_binarized\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(y, list):\n",
    "        y = np.asarray(y)\n",
    "\n",
    "    label_binarized_y = np.zeros(shape=(len(y), len(class_labels)))\n",
    "    # this is a column wise operation but should eventually show \"transposed\"\n",
    "    for y_index, each_y_element in enumerate(y):\n",
    "        label_binarized_y[y_index][int(each_y_element)] = 1\n",
    "\n",
    "    return label_binarized_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "PYoey-deW2kX"
   },
   "outputs": [],
   "source": [
    "# Binarize the labels\n",
    "y_true_binarized = multiclass_label_binarize(y_true, classes)\n",
    "y_pred_binarized = multiclass_label_binarize(y_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "label_binarize(y_true, classes = classes) == y_true_binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "d-afyFsiswdz"
   },
   "outputs": [],
   "source": [
    "tp_c1, fp_c1, fn_c1, tn_c1 = \\\n",
    "    confusion_matrix_(\n",
    "    y_true_binarized[:, 0], y_pred_binarized[:, 0]\n",
    "    ).ravel()\n",
    "\n",
    "tp_c2, fp_c2, fn_c2, tn_c2 = \\\n",
    "    confusion_matrix_(\n",
    "    y_true_binarized[:, 1], y_pred_binarized[:, 1]\n",
    "    ).ravel()\n",
    "\n",
    "tp_c3, fp_c3, fn_c3, tn_c3 = \\\n",
    "    confusion_matrix_(\n",
    "    y_true_binarized[:, 2], y_pred_binarized[:, 2]\n",
    "    ).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "id": "PAy-RiidTEWv",
    "outputId": "48c446c8-94c3-4b12-ed0e-6afeee936b75"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(\n",
    "    y_true_binarized[:, 0],\n",
    "    y_pred_binarized[:, 0],\n",
    "    title=\"Confusion Matrix (Benign as +)\",\n",
    "    labels=[0, 1],\n",
    "    tick_labels=[\"not benign\", \"benign\"],\n",
    ")\n",
    "plot_confusion_matrix(\n",
    "    y_true_binarized[:, 1],\n",
    "    y_pred_binarized[:, 1],\n",
    "    title=\"Confusion Matrix (Borderline as +)\",\n",
    "    labels=[0, 1],\n",
    "    tick_labels=[\"not borderline\", \"borderline\"],\n",
    ")\n",
    "plot_confusion_matrix(\n",
    "    y_true_binarized[:, 2],\n",
    "    y_pred_binarized[:, 2],\n",
    "    title=\"Confusion Matrix (Malignant as +)\",\n",
    "    labels=[0, 1],\n",
    "    tick_labels=[\"not malignant\", \"malignant\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMmUnzHET3e8"
   },
   "source": [
    "Then Macro-Average is calculated for each confusion matrix, and then averaged over the total number of classes.\n",
    "\n",
    "$$\\text{Macro-Average Precision} = \\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}P_{i}$$\n",
    "\n",
    "where $P_i$ is the precision score for each individual confusion matrix for each class. This can be extended for recall and f1 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hANwfTCS48nL",
    "outputId": "61a0a627-caeb-429b-8b93-5c722e44f553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666 0.0 0.0\n",
      "Macro-Averaged Precision: 0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "# Macro-Average\n",
    "precision_c1 = tp_c1 / (\n",
    "    tp_c1 + fp_c1\n",
    ")  # precision for confusion matrix 1 where benign is +\n",
    "precision_c2 = tp_c2 / (tp_c2 + fp_c2)\n",
    "precision_c3 = tp_c3 / (tp_c3 + fp_c3)\n",
    "\n",
    "print(precision_c1, precision_c2, precision_c3)\n",
    "print(\n",
    "    f\"Macro-Averaged Precision: {np.sum([precision_c1, precision_c2, precision_c3]) / len(classes)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEmo1kL2UDcB"
   },
   "source": [
    "### Micro-Averaging\n",
    "\n",
    "Similar to Micro-Averaging, we still have 3 confusion matrices, but we first aggregate all the 3 confusion matrices into one single confusion matrices.\n",
    "\n",
    "$$TP_{\\text{agg}}=\\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}TP_{i}$$\n",
    "\n",
    "$$FP_{\\text{agg}}=\\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}FP_{i}$$\n",
    "\n",
    "$$FN_{\\text{agg}}=\\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}FN_{i}$$\n",
    "\n",
    "$$TN_{\\text{agg}}=\\frac{1}{\\text{num_class}}\\sum_{i=1}^{\\text{num_class}}TN_{i}$$\n",
    "\n",
    "And then once we get the aggregated metrics, we can apply the normal calculation to it.\n",
    "\n",
    "$$\\text{Precision} = \\frac{TP_{\\text{agg}}}{TP_{\\text{agg}} + FP_{\\text{agg}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TtsMS2mMsxM9"
   },
   "outputs": [],
   "source": [
    "tp_c1, fp_c1, fn_c1, tn_c1 = \\\n",
    "    confusion_matrix_(\n",
    "    y_true_binarized[:, 0], y_pred_binarized[:, 0]\n",
    "    ).ravel()\n",
    "\n",
    "tp_c2, fp_c2, fn_c2, tn_c2 = \\\n",
    "    confusion_matrix_(\n",
    "    y_true_binarized[:, 1], y_pred_binarized[:, 1]\n",
    "    ).ravel()\n",
    "\n",
    "tp_c3, fp_c3, fn_c3, tn_c3 = \\\n",
    "    confusion_matrix_(\n",
    "    y_true_binarized[:, 2], y_pred_binarized[:, 2]\n",
    "    ).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "os0LZNZ_YXfV",
    "outputId": "d55a9206-0681-4314-f518-1c13d77b4856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-Averaged Precision: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Aggregation\n",
    "tp_agg = (tp_c1 + tp_c2 + tp_c3) / 3\n",
    "fp_agg = (fp_c1 + fp_c2 + fp_c3) / 3\n",
    "fn_agg = (fn_c1 + fn_c2 + fn_c3) / 3\n",
    "tn_agg = (tn_c1 + tn_c2 + tn_c3) / 3\n",
    "\n",
    "# Calculate precision using Micro-Averaging\n",
    "print(f\"Micro-Averaged Precision: {tp_agg / (tp_agg + fp_agg)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zd1MK0UlqCfc"
   },
   "source": [
    "### Micro vs Macro\n",
    "\n",
    "The following content is taken from DataScienceExchange[^1].\n",
    "\n",
    "Micro- and macro-averages (for whatever metric) will compute slightly different things, and thus their interpretation differs. A macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average will aggregate the contributions of all classes to compute the average metric. In a multi-class classification setup, micro-average is preferable if you suspect there might be class imbalance (i.e you may have many more examples of one class than of other classes). \n",
    "\n",
    "To illustrate why, take for example precision $Pr=\\frac{TP}{(TP+FP)}$. Let's imagine you have a *One-vs-All* (there is only one correct class output per example) multi-class classification system with four classes and the following numbers when tested:\n",
    "\n",
    "* Class A: 1 TP and 1 FP\n",
    "* Class B: 10 TP and 90 FP\n",
    "* Class C: 1 TP and 1 FP\n",
    "* Class D: 1 TP and 1 FP\n",
    "\n",
    "You can see easily that $Pr_A = Pr_C = Pr_D = 0.5$, whereas $Pr_B=0.1$.\n",
    "\n",
    "* A macro-average will then compute: $Pr=\\frac{0.5+0.1+0.5+0.5}{4}=0.4$\n",
    "* A micro-average will compute: $Pr=\\frac{1+10+1+1}{2+100+2+2}=0.123$\n",
    "\n",
    "These are quite different values for precision. Intuitively, in the macro-average the \"good\" precision (0.5) of classes A, C and D is contributing to maintain a \"decent\" overall precision (0.4). While this is technically true (across classes, the average precision is 0.4), it is a bit misleading, since a large number of examples are not properly classified. These examples predominantly correspond to class B, so they only contribute 1/4 towards the average in spite of constituting 94.3% of your test data. The micro-average will adequately capture this class imbalance, and bring the overall precision average down to 0.123 (more in line with the precision of the dominating class B (0.1)).\n",
    "\n",
    "For computational reasons, it may sometimes be more convenient to compute class averages and then macro-average them. If class imbalance is known to be an issue, there are several ways around it. One is to report not only the macro-average, but also its standard deviation (for 3 or more classes). Another is to compute a weighted macro-average, in which each class contribution to the average is weighted by the relative number of examples available for it. In the above scenario, we obtain:\n",
    "\n",
    "$Pr_{macro-mean}={0.250.5+0.250.1+0.250.5+0.250.5}=0.4$\n",
    "$Pr_{macro-stdev}=0.173$\n",
    "\n",
    "$Pr_{macro-weighted}={0.01890.5+0.9430.1+0.01890.5+0.01890.5}={0.009+0.094+0.009+0.009}=0.123$\n",
    "\n",
    "The large standard deviation (0.173) already tells us that the 0.4 average does not stem from a uniform precision among classes, but it might be just easier to compute the weighted macro-average, which in essence is another way of computing the micro-average.\n",
    "\n",
    "[1^]: https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBP0SawhZNHe"
   },
   "source": [
    "### Building our own Classification Report\n",
    "\n",
    "Just like scikit-learn's [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report), we can build our own and test if it correct.\n",
    "\n",
    "The code is made easy to follow such that you can detail each step in details if you do not understand how micro or macro is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "a2hesXlranYe"
   },
   "outputs": [],
   "source": [
    "def classification_report_(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    class_labels: List[int],\n",
    "    display_labels: Union[Optional[List[str]], Optional[List[int]]] = None,\n",
    ") -> Union[List[float], Dict[str, float]]:\n",
    "    \"\"\"Classification report that reports precision, recall and f1-score.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): Ground truth (correct) target values.\n",
    "        y_pred (np.ndarray): Predicted target values.\n",
    "        class_labels (List[int]): List of class labels.\n",
    "        display_labels: List of display labels.\n",
    "                        (if None, class_labels is used).\n",
    "\n",
    "    Returns:\n",
    "        confusion_matrices (List[np.ndarray]): List of confusion matrices.\n",
    "        tp_fp_fn_tn (Dict[str, float]): List of true positive, false positive,\n",
    "                                        true negative and false negative\n",
    "                                        values.\n",
    "        metrics Dict[str, float]: List of precision, recall and f1-score\n",
    "                                    values.\n",
    "    \"\"\"\n",
    "    if display_labels is None:\n",
    "        # assign display labels to default labels if none is passed in.\n",
    "        display_labels = class_labels  \n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    y_true_binarized = multiclass_label_binarize(\n",
    "        y_true, class_labels, pos_label=1, neg_label=0\n",
    "    )\n",
    "    y_pred_binarized = multiclass_label_binarize(\n",
    "        y_pred, class_labels, pos_label=1, neg_label=0\n",
    "    )\n",
    "\n",
    "    confusion_matrices: Dict[str, List[int]] = {}\n",
    "    tp_fp_fn_tn: Dict[str, List[float]] = {}\n",
    "    metrics: Dict[str, List[float]] = {}\n",
    "\n",
    "    for index, label in enumerate(class_labels):\n",
    "        assert (\n",
    "            index == label\n",
    "        ), \"Index should coincide with label,\\\n",
    "            if not, please check how your classes are labelled.\"\n",
    "        cm = confusion_matrix_(\n",
    "            y_true_binarized[:, index], y_pred_binarized[:, index]\n",
    "        )\n",
    "        confusion_matrices[display_labels[index]] = cm\n",
    "        tp, fp, fn, tn = cm.ravel()\n",
    "\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (\n",
    "            2 * (precision * recall) / (precision + recall)\n",
    "            if (precision + recall) != 0\n",
    "            else 0\n",
    "        )\n",
    "        tp_fp_fn_tn[display_labels[index]] = {\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "\n",
    "    def calculate_micro_avg(confusion_matrices) -> Dict[str, float]:\n",
    "        \"\"\"Calculate micro average for precision, recall and f1-score.\n",
    "\n",
    "        Args:\n",
    "            confusion_matrices ([type]): Pass in from local scope.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, float]: Dictionary of micro average values.\n",
    "        \"\"\"\n",
    "        tp_agg, fp_agg, fn_agg, tn_agg = 0, 0, 0, 0\n",
    "        micro_metrics: Dict[str, List[float]] = {}\n",
    "        total_count = 0\n",
    "        for cm in confusion_matrices.values():\n",
    "            tp, fp, fn, tn = cm.ravel()\n",
    "            tp_agg += tp\n",
    "            fp_agg += fp\n",
    "            fn_agg += fn\n",
    "            tn_agg += tn\n",
    "            total_count += 1\n",
    "\n",
    "        assert total_count == len(\n",
    "            class_labels\n",
    "        ), \"Denominator total_count should equal number of class labels.\"\n",
    "\n",
    "        tp_agg, fp_agg, fn_agg, tn_agg = (\n",
    "            np.asarray([tp_agg, fp_agg, fn_agg, tn_agg]) / total_count\n",
    "        )  # aggregation is performed here using numpy broadcasting\n",
    "\n",
    "        micro_precision = tp_agg / (tp_agg + fp_agg)\n",
    "        micro_recall = tp_agg / (tp_agg + fn_agg)\n",
    "        micro_f1 = (\n",
    "            2\n",
    "            * (micro_precision * micro_recall)\n",
    "            / (micro_precision + micro_recall)\n",
    "            if (micro_precision + micro_recall) != 0\n",
    "            else 0\n",
    "        )\n",
    "        return {\n",
    "            \"micro_precision\": micro_precision,\n",
    "            \"micro_recall\": micro_recall,\n",
    "            \"micro_f1\": micro_f1,\n",
    "        }\n",
    "\n",
    "    metrics[\"micro_scores\"] = calculate_micro_avg(confusion_matrices)\n",
    "\n",
    "    def calculate_macro_avg(confusion_matrices) -> Dict[str, float]:\n",
    "        \"\"\"Calculate macro average for precision, recall and f1-score.\n",
    "\n",
    "        Args:\n",
    "            confusion_matrices ([type]): Pass in from local scope.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, float]: Dictionary of macro average values.\n",
    "        \"\"\"\n",
    "        macro_precision, macro_recall, macro_f1 = 0, 0, 0\n",
    "        for cm in confusion_matrices.values():\n",
    "            tp, fp, fn, tn = cm.ravel()\n",
    "            precision = tp / (tp + fp)\n",
    "            recall = tp / (tp + fn)\n",
    "            f1 = (\n",
    "                2 * (precision * recall) / (precision + recall)\n",
    "                if (precision + recall) != 0\n",
    "                else 0\n",
    "            )\n",
    "            macro_precision += precision\n",
    "            macro_recall += recall\n",
    "            macro_f1 += f1\n",
    "\n",
    "        macro_precision = macro_precision / len(class_labels)\n",
    "        macro_recall = macro_recall / len(class_labels)\n",
    "        macro_f1 = macro_f1 / len(class_labels)\n",
    "        return {\n",
    "            \"macro_precision\": macro_precision,\n",
    "            \"macro_recall\": macro_recall,\n",
    "            \"macro_f1\": macro_f1,\n",
    "        }\n",
    "\n",
    "    metrics[\"macro_scores\"] = calculate_macro_avg(confusion_matrices)\n",
    "\n",
    "    return confusion_matrices, tp_fp_fn_tn, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFDVivipolhB",
    "outputId": "f0883cd8-a66a-4637-deb0-a943d21c33de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our own classification report: {'micro_scores': {'micro_precision': 0.3333333333333333, 'micro_recall': 0.3333333333333333, 'micro_f1': 0.3333333333333333}, 'macro_scores': {'macro_precision': 0.2222222222222222, 'macro_recall': 0.3333333333333333, 'macro_f1': 0.26666666666666666}}\n",
      "scikit-learn's classification report: {'benign': {'precision': 0.6666666666666666, 'recall': 1.0, 'f1-score': 0.8, 'support': 2}, 'borderline': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'malignant': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'accuracy': 0.3333333333333333, 'macro avg': {'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1-score': 0.26666666666666666, 'support': 6}, 'weighted avg': {'precision': 0.2222222222222222, 'recall': 0.3333333333333333, 'f1-score': 0.26666666666666666, 'support': 6}}\n"
     ]
    }
   ],
   "source": [
    "confusion_matrices, tp_fp_fn_tn, metrics_report = classification_report_(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    class_labels=classes,\n",
    "    display_labels=[\"benign\", \"borderline\", \"malignant\"],\n",
    ")\n",
    "\n",
    "sklearn_classification_report = metrics.classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    output_dict=True,\n",
    "    labels=classes,\n",
    "    target_names=[\"benign\", \"borderline\", \"malignant\"],\n",
    ")\n",
    "print(f\"Our own classification report: {metrics_report}\")\n",
    "print(f\"scikit-learn's classification report: {sklearn_classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBbW9yZGpX6c"
   },
   "source": [
    "We have successfully coded out classification report to behave the same way as scikit-learn's one."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "precision_recall_f1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
