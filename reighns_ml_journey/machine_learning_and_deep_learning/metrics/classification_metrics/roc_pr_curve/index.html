
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://reighns92.github.io/reighns-ml-blog/reighns_ml_journey/machine_learning_and_deep_learning/metrics/classification_metrics/roc_pr_curve/">
      
      <link rel="icon" href="../../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.13">
    
    
      
        <title>ROC and PR Curves - Hongnan G. Machine Learning Blog</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.e411adfe.min.css">
      
        
        <link rel="stylesheet" href="../../../../../assets/stylesheets/palette.cc9b2e1e.min.css">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../../css/extra.css">
    
    <script>__md_scope=new URL("../../../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#receiver-operating-characteristic-roc" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../.." title="Hongnan G. Machine Learning Blog" class="md-header__button md-logo" aria-label="Hongnan G. Machine Learning Blog" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Hongnan G. Machine Learning Blog
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              ROC and PR Curves
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="Hongnan G. Machine Learning Blog" class="md-nav__button md-logo" aria-label="Hongnan G. Machine Learning Blog" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Hongnan G. Machine Learning Blog
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../../about/" class="md-nav__link">
        About
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../../articles.md" class="md-nav__link">
        How to write articles
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Software Engineering Practices
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Software Engineering Practices" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Software Engineering Practices
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../software_engineering/workflow/" class="md-nav__link">
        Workflow
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../software_engineering/git/" class="md-nav__link">
        Git
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../software_engineering/code_design/" class="md-nav__link">
        Code Design
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../software_engineering/gcp/" class="md-nav__link">
        GCP
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../software_engineering/github_actions_test_packages_compatibility/" class="md-nav__link">
        Test Packages Compatibility
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/gradient_descent/" class="md-nav__link">
        Gradient Descent
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6">
          Mathematics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Mathematics" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Mathematics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/general_mathematical_terms_and_definitions/" class="md-nav__link">
        General Mathematic Terms and Definitions
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_2" type="checkbox" id="__nav_6_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_2">
          Linear Algebra
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Linear Algebra" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_2">
          <span class="md-nav__icon md-icon"></span>
          Linear Algebra
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_2_1" type="checkbox" id="__nav_6_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_2_1">
          Preliminaries
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Preliminaries" data-md-level="3">
        <label class="md-nav__title" for="__nav_6_2_1">
          <span class="md-nav__icon md-icon"></span>
          Preliminaries
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/01_preliminaries/lines_and_planes/" class="md-nav__link">
        Lines and Planes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/01_preliminaries/fields/" class="md-nav__link">
        Fields
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_2_2" type="checkbox" id="__nav_6_2_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_2_2">
          Vectors
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Vectors" data-md-level="3">
        <label class="md-nav__title" for="__nav_6_2_2">
          <span class="md-nav__icon md-icon"></span>
          Vectors
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors/" class="md-nav__link">
        Vector Operations
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_2_2_2" type="checkbox" id="__nav_6_2_2_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_2_2_2">
          Vector Products
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Vector Products" data-md-level="4">
        <label class="md-nav__title" for="__nav_6_2_2_2">
          <span class="md-nav__icon md-icon"></span>
          Vector Products
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_linear_combination/" class="md-nav__link">
        Linear Combination
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_dot_product/" class="md-nav__link">
        Dot Product
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_outer_product/" class="md-nav__link">
        Outer Product
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_unit_vector/" class="md-nav__link">
        Unit Vector
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_exercises/" class="md-nav__link">
        Exercises
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_2_3" type="checkbox" id="__nav_6_2_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_2_3">
          Vector Spaces
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Vector Spaces" data-md-level="3">
        <label class="md-nav__title" for="__nav_6_2_3">
          <span class="md-nav__icon md-icon"></span>
          Vector Spaces
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/" class="md-nav__link">
        Vector Space and Subspaces
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/" class="md-nav__link">
        Vector Span
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/" class="md-nav__link">
        Linear Independence
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/" class="md-nav__link">
        Basis and Dimension
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_2_4" type="checkbox" id="__nav_6_2_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_2_4">
          Matrix
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Matrix" data-md-level="3">
        <label class="md-nav__title" for="__nav_6_2_4">
          <span class="md-nav__icon md-icon"></span>
          Matrix
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix/" class="md-nav__link">
        Matrix
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/" class="md-nav__link">
        Basic Matrix Types
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/" class="md-nav__link">
        Basic Matrix Operations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/" class="md-nav__link">
        Matrix Multiplication
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_2_5" type="checkbox" id="__nav_6_2_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_2_5">
          Matrix Theory
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Matrix Theory" data-md-level="3">
        <label class="md-nav__title" for="__nav_6_2_5">
          <span class="md-nav__icon md-icon"></span>
          Matrix Theory
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations/" class="md-nav__link">
        System of Linear Equations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.02_linear_algebra_row_reduction_preserves_rank/" class="md-nav__link">
        Row Reduction Preserves Rank
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/" class="md-nav__link">
        Row Space
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/" class="md-nav__link">
        Column Space
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.05_linear_algebra_matrix_theory_matrix_spaces_right_nullspace/" class="md-nav__link">
        Right Nullspace (Kernel)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.06_linear_algebra_matrix_theory_matrix_spaces_left_nullspace/" class="md-nav__link">
        Left Nullspace
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/" class="md-nav__link">
        Matrix Rank
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.08_linear_algebra_matrix_theory_matrix_spaces_summary/" class="md-nav__link">
        The Four Fundamental Subspaces (Summary)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_2_6" type="checkbox" id="__nav_6_2_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_2_6">
          Linear Transformation
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Linear Transformation" data-md-level="3">
        <label class="md-nav__title" for="__nav_6_2_6">
          <span class="md-nav__icon md-icon"></span>
          Linear Transformation
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/" class="md-nav__link">
        Linear Transformation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/06_linear_transformation/06.02_linear_algebra_linear_transformations_nullspace/" class="md-nav__link">
        Nullspace
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/06_linear_transformation/06.03_linear_algebra_linear_transformations_ranges/" class="md-nav__link">
        Range
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/06_linear_transformation/06.04_linear_algebra_linear_transformations_homomorphism/" class="md-nav__link">
        Homomorphism
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/06_linear_transformation/06.05_linear_algebra_linear_transformations_fundamental_theorem/" class="md-nav__link">
        Fundamental Theorem
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/06_linear_transformation/06.06_linear_algebra_linear_transformations_matrix/" class="md-nav__link">
        Linear Transformation and Matrix
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_2_7" type="checkbox" id="__nav_6_2_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_2_7">
          Analytic Geometry
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Analytic Geometry" data-md-level="3">
        <label class="md-nav__title" for="__nav_6_2_7">
          <span class="md-nav__icon md-icon"></span>
          Analytic Geometry
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/08_analytic_geometry/08.01_motivation/" class="md-nav__link">
        Motivation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/08_analytic_geometry/08.02_norms/" class="md-nav__link">
        Norms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/08_analytic_geometry/08.03_inner_products/" class="md-nav__link">
        Inner Product Spaces
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/08_analytic_geometry/08.04_lengths_and_distances/" class="md-nav__link">
        Lengths and Distances
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/08_analytic_geometry/08.05_angles_and_orthogonality/" class="md-nav__link">
        Angles and Orthogoanlity
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/" class="md-nav__link">
        Orthogonal Subspace
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/08_analytic_geometry/08.07_orthogonal_projections/" class="md-nav__link">
        Orthogonal Projection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/08_analytic_geometry/08.08_orthogonal_matrices_and_basis/" class="md-nav__link">
        Orthogonal Matrices and Basis
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/08_analytic_geometry/08.09_gram_schmidt_orthogonalization/" class="md-nav__link">
        Gram-Schmidt Orthogonalization
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/linear_algebra/linear_algebra_interview_questions/" class="md-nav__link">
        Interview
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_3" type="checkbox" id="__nav_6_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_3">
          Probability and Statistics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Probability and Statistics" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_3">
          <span class="md-nav__icon md-icon"></span>
          Probability and Statistics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/probability_statistics_theory/probability4datascience/" class="md-nav__link">
        Introduction to Probability for Data Science (Stanley H. Chan)
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_3_2" type="checkbox" id="__nav_6_3_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_3_2">
          Introduction to Probability
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Introduction to Probability" data-md-level="3">
        <label class="md-nav__title" for="__nav_6_3_2">
          <span class="md-nav__icon md-icon"></span>
          Introduction to Probability
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/probability_statistics_theory/02_introduction_to_probability/02.01_probability_space/" class="md-nav__link">
        Probability Space
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/probability_statistics_theory/02_introduction_to_probability/02.02_probability_axioms/" class="md-nav__link">
        Probability Axioms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/probability_statistics_theory/02_introduction_to_probability/02.03_conditional_probability/" class="md-nav__link">
        Conditional Probability
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/probability_statistics_theory/02_introduction_to_probability/02.04_independence/" class="md-nav__link">
        Independence
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/probability_statistics_theory/02_introduction_to_probability/02.05_bayes_theorem/" class="md-nav__link">
        Bayes Theorem
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mathematics/probability_statistics_theory/02_introduction_to_probability/02.06_summary/" class="md-nav__link">
        Summary
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" type="checkbox" id="__nav_7" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_7">
          Machine Learning and Deep Learning
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Machine Learning and Deep Learning" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          Machine Learning and Deep Learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_1" type="checkbox" id="__nav_7_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_7_1">
          Metrics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Metrics" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_1">
          <span class="md-nav__icon md-icon"></span>
          Metrics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_1_1" type="checkbox" id="__nav_7_1_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_7_1_1">
          Classification
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Classification" data-md-level="3">
        <label class="md-nav__title" for="__nav_7_1_1">
          <span class="md-nav__icon md-icon"></span>
          Classification
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../classification_metrics/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../accuracy/" class="md-nav__link">
        Accuracy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../confusion_matrix/" class="md-nav__link">
        Confusion Matrix
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../precision_recall_f1/" class="md-nav__link">
        Precision-Recall-F1
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          ROC and PR Curves
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        ROC and PR Curves
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#receiver-operating-characteristic-roc" class="md-nav__link">
    Receiver operating characteristic (ROC)
  </a>
  
    <nav class="md-nav" aria-label="Receiver operating characteristic (ROC)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#intuition" class="md-nav__link">
    Intuition
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#definition-of-roc-curve" class="md-nav__link">
    Definition of ROC Curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#definition-of-area-under-roc-curve" class="md-nav__link">
    Definition of Area under ROC Curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auroc-as-a-ranking" class="md-nav__link">
    AUROC as a Ranking
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc-as-c-statistic" class="md-nav__link">
    ROC as C-Statistic
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pros-and-cons-of-auroc" class="md-nav__link">
    Pros and Cons of AUROC
  </a>
  
    <nav class="md-nav" aria-label="Pros and Cons of AUROC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pros-when-your-classes-are-more-balanced" class="md-nav__link">
    Pros: When your classes are more balanced
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pros-scale-invariant" class="md-nav__link">
    Pros: Scale Invariant
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pros-classification-threshold-invariant" class="md-nav__link">
    Pros: Classification Threshold Invariant
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cons-imbalanced" class="md-nav__link">
    Cons: Imbalanced
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cons-uncalibrated" class="md-nav__link">
    Cons: Uncalibrated
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-of-roc-and-auc" class="md-nav__link">
    Implementation of ROC and AUC
  </a>
  
    <nav class="md-nav" aria-label="Implementation of ROC and AUC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-1-problem-setup" class="md-nav__link">
    Step 1: Problem Setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-define-threshold-range" class="md-nav__link">
    Step 2: Define Threshold Range
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-classify-prediction-according-to-threshold" class="md-nav__link">
    Step 3: Classify prediction according to threshold
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-calculate-tpr-and-fpr" class="md-nav__link">
    Step 4: Calculate TPR and FPR
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-5-plot-the-points-as-roc-curve" class="md-nav__link">
    Step 5: Plot the points as ROC Curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-6-area-under-roc-curve" class="md-nav__link">
    Step 6: Area under ROC Curve
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#couple-roc-with-brier-score" class="md-nav__link">
    Couple ROC with Brier Score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sklearn-definition-of-binary-classification-roc-auc" class="md-nav__link">
    SKLEARN Definition of Binary Classification ROC-AUC
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#first-interpretation" class="md-nav__link">
    First Interpretation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#precision-recall-curve" class="md-nav__link">
    Precision-Recall Curve
  </a>
  
    <nav class="md-nav" aria-label="Precision-Recall Curve">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#loss-function-and-decision-function" class="md-nav__link">
    Loss function and Decision Function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#an-extensive-study-on-precision-recall-curve" class="md-nav__link">
    An extensive study on Precision-Recall Curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use-precision-recall" class="md-nav__link">
    When to use Precision-Recall
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-not-to-use-precision-recall" class="md-nav__link">
    When NOT to use Precision-Recall
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-of-pr-curve" class="md-nav__link">
    Implementation of PR-Curve
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-debate-auroc-vs-auprc" class="md-nav__link">
    The Debate: AUROC vs AUPRC
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#metrics-for-multi-class-label-classification" class="md-nav__link">
    Metrics for Multi-Class-Label Classification
  </a>
  
    <nav class="md-nav" aria-label="Metrics for Multi-Class-Label Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multi-class-roc" class="md-nav__link">
    Multi-Class ROC
  </a>
  
    <nav class="md-nav" aria-label="Multi-Class ROC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#intuition_1" class="md-nav__link">
    Intuition
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-of-ovr-multi-class-roc" class="md-nav__link">
    Implementation of OVR Multi-Class ROC
  </a>
  
    <nav class="md-nav" aria-label="Implementation of OVR Multi-Class ROC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-1-problem-setup_1" class="md-nav__link">
    Step 1: Problem Setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-binarize" class="md-nav__link">
    Step 2: Binarize
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-roc-score-for-each-class" class="md-nav__link">
    Step 3: ROC score for each class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-one-vs-rest" class="md-nav__link">
    Step 4: One Vs Rest
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-5-modularize" class="md-nav__link">
    Step 5: Modularize
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-label-roc" class="md-nav__link">
    Multi-Label ROC
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#quadratic-weighted-kappa" class="md-nav__link">
    Quadratic Weighted Kappa
  </a>
  
    <nav class="md-nav" aria-label="Quadratic Weighted Kappa">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#intuition-of-qwk" class="md-nav__link">
    Intuition of QWK  
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1-create-the-nxn-histogram-matrix-o" class="md-nav__link">
    Step 1: Create the NxN histogram matrix O 
  </a>
  
    <nav class="md-nav" aria-label="Step 1: Create the NxN histogram matrix O ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-using-our-competitions-dataset" class="md-nav__link">
    Example using our competition's dataset
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-create-the-weighted-matrix-w" class="md-nav__link">
    Step 2: Create the Weighted Matrix w 
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-create-the-expected-matrix" class="md-nav__link">
    Step 3: Create the Expected Matrix 
  </a>
  
    <nav class="md-nav" aria-label="Step 3: Create the Expected Matrix ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#writing-out-the-expected-matrix-in-python" class="md-nav__link">
    Writing out the expected matrix in python
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-final-step-weighted-kappa-formula-and-its-python-codes" class="md-nav__link">
    Step 4: Final Step: Weighted Kappa formula and Its python codes 
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    References
  </a>
  
    <nav class="md-nav" aria-label="References">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#accuracy" class="md-nav__link">
    Accuracy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#receiver-operating-characteristic-roc_1" class="md-nav__link">
    Receiver Operating Characteristic (ROC)
  </a>
  
    <nav class="md-nav" aria-label="Receiver Operating Characteristic (ROC)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#interpretation-of-roc" class="md-nav__link">
    Interpretation of ROC
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pros-and-cons-of-auroc_1" class="md-nav__link">
    Pros and Cons of AUROC
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation" class="md-nav__link">
    Implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#precision-recall-curve_1" class="md-nav__link">
    Precision-Recall Curve
  </a>
  
    <nav class="md-nav" aria-label="Precision-Recall Curve">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#interpretation-of-pr" class="md-nav__link">
    Interpretation of PR
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../cohens_kappa/" class="md-nav__link">
        Cohen's Kappa
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_1_2" type="checkbox" id="__nav_7_1_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_1_2">
          Regression
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Regression" data-md-level="3">
        <label class="md-nav__title" for="__nav_7_1_2">
          <span class="md-nav__icon md-icon"></span>
          Regression
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../regression_metrics/regression_metrics/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../regression_metrics/mae_rmse/" class="md-nav__link">
        MAE and MSE
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../regression_metrics/mape/" class="md-nav__link">
        MAPE
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_2" type="checkbox" id="__nav_7_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_2">
          Computer Vision
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Computer Vision" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_2">
          <span class="md-nav__icon md-icon"></span>
          Computer Vision
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../computer_vision/" class="md-nav__link">
        README
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_2_2" type="checkbox" id="__nav_7_2_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_2_2">
          Neural Network Interpretation
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Neural Network Interpretation" data-md-level="3">
        <label class="md-nav__title" for="__nav_7_2_2">
          <span class="md-nav__icon md-icon"></span>
          Neural Network Interpretation
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_2_2_1" type="checkbox" id="__nav_7_2_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_2_2_1">
          Visualization of Feature Map Activations
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Visualization of Feature Map Activations" data-md-level="4">
        <label class="md-nav__title" for="__nav_7_2_2_1">
          <span class="md-nav__icon md-icon"></span>
          Visualization of Feature Map Activations
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/" class="md-nav__link">
        Feature Map Activations (Part I)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/" class="md-nav__link">
        Feature Map Activations (Part II)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../computer_vision/neural_network_interpretation/conv_filters/Visualizing Convolutional Filters.md" class="md-nav__link">
        Visualization of Convolutional Filters
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../computer_vision/neural_network_interpretation/salient_map/Salient Map.md" class="md-nav__link">
        Salient Map
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_2_2_4" type="checkbox" id="__nav_7_2_2_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_2_2_4">
          Grad-CAM
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Grad-CAM" data-md-level="4">
        <label class="md-nav__title" for="__nav_7_2_2_4">
          <span class="md-nav__icon md-icon"></span>
          Grad-CAM
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/" class="md-nav__link">
        Grad-CAM Explained
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/" class="md-nav__link">
        Grad-CAM from Scratch
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../computer_vision/image_normalization/Image_Normalization_and_Standardization/" class="md-nav__link">
        Image Normalization
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_3" type="checkbox" id="__nav_7_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_3">
          Fundamental Concepts
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Fundamental Concepts" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_3">
          <span class="md-nav__icon md-icon"></span>
          Fundamental Concepts
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss_from_scratch/" class="md-nav__link">
        Cross Entropy Loss
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_4" type="checkbox" id="__nav_7_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_4">
          Ensemble Theory
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Ensemble Theory" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_4">
          <span class="md-nav__icon md-icon"></span>
          Ensemble Theory
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ensemble_theory/forward_ensemble/" class="md-nav__link">
        Forward Ensemble (Hill Climbing)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_8" type="checkbox" id="__nav_8" >
      
      
      
      
        <label class="md-nav__link" for="__nav_8">
          Data Structures and Algorithms
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Data Structures and Algorithms" data-md-level="1">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          Data Structures and Algorithms
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../data_structures_and_algorithms/introduction.md" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../data_structures_and_algorithms/Linked%20List/" class="md-nav__link">
        Linked Lists
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9" type="checkbox" id="__nav_9" >
      
      
      
      
        <label class="md-nav__link" for="__nav_9">
          Machine Learning Projects
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Machine Learning Projects" data-md-level="1">
        <label class="md-nav__title" for="__nav_9">
          <span class="md-nav__icon md-icon"></span>
          Machine Learning Projects
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/" class="md-nav__link">
        RANZCR CLiP - Catheter and Line Position Challenge
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/" class="md-nav__link">
        SIIM-ISIC Melanoma Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../projects/LTA_road_cracks_detection/notebooks/walkthrough/" class="md-nav__link">
        LTA
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9_4" type="checkbox" id="__nav_9_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_9_4">
          Breast Cancer Wisconsin (Supervised Classification)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Breast Cancer Wisconsin (Supervised Classification)" data-md-level="2">
        <label class="md-nav__title" for="__nav_9_4">
          <span class="md-nav__icon md-icon"></span>
          Breast Cancer Wisconsin (Supervised Classification)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../projects/breast_cancer_wisconsin/Stage%200%20-%20Introduction%20and%20Problem%20Statement/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../projects/breast_cancer_wisconsin/Stage%201%20-%20Preliminary%20Data%20Inspection%20and%20Cleaning/" class="md-nav__link">
        Preliminary Data Inspection and Cleaning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/" class="md-nav__link">
        EDA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../projects/breast_cancer_wisconsin/Stage%203%20-%20Feature%20Engineering/" class="md-nav__link">
        Feature Engineering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../projects/breast_cancer_wisconsin/Stage%204%20-%20Modelling%20%28Metric%20to%20Optimize%29/" class="md-nav__link">
        Modelling (Metrics)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../projects/breast_cancer_wisconsin/Stage%205%20-%20Modelling%20%28Cross-Validation%20Methodology%29/" class="md-nav__link">
        Modelling (Cross-Validation Schema)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../projects/breast_cancer_wisconsin/Stage%206%20-%20Modelling%20%28Preprocessing%20and%20Spot%20Checking%29/" class="md-nav__link">
        Modelling (Preprocessing and Spot Checking)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/" class="md-nav__link">
        Modelling (Model Selection)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../projects/breast_cancer_wisconsin/Stage%208%20-%20Modelling%20%28Model%20Evaluation%20and%20Interpretation%29/" class="md-nav__link">
        Modelling (Model Evaluation)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#receiver-operating-characteristic-roc" class="md-nav__link">
    Receiver operating characteristic (ROC)
  </a>
  
    <nav class="md-nav" aria-label="Receiver operating characteristic (ROC)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#intuition" class="md-nav__link">
    Intuition
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#definition-of-roc-curve" class="md-nav__link">
    Definition of ROC Curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#definition-of-area-under-roc-curve" class="md-nav__link">
    Definition of Area under ROC Curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auroc-as-a-ranking" class="md-nav__link">
    AUROC as a Ranking
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc-as-c-statistic" class="md-nav__link">
    ROC as C-Statistic
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pros-and-cons-of-auroc" class="md-nav__link">
    Pros and Cons of AUROC
  </a>
  
    <nav class="md-nav" aria-label="Pros and Cons of AUROC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pros-when-your-classes-are-more-balanced" class="md-nav__link">
    Pros: When your classes are more balanced
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pros-scale-invariant" class="md-nav__link">
    Pros: Scale Invariant
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pros-classification-threshold-invariant" class="md-nav__link">
    Pros: Classification Threshold Invariant
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cons-imbalanced" class="md-nav__link">
    Cons: Imbalanced
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cons-uncalibrated" class="md-nav__link">
    Cons: Uncalibrated
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-of-roc-and-auc" class="md-nav__link">
    Implementation of ROC and AUC
  </a>
  
    <nav class="md-nav" aria-label="Implementation of ROC and AUC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-1-problem-setup" class="md-nav__link">
    Step 1: Problem Setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-define-threshold-range" class="md-nav__link">
    Step 2: Define Threshold Range
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-classify-prediction-according-to-threshold" class="md-nav__link">
    Step 3: Classify prediction according to threshold
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-calculate-tpr-and-fpr" class="md-nav__link">
    Step 4: Calculate TPR and FPR
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-5-plot-the-points-as-roc-curve" class="md-nav__link">
    Step 5: Plot the points as ROC Curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-6-area-under-roc-curve" class="md-nav__link">
    Step 6: Area under ROC Curve
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#couple-roc-with-brier-score" class="md-nav__link">
    Couple ROC with Brier Score
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sklearn-definition-of-binary-classification-roc-auc" class="md-nav__link">
    SKLEARN Definition of Binary Classification ROC-AUC
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#first-interpretation" class="md-nav__link">
    First Interpretation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#precision-recall-curve" class="md-nav__link">
    Precision-Recall Curve
  </a>
  
    <nav class="md-nav" aria-label="Precision-Recall Curve">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#loss-function-and-decision-function" class="md-nav__link">
    Loss function and Decision Function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#an-extensive-study-on-precision-recall-curve" class="md-nav__link">
    An extensive study on Precision-Recall Curve
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use-precision-recall" class="md-nav__link">
    When to use Precision-Recall
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-not-to-use-precision-recall" class="md-nav__link">
    When NOT to use Precision-Recall
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-of-pr-curve" class="md-nav__link">
    Implementation of PR-Curve
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-debate-auroc-vs-auprc" class="md-nav__link">
    The Debate: AUROC vs AUPRC
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#metrics-for-multi-class-label-classification" class="md-nav__link">
    Metrics for Multi-Class-Label Classification
  </a>
  
    <nav class="md-nav" aria-label="Metrics for Multi-Class-Label Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multi-class-roc" class="md-nav__link">
    Multi-Class ROC
  </a>
  
    <nav class="md-nav" aria-label="Multi-Class ROC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#intuition_1" class="md-nav__link">
    Intuition
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-of-ovr-multi-class-roc" class="md-nav__link">
    Implementation of OVR Multi-Class ROC
  </a>
  
    <nav class="md-nav" aria-label="Implementation of OVR Multi-Class ROC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-1-problem-setup_1" class="md-nav__link">
    Step 1: Problem Setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-binarize" class="md-nav__link">
    Step 2: Binarize
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-roc-score-for-each-class" class="md-nav__link">
    Step 3: ROC score for each class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-one-vs-rest" class="md-nav__link">
    Step 4: One Vs Rest
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-5-modularize" class="md-nav__link">
    Step 5: Modularize
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-label-roc" class="md-nav__link">
    Multi-Label ROC
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#quadratic-weighted-kappa" class="md-nav__link">
    Quadratic Weighted Kappa
  </a>
  
    <nav class="md-nav" aria-label="Quadratic Weighted Kappa">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#intuition-of-qwk" class="md-nav__link">
    Intuition of QWK  
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1-create-the-nxn-histogram-matrix-o" class="md-nav__link">
    Step 1: Create the NxN histogram matrix O 
  </a>
  
    <nav class="md-nav" aria-label="Step 1: Create the NxN histogram matrix O ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-using-our-competitions-dataset" class="md-nav__link">
    Example using our competition's dataset
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-create-the-weighted-matrix-w" class="md-nav__link">
    Step 2: Create the Weighted Matrix w 
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-create-the-expected-matrix" class="md-nav__link">
    Step 3: Create the Expected Matrix 
  </a>
  
    <nav class="md-nav" aria-label="Step 3: Create the Expected Matrix ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#writing-out-the-expected-matrix-in-python" class="md-nav__link">
    Writing out the expected matrix in python
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-final-step-weighted-kappa-formula-and-its-python-codes" class="md-nav__link">
    Step 4: Final Step: Weighted Kappa formula and Its python codes 
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    References
  </a>
  
    <nav class="md-nav" aria-label="References">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#accuracy" class="md-nav__link">
    Accuracy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#receiver-operating-characteristic-roc_1" class="md-nav__link">
    Receiver Operating Characteristic (ROC)
  </a>
  
    <nav class="md-nav" aria-label="Receiver Operating Characteristic (ROC)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#interpretation-of-roc" class="md-nav__link">
    Interpretation of ROC
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pros-and-cons-of-auroc_1" class="md-nav__link">
    Pros and Cons of AUROC
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation" class="md-nav__link">
    Implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#precision-recall-curve_1" class="md-nav__link">
    Precision-Recall Curve
  </a>
  
    <nav class="md-nav" aria-label="Precision-Recall Curve">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#interpretation-of-pr" class="md-nav__link">
    Interpretation of PR
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


<div class="highlight"><pre><span></span><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">scikit</span><span class="o">-</span><span class="n">learn</span><span class="o">==</span><span class="mf">1.0.1</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">brier_score_loss</span><span class="p">,</span> <span class="n">cohen_kappa_score</span><span class="p">,</span> <span class="n">make_scorer</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span>

<span class="kn">from</span> <span class="nn">IPython.core.interactiveshell</span> <span class="kn">import</span> <span class="n">InteractiveShell</span>
<span class="n">InteractiveShell</span><span class="o">.</span><span class="n">ast_node_interactivity</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span>
</code></pre></div>
<h2 id="receiver-operating-characteristic-roc">Receiver operating characteristic (ROC)</h2>
<h3 id="intuition">Intuition</h3>
<p>Mathematically, ROC graphs are two dimensional graphs in which the x-axis is the False Positive Rate (FPR) and the y-axis, the True Positive Rate (TPR). The curve is parametrized by the parameter <span class="arithmatex">\(\vec{thr}\)</span> which represents the threshold of the classifier. The graph also depicts the tradeoffs between TPR and FPR, much like the dilemma of the Bias-Variance tradeoff. Also note that in the ROC space, each point on the graph represents a threshold, and therefore each point can have its own confusion matrix as well.</p>
<p>We come up with an example from the <a href="https://www.kaggle.com/c/siim-isic-melanoma-classification">Melanoma Competition</a> where we denote a malignant cell to be 1, and benign to be 0. If we treat the <strong>malignance class as positive class</strong>, and the model you trained on outputs a probability vector (using softmax here) <span class="arithmatex">\([0.7, 0.3]\)</span> corresponding to class 0 and 1 respectively, the value of 0.3 translates to saying that the image is 30% positive that it is malignant; in other words, it is 70% sure that this image is a benign cell. If we choose the default threshold to be the traditional <span class="arithmatex">\(\vec{thr}=0.5\)</span>, then the classifier will label this image as a <span class="arithmatex">\(0\)</span>. This is because the thresholds defines our <strong>hard label</strong> from the <strong>soft label</strong>, and thus anything above the threshold 0.5, will be classified as a positive class 1, and negative class otherwise.</p>
<p>If however, you lower your classification threshold, say from 0.5 to 0.2, then our image will become now become positive class, indicating the image's cell to be malignant. Intuitively, the consequence is that more images will be classified to become positive as lowering the threshold will allow the model to predict true more often. The consequence is that the TPR will go up, and so will the FPR.</p>
<hr />
<div class="alert alert-block alert-warning">
<b>Example:</b> There are 10 ground truth targets of y_true = [1,1,1,0,0,0,0,0,1,0,0] and your model predicts y_pred = [0.6,0.7,0.4,0.6,0.55,0.4,0.3,0.2,0.6,0.1] which if you apply argmax to y_pred, then it will become y_pred_argmax = [1,1,0,1,1,0,0,0,1,0]. The TPR here is given by $\frac{2}{4}$ since there are 4 positive ground truth, and among the predicted labels, the model correctly classify 2 positives correctly. The FPR is given by $\frac{3}{6}$ because we gave 3 people the false alarm, predicting them to have cancer whereas they don't. Now if you lower you threshold to 0.2, then you can see that the new predicted label array to be [1,1,1,1,1,1,1,0,1,0] where the new calibrated TPR is $\frac{3}{4}$ and the FPR is $\frac{5}{6}$. Therefore, without any proofs, just intuition, one should be convinced that if you lower the threshold, more patients will be classified as positive, consequently, the TPR and FPR both increase. Conversely, if you increase the threshold, then the TPR and FPR will both decrease. This may not hold true in a monotone manner, as wrongly described earlier, as it can jolly well be the TPR or FPR do not change, as can be seen in the diagram in the section Ranking.
</div>

<h3 id="definition-of-roc-curve">Definition of ROC Curve</h3>
<div class="alert alert-block alert-success">
<b>Definition:</b> The ROC Curve is a graph that plots the True Positive Rate on the y-axis and False Positive Rate on the x-axis, furthermore, this curve is parametrized by a threshold vector $\vec{t}$.
</div>

<hr />
<blockquote>
<p>From Wikipedia: In binary classification, the class prediction for each instance is often made based on a continuous random variable <span class="arithmatex">\(X\)</span>, which is a "score" computed for the instance (e.g. the estimated probability in logistic regression). Given a threshold parameter <span class="arithmatex">\(T\)</span>, the instance is classified as "positive" if <span class="arithmatex">\(X &gt; T\)</span>, and "negative" otherwise. <span class="arithmatex">\(X\)</span> follows a probability density <span class="arithmatex">\(f_1(x)\)</span> if the instance actually belongs to class "positive", and <span class="arithmatex">\(f_0(x)\)</span> if otherwise. Therefore, the true positive rate is given by <span class="arithmatex">\(TPR(T) = \int_{T}^{\infty}f_1(x)dx\)</span> and the false positive rate is given by <span class="arithmatex">\(FPR(T) = \int_{T}^{\infty}f_0(x)dx\)</span>. The ROC curve plots parametrically TPR(T) with FPR(T) as the varying parameter.</p>
</blockquote>
<div class="alert alert-block alert-warning">
<b>Example:</b> 
For example, imagine that the blood protein levels in diseased people and healthy people are normally distributed with means of 2 g/dL and 1 g/dL respectively. A medical test might measure the level of a certain protein in a blood sample and classify any number above a certain threshold as indicating disease. The experimenter can adjust the threshold (black vertical line in the figure), which will in turn change the false positive rate. Increasing the threshold would result in fewer false positives (and more false negatives), corresponding to a leftward movement on the curve. The actual shape of the curve is determined by how much overlap the two distributions have.
</div>

<h3 id="definition-of-area-under-roc-curve">Definition of Area under ROC Curve</h3>
<div class="alert alert-block alert-success">
<b>Definition:</b> The AUROC is thus the area under the ROC Curve.
</div>

<p>More formally, in the<a href="https://www.alexejgossmann.com/auc/">probabilistic perspective of AUC</a>, AUC is the probability of a randomly chosen positive case outranks a randomly chosen negative case based on the classifier.</p>
<div class="arithmatex">\[
\begin{aligned}
AUC &amp;= P(f(x+)&gt;f(x)|\text{class}(x+)=1, \text{class}(x)=0)\\ 
    &amp;= \frac{1}{PN}\sum_{i=1}^{P}\sum_{j=1}^{N}1(f(x+)f(x))
\end{aligned}
\]</div>
<p>where </p>
<ul>
<li><span class="arithmatex">\(f(x)\)</span>: classifier</li>
<li>P : # of true positive item,</li>
<li>N : # of true negative item</li>
</ul>
<hr />
<p>Or expressed in another digestable way:</p>
<blockquote>
<p>The AUC of a classifier is equal to the probability that the classifier will rank a randomly chosen positive example higher than a randomly chosen negative example, i.e. <span class="arithmatex">\(P\Big(\text{score}(x^+) &gt; \text{score}(x^-)\Big)\)</span></p>
<p>This line above means that if you randomly take two samples, one positive and one negative, the AUC score, say 0.8, says that the probability of your positive sample being ranked higher (means probability higher) than the negative sample is 0.8.</p>
</blockquote>
<p>In other words, it measures how well the probability ranks based on their true classes. Thus, it is a threshold-invariant and scale-invariant metrics and only the sequence matters in the predicted probabilities. Based on this property, models with higher AUC indicate better discrimination between the two classes. However, the probabilities output from models with higher AUC dont always generate well-calibrated probabilities. More information can be found here:<a href="https://www.youtube.com/watch?v=RXMu96RJj_s">Safe Handling Instructions for Probabilistic Classification</a>.</p>
<hr />
<p>Another answer from Stackoverflow, to reference it.</p>
<p>Although I'm a bit late to the party, but here's my 5 cents. @FranckDernoncourt (+1) already mentioned possible interpretations of AUC ROC, and my favorite one is the first on his list (I use different wording, but it's the same):</p>
<blockquote>
<p>the AUC of a classifier is equal to the probability that the classifier will rank a randomly chosen positive example higher than a randomly chosen negative example, i.e. <span class="arithmatex">\(P\Big(\text{score}(x^+) &gt; \text{score}(x^-)\Big)\)</span></p>
</blockquote>
<p>Consider this example (auc=0.68): </p>
<p><img alt="enter image description here" src="http://en.wikipedia.org/wiki/Frequentist_inference" /></p>
<p>Let's try to simulate it: draw random positive and negative examples and then calculate the proportion of cases when positives have greater score than negatives</p>
<!-- language: lang-r -->

<div class="highlight"><pre><span></span><code>cls = c(&#39;P&#39;, &#39;P&#39;, &#39;N&#39;, &#39;P&#39;, &#39;P&#39;, &#39;P&#39;, &#39;N&#39;, &#39;N&#39;, &#39;P&#39;, &#39;N&#39;, &#39;P&#39;,
        &#39;N&#39;, &#39;P&#39;, &#39;N&#39;, &#39;N&#39;, &#39;N&#39;, &#39;P&#39;, &#39;N&#39;, &#39;P&#39;, &#39;N&#39;)
score = c(0.9, 0.8, 0.7, 0.6, 0.55, 0.51, 0.49, 0.43, 0.42, 0.39, 0.33, 
          0.31, 0.23, 0.22, 0.19, 0.15, 0.12, 0.11, 0.04, 0.01)

pos = score[cls == &#39;P&#39;]
neg = score[cls == &#39;N&#39;]

set.seed(14)
p = replicate(50000, sample(pos, size=1) &gt; sample(neg, size=1))
mean(p)
</code></pre></div>
<p>And we get 0.67926. Quite close, isn't it? </p>
<p>&nbsp;</p>
<p>By the way, in R I typically use <a href="http://en.wikipedia.org/wiki/Bayesian_statistics">ROCR</a> package for drawing ROC curves and calculating AUC. </p>
<!-- language: lang-r -->

<div class="highlight"><pre><span></span><code>library(&#39;ROCR&#39;)

pred = prediction(score, cls)
roc = performance(pred, &quot;tpr&quot;, &quot;fpr&quot;)

plot(roc, lwd=2, colorize=TRUE)
lines(x=c(0, 1), y=c(0, 1), col=&quot;black&quot;, lwd=1)

auc = performance(pred, &quot;auc&quot;)
auc = unlist(auc@y.values)
auc
</code></pre></div>
<p><img alt="enter image description here" src="http://i.stack.imgur.com/Zw4Yw.png" /></p>
<h3 id="auroc-as-a-ranking">AUROC as a Ranking</h3>
<p>One confusing aspect of ROC space is the ranking system. This can be seen in the notebook I created here. Remember, if you code it out yourself from scratch, then it will be more beneficial as you can understand where ranking come into play (without using sklearn). The algorithm starts from the point where threshold is \infty or in sklearn it starts with some other number. A threshold of infinity will guarantee that the point starts at (0,0). Thus, our very first point MUST start from the origin in this algorithm. Then assuming we do not consider an infinity number of thresholds, as this is too computationally expensive, we consider say 10 threshold values that we want to test (a common number is the number in the dataset). We divide the 10 values into 0.9,0.8,0.7,...,0.1, (for example only). Then we start from 0.9, the highest threshold, and move down to the lowest, in order (ranking). As we have seen just now, as you lower the threshold, both your TPR and FPR go up. Therefore, if you don't want to get your hands dirty, then the intuition is that if you have ground truth [0,1,1,0] and pred_1 = [0.03,0.99,0.05,0.06] and pred_2 = [0.15,0.92,0.89,0.91] then if you then imagine that your thresholds are given by thres_1 = [infinity,0.99,0.06,0.05,0.03] and thres_2 = [infinity, 0.92,0.91,0.89,0.15] , then you can calculate that the TPR and FPR rate at each of the threshold for both predictions are actually the same, consequently, forming the same ROC curve. (Consider plotting it). The idea here is we do not care what your values of the predictions are, in fact, in neural networks, transforming logits through softmax may not be a well calibrated (refer to my calibrated probability notes) probability anyways. We do however, care about the ranking, as you can see our thresholds are sorted in descending order, noticed that we only need that many thresholds for the dataset because only the thresholds at the predictions matter. If you take a number between 0.06 and 0.99 for the first threshold set, you will notice that between this threshold, the TPR and FPR will always be the same. Therefore, we conclude, without proof, that if two arrays of prediction has the exact same relative order, then the AUC for both predictions will be the same, which means that AUC is invariant to the scale of the predictions, and in fact invariant to any sort of transformation, that preserves the order (i.e. a non-negative linear transformation); (you can have numbers greater than 1 and the AUC will be the same try [100,200,150,160]).  A corollary of this is we cant treat outputs of an AUC-optimized model as the likelihood that its true. Some models may be poorly calibrated (eg: its output is always between 0.3 and 0.32) but still achieve a good AUC score because its relative ordering is correct. This is something to look out for when blending together predictions of different models.</p>
<p><img src='https://raw.githubusercontent.com/reigHns/reighns-MLAlgorithms/master/reighns-metrics/data/images/ranking_auc.png' width="390" height="200"/></p>
<p>Furthermore, if you see my notebook example, you can predict wrongly, but still have an AUC of 1. One last thing is about the predictions ordering, there is no rule that your predictions must SORT IN DESCENDING ORDER, for example: This will give you an AUC score of 1, even though it may not seem to predict everything correctly. Because the below order gives rise to the best AUC, which is 1 in this case, and hence this will give you 1 as well. If you switch a few numbers inside y_pred you will notice it can still stay at 1. However, if you reverse the list order, then you will get an AUC of 0 (the opposite of the best).</p>
<div class="highlight"><pre><span></span><code><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.99999</span><span class="p">,</span> <span class="mf">0.98</span><span class="p">,</span> <span class="mf">0.97</span><span class="p">,</span> <span class="mf">0.96</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.94</span><span class="p">,</span> <span class="mf">0.68139</span><span class="p">,</span> <span class="mf">0.50961</span><span class="p">,</span> <span class="mf">0.48880</span><span class="p">,</span> <span class="mf">0.44951</span><span class="p">]</span>
<span class="n">full_score_example</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>  
<span class="nb">print</span><span class="p">(</span><span class="n">full_score_example</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="mi">1</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>
<span class="n">y_pred_same_rank</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>


<span class="n">fpr_rank_1</span><span class="p">,</span> <span class="n">tpr_rank_1</span><span class="p">,</span> <span class="n">threshold_rank_1</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">drop_intermediate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">fpr_rank_2</span><span class="p">,</span> <span class="n">tpr_rank_2</span><span class="p">,</span> <span class="n">threshold_rank_2</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_same_rank</span><span class="p">,</span> <span class="n">drop_intermediate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">roc_rank_1</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_fpr</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># 0.833</span>
<span class="n">roc_rank_2</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_pred_same_rank</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_fpr</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># 0.833</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">9</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Receiver Operating Characteristic&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_rank_1</span><span class="p">,</span> <span class="n">tpr_rank_1</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;AUC = </span><span class="si">%0.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">roc_rank_1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_rank_2</span><span class="p">,</span> <span class="n">tpr_rank_2</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;AUC = </span><span class="si">%0.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">roc_rank_2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span><span class="s1">&#39;r--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div>
<p><img alt="png" src="../roc_pr_curve_files/roc_pr_curve_9_0.png" /></p>
<h3 id="roc-as-c-statistic">ROC as C-Statistic</h3>
<p>ROC can be interpreted as <a href="https://stats.stackexchange.com/questions/193138/roc-curve-drawbacks">c-statistics</a>.
ROC AUC has the property that it coincides with the <span class="arithmatex">\(c\)</span> statistic. The <span class="arithmatex">\(c\)</span> statistic measures the probability that a positive example is ranked higher than a negative example. In this sense, the ROC AUC answers the question of how well the model discriminates between the two classes.</p>
<p>A model with high discrimination is not necessarily well calibrated. Suppose a logistic regression model predicts probabilities of 0.52 for positives and 0.51 for negatives (imagine 10 ground truth where 6 is positive and 4 is negative, then the author meant the associated probabilities with each of these ground truth is 0.52 and 0.51 respectively, for the positive and negative classes). This model has an AUC of 1 (recall you need not predict everything correctly to get an AUC of 1) but the probabilities aren't helpful in the sense of identifying which purported positives are highest-risk. Because all of the positives are assigned the same posterior probability, they can't be differentiated.</p>
<p>Moreover, a well-calibrated model will have its maximum ROC AUC fixed by the ratio of positives to negatives in the data. This means that a model which has some very desirable probabilities (i.e. its posterior probabilities match the true probability) has a cap on its performance, and therefore an <strong>uncalibrated</strong> model could "dominate" in terms of ROC AUC.</p>
<p>ROC AUC doesn't tell you anything about the costs of different kinds of errors. For example, if you're trying to detect fraud, a 10,000 dollar purchase of uncertain provenance represents a larger potential loss than a 10 dollar purchase. But ROC AUC would treat both events as if they have the same weight -- obviously any reasonable model should be able to distinguish between these two types of error.</p>
<p>ROC AUC also tends to be dominated by the "high FPR" points. <strong>Depending on the application, these points may be the least relevant.</strong> Consider the case where the model is used to refer high-risk transactions to experts who will conduct further vetting. There may only be enough humans to assess 50 transactions per unit time; since the most highly-ranked transactions occur on the "left hand" size of the ROC curve by definition, this is also the region with the lowest area. So by looking at the whole AUC, you're optimistically biasing your results upwards, i.e. ROC AUC is buoyed by the observations "to the right" of the actual set of observations which humans will vet. (Illustration is simple. Draw a vertical line at FPR&lt;0.5 on any ROC curve. The area to left is higher for all such vertical lines.) To avoid this, some people use partial ROC AUC, which has its own host of problems, chief among them that software implementations tend to assume that you're interested in truncation <em>at some value of FPR.</em> But in the case that you care about the top <span class="arithmatex">\(n\)</span> transactions, this approach is obviously wrong because the top <span class="arithmatex">\(n\)</span> transactions will happen at different FPR values for different classifiers. Standardization of partial AUC (to preserve the property that AUC &lt; 0.5 is worse than random, 1 is perfect, 0 is worthless) incurs further difficulties.</p>
<p>The ROC curve itself is of little interest. "Dominating" classifiers can be assessed by AUC. Stochastic equivalence can be assessed by tests of equivalence of ranks. Prof. Harrell's comment drives at a consistent theme of his work, which is that the real question diagnostics should answer is one of risk assessment and utility optimization. Examining ROC AUC tends to encourage selection of truncation points, which should be avoided because it only provides partial information to decision makers.</p>
<p>Alternative measures of performance (e.g. log-likelihood) characterize the calibration of the model and proper scoring rules generally have the quality that they encourage honest forecasts.</p>
<h3 id="pros-and-cons-of-auroc">Pros and Cons of AUROC</h3>
<p>Before we go ham on the <a href="https://stats.stackexchange.com/questions/193138/roc-curve-drawbacks">Drawbacks of AUROC</a>, we first try to think the following:</p>
<div class="alert alert-block alert-info">
<b>Food For Thought:</b> I think intuitively you can say that if your model needs to perform equally well on the positive class as the negative class (for example, for classifying images between cats and dogs, you would like the model to perform well on the cats as well as on the dogs. For this you would use the AUROC.)<p>

On the other hand, if you're not really interested in how the model performs on the negative class, but just want to make sure every positive prediction is correct (precision), and that you get as many of the positives predicted as positives as possible (recall), then you should choose PRAUC (more with it later). For example, for detecting cancer, you don't care how many of the negative predictions are correct, you want to make sure all the positive predictions are correct, and that you don't miss any. (In fact, in this case missing a cancer would be worse than a false positive so you'd want to put more weight towards recall.)
</div>

<h4 id="pros-when-your-classes-are-more-balanced">Pros: When your classes are more balanced</h4>
<p>ROC curves are insensitive to changes in class distribution. Quote unquote from "The analysis of ROC Curves", we see that the <strong>if the proportion of positive to negative instances changes in a test set, the ROC curves will not change</strong>. This is because the AUC is equals to the probability of ranking a random positive example over a random negative example, and by definition this happens after you have drawn a positive and a negative, which indicates that we do not need to know anything about the original distribution and the class proportions.</p>
<hr />
<p>AUROC curve better reflects the total amount of False Positives independent of in which class they come up. We can see this by a simple math example:</p>
<p>Essentially, AUROC is measuring the TPR vs FPR ratio: We can interpret it as such</p>
<div class="arithmatex">\[TPR:FPR = \dfrac{TP}{TP + FN} : \dfrac{FP}{FP+TN} = \dfrac{TP}{TP+FN} \times \dfrac{FP + TN}{FP} = \dfrac{TP}{|+|} \times \dfrac{|-|}{FP}=\dfrac{|-|}{|+|} \times \dfrac{TP}{FP}\]</div>
<hr />
<!-- This portion here is important and can be extended into the Cons section as well. In summary, if you notice that AUROC curve is made up by TPR vs FPR, and since FPR = 1- TNR, we can deduce the following:

$$FPR = 1 - P(\hat{Y}=0|Y=0) \text{ and } TPR = P(\hat{Y}=1|Y=1)$$

Now you may wonder, why did I express them in this format? This is because we should understand it probabilistically. Notice that both TPR and FPR are **probabilities conditioned on the true class label**. As a result, AUROC curves is the same no matter what the baseline probability is. To make it more concrete, consider the sample set $\mathcal{D}$ to have 100 samples, in which 90 is **negative** and 10 is **positive**. Thus the baseline classifier ZeroR will always predict majority, in this case, it will always predict negative.

$$P(Y=1) = 10\% \text{ and } P(Y=0) = 90\%$$ -->

<h4 id="pros-scale-invariant">Pros: Scale Invariant</h4>
<p><strong>See section on AUROC as a Ranking for code example</strong>. </p>
<p>AUC measures how well predictions are ranked, rather than their absolute values. <strong>This means that your score from the model need not be calibrated into a strict probability. You can predict any score you want. This allows us to compare different classifiers that predict values on a different scale.</strong></p>
<hr />
<p>This can be a con as highlighted in Cons: uncalibrated.</p>
<h4 id="pros-classification-threshold-invariant">Pros: Classification Threshold Invariant</h4>
<p>AUC measures the quality of the model's predictions irrespective of what classification threshold is chosen. What this means is if you compare an example to accuracy, how do you compute it? You say that if threshold is more than <span class="arithmatex">\(t\)</span>, then you proceed to calculate the accuracy score - and different threshold gives different accuracies. But in ROC, the nuance is that our final metric is area under the ROC curve, over various (all possible) thresholds <span class="arithmatex">\(t\)</span>, so as you see, we do not depend on the threshold to calculate the final score! This may be good in the sense that it gives you an overall performance on the binary classifier.</p>
<hr />
<p>This can also be a con when you want to specifically minimize one metric like False Negatives or False Positives. For example, in cancer detection where malignant is the positive class, you will likely want to minimize False Negatives, <strong>even if it results in a huge increase in False Positives</strong>, then ROC may not be best suited. So if you only have the ROC curve for analysis, then you can choose your threshold according to the curve, in this case we choose the point which maximizes TPR as maximizing TPR is equivalent to minimizng FN.</p>
<h4 id="cons-imbalanced">Cons: Imbalanced</h4>
<div class="alert alert-block alert-danger">
<b>Imbalanced Data:</b> We examine the case in which the dataset is imbalanced and further assume that the positive class is the minority, (note if you assume positive class is majority, then ROC may perform very well here, so the assumption is that the minority is of the positive class). We assume further that the negative class is 90% and positive class is 10%. Intuitively, in an imbalanced dataset, the model **usually does not have trouble predicting the majority class**, and this suggests that they will often get the negatives correct in this case, leading to a high TN. By looking at the FPR, we notice that $\frac{FP}{FP + TN}$ suggests that FP will be low and TN will be high simply because of the aforementioned idea that the model will likely get the TN correct, and if TN is high, then the FP is low. Consequently, FPR is high. <p>

The following [on why AUC can be misleading](https://stats.stackexchange.com/questions/360017/when-is-an-auc-score-misleadingly-high/360040#360040)
One possible reason you can get high AUROC with what some might consider a mediocre prediction is if you have imbalanced data (in favor of the "zero" prediction), high recall, and low precision. That is, you're predicting most of the ones at the higher end of your prediction probabilities, but most of the outcomes at the higher end of your prediction probabilities are still zero. This is because the ROC score still gets most of its "lift" at the early part of the plot, i.e., for only a small fraction of the zero-predictions. 

For example, if 5% of the test set are "ones" and all of the ones appear in the top 10% of your predictions, then your AUC will be at least 18/19 because, after 18/19 of the zeroes are predicted, already 100% of the ones were predicted. Even if the top 5% are all zeroes.

Whether this is a "bad" prediction depends on your priorities. If you think that false negatives are terrible and false positives are tolerable, then this prediction is okay. But if it's the opposite, then this prediction is pretty bad.
</div>

<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">yTest</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">yPredicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">yTest</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">yPredicted</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="n">imbalanced_roc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yPredicted</span><span class="p">)</span> <span class="c1"># ~0.89</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;roc score: </span><span class="si">{</span><span class="n">imbalanced_roc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="n">fpr_imbalanced</span><span class="p">,</span> <span class="n">tpr_imbalanced</span><span class="p">,</span> <span class="n">threshold_imbalanced</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yPredicted</span><span class="p">,</span> <span class="n">drop_intermediate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;fpr: </span><span class="se">\n</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">fpr_imbalanced</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tpr: </span><span class="se">\n</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tpr_imbalanced</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;thresholds: </span><span class="se">\n</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">threshold_imbalanced</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_imbalanced</span><span class="p">,</span> <span class="n">tpr_imbalanced</span><span class="p">);</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>[0.9        0.87333333 0.84666667 0.82       0.79333333 0.76666667
 0.74       0.71333333 0.68666667 0.66       0.63333333 0.60666667
 0.58       0.55333333 0.52666667 0.5        0.47333333 0.44666667
 0.42       0.39333333 0.36666667 0.34       0.31333333 0.28666667
 0.26       0.23333333 0.20666667 0.18       0.15333333 0.12666667
 0.1       ]

roc score: 0.888888888888889

fpr: 
[0.0, 0.037, 0.074, 0.074, 0.111, 0.111, 0.185, 0.185, 1.0]

tpr: 
[0.0, 0.0, 0.0, 0.5, 0.5, 0.75, 0.75, 1.0, 1.0]

thresholds: 
[1.9, 0.9, 0.873, 0.82, 0.793, 0.767, 0.713, 0.687, 0.1]
</code></pre></div>
<p><img alt="png" src="../roc_pr_curve_files/roc_pr_curve_16_1.png" /></p>
<p>This diagram above says a thousand words. Because one perpetual question I had was how does class imbalance really plays a part in giving AUROC an overly optimistic picture. Note that the above I put <code>drop_intermediate=True</code>, which means we are only shown meaningful thresholds. In the thresholds above, we can see the fpr consistently is low, with low tpr at first. Then at the second last point, the fpr is 0.185 and tpr is 1, meaning we classified all positive points correctly. We see that this corresponding threshold is 0.687, and indeed, if we check the yTest and yPredicted, all the 1s have HIGHER probability than 0.687, which is the "trick here", thus once the threshold is set to &gt; 0.687, all POSITIVE POINTS will be classified correctly, but this does not mean there is no FP, but now the FP is a lot at the expense, because we predict many as positive but it is actually negative, but fpr will be low, because fpr = fp/fp+tn, and even if fp is high, our tn is very big, pulling our denominator big, and as a result, making fpr seem deceptively low.</p>
<h4 id="cons-uncalibrated">Cons: Uncalibrated</h4>
<div class="alert alert-block alert-danger">
<b>Uncalibrated:</b> 
A model with high AUROC does not necessarily imply a well calibrated model. By this I mean a model with all extreme predictions for of say, it predicts all positive ground truths to be 0.52 and all negative ground truths to be 0.51. This model has an AUC of 1, but the probabilities aren't helpful in the sense of identifying which purported positives are highest-risk. Because all of the positives are assigned the same posterior probability, they can't be differentiated. Note that models like logistic regression are naturally well calibrated, but models like neural networks output logits, and hence we have to apply `sigmoid` or `softmax` to make it probabilities. <p>

Below is the "phenomenon" that AUC of 1 but the models look bad. Notice that even though we have a perfect AUROC score of 1, the model is not at all confident with the predictions in the sense that we cannot pin point any two positive labels and say that one of them is of higher probability than the other. If you are not convinced, the below code illustrates the point and the plot shows you.
</div>

<div class="highlight"><pre><span></span><code><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.52</span><span class="p">,</span> <span class="mf">0.51</span><span class="p">,</span> <span class="mf">0.52</span><span class="p">,</span> <span class="mf">0.51</span><span class="p">,</span> <span class="mf">0.52</span><span class="p">,</span> <span class="mf">0.51</span><span class="p">,</span> <span class="mf">0.52</span><span class="p">,</span> <span class="mf">0.51</span><span class="p">,</span> <span class="mf">0.52</span><span class="p">,</span> <span class="mf">0.52</span><span class="p">]</span>

<span class="n">uncalibrated_roc</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;roc score: </span><span class="si">{</span><span class="n">uncalibrated_roc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">fpr_uncalibrated</span><span class="p">,</span> <span class="n">tpr_uncalibrated</span><span class="p">,</span> <span class="n">threshold_uncalibrated</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">drop_intermediate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">fpr_uncalibrated</span><span class="p">,</span> <span class="n">tpr_uncalibrated</span><span class="p">,</span> <span class="n">threshold_uncalibrated</span><span class="p">)</span>

<span class="c1"># Another example</span>
<span class="c1"># y_true = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]</span>
<span class="c1"># y_pred = [0.99999, 0.98, 0.97, 0.96, 0.95, 0.94, 0.68139, 0.50961, 0.48880, 0.44951]</span>
<span class="c1"># full_score_example = sklearn.metrics.roc_auc_score(y_true, y_pred)  </span>
<span class="c1"># print(full_score_example) -&gt; 1</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>roc score: 1.0
[0. 0. 1.] [0. 1. 1.] [1.52 0.52 0.51]
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">fpr_uncalibrated</span><span class="p">,</span> <span class="n">tpr_uncalibrated</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#0F9D58&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_uncalibrated</span><span class="p">,</span> <span class="n">tpr_uncalibrated</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#0F9D58&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;auc: </span><span class="si">{</span><span class="n">uncalibrated_roc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ROC Curve&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False Positive Rate&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Positive Rate&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">);</span>
</code></pre></div>
<p><img alt="png" src="../roc_pr_curve_files/roc_pr_curve_20_0.png" /></p>
<h3 id="implementation-of-roc-and-auc">Implementation of ROC and AUC</h3>
<p>This implementation follows closely to <a href="https://towardsdatascience.com/roc-curve-and-auc-from-scratch-in-numpy-visualized-2612bb9459ab">Implementation of ROC - roc-curve-and-auc-from-scratch-in-numpy-visualized - TDS</a>.</p>
<h4 id="step-1-problem-setup">Step 1: Problem Setup</h4>
<div class="highlight"><pre><span></span><code><span class="n">y_true_binary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">y_pred_binary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
</code></pre></div>
<p>We have a binary classification problem with the targets and predictions shown above. We further note that the predictions are probabilities output from the <strong>Sigmoid</strong> layer in a logistic classifier.</p>
<div class="highlight"><pre><span></span><code><span class="n">y_true_binary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">y_pred_binary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
</code></pre></div>
<h4 id="step-2-define-threshold-range">Step 2: Define Threshold Range</h4>
<p>For our classifier, our usual default threshold is as such:</p>
<div class="highlight"><pre><span></span><code><span class="k">if</span> <span class="n">y_pred_binary</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
    <span class="n">assign</span> <span class="n">y_pred_binary</span> <span class="k">as</span> <span class="n">positive</span> <span class="k">class</span> <span class="err">(+)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">assign</span> <span class="n">y_pred_binary</span> <span class="k">as</span> <span class="n">negative</span> <span class="k">class</span> <span class="err">(-)</span>
</code></pre></div>
<p>Then it follows that different thresholds will result to different TPR and FPR. We can discretize our thresholds uniformly. Note that <code>scikit-learn</code> uses a different method to find the thresholds and are more optimized.</p>
<p>For starter, we will just set our threshold range from 0 to 1 with uniform interval of 0.1.</p>
<div class="highlight"><pre><span></span><code><span class="n">threshold_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">10</span>
<span class="nb">print</span><span class="p">(</span><span class="n">threshold_range</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]
</code></pre></div>
<h4 id="step-3-classify-prediction-according-to-threshold">Step 3: Classify prediction according to threshold</h4>
<p>The next step we need to do is to classify our <code>y_pred_binary</code> from probabilities into hard labels, a 0 or 1 label. We create a dictionary <code>y_pred_thresholded</code> which has the threshold as key, and the value is the corresponding hard labels.</p>
<div class="highlight"><pre><span></span><code><span class="n">y_pred_thresholded</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mf">0.0</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.1</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.2</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.3</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.4</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.5</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.6</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.7</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.8</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.9</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="mf">1.0</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="p">}</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">y_pred_thresholded</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">threshold_range</span><span class="p">:</span>

    <span class="k">if</span> <span class="n">threshold</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">y_pred_thresholded</span><span class="p">:</span>
        <span class="n">y_pred_thresholded</span><span class="p">[</span><span class="n">threshold</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">y_p</span> <span class="ow">in</span> <span class="n">y_pred_binary</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">y_p</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">:</span>
            <span class="n">y_pred_thresholded</span><span class="p">[</span><span class="n">threshold</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y_pred_thresholded</span><span class="p">[</span><span class="n">threshold</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<h4 id="step-4-calculate-tpr-and-fpr">Step 4: Calculate TPR and FPR</h4>
<p>Now we calculate the respective TPR and FPR for each thresholds's hard labels against the <code>y_true_binary</code>. We will make use of our <code>reighns_confusion_matrix</code> defined earlier to calculate.</p>
<div class="highlight"><pre><span></span><code><span class="n">tpr_fpr</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
<span class="p">]</span>
</code></pre></div>
<p>where the first element of the inner list is <code>tpr</code> and the second element is <code>fpr</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">tpr_fpr</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;tpr&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;fpr&quot;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">y_pred</span> <span class="ow">in</span> <span class="n">y_pred_thresholded</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">reighns_confusion_matrix</span><span class="p">(</span><span class="n">y_true_binary</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">tpr</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">fpr</span> <span class="o">=</span> <span class="n">fp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
    <span class="n">tpr_fpr</span><span class="p">[</span><span class="s2">&quot;tpr&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tpr</span><span class="p">)</span>
    <span class="n">tpr_fpr</span><span class="p">[</span><span class="s2">&quot;fpr&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fpr</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tpr_fpr</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>{&#39;tpr&#39;: [1.0, 1.0, 1.0, 1.0, 0.75, 0.5, 0.5, 0.5, 0.25, 0.0, 0.0], &#39;fpr&#39;: [1.0, 1.0, 0.75, 0.5, 0.5, 0.5, 0.25, 0.0, 0.0, 0.0, 0.0]}
</code></pre></div>
<h4 id="step-5-plot-the-points-as-roc-curve">Step 5: Plot the points as ROC Curve</h4>
<p>The main idea of ROC Curve is to plot various pairs of [TPR, FPR] at different threshold on the graph, as shown below. Note that we <strong>reversed</strong> our tpr and fpr to be in line with Scikit-Learn. It does not affect the end result.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>

<span class="n">tpr_reighns</span> <span class="o">=</span> <span class="n">tpr_fpr</span><span class="p">[</span><span class="s2">&quot;tpr&quot;</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">fpr_reighns</span> <span class="o">=</span> <span class="n">tpr_fpr</span><span class="p">[</span><span class="s2">&quot;fpr&quot;</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">fpr_reighns</span><span class="p">,</span> <span class="n">tpr_reighns</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#0F9D58&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ROC Curve&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False Positive Rate&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Positive Rate&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">);</span>
</code></pre></div>
<p><img alt="png" src="../roc_pr_curve_files/roc_pr_curve_31_0.png" /></p>
<p>Let us compare to the <code>scikit-learn's</code> version!</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
<span class="n">fpr_sklearn</span><span class="p">,</span> <span class="n">tpr_sklearn</span><span class="p">,</span> <span class="n">thresholds_sklearn</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true_binary</span><span class="p">,</span> <span class="n">y_pred_binary</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">fpr_sklearn</span><span class="p">,</span> <span class="n">tpr_sklearn</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Scikit-learn&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">fpr_reighns</span><span class="p">,</span> <span class="n">tpr_reighns</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#0F9D58&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Our implementation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ROC Curve&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False Positive Rate&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Positive Rate&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</code></pre></div>
<p><img alt="png" src="../roc_pr_curve_files/roc_pr_curve_33_0.png" /></p>
<p>Notice that in Scikit-Learn's version, they have 3 less points that us, this is discussed in details in the reference links I appended below. But just know that the end result is the same when we go to AUC!</p>
<div class="alert alert-block alert-danger">
<b>Starting and Ending Point:</b> 
Notice that the starting point and ending point of the ROC curve always start with (0, 0) and (1, 1). See the `y_pred_thresholded` we got earlier.
</div>

<div class="highlight"><pre><span></span><code><span class="n">y_true_binary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">y_pred_thresholded</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mf">0.0</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.1</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.2</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.3</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.4</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.5</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.6</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.7</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.8</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="mf">0.9</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="mf">1.0</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="p">}</span>
</code></pre></div>
<p>A bit of probing reveals that if you discretize your threshold from 0 to 1 inclusive, then it follows that at the threshold 1, everything is predicted as the negative class as shown, then by definition, TPR is 0 because the numerator of TPR is TP, and there is 0 TP because every single prediction made is of negative class, similarly, FPR is also 0 because the numerator of FPR is FP, and the model did not miss any negatives since it predicted every single one as negative.</p>
<hr />
<p>The same logic can be applied to when the threshold is 0, we instead have FPR and TPR to be both 1.</p>
<h4 id="step-6-area-under-roc-curve">Step 6: Area under ROC Curve</h4>
<p>In the <a href="https://towardsdatascience.com/roc-curve-and-auc-from-scratch-in-numpy-visualized-2612bb9459ab">Implementation of ROC - roc-curve-and-auc-from-scratch-in-numpy-visualized - TDS</a> visualization, we understand that we can approximate AUROC score by "integrating" over the rectangles. In a way, this is calculating areas of rectangles under the curve, as follows.</p>
<div class="highlight"><pre><span></span><code><span class="n">rectangle_area</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">threshold_range</span><span class="p">)):</span>
    <span class="n">rectangle_area</span> <span class="o">+=</span> <span class="p">(</span><span class="n">fpr_reighns</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">fpr_reighns</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">*</span> <span class="n">tpr_reighns</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">threshold_range</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span> 
        <span class="k">break</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;reighns roc_auc_score: </span><span class="si">{</span><span class="n">rectangle_area</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="n">roc_auc_sklearn</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true_binary</span><span class="p">,</span> <span class="n">y_pred_binary</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;sklearn roc_auc_score: </span><span class="si">{</span><span class="n">roc_auc_sklearn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>reighns roc_auc_score: 0.75
sklearn roc_auc_score: 0.75
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># alternatively, we can use np.trapz to calculate the area under the curve.</span>
<span class="n">roc_area</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trapz</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">tpr_reighns</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">fpr_reighns</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">roc_area</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>0.75
</code></pre></div>
<h3 id="couple-roc-with-brier-score">Couple ROC with Brier Score</h3>
<p>https://medium.com/@penggongting/understanding-roc-auc-pros-and-cons-why-is-bier-score-a-great-supplement-c7a0c976b679</p>
<h3 id="summary"><strong>Summary</strong></h3>
<ol>
<li>AUC is a threshold-free metrics capable of measuring the overall performance of binary classifier.</li>
<li>AUC should be used in binary classification. In multinomial classification, one-to-rest AUC would be an option using the average of each class.</li>
<li>AUC is a good metric when the rank of output probabilities is of interest.</li>
<li>Note that if you have 2 classes, then finding the AUROC of the positive class (class 1) is equivalent to 1 minus the AUROC of the negative class (class 0). This is not true when we deal with PR-curve.</li>
<li><strong>Although AUC is powerful, it is not a cure-all. AUC is not suitable for heavily imbalanced class distribution and when the goal is to have well-calibrated probabilities.</strong></li>
<li>Models with maximized AUC treat the weight between positive and negative class equally.</li>
<li>
<p>AUROC would be the metric to use if the goal of the model is to perform equally well on both classes. Image classification between cats &amp; dogs is a good example because the performance on cats is equally important on dogs. </p>
<p>AUPRC would be the metric to use if the focus of the model is to identify correctly as many <strong>positive</strong> samples as possible. Take spam detectors for example, the goal is to find all the possible spams. Regular emails are not of interest at all  they overshadow the number of positives.</p>
<p>There are no defined rules to select the suitable metrics. It really depends on the data and the application. It is important to think thoroughly about the purpose of the model before jumping into the modeling process.</p>
<p>One thing to note here is that the PR AUC serves as an alternative metric. If the model doesnt work after the metric is changed, there are still other remedies to deal with imbalanced data, such as downsampling/upsampling. Well cover it later in future posts.</p>
</li>
</ol>
<h3 id="sklearn-definition-of-binary-classification-roc-auc">SKLEARN Definition of Binary Classification ROC-AUC</h3>
<div class="highlight"><pre><span></span><code>sklearn.metrics.roc_auc_score(y_true, y_score, *, average=&#39;macro&#39;, sample_weight=None, max_fpr=None, multi_class=&#39;raise&#39;, labels=None)
</code></pre></div>
<p><strong>y_score: array-like of shape (n_samples,) or (n_samples, n_classes)</strong></p>
<p>Target scores. In the binary and multilabel cases, these can be either probability estimates or non-thresholded decision values (as returned by decision_function on some classifiers). In the multiclass case, these must be probability estimates which sum to 1. The binary case expects a shape (n_samples,), and the scores must be the scores of the class with the greater label. The multiclass and multilabel cases expect a shape (n_samples, n_classes). In the multiclass case, the order of the class scores must correspond to the order of labels, if provided, or else to the numerical or lexicographical order of the labels in y_true.</p>
<p>Understanding the binary case is important, it says that the binary case expects a list/array of shape <code>(n_samples,)</code>, a 1d-array, where the scores inside the 1d-array must be the scores of the <strong>greater label</strong>. In other words, if you have class 0 and 1, then the greater label is <code>np.argmax(0,1) = 1</code>. As a consequence, it is important that you should only pass the "positive class" which is the "greater label" here into the <code>y_score</code>. </p>
<p>In multiclass, there are two cases, either you provide a <code>labels</code> argument in, say <code>labels = [0,2,1]</code> or <code>labels = [0,1,2]</code>, or if you do not provide, then the <code>y_score</code> will necessarily be in the order of the numerical/alphabetical order of the labels in <code>y_true</code>. In other words, if <code>y_true</code> has 3 unique labels: 0, 1 and 2; then the <code>y_score</code> will be a <strong>2d-array</strong> in the form of <code>y_score = [[0.2, 0.3, 0.5],[...],[...]]</code> where <code>y_score[0] = [0.2,0.3,0.5]</code> must correspond to class 1, 2 and 3 respectively, unless otherwise stated in <code>labels</code>.</p>
<h3 id="first-interpretation">First Interpretation</h3>
<p>Now ROC curve is a TPR vs FPR graph, and the AUC is the area under the curve literally. To find the ROC-AUC, we need to plot many different pairs of points on the graph, and compute the area under it.</p>
<p>As we can see from the above naive and simple example, there are a total of 6 pairs of points to plot. Those are from <code>fpr</code>, <code>tpr</code> respectively --&gt; Allow me to further explain with this example where 1 is the positive class:</p>
<div class="highlight"><pre><span></span><code>y_true_1 = [0,0,1,1,0,0,1,1]
y_preds_1 = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8]
</code></pre></div>
<ol>
<li>
<p>We need to initialize the thresholds with a large number usually - usually <code>roc_curve</code> is written so that ROC point corresponding to the highest threshold <code>(fpr[0], tpr[0])</code> is always <code>(0, 0)</code>. If this is not the case, a new threshold is created with an arbitrary value of <code>max(y_score)+1</code>. Therefore, in this case, we get 1.8 as the first threshold. This large number will ensure the <code>fpr, tpr</code> starts at (0,0).</p>
</li>
<li>
<p>Next, when the threshold is <span class="arithmatex">\(T=0.8\)</span>, then one can see that <code>y_preds_1</code> has 1 predictions 1, so <code>y_preds_1=[0,0,0,0,0,0,0,1]</code> and hence we can calculate the FPR and TPR: FPR will be 0 because no negative samples 0 are misclassified as 1 in our prediction. TPR will be 0.25 because by definition TPR=TP/TP+FN = 1/1+3=0.25 by definition. Therefore <code>(fpr, tpr) = (0,0.25)</code></p>
</li>
<li>
<p><span class="arithmatex">\(T=0.7 \rightarrow\)</span> <code>y_preds_1 = [0,0,0,0,0,0,1,1]</code>, same logic, FPR will be 0 cause no negative samples 0 are classified as 1 by our classifier! But TPR will be 0.5 because TPR = TP/TP+FN = 2/2+2 = 0.5. Therefore <code>(fpr, tpr) = (0,0.5)</code></p>
</li>
<li>
<p>We continue this way until we exhaust all thresholds given <code>[array([1.8, 0.8, 0.7, 0.5, 0.3, 0.1])]</code>. And we plot on the graph. </p>
</li>
<li>
<p>How then, do we calculate the area under this curve? One can refer to the source code <code>auc</code> in <code>sklearn.metrics.auc</code> and see that they used <strong><a href="https://en.wikipedia.org/wiki/Trapezoidal_rule">Trapezoidal Rule</a></strong> to solve it.</p>
</li>
<li>
<p>So one have a rough idea, how the <code>ROC-AUC</code> area is computed, and one has to bear in mind that the area is calculated over all thresholds (apparently not the case as <code>sklearn</code> discretized the thresholds to reduce computing time, so you will not see the full range of thresholds here). </p>
</li>
</ol>
<h2 id="precision-recall-curve"><strong>Precision-Recall Curve</strong></h2>
<h3 id="loss-function-and-decision-function">Loss function and Decision Function</h3>
<p><a href="https://stats.stackexchange.com/questions/104988/what-is-the-difference-between-a-loss-function-and-decision-function">Loss function and decision Function link</a></p>
<p>A <strong>decision function</strong> is a function which takes a dataset as input and gives a decision as output. What the decision can be depends on the problem at hand. Examples include:</p>
<ul>
<li><em>Estimation problems:</em> the "decision" is the estimate.</li>
<li><em>Hypothesis testing problems:</em> the decision is to reject or not reject the null hypothesis. Think of Linear Regression problems, they are mostly related to hypothesis testing.</li>
<li><em>Classification problems:</em> the decision is to classify a new observation (or observations) into a category.</li>
<li><em>Model selection problems:</em> the decision is to chose one of the candidate models.</li>
</ul>
<p>Typically, there are an infinite number of decision functions available for a problem. If we for instance are interested in estimating the height of Swedish males based on ten observations <span class="arithmatex">\(\mathbf{x}=(x_1,x_2,\ldots,x_{10})\)</span>, we can use any of the following decision functions <span class="arithmatex">\(d(\mathbf{x})\)</span>:</p>
<ul>
<li>The sample mean: <span class="arithmatex">\(d(\mathbf{x})=\frac{1}{10}\sum_{i=1}^{10}x_i\)</span>.</li>
<li>The median of the sample: <span class="arithmatex">\(d(\mathbf{x})=\mbox{median}(\mathbf{x})\)</span></li>
<li>The geometric mean of the sample: <span class="arithmatex">\(d(\mathbf{x})=\sqrt[10]{x_1\cdots x_{10}}\)</span></li>
<li>The function that always returns 1: <span class="arithmatex">\(d(\mathbf{x})=1\)</span>, regardless of the value of <span class="arithmatex">\(\mathbf{x}\)</span>. Silly, yes, but it is nevertheless a valid decision function.</li>
</ul>
<p>How then can we determine which of these decision functions to use? One way is to use a <strong>loss function</strong>, which describes the loss (or cost) associated with all possible decisions. Different decision functions will tend to lead to different types of mistakes. The loss function tells us which type of mistakes we should be more concerned about. The best decision function is the function that yields the lowest <strong>expected loss</strong>. What is meant by expected loss depends on the setting (in particular, whether we are talking about <a href="http://en.wikipedia.org/wiki/Frequentist_inference">frequentist</a> or <a href="http://en.wikipedia.org/wiki/Bayesian_statistics">Bayesian</a> statistics).</p>
<p><strong>In summary:</strong> </p>
<ul>
<li>Decision functions are used to make decisions based on data.</li>
<li>Loss functions are used to determine which decision function to use.</li>
</ul>
<h3 id="an-extensive-study-on-precision-recall-curve">An extensive study on Precision-Recall Curve</h3>
<p>Before I start, I will quote <a href="https://www.fharrell.com/post/classification/">Frank Harrell's first</a> and <a href="http://www.fharrell.com/2017/03/damage-caused-by-classification.html">his second</a> article. I will also use the links on stack exchange <a href="https://stats.stackexchange.com/questions/312780/why-is-accuracy-not-the-best-measure-for-assessing-classification-models">here</a> and <a href="https://stats.stackexchange.com/questions/368949/example-when-using-accuracy-as-an-outcome-measure-will-lead-to-a-wrong-conclusio">here</a> by <a href="https://stats.stackexchange.com/users/1352/stephan-kolassa">Stephan Kolassa</a>. They are really good and the entire intuition is from him, I will almost use his intuition verbatim and everything in this section will be credited to the links above; I just find it too difficult to phrase it in my own words because their answers are perfect.</p>
<p>Basically, let me put it up front now: <strong><em>Accuracy, Sensitivity and Specificity are one-sided or conditional versions of classification accuracy. As such they are also discontinuous improper accuracy scores, and optimizing them will result in the wrong model.</em></strong>  </p>
<p>The <code>confusion matrix</code> and the <code>classification report</code> provide a very detailed analysis of a particular set of predictions. However, the predictions themselves already threw away a lot of information that is contained in the model - to explain this statement further: We consider the example of a logistic regression classifier, used to predict whether a patient has cancer (1, positive class) or not (0, negative class). We defined Y as our response variable, outputting only 1 or 0, while <span class="arithmatex">\(X\)</span> is the set of predictors.</p>
<p>In the case of our cancer classification model, (which we assume to be a logistic regression classifier), we remember that the positive class (class = 1) is the patient has cancer, and the negative class (class = 0) is the patient does not have cancer. And to delve a little deeper, our default classification threshold is:</p>
<p><span class="arithmatex">\(\begin{equation}
 Y=\begin{cases}
1, &amp; \text{if <span class="arithmatex">\(P(Y=1 ~|~X) \geq 0.5\)</span>}\
0, &amp; \text{if <span class="arithmatex">\(P(Y=1~|~X) &lt; 0.5\)</span>}\\
\end{cases} \end{equation}\)</span></p>
<p>which means that whenever our logistic regression outputs a probability of the patient getting cancer is more than <span class="arithmatex">\(0.5\)</span>, we classify the patient to be in the positive class (predict him/her to have cancer). When we use the <code>LogisticClassifier()</code> to fit and predict, we are actually predicting the probability <span class="arithmatex">\(p(X)\)</span>, i.e.the probability of the patient having cancer given predictors X; Consequently, we need to further set a threshold, or to make a decision on whether to classify a patient as cancer or benign based on the probability we get from <span class="arithmatex">\(<span class="arithmatex">\(p(X) = \dfrac{e^{\beta_0}+\beta_1X_1+...+\beta_nX_n}{1+ e^{\beta_0}+\beta_1X_1+...+\beta_nX_n}\)</span>\)</span></p>
<p>The threshold is defaulted to 0.5 in <code>predict_proba</code>. As we discussed earlier, most classifiers provide a <code>decision_function</code> or a <code>predict_proba</code> method to assess degrees of certainty about predictions. Making predictions can be seen as thresholding the output of <code>decision_function</code> or <code>predict_proba</code> at a certain fixed point; in binary classification we use 0 for the decision function and 0.5 for predict_proba as default.</p>
<p><br></p>
<p>To fully evaluate the effectiveness of a model, you must examine both precision and recall. Unfortunately, precision and recall are often in tension. That is, improving precision typically reduces recall and vice versa. Explore this notion by looking at the following figure, which shows 30 predictions made by an email classification model. Those to the right of the classification threshold are classified as "spam", while those to the left are classified as "not spam."</p>
<p>Always remember, do not ever just use a single metric like <code>recall, precision</code> to gauge your classifier. This is because your classifier (say <code>SVM()</code> may somehow trivially classify everything as the positive class,  and then you will get 100% recall).</p>
<h3 id="when-to-use-precision-recall">When to use Precision-Recall</h3>
<p><a href="http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf">Precision-Recall curves should be used when there is a moderate to large class imbalance.</a>. In particular, when the positive class</p>
<p>Precision and recall, however, don't consider true negatives and thus won't be affected by the relative imbalance (which is precisely why they're used for imbalanced datasets). </p>
<p><a href="https://www.kaggle.com/general/7517#41179">Kaggle Forum</a></p>
<p>As goes for any metric, your metric depends entirely on what I you mean to do with the data.</p>
<p>I think intuitively you can say that if your model needs to perform equally well on the positive class as the negative class (for example, for classifying images between cats and dogs, you would like the model to perform well on the cats as well as on the dogs. For this you would use the ROC AUC.</p>
<p>On the other hand, if you're not really interested in how the model performs on the negative class, but just want to make sure every positive prediction is correct (precision), and that you get as many of the positives predicted as positives as possible (recall), then you should choose PR AUC. For example, for detecting cancer, you don't care how many of the negative predictions are correct, you want to make sure all the positive predictions are correct, and that you don't miss any. (In fact, in this case missing a cancer would be worse then a false positive so you'd want to put more weight towards recall.)</p>
<p>True negatives need to be meaningful for ROC to be a good choice of measure. In his example, if we've got 1,000 pictures of cats and dogs and our model determines whether the picture is a cat (target = 0) or a dog (target = 1), we probably care just as much about getting the cats right as the dogs, and so ROC is a good choice of metric.</p>
<p>If instead, we've got a collection of 1,000,000 pictures and we build a model to try to identify the 1,000 dog pictures mixed in it, correctly identifying "not-dog" pictures is not quite as useful. Instead, it makes more sense to measure how often a picture is a dog when our model says it's a dog (i.e., precision) and how many of the dogs in the picture set we found (i.e., recall).</p>
<div class="alert alert-block alert-info">
<b>Perspective:</b> In the cancer example above, your AUROC score might be very bad, simply because your False Positives might be high, as a result of minimizing False Negatives, but your AUPRC might be good, because you are maximizing precision!
</div>

<h3 id="when-not-to-use-precision-recall">When NOT to use Precision-Recall</h3>
<div class="alert alert-block alert-danger">
<b>Majority Negative:</b> 
Notice that PR curve does not have TN in their equations, and this implies that PR curves are useful when there are minority positive samples and majority negative samples. But if it is the other way round, with minority negative samples, then PR curve will not tell you useful things.
</div>

<h3 id="implementation-of-pr-curve">Implementation of PR-Curve</h3>
<h2 id="the-debate-auroc-vs-auprc">The Debate: AUROC vs AUPRC</h2>
<p>I just finished reading this discussion. They argue that PR AUC is better than ROC AUC on imbalanced dataset.</p>
<p>For example, we have 10 samples in test dataset. 9 samples are positive and 1 is negative. We have a terrible model which predicts everything positive. Thus, we will have a metric that TP = 9, FP = 1, TN = 0, FN = 0.</p>
<p>Then, Precision = 0.9, Recall = 1.0. The precision and recall are both very high, but we have a poor classifier.</p>
<p>On the other hand, TPR = TP/(TP+FN) = 1.0, FPR = FP/(FP+TN) = 1.0. Because the FPR is very high, we can identify that this is not a good classifier.</p>
<p>Clearly, ROC is better than PR on imbalanced datasets. Can somebody explain why PR is better?</p>
<hr />
<p>Usually when I do imbalanced models, even balanced models, I look at PR for ALL my classes.</p>
<p>In your example, yes, your positive class has P = 0.9 and R = 1.0. But what you should look at are ALL your classes. So for your negative class, your P = 0 and your R = 0. And you usually don't just look at PR scores individually. You want to look at F1-score (F1 macro or F1 micro, depending on your problem) that is a harmonic average of your PR scores for both class 1 and class 0. Your class 1 PR score is super good, but combine that with your class 0 PR score, your F1-score will be TERRIBLE, which is the correct conclusion for your scenario.</p>
<p>TL,DR: Look at PR scores for ALL your classes, and combine them with a metric like F1-score to have a realistic conclusion about your model performance. The F1-score for your scenario will be TERRIBLE, which is the correct conclusion for your scenario.</p>
<h1 id="metrics-for-multi-class-label-classification"><strong>Metrics for Multi-Class-Label Classification</strong></h1>
<p>Most Metrics discussed in Binary Classification can be extended to Multi-Class Classification.</p>
<h2 id="multi-class-roc">Multi-Class ROC</h2>
<h3 id="intuition_1">Intuition</h3>
<p>ROC is originally used for Binary Classification only, a natural extension to Multi-Class model is the 
In multi-class model, we can plot N number of AUC ROC Curves for N number classes using One vs ALL methodology. So for Example, If you have three classes named X, Y and Z, you will have one ROC for X classified against Y and Z, another ROC for Y classified against X and Z, and a third one of Z classified against Y and X.</p>
<p>Firstly, you need to make use of the below code in <a href="https://github.com/scikit-learn/scikit-learn/blob/0fb307bf3/sklearn/metrics/_ranking.py#L690">source</a> where we are using the concept of One-Vs-All (ovr) and first thing first, for all <code>y_true</code> labels, we need to <code>label_binarize</code> them. As we can see, we must pass in the <code>y_true</code> and <code>classes</code> in which if our classes are <code>[0,1,2,3,4,5]</code> then we need to specify in the <code>labels</code> argument of <code>roc_auc_curve</code>. If we do not specify, the <code>_encode</code> will help us as well, so it is up to one's preference if your labels order matter.</p>
<div class="highlight"><pre><span></span><code><span class="k">else</span><span class="p">:</span>
    <span class="c1"># ovr is same as multi-label</span>
    <span class="n">y_true_multilabel</span> <span class="o">=</span> <span class="n">label_binarize</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_average_binary_score</span><span class="p">(</span><span class="n">_binary_roc_auc_score</span><span class="p">,</span> <span class="n">y_true_multilabel</span><span class="p">,</span>
                                 <span class="n">y_score</span><span class="p">,</span> <span class="n">average</span><span class="p">,</span>
                                 <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</code></pre></div>
<h3 id="implementation-of-ovr-multi-class-roc">Implementation of OVR Multi-Class ROC</h3>
<h4 id="step-1-problem-setup_1">Step 1: Problem Setup</h4>
<ul>
<li>Multi-Class: 3 classes of 0, 1 and 2. </li>
<li>Number of samples: 4 </li>
<li>Predictions: output using Softmax</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">scipy</span>
<span class="n">y_true_multiclass</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">y_logit_multiclass</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="mf">0.0802</span><span class="p">,</span> <span class="mf">0.0347</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.2640</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0701</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0087</span><span class="p">,</span> <span class="mf">0.0502</span><span class="p">,</span> <span class="mf">0.0039</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.0496</span><span class="p">,</span> <span class="mf">0.0059</span><span class="p">,</span> <span class="mf">0.0123</span><span class="p">],</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">y_pred_multiclass</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">y_logit_multiclass</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">y_pred_multiclass</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="mf">0.34</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.29</span><span class="p">,</span> <span class="mf">0.32</span><span class="p">],</span> 
        <span class="p">[</span><span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">],</span> 
        <span class="p">[</span><span class="mf">0.34</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">]]</span>
<span class="p">)</span>
</code></pre></div>
<h4 id="step-2-binarize">Step 2: Binarize</h4>
<p>We need to binarize the <code>y_true_multiclass</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
</code></pre></div>
<p>where we need to interpret as follows:</p>
<table>
<thead>
<tr>
<th>Class 1</th>
<th>Class 2</th>
<th>Class 3</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>where [1,0,0,0] (first column) represents the case where class 1 is the <strong>positive class</strong> and class 2 and 3 are considered the negative class (both are class 0). </p>
<table>
<thead>
<tr>
<th>Class 1 Preds</th>
<th>Class 2 Preds</th>
<th>Class 3 Preds</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.34</td>
<td>0.33</td>
<td>0.33</td>
</tr>
<tr>
<td>0.4</td>
<td>0.29</td>
<td>0.32</td>
</tr>
<tr>
<td>0.33</td>
<td>0.35</td>
<td>0.33</td>
</tr>
<tr>
<td>0.34</td>
<td>0.33</td>
<td>0.33</td>
</tr>
</tbody>
</table>
<p>where [0.34, 0.4, 0.33, 0.34] (first column) represents the probability of class 1 being the positive class. And to avoid confusion, the second column [0.33, 0.29, 0.35, 0.33] represents the probability of class 2 being the positive class (class 1).</p>
<hr />
<p>Note that I labelled the above as class 1, 2 and 3 but in our code it is class 0, 1 and 2. This does not affect the ultimate score but just note in case of confusion.</p>
<div class="highlight"><pre><span></span><code><span class="n">y_binarize</span><span class="o">=</span><span class="n">sklearn</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">label_binarize</span><span class="p">(</span><span class="n">y_true_multiclass</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_binarize</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>[[1 0 0]
 [0 1 0]
 [0 0 1]
 [0 1 0]]
</code></pre></div>
<h4 id="step-3-roc-score-for-each-class">Step 3: ROC score for each class</h4>
<p>At this step, we calculate the ROC score for each class. We have have 3 different scores, one for each class. That is to say, the first score is class 0 vs the rest, where we treated class 0 as the positive class.</p>
<div class="highlight"><pre><span></span><code><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">fpr_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="n">tpr_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="n">threshold_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="n">roc_auc_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

<span class="k">for</span> <span class="n">label_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
    <span class="n">y_true_for_curr_class</span> <span class="o">=</span> <span class="n">y_binarize</span><span class="p">[:,</span> <span class="n">label_num</span><span class="p">]</span>
    <span class="n">y_pred_for_curr_class</span> <span class="o">=</span> <span class="n">y_pred_multiclass</span><span class="p">[:,</span> <span class="n">label_num</span><span class="p">]</span>

    <span class="c1"># calculate fpr,tpr and thresholds across various decision thresholds; pos_label = 1 because one hot encode guarantees it</span>

    <span class="n">fpr_dict</span><span class="p">[</span><span class="n">label_num</span><span class="p">],</span> <span class="n">tpr_dict</span><span class="p">[</span><span class="n">label_num</span><span class="p">],</span> <span class="n">threshold_dict</span><span class="p">[</span><span class="n">label_num</span><span class="p">]</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span>
        <span class="n">y_true</span><span class="o">=</span><span class="n">y_true_for_curr_class</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_pred_for_curr_class</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>
    <span class="n">roc_auc_dict</span><span class="p">[</span><span class="n">label_num</span><span class="p">]</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr_dict</span><span class="p">[</span><span class="n">label_num</span><span class="p">],</span> <span class="n">tpr_dict</span><span class="p">[</span><span class="n">label_num</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ROC score for class </span><span class="si">{</span><span class="n">label_num</span><span class="si">}</span><span class="s2"> is </span><span class="si">{</span><span class="n">roc_auc_dict</span><span class="p">[</span><span class="n">label_num</span><span class="p">]</span><span class="si">}</span><span class="s2">. </span><span class="se">\n</span><span class="s2">Note we are considering class </span><span class="si">{</span><span class="n">label_num</span><span class="si">}</span><span class="s2"> as the positive class and treating other classes as negative class.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">fpr_dict</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tpr_dict</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">threshold_dict</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>ROC score for class 0 is 0.5. 
Note we are considering class 0 as the positive class and treating other classes as negative class.

ROC score for class 1 is 0.125. 
Note we are considering class 1 as the positive class and treating other classes as negative class.

ROC score for class 2 is 0.6666666666666667. 
Note we are considering class 2 as the positive class and treating other classes as negative class.

{0: array([0.        , 0.33333333, 0.66666667, 1.        ]), 1: array([0. , 0.5, 1. , 1. ]), 2: array([0.        , 0.66666667, 1.        ])}
{0: array([0., 0., 1., 1.]), 1: array([0. , 0. , 0.5, 1. ]), 2: array([0., 1., 1.])}
{0: array([1.4 , 0.4 , 0.34, 0.33]), 1: array([1.35, 0.35, 0.33, 0.29]), 2: array([1.33, 0.33, 0.32])}
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># plotting    </span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_dict</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tpr_dict</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Class 0 vs Rest&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_dict</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">tpr_dict</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Class 1 vs Rest&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_dict</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">tpr_dict</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Class 2 vs Rest&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Multiclass ROC curve&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive rate&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;Multiclass ROC&#39;</span><span class="p">,</span><span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">);</span>    
</code></pre></div>
<p><img alt="png" src="../roc_pr_curve_files/roc_pr_curve_60_0.png" /></p>
<h4 id="step-4-one-vs-rest">Step 4: One Vs Rest</h4>
<p>We will do a arithmetic mean over the scores we get. This concludes the OvR algorithm.</p>
<div class="highlight"><pre><span></span><code><span class="n">macro_average_roc_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">roc_auc_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">macro_average_roc_score</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>0.4305555555555556
</code></pre></div>
<h4 id="step-5-modularize">Step 5: Modularize</h4>
<div class="highlight"><pre><span></span><code><span class="c1"># This code belows also WORKS for Binary class if you are using Softmax Predictions!</span>
<span class="c1"># replicating from https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#multiclass-settings</span>
<span class="k">def</span> <span class="nf">multiclass_roc</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_logit</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
    <span class="n">label_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">fpr</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">tpr</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">roc_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">label_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">class_list</span><span class="p">)):</span>

        <span class="c1"># get y_true_multilabel binarized version for each loop (end of each epoch)</span>
        <span class="n">y_true_multiclass_array</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">label_binarize</span><span class="p">(</span>
            <span class="n">y_true</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_list</span>
        <span class="p">)</span>

        <span class="n">y_true_for_curr_class</span> <span class="o">=</span> <span class="n">y_true_multiclass_array</span><span class="p">[:,</span> <span class="n">label_num</span><span class="p">]</span>
        <span class="n">y_pred_for_curr_class</span> <span class="o">=</span> <span class="n">y_logit</span><span class="p">[:,</span> <span class="n">label_num</span><span class="p">]</span>
        <span class="c1"># calculate fpr,tpr and thresholds across various decision thresholds</span>
        <span class="c1"># pos_label = 1 because one hot encode guarantees it</span>
        <span class="n">fpr</span><span class="p">[</span><span class="n">label_num</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">label_num</span><span class="p">],</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span>
            <span class="n">y_true</span><span class="o">=</span><span class="n">y_true_for_curr_class</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_pred_for_curr_class</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">roc_auc</span><span class="p">[</span><span class="n">label_num</span><span class="p">]</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">[</span><span class="n">label_num</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">label_num</span><span class="p">])</span>
        <span class="n">roc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">[</span><span class="n">label_num</span><span class="p">])</span>
        <span class="c1"># if binary class, the one hot encode will (n_samples,1) and therefore will only need to slice [:,0] ONLY.</span>
        <span class="c1"># that is why usually for binary class, we do not need to use this piece of code, just for testing purposes.</span>
        <span class="c1"># However, it will now treat our 0 (negative class) as positive, hence returning the roc for 0, in which case</span>
        <span class="c1"># to get both 0 and 1, you just need to use 1-roc(0)value</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">roc_auc</span><span class="p">[</span><span class="n">config</span><span class="o">.</span><span class="n">class_list</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">roc_auc</span><span class="p">[</span><span class="n">label_num</span><span class="p">]</span>
            <span class="k">break</span>
    <span class="n">avg_roc_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">roc_scores</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">roc_auc</span><span class="p">,</span> <span class="n">avg_roc_score</span>
</code></pre></div>
<h2 id="multi-label-roc">Multi-Label ROC</h2>
<p>Incidentally, the way we compute OVR Multi-Class ROC can be used in Multi-Label ROC as well.</p>
<h1 id="quadratic-weighted-kappa">Quadratic Weighted Kappa</h1>
<p>The below explanation will correspond to my <a href="https://www.kaggle.com/reighns/understanding-the-quadratic-weighted-kappa/">notebook during the PANDAS competition</a>.</p>
<p>## Table of Contents
1. <a href="#intuition">Intuition of QWK</a>
2. <a href="#confusion">Step 1: Create the NxN histogram matrix O</a> <br>
3. <a href="#weighted">Step 2: Create the Weighted Matrix w</a><br>
4. <a href="#expected">Step 3: Create the Expected Matrix</a> <br>
5. <a href="#qwk">Step 4: Final Step: Weighted Kappa formula and Its python codes</a> </p>
<h2 id="intuition-of-qwk"><strong>Intuition of QWK</strong> <a id="intuition"></a> <a id="intuition"></a></h2>
<p>TLDR: one can skip to the last section on the python code implementation of QWK and also take reference to <a href="https://www.kaggle.com/c/prostate-cancer-grade-assessment/discussion/145105">CPMP's Fast QWK Computation</a> as well.</p>
<p>Kappa or Cohens Kappa is like classification accuracy, except that it is normalized at the baseline of random chance on your dataset: It basically tells you how much better your classifier is performing over the performance of a classifier that simply guesses at random according to the frequency of each class.</p>
<p>First off, we define the formula exactly as mentioned. Quoting from the evaluation page: <strong>Submissions are scored based on the quadratic weighted kappa, which measures the agreement between two outcomes. This metric typically varies from 0 (random agreement) to 1 (complete agreement). In the event that there is less agreement than expected by chance, the metric may go below 0.</strong> </p>
<p><strong>The quadratic weighted kappa is calculated as follows. First, an N x N histogram matrix O is constructed, such that <span class="arithmatex">\(O_{i,j}\)</span> corresponds to the number of <code>isup_grade</code>'s i (actual) that received a predicted value j. An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted values:</strong></p>
<div class="arithmatex">\[w_{i,j} = \dfrac{(i-j)^2}{(N-1)^2}\]</div>
<p><br></p>
<p><strong>An N-by-N histogram matrix of expected outcomes, E, is calculated assuming that there is</strong> <strong><em>no correlation</em></strong> <strong>between values.This is calculated as the outer product between the actual histogram vector of outcomes and the predicted histogram vector, normalized such that E and O have the same sum. </strong></p>
<p><br></p>
<p>Finally, from these three matrices, the quadratic weighted kappa is calculated as:</p>
<div class="arithmatex">\[\kappa = 1 - \dfrac{\sum_{i,j}\text{w}_{i,j}O_{i,j}}{\sum_{i,j}\text{w}_{i,j}E_{i,j}}\]</div>
<p>where <span class="arithmatex">\(w\)</span> is the weighted matrix, <span class="arithmatex">\(O\)</span> is the histogram matrix and <span class="arithmatex">\(E\)</span> being the expected matrix.</p>
<h2 id="step-1-create-the-nxn-histogram-matrix-o"><strong>Step 1: Create the NxN histogram matrix O</strong> <a id="confusion"></a></h2>
<p><strong><em>Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon.</em></strong></p>
<p><strong><em>Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon.</em></strong></p>
<p><strong><em>Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon.</em></strong></p>
<p><br></p>
<p><strong><em>Reminder: Although it is a counter example, it still illustrates what a NxN histogram matrix is! We will now call our histogram matrix C instead because in actual fact, the histogram matrix is merely a multi class confusion matrix between actual and predicted values</em></strong></p>
<p>We use a naive example where there are 5 classes (note our competition is_up grade has 6 classes; but this is just an example. Our <code>y_true</code> is the ground truth labels and correspondingly, our <code>y_pred</code> is the predicted values.</p>
<div class="highlight"><pre><span></span><code><span class="n">y_true</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span>  <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span>   <span class="s1">&#39;cat&#39;</span><span class="p">,</span>  <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;pig&#39;</span><span class="p">,</span>  <span class="s1">&#39;pig&#39;</span><span class="p">,</span> <span class="s1">&#39;hen&#39;</span><span class="p">,</span> <span class="s1">&#39;pig&#39;</span><span class="p">],</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;Actual&#39;</span><span class="p">)</span>
<span class="n">y_pred</span>   <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;hen&#39;</span><span class="p">,</span> <span class="s1">&#39;pig&#39;</span><span class="p">,</span><span class="s1">&#39;bird&#39;</span><span class="p">,</span>  <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;pig&#39;</span><span class="p">,</span> <span class="s1">&#39;pig&#39;</span><span class="p">,</span> <span class="s1">&#39;hen&#39;</span><span class="p">,</span> <span class="s1">&#39;pig&#39;</span><span class="p">],</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ground truth:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted Values:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_pred</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Ground truth:
0    cat
1    cat
2    dog
3    cat
4    cat
5    cat
6    pig
7    pig
8    hen
9    pig
Name: Actual, dtype: object
----------------------------------------
Predicted Values:
0    bird
1     hen
2     pig
3    bird
4    bird
5    bird
6     pig
7     pig
8     hen
9     pig
Name: Predicted, dtype: object
</code></pre></div>
<p>First, an N x N confusion matrix <strong>C</strong> is constructed, such that <span class="arithmatex">\(\text{C}_{i,j}\)</span> is the entry that corresponds to the <strong>number of animal i (actual) that received a predicted value j</strong>. </p>
<div class="highlight"><pre><span></span><code><span class="n">classes</span><span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bird&#39;</span><span class="p">,</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span><span class="s1">&#39;dog&#39;</span><span class="p">,</span><span class="s1">&#39;hen&#39;</span><span class="p">,</span> <span class="s1">&#39;pig&#39;</span><span class="p">]</span>

<span class="c1"># thank you https://datascience.stackexchange.com/questions/40067/confusion-matrix-three-classes-python </span>
<span class="k">def</span> <span class="nf">plot_confusion_matrix</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span>
                          <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                          <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Confusion matrix&#39;</span><span class="p">,</span>
                          <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function prints and plots the confusion matrix.</span>
<span class="sd">    Normalization can be applied by setting `normalize=True`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="n">cm</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Normalized confusion matrix&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Confusion matrix, without normalization&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
    <span class="n">tick_marks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>

    <span class="n">fmt</span> <span class="o">=</span> <span class="s1">&#39;.2f&#39;</span> <span class="k">if</span> <span class="n">normalize</span> <span class="k">else</span> <span class="s1">&#39;d&#39;</span>
    <span class="n">thresh</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">/</span> <span class="mf">2.</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="nb">format</span><span class="p">(</span><span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">fmt</span><span class="p">),</span>
                 <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
                 <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span> <span class="k">if</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">thresh</span> <span class="k">else</span> <span class="s2">&quot;black&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True label&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted label&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="n">cnf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;bird&#39;</span><span class="p">,</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span><span class="s1">&#39;dog&#39;</span><span class="p">,</span><span class="s1">&#39;hen&#39;</span><span class="p">,</span> <span class="s1">&#39;pig&#39;</span><span class="p">],)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Plot non-normalized confusion matrix</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;bird&#39;</span><span class="p">,</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span><span class="s1">&#39;dog&#39;</span><span class="p">,</span><span class="s1">&#39;hen&#39;</span><span class="p">,</span> <span class="s1">&#39;pig&#39;</span><span class="p">],</span>
                      <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Confusion matrix C, without normalization&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>&lt;Figure size 432x288 with 0 Axes&gt;



Confusion matrix, without normalization
</code></pre></div>
<p><img alt="png" src="../roc_pr_curve_files/roc_pr_curve_75_2.png" /></p>
<h3 id="example-using-our-competitions-dataset">Example using our competition's dataset</h3>
<p>The above matrix is a <strong>multi class confusion matrix</strong>. As an example, for the 2nd row, we predicted 4 cats to be birds, and 1 cat to be predicted as hen. More compactly, it can be represented as the matrix <span class="arithmatex">\(C_{2,1}\)</span> = 4.</p>
<p>We can easily reconcile our example above to relate back to our competition: <strong>After the biopsy is assigned a Gleason score, it is converted into an ISUP grade on a 1-5 scale</strong>. For now, I will include the label <strong>0</strong> because it is the background/non-tissue. </p>
<p>What I do next is to take the ground truth and call it <code>y_true</code> which is a series. I then generate a dummy <code>y_pred</code> by using <code>np.random.choice</code> and randomly generate numbers from 0 to 5.</p>
<div class="highlight"><pre><span></span><code><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/datasets/prostate-cancer-grade-assessment-train.csv&quot;</span><span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">isup_grade</span>
<span class="n">y_true</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">10616</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">y_pred</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>0        0
1        0
2        4
3        4
4        0
        ..
10611    0
10612    5
10613    0
10614    2
10615    4
Name: isup_grade, Length: 10616, dtype: int64






0        2
1        2
2        4
3        1
4        5
        ..
10611    2
10612    2
10613    1
10614    5
10615    1
Length: 10616, dtype: int32
</code></pre></div>
<p>The following confusion matrix, is what we mean by the "N by N" (6 by 6) <strong>histogram matrix</strong>. </p>
<div class="highlight"><pre><span></span><code><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],)</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
                      <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Confusion matrix C, without normalization&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Confusion matrix, without normalization
</code></pre></div>
<p><img alt="png" src="../roc_pr_curve_files/roc_pr_curve_81_1.png" /></p>
<p><strong><em>So far we have settled the first portion, construction the histogram matrix.</em></strong></p>
<h2 id="step-2-create-the-weighted-matrix-w"><strong>Step 2: Create the Weighted Matrix w</strong> <a id ="weighted"></a></h2>
<p>An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted rating scores. The formula is as follows:  <span class="arithmatex">\(<span class="arithmatex">\(w_{i,j} = \dfrac{(i-j)^2}{(N-1)^2}\)</span>\)</span></p>
<p>Under Step-2, each element is weighted. Predictions that are further away from actuals are marked harshly than predictions that are closer to actuals. However, I suddenly realized that these animals above have no obvious hierarchy in them. Therefore, it is not correct to say that predicting a cat as a bird is any better/worse off than predicting a cat as hen.</p>
<p><strong>Consequently, this is a realization. Because now I start to understand why certain competitions use metrics like quadratic weighted kappa!</strong> Consider the same example as animals just now, but instead of animals, we change to <strong>isup_grade</strong>). So there is an inherent order within the <strong>isup_grade</strong> 0 - 5 such that 0 and 1 is closer than 0 and 2, 1 and 2 is closer to 1 and 3 etc. <span class="arithmatex">\(<span class="arithmatex">\(0 &gt; 1 &gt; 2 &gt; 3 &gt; 4 &gt; 5\)</span>\)</span></p>
<p><br></p>
<p>For example, let's use a simplified example:</p>
<div class="highlight"><pre><span></span><code>y_true = [2,2,2,1,2,3,4,5,0,1]
y_pred = [1,2,4,1,2,3,4,5,0,1]
</code></pre></div>
<p>As a result, our purpose of the weighted matrix is to allocate a higher penalty score if our prediction is further away from the actual value. That is, if our <strong>isup_grade</strong> is 2 but we predicted it as 1 (see the example), then based on our formula above, we have i = 2 and j = 1 (entry <span class="arithmatex">\(C_{2,1}\)</span>), the penalty is <span class="arithmatex">\(<span class="arithmatex">\(\dfrac{(2-1)^2}{(5-1)^2}  = 0.0625\)</span>\)</span> but if our <strong>isup_grade</strong> is 2 and we predicted it as 4 (see the example), then the penalty involved is higher <span class="arithmatex">\(<span class="arithmatex">\(\dfrac{(2-4)^2}{(5-1)^2} = 0.25\)</span>\)</span></p>
<p>Indeed, the weight matrix helped us assign a heavier penalty to predicting 2 as 4 than 2 as 1.</p>
<p><strong><em>Lastly, we also observe that the formula will give us 0 for the diagonals of the weighted matrix. This means penalty is 0 whenever we correctly predict something.</em></strong></p>
<p>To calculate weighted matrix in python code, here is the code with reference to <a href="https://www.kaggle.com/aroraaman/quadratic-kappa-metric-explained-in-5-simple-steps">Aman Arora</a>.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># We construct the weighted matrix starting from a zero matrix, it is like constructing a </span>
<span class="c1"># list, we usually start from an empty list and add things inside using loops.</span>

<span class="k">def</span> <span class="nf">weighted_matrix</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">weighted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">))</span> 
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weighted</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weighted</span><span class="p">)):</span>
            <span class="n">weighted</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(((</span><span class="n">i</span><span class="o">-</span><span class="n">j</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> 
    <span class="k">return</span> <span class="n">weighted</span>

<span class="nb">print</span><span class="p">(</span><span class="n">weighted_matrix</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>[[0.   0.06 0.25 0.56 1.  ]
 [0.06 0.   0.06 0.25 0.56]
 [0.25 0.06 0.   0.06 0.25]
 [0.56 0.25 0.06 0.   0.06]
 [1.   0.56 0.25 0.06 0.  ]]
</code></pre></div>
<p><strong><em>Remember, the further away from the diagonal you get, the worse off is your prediction and it will be penalized harder by a bigger weight.</em></strong>  As you can easily infer from the weighted matrix above, we use the first row as an example in case one did not understand. Basically, the weighted matrix's first row's first element is 0, because it means we predicted correctly and no penalty is meted out; but as we move further to the left, you can see that the punishment gets harsher and harsher: <span class="arithmatex">\(<span class="arithmatex">\(0 &lt; 0.06 &lt; 0.25 &lt; 0.56 &lt; 1\)</span>\)</span></p>
<h2 id="step-3-create-the-expected-matrix"><strong>Step 3: Create the Expected Matrix</strong> <a id ="expected"></a></h2>
<div class="highlight"><pre><span></span><code><span class="c1">## dummy example </span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span> 
<span class="n">pred</span>   <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span> 
<span class="n">C</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

<span class="n">N</span><span class="o">=</span><span class="mi">5</span>
<span class="n">act_hist</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">N</span><span class="p">])</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">actual</span><span class="p">:</span> 
    <span class="n">act_hist</span><span class="p">[</span><span class="n">item</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">+=</span><span class="mi">1</span>

<span class="n">pred_hist</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">N</span><span class="p">])</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">:</span> 
    <span class="n">pred_hist</span><span class="p">[</span><span class="n">item</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">+=</span><span class="mi">1</span>


<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Actuals value counts:</span><span class="si">{</span><span class="n">act_hist</span><span class="si">}</span><span class="s1">, </span><span class="se">\n</span><span class="s1">Prediction value counts:</span><span class="si">{</span><span class="n">pred_hist</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Actuals value counts:[0. 3. 1. 1. 5.], 
Prediction value counts:[4. 4. 2. 0. 0.]
</code></pre></div>
<p>This part is the most difficult to understand, especially for someone who has little statistic backgrounds (mind you when I was majoring in applied math back then, I only took <strong>one</strong> statistic module in my whole tenure.) Googling the idea of expected matrix is not apparently clear to me, but luckily someone pointed to me to read expected frequency of Chi-Square test and then and, there I start to slowly understand.</p>
<p>For the purpose of better understanding, we call our actual values to be rater A and our prediction model to be rater B. We want to quantify the agreement between rater A and rater B. Here are some terminologies to get hold of first.</p>
<ul>
<li>There are a total number of <span class="arithmatex">\(k = 5\)</span> classes in this example;</li>
<li>There are a total number of <span class="arithmatex">\(n = 10\)</span> observations in this example;</li>
<li>Define Y to be the random variable that rater A has chosen (aka our actual classes 1,2,3,4,5);</li>
<li>and <span class="arithmatex">\(\widehat{Y}\)</span> be the random variable that rater <span class="arithmatex">\(B\)</span> has chosen (aka our predicted classes 1,2,3,4,5 by rater B)</li>
<li><span class="arithmatex">\(r_i\)</span> be the i-th entry of the column vector for actual value counts shown above, <span class="arithmatex">\(c_i\)</span> be the i-th entry of the column vector for prediction value counts shown above.
<br></li>
</ul>
<p>Then the probability of rater A choosing class 2 and rater B choosing class 2 for example, is given by <span class="arithmatex">\(<span class="arithmatex">\(P(Y = 2 \text{ and } \widehat{Y} = 2)  = P(Y = 2) \cdot P(\widehat{Y} = 2) = 30\% \times 40\%  = 12\%\)</span>\)</span></p>
<p>This is under the assumption that both raters are <strong>independent of each other</strong>. Note that <span class="arithmatex">\(P(Y = 2) = 30\%\)</span> because as we see from the actual value counts of rater <span class="arithmatex">\(A\)</span>, there are a total of 3 class 2's and therefore the probability of Y being 2 is just the proportion. Similarly, we calculate <span class="arithmatex">\(\widehat{Y}\)</span> the same way.</p>
<p>In general, the formula of rater A choosing class i and rater B choosing (predicting) class j is given as follows: <span class="arithmatex">\(<span class="arithmatex">\(P(Y = i \text{ and }  \widehat{Y} = j) =  P(Y = i) \times P (\widehat{Y} = j)\)</span>\)</span></p>
<p><br></p>
<p>Now the real question comes: On average, if you have <span class="arithmatex">\(n\)</span> number of points to predict, how many times (what is the frequency) would you <strong>expect</strong> to see rater A choose class i and rater B choose class j.</p>
<p>To reiterate, recall that the probability of the actual class being 1 <strong>and (super important word here, it means a joint distribution)</strong> and the predicted class to be 1 as well is <span class="arithmatex">\(P(Y = 1 \text{ and }  \widehat{Y} = 1)\)</span>, similarly, the probability of the actual class being 1 and the predicted class to be 2 is <span class="arithmatex">\(P(Y = 1 \text{ and }  \widehat{Y} = 2)\)</span>. Generalizing, the probability of the actual class being <span class="arithmatex">\(i\)</span> and the predicted class being <span class="arithmatex">\(j\)</span> is the joint probability <span class="arithmatex">\(<span class="arithmatex">\(P(Y = i \text{ and }  \widehat{Y} = j)\)</span>\)</span></p>
<p>So the intuition lies here: based on the joint probability above, what is the expected number of times (frequency) that <span class="arithmatex">\(Y = i\)</span> and <span class="arithmatex">\(\widehat{Y} = j\)</span> happened (this means Y is i but rater B predict <span class="arithmatex">\(\widehat{Y}\)</span> as j) out of 10 times? Easy, just use <span class="arithmatex">\(n \times P(Y = i \text{ and }  \widehat{Y} = j)\)</span>. So for rater B, our prediction model, <strong>by just using theoretical probability</strong>, should have <span class="arithmatex">\(n \times P(Y = i \text{ and }  \widehat{Y} = j)\)</span> for each <span class="arithmatex">\(i,j\)</span>. But in reality, this may not be the case. Reconcile this idea with the classic coin toss example:</p>
<ul>
<li>
<p><strong>Example on coin toss:</strong> Expected frequency is defined as the number of times that we predict an event will occur based on a calculation using theoretical probabilities. You know how a coin has two sides, heads or tails? That means that the probability of the coin landing on any one side is 50% (or 1/2, because it can land on one side out of two possible sides). If you flip a coin 1,000 times, how many times would you expect to get heads? About half the time, or 500 out of the 1,000 flips. To calculate the expected frequency, all we need to do is multiply the total number of tosses (1,000) by the probability of getting a heads (1/2), and we get 1,000 * 1/2 = 500 heads. if event A has prob of p happening, and sample size of n, then the average or expected number of times that A happens is <span class="arithmatex">\(np\)</span>. The expected frequency of heads is 500 out of 1,000 total tosses. The expected frequency is based on our knowledge of probability - we haven't actually done any coin tossing. However, if we had enough time on our hands, we could actually flip a coin 1,000 times to experimentally test our prediction. If we did this, we would be calculating the experimental frequency. The experimental frequency is defined as the number of times that we observe an event to occur when we actually perform an experiment, test, or trial in real life. If you flipped a coin 1,000 times and it landed on heads 479 times, then the experimental frequency of heads is 479.</p>
<p>But wait - didn't we predict the coin would land on heads 500 times? Why did it actually land on heads only 479 times? Well, the expected frequency was just that - what we expected to happen, based on our knowledge of probability. There are no guarantees when it comes to probability, what we expect to happen might differ from what actually happens. </p>
</li>
</ul>
<p><br></p>
<p>Since we know <span class="arithmatex">\(<span class="arithmatex">\(E_{2,2} = 10 \times P(Y = 2 \text{ and } \widehat{Y} = 2)  = 10 \times P(Y = 2) \cdot P(\widehat{Y} = 2) = 10 \times 30\% \times 40\%  = 1.2\)</span>\)</span></p>
<p>This <span class="arithmatex">\(E_{2,2}\)</span> means that we only expect the rater A to choose 2 and rater B to choose 2 at the same time only 1.2 times out of 10 times. In other words, our predicted model classify 2 as 2 1.2 times. However, from our observations in our matrix C (confusion/histogram matrix), rater A choosing 2 and rater B choosing 2 have a frequency of 3! In other words, our predicted model classified 2 as 2 three times! So we kinda exceeded expectation for this particular configuration.</p>
<div class="arithmatex">\[C = \begin{bmatrix}
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 3 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
4 &amp; 0 &amp; 1 &amp; 0 &amp; 0\\
\end{bmatrix}\]</div>
<p>Let me give you one more example, <span class="arithmatex">\(<span class="arithmatex">\(E_{5,2} = 10 \times P(Y = 5 \text{ and } \widehat{Y} = 2) = 10 \times P(Y = 5) \cdot P(\widehat{Y} = 2) = 10 \times 50\% \times 40\%  = 2\)</span>\)</span></p>
<p>This means that we only expect the rater A to choose 5 and rater B to choose 2 at the same time only 2 times out of 10 times! But in reality, our observations say that our rater B classified 5 as 2 zero times! </p>
<p>We calculate <span class="arithmatex">\(E_{i,j}\)</span> given by the formula: <span class="arithmatex">\(<span class="arithmatex">\(E_{i,j} = n \times P(Y = i \text{ and }  \widehat{Y} = j) = n \times P(Y = i) \times P (\widehat{Y} = j) = n \times \dfrac{r_i}{n} \times \dfrac{c_j}{n}\)</span>\)</span></p>
<div class="arithmatex">\[E = \begin{bmatrix}
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
1.2 &amp; 1.2 &amp; 0.6 &amp; 0 &amp; 0 \\
0.4 &amp; 0.4 &amp; 0.2 &amp; 0 &amp; 0\\
0.4 &amp; 0.4 &amp; 0.2 &amp; 0 &amp; 0\\
2 &amp; 2 &amp; 1 &amp; 0 &amp; 0\\
\end{bmatrix}\]</div>
<p>Note <span class="arithmatex">\(r_i \times c_j\)</span> is the <span class="arithmatex">\((i,j)\)</span> entry of the outer product between the actual histogram vector of outcomes (actual value counts) and the predicted histogram vector (prediction value counts).</p>
<p>What does the random chance mean here? Simple, it just means that the probability for rater A (actual) to be class i AND for rater B (predicted) to be class j is <span class="arithmatex">\(p\%\)</span> (say 10%). Therefore, if we have made 100 predictions, random chance aka the theoratical probability tells us you should only have <span class="arithmatex">\(100 \times 10\% = 10\)</span> predictions to be of this configuration (rater A class i AND rater B class j).</p>
<h4 id="writing-out-the-expected-matrix-in-python">Writing out the expected matrix in python</h4>
<p>So to get the expected matrix, E, is calculated assuming that there is no correlation between values.  This is calculated as the outer product between the actual histogram vector of outcomes and the predicted histogram vector, normalized such that E and C have the same sum. Note carefully below that we do not need to normalize both, we just need to normalize E to the same sum as C.</p>
<div class="highlight"><pre><span></span><code><span class="n">E</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">act_hist</span><span class="p">,</span> <span class="n">pred_hist</span><span class="p">)</span><span class="o">/</span><span class="mi">10</span>


<span class="n">E</span>
<span class="n">C</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>array([[0. , 0. , 0. , 0. , 0. ],
       [1.2, 1.2, 0.6, 0. , 0. ],
       [0.4, 0.4, 0.2, 0. , 0. ],
       [0.4, 0.4, 0.2, 0. , 0. ],
       [2. , 2. , 1. , 0. , 0. ]])






array([[0, 0, 0, 0, 0],
       [0, 3, 0, 0, 0],
       [0, 0, 1, 0, 0],
       [0, 1, 0, 0, 0],
       [4, 0, 1, 0, 0]], dtype=int64)
</code></pre></div>
<h2 id="step-4-final-step-weighted-kappa-formula-and-its-python-codes"><strong>Step 4: Final Step: Weighted Kappa formula and Its python codes</strong> <a id="qwk"></a></h2>
<p>From these three matrices: E, C and weighted, the quadratic weighted kappa is calculated as: </p>
<div class="arithmatex">\[\kappa = 1 - \dfrac{\sum_{i,j}\text{weighted}_{i,j}C_{i,j}}{\sum_{i,j}\text{weighted}_{i,j}E_{i,j}}\]</div>
<p>Note that a higher value generally means your prediction model is way better than a random model, but there is no consensus on which value is really good or bad.</p>
<div class="arithmatex">\[\text{Weighted} = \begin{bmatrix}
0 &amp; 0.0625 &amp; 0.25 &amp; 0.5625 &amp; 1\\
0.0625 &amp; 0 &amp; 0.0625 &amp; 0.25 &amp; 0.5625 \\
0.25 &amp; 0.0625 &amp; 0 &amp; 0.0625 &amp; 0.25\\
0.5625 &amp; 0.25 &amp; 0.0625 &amp; 0 &amp; 0.0625\\
1 &amp; 0.5625 &amp; 0.25 &amp; 0.0625 &amp; 0\\
\end{bmatrix}\]</div>
<p>The notation <span class="arithmatex">\(\sum_{i,j}\text{W}_{i,j}C_{i,j}\)</span> is just <span class="arithmatex">\(<span class="arithmatex">\(\sum_{i=1}^{k}\sum_{j=1}^{k} W_{i,j} C_{i,j} = (W_{1,1}C_{1,1} + W_{1,2}C_{1,2} + ...+ W_{1,k}C_{1,k}) + (W_{2,1}C_{2,1}+...+W_{2,k}C_{2,k}) +...+(W_{k,1}C_{k,1}+...+W_{k,k}C_{k,k})\)</span>\)</span></p>
<p>To put our understanding into perspective, consider just one entry <span class="arithmatex">\(W_{5,1}C_{5,1} = 1 \times 4 = 4\)</span>. This roughly means that our predicted model classified class 5 as class 1 FOUR times (re: <span class="arithmatex">\(C_{5,1} = 4\)</span>), and since class 5 is so far away from class 1, we need to <strong>punish</strong> this wrong prediction more than the others. And we did see that the corresponding weight <span class="arithmatex">\(W_{5,1} = 1\)</span> is the highest weight.</p>
<p>Consequently, the numerator being <span class="arithmatex">\(\sum_{i,j}\text{W}_{i,j}C_{i,j}\)</span> calculates the total "penalty cost" for the rater A (our predicted model), and similarly, <span class="arithmatex">\(\sum_{i,j}\text{W}_{i,j}E_{i,j}\)</span> calculates the total "penalty cost" for the rater B (our "expected" model). Therefore, you can think both values (num and den) as a cost function, and the lesser the better. And kappa formula tells us, if our <span class="arithmatex">\(\sum_{i,j}\text{W}_{i,j}C_{i,j}\)</span> is significantly smaller than <span class="arithmatex">\(\sum_{i,j}\text{W}_{i,j}E_{i,j}\)</span>, this will yield a very small value of <span class="arithmatex">\(<span class="arithmatex">\(\dfrac{\sum_{i,j}\text{weighted}_{i,j}C_{i,j}}{\sum_{i,j}\text{weighted}_{i,j}E_{i,j}}\)</span>\)</span> which will yield a very high kappa value - signifying a better model.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Method 1</span>
<span class="c1"># apply the weights to the confusion matrix</span>
<span class="n">weighted</span> <span class="o">=</span> <span class="n">weighted_matrix</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">num</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">weighted</span><span class="p">,</span> <span class="n">C</span><span class="p">))</span>
<span class="c1"># apply the weights to the histograms</span>
<span class="n">den</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">weighted</span><span class="p">,</span> <span class="n">E</span><span class="p">))</span>

<span class="n">kappa</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">num</span><span class="p">,</span><span class="n">den</span><span class="p">)</span>
<span class="n">kappa</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>-0.13924050632911378
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># Method 2</span>

<span class="n">num</span><span class="o">=</span><span class="mi">0</span>
<span class="n">den</span><span class="o">=</span><span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weighted</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weighted</span><span class="p">)):</span>
        <span class="n">num</span><span class="o">+=</span><span class="n">weighted</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
        <span class="n">den</span><span class="o">+=</span><span class="n">weighted</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">E</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>

<span class="n">weighted_kappa</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">num</span><span class="o">/</span><span class="n">den</span><span class="p">));</span> <span class="n">weighted_kappa</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>-0.13924050632911378
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># Method 3: Just use sk learn library</span>

<span class="n">cohen_kappa_score</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span> <span class="s1">&#39;quadratic&#39;</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>-0.13924050632911378
</code></pre></div>
<p>Just a side note that one can also use SK learn's cohen_kappa_score function calculate the quadratic weighted kappa in this competition, with weights set to quadratic. Also please do refer to <a href="https://www.kaggle.com/c/prostate-cancer-grade-assessment/discussion/145105">CPMP's discussion topic for fast QWK computation</a></p>
<h1 id="references">References</h1>
<p><a href="https://towardsdatascience.com/https-medium-com-abrown004-how-to-ease-the-pain-of-working-with-imbalanced-data-a7f7601f18ba">Reference I</a></p>
<p><a href="https://www.knime.com/blog/correcting-predicted-class-probabilities-in-imbalanced-datasets">Reference II</a></p>
<p><a href="https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28">Reference III</a></p>
<h2 id="accuracy"><strong>Accuracy</strong></h2>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Indicator_function">Indicator Function - Wikipedia</a></li>
<li><a href="https://stats.stackexchange.com/questions/312780/why-is-accuracy-not-the-best-measure-for-assessing-classification-models">Why is accuracy not the best measure for assessing classification models? - StackExchange</a></li>
<li><a href="https://stats.stackexchange.com/questions/368949/example-when-using-accuracy-as-an-outcome-measure-will-lead-to-a-wrong-conclusio">Example when using accuracy as an outcome measure will lead to a wrong conclusion - StackExchange</a></li>
</ul>
<p><strong>Precision-Recall</strong>
- <a href="https://en.wikipedia.org/wiki/Precision_and_recall">Precision-Recall: Estimations of Probabilities - Wikipedia</a>
- <a href="https://stats.stackexchange.com/questions/104988/what-is-the-difference-between-a-loss-function-and-decision-function">Loss function and Decision Function - StatsExchange</a>
- <a href="https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall">Precision and Recall Tradeoff - Google</a></p>
<h2 id="receiver-operating-characteristic-roc_1"><strong>Receiver Operating Characteristic (ROC)</strong></h2>
<h3 id="interpretation-of-roc">Interpretation of ROC</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">Wikipedia has an extensive explanation of the probability behind ROC</a></li>
<li><a href="https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it">Different Interpretations of AUC - StatsExchange</a></li>
<li><a href="https://www.alexejgossmann.com/auc/">Probabilistic Perspective of AUC</a></li>
<li><a href="https://sinyi-chou.github.io/classification-auc/">AUC - Insider's Guide to the Theory and Applications</a></li>
<li><a href="https://www.youtube.com/watch?v=RXMu96RJj_s">Safe Handling Instructions for Probabilistic Classification</a>.</li>
<li><a href="https://stats.stackexchange.com/questions/193138/roc-curve-drawbacks">c-statistics</a>.</li>
<li><a href="https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/173020">SIIM Melanoma ROC</a></li>
<li><a href="https://www.sciencedirect.com/science/article/abs/pii/S016786550500303X">An Introduction to ROC analysis</a></li>
</ul>
<h3 id="pros-and-cons-of-auroc_1">Pros and Cons of AUROC</h3>
<ul>
<li><a href="chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/viewer.html?pdfurl=https%3A%2F%2Fwww.biostat.wisc.edu%2F~page%2Frocpr.pdf&amp;clen=137145&amp;chunk=true">The Relationship Between Precision-Recall and ROC Curves</a></li>
<li><a href="https://stats.stackexchange.com/questions/193138/roc-curve-drawbacks">Drawbacks of AUROC</a>.</li>
<li><a href="https://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves">ROC vs precision-and-recall curves</a></li>
<li><a href="https://stats.stackexchange.com/questions/262616/roc-vs-precision-recall-curves-on-imbalanced-dataset">ROC vs Precision-recall curves on imbalanced dataset</a></li>
<li><a href="https://stats.stackexchange.com/questions/360017/when-is-an-auc-score-misleadingly-high/360040#360040">on why AUC can be misleading</a></li>
<li><a href="https://towardsdatascience.com/an-understandable-guide-to-roc-curves-and-auc-and-why-and-when-to-use-them-92020bc4c5c1">AUC scale and threshold invariant - TDS</a></li>
</ul>
<h3 id="implementation">Implementation</h3>
<ul>
<li><a href="https://towardsdatascience.com/roc-curve-and-auc-from-scratch-in-numpy-visualized-2612bb9459ab">Implementation of ROC - roc-curve-and-auc-from-scratch-in-numpy-visualized - TDS</a></li>
<li>
<p><a href="https://ece.uwaterloo.ca/~dwharder/NumericalAnalysis/13Integration/comptrap/complete.html">Trapezoid Rule</a></p>
</li>
<li>
<p><a href="https://stackoverflow.com/questions/52358114/why-is-roc-curve-return-an-additional-value-for-the-thresholds-2-0-for-some-cl">On why thresholds return 2 sometimes</a>(https://stackoverflow.com/questions/23200518/scikit-learn-roc-curve-why-does-it-return-a-threshold-value-2-some-time)</p>
</li>
<li><a href="https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc#:~:text=ROC%20AUC%20vs%20PR%20AUC&amp;text=What%20is%20different%20however%20is,and%20true%20positive%20rate%20TPR.">PR-Curve vs ROC-Curve</a></li>
<li>https://stackoverflow.com/questions/59666138/sklearn-roc-auc-score-with-multi-class-ovr-should-have-none-average-available</li>
<li>https://stackoverflow.com/questions/39685740/calculate-sklearn-roc-auc-score-for-multi-class</li>
<li>https://datascience.stackexchange.com/questions/36862/macro-or-micro-average-for-imbalanced-class-problems#:~:text=Micro%2Daverage%20is%20preferable%20if,your%20dataset%20varies%20in%20size.</li>
<li>https://www.google.com/search?q=roc_auc_score+multiclass+site:stackoverflow.com&amp;rlz=1C1CHBF_enSG891SG891&amp;sxsrf=ALeKk018tRSfmKgIUw63SPI8dsdkvJgPuw:1608711331403&amp;sa=X&amp;ved=2ahUKEwjg7NDb1OPtAhUXVH0KHVNHCmwQrQIoBHoECAMQBQ&amp;biw=1280&amp;bih=610</li>
<li>https://stackoverflow.com/questions/56227246/how-to-calculate-roc-auc-score-having-3-classes</li>
<li>https://glassboxmedicine.com/2019/02/23/measuring-performance-auc-auroc/</li>
<li>https://stackoverflow.com/questions/56227246/how-to-calculate-roc-auc-score-having-3-classes</li>
</ul>
<hr />
<h2 id="precision-recall-curve_1"><strong>Precision-Recall Curve</strong></h2>
<h3 id="interpretation-of-pr">Interpretation of PR</h3>
<ul>
<li><a href="https://www.fharrell.com/post/class-damage/">Damage Caused by Classification Accuracy and Other Discontinuous Improper Accuracy Scoring Rules - Frank Harrell</a></li>
<li><a href="https://www.fharrell.com/post/classification/">Classification vs. Prediction - Frank Harrell</a></li>
</ul>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../precision_recall_f1/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Precision-Recall-F1" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Precision-Recall-F1
            </div>
          </div>
        </a>
      
      
        
        <a href="../cohens_kappa/" class="md-footer__link md-footer__link--next" aria-label="Next: Cohen&#39;s Kappa" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Cohen's Kappa
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../../../..", "features": ["content.code.annotate"], "search": "../../../../../assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.ed9748b7.min.js"></script>
      
        <script src="../../../../../javascript/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>