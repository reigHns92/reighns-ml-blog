{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b698ab9-d287-4d4c-ac05-67bd95c9666d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\F}{\\mathbb{F}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\v}{\\mathbf{v}}\n",
    "\\newcommand{\\a}{\\mathbf{a}}\n",
    "\\newcommand{\\b}{\\mathbf{b}}\n",
    "\\newcommand{\\c}{\\mathbf{c}}\n",
    "\\newcommand{\\x}{\\mathbf{x}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\yhat}{\\mathbf{\\hat{y}}}\n",
    "\\newcommand{\\0}{\\mathbf{0}}\n",
    "\\newcommand{\\1}{\\mathbf{1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee26ac3-9383-4332-84d9-e4a3264e9f64",
   "metadata": {},
   "source": [
    "## Mean Absolute Error\n",
    "\n",
    "Mean Absolute Error is a risk metric corresponding to the *expected* value of the absolute error loss or $l1$-norm loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2059f0e-753d-404c-9dd4-abe69d89629b",
   "metadata": {},
   "source": [
    "### Definition (Mean Absolute Error)\n",
    "\n",
    "Given a dataset of $n$ samples indexed by the tuple pair $(x_i, y_i)$, the **mean absolute error (MAE)** is defined as:\n",
    "\n",
    "$$\n",
    "\\textbf{MAE} = \\dfrac{\\sum_{i=1}^n |\\hat{y}_i - y_i|}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4721425-ebf0-46a3-8867-90beff508395",
   "metadata": {},
   "source": [
    "### Theorem (Optimality)\n",
    "\n",
    "In simple words, this is the property of **the median minimizes the sum of absolute error (${\\ell}_{1}$ loss).** This is important that one realises this when doing linear regression, and in complement to **the mean minimizes the root mean squared error**.\n",
    "\n",
    "For some proofs:\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Mean_absolute_error\n",
    "- https://math.stackexchange.com/questions/113270/the-median-minimizes-the-sum-of-absolute-deviations-the-ell-1-norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfb287d-317f-41d0-ace0-235cbae1a4e5",
   "metadata": {},
   "source": [
    "### Implementation of MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de821f33-dd29-4586-b75c-3aecefaca288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_absolute_error_(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Mean absolute error regression loss.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): Ground truth (correct) target values.\n",
    "        y_pred (np.ndarray): Estimated target values.\n",
    "\n",
    "    Shape:\n",
    "        y_true: (n_samples, )\n",
    "        y_pred: (n_samples, )\n",
    "\n",
    "    Returns:\n",
    "        loss (float): The mean absolute error.\n",
    "\n",
    "    Examples:\n",
    "        >>> y_true = [3, -0.5, 2, 7]\n",
    "        >>> y_pred = [2.5, 0.0, 2, 8]\n",
    "        >>> mean_absolute_error_(y_true, y_pred)\n",
    "        0.5\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).flatten()\n",
    "    y_pred = np.asarray(y_pred).flatten()\n",
    "    loss = np.mean(np.abs(y_true - y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0d670f4-a751-4ba0-bacf-4368225532f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> y_true = [3, -0.5, 2, 7]\n",
    ">>> y_pred = [2.5, 0.0, 2, 8]\n",
    ">>> mean_absolute_error_(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ced630-3927-423d-9be5-e0b13af7beb0",
   "metadata": {},
   "source": [
    "## (Root) Mean Squared Error\n",
    "\n",
    "Mean Squared Error is a risk metric corresponding to the *expected* value of the mean error loss or $l2$-norm loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ff64e9-c764-42a7-831b-dbc9209f0f32",
   "metadata": {},
   "source": [
    "### Definition (Root Mean Squared Error)\n",
    "\n",
    "Given a dataset of $n$ samples indexed by the tuple pair $(x_i, y_i)$, the **mean squared error (MSE)** is defined as:\n",
    "\n",
    "$$\n",
    "\\textbf{MSE} = \\dfrac{\\sum_{i=1}^n \\left(\\hat{y}_i - y_i\\right)^2}{n}\n",
    "$$\n",
    "\n",
    "and for **root mean squared error (RMSE)**\n",
    "\n",
    "$$\n",
    "\\textbf{RMSE} = \\sqrt{\\dfrac{\\sum_{i=1}^n \\left(\\hat{y}_i - y_i\\right)^2}{n}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62363148-377c-4968-8f40-50408fdd19ce",
   "metadata": {},
   "source": [
    "### Estimator\n",
    "\n",
    "The MSE of an estimator $\\hat{\\theta}$ with respect to an unknown parameter $\\theta$ is definend as:\n",
    "\n",
    "$$\n",
    "\\textbf{MSE}(\\hat{\\theta}) = E_{\\theta}\\left[\\left(\\hat{\\theta} - \\theta \\right)^2 \\right]\n",
    "$$\n",
    "\n",
    "The MSE can also be written as the sum of the variance and squared bias of the estimator, in which case if the estimators are unbiased, we recover the MSE to be equivalent as the variance:\n",
    "\n",
    "$$\n",
    "\\textbf{MSE}(\\hat{\\theta}) = \\textbf{Var}_{\\theta}\\left(\\hat{\\theta} \\right) + \\textbf{Bias}\\left(\\hat{\\theta}, \\theta \\right)^2\n",
    "$$\n",
    "\n",
    "Proof of which can be found in [Wikipedia: Mean_squared_error](https://en.wikipedia.org/wiki/Mean_squared_error)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7c489-bf8d-4292-9c09-cbaef4eee239",
   "metadata": {},
   "source": [
    "### Theorem (Optimality)\n",
    "\n",
    "The mean minimizes the mean squared error.\n",
    "\n",
    "Proof: https://math.stackexchange.com/questions/2554243/understanding-the-mean-minimizes-the-mean-squared-error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034e9062-cadf-4de8-b096-283061672d76",
   "metadata": {},
   "source": [
    "### Implementation of MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4b067af-164b-4968-b8ee-ecb8b8f743cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error_(\n",
    "    y_true: np.ndarray, y_pred: np.ndarray, squared: bool = True\n",
    ") -> float:\n",
    "    \"\"\"Mean squared error regression loss.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): Ground truth (correct) target values.\n",
    "        y_pred (np.ndarray): Estimated target values.\n",
    "        squared (bool): If True, returns MSE; if False, returns RMSE.\n",
    "\n",
    "    Shape:\n",
    "        y_true: (n_samples, )\n",
    "        y_pred: (n_samples, )\n",
    "\n",
    "    Returns:\n",
    "        loss (float): The mean squared error.\n",
    "\n",
    "    Examples:\n",
    "    >>> y_true = [3, -0.5, 2, 7]\n",
    "    >>> y_pred = [2.5, 0.0, 2, 8]\n",
    "    >>> mean_squared_error_(y_true, y_pred)\n",
    "        0.375\n",
    "    >>> mean_squared_error_(y_true, y_pred, squared=False)\n",
    "        0.612...\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).flatten()\n",
    "    y_pred = np.asarray(y_pred).flatten()\n",
    "\n",
    "    loss = np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "    return loss if squared else np.sqrt(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86811650-1efb-4049-984a-5a0dab365deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> y_true = [3, -0.5, 2, 7]\n",
    ">>> y_pred = [2.5, 0.0, 2, 8]\n",
    ">>> mean_squared_error_(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7df22a5-195a-41fa-a39c-77c2c6599c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6123724356957945"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> mean_squared_error_(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2be7340-bc66-4365-bd88-4f8e1fb04892",
   "metadata": {},
   "source": [
    "## Probabilistic Interpretation\n",
    "\n",
    "We can also understand regression metrics through the lens of statistics. For further reading, one should understand the below topics:\n",
    "\n",
    "- Loss Function: https://en.wikipedia.org/wiki/Loss_function#Expected_loss\n",
    "- Risk Function: https://en.wikipedia.org/wiki/Risk_function\n",
    "\n",
    "In particular, one should have a basic knowledge on [empirical risk minimization](https://en.wikipedia.org/wiki/Empirical_risk_minimization), that MSE can be understood as the *empirical risk* (average loss on an observed data set), as an **estimate** of the true MSE where the true risk refers to the average loss on the actual population distribution)[^mse_wiki].\n",
    "\n",
    "[^mse_wiki]: https://en.wikipedia.org/wiki/Mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4566fa4a-c674-4e52-9755-86e197af181b",
   "metadata": {},
   "source": [
    "## MAE vs R(MSE)\n",
    "\n",
    "For convenience sake, we compare MAE vs MSE and only mention RMSE for some special properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020c5c17-b474-4787-a247-7a951386918a",
   "metadata": {},
   "source": [
    "### Robustness to Outliers\n",
    "\n",
    "The naive rule of thumb points to the urban saying that MSE penalizes large errors while MAE does not. Let us see a simple example:\n",
    "\n",
    "- $y = 10$;\n",
    "- $\\hat{y}_{1} = 15$\n",
    "- $\\hat{y}_{2} = 20$\n",
    "\n",
    "where $\\hat{y}_{1}$ and $\\hat{y}_{2}$ are both predictions made on the ground truth $y = 10$.\n",
    "\n",
    "Then we easily see that:\n",
    "\n",
    "- $\\textbf{MAE}(y, \\hat{y}_{1}) = 5$\n",
    "- $\\textbf{MAE}(y, \\hat{y}_{2}) = 10$ \n",
    "- $\\textbf{MSE}(y, \\hat{y}_{1}) = 25$\n",
    "- $\\textbf{MSE}(y, \\hat{y}_{2}) = 100$\n",
    "\n",
    "We note that $\\hat{y}_{1}$ is off by 5 and $\\hat{y}_{2}$ is off by 10 from the ground truth. When comparing $\\hat{y}_{1}$ to $\\hat{y}_{2}$, we conclude that $\\hat{y}_{2}$ is off by exactly twice as $\\hat{y}_{1}$. \n",
    "\n",
    "Now, if we use MAE, we find out that by definition, the loss of $\\hat{y}_{2}$ will also be *exactly* twice of that $\\hat{y}_{1}$ but for MSE, it will be four times. We then can *naively* conclude that if your errors being off by 10 if *twice* as bad as being off by 5, then one should use MAE, if you foresee that being off by 10 is **more than twice as bad** as being off by 5, then MSE is better. [^mae_vs_mse]\n",
    "\n",
    "To put things in perspective, if you are predicting (.. fill in a good example).\n",
    "\n",
    "\n",
    "[^mae_vs_mse]: https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a09f44d-0fdb-4693-8783-724fbf6bfbfb",
   "metadata": {},
   "source": [
    "### Ease of Interpretation\n",
    "\n",
    "MAE clearly wins as the interpretation of this metric is simple. The units are on the same scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ef74f3-dfe3-48f9-b663-deb40a7fce79",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
