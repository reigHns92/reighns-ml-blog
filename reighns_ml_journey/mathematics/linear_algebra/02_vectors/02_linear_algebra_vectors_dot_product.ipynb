{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18de9b4e-6f8d-4a2a-a016-5cfd4bb81de8",
   "metadata": {},
   "source": [
    "$$\\newcommand{\\F}{\\mathbb{F}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\v}{\\mathbf{v}}\n",
    "\\newcommand{\\a}{\\mathbf{a}}\n",
    "\\newcommand{\\b}{\\mathbf{b}}\n",
    "\\newcommand{\\c}{\\mathbf{c}}\n",
    "\\newcommand{\\w}{\\mathbf{w}}\n",
    "\\newcommand{\\u}{\\mathbf{u}}\n",
    "\\newcommand{\\0}{\\mathbf{0}}\n",
    "\\newcommand{\\1}{\\mathbf{1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfcb049-5b1c-4f2f-aa7e-6eb2f198fbfb",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Table of Contents](#table-of-contents)\n",
    "- [Vector Multiplications](#vector-multiplications)\n",
    "  - [Dot Product](#dot-product)\n",
    "    - [Algebraic Definition (Dot Product)](#algebraic-definition-dot-product)\n",
    "      - [Example of Dot Product](#example-of-dot-product)\n",
    "    - [Dot Product (Geometric definition)](#dot-product-geometric-definition)\n",
    "      - [Scalar projections](#scalar-projections)\n",
    "      - [Sign of the DOT Product is determined by the Angle in between the two vectors](#sign-of-the-dot-product-is-determined-by-the-angle-in-between-the-two-vectors)\n",
    "    - [Intuition](#intuition)\n",
    "    - [Properties of Dot Product](#properties-of-dot-product)\n",
    "    - [Application to the law of cosines](#application-to-the-law-of-cosines)\n",
    "      - [Proof](#proof)\n",
    "  - [Cauchy-Schwarz Inequality](#cauchy-schwarz-inequality)\n",
    "    - [Definition (Cauchy-Schwarz Inequality)](#definition-cauchy-schwarz-inequality)\n",
    "    - [Proof of Algebraic and Geometric Equivalence of DOT Product](#proof-of-algebraic-and-geometric-equivalence-of-dot-product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c57caa-a66a-421c-a637-ea9bbd354557",
   "metadata": {},
   "source": [
    "!!! summary \"Learning Objectives\"\n",
    "    - Definition of a Vector Multiplications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f53d8-f995-404e-b51d-2e978d0d7b0f",
   "metadata": {},
   "source": [
    "## Vector Multiplications\n",
    "\n",
    "This section introduces one of the most important idea in Linear Algebra, the **Dot Product**. Since [Wikipedia](https://en.wikipedia.org/wiki/Dot_product)[^Dot_product] has a wholesome introduction, we will be copying over some definitions from it.\n",
    "\n",
    "\n",
    "[^Dot_product]: https://en.wikipedia.org/wiki/Dot_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9251313-d005-4423-9b53-42a1bb716591",
   "metadata": {},
   "source": [
    "### Dot Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead711b9-062f-42a0-b47c-d812083e3031",
   "metadata": {},
   "source": [
    "#### Algebraic Definition (Dot Product)\n",
    "\n",
    "!!! success \"Definition\"\n",
    "    The dot product of two vectors $\\color{red}{\\a =  \\begin{bmatrix} a_1  \\; a_2  \\; \\dots \\; a_n \\end{bmatrix}^{\\rm T}}$ and \n",
    "    $\\color{blue}{\\b =  \\begin{bmatrix} b_1 & b_2  & \\dots & b_n \\end{bmatrix}^{\\rm T}}$ is defined as:\n",
    "\n",
    "    $$\\mathbf{\\color{red}\\a}\\cdot\\mathbf{\\color{blue}\\b}=\\sum_{i=1}^n {\\color{red}a}_i{\\color{blue}b}_i={\\color{red}a}_1{\\color{blue}b}_1+{\\color{red}a}_2{\\color{blue}b}_2+\\cdots+{\\color{red}a}_n{\\color{blue}b}_n$$\n",
    "\n",
    "    where $\\sum$ denotes summation and $n$ is the dimension of the vector space. Since **vector spaces** have not been introduced, we just think of it as the $\\R^n$ dimensional space. \n",
    "\n",
    "##### Example of Dot Product\n",
    "\n",
    "!!! example\n",
    "    For instance, in 3-dimensional space, the **dot product** of column vectors $\\begin{bmatrix}1 & 3 & -5\\end{bmatrix}^{\\rm T}$ and $\\begin{bmatrix}4 & -2 & -2\\end{bmatrix}^{\\rm T}$\n",
    "\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\ [{\\color{red}1, 3, -5}] \\cdot  [{\\color{blue}4, -2, -1}] &= ({\\color{red}1} \\times {\\color{blue}4}) + ({\\color{red}3}\\times{\\color{blue}-2}) + ({\\color{red}-5}\\times{\\color{blue}-1}) \\\\\n",
    "    &= 4 - 6 + 5 \\\\\n",
    "    &= 3\n",
    "    \\end{align}\n",
    "    $$\n",
    "\n",
    "---\n",
    "\n",
    "!!! info \"Vector as Matrices\"\n",
    "\n",
    "    We are a little ahead in terms of the definition of Matrices, but for people familiar with it, or have worked with `numpy` before, we know that we can interpret a row vector of dimension $n$ as a matrix of dimension $1 \\times n$. Similarly, we can interpret a column vector of dimension $n$ as a matrix of dimension $n \\times 1$. With this interpretation, we can perform a so called \"matrix multiplication\" of the row vector and column vector. The result is the dot product. We will go in details when we get to it.\n",
    "\n",
    "    If vectors are treated like row matrices, the dot product can also be written as a matrix multiplication.\n",
    "\n",
    "    $$\\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} = \\mathbf{\\color{red}a}^\\mathsf T \\mathbf{\\color{blue}b}$$\n",
    "\n",
    "    Expressing the above example in this way, a 1 × 3 matrix **row vector** is multiplied by a 3 × 1 matrix **column vector** to get a 1 × 1 matrix that is identified with its unique entry:\n",
    "    $$\n",
    "      \\begin{bmatrix}\n",
    "       \\color{red}1 & \\color{red}3 & \\color{red}-5\n",
    "      \\end{bmatrix}\n",
    "      \\begin{bmatrix}\n",
    "       \\color{blue}4 \\\\ \\color{blue}-2 \\\\ \\color{blue}-1\n",
    "      \\end{bmatrix} = \\color{purple}3\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8eabd1-5093-49ea-b810-7b3cb8c46eda",
   "metadata": {},
   "source": [
    "#### Dot Product (Geometric definition)\n",
    "\n",
    "!!! success \"Definition\"\n",
    "    In [Euclidean space](Euclidean_space \"wikilink\"), a [Euclidean vector](Euclidean_vector \"wikilink\") is a geometric object that possesses both a magnitude and a direction. A vector can be pictured as\n",
    "    an arrow. Its magnitude is its length, and its direction is the direction to which the arrow points. The magnitude of a vector **a** is denoted by $\\left\\| \\mathbf{a} \\right\\|$. The dot product of two\n",
    "    Euclidean vectors **a** and **b** is defined by\n",
    "    \n",
    "    $$\\mathbf{a}\\cdot\\mathbf{b}=\\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta ,$$\n",
    "    \n",
    "    where $\\theta$ is the angle between $\\a$ and $\\b$.\n",
    "\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/linear_algebra/linear_algebra_theory_intuition_code_chap3_fig_3.1_scalar_projection_and_dot_product.PNG\" style=\"margin-left:auto; margin-right:auto\"/>\n",
    "<p style=\"text-align: center\">\n",
    "    <b>Fig 3.11: Diagram of Scalar Projection and Dot Product; By Hongnan G.</b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41836dac-e5fb-4d7c-8052-820124a8cebc",
   "metadata": {},
   "source": [
    "##### Scalar projections\n",
    "\n",
    "TODO: To motivate the geometric interpretation, we should see the example on scalar projections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e103b15b-4d4d-4d89-9658-3a4a845a5f1c",
   "metadata": {},
   "source": [
    "##### Sign of the DOT Product is determined by the Angle in between the two vectors\n",
    "\n",
    "!!! note \"Refactor Geometric Formula\"\n",
    "    The geometric definition can be re-written as follows:\n",
    "\n",
    "    \\begin{equation} \\label{eq1}\n",
    "    \\begin{split}\n",
    "    \\mathbf{a}\\cdot\\mathbf{b} &=\\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta \\implies \\cos(\\theta) = \\frac{\\a^\\top \\b}{\\|\\a\\| \\|\\b\\|} \\implies \\theta = \\cos^{-1}\\left(\\frac{\\a^\\top \\b}{\\|\\a\\| \\|\\b\\|}\\right)\n",
    "    \\end{split}\n",
    "    \\end{equation}\n",
    "\n",
    "    which essentially means that one can find the angle between two known vectors in any dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de6bd08-e99c-4f16-86c7-181c7de828e6",
   "metadata": {},
   "source": [
    "Mike X Cohen explains in **Linear Algebra: Theory, Intuition, Code, 2021. (pp. 51-52)** how the **sign** of the dot product is determined solely by the angle between the two vectors.\n",
    "**By definition**,\n",
    "$\\mathbf{a\n",
    "}\\cdot\\mathbf{b} = \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta$, we know that the sign (positive or negative) of the dot product $\\a \\cdot \\b$ is solely determined by $\\cos \\theta$ since $\\|\\a\\| \\|\\b\\|$ is always positive.\n",
    "\n",
    "- **Case 1 ($0< \\theta < 90$): This implies that $\\cos \\theta > 0 \\implies \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta > 0 \\implies \\mathbf{a}\\cdot\\mathbf{b} > 0$.**\n",
    "- **Case 2 ($90 < \\theta < 180$): This implies that $\\cos \\theta < 0 \\implies \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta < 0 \\implies \\mathbf{a}\\cdot\\mathbf{b} < 0$.**\n",
    "- **Case 3 ($\\theta = 90$): This is an important property, for now, we just need to know that since $\\cos \\theta = 0$, then $\\a \\cdot \\b = \\0$. These two vectors are orthogonal.**\n",
    "- **Case 4 ($\\theta = 0$ or $\\theta = 180$): This implies that $\\cos \\theta = 1 \\implies \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|\\cos\\theta = \\|\\mathbf{a}\\|\\ \\|\\mathbf{b}\\|$. We say these two vectors are collinear.**\n",
    "\n",
    "!!! note \"Consequence of Case 4\"\n",
    "    A simple consequence of case 4 is that if a vector $\\a$ dot product with itself, then by case 4, we have $\\a \\cdot \\a = \\|\\a\\|^2 \\implies \\|\\a\\| = \\sqrt{\\a \\cdot \\a}$ which is the formula of the  [Euclidean length](Euclidean_length \"wikilink\") of the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2b5a24-242b-4477-9064-f85e2c02ab33",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/linear_algebra/linear_algebra_theory_intuition_code_chap3_fig_3.2.svg\" style=\"margin-left:auto; margin-right:auto\"/>\n",
    "<p style=\"text-align: center\">\n",
    "    <b>Fig 3.2: Sign of Dot Product and Angle between two vectors; By Hongnan G.</b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86721c0-bc0f-4398-9d0a-62b596160998",
   "metadata": {},
   "source": [
    "#### Intuition\n",
    "\n",
    "\n",
    "- https://flexbooks.ck12.org/cbook/ck-12-college-precalculus/section/9.6/primary/lesson/scalar-and-vector-projections-c-precalc/\n",
    "- https://www.quora.com/What-are-the-geometrical-meanings-of-a-dot-product-and-cross-product-of-a-vector\n",
    "- https://math.stackexchange.com/questions/805954/what-does-the-dot-product-of-two-vectors-represent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b03ca-98b7-4e80-93d9-8e15f2850379",
   "metadata": {},
   "source": [
    "#### Properties of Dot Product\n",
    "\n",
    "!!! info \"Properties of Dot Product\"\n",
    "    The **dot product**[^dot_product] fulfills the following properties if **a**, **b**, and **c** are real [vectors](vector_(geometry) \"wikilink\") and $\\lambda$ is a [scalar](scalar_(mathematics) \"wikilink\").\n",
    "\n",
    "    1.  **[Commutative](Commutative \"wikilink\"):**\n",
    "\n",
    "        $\\mathbf{a} \\cdot \\mathbf{b} = \\mathbf{b} \\cdot \\mathbf{a} ,$\n",
    "        which follows from the definition (*θ* is the angle between **a** and **b**): $\\mathbf{a} \\cdot \\mathbf{b} = \\left\\| \\mathbf{a} \\right\\| \\left\\| \\mathbf{b} \\right\\| \\cos \\theta = \\left\\| \\mathbf{b} \\right\\| \\left\\| \\mathbf{a} \\right\\| \\cos \\theta = \\mathbf{b} \\cdot \\mathbf{a} .$\n",
    "\n",
    "    2.  **[Distributive](Distributive_property \"wikilink\") over vector\n",
    "        addition:**\n",
    "\n",
    "        $\\mathbf{a} \\cdot (\\mathbf{b} + \\mathbf{c}) = \\mathbf{a} \\cdot \\mathbf{b} + \\mathbf{a} \\cdot \\mathbf{c} .$\n",
    "\n",
    "    3.  **[Bilinear](bilinear_form \"wikilink\")**:\n",
    "\n",
    "        $\\mathbf{a} \\cdot ( \\lambda \\mathbf{b} + \\mathbf{c} ) = \\lambda ( \\mathbf{a} \\cdot \\mathbf{b} ) + ( \\mathbf{a} \\cdot \\mathbf{c} ) .$\n",
    "\n",
    "    4.  **[Scalar multiplication](Scalar_multiplication \"wikilink\"):**\n",
    "\n",
    "        $( \\lambda_1 \\mathbf{a} ) \\cdot ( \\lambda_2 \\mathbf{b} ) = \\lambda_1 \\lambda_2 ( \\mathbf{a} \\cdot \\mathbf{b} ) .$\n",
    "\n",
    "    5.  **Not [associative](associative \"wikilink\")**:\n",
    "    \n",
    "        This is because the dot\n",
    "        product between a scalar (**a ⋅ b**) and a vector (**c**) is not\n",
    "        defined, which means that the expressions involved in the\n",
    "        associative property, (**a ⋅ b**) ⋅ **c** or **a** ⋅ (**b ⋅ c**) are\n",
    "        both ill-defined. Note however that the previously mentioned\n",
    "        scalar multiplication property is sometimes called the \"associative\n",
    "        law for scalar and dot product\" or one can say that \"the dot\n",
    "        product is associative with respect to scalar multiplication\"\n",
    "        because $\\lambda (\\a \\cdot \\b) = (\\lambda \\a) \\cdot \\b = \\a \\cdot (\\lambda\n",
    "        \\b)$.\n",
    "\n",
    "    6.  **[Orthogonal](Orthogonal \"wikilink\"):**\n",
    "\n",
    "        Two non-zero vectors **a** and **b** are *orthogonal* if and only if $\\a \\cdot \\b = \\0$.\n",
    "\n",
    "    7.  **No [cancellation](cancellation_law \"wikilink\"):**\n",
    "    \n",
    "        Unlike multiplication of ordinary numbers, where if $ab=ac$  then *b* always equals *c* unless *a* is zero, the dot product does not obey the [cancellation law](cancellation_law \"wikilink\").\n",
    "\n",
    "    8.  **[Product Rule](Product_Rule \"wikilink\"):**\n",
    "\n",
    "         If **a** and **b** are (vector-valued) [differentiable functions](differentiable_function \"wikilink\"), then the derivative, denoted by a prime ' of $\\a \\cdot \\b$ is given by the rule $(\\a \\cdot \\b)' = \\a' \\cdot \\b + \\a \\cdot \\b'$.\n",
    "\n",
    "    [^dot_product]: https://en.wikipedia.org/wiki/Dot_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8815589e-bf42-4a0d-9562-2af147d2db02",
   "metadata": {},
   "source": [
    "#### Application to the law of cosines\n",
    "\n",
    "A triangle with lines a, b and c is presented in figure 3.31, a and b are separated by angle *θ*, then the **law of cosine** states that \n",
    "\n",
    "$$\\Vert c \\Vert^2 = \\Vert a \\Vert^2 + \\Vert b \\Vert^2 - 2ab\\cos(\\theta)$$\n",
    "\n",
    "##### Proof\n",
    "\n",
    "The proof is from Wikipedia[^law_of_cosine_vector_proof].\n",
    "\n",
    "Denote\n",
    "\n",
    "$$\\overrightarrow{CB}=\\vec{a}, \\ \\overrightarrow{CA}=\\vec{b}, \\ \\overrightarrow{AB}=\\vec{c}$$\n",
    "\n",
    "Therefore,\n",
    " \n",
    "$$\\vec{c} = \\vec{a}-\\vec{b}$$\n",
    "\n",
    "Taking the dot product of each side with itself:\n",
    "\n",
    "$$\\vec{c}\\cdot\\vec{c} = (\\vec{a}-\\vec{b})\\cdot(\\vec{a}-\\vec{b})$$\n",
    "$$\\Vert\\vec{c}\\Vert^2 = \\Vert\\vec{a}\\Vert^2 + \\Vert\\vec{b}\\Vert^2 - 2\\,\\vec{a}\\cdot\\vec{b}$$\n",
    "\n",
    "Using the identity (see [[Dot product]]) \n",
    "\n",
    "$$\\vec{u}\\cdot\\vec{v} = \\Vert\\vec{u}\\Vert\\,\\Vert\\vec{v}\\Vert \\cos\\angle(\\vec{u}, \\ \\vec{v})$$\n",
    "\n",
    "leads to\n",
    "\n",
    "$$\\Vert\\vec{c}\\Vert^2 = \\Vert\\vec{a}\\Vert^2 + {\\Vert\\vec{b}\\Vert}^2 - 2\\,\\Vert\\vec{a}\\Vert\\!\\;\\Vert\\vec{b}\\Vert \\cos\\angle(\\vec{a}, \\ \\vec{b})$$\n",
    "\n",
    "The result follows.\n",
    "\n",
    "---\n",
    "\n",
    "In short, the proof is presented below:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbf{\\color{orange}c} \\cdot \\mathbf{\\color{orange}c}  & = ( \\mathbf{\\color{red}a} - \\mathbf{\\color{blue}b}) \\cdot ( \\mathbf{\\color{red}a} - \\mathbf{\\color{blue}b} ) \\\\\n",
    " & = \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{red}a} - \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} - \\mathbf{\\color{blue}b} \\cdot \\mathbf{\\color{red}a} + \\mathbf{\\color{blue}b} \\cdot \\mathbf{\\color{blue}b} \\\\\n",
    " & = \\mathbf{\\color{red}a}^2 - \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} - \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} + \\mathbf{\\color{blue}b}^2 \\\\\n",
    " & = \\mathbf{\\color{red}a}^2 - 2 \\mathbf{\\color{red}a} \\cdot \\mathbf{\\color{blue}b} + \\mathbf{\\color{blue}b}^2 \\\\\n",
    "\\mathbf{\\color{orange}c}^2 & = \\mathbf{\\color{red}a}^2 + \\mathbf{\\color{blue}b}^2 - 2 \\mathbf{\\color{red}a} \\mathbf{\\color{blue}b} \\cos \\mathbf{\\color{purple}\\theta} \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "which is the [law of cosines](law_of_cosines \"wikilink\").\n",
    "\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/reighns/reighns_ml_projects/docs/linear_algebra/linear_algebra_theory_intuition_code_chap3_fig_3.31_law_of_cosine.svg\" style=\"margin-left:auto;margin-center:auto; margin-right:auto\"/>\n",
    "<p style=\"text-align: center\">\n",
    "    <b>Fig 3.31; Law of Cosine;</b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ce08eb-47e1-4900-bc58-c4ad4df27d69",
   "metadata": {},
   "source": [
    "### Cauchy-Schwarz Inequality\n",
    "\n",
    "#### Definition (Cauchy-Schwarz Inequality)\n",
    "\n",
    "!!! success \"Definition\"\n",
    "    Let two vectors $\\v$ and $\\w$ be in a field $\\F^n$, then the inequality\n",
    "\n",
    "    $$|\\v^\\top \\w| \\leq \\Vert \\v \\Vert \\Vert \\w \\Vert$$ \n",
    "\n",
    "    holds. \n",
    "\n",
    "---\n",
    "\n",
    "> This inequality provides an **upper bound** for the dot product between two vectors; in other words, the absolute value of the dot product between two vectors cannot be larger than the product of the norms of the individual vectors. Note that the inequality can become an equality if and only if both vectors are the zero vector $\\0$ or if one vector (either one) is scaled by the other vector $\\v = \\lambda \\w$.  - **Mike X Cohen, Linear Algebra: Theory, Intuition, Code**\n",
    "\n",
    "If you wonder why when $\\v = \\lambda \\w$ implies equality, it is apparent if you do a substitution as such \n",
    "\n",
    "$$|\\v^\\top \\w| = |\\lambda \\w^\\top \\w| = \\lambda |\\w^\\top \\w| = \\lambda \\|\\w\\|^2 = \\lambda \\|\\w\\| \\|\\w\\| = \\|\\v\\| \\|\\w\\|$$\n",
    "\n",
    "where we used the fact that $\\w^\\top \\w = \\|\\w\\|^2$ by definition.\n",
    "\n",
    "The author decided to include this inequality here because this theorem is always used in many proofs. He then shows a use case in the Geometric Interpretation of the Dot Product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380fbe90-a4e7-4eee-a3a6-68bc28b24c38",
   "metadata": {},
   "source": [
    "#### Proof of Algebraic and Geometric Equivalence of DOT Product\n",
    "\n",
    "Read [here](https://proofwiki.org/wiki/Equivalence_of_Definitions_of_Dot_Product) and also page 54-56 of Mike's book."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
